"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Perceptual interactions in thermo-tactile displays","A. Singhal; L. A. Jones","Department of Mechanical Engineering, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, MA 02139, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, MA 02139, USA","2017 IEEE World Haptics Conference (WHC)","27 Jul 2017","2017","","","90","95","Thermo-tactile displays have been developed to enhance the degree of realism in virtual environments and assist in the identification of virtual objects. It is unknown whether the simultaneous presentation of thermal and tactile cues enhances user performance and if the two types of sensory signals can be processed independently or interact. The present experiment measured thermal pattern identification in the presence of concurrent vibrotactile feedback on the thenar eminence on the hand. The thermal patterns varied with respect to the direction, rate, and duration of the change in skin temperature and for the vibration inputs the number of pulses was varied. The results indicated that with concurrent tactile stimulation warm stimuli (89%) were easier to identify than cool stimuli (76%) and that the number of pulses in the vibration signal affected thermal identification. The mean Information Transfer (IT) associated with these thermo-tactile patterns was 1.94 bits. These thermal-tactile interactions indicate that in multi-sensory displays the ability to perceive independent channels of communication can be influenced by the concurrent presentation of other sensory cues.","","978-1-5090-1425-5","10.1109/WHC.2017.7989882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7989882","","Skin;Temperature measurement;Temperature sensors;Thumb;Thermistors;Vibrations","force feedback;haptic interfaces;screens (display);vibrations","perceptual interactions;thermo-tactile displays;virtual environments;virtual object identification;thermal cues;tactile cues;sensory signals;thermal pattern identification;concurrent vibrotactile feedback;thenar eminence;skin temperature;concurrent tactile stimulation;warm stimuli;cool stimuli;vibration signal;information transfer;thermo-tactile patterns;thermal-tactile interactions;multisensory displays;sensory cues","","6","","34","","27 Jul 2017","","","IEEE","IEEE Conferences"
"Simulator-Based Team Training to Share Resources in a Matrix Structure Organization","L. Davidovitch; A. Parush; A. Shtub","Industrial Engineering and Management Faculty , Technion Israel Institute of Technology, Haifa, Israel; Department of Psychology, Carleton University, Ottawa, Canada; Industrial Engineering and Management Faculty , Technion Israel Institute of Technology, Haifa, Israel","IEEE Transactions on Engineering Management","19 Apr 2010","2010","57","2","288","300","Project management in a matrix organization is complex because project managers share the organization resources (budget and human), and cooperation between managers is critical for effective resource sharing. Therefore, training project managers in the matrix structure to work as a team is required. A simulator-based method to train managers to work as a team is presented. A project team builder (PTB) simulating a dynamic, stochastic multiproject environment was designed and implemented in a project management course for graduate students in systems engineering. Recording the learning history and having a debriefing mechanism were implemented as mechanisms to facilitate team learning. A total of 132 participants composed of graduate students, representing experienced managers, and undergraduate students as inexperienced managers, assigned into teams of three participants each, used the simulator in a multiuser multi-project mode. The findings indicate that for the initial learning phase and transfer to a different scenario, the three factors, history, debriefing, and experience, affected the performances. Furthermore, the interactions between the debriefing and history factors, between the experience and debriefing factors, and between the history and experience factors were all significant. Based on these findings, a new paradigm for a simulation-based team learning is presented.","1558-0040","","10.1109/TEM.2009.2023142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5433056","Collective learning;experience;experiential team learning;feedback;history recording;matrix structure organization;project management;simulator-based team learning;team debriefing","History;Organizations;Project management;Training;Book reviews;Resource management;Modeling","continuing education;engineering education;industrial training;management education;management training;project management;team working","simulator-based team training;matrix structure organization;project management;organization resources sharing;project team builder;graduate students;systems engineering;team learning;undergraduate students;teamwork","","10","","61","","18 Mar 2010","","","IEEE","IEEE Journals"
"A constraint-based technique for haptic volume exploration","M. Ikits; J. D. Brederson; C. D. Hansen; C. R. Johnson","Sci. Comput. & Imaging Inst., Utah Univ., USA; Sci. Comput. & Imaging Inst., Utah Univ., USA; Sci. Comput. & Imaging Inst., Utah Univ., USA; Sci. Comput. & Imaging Inst., Utah Univ., USA","IEEE Visualization, 2003. VIS 2003.","8 Dec 2003","2003","","","263","269","We present a haptic rendering technique that uses directional constraints to facilitate enhanced exploration modes for volumetric datasets. The algorithm restricts user motion in certain directions by incrementally moving a proxy point along the axes of a local reference frame. Reaction forces are generated by a spring coupler between the proxy and the data probe, which can be tuned to the capabilities of the haptic interface. Secondary haptic effects including field forces, friction, and texture can be easily incorporated to convey information about additional characteristics of the data. We illustrate the technique with two examples: displaying fiber orientation in heart muscle layers and exploring diffusion tensor fiber tracts in brain white matter tissue. Initial evaluation of the approach indicates that haptic constraints provide an intuitive means or displaying directional information in volume data.","","0-7803-8120-3","10.1109/VISUAL.2003.1250381","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1250381","","Haptic interfaces;Probes;Rendering (computer graphics);Data visualization;Feedback;Friction;Computer graphics;Scientific computing;Springs;Optical fiber couplers","haptic interfaces;data visualisation;virtual reality;medical computing;transfer functions","constraint-based technique;haptic volume exploration;haptic rendering;directional constraints;exploration modes;volumetric datasets;reaction forces;spring coupler;data probe;haptic effects;field forces;fiber orientation;heart muscle layers;diffusion tensor fiber tracts;brain white matter tissue;directional information;immersive visualization;human-computer interaction","","28","","43","","8 Dec 2003","","","IEEE","IEEE Conferences"
"Effect of security education using KIPS and gamification theory at KOSEN","K. Yonemura; R. Komura; J. Sato; T. Hoga; Y. Takeichi; E. Chida; M. Matsuoka","Dept. of Information and Computer Engineering, National Institute of Technology, Kisarazu College, Kisarazu-City, Chiba, Japan; Dept. of Electronics and Information Engineering, National Institute of Technology, Ishikawa College, Tsubata-City, Ishikawa, Japan; Dept. of Electrical and Electronic Engineering, National Institute of Technology, Tsuruoka College, Tsuruoka-City, Yamagata, Japan; Dept. of Electrical and Electronic Engineering, National Institute of Technology, Tsuruoka College, Tsuruoka-City, Yamagata, Japan; Dept. of Electrical and Electronic Engineering, National Institute of Technology, Tsuruoka College, Tsuruoka-City, Yamagata, Japan; Dept. of Electrical and Computer Engineering, National Institute of Technology, Ichinoseki College, Ichinoseki-City, Iwate, Japan; Kaspersky Labs Japan, Chiyoda-Ku, Tokyo, Japan","2018 IEEE Symposium on Computer Applications & Industrial Electronics (ISCAIE)","9 Jul 2018","2018","","","255","258","To produce human resources who are good at OT security is important task for KOSEN which is closely cooperation with the industry on which faces increasing cyber-attacks. We examined the educational effect and issues on multiple practicing of KIPS (Kaspersky Industrial Protection Simulation) which is based on gamification. Practicing experimental results showed that multiple playing simple contribute to the positive educational effect and we find the possibility of positive skill transfer, however we obtained a great future work which we need the educational contents that can fill the gap of multiple practicing effectively. KOSEN has the big mission that updates the practice-based curriculum constantly.","","978-1-5386-3527-8","10.1109/ISCAIE.2018.8405480","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405480","security education;gamifcationy;operational technology;ICT;KOSEN","Computer security;Education;Industries;Correlation;Games;Problem-solving","computer aided instruction;computer games;computer science education;educational courses;human computer interaction;security of data","security education;KIPS;gamification theory;KOSEN;human resources;OT security;cyber-attacks;Kaspersky Industrial Protection Simulation;educational contents;practice-based curriculum","","","","7","","9 Jul 2018","","","IEEE","IEEE Conferences"
"A network-adaptive compensation technique for tele-haptics using position prediction algorithm","T. H. Tee; K. S. Eu; K. M. Yap; A. Marshall; T. Lee","Faculty of Science and Technology, Sunway University, Bandar Sunway, Malaysia; Faculty of Science and Technology, Sunway University, Bandar Sunway, Malaysia; Faculty of Science and Technology, Sunway University, Bandar Sunway, Malaysia; School of Electronics, Electrical Engineering and Computer Science, Queens University Belfast, Northern Ireland, UK; Department of Computer and Information Science, National Taichung University, Taiwan","2013 IEEE International Symposium on Haptic Audio Visual Environments and Games (HAVE)","12 Dec 2013","2013","","","39","44","Haptic interfaces have been applied as controllers in many areas especially tele-operation and distributed virtual environments. They are used to manipulate objects in both physical and virtual environments. Haptics enhance force interactions and provides a better immersive user experience. Moreover haptic devices inherently function in close proximity to humans. In the case of network-based haptic control, the network criteria for stability in haptic interactions are much more sophisticated than that for tethered devices and the kinematic and force data are required to be transferred over communication link within a stringent time. Otherwise, users may feel unexpected vibration or abrupt force even when the device is in free motion. This is mainly due to position de-synchronization between local and remote environments. This paper addresses position synchronization which is the essential problem to lose stability of haptic experience under the influence of network and system impairments. A novel encoder referencing position synchronization algorithm is proposed in order to compensate the network latency and packet loss over network. This has been successfully tested under influence of the network impairment and low transmission rates.","","978-1-4799-0849-3","10.1109/HAVE.2013.6679608","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6679608","haptic traffic;tele-haptic;position prediction;network impairment;network-adaptive compensation","Haptic interfaces;Packet loss;Delays;Jitter;Prediction algorithms;Equations","compensation;haptic interfaces;virtual reality","network-adaptive compensation technique;tele-haptics;position prediction algorithm;haptic interfaces;tele-operation;distributed virtual environments;object manipulation;physical environment;force interactions;immersive user experience;network-based haptic control;network criteria;stability;haptic interactions;communication link;position de-synchronization;haptic experience;encoder referencing position synchronization algorithm;network impairment","","3","","15","","12 Dec 2013","","","IEEE","IEEE Conferences"
"Efficient reinforcement learning for robots using informative simulated priors","M. Cutler; J. P. How","Laboratory of Information and Decision Systems, Massachusetts Institute of Technology, 77 Massachusetts Ave., Cambridge, USA; Laboratory of Information and Decision Systems, Massachusetts Institute of Technology, 77 Massachusetts Ave., Cambridge, USA","2015 IEEE International Conference on Robotics and Automation (ICRA)","2 Jul 2015","2015","","","2605","2612","Autonomous learning through interaction with the physical world is a promising approach to designing controllers and decision-making policies for robots. Unfortunately, learning on robots is often difficult due to the large number of samples needed for many learning algorithms. Simulators are one way to decrease the samples needed from the robot by incorporating prior knowledge of the dynamics into the learning algorithm. In this paper we present a novel method for transferring data from a simulator to a robot, using simulated data as a prior for real-world learning. A Bayesian nonparametric prior is learned from a potentially black-box simulator. The mean of this function is used as a prior for the Probabilistic Inference for Learning Control (PILCO) algorithm. The simulated prior improves the convergence rate and performance of PILCO by directing the policy search in areas of the state-space that have not yet been observed by the robot. Simulated and hardware results show the benefits of using the prior knowledge in the learning framework.","1050-4729","978-1-4799-6923-4","10.1109/ICRA.2015.7139550","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7139550","","Heuristic algorithms;Robots;Data models;Gaussian processes;Hardware;Prediction algorithms;Mathematical model","Bayes methods;learning (artificial intelligence);learning systems;nonparametric statistics;robots","reinforcement learning algorithm;informative simulated priors;autonomous learning;decision-making policy;controller design;Bayesian nonparametric prior;black-box simulator;probabilistic inference for learning control algorithm;PILCO algorithm;convergence rate","","27","","24","","2 Jul 2015","","","IEEE","IEEE Conferences"
"Video game experience and basic robotic skills","A. Tanaka; R. Smith; C. Hughes","The Nicholson Center, Florida Hospital, Celebration, US; The Nicholson Center, Florida Hospital, Celebration, US; Department of Computer Science, The University of Central Florida, Orlando, US","2016 IEEE International Conference on Serious Games and Applications for Health (SeGAH)","10 Oct 2016","2016","","","1","6","Virtual reality simulators have emerged as valuable tools for standardized and objective robotic surgery skill training and assessments. In recent years the idea of using video game technology in surgical education for laparoscopy has also been explored, however few have attempted to make a connection between video game experience and robotic surgical skills. Thus, the current study aims to examine the performance of video gamers in a virtual reality robotic surgery simulator. Furthermore, the video gamers' performance was compared to that of medical students, expert robotic surgeons, and “laypeople.” The purpose of this study is to demonstrate that video gamers acquire perceptual and psychomotor skills through video game play, similar to those used by robotic surgeons. Subjects completed a demographic questionnaire and performed three computer-based perceptual tests: a Flanker compatibility task, a subsidizing task, and a Multiple Object Tracking test. Participants then performed two warm-up exercises and eight trials of two core exercises on a robotic surgery simulator. After completing all trials, participants completed a post-questionnaire regarding their experience with the system. Expert video gamers (n=40), medical students (n=24), laypeople (n=42) and expert robotic surgeons (n=16) were recruited. Medical students and gamers were significantly faster than experts in the Flanker Task. The experts were significantly slower than the all other groups in the subsidizing task. Experts scored significantly higher, were significantly more efficient, and were significantly faster than laypeople, medical students, and gamers in the first trial of Ring & Rail 1 and Suture Sponge. In trial eight of the simulation exercises, the experts performed significantly better than most groups in all of the metrics. Contrary to prior literature in laparoscopy, this study was unable to validate enhanced abilities of video gamers in a robotic surgery simulator. This study does further demonstrate that the transfer of skills developed through video game play is relevant to the surgical technique. This may be due to the differences of the systems and how the users interact within them. In a society where video games have become an integral past time, it is important to determine the role that video games play in the perceptual and psychomotor development of users. These findings can be generalized to domains outside of medicine that utilize robotic and computer-controlled systems, speaking to the scope of the gamers' abilities and pointing to the capacity within these systems.","","978-1-5090-2210-6","10.1109/SeGAH.2016.7586262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586262","","Surgery;Robots;Measurement;Games;Training;Rails;Cameras","biomedical education;computer aided instruction;computer games;educational robots;human-robot interaction;medical computing;medical robotics;surgery;virtual reality","video game experience;basic robotic skills;virtual reality robotic surgery simulator;standardized robotic surgery skill training;objective robotic surgery skill training;standardized robotic surgery skill assessment;objective robotic surgery skill assessment;surgical education;laparoscopy;video game technology;perceptual skill acquisition;psychomotor skill acquisition;computer-based perceptual tests;flanker compatibility task;subsidizing task;multiple object tracking test;computer-controlled systems","","1","","17","","10 Oct 2016","","","IEEE","IEEE Conferences"
"Cross-reality Services for 3D Virtual Environments","K. P. C. Madhavan; J. Upham; B. Sterrett; J. Fisher; S. Goasguen","Member, Clemson University, Clemson, SC 29634. phone: 864-656-5874; fax: 864-656-0145; e-mail: cm@clemson.edu; Clemson Univ., Clemson, SC, USA; Clemson Univ., Clemson, SC, USA; Clemson Univ., Clemson, SC, USA; Senior Member, IEEE, Clemson University, Clemson, SC 29634. phone: 864-656-6753; fax: 864-656-0145; e-mail: sebgoa@clemson.edu","2008 Grid Computing Environments Workshop","6 Jan 2009","2008","","","1","7","In this paper we present results on the design and testing of new middleware services for cross-reality data/insight transfer between the real-world and 3D virtual environments. We highlight the architecture that is used along with the implementation of a cyberinfrastructure toolbox containing a set of tools in a virtual environment. The toolbox itself uses a service-oriented architecture to implement a variety of services - such as Location Service, Social Tagging Service, Interaction with real-world compute resources, and real-time cross-reality sensor data transfer. The driving concept behind the middleware implementation is the use of proxy services with straightforward REST interfaces. This paper expands on prior work and shows progress towards the integration of education and research in a common environment.","2152-1093","978-1-4244-2860-1","10.1109/GCE.2008.4738440","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4738440","Learning systems;cyber-enabled education;future virtual environments;virtual worlds;informal science education;beyond web 2.0;design;experimentation;theory","Virtual environment;Middleware;Tagging;Computer architecture;Instruments;Second Life;Feedback;Social network services;Prototypes;Educational technology","middleware;software architecture;virtual reality;Web services","cross-reality services;3D virtual environments;middleware services;cyberinfrastructure toolbox;service-oriented architecture;location service;social tagging service;real-time cross-reality sensor data transfer;proxy services;REST interfaces","","","","11","","6 Jan 2009","","","IEEE","IEEE Conferences"
"Transparency and stability analysis of a surgical teleoperator system","H. Flemmer; J. Wikander","Mechatronics Lab/Machine Design, R. Inst. of Technol., Stockholm, Sweden; Mechatronics Lab/Machine Design, R. Inst. of Technol., Stockholm, Sweden","11th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, 2003. HAPTICS 2003. Proceedings.","2 Apr 2003","2003","","","382","389","This paper discusses transparency and stability issues for a three channel teleoperator system to be used in sensitive skullbase operations. Based on a design model of the combined master human system with parameter uncertainties and teleoperator optimal transparency conditions, the interaction (communication) channel controllers are derived. One of the interaction channel controllers is then altered to make the teleoperator closed loop meet requirements imposed by the robustness property passivity. Transparency of the teleoperator system is analysed by analysing the gain plots of all the four transfer functions in the H-matrix. The three channel teleoperator is found to have a bandwidth of around 90 rad/sec in the force reflection channel, a small influence on the reflected force from the master velocity for low frequencies, a bandwidth of 150 rad/sec in the forward channel and a slave which is relatively unaffected by external forces. The theoretical results from the stability analysis are verified by experimental results.","","0-7695-1890-7","10.1109/HAPTIC.2003.1191319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1191319","","Stability analysis;Surgery;Teleoperators;Communication system control;Bandwidth;Humans;Uncertain systems;Optimal control;Robust control;Transfer functions","telerobotics;surgery;haptic interfaces;matrix algebra;stability;medical robotics;telemedicine;force feedback","stability analysis;surgical teleoperator system;transparency;three channel teleoperator system;sensitive skullbase operations;parameter uncertainties;optimal transparency conditions;interaction channel controllers;robustness;passivity;transfer functions;telerobotic system;H-matrix;bandwidth;force reflection channel;experimental results","","4","","22","","2 Apr 2003","","","IEEE","IEEE Conferences"
"A Simple and Real-Time Parallel Compression of Time Series Scientific Simulation Data for Interactive and Cooperative Supercomputing","W. Liu; X. Hei; S. Fukuma; S. Mori","Comput. Sci. & Eng., Xi'an Univ. of Technol., Xi'an, China; Comput. Sci. & Eng., Xi'an Univ. of Technol., Xi'an, China; Grad. Sch. of Eng., Univ. of Fukui, Fukui, Japan; Grad. Sch. of Eng., Univ. of Fukui, Fukui, Japan","2014 Tenth International Conference on Computational Intelligence and Security","22 Jan 2015","2014","","","578","582","In order to realize a cooperative supercomputing environment, Large-scale scientific simulation data should be exchanged among supercomputers over the Internet. To maintain the interactivity of the time-series simulation in such an environment, real-time data compression is required. Given the accuracy requirements of scientific simulation, we only focus on lossless data compression. In this paper, we propose Think Mantissa as Integer method to decrease the entropy of scientific datasets, achieving a good compression ratio and speeds. We evaluate this scheme in two experiments and compare it with the existing compression strategies (gzip, bzip2). Our approach gets about a 30% improvement in the compression ratio and hundreds of times speed acceleration. We also computed the total time of the data transfer using this method under some specific bandwidth cases, and nearly all of them have gotten a good acceleration.","","978-1-4799-7434-4","10.1109/CIS.2014.107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7016962","Lossless compression;Parallel Processing;Real-time Interaction;Supercomputing","Data models;Computational modeling;Data compression;Time series analysis;Parallel processing;Computational efficiency;Fluids","data compression;interactive systems;parallel processing;real-time systems;scientific information systems;time series","parallel compression;time series scientific simulation data;interactive cooperative supercomputing;cooperative supercomputing environment;large-scale scientific simulation data;supercomputers;time-series simulation interactivity;real-time data compression;scientific simulation;lossless data compression;Think Mantissa;integer method;scientific dataset entropy;gzip compression strategies;bzip2 compression strategies;compression ratio improvement;speed acceleration;data transfer","","1","","9","","22 Jan 2015","","","IEEE","IEEE Conferences"
"Harnessing Automated Test Case Generators for GUI Testing in Industry","C. Klammer; R. Ramler; H. Stummer","Software Competence Center Hagenberg GmbH, Hagenberg, Austria; Software Competence Center Hagenberg GmbH, Hagenberg, Austria; KEBA AG, Linz, Austria","2016 42th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)","18 Oct 2016","2016","","","227","234","Modern graphical user interfaces (GUIs) are highly dynamic and support multi-touch interactions and screen gestures besides conventional inputs via mouse and keyboard. Hence, the flexibility of modern GUIs enables countless usage scenarios and combinations including all kind of interactions. From the viewpoint of testing, this flexibility results in a combinatorial explosion of possible interaction sequences. It dramatically raises the required time and effort involved in GUI testing, which brings manual exploration as well as conventional regression testing approaches to its limits. Automated test generation (ATG) has been proposed as a solution to reduce the effort for manually designing test cases and to speed-up test execution cycles. In this paper we describe how we successfully harnessed a state-of-the-art ATG tool (Randoop) developed for code-based API testing to generate GUI test cases. The key is an adapter that transforms API calls to GUI events. The approach is the result of a research transfer project with the goal to apply ATG for testing of human machine interfaces used to control industrial machinery. In this project the ATG tool was used to generate unit test cases for custom GUI controls and system tests for exploring navigation scenarios. It helped to increase the test coverage and was able reveal new defects in the implementation of the GUI controls as well as in the GUI application.","2376-9505","978-1-5090-2820-7","10.1109/SEAA.2016.60","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7592801","user interface testing;GUI testing;test case generation;test automation;industry experience report","Graphical user interfaces;Testing;Industries;Automation;Pressing;Mice;Manuals","application program interfaces;graphical user interfaces;human computer interaction;program testing;touch sensitive screens","automated test case generators;GUI testing;graphical user interfaces;multitouch interactions;screen gestures;combinatorial explosion;interaction sequences;automated test generation;ATG;code-based API testing;Randoop;human machine interfaces;control industrial machinery","","7","","22","","18 Oct 2016","","","IEEE","IEEE Conferences"
"Contract research as a part of new product development","M. von Zimmermann; S. Engel; C. Baccarella; K. Voigt","Friedrich-Alexander-University Erlangen-Nuremberg, Germany; Friedrich-Alexander-University Erlangen-Nuremberg, Germany; Friedrich-Alexander-University Erlangen-Nuremberg, Germany; Friedrich-Alexander-University Erlangen-Nuremberg, Germany","2012 Proceedings of PICMET '12: Technology Management for Emerging Technologies","17 Sep 2012","2012","","","2524","2532","Due to shortened product lifecycles and a growing complexity of technologies, companies increasingly cooperate with external partners to optimize their R&D process. To expand their own R&D effort on new technologies, companies can use external resources from partners like universities. Due to their extensive resources and high scientific expertise, universities have proved ideal partners for contract research. This cooperation intensified with amendments such as the US Bayh-Dole Act in 1980 and similar changes in Germany in 2002. Although university-industry technology transfer has been investigated in detail the last two decades, little is known about integrating universities as an external partner into a company's new product development process. In our study, we upgrade Cooper's well-proven Stage-Gate-Process to include different forms of university research. We present a way to establish prolonged interaction from preliminary idea screening to market launch. Our theoretical model was tested and modified in three in-depth case studies and offers the basis for future research in different industries since we kept it in a general form. It is of great relevance to companies dealing with emerging technologies, because their knowledge often originates from university research and they cooperate with university scientists on a regular basis.","2159-5100","978-1-890843-25-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6304268","","Companies;Educational institutions;Technology transfer;Logic gates;Contracts;Product development;Outsourcing","contracts;educational institutions;product development;research and development;technology transfer","contract research;new product development;product life cycle;R and D process;research and development;US Bayh-Dole Act;United States;Germany;university-industry technology transfer;stage-gate-process;university research;market launch","","","","29","","17 Sep 2012","","","IEEE","IEEE Conferences"
"Interactive Near-Field Illumination for Photorealistic Augmented Reality with Varying Materials on Mobile Devices","K. Rohmer; W. Büschel; R. Dachselt; T. Grosch","Computational Visualistics Group, University of Magdeburg, Germany; Interactive Media Lab, Technische Universität Dresden, Germany; Interactive Media Lab, Technische Universität Dresden, Germany; Computational Visualistics Group, University of Magdeburg, Germany","IEEE Transactions on Visualization and Computer Graphics","26 Oct 2015","2015","21","12","1349","1362","At present, photorealistic augmentation is not yet possible since the computational power of mobile devices is insufficient. Even streaming solutions from stationary PCs cause a latency that affects user interactions considerably. Therefore, we introduce a differential rendering method that allows for a consistent illumination of the inserted virtual objects on mobile devices, avoiding delays. The computation effort is shared between a stationary PC and the mobile devices to make use of the capacities available on both sides. The method is designed such that only a minimum amount of data has to be transferred asynchronously between the participants. This allows for an interactive illumination of virtual objects with a consistent appearance under both temporally and spatially varying real illumination conditions. To describe the complex near-field illumination in an indoor scenario, HDR video cameras are used to capture the illumination from multiple directions. In this way, sources of illumination can be considered that are not directly visible to the mobile device because of occlusions and the limited field of view. While our method focuses on Lambertian materials, we also provide some initial approaches to approximate non-diffuse virtual objects and thereby allow for a wider field of application at nearly the same cost.","1941-0506","","10.1109/TVCG.2015.2450717","German Research Foundation (DFG); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7138641","Computer Graphics;Three-Dimensional Graphics and Realism;Augmented and Virtual Realities;Computer graphics;three-dimensional graphics and realism;augmented and virtual realities","Lighting;Cameras;Mobile handsets;Rendering (computer graphics);Image reconstruction;Light sources;Photography","augmented reality;lighting;mobile computing;rendering (computer graphics)","interactive near-field illumination;photorealistic augmented reality;differential rendering method;virtual objects;mobile devices;stationary PC;spatially varying real illumination conditions;temporally varying real illumination conditions;HDR video cameras;Lambertian materials","","8","","48","","29 Jun 2015","","","IEEE","IEEE Journals"
"Virtual Multi-Interaction for Rehabilitation Robotics","W. Li; A. Rovetta; X. Ding; L. Chen; Y. Han","Beijing Microelectron. Technol. Inst., Beijing, China; School of Mechanical Engineering and Automation, Beihang University,Beijing, BJ,P.R.China,10086; School of Mechanical Engineering and Automation, Beihang University,Beijing, BJ,P.R.China,10086; Beijing Microelectronics Technology Institute,Beijing, BJ,P.R.China,10076; Beijing Microelectronics Technology Institute,Beijing, BJ,P.R.China,10076","2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM)","14 Sep 2020","2020","","","204","208","This article is to develop an intelligent exoskeleton to support the wearable, interactive and customizable path on the rehabilitation needs of falling foot. In collaboration with engineers and doctors from Milan and Beijing, it is to realize an active device that performs function adapting perfectly to the anatomical characteristics of each subject, and it would supply greater possibilities and flexibility. Traditional devices are passive rigid orthoses (AFO) and active peroneal stimulation systems (FES). Although simple and cheap, AFO system can bring about phenomena of adaptation at the central level that gradually decrease muscle activity over time. More is the stiffness in the path. FES devices ensure a more natural movement of the foot but without control autonomy. Moreover, the efficiency is always limited with high costs. According analysis of the path, anatomy and biomechanics of the calf, considering combination of sensing and interaction technologies and devices, it focuses on using MEMS inertial sensors and force sensors to make a fusion and measure state of the calf's motion and attitude. It also uses 3D printing to construct lightweight and customable structures. The mobile device is used as local center to transfer data and feedback with Bluetooth and Internet, to give instruction and detect emotion with voice. Virtual Reality is used to build training scenes combined with rehabilitation plan, connections and feedbacks are also built between vision and motion states to form closed loop control. It expounds system construction, virtual scene construction, control method design, system tests, etc. according rehabilitation application, and preliminary application data indicates that the whole system works well with low cost and high efficiency.","","978-1-7281-6479-3","10.1109/ICARM49381.2020.9195384","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195384","","Exoskeletons;Cloud computing;Servers;Robots;Software;Training;Control systems","biomechanics;Bluetooth;closed loop systems;feedback;force sensors;Internet;medical robotics;microsensors;muscle;neuromuscular stimulation;patient rehabilitation;virtual reality","system construction;closed loop control;motion states;virtual reality;mobile device;lightweight structures;force sensors;MEMS inertial sensors;biomechanics;FES devices;muscle activity;central level;active peroneal stimulation systems;passive rigid orthoses;anatomical characteristics;intelligent exoskeleton;rehabilitation robotics;virtual multiinteraction;rehabilitation application;control method design;virtual scene construction","","","","13","","14 Sep 2020","","","IEEE","IEEE Conferences"
"Development of joint attention related actions based on reproducing interaction contingency","H. Sumioka; Y. Yoshikawa; M. Asada","JST ERATO Asada Synergistic Intell. Project, Suita; JST ERATO Asada Synergistic Intell. Project, Suita; JST ERATO Asada Synergistic Intell. Project, Suita","2008 7th IEEE International Conference on Development and Learning","10 Oct 2008","2008","","","256","261","Understanding the developmental process of joint attention related actions, such as gaze following and alternation, is one of essential issues for the emergence of communication. Previous synthetic studies have proposed learning methods for gaze following without any explicit instructions as the first step to understand the development of these actions. However, a robot was given a priori knowledge about which pair of sensory information and action should be associated. This paper addresses the development of social actions without such knowledge with a learning mechanism that iteratively acquires social actions by finding and reproducing the contingency inherent in the interaction with a caregiver. The measurement of contingency based on transfer entropy is used to find appropriate pairs of variables for acquiring social actions from possible candidates. The reproduction of found contingency promotes a change of contingent structure in the subsequent actions of a caregiver and a robot. In computer simulations of human-robot interaction, we examine what kinds of actions related to joint attention can be acquired in which order by controlling the behavior of caregiver agents. The result shows that a robot acquires joint attention related actions in an order that resembles an infantpsilas development of joint attention.","2161-9476","978-1-4244-2661-4","10.1109/DEVLRN.2008.4640839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4640839","joint attention;transfer entropy;contingent chain;sequential acquisition of social behavior","Robots;Robot sensing systems;Joints;Face;Detectors;Reliability;Pediatrics","artificial intelligence;biocommunications;biocybernetics;information theory;learning systems;robots","joint attention related action development;interaction contingency reproduction;gaze following;gaze alternation;communication;learning methods;learning mechanism;social action acquisition;interaction contingency search;contingency measurement;transfer entropy;contingent structure change;human-robot interaction","","7","","11","","10 Oct 2008","","","IEEE","IEEE Conferences"
"Spatial programming for industrial robots based on gestures and Augmented Reality","J. Lambrecht; J. Krüger","Department of Industrial Automation Technology, Institute for Machine Tools and Factory Management, Berlin Institute of Technology, Pascalstr. 8-9, Germany; Department of Industrial Automation Technology, Institute for Machine Tools and Factory Management, Berlin Institute of Technology, Pascalstr. 8-9, Germany","2012 IEEE/RSJ International Conference on Intelligent Robots and Systems","20 Dec 2012","2012","","","466","472","The presented spatial programming system provides an assistance system for online programming of industrial robots. A handheld device and a motion tracking system establish the basis for a modular 3D programming approach corresponding to different phases of robot programming: definition, evaluation and adaption. Static and dynamic gestures enable the program definition of poses, trajectories and tasks. The spatial evaluation is done using an Augmented Reality application on a handheld device. Therefore, the programmer is able to move freely within the robot cell and define the program spatially through gestures. The camera image of the handheld is simultaneously enhanced by virtual objects representing the robot program. Based on 3D motion tracking of human movements and a mobile Augmented Reality application, we introduce a novel kind of interaction for the adaption of robot programs. The programmer is enabled to interact with virtual program components through bare-hand gestures. Such sample forms of interaction include translation and rotation applicable to poses, trajectories or tasks representations. Finally, the program is adapted according to the gestural changes and can be transferred from the handheld device directly to the robot controler.","2153-0866","978-1-4673-1736-8","10.1109/IROS.2012.6385900","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6385900","","Programming;Tracking;Service robots;Trajectory;Robot kinematics;Robot sensing systems","augmented reality;cameras;gait analysis;gesture recognition;image motion analysis;industrial robots;interactive programming;robot programming","spatial programming;spatial programming system;assistance system;online programming;industrial robots;handheld device;motion tracking system;modular 3D programming approach;robot programming;dynamic gestures;static gestures;program definition;handheld device;robot cell;camera image;virtual objects;3D motion tracking;human movements;mobile augmented reality application;robot programs;virtual program components;bare-hand gestures;robot controler","","23","","26","","20 Dec 2012","","","IEEE","IEEE Conferences"
"A Novel Predictive Haptic Control Interface for Automation-to-Human Takeover of Automated Vehicles","Y. Li; C. Lv; J. Xue","School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore, 639798; School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore, 639798; Beijing Jingwei Hirain Technologies Co., Ltd., Beijing, 100191, P.R.China","2019 IEEE Intelligent Vehicles Symposium (IV)","29 Aug 2019","2019","","","994","999","Human driver's intervention is still needed before achieving fully autonomous driving, and this poses a great challenge for ensuring safety and smoothness during control transition from automation to human driver. This paper addresses this challenge by proposing a novel predictive haptic takeover control method. First, a new human-machine interaction model considering two phases, namely machine dominance and human dominance, is developed to describe the interactive behaviors between human driver and automation system during takeover. Based on the model built, a novel haptic takeover controller is designed by using model predictive control approach in order to achieve a safe and smooth handover transition. The optimal steering input is derived by considering the expected paths of both human driver and automation system. The takeover controller generates predictive haptic steering torque based on driver's states, guiding and assisting human driver to gradually resume manual control. Simulation is conducted under a typical driving condition with proposed method. Simulation results indicate that the automation-to-human control transfer is completed safely and smoothly with the proposed haptic takeover controller, and meanwhile the vehicle performance and stability are also guaranteed.","2642-7214","978-1-7281-0560-4","10.1109/IVS.2019.8814252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8814252","","","control system synthesis;haptic interfaces;human-robot interaction;interactive systems;mobile robots;predictive control;road safety;road vehicles;steering systems","haptic takeover controller;predictive haptic control interface;machine dominance;automation-to-human control transfer;predictive haptic steering torque;smooth handover transition;safe handover transition;model predictive control approach;human dominance;human-machine interaction model;takeover control method;control transition;automated vehicles;automation-to-human takeover","","","","26","","29 Aug 2019","","","IEEE","IEEE Conferences"
"An integrated device design environment for semiconductors","P. A. Gough; M. K. Johnson; P. Walker; H. Hermans","Philips Res. Lab., Redhill, UK; Philips Res. Lab., Redhill, UK; Philips Res. Lab., Redhill, UK; NA","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","6 Aug 2002","1991","10","6","808","821","An integrated device design environment (IDDE) for semiconductor devices that is based on workstations and utilizes highly graphical and interactive input techniques has been developed. The framework of the system comprises a device editor, a mesh generator, and a graphical viewer which are interlinked by standard interface files. Into this has been installed a number of process (one-dimensional/two-dimensional) and device (two-dimensional/three-dimensional) simulators. The system has two major advantages. Firstly it effects, from a user perspective, a vast simplification of input to CAD tools without loss of generality and so may be effectively used in both development and research environments. This has been achieved via the use of graphical user interfaces utilizing WIMP and direct manipulation techniques which can produce input for any of the device simulators. Secondly, it facilitates transfer of results between modeling tools via standard interface files and so provides an open architecture which can be expanded without excessive effort. In addition, the software requires only a single workstation, making it economically attractive to small development groups.<>","1937-4151","","10.1109/43.137509","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=137509","","Circuit simulation;Communication standards;Human computer interaction;Laboratories;Semiconductor devices;Design automation;Design methodology;Workstations;User interfaces;SPICE","CAD;electronic engineering computing;engineering workstations;interactive systems;semiconductor device models;semiconductors;user interfaces","2D process simulator;3D device simulator;integrated device design environment;semiconductor devices;workstations;interactive input techniques;device editor;mesh generator;graphical viewer;standard interface files;graphical user interfaces;WIMP;direct manipulation techniques;modeling tools;open architecture","","6","3","27","","6 Aug 2002","","","IEEE","IEEE Journals"
"Using distributed hypermedia educational systems for distance education","Man-Piu Hui; Sheung-Lun Hung","Dept. of Comput. Sci., City Univ. of Hong Kong, Kowloon Tong, Hong Kong; NA","1996 IEEE International Conference on Multi Media Engineering Education. Conference Proceedings","6 Aug 2002","1996","","","135","140","This paper describes a Distributed Hypermedia Educational System (DHES) that applies the most current distributed hypermedia technologies for instructional delivery. The system provides more realistic learning environment than that are currently available in all the electronic educational systems. It offers the advantages of simulated face-to-face interaction as well as self-learning. The system incorporated most of the essential Internet services such as customized email, file transfer, remote log in to another host and World Wide Web navigator. The system has been field tested and the experience has been most encouraging.","","0-7803-3173-7","10.1109/MMEE.1996.570254","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=570254","","Distance learning;Internet;Web server;Educational technology;System testing;Space technology;Humans;Education;Multimedia systems;Computer science","hypermedia;Internet;computer aided instruction;interactive systems","distributed hypermedia educational systems;distance education;instructional delivery;learning environment;electronic educational systems;simulated face-to-face interaction;self-learning;Internet services;customized email;file transfer;World Wide Web navigator","","","","16","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Estimation of muscle forces and joint torque from EMG using SA process","A. W. Oyong; S. Parasuraman; V. L. Jauw","School of Engineering, Monash University (Sunway Campus), Jalan Lagoon Selatan, Bandar Sunway, 46150, Selangor Darul Ehsan, Malaysia; School of Engineering, Monash University (Sunway Campus), Jalan Lagoon Selatan, Bandar Sunway, 46150, Selangor Darul Ehsan, Malaysia; School of Engineering, Monash University (Sunway Campus), Jalan Lagoon Selatan, Bandar Sunway, 46150, Selangor Darul Ehsan, Malaysia","2010 IEEE EMBS Conference on Biomedical Engineering and Sciences (IECBES)","5 Apr 2011","2010","","","81","86","This paper is motivated by works done in the area of robot-assisted stroke rehabilitation. The use of electromyographic (EMG) signal brings a new way of communication interface between user and robot. However, the EMG signal has to be transferred into useful information that serve as robot input. This paper presents a novel methodology for conversion of electromyographic (EMG) signal into estimated joint torque. Investigation of the proposed methodology covers human upper limb movement: shoulder flexion-extension, shoulder abduction-adduction, and elbow flexion-extension. Simulated annealing (SA) is implemented to obtain optimum model that maps EMG into estimated joint torque. General principle, design, and the implementation of SA for the problem are discussed in this paper. Experimentation was carried out to investigate the feasibility of the proposed algorithm. The results show that the algorithm is able to find optimum model that enables EMG to joint torque conversion.","","978-1-4244-7600-8","10.1109/IECBES.2010.5742204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5742204","flexor tendon;tendon repair;suture pull-out;suture rupture","Biological system modeling;Electromyography;Annealing;Frequency measurement;Robots;Nuclear measurements;Humans","biomechanics;bone;electromyography;human-robot interaction;medical robotics;muscle;patient rehabilitation;simulated annealing;torque;user interfaces","muscle force estimation;joint torque;EMG;robot-assisted stroke rehabilitation;electromyographic signal;communication interface;robot-user interface;human upper limb movement;shoulder flexion-extension;shoulder abduction-adduction;elbow flexion-extension;simulated annealing;optimum model","","6","","10","","5 Apr 2011","","","IEEE","IEEE Conferences"
"A Programming Method Combining Static Display with Dynamic Robots","C. Ko; H. Tsai; T. Chang","Dept. of Civil Eng., Nat. Pingtung Univ. of Sci. & Technol., Pingtung, Taiwan; Dept. of Civil Eng., Nat. Pingtung Univ. of Sci. & Technol., Pingtung, Taiwan; Dept. of Civil Eng., Nat. Pingtung Univ. of Sci. & Technol., Pingtung, Taiwan","2011 First International Conference on Robot, Vision and Signal Processing","29 Dec 2011","2011","","","69","72","Computer programming is one of the major skills required for engineering students. This research focuses on developing a programming method that combines static interaction with dynamic interaction. The static interaction procedure shows the program execution results on a computer screen. The dynamic interaction procedure employs a programmable robot. The executable program is transferred from the PC to the moving device to demonstrate the result of the program. The proposed method can be used to enhance student incentive to learn computer programming. This method is patented by invention number I336820.","2376-9807","978-1-4577-1881-6","10.1109/RVSP.2011.50","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6114906","computer programming;learning incentive;robots","Heuristic algorithms;Robots;Dynamic programming;Mobile handsets;Programming profession;Vehicle dynamics","computer aided instruction;computer displays;educational robots;incentive schemes;robot programming","static display;dynamic robots;computer programming;engineering student learning;static interaction;dynamic interaction;program execution;computer screen;programmable robot;student incentive","","","","7","","29 Dec 2011","","","IEEE","IEEE Conferences"
"The negative transfer problem in neural networks: a solution","A. M. Abunawass","Dept of Comput. Sci., Western Illinois Univ., Macomb, IL, USA","[Proceedings] 1991 IEEE International Joint Conference on Neural Networks","12 Sep 2019","1991","","","881","886 vol.1","The authors introduce a modified BP (backpropagation) model that can be used in sequential learning to overcome the NET (negative transfer) effect. Simulations were conducted to contrast the performance of the original BP model with the modified one. The results of the simulations showed that effect of the NT can be completely eliminated, and in some cases reversed, by using the modified BP model. The behavior and interactions of the weight matrices are studied over successive training sessions. This work confirms the need to have an overall cognitive architecture that goes beyond the basic application of the learning model.<>","","0-7803-0227-3","10.1109/IJCNN.1991.170511","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=170511","","Intelligent networks;Neural networks;Humans;Interference;Degradation;Biological neural networks;Computer science;History;Chemicals;Nervous system","learning systems;neural nets","negative transfer problem;neural networks;modified BP;backpropagation;sequential learning;NET;negative transfer;weight matrices;training sessions;cognitive architecture","","","","","","12 Sep 2019","","","IEEE","IEEE Conferences"
"A robot hand-over control scheme for human-like haptic interaction","E. Psomopoulou; Z. Doulgeri","Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, 54124 Thessaloniki, Greece; Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, 54124 Thessaloniki, Greece","22nd Mediterranean Conference on Control and Automation","20 Nov 2014","2014","","","1470","1475","A robot hand-over control scheme is proposed achieving human-like haptic interaction during object load transfer from a giver to a receiver hand for the planar case. It is assumed that the object has parallel surfaces and unknown mass. The giver initiates the hand-over process while the receiver estimates the transferred object mass adapting its grip force accordingly in a three stage process. The control laws are based on a dynamically stable grasp controller which is modified for the hand-over task. A stable load transfer is securely achieved as shown by the theoretical analysis and illustrated by the simulation results.","","978-1-4799-5901-3","10.1109/MED.2014.6961583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6961583","","Receivers;Force;Robots;Equations;Vectors;Grasping;Joints","dexterous manipulators;force control;haptic interfaces;stability","robot hand-over control scheme;human-like haptic interaction;object load transfer;object mass;grip force;dynamically stable grasp controller","","2","","4","","20 Nov 2014","","","IEEE","IEEE Conferences"
"Transferring Human Impedance Behavior to Heterogeneous Variable Impedance Actuators","M. Howard; D. J. Braun; S. Vijayakumar","Nakamura Lab, Department of Mechano-Informatics, University of Tokyo, Tokyo, Japan; Institute of Perception Action and Behaviour, School of Informatics, University of Edinburgh, Edinburgh, U.K.; Institute of Perception Action and Behaviour, School of Informatics, University of Edinburgh, Edinburgh, U.K.","IEEE Transactions on Robotics","2 Aug 2013","2013","29","4","847","862","This paper presents a comparative study of approaches to control robots with variable impedance actuators (VIAs) in ways that imitate the behavior of humans. We focus on problems where impedance modulation strategies are recorded from human demonstrators for transfer to robotic systems with differing levels of heterogeneity, both in terms of the dynamics and actuation. We categorize three classes of approach that may be applied to this problem, namely, 1) direct, 2) feature-based, and 3) inverse optimal approaches to transfer. While the first is restricted to highly biomorphic plants, the latter two are shown to be sufficiently general to be applied to various VIAs in a way that is independent of the mechanical design. As instantiations of such transfer schemes, 1) a constraint-based method and 2) an apprenticeship learning framework are proposed, and their suitability to different problems in robotic imitation, in terms of efficiency, ease of use, and task performance, is characterized. The approaches are compared in simulation on systems of varying complexity, and robotic experiments are reported for transfer of behavior from human electromyographic data to two different variable passive compliance robotic devices.","1941-0468","","10.1109/TRO.2013.2256311","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6510474","Behavior transfer;imitation learning;passive impedance control;variable stiffness actuation","","actuators;electromyography;human-robot interaction;inverse problems;learning (artificial intelligence);robot dynamics","variable passive compliance robotic device;human electromyographic;robotic imitation;apprenticeship learning;constraint-based method;transfer scheme;mechanical design;VIA;biomorphic plant;feature-based approach;inverse optimal approach;robot dynamics;impedance modulation strategy;robot control;human impedance behavior transfer;heterogeneous variable impedance actuator","","33","2","63","","30 Apr 2013","","","IEEE","IEEE Journals"
"A new apparel design and online shopping framework for mass customization and best fit","C. Guan; B. Xu; S. Qin; S. Wang","School of Art and Communication, Southwest Jiaotong University, Chengdu, P.R. China; School of Art and Communication, Southwest Jiaotong University, Chengdu, P.R. China; School of Engineering and Design Brunel University, London, UK; School of Engineering and Design, Northwestern Polytechnical University Xi'an, PRC","18th International Conference on Automation and Computing (ICAC)","15 Oct 2012","2012","","","1","5","In this paper we propose a framework of a virtual clothing shop which meets the mass customization based on virtual garment design model. To incorporate the respective merits both online and custom-tailoring shops, the framework will be used to establish a new interactive model which consists of virtual human, virtual clothing and virtual interaction. Among this model, virtual interaction plays a pivotal role in transferring formation between client and designer. Furthermore, we explore various interactive approaches and user interface which is based on user-friendly, identifiable, state-of-the-art technique, comprehensive service and human-centered design. Ultimately, building this model will lay the foundation for latter commercialization at the end.","","978-1-908549-00-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6330536","Interactive design;virtual clothing;mass customization;online shopping;user interface","Clothing;Fitting;Humans;Mass customization;Shape;Size measurement;Internet","clothing;graphical user interfaces;human computer interaction;Internet;product customisation;retail data processing;user centred design;virtual reality","apparel design;online shopping framework;mass customization;best fit;virtual clothing shop;virtual garment design model;custom-tailoring shops;interactive model;virtual human;virtual interaction;user interface;user-friendly technique;human-centered design","","","7","12","","15 Oct 2012","","","IEEE","IEEE Conferences"
"Virtual Design Studio and Web Applications for e-Learning","R. Yamacli; L. Y. Tokman","Anadolu Univ. Eskisehir, Eskisehir; Anadolu Univ. Eskisehir, Eskisehir","2009 Fourth International Conference on Internet and Web Applications and Services","12 Jun 2009","2009","","","545","548","The collaborative opportunities among universities thanks to European credit transfer system_ ECTS credit system and ERASMUS, SOCRATES etc., point to global studios for educational purposes. The virtual design studio can be considered a sample for future virtual design studios and disciplinary/ interdisciplinary interactions that is the provision of a highly interactive studio environment independent of time and place. There are three main cognitive and professional interests field-politic in accordance with the globalization process in architectural education: These are design, construction and productivity of knowledge. According to this approach, the needs of reaching the environment which have the better quality are being appeared more important including the interaction of professions. The correct commentary of globalization is being provided by using a good communication. At this point of view, having the benefits of information technology -IT- in all universities and schools are providing us better educational quality for professional degree.","","978-1-4244-3851-8","10.1109/ICIW.2009.88","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5072575","virtual design studio;web;education","Electronic learning;Globalization;Educational programs;Concrete;Electrical capacitance tomography;Educational institutions;Process design;Accreditation;Educational technology;Europe","architectural CAD;computer aided instruction;Internet;virtual reality","virtual design studio;Web application;e-learning;collaborative opportunity;European credit transfer system;ECTS credit system;educational purpose;disciplinary-interdisciplinary interaction;architectural design education;information technology","","2","","10","","12 Jun 2009","","","IEEE","IEEE Conferences"
"The effects of visual information about self-movement on grasp forces when receiving objects in an augmented environment","A. H. Mason; C. L. MacKenzie","Sch. of Kinesiology, Simon Fraser Univ., Burnaby, BC, Canada; NA","Proceedings 10th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems. HAPTICS 2002","7 Aug 2002","2002","","","105","112","This work explored how the presence of visual information about self-movement affected grasp forces when receiving an object from a partner. Twelve subjects either reached to grasp or grasped without reaching objects that were passed by a partner or rested on a table surface. Visual feedback about self-movement was available for half the trials and was removed for the other half. Results indicated that a graphic representation of self-movement significantly decreased transfer time when objects were passed between subjects. Results also indicated decreased time to peak grip force and peak grip force rate by the receiver with this visual feedback. These results suggest that grip force production on objects acquired from another person benefit from a crude graphical representation of the finger pads. Furthermore, these results suggest that sources of sensory feedback cannot be studied in isolation. Instead we must consider how feedback modalities are integrated for successful interaction. Implications for the design of virtual environments and integrated feedback devices are discussed.","","0-7695-1489-8","10.1109/HAPTIC.2002.998947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=998947","","Electrical capacitance tomography;Force feedback;Haptic interfaces;Humans;Virtual environment;Production;Read only memory;Computer graphics;Tellurium;RAKE receivers","augmented reality;haptic interfaces;force feedback;human factors","visual information;self-movement;grasp forces;augmented environment;visual feedback;graphic representation;finger pads;sensory feedback;feedback modalities;virtual environments;rated feedback devices","","1","","21","","7 Aug 2002","","","IEEE","IEEE Conferences"
"Robust face recognition via transfer learning for robot partner","N. N. Wi Tay; J. Botzheim; C. K. Loo; N. Kubota","Graduate School of System Design Tokyo Metropolitan University Tokyo, Japan; Graduate School of System Design Tokyo Metropolitan University Tokyo, Japan; Faculty of Computer Science & Information Technology University of Malaya Kuala Lumpur, Malaysia; Graduate School of System Design Tokyo Metropolitan University Tokyo, Japan","2014 IEEE Symposium on Robotic Intelligence in Informationally Structured Space (RiiSS)","15 Jan 2015","2014","","","1","8","Face recognition is crucial for human-robot interaction. Robot partners are required to work in real-time under unconstrained condition, yet, do not restrict the personal freedom of human occupants. On the other hand, due to its limited computational capability, a tradeoff between accuracy and computational load needs to be made. This tradeoff can be alleviated via the introduction of informationally structured space. For this paper, transfer learning is employed to perform unconstrained face recognition, where templates are constructed from domains acquired from various image-capturing devices, which is a subset of sensors from the informationally structured space. Given the environmental conditions, appropriate templates are used for recognition. Currently, different database images are used to simulate different environmental conditions. The templates can be easily learned and merged via a reformulated joint probabilistic face verification method, which reduces significantly the processing load. Tested on standard databases, experimental studies show that specific and small target domain samples can boost the recognition performance without imposing strain on computation.","","978-1-4799-4464-4","10.1109/RIISS.2014.7009163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7009163","Face recognition;transfer learning;robot partner;informationally structured space","Face;Face recognition;Robots;Databases;Cameras;Accuracy;Joints","face recognition;human-robot interaction;learning (artificial intelligence);robot vision","robust face recognition;robot partner;human-robot interaction;unconstrained condition;human occupants;computational capability;informationally structured space;transfer learning;image-capturing devices;environmental conditions;database images;reformulated joint probabilistic face verification method;target domain samples","","1","","37","","15 Jan 2015","","","IEEE","IEEE Conferences"
"Compliant Impedance Control for a Redundant Manipulator During Human Robot Interaction","Y. Jiang; C. Yang; Z. Ju; A. Annamalai; H. Liu","School of Computing, University of Portsmouth, Portsmouth, PO1 3HE, UK; Zienkiewicz Center for Computational Engineering, Swansea University, Swansea, SA1 8EN, UK; School of Computing, University of Portsmouth, Portsmouth, PO1 3HE, UK; Moray College, University of Highlands and Islands, Elgin, IV30 1JJ, UK; School of Computing, University of Portsmouth, Portsmouth, PO1 3HE, UK","2018 24th International Conference on Automation and Computing (ICAC)","1 Jul 2019","2018","","","1","6","Robot control with a compliant motion behaviour is important to guarantee the safety of human robot interaction. In this paper, we aim to guarantee the desired task impedance of the end-effector and to ensure a compliant behaviour of a redundant robot during human robot interactions. A task space impedance control scheme is proposed by designing a transferred impedance error, such that the robot end-effector can be governed to follow a target impedance model. Additionally, a low-priority controller is designed using the null space projection, such that compliant joint motion is guaranteed without affecting the main task. The stability of the whole system is illustrated using a conditional Lyapunov theorem. Simulation studies based on a plane redundant robot is carried out to demonstrate the validity of the proposed controller.","","978-1-86220-341-9","10.23919/IConAC.2018.8749048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8749048","Redundant Robot;Human-robot Interaction;Null Space Control;Impedance Control","Robots;Impedance;Task analysis;Aerospace electronics;Null space;Torque;Force","end effectors;force control;human-robot interaction;Lyapunov methods;motion control;position control;redundant manipulators;stability","compliant impedance control;human robot interaction;robot control;compliant motion behaviour;task space impedance control scheme;robot end-effector;compliant joint motion;plane redundant robot;task impedance;conditional Lyapunov theorem;null space projection;stability","","","","20","","1 Jul 2019","","","IEEE","IEEE Conferences"
"Construction safety education model based on second life","Q. Le; Chan-Sik Park","Department of Architectural Engineering, Chung-Ang University, Seoul, South Korea; Department of Architectural Engineering, Chung-Ang University, Seoul, South Korea","Proceedings of IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE) 2012","24 Nov 2012","2012","","","H2C-1","H2C-5","Construction industry is a very complicated and complex environment that causes high accident rate. The development of advanced virtual world has become an important issue for safety education in order to reduce dangerous occurrence in the construction site. However, most researchers on virtual world still have limitations such as the offline virtual world simulation, the low level of interaction between users in virtual world, and so on. With the regard to this issue, this paper proposes the adoption online 3D world Second Life (SL) platform which allows students to perform role-playing, dialogic learning, and social interaction for efficient and effective construction safety and health education. In this approach, construction safety education model based on Second Life (CSESL) is developed, which consists of the following three modules: 1) Safety information and knowledge preparation to understand the critical causes of accident in construction site; 2) Collaborative simulation for safety case study to transfer unsafe case or dangerous occurrence information to 3D modeling; 3) Reflection on safety lesson for education and training to enhance practical safety knowledge by participating in 3D inspection game. The CSESL advantages and disadvantages are identified by testing the model using a real case scenario. This study presents the potentials and benefits of SL which could enhance construction safety and health education.","","978-1-4673-2418-2","10.1109/TALE.2012.6360336","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360336","construction safety and health;virtual environment;Second Life;education","Safety;Solid modeling;Collaboration;Accidents;Second Life;Training","accidents;computer aided instruction;computer games;construction industry;digital simulation;engineering education;occupational health;occupational safety;solid modelling;virtual reality","construction safety education model;Second Life;construction industry;virtual world;role-playing;dialogic learning;social interaction;construction health education;safety information;knowledge preparation;construction accident;collaborative simulation;3D modeling;safety lesson;3D inspection game","","4","","14","","24 Nov 2012","","","IEEE","IEEE Conferences"
"Toward a psychophysical-based procedural texture generation system for interactive design","Xiaoxu Cai; Jun Liu; Lin Qi; Junyu Dong; Ying Gao; Hui Yu","Department of Information Science and Engineering, Ocean University of China, Qingdao, China; Department of Information Science and Engineering, Ocean University of China, Qingdao, China; Department of Information Science and Engineering, Ocean University of China, Qingdao, China; Department of Information Science and Engineering, Ocean University of China, Qingdao, China; Colleage of Information Science and Technology, Chengdu University of Technology, China; School of Creative Technologies, University of Portsmouth, London, UK","2015 8th International Conference on Human System Interaction (HSI)","30 Jul 2015","2015","","","373","378","Procedural textures have been widely used as they can be easily generated from various mathematical models. However, the model parameters are not perceptually meaningful or uniform for non-expert users. In this paper, we proposed a system that can generate procedural textures interactively along certain perceptual dimensions. We built a procedural texture dataset and measured twelve perceptual properties of a small subset through psychophysical experiments. The perceived magnitude of the rest textures was estimated by Support Vector Machines using computational features from a cascaded PCA network. For a given texture displayed on a touch screen, the user makes finger gestures which were then transferred to magnitude changes in perceptual space. The texture in the database that matches the new perceptual scale and with nearest distance in computational feature space will be chosen and displayed. We reported our experiment results for two particular perceptual properties: surface roughness and directionality. Other properties can be manipulated similarly.","2158-2254","978-1-4673-6936-7","10.1109/HSI.2015.7170696","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7170696","","Feature extraction;Computational modeling;Noise;Fractals;Mathematical model;Support vector machines;Histograms","gesture recognition;human computer interaction;interactive systems;support vector machines","psychophysical-based procedural texture generation system;interactive design;mathematical model;model parameters;perceptual dimension;procedural texture dataset;perceptual properties;psychophysical experiment;support vector machines;cascaded PCA network;touch screen;finger gesture;magnitude changes;perceptual space;computational feature space;surface roughness;directionality","","","","29","","30 Jul 2015","","","IEEE","IEEE Conferences"
"Towards automatic generation of multimodal AR-training applications and workflow descriptions","T. Engelke; S. Webel; U. Bockholt; H. Wuest; N. Gavish; F. Tecchia; C. Preusche","Fraunhofer IGD, Germany; Fraunhofer IGD, Germany; Fraunhofer IGD, Germany; Fraunhofer IGD, Germany; Technion-Israel, Institute of Technology, Israel; PERCRO - Scuola Superiore Sant'Anna, Italy; German Aerospace Center (DLR), Germany","19th International Symposium in Robot and Human Interactive Communication","11 Oct 2010","2010","","","434","439","Augmented Reality (AR) is a technology which has become very popular in the last years. In this context also the idea of using of AR for training applications has become very important. AR offers a large potential for training only if the training is well focused to the skills that have to be trained and if the training protocol is well designed. On the other hand, the generation of the training content to be transferred via AR is a comprehensive problem that is addressed in this paper. Thus, this paper tries to describe the whole chain of implementations and general aspects involved in the creation of AR training applications, including examples for used multimodal devices. This chain starts with the capturing of expert actions to be hold in the ""digital representation of skill"". The digital representation of skill is transferred to the training protocol that specifies the storyboard of the AR training session. The paper includes two different implementations of AR training systems and describes the general idea of informational abstraction from low level data up to interaction and from design to application.","1944-9437","978-1-4244-7990-0","10.1109/ROMAN.2010.5598613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5598613","","Training;Augmented reality;Protocols;Assembly;Solid modeling;Haptic interfaces;Maintenance engineering","augmented reality;computer aided instruction","multimodal AR-training applications;workflow descriptions;augmented reality;training protocol;digital representation","","2","","21","","11 Oct 2010","","","IEEE","IEEE Conferences"
"Emotion dependent dialogues in the VirCA system","I. M. Fülöp","Computer and Automation Research Institute, Hungarian Academy of Sciences, Budapest, Hungary","2011 2nd International Conference on Cognitive Infocommunications (CogInfoCom)","25 Aug 2011","2011","","","1","3","In the VirCA system, the Wikipedia cyber device was developed in order to realize dialogues with human users as a case of inter-cognitive sensor sharing communication. These dialogues are based on the scenarios of wiki pages edited on the web. This cyber device was extended with the ability of emotion support: the Wikipedia answers the user with the emotion received from some emotion tracker component. This way not only speech but emotion is transferred as well in the course of cognitive infocommunication. To realize this attitude, on the one hand, a universal thesaurus component was developed, which can select the appropriate version of a default lingual item which matches the received emotion. On the other hand, a universal emotion tracker component was also developed to recognize the emotion of the user either from the voice or the used lingual items of the user. This paper intends to present how the different components are connected together in order to realize the desired behaviour. It is going to be described how the universal components are exactly operating and which technologies are applied to achieve the required operation. Examples for the usage of the system are going to be presented as well.","","978-963-8111-78-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5999452","Emotion vector;Emotion tracking;Virtual reality;Cognitive infocommunication;User interaction","Encyclopedias;Electronic publishing;Internet;Thesauri;Speech recognition;Solid modeling","cognition;emotion recognition;virtual reality;Web sites","emotion dependent dialogue;VirCA system;Wikipedia cyber device;intercognitive sensor sharing communication;wiki page;World Wide Web;emotion tracker component;cognitive infocommunication;universal thesaurus component","","2","","3","","25 Aug 2011","","","IEEE","IEEE Conferences"
"LiveSync: Deformed Viewing Spheres for Knowledge-Based Navigation","P. Kohlmann; S. Bruckner; A. Kanitsar; E. Gröller","Vienna Univ. of Technol., Vienna; Vienna Univ. of Technol., Vienna; NA; IEEE Computer Society","IEEE Transactions on Visualization and Computer Graphics","5 Nov 2007","2007","13","6","1544","1551","Although real-time interactive volume rendering is available even for very large data sets, this visualization method is used quite rarely in the clinical practice. We suspect this is because it is very complicated and time consuming to adjust the parameters to achieve meaningful results. The clinician has to take care of the appropriate viewpoint, zooming, transfer function setup, clipping planes and other parameters. Because of this, most often only 2D slices of the data set are examined. Our work introduces LiveSync, a new concept to synchronize 2D slice views and volumetric views of medical data sets. Through intuitive picking actions on the slice, the users define the anatomical structures they are interested in. The 3D volumetric view is updated automatically with the goal that the users are provided with expressive result images. To achieve this live synchronization we use a minimal set of derived information without the need for segmented data sets or data-specific pre-computations. The components we consider are the picked point, slice view zoom, patient orientation, viewpoint history, local object shape and visibility. We introduce deformed viewing spheres which encode the viewpoint quality for the components. A combination of these deformed viewing spheres is used to estimate a good viewpoint. Our system provides the physician with synchronized views which help to gain deeper insight into the medical data with minimal user interaction.","1941-0506","","10.1109/TVCG.2007.70576","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376185","Navigation;interaction;linked views;medical visualization;viewpoint selection.","Navigation;Biomedical imaging;Displays;Data visualization;Medical diagnostic imaging;Transfer functions;Anatomical structure;Computed tomography;Image segmentation;History","data visualisation;interactive systems;knowledge based systems;medical image processing;rendering (computer graphics)","LiveSync deformed viewing sphere;knowledge-based navigation;interactive volume rendering;visualization method;medical image","Algorithms;Anatomy, Cross-Sectional;Artificial Intelligence;Computer Graphics;Computer Simulation;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Models, Anatomic;Reproducibility of Results;Sensitivity and Specificity;Surgery, Computer-Assisted;User-Computer Interface","23","5","20","","5 Nov 2007","","","IEEE","IEEE Journals"
"CoCOasis: The Collaborative Creativity Oasis","R. E. Wendrich; A. Kitchen","Enschede, Univ. of Twente, Enschede, Netherlands; Ramulus Ltd., Kenilworth, UK","2013 IEEE 13th International Conference on Advanced Learning Technologies","19 Sep 2013","2013","","","463","464","Cocoas is (CCO) aims to improve education (learning) and foster creativity in design disciplines, through the use of ICT provided by human-computer based expert systems, while reducing the 'skills gap' when students transfer from the current education system into the 21st Century Skills industry. Creative processes are often hindered by context, predefined boundaries, constraints and 'blind spots' (a term used to describe unexpected, unseen, unknown, unforeseen and/or ignored areas of knowledge and gaps in an individual's understanding and experience of the world around them). The concept of this vision is to support human creative processes by augmenting them with technology, enhancing creativity and tackling the blind spots, for example, head-on. We envision the CCO as an open and flexible area, indoors or outdoors, which can fit or emerge anywhere/anytime/anyhow. It can be a room, a space, a yard, a public space or simply a floor. An oasis can be made from a range of available artifacts (e.g. chairs, tables, walls, dividers, screens, whiteboards, cardboard boxes etc.) or could stay bare, each eventually being populated with actors/users and/or stakeholders. Such a ""place"" is easily transformed into a CCO the moment interaction and activity (i.e. face-to-face, dialogue, playing, gaming etc.) is started and participants immerse in the interactive creative design process.","2161-377X","978-0-7695-5009-1","10.1109/ICALT.2013.144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6601986","design;creativity;collaborative;processing;HCI","Collaboration;Educational institutions;Context;Technological innovation;Virtual reality;Hardware","computer aided instruction;expert systems;human computer interaction","CoCOasis;collaborative creativity oasis;CCO;ICT;human-computer based expert systems;education system;interactive creative design process","","","","6","","19 Sep 2013","","","IEEE","IEEE Conferences"
"Human sit-to-stand transfer modeling for optimal control of assistive robots","M. Geravand; P. Z. Korondi; A. Peer","Institute of Automatic Control Engineering, Technische Universita¨t Mu¨nchen, Munich, Germany; Institute of Automatic Control Engineering, Technische Universita¨t Mu¨nchen, Munich, Germany; Institute of Automatic Control Engineering, Technische Universita¨t Mu¨nchen, Munich, Germany","5th IEEE RAS/EMBS International Conference on Biomedical Robotics and Biomechatronics","2 Oct 2014","2014","","","670","676","Sit-to-stand (STS) transfers are a common human task which involves very complex sensorimotor processes to control the highly nonlinear musculoskeletal system. In this paper, typical unassisted and assisted human STS transfers are formulated as optimal feedback control problem that finds a compromise between task end-point accuracy, human balance, jerk, effort, and torque change and takes further human biomechanical control constraints into account. Differential dynamic programming is employed, which allows taking the full, nonlinear human dynamics into consideration. The biomechanical dynamics of the human is modeled by a six link rigid body including leg, trunk and arm segments. Accuracy of the proposed modelling approach is evaluated for different human healthy subjects by comparing simulations and experimentally collected data. Acceptable model accuracy is achieved with a generic set of constant weights that prioritize the different criteria. The proposed STS model is finally used to determine optimal assistive strategies to be performed by a robotic mobility assistant suitable for either a person with specific body segment weakness or a more general weakness.","2155-1782","978-1-4799-3128-6","10.1109/BIOROB.2014.6913855","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913855","","Biological system modeling;Joints;Trajectory;Data models;Torque;Cost function;Biomechanics","assisted living;feedback;gait analysis;handicapped aids;human-robot interaction;medical robotics;mobile robots;nonlinear dynamical systems;optimal control;robot dynamics;service robots;torque control","human sit-to-stand transfer modeling;assistive robots;very complex sensorimotor processes;nonlinear musculoskeletal system;unassisted human STS transfer;assisted human STS transfer;optimal feedback control problem;task end-point accuracy;human balance;jerk;effort;torque change;human biomechanical control constraints;differential dynamic programming;nonlinear human dynamics;human biomechanical dynamics;rigid body;robotic mobility assistant","","2","","27","","2 Oct 2014","","","IEEE","IEEE Conferences"
"Learning motion and impedance behaviors from human demonstrations","M. Saveriano; D. Lee","Chair of Automatic Control Engineering, Technical University of Munich, Munich, Germany; Chair of Automatic Control Engineering, Technical University of Munich, Munich, Germany","2014 11th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)","12 Mar 2015","2014","","","368","373","Human-robot skill transfer has been deeply investigated from a kinematic point of view, generating various approaches to increase the robot knowledge in a simple and compact way. Nevertheless, social robotics applications require a close and active interaction with humans in a safe and natural manner. Torque controlled robots, with their variable impedance capabilities, seem a viable option toward a safe and profitable human-robot interaction. In this paper, an approach is proposed to simultaneously learn motion and impedance behaviors from tasks demonstrations. Kinematic aspects of the task are represented in a statistical way, while the variability along the demonstrations is used to define a variable impedance behavior. The effectiveness of our approach is validated with simulations on real and synthetic data.","","978-1-4799-5333-2","10.1109/URAI.2014.7057371","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057371","Learning from Demonstrations;variable impedance control;state-dependent behavior","Robots;Impedance;Covariance matrices;Eigenvalues and eigenfunctions;Trajectory;Force;Computational modeling","human-robot interaction;robot kinematics","learning motion;impedance behaviors;human demonstrations;human-robot skill transfer;kinematic point of view;robot knowledge;social robotics applications;active interaction;torque controlled robots;variable impedance capabilities;viable option;profitable human-robot interaction;tasks demonstrations;kinematic aspects;variable impedance behavior;simulations;synthetic data","","7","","17","","12 Mar 2015","","","IEEE","IEEE Conferences"
"Interactive educational system for coal combustion modeling in power plant boilers","M. Gayer; P. Slavik; F. Hrdlicka","Comput. Sci. & Eng. Dept., Czech Tech. Univ., Prague, Czech Republic; NA; NA","The IEEE Region 8 EUROCON 2003. Computer as a Tool.","3 Dec 2003","2003","2","","220","224 vol.2","We present our educational system for interactive education of combustion processes. The system is built on several concepts used mainly in the computer graphics area (fluid simulator, particle system) and combustion simulation field (simplified combustion process model and heat transfer engine). Together they combine unique and original concepts that offer real-time simulation and visualization of the combustion process. The user may have immediate interaction during simulation and visualization - e.g. changing coal inlets and combustible properties and other input parameters during simulation. The system allows real-time monitoring of about 40 basic cell volume characteristics inside the boiler and 10 pulverized coal particle characteristics. All these features are available immediately, without needing to wait hours for complex calculations to finish. The system is especially suitable for interactive education purposes in power-engineering.","","0-7803-7763-X","10.1109/EURCON.2003.1248187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1248187","","Combustion;Power system modeling;Power generation;Boilers;Computational modeling;Computer simulation;Heat engines;Visualization;Computer science education;Computer graphics","computer aided instruction;computer based training;user interfaces;interactive systems;power plants;combustion;modelling","interactive educational system;coal combustion modeling;power plant boilers;educational system;interactive education;combustion processes;computer graphics area;fluid simulator;particle system;combustion simulation field;simplified combustion process model;heat transfer engine;real-time simulation;combustion process visualization;coal inlets;combustible properties;input parameters;real-time monitoring;cell volume characteristics;pulverized coal particle characteristics;power-engineering","","","","11","","3 Dec 2003","","","IEEE","IEEE Conferences"
"High Quality Light Field Extraction and Post-Processing for Raw Plenoptic Data","P. Matysiak; M. Grogan; M. Le Pendu; M. Alain; E. Zerman; A. Smolic","School of Computer Science and Statistics, Trinity College Dublin, The University of Dublin, Dublin 2, Ireland; School of Computer Science and Statistics, Trinity College Dublin, The University of Dublin, Dublin 2, Ireland; School of Computer Science and Statistics, Trinity College Dublin, The University of Dublin, Dublin 2, Ireland; School of Computer Science and Statistics, Trinity College Dublin, The University of Dublin, Dublin 2, Ireland; School of Computer Science and Statistics, Trinity College Dublin, The University of Dublin, Dublin 2, Ireland; School of Computer Science and Statistics, Trinity College Dublin, The University of Dublin, Dublin 2, Ireland","IEEE Transactions on Image Processing","7 Feb 2020","2020","29","","4188","4203","Light field technology has reached a certain level of maturity in recent years, and its applications in both computer vision research and industry are offering new perspectives for cinematography and virtual reality. Several methods of capture exist, each with its own advantages and drawbacks. One of these methods involves the use of handheld plenoptic cameras. While these cameras offer freedom and ease of use, they also suffer from various visual artefacts and inconsistencies. We propose in this paper an advanced pipeline that enhances their output. After extracting sub-aperture images from the RAW images with our demultiplexing method, we perform three correction steps. We first remove hot pixel artefacts, then correct colour inconsistencies between views using a colour transfer method, and finally we apply a state of the art light field denoising technique to ensure a high image quality. An in-depth analysis is provided for every step of the pipeline, as well as their interaction within the system. We compare our approach to existing state of the art sub-aperture image extracting algorithms, using a number of metrics as well as a subjective experiment. Finally, we showcase the positive impact of our system on a number of relevant light field applications.","1941-0042","","10.1109/TIP.2020.2967600","Science Foundation Ireland; Trinity College Dublin; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8967224","Light fields;image coding;colour transfer;image enhancement;image denoising","Image color analysis;Cameras;Pipelines;Demultiplexing;Sensor arrays;Brightness;Lenses","cameras;computer vision;feature extraction;image colour analysis;image denoising;image enhancement;image resolution;image sensors;virtual reality","hot pixel artefacts;correct colour inconsistencies;colour transfer method;image quality;relevant light field applications;high quality light field extraction;computer vision research;virtual reality;handheld plenoptic cameras;visual artefacts;sub-aperture images;demultiplexing method;correction steps;sub-aperture image extracting algorithms","","4","","66","IEEE","23 Jan 2020","","","IEEE","IEEE Journals"
"MulseBox: Portable Multisensory Interactive Device","C. Jost; B. L. Pévédic; O. E. Barraj; G. Uzan","CHArt Laboratory,Saint-Deni,France; Lab-STICC Laboratory,Vannes,France; Lab-STICC Laboratory,Vannes,France; CHArt Laboratory,Saint-Deni,France","2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)","28 Nov 2019","2019","","","3956","3961","This paper presents MulseBox, a new multisensory interactive device, which can simulate real-life situations in order to help learning and transfer of learning in daily-life. Indeed, multisensory interaction is known to improve learning performances. MulseBox can easily be enriched with real objects and virtual objects. It is evolving. MulseBox was designed because the literature highlighted the lack of a unique multisensory device to work on common problematics. Indeed, six disciplines at least are investigating multisensory with the shared secondary objectives to increase users' Quality of Experience and to design for all (that is taking disabilities into account). MulseBox may also be a test-bed for researchers to solve identified problematics. An exploratory evaluation of acceptability showed promising results which make us think that MulseBox is relevant.","2577-1655","978-1-7281-4569-3","10.1109/SMC.2019.8913987","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8913987","","Fans;Acoustics;Computer architecture;Reliability;Haptic interfaces;Vibrations;Loudspeakers","computer aided instruction;human computer interaction;interactive devices;mobile learning;quality of experience;virtual reality","MulseBox;virtual objects;portable multisensory interactive device;multisensory interaction;learning performances;Quality of Experience","","1","","35","","28 Nov 2019","","","IEEE","IEEE Conferences"
"Skill generalization relevant to robotic neuro-rehabilitation","D. Bansal; R. Kenyon; J. L. Patton","University of Illinois-Chicago, USA; University of Illinois-Chicago, USA; University of Illinois-Chicago, USA","2010 Annual International Conference of the IEEE Engineering in Medicine and Biology","11 Nov 2010","2010","","","2250","2254","Upper limb extremity rehabilitation practices are increasingly involving robotic interaction for repetitive practice, and there is increasing skepticism whether such systems can provide the relevant practice that can be generalized (or transferred) to functional activities in the real world. Most importantly, will patients be able to generalize in three critical ways: (1) to unpracticed directions, (2) to unpracticed movement distances, and (3) to unpracticed weight-eliminated conditions? Rather than presuming that patients could generalize in three conditions, this study tested whether there was any evidence of such generalization ability in healthy individuals. We found that there was some evidence in all conditions except for the ability of healthy subjects to generalize to large movements after practicing small. Such results suggest that larger robotic systems are advantageous for training the functional motions that can include large actions.","1558-4615","978-1-4244-4123-5","10.1109/IEMBS.2010.5627308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5627308","","Training;Gravity;Visualization;Virtual reality;Performance evaluation;Robot sensing systems","medical robotics;neurophysiology;patient rehabilitation;robot kinematics;virtual reality","skill generalization;robotic neuro-rehabilitation;upper limb extremity rehabilitation;robotic interaction;repetitive practice;unpracticed directions;unpracticed movement distances;unpracticed weight-eliminated condition","Activities of Daily Living;Adult;Algorithms;Arm Injuries;Equipment Design;Female;Humans;Male;Motor Activity;Movement;Movement Disorders;Nervous System;Robotics;Upper Extremity","","","19","","11 Nov 2010","","","IEEE","IEEE Conferences"
"Deep Neural Network Approach in Electrical Impedance Tomography-based Real-time Soft Tactile Sensor","H. Park; H. Lee; K. Park; S. Mo; J. Kim","Korea Advanced Institute of Science and Technology,Daejeon,South Korea,34141; Max Planck Institute of Intelligent Systems,Stuttgart,Germany,70569; Korea Advanced Institute of Science and Technology,Daejeon,South Korea,34141; Korea Advanced Institute of Science and Technology,Daejeon,South Korea,34141; Korea Advanced Institute of Science and Technology,Daejeon,South Korea,34141","2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","28 Jan 2020","2019","","","7447","7452","Recently, a whole-body tactile sensing have emerged in robotics for safe human-robot interaction. A key issue in the whole-body tactile sensing is ensuring large-area manufacturability and high durability. To fulfill these requirements, a reconstruction method called electrical impedance tomography (EIT) was adopted in large-area tactile sensing. This method maps voltage measurements to conductivity distribution using only a few number of measurement electrodes. A common approach for the mapping is using a linearized model derived from the Maxwell's equation. This linearized model shows fast computation time and moderate robustness against measurement noise but reconstruction accuracy is limited. In this paper, we propose a novel nonlinear EIT algorithm through Deep Neural Network (DNN) approach to improve the reconstruction accuracy of EIT-based tactile sensors. The neural network architecture with rectified linear unit (ReLU) function ensured extremely low computational time (0.002 seconds) and nonlinear network structure which provides superior measurement accuracy. The DNN model was trained with dataset synthesized in simulation environment. To achieve the robustness against measurement noise, the training proceeded with additive Gaussian noise that estimated through actual measurement noise. For real sensor application, the trained DNN model was transferred to a conductive fabric-based soft tactile sensor. For validation, the reconstruction error and noise robustness were mainly compared using conventional linearized model and proposed approach in simulation environment. As a demonstration, the tactile sensor equipped with the trained DNN model is presented for a contact force estimation.","2153-0866","978-1-7281-4004-9","10.1109/IROS40897.2019.8968532","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8968532","","","electric impedance imaging;Gaussian noise;human-robot interaction;image reconstruction;learning (artificial intelligence);neural nets;robot vision;tactile sensors","Deep Neural Network approach;electrical impedance tomography-based real-time soft tactile sensor;whole-body tactile sensing;human-robot interaction;large-area manufacturability;reconstruction method;large-area tactile sensing;voltage measurements;measurement electrodes;computation time;reconstruction accuracy;novel nonlinear EIT algorithm;EIT-based tactile sensors;neural network architecture;rectified linear unit function;extremely low computational time;nonlinear network structure;additive Gaussian noise;actual measurement noise;sensor application;trained DNN model;conductive fabric-based soft tactile sensor;reconstruction error;noise robustness;conventional linearized model","","3","","24","","28 Jan 2020","","","IEEE","IEEE Conferences"
"Speaking robots: The challenges of acceptance by the ageing society","J. Oliveira; G. S. Martins; A. Jegundo; C. Dantas; C. Wings; L. Santos; J. Dias; F. Perdigão","University of Coimbra; University of Coimbra; Cáritas Diocesana de Coimbra, Portugal; Cáritas Diocesana de Coimbra, Portugal; Zuyderland Medisch en Zorgconcern, Sittard-Geleen, The Netherlands; University of Coimbra; Khalifa University, Robotics Institute, Ab u Dhabi, UAE; University of Coimbra","2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","14 Dec 2017","2017","","","1285","1290","The ability of robots to dialogue with humans appears as one critical Human-Machine Interaction feature when it comes to transferring robots into society. This ability gains additional importance when it comes to elderly people, since they find it more comfortable and natural to interact using voice, due to possible natural physical impairments that hinder the usage of some of the interaction modalities (e.g. touch screens). Challenges like recognition accuracy, distant speech, the idiosyncrasies of elderly voices (fading, muffled pronunciation, etc.), the effects of surrounding environment noise or the expressiveness of the robot when speaking, become highly relevant in the acceptance and usability of service robots by the ageing population. In this paper, we present the results, challenges and solutions developed during a nine-month iterative evaluation process that took place within the GrowMeUp project, with focus on speech recognition and synthesis. The paper concludes with an identification of open scientific and technological problems, based on our interpretation of results, which we identify as critical for the acceptance and usability of robots by an ageing society.","1944-9437","978-1-5386-3518-6","10.1109/ROMAN.2017.8172470","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8172470","","Senior citizens;Speech recognition;Speech;Usability;Service robots;Robot sensing systems","geriatrics;human computer interaction;interactive systems;service robots;social aspects of automation;speech recognition","service robots;ageing population;speech recognition;acceptance;ageing society;speaking robots;critical Human-Machine Interaction feature;speech synthesis;natural physical impairments;GrowMeUp project;elderly voices;distant speech;recognition accuracy;touch screens;interaction modalities;elderly people","","","","22","","14 Dec 2017","","","IEEE","IEEE Conferences"
"Accessing Urban History using Spatial Historical Photographs","F. Niebling; F. Maiwald; S. Münster; J. Bruschke; F. Henze","Human-Computer Interaction, University of Würzburg, Würzburg, Germany; Institute of Photogrammetry and Remote Sensing, TU Dresden, Dresden, Germany; Media Centre, TU Dresden, Dresden, Germany; Human-Computer Interaction, University of Würzburg, Würzburg, Germany; Media Centre, TU Dresden, Dresden, Germany","2018 3rd Digital Heritage International Congress (DigitalHERITAGE) held jointly with 2018 24th International Conference on Virtual Systems & Multimedia (VSMM 2018)","26 Aug 2019","2018","","","1","8","We aim to investigate and develop methods and technologies to transfer extensive repositories of historical media and their contextual information into a three-dimensional spatial model, with an additional temporal component. This will make content accessible to different target groups, researchers and the public, via a 4D browser. A location-dependent virtual reality representation can be used as an information base, research tool, and to communicate historical knowledge. The data resources available for this research include extensive holdings of historical photographs of Dresden, which have documented the city over the decades, and digitized map collections on the Deutsche Fotothek (German photographic collection) platform. These will lay the foundation for a prototype model which will give users a virtual experience of historic parts of Dresden.","","978-1-7281-0292-4","10.1109/DigitalHeritage.2018.8809998","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809998","Urban History;Spatial Photography;Building Segmentation;Photogrammetry;Spatial Browsing","Buildings;Three-dimensional displays;Solid modeling;Urban areas;Image segmentation;Media;Photography","computer vision;history;town and country planning;virtual reality","urban history;spatial historical photographs;historical media;contextual information;three-dimensional spatial model;location-dependent virtual reality representation;information base;historical knowledge;data resources;extensive holdings;digitized map collections;Deutsche Fotothek platform;German photographic collection;prototype model;virtual experience;temporal component","","","","58","","26 Aug 2019","","","IEEE","IEEE Conferences"
"A Multithreaded Distributed Telerobotic Framework","M. A. Al-Mouhamed; O. Toker; A. Iqbal","Dept. of Comput. Eng., King Fahd Univ. of Pet. & Miner.; NA; NA","IEEE/ASME Transactions on Mechatronics","16 Oct 2006","2006","11","5","558","566","A reliable real-time client-server telerobotic system that uses a distributed component framework to promote software reusability, ease of extensibility, debugging, and data encapsulation is proposed. .NET remoting is used for automatic handling of the network resources and data transfer while isolating the components from network protocol issues. A client-server transfer of live stereo video provides the operator three-dimensional (3-D) views of the slave scene with augmented reality (AR) framework and services. Overall distributed framework and design independence improves the portability and modularity of the proposed telerobotic system. A multithreaded execution is proposed for streaming of force, command, and for the transfer of live stereo video data. The proposed framework provides a useful integrated software and hardware environment to enhance man-machine interactions using stereo visualization and AR in real-time telerobotic systems","1941-014X","","10.1109/TMECH.2006.882986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1709861","Distributed application framework;man–machine interface;reflected force feedback;telerobotics;three-dimensional (3-D) visualization","Telerobotics;Real time systems;Software reusability;Debugging;Data encapsulation;Protocols;Layout;Augmented reality;Streaming media;Hardware","augmented reality;client-server systems;control engineering computing;data encapsulation;multi-threading;program debugging;software reusability;stereo image processing;telerobotics","multithreaded distributed telerobotic;client-server telerobotic system;software reusability;debugging;data encapsulation;.NET remoting;network resources;data transfer;augmented reality;stereo visualization","","8","1","27","","16 Oct 2006","","","IEEE","IEEE Journals"
"Development of a variable speed wind turbine emulator for research and training","G. Henz; G. Koch; C. M. Franchi; H. Pinheiro","Power Electronics and Control Research Group - GEPOC, Federal University of Santa Maria - Brazi006C; Power Electronics and Control Research Group - GEPOC, Federal University of Santa Maria - Brazi006C; Power Electronics and Control Research Group - GEPOC, Federal University of Santa Maria - Brazi006C; Power Electronics and Control Research Group - GEPOC, Federal University of Santa Maria - Brazi006C","2013 Brazilian Power Electronics Conference","10 Apr 2014","2013","","","737","742","This paper describes the development of a variable speed wind turbine emulator used for educational purposes. The emulator reproduces different wind conditions and turbine modes of operation. The grid connection system is identical with the one used in a real wind turbine, model DR-14. Therefore, the emulator provides hands on experience to students giving them insight into wind energy conversion systems (WECS) under different operating conditions. A supervisory control and data acquisition (SCADA) system was developed in order to allow wind turbine monitoring and parameters setting with a user-friendly interface. Communication networks were established to transfer data and signals between software and hardware to reproduce the wind turbine behavior.","2165-0454","978-1-4799-0272-9","10.1109/COBEP.2013.6785197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785197","Communication networks;Emulation;SCADA systems;Simulation;System testing;Wind energy generation","Wind turbines;Wind speed;Generators;Software packages;SCADA systems;Wind energy;Time series analysis","computer based training;computerised monitoring;human computer interaction;power engineering education;power grids;SCADA systems;user interfaces;wind turbines","variable speed wind turbine emulator;grid connection system;DR-14 model;wind energy conversion systems;WECS;supervisory control and data acquisition system;SCADA system;wind turbine monitoring;wind turbine parameters;user-friendly interface;data transfer;signal transfer","","5","","21","","10 Apr 2014","","","IEEE","IEEE Conferences"
"Vibrotactile Compliance Feedback for Tangential Force Interaction","S. Heo; G. Lee","School of Computing, KAIST, Daejeon, South Korea; School of Computing, KAIST, Daejeon, South Korea","IEEE Transactions on Haptics","15 Sep 2017","2017","10","3","444","455","This paper presents a method to generate a haptic illusion of compliance using a vibrotactile actuator when a tangential force is applied to a rigid surface. The novel method builds on a conceptual compliance model where a physical object moves on a textured surface in response to a tangential force. The method plays vibration patterns simulating friction-induced vibrations as an applied tangential force changes. We built a prototype consisting of a two-dimensional tangential force sensor and a surface transducer to test the effectiveness of the model. Participants in user experiments with the prototype perceived the rigid surface of the prototype as a moving, rubber-like plate. The main findings of the experiments are: 1) the perceived stiffness of a simulated material can be controlled by controlling the force-playback transfer function, 2) its perceptual properties such as softness and pleasantness can be controlled by changing friction grain parameters, and 3) the use of the vibrotactile compliance feedback reduces participants' workload including physical demand and frustration while performing a force repetition task.","2329-4051","","10.1109/TOH.2016.2604305","Basic Science Research Program; National Research Foundation of Korea (NRF); Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7556272","Haptic I/O;input devices and strategies;tactile displays","Force;Vibrations;Haptic interfaces;Prototypes;Friction;Springs;Force measurement","actuators;force sensors;haptic interfaces;transducers;vibrations","vibrotactile compliance feedback;tangential force interaction;haptic illusion;vibrotactile actuator;rigid surface;vibration patterns;friction-induced vibrations;two-dimensional tangential force sensor;surface transducer;force-playback transfer function;perceptual properties;friction grain parameters","Adult;Equipment Design;Feedback;Feedback, Sensory;Female;Friction;Humans;Male;Touch Perception;User-Computer Interface;Vibration;Young Adult","","","39","Traditional","30 Aug 2016","","","IEEE","IEEE Journals"
"A Voice Control Platform of Mobile Robot through ROS","W. Ye; J. Gao; H. Chen; J. Guo","School of Automation, Guangdong University of Technology, Guangdong, 510006; School of Automation, Guangdong University of Technology, Guangdong, 510006; School of Automation, Guangdong University of Technology, Guangdong, 510006; School of Automation, Guangdong University of Technology, Guangdong, 510006","2019 Chinese Control Conference (CCC)","17 Oct 2019","2019","","","4338","4341","In order to enable the interaction between human and mobile robot, a control platform of mobile robot is designed using speech recognition and robot operation system (ROS). The PC installed with ROS performs as server to communicate with the mobile robot which acts as client through WIFI. The server sends commands generated from the speech recognition to the client to control the motion of mobile robot. Simultaneously, the mobile robot transfers information to the sever, and the visualization tool called RVIZ is used to display the motion trajectory and tilt angle of the robot in real-time. The simulation and experimental results demonstrate that the platform can play an important role on human-robot interaction research field and provides potential engineering application and promotion significance.","1934-1768","978-9-8815-6397-2","10.23919/ChiCC.2019.8865596","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8865596","ROS;Speech Recognition;Visualization Tool;Human-robot Interaction","","control engineering computing;human-robot interaction;mobile robots;motion control;speech recognition","voice control platform;speech recognition;robot operation system;mobile robot;human-robot interaction research field;ROS;visualization tool;RVIZ;motion trajectory","","","","13","","17 Oct 2019","","","IEEE","IEEE Conferences"
"Designing Variable Stiffness Profiles to Optimize the Physical Human Robot Interface of Hand Exoskeletons","R. J. Varghese; G. Mukherjee; R. King; S. Keller; A. D. Deshpande","Department of Mechanical Engineering, University of Texas at Austin, Austin, Texas, 78712, USA; Department of Mechanical Engineering, University of Washington, Seattle, WA, 98195, USA; Oculus & Facebook, Redmond, WA, 98052, USA; Oculus & Facebook, Redmond, WA, 98052, USA; Department of Mechanical Engineering, University of Texas at Austin, Austin, Texas, 78712, USA","2018 7th IEEE International Conference on Biomedical Robotics and Biomechatronics (Biorob)","11 Oct 2018","2018","","","1101","1108","The design of comfortable and effective physical human robot interaction (pHRI) interfaces for force transfer is a prominent challenge for coupled human-robot systems. Forces applied by the robot at the fingers create reaction forces on the dorsal surface of the hand, often leading to high pressure concentrations which can cause pain and discomfort. In this paper, the interaction between the pHRI interface and the dorsal surface of the hand is systematically characterized, and a new method for the design of comfortable interfaces is presented. The variability of the stiffness of the hand dorsum is quantified experimentally, and this data is used to minimize the peak pressure exerted on the hand dorsum, by varying the stiffness profile of the pHRI interface. This optimized design is demonstrated to improve the pressure distribution over the hand dorsum where the robot is attached to the hand. Additionally, to enable informed design choices, the effects of varying the stiffness of the pHRI interface on relative displacement between the robot and the hand dorsum are also characterized. This optimization approach to designing pHRI interface can be extended to different limbs, especially when there is a transfer of high moment loads to the human body, provided the appropriate stiffness data is available.","2155-1782","978-1-5386-8183-1","10.1109/BIOROB.2018.8487862","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8487862","","Force;Robots;Load modeling;Exoskeletons;Loading;Surface impedance;Numerical simulation","human-robot interaction;medical robotics;optimisation","hand exoskeletons;force transfer;coupled human-robot systems;reaction forces;dorsal surface;high pressure concentrations;pHRI interface;hand dorsum;optimized design;informed design choices;human body;stiffness data;variable stiffness profiles;physical human robot interaction interface;pressure distribution;relative displacement;optimization approach;high moment loads","","","","14","","11 Oct 2018","","","IEEE","IEEE Conferences"
"A Framework for Collaborative Real-Time 3D Teleimmersion in a Geographically Distributed Environment","G. Kurillo; R. Vasudevan; E. Lobaton; R. Bajcsy","Dept. of Electr. Eng. & Comput. Sci., Univ. of California, Berkeley, CA; Dept. of Electr. Eng. & Comput. Sci., Univ. of California, Berkeley, CA; Dept. of Electr. Eng. & Comput. Sci., Univ. of California, Berkeley, CA; Dept. of Electr. Eng. & Comput. Sci., Univ. of California, Berkeley, CA","2008 Tenth IEEE International Symposium on Multimedia","9 Jan 2009","2008","","","111","118","In this paper, we present a framework for immersive 3D video conferencing and geographically distributed collaboration. Our multi-camera system performs a full-body 3D reconstruction of users in real time and renders their image in a virtual space allowing remote interaction between users and the virtual environment. The paper features an overview of the technology and algorithms used for calibration, capturing, and reconstruction. We introduce stereo mapping using adaptive triangulation which allows for fast (under 25 ms) and robust real-time 3D reconstruction. The chosen representation of the data provides high compression ratios for transfer to a remote site. The algorithm produces partial 3D meshes, instead of dense point clouds, which are combined on the renderer to create a unified model of the user. We have successfully demonstrated the use of our system in various applications such as remote dancing and immersive Tai Chi learning.","","978-0-7695-3454-1","10.1109/ISM.2008.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4741155","remote collaboration;teleimmersion;3D reconstruction;real-time systems","Collaboration;Image reconstruction;Space technology;Videoconference;Real time systems;Rendering (computer graphics);Virtual environment;Paper technology;Calibration;Stereo image processing","data compression;distributed processing;image reconstruction;image representation;teleconferencing;video communication;video signal processing;virtual reality","collaborative real-time 3D teleimmersion;geographically distributed environment;3D video conferencing;multicamera system;full-body 3D reconstruction;stereo mapping;adaptive triangulation;partial 3D meshes;immersive Tai Chi learning;remote dancing","","9","4","24","","9 Jan 2009","","","IEEE","IEEE Conferences"
"A two-grid iterative approach for real time haptics mediated interactive simulation of deformable objects","V. S. Arikatla; S. De","Advanced Computational Research Laboratory, Rensselaer Polytechnic Institute, Troy, NY, USA; Advanced Computational Research Laboratory, Rensselaer Polytechnic Institute, Troy, NY, USA","2010 IEEE Haptics Symposium","8 Apr 2010","2010","","","501","508","Fast and efficient algorithms are paramount in any real-time multimodal interactive simulation involving soft deformable objects. To achieve real time computational rates, it is expedient to adaptively refine the simulation mesh in the vicinity of the interaction region instead of using a uniformly refined mesh. While appealing, such an approach is difficult to implement as the system of linear algebraic equations changes during the course of the simulation as the interaction region is dynamically updated. A direct solution approach for the discretized system of equations is, of course, computationally expensive hence iterative approaches must be pursued. In this paper, we present a novel two-grid computational methodology that uses pre-computed solution on a coarse grid representation of the geometry and a prolongation operator that transfers the coarse grid solution to a locally refined fine grid to generate the initial guess for a Gauss-Seidel type iterative solver. A local relaxation approach is then introduced that preferentially relaxes the local and global residuals and vastly improves computational efficiency, especially with increasing number of degrees of freedom of the mesh. Example problems demonstrate the effectiveness of the method.","2324-7355","978-1-4244-6822-5","10.1109/HAPTIC.2010.5444611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444611","Multigrid;real-time simulation;haptics;fast reanalysis technique;local relaxation","Iterative methods;Haptic interfaces;Deformable models;Computational modeling;Equations;Iterative algorithms;Grid computing;Computational geometry;Mesh generation;Gaussian processes","geometry;haptic interfaces;iterative methods;linear algebra;relaxation theory;rendering (computer graphics)","two-grid iterative approach;real time haptics mediated interactive simulation;real-time multimodal interactive simulation;soft deformable objects;linear algebraic equation;discretized system;two-grid computational methodology;coarse grid representation;prolongation operator;Gauss-Seidel type iterative solver;local relaxation approach;degrees of freedom;haptic rendering;geometry","","1","","23","","8 Apr 2010","","","IEEE","IEEE Conferences"
"Cooperative Steering Assist Control System","C. Sentouh; B. Soualmi; J. Popieul; S. Debernard","LAMIH, Univ. of Valenciennes, Valenciennes, France; LAMIH, Univ. of Valenciennes, Valenciennes, France; LAMIH, Univ. of Valenciennes, Valenciennes, France; LAMIH, Univ. of Valenciennes, Valenciennes, France","2013 IEEE International Conference on Systems, Man, and Cybernetics","27 Jan 2014","2013","","","941","946","The paper deals with the design of lateral shared vehicle control taking into account the interaction between the driver and the assistance system. The shared control system is designed in such a way to ensure a good transfer of the control authority without generating negative interference. For that a driver model that allows making valid predictions on the driver behaviour is integrated in the design process of the controller. In order to avoid complex conflict situations such as during lane change maneuver, a decision making algorithm for the control authority shifting is also proposed and implemented. Experimental results provided in the paper, using interactive simulator, show the effectiveness of the approach to ensure shared lateral vehicle control.","1062-922X","978-1-4799-0652-9","10.1109/SMC.2013.165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6721918","human-machine cooperation;lateral shared control;active safety systems;driver-vehicle interaction;lane keeping assist systems","Vehicles;Vectors;Mathematical model;Torque;Control systems;Interference;Robustness","human computer interaction;road traffic control;steering systems;traffic engineering computing;trajectory control","cooperative steering assist control system;lateral shared vehicle control;driver behavior;assistance system;lane change maneuver;decision making algorithm;control authority shifting;interactive simulator","","29","","17","","27 Jan 2014","","","IEEE","IEEE Conferences"
"MaeSTrO: A Mobile App for Style Transfer Orchestration Using Neural Networks","M. Reimann; M. Klingbeil; S. Pasewaldt; A. Semmo; M. Trapp; J. Döllner",NA; NA; NA; NA; NA; NA,"2018 International Conference on Cyberworlds (CW)","27 Dec 2018","2018","","","9","16","Mobile expressive rendering gained increasing popularity among users seeking casual creativity by image stylization and supports the development of mobile artists as a new user group. In particular, neural style transfer has advanced as a core technology to emulate characteristics of manifold artistic styles. However, when it comes to creative expression, the technology still faces inherent limitations in providing low-level controls for localized image stylization. This work enhances state-of-the-art neural style transfer techniques by a generalized user interface with interactive tools to facilitate a creative and localized editing process. Thereby, we first propose a problem characterization representing trade-offs between visual quality, run-time performance, and user control. We then present MaeSTrO, a mobile app for orchestration of neural style transfer techniques using iterative, multi-style generative and adaptive neural networks that can be locally controlled by on-screen painting metaphors. At this, first user tests indicate different levels of satisfaction for the implemented techniques and interaction design.","","978-1-5386-7315-7","10.1109/CW.2018.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8590011","non photorealistic rendering;style transfer","Neural networks;Rendering (computer graphics);Tools;Creativity;Adaptive systems;Painting;Mobile handsets","image processing;iterative methods;mobile computing;neural nets;rendering (computer graphics);user interfaces","MaeSTrO;mobile app;adaptive neural networks;user tests;style transfer orchestration;mobile expressive rendering;casual creativity;mobile artists;particular style transfer;core technology;manifold artistic styles;creative expression;inherent limitations;low-level controls;localized image stylization;generalized user interface;creative editing process;localized editing process;user control;neural style transfer techniques","","2","","39","","27 Dec 2018","","","IEEE","IEEE Conferences"
"Cognitive-affective regulation process for micro-expressions in active field state space","X. Liu; L. Xie; Z. Wang; D. Fu","School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing 100085, China; School of Computer and Communication Engineering University of Science and Technology Beijing, Beijing 100085, China; School of Computer and Communication Engineering University of Science and Technology Beijing, Beijing 100085, China; School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing 100085, China","2012 IEEE 2nd International Conference on Cloud Computing and Intelligence Systems","14 Nov 2013","2012","02","","831","835","In the active field state space, this paper discusses the transferring process of emotional states driven by the psychological energy. First, the cognitive reasoning process and the recognition method for micro-expressions is the basis of cognitive-affective regulation process. Second, the attenuation function and threshold function are proposed to quantify the personality. The robot emotional states and external stimulus are quantified as the transferring probability in the active field by the attraction. Finally, the relationship coefficient is introduced to the Gross model for cognitive reappraisal. The experiment results shows that this model can effectively regulate the emotional states in the human-robot interaction, and can obviously improve the robot's humanoid, intelligent degree, and interactive effect. This model is in line with the psychological significance in the experiment and simulation, and enables the robot to get rid of the mechanical emotional transferring process.","2376-595X","978-1-4673-1857-0","10.1109/CCIS.2012.6664292","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6664292","Micro-expression;Cognitive-affective regulation;Emotional states space;Relationship coefficient;Transferring probability","Robots;Attenuation;Psychology;Stress;Eyelids;Cognition;Mouth","cognitive systems;emotion recognition;humanoid robots;human-robot interaction","mechanical emotional transferring process;humanoid robot;robot interactive effect;robot intelligent degree;human-robot interaction;cognitive reappraisal;Gross model;relationship coefficient;robot external stimulus;robot emotional states;threshold function;attenuation function;recognition method;cognitive reasoning process;psychological energy;emotional states transferring process;active field state space;microexpressions;cognitive-affective regulation process","","1","","16","","14 Nov 2013","","","IEEE","IEEE Conferences"
"An interactive visualization of the past using a situated simulation approach","J. B. Madsen; C. B. Madsen","Department of Architecture, Design and Media Technology Aalborg University; Department of Architecture, Design and Media Technology Aalborg University","2013 Digital Heritage International Congress (DigitalHeritage)","20 Feb 2014","2013","1","","307","314","This paper describes aspects of the development of an interactive installation for visualizing a 3D reconstruction of a historical church chapel in Kolding, Denmark. We focus on three aspects inherent to a mobile Augmented Reality development context; 1) A procedure for combating gyroscope drift on handheld devices, 2) achieving realistic lighting computation on a mobile platform at interactive frame-rates and 3) an approach to relocation within this applications situated location without position tracking. We present a solution to each of these three aspects. The development is targeted a specific application, but the presented solutions should be relevant to researchers and developers facing similar issues in other contexts. We furthermore present initial findings from everyday usage by visitors at the museum, and explore how these findings can be useful in connection with novel technology for facilitating information transfer to a museum audience. The installation is in active commercial use and is currently logging further user interactions via in-application logging for future investigations in line with this project.","","978-1-4799-3170-5","10.1109/DigitalHeritage.2013.6743754","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6743754","","Visualization;Tablet computers;Solid modeling;Gyroscopes;Three-dimensional displays;Compass;Lighting","augmented reality;data visualisation;history;mobile computing;museums","past interactive visualization;situated simulation approach;interactive installation;3D reconstruction visualization;historical church chapel;Kolding;Denmark;mobile augmented reality development;gyroscope drift;handheld devices;realistic lighting computation;interactive frame-rates;application situated location;museum;information transfer;in-application logging","","4","","25","","20 Feb 2014","","","IEEE","IEEE Conferences"
"Human computer interface virtual acoustic display using gyroscopic sensors","M. Sunny; A. Kalkan-Savoy; C. Thompson","University of Massachusetts Lowell, Center for Advanced Computations and Telecommunications, Department of Electrical and Computer Engineering, 1 University Ave, 01854, USA; University of Massachusetts Lowell, Center for Advanced Computations and Telecommunications, Department of Electrical and Computer Engineering, 1 University Ave, 01854, USA; University of Massachusetts Lowell, Center for Advanced Computations and Telecommunications, Department of Electrical and Computer Engineering, 1 University Ave, 01854, USA","2011 Digital Signal Processing and Signal Processing Education Meeting (DSP/SPE)","24 Mar 2011","2011","","","163","167","In the paper the spherical-head model for the HRTF is developed and is used in conjunction with yaw angle tracking provided using software developed for a WiiRemote controller to simulate sound radiated from a point source as a function of head position. The yaw rotation angle is evaluated using gyros supplied in the Wii motion plus extension device. The real-time data obtained is used to control the parameters of the head related transfer function. This work aims to bring affordable experimental platforms for educating students in physical acoustics and signal processing.","","978-1-61284-227-1","10.1109/DSP-SPE.2011.5739205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5739205","HRTF;position tracking;yaw tracking;Wii;Wiimote","Ear;Delay;Headphones;Software;Auditory system;Scattering;Computational modeling","acoustic signal processing;computer aided instruction;computer displays;human computer interaction;interactive devices","human computer interface;virtual acoustic display;gyroscopic sensors;spherical head model;HRTF;Wii remote controller;yaw rotation angle;Wii motion plus extension device;head related transfer function;physical acoustics;signal processing","","","","13","","24 Mar 2011","","","IEEE","IEEE Conferences"
"Exploiting value statistics for similar continuing tasks","F. Tanaka; M. Yamamura","Dept. Comput. Intelligence & Syst. Sci., Tokyo Inst. of Technol., Yokohama, Japan; Dept. Comput. Intelligence & Syst. Sci., Tokyo Inst. of Technol., Yokohama, Japan","The 12th IEEE International Workshop on Robot and Human Interactive Communication, 2003. Proceedings. ROMAN 2003.","19 Dec 2003","2003","","","271","276","In this paper, we try to consider interaction design for adaptation from the viewpoint of transfer of knowledge. Advancements in robotics are amazing, and their interaction processes with outside world (including human) are getting to be longer in time scale. We investigate these matters in an abstract agent that faces multiple learning tasks within its lifetime, transferring past learning experiences to improve its performance. We formulize the multitask reinforcement learning problem at first, and then we present two ways of incorporating past learning experiences into the agent's learning algorithm.","","0-7803-8136-X","10.1109/ROMAN.2003.1251857","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1251857","","Statistics;Learning;Computational intelligence;Human robot interaction;Embedded system;Cleaning;Finishing;Humanoid robots;Statistical distributions","robots;software agents;learning (artificial intelligence);human computer interaction;statistics","robotics;multiple learning tasks;multitask reinforcement learning problem;learning agent;value statistics;similar continuing tasks","","1","","14","","19 Dec 2003","","","IEEE","IEEE Conferences"
"FPGA based hand sign recognition system","M. M. Mahesh; M. S. Jerry; D. S. B. Wadala","Electronics and Telecommunications Engineering, Alamuri Ratnamala Institute of Engineering and Technology (ARIET), Thane - Maharashtra, India; Electronics and Telecommunications Engineering, Alamuri Ratnamala Institute of Engineering and Technology (ARIET), Thane - Maharashtra, India; Electronics and Telecommunications Engineering, Vidyalankar Institute of Technology Mumbai - Maharashtra, India","2017 2nd IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT)","15 Jan 2018","2017","","","294","299","The prehistoric or primitive cave men's where communication first existed or started were using a means of sign language or gesture for communicating with each other. With the dawn of time, the man started working tirelessly to make his life better and better. The inventions of new technologies and the computer brought a huge change in the life of people. The Computer and advent of the internet made communication and transfer of information easier. But this is always an interaction with machines. The future era is conceiving of human-computer interaction (HCI) that can be used for implementing 3D applications in which user can move or rotate his hands without any input devices like keyboard or mouse. The communication involving hand gestures or signs for communication forms a basic platform for the proposed system. Many researchers have performed different work by using different algorithms. Some of them even have revised their previous algorithm. The current work and related literature review have given a way of developing a new system that can overcome all the system and should provide the best accuracy. The proposed system involves capture of images and then processing it, then filtering the unwanted part. The further processing of the image is carried out using FPGA, i.e. Field Programmable Gate Array. The system desires to give an excellent simulation, good accuracy, minimizes run time and efficiently reduces the power consumption. It will be forming a great alternative with low cost and best computational algorithm. The proposed system is desired to give better results and desired characteristics after implementation.","","978-1-5090-3704-9","10.1109/RTEICT.2017.8256604","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8256604","Human Computer Interaction (HCI);FPGA (Field Programmable Gate Array);Discrete Fourier transform (DFT);Radial Basis Function (RBF);Very Large Scale Integration (VLSI)","Field programmable gate arrays;Feature extraction;Human computer interaction;Gesture recognition;Very large scale integration;Logic gates;Discrete Fourier transforms","field programmable gate arrays;human computer interaction;image capture;image filtering;sign language recognition","sign language;human-computer interaction;hand gestures;FPGA based hand sign recognition system;Field Programmable Gate Array;image filtering","","","","7","","15 Jan 2018","","","IEEE","IEEE Conferences"
"A multimodal virtual keyboard using eye-tracking and hand gesture detection","H. Cecotti; Y. K. Meena; G. Prasad","Department of Computer Science, Fresno State University, Fresno, Ca, USA; Intelligent System Research Centre, Ulster University, N. Ireland, UK; Intelligent System Research Centre, Ulster University, N. Ireland, UK","2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","28 Oct 2018","2018","","","3330","3333","A large number of people with disabilities rely on assistive technologies to communicate with their families, to use social media, and have a social life. Despite a significant increase of novel assistive technologies, robust, non-invasive, and inexpensive solutions should be proposed and optimized in relation to the physical abilities of the users. A reliable and robust identification of intentional visual commands is an important issue in the development of eye-movements based user interfaces. The detection of a command with an eyetracking system can be achieved with a dwell time. Yet, a large number of people can use simple hand gestures as a switch to select a command. We propose a new virtual keyboard based on the detection of ten commands. The keyboard includes all the letters of the Latin script (upper and lower case), punctuation marks, digits, and a delete button. To select a command in the keyboard, the user points the desired item with the gaze, and select it with hand gesture. The system has been evaluated across eight healthy subjects with five predefined hand gestures, and a button for the selection. The results support the conclusion that the performance of a subject, in terms of speed and information transfer rate (ITR), depends on the choice of the hand gesture. The best gesture for each subject provides a mean performance of 8.77 ± 2.90 letters per minute, which corresponds to an ITR of 57.04 ± 14.55 bits per minute. The results highlight that the hand gesture assigned for the selection of an item is inter-subject dependent.","1558-4615","978-1-5386-3646-6","10.1109/EMBC.2018.8512909","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8512909","","Keyboards;Assistive technology;Visualization;Graphical user interfaces;Human computer interaction;Layout;Reliability","assisted living;gaze tracking;gesture recognition;handicapped aids;human computer interaction;keyboards;virtual reality","multimodal virtual keyboard;hand gesture detection;assistive technologies;social media;physical abilities;reliable identification;robust identification;intentional visual commands;eye-movements based user interfaces;eyetracking system;disabilities;Latin script;punctuation marks;digits;delete button;gaze;information transfer rate;ITR;inter-subject dependent","Eye Movements;Gestures;Hand;Healthy Volunteers;Humans;Self-Help Devices","1","","16","","28 Oct 2018","","","IEEE","IEEE Conferences"
"Knowledge integration in early design stages for collaboration on a virtual mock up","I. Thouvenin; D. Lenne; A. Guenand; S. Aubry","Lab. Heudiasyc, Univ. de Technologie de Compiegne, France; NA; NA; NA","Proceedings of the Ninth International Conference on Computer Supported Cooperative Work in Design, 2005.","6 Sep 2005","2005","2","","1141","1145 Vol. 2","With the intensification and the expansion of collaboration modes between designers and engineers for better time and quality mastering, the communication efficiency between these two communities of practice have to be thought taking in to account both designers and engineer's representation systems. While designers participate to the concept research and deliver the product's scenario of use through images, sketches and renderings, the engineers participate to the physical definition and to the materialization of these concepts. There is a need for a common representation of the concepts and the product, i.e. explicit link between the subjective data coming from the designer and the objective data materializing the product. Nevertheless semantic product characterization have specific tools and methods usually found in 2D environments and 3D CAD systems do not answer to the needs of exchanges in a multi disciplinary design team. In this paper we introduce a virtual environment to integrate, capitalize and explore knowledge around the virtual mock up in order to facilitate subjective and objective product characterization for designers and engineers collaboration. This virtual environment (MATRICS) allows the user to post multi-media annotations on a virtual 3D mock up, to support intentions transferred from the designer to the engineer when communicating. Another aspect of this environment is to provide a shared visualization of knowledge connected to the model and users interaction with knowledge representation increasing the collaboration level while designing.","","1-84600-002-5","10.1109/CSCWD.2005.194350","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1504257","","Collaboration;Design engineering;Virtual environment;Systems engineering and theory;Rendering (computer graphics);Design automation;Product design;Knowledge engineering;Multimedia communication;Visualization","groupware;multimedia computing;data visualisation;knowledge representation;product design;virtual reality;virtual manufacturing","knowledge integration;product characterization;virtual environment;multimedia annotations;virtual 3D mock up;shared visualization;knowledge representation","","2","","13","","6 Sep 2005","","","IEEE","IEEE Conferences"
"Learning Safety Equipment Detection using Virtual Worlds","M. di Benedetto; E. Meloni; G. Amato; F. Falchi; C. Gennaro","National Research Council, Institute of Information Science and Technologies, Italy; Università di Pisa, Italy; National Research Council, Institute of Information Science and Technologies, Italy; National Research Council, Institute of Information Science and Technologies, Italy; National Research Council, Institute of Information Science and Technologies, Italy","2019 International Conference on Content-Based Multimedia Indexing (CBMI)","21 Oct 2019","2019","","","1","6","Nowadays, the possibilities offered by state-of-the-art deep neural networks allow the creation of systems capable of recognizing and indexing visual content with very high accuracy. Performance of these systems relies on the availability of high quality training sets, containing a large number of examples (e.g. million), in addition to the the machine learning tools themselves. For several applications, very good training sets can be obtained, for example, crawling (noisily) annotated images from the internet, or by analyzing user interaction (e.g.: on social networks). However, there are several applications for which high quality training sets are not easy to be obtained/created. Consider, as an example, a security scenario where one wants to automatically detect rarely occurring threatening events. In this respect, recently, researchers investigated the possibility of using a visual virtual environment, capable of artificially generating controllable and photo-realistic contents, to create training sets for applications with little available training images. We explored this idea to generate synthetic photo-realistic training sets to train classifiers to recognize the proper use of individual safety equipment (e.g.: worker protection helmets, high-visibility vests, ear protection devices) during risky human activities. Then, we performed domain adaptation to real images by using a very small image data set of real-world photographs. We show that training with the generated synthetic training set and using the domain adaptation step is an effective solution to address applications for which no training sets exist.","1949-3991","978-1-7281-4673-7","10.1109/CBMI.2019.8877466","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877466","Deep Learning;Virtual Dataset;Transfer Learning;Domain Adaptation;Safety Equipment Detection","Training;Safety;Games;Engines;Head;Neural networks;Visualization","feature extraction;image classification;learning (artificial intelligence);neural nets;occupational safety;virtual reality","visual virtual environment;photo-realistic training sets;high-visibility vests;safety equipment detection;virtual worlds;machine learning tools;classifier training;deep neural network training;individual safety equipment recognition;risky human activities","","2","","27","","21 Oct 2019","","","IEEE","IEEE Conferences"
"Interactive Level-of-Detail Selection Using Image-Based Quality Metric for Large Volume Visualization","C. Wang; A. Garcia; H. Shen","Department of Computer Science and Engineering, The Ohio State University, 395 Dreese Laboratories, 2015 Neil Avenue, Columbus, OH 43210; Intel Corporation, 2700 156th Avenue NE, Suite 300, Bellevue, WA 98007; Department of Computer Science and Engineering, The Ohio State University, 395 Dreese Laboratories, 2015 Neil Avenue, Columbus, OH 43210","IEEE Transactions on Visualization and Computer Graphics","20 Nov 2006","2007","13","1","122","134","For large volume visualization, an image-based quality metric is difficult to incorporate for level-of-detail selection and rendering without sacrificing the interactivity. This is because it is usually time-consuming to update view-dependent information as well as to adjust to transfer function changes. In this paper, we introduce an image-based level-of-detail selection algorithm for interactive visualization of large volumetric data. The design of our quality metric is based on an efficient way to evaluate the contribution of multiresolution data blocks to the final image. To ensure real-time update of the quality metric and interactive level-of-detail decisions, we propose a summary table scheme in response to runtime transfer function changes and a GPU-based solution for visibility estimation. Experimental results on large scientific and medical data sets demonstrate the effectiveness and efficiency of our algorithm","1941-0506","","10.1109/TVCG.2007.15","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4015403","Data compaction and compression;perceptual reasoning;viewing algorithms;interaction techniques;hierarchical image representation;volume visualization.","Rendering (computer graphics);Data visualization;Signal resolution;Image resolution;Transfer functions;Runtime;Biomedical imaging;Hardware;Medical simulation;Spatial resolution","image texture;interactive systems;rendering (computer graphics)","interactive level-of-detail selection algorithm;image-based quality metric;large volume interactive visualization;rendering;summary table scheme;transfer function changes;GPU-based solution;visibility estimation","Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;User-Computer Interface","33","","33","","20 Nov 2006","","","IEEE","IEEE Journals"
"Enhancing Social Communication in High-Functioning Children with Autism through a Co-Located Interface","N. Bauminger; D. Goren-Bar; E. Gal; P. L. Weiss; R. Yifat; J. Kupersmitt; F. Pianesi; O. Stock; M. Zancanaro","Bar Ilan University, Israel, bauminn@biu.ac.il; Ben-Gurion University of the Negev, Israel, dinag@bgumail.bgu.ac.il; University of Haifa, Israel, egal@univ.haifa.ac.il; University of Haifa, Israel, tamar@research.haifa.ac.il; University of Haifa, Israel; University of Haifa, Israel, judykup@bezeqint.net; FBK-irst, pianesi@itc.it; FBK-irst, stock@itc.it; FBK-irst, zancana@itc.it","2007 IEEE 9th Workshop on Multimedia Signal Processing","2 Jan 2008","2007","","","18","21","In this paper we describe a pilot study for an intervention aimed at enhancing social skills in high functioning children with autism. We found initial evidences that the use of a social interaction and may lessen the repetitive behaviors typical of autism. These positive effects also appear to be transferred to other tasks following the intervention. We hypothesize that the effect is due to some unique characteristics of the interfaces used, in particular enforcing some tasks to be done together through the use of multiple-user GUI actions.","","978-1-4244-1274-7","10.1109/MMSP.2007.4412808","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4412808","Multiple-user GUI;computer assisted instruction;social interaction;autism","Autism;Collaboration;Graphical user interfaces;Computer aided instruction;Computer displays;Virtual environment;Impedance","computer aided instruction;graphical user interfaces;handicapped aids;paediatrics","social communication;high-functioning children;autism;colocated interface;social skills;multiple-user GUI actions","","19","","9","","2 Jan 2008","","","IEEE","IEEE Conferences"
"Investigating patterns of emotion and expressions using smart learning spaces","G. Dafoulas; A. Tsiakara; J. Samuels-Clarke; C. C. Maia; D. Neilson; A. A. Ali","Computer Science Department, Middlesex University, London, UK; Computer Science Department, Middlesex University, London, UK; Department of Design Engineering and Mathematics, Middlesex University, London, UK; Computer Science Department, Middlesex University, London, UK; Computer Science Department, Middlesex University, London, UK; Computer Science Department, Middlesex University, London, UK","2019 10th International Conference on Information and Communication Systems (ICICS)","22 Aug 2019","2019","","","238","244","The Internet of Things (IoT) is based on the use of interconnected device for data transfer. This paper describes findings from current work that uses a range of sensors that are connected together in collecting biometric data from learners. The research is focused on assessing learners' state during different learning activities by using different biometric data. The paper investigates certain patterns of emotion, expressions and Galvanic Skin Response (GSR) (i.e. sweat levels) amongst participants. The findings are discussed under the prism of learner classification against a number of criteria including learning styles, project management preference, team profile and personality type. The paper contributes in understanding how we can monitor individuals' state and behaviour during different learning activities and identify predominant patterns.","2573-3346","978-1-7281-0045-6","10.1109/IACS.2019.8809119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809119","Internet of Things;Galvanic Skin Response;Sensors;Biometrics;Smart learning Spaces;emotion recognition","Monitoring;Augmented reality;Intelligent sensors;STEM;Bioinformatics;Task analysis","computer aided instruction;emotion recognition;human computer interaction;Internet of Things;pattern classification;skin","smart learning spaces;IoT;interconnected device;data transfer;different biometric data;learner classification;learning styles;learning activities;galvanic skin response;emotion patterns;learner state assessment;sweat level;team profile;personality type;project management preference","","","","24","","22 Aug 2019","","","IEEE","IEEE Conferences"
"Research on rapid modeling method and simulation platform of the gas-steam combined cycle system","T. Xu; Y. Hou; X. Tian; S. Chai; C. Song; J. Luo; Y. Quo; X. Wang","State Power Economic and Technological Research Institute Co., Ltd., Beijing 102209; Beijing Institute of Technology, Beijing 100081, China; State Power Economic and Technological Research Institute Co., Ltd., Beijing 102209; Beijing Institute of Technology, Beijing 100081, China; State Power Economic and Technological Research Institute Co., Ltd., Beijing 102209; State Power Economic and Technological Research Institute Co., Ltd., Beijing 102209; State Power Economic and Technological Research Institute Co., Ltd., Beijing 102209; State Power Economic and Technological Research Institute Co., Ltd., Beijing 102209","2018 Chinese Control And Decision Conference (CCDC)","9 Jul 2018","2018","","","4109","4114","Aiming at the gas-steam combined cycle system models with complex algorithm structures, the single algorithm simulation software cannot build a friendly man-machine interface. Existing hybrid programming methods that combine MATLAB tools and the foreground interface are restricted by the algebraic loop structure in models and are not able to be applied. A distributed modeling and simulation platform with self-defined interfaces is proposed, which utilizes database as a medium to realize data storage and interaction between the server and clients. And implementation in the gas-steam combined cycle system showed that the proposed platform gave full play to advantages of rapid prototyping's fast iteration, complex control computing capability and the environment-friendly clients' interface. The proposed platform holds effective real-time simulation, strong confidentiality, flexibility, and versatility, which satisfies mass data's simulation and storage need for multiple clients.","1948-9447","978-1-5386-1244-6","10.1109/CCDC.2018.8407838","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8407838","Gas-Steam Combined Cycle System;Simulation;Database;Distributed Platform","Heat transfer;Electron tubes;Matlab;Boilers;Turbines;Databases;Biological system modeling","combined cycle power stations;digital simulation;Matlab;power engineering computing;user interfaces","real-time simulation;MATLAB tools;environment-friendly clients interface;self-defined interfaces;distributed modeling;algebraic loop structure;foreground interface;hybrid programming methods;complex algorithm structures;gas-steam combined cycle system models;simulation platform;rapid modeling method","","","","15","","9 Jul 2018","","","IEEE","IEEE Conferences"
"A portable and high efficiency system for cell electroporation under low voltage","M. Wu; Z. Wei; D. Zhao; Z. Li","School of Computer and Information Engineering, Peking University Shenzhen Graduate School, China; National Key Laboratory of Science and Technology on Micro/Nano Fabrication, Institute of Microelectronics, Peking University, Beijing, China; Institute of Molecular Medicine, Peking University, Beijing, China; National Key Laboratory of Science and Technology on Micro/Nano Fabrication, Institute of Microelectronics, Peking University, Beijing, China","2011 6th IEEE International Conference on Nano/Micro Engineered and Molecular Systems","12 Sep 2011","2011","","","768","771","Based on a novel micro-fabricated electroporation (EP) chip, a portable EP system was designed and manufactured. The whole system consisted of a programmable and adjustable mini impulsator and micro EP chips. Large statistical data of transfection efficiency were determined under various pulse amplitudes, durations and intervals in this system for HEK-293 cells. High transfeciton efficiency (80%) was achieved under low voltage (~20V) in this system. A man-machine interface was developed by keyboard and LCD screen in the mini impulsator using single chip micyoco. The impulsator can be adjusted to accommodate its pulse electrical parameters to a variety of conditions. The system has been fabricated and is in probation. With further EP experiments on other kinds of cells, more guidance will be given for researchers to shorten EP time and enhance efficiency.","","978-1-61284-777-1","10.1109/NEMS.2011.6017467","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6017467","electroporation;HEK-293 cell;low voltage transfer;single chip micyoco system;man-machine interface","Electric fields;Electrodes;User interfaces;Low voltage;Micromechanical devices;Keyboards;Educational institutions","biocomputing;bioelectric phenomena;human computer interaction;keyboards;liquid crystal displays;microfabrication;portable instruments","cell electroporation;microfabricated electroporation chip;portable EP system;programmable impulsator;adjustable impulsator;pulse amplitudes;HEK-293 cells;transfeciton efficiency;man-machine interface;keyboard;LCD screen;pulse electrical parameters","","1","","6","","12 Sep 2011","","","IEEE","IEEE Conferences"
"Power Optimization of Ultrasonic Friction-Modulation Tactile Interfaces","M. Wiertlewski; J. E. Colgate","Department of Mechanical Engineering, Northwestern University, Evanston, IL; Department of Mechanical Engineering, Northwestern University, Evanston, IL","IEEE Transactions on Haptics","19 May 2017","2015","8","1","43","53","Ultrasonic friction-modulation devices provide rich tactile sensation on flat surfaces and have the potential to restore tangibility to touchscreen. To date, their adoption into consumer electronics has been in part limited by relatively high power consumption, incompatible with the requirements of battery-powered devices. This paper introduces a method that optimizes the energy efficiency and performance of this class of devices. It considers optimal energy transfer to the impedance provided by the finger interacting with the surface. Constitutive equations are determined from the mode shape of the interface and the piezoelectric coupling of the actuator. The optimization procedure employs a lumped parameter model to simplify the treatment of the problem. Examples and an experimental study show the evolution of the optimal design as a function of the impedance of the finger.","2329-4051","","10.1109/TOH.2014.2362518","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6919307","Ultrasonic;surface haptics;haptics;tactile interface;variable friction;Ultrasonic;surface haptics;haptics;tactile interface;variable friction","Actuators;Acoustics;Glass;Shape;Friction;Impedance","consumer electronics;energy conservation;haptic interfaces;human computer interaction;lumped parameter networks;optimisation;piezoelectric actuators;touch sensitive screens","optimal design evolution;lumped parameter model;actuator;piezoelectric coupling;mode shape;constitutive equations;finger interaction;optimal energy transfer;performance optimization;energy efficiency optimization;consumer electronics;touchscreen;tactile sensation;ultrasonic friction-modulation tactile interface;power optimization","Electric Impedance;Electric Power Supplies;Electronics;Energy Transfer;Equipment Design;Fingers;Friction;Humans;Man-Machine Systems;Models, Biological;Touch;Ultrasonics","17","","31","","9 Oct 2014","","","IEEE","IEEE Journals"
"Electric superbike racing — The design and construction of a championship winning electric superbike","P. Wheeler; J. Blissett; M. G. Fabra","Power Electronics, Machines and Control Research Group, University of Nottingham, UK; Power Electronics, Machines and Control Research Group, University of Nottingham, UK; Power Electronics, Machines and Control Research Group, University of Nottingham, UK","2017 7th International Conference on Power Electronics Systems and Applications - Smart Mobility, Power Transfer & Security (PESA)","1 Feb 2018","2017","","","1","5","The electric superbikes recently developed at The University of Nottingham are considered to be high performance vehicles, competing with its internal combustion engine driven counterparts. This paper presents the motivations for this work and details the design of the bikes which, a process that has ensured maximized race performance. Extensive modelling has also given a good understanding of the system interaction. Data recorded during races and on a rolling road are presented to validate the simulation work.","","978-1-5386-1387-0","10.1109/PESA.2017.8277747","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8277747","Electric vehicles;transportation electrification;motor drives;vehicle propulsion","Torque;Motorcycles;Permanent magnet motors;Gears;Batteries;Wheels;Motor drives","design engineering;educational courses;electric vehicles;internal combustion engines;motorcycles;roads;velocity measurement","speed measurement;superbike design;rolling road;University of Nottingham;internal combustion engine;high performance vehicles;electric superbike racing;race performance","","1","","12","","1 Feb 2018","","","IEEE","IEEE Conferences"
"Real-Time Control of an Interactive Impulsive Virtual Prosthesis","N. E. Bunderson","Georgia Institute of Technology, Atlanta, GA, USA","IEEE Transactions on Neural Systems and Rehabilitation Engineering","5 Mar 2014","2014","22","2","363","370","An interactive virtual dynamic environment for testing control strategies for neural machine interfacing with artificial limbs offers several advantages. The virtual environment is low-cost, easily configured, and offers a wealth of data for post-hoc analysis compared with real physical prostheses and robots. For use with prosthetics and research involving amputee subjects it allows the valuable time with the subject to be spent in experiments rather than fixing hardware issues. The usefulness of the virtual environment increases as the realism of the environment increases. Most tasks performed with limbs require interactions with objects in the environment. To simulate these tasks the dynamics of frictional contact, in addition to inertial limb dynamics must be modeled. Here, subjects demonstrate real-time control of an eight degree-of-freedom virtual prosthesis while performing an interactive box-and-blocks task. With practice, four nonamputee subjects and one shoulder disarticulation subject were able to successfully transfer blocks in the virtual environment at an average rate of just under two blocks per minute. The virtual environment is configurable in terms of the virtual arm design, control strategy, and task.","1558-0210","","10.1109/TNSRE.2013.2274599","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6587127","Myoelectric control;neural machine interface;prosthesis;targeted muscle reinnervation;virtual system","Prosthetics;Wrist;Joints;Virtual environments;Shoulder;Electromyography;Dynamics","biomechanics;brain-computer interfaces;electromyography;friction;mechanical variables control;medical control systems;medical signal processing;neurophysiology;prosthetics;virtual reality","real-time control;interactive impulsive virtual prosthesis;interactive virtual dynamic environment;control strategy testing;neural machine interfacing;artificial limbs;post-hoc analysis;real physical prostheses;robots;amputee subjects;fixing hardware issues;frictional contact;inertial limb dynamics;degree-of-freedom virtual prosthesis;interactive box-and-blocks task;shoulder disarticulation subject;nonamputee subjects;virtual arm design;control strategy","Algorithms;Amputation;Artificial Limbs;Biomechanical Phenomena;Brain-Computer Interfaces;Computer Simulation;Disarticulation;Electromyography;Fingers;Hand;Humans;Linear Models;Male;Motor Skills;Movement;Prostheses and Implants;Prosthesis Design;Shoulder;Torque;Ulna;User-Computer Interface;Wrist","5","","33","","26 Aug 2013","","","IEEE","IEEE Journals"
"Shape Localization and Recognition Using a Magnetorheological-Fluid Haptic Display","R. Rizzo; A. Musolino; L. A. Jones","Department of Engineering for Energy and Systems, University of Pisa, Pisa, Italy; Department of Engineering for Energy and Systems, University of Pisa, Pisa, Italy; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA","IEEE Transactions on Haptics","18 Jun 2018","2018","11","2","317","321","Smart materials such as magnetorheological fluids (MRF) offer an interesting technology for use in haptic displays as changes in the magnetic field are rapid, reversible, and controllable. These interfaces have been evaluated in a number of medical and surgical simulators where they can provide cues regarding the viscoelastic properties of tissues. The objective of the present set of experiments was first to determine whether a shape embedded in the MRF could be precisely localized and second whether 10 shapes rendered in a MRF haptic display could be accurately identified. It was also of interest to determine how the information transfer associated with this type of haptic display compares to that achieved using other haptic channels of communication. The overall performance of participants at identifying the shapes rendered in the MRF was good with a mean score of 73 percent correct and an Information Transfer (IT) of 2.2 bits. Participants could also localize a rigid object in the display accurately. These findings indicate that this technology has potential for use in training manual palpation skills and in exploring haptic shape perception in dynamic environments.","2329-4051","","10.1109/TOH.2017.2771420","Università di Pisa; US National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8101013","Touch-based properties and capabilities of the human user;hardware and software that enable touch-based interactions with real;remote;and virtual environments;tactile communication","Haptic interfaces;Shape;Fluids;Coils;Magnetic fields;Surgery;Actuators","biological tissues;haptic interfaces;magnetic fluids;magnetorheology;medical computing;shape recognition;viscoelasticity","manual palpation skills training;haptic channels;tissues viscoelastic properties;shape recognition;MRF haptic display;surgical simulators;medical simulators;magnetic field;magnetorheological fluids;smart materials;magnetorheological-fluid haptic display;shape localization;haptic shape perception;information transfer","Adult;Electromagnetic Phenomena;Electronics, Medical;Female;Form Perception;Humans;Male;Touch Perception;User-Computer Interface;Young Adult","2","","36","","9 Nov 2017","","","IEEE","IEEE Journals"
"Design and Development of a Multi-Control Gesture-Recognition based Robotic Arm","S. S. Pradhan","University of Mumbai,Department of Engineering Sciences & Humanities,Mumbai,India","2019 International Conference on Innovative Trends and Advances in Engineering and Technology (ICITAET)","18 Aug 2020","2019","","","100","106","With the advent of automation technology, Human-Machine Interface (HMI) has emerged as new trend in industry today. However, precision control in such systems has been the main hindrance in path for further improvements. This paper proposes a wireless communication HMI framework to operate a human-resembling robotic arm that tracks and follows the controller's arm movements. A 6 Degree-of-Freedom prosthetic arm is designed on a 3D CAD software `SolidWorks' to enact human arm activity. The end-effector of this setup is a mechanical human hand. This model is constructed and then simulated in Simscape. Arduino boards and IDE are utilized for instruction and data transfer. Simulink's support package for Arduino hardware is used for the arm's physical modelling. To resolve the aforementioned problem, various types of control structures are explored and implemented. These include gyro-accelerometer based position tracking, arm skeletal imaging and color tracking by using MATLAB. Performances of all the structures are analyzed and compared with the simulation. To obtain best results, the creation of a platform ROS (Robot Operating System) is proposed that corrects the input control for each set of time frame in accordance with the simultaneously run simulation. In future, this technique can be employed in all types of bilateral teleoperations and haptic feedback systems.","","978-1-7281-1901-4","10.1109/ICITAET47105.2019.9170215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9170215","human-machine-interface;gesture;robotic;sensor;end-effector;Link;Joint;DOF;servo;accelerometer;SolidWorks;Simscape;MATLAB;Kinect;bluetooth","","accelerometers;CAD;control engineering computing;end effectors;feedback;gesture recognition;haptic interfaces;human computer interaction;human-robot interaction;man-machine systems;mobile robots;position control;prosthetics;telerobotics;user interfaces","input control;Robot Operating System;color tracking;arm skeletal imaging;gyro-accelerometer based position tracking;control structures;Arduino hardware;simulink;data transfer;Arduino boards;mechanical human hand;human arm activity;3D CAD software;Degree-of-Freedom prosthetic arm;controller;human-resembling robotic arm;wireless communication HMI framework;main hindrance;precision control;Human-Machine Interface;automation technology;multicontrol gesture-recognition based robotic arm","","","","15","","18 Aug 2020","","","IEEE","IEEE Conferences"
"Contact force modelling and adaptive control of pneumatic system","W. Lin; W. Dong; Y. Deng; C. Qian; J. Qiu","Research Institute of Intelligent Control and Systems, Harbin Institute of Technology, Harbin, 150080, China; Research Institute of Intelligent Control and Systems, Harbin Institute of Technology, Harbin, 150080, China; Research Institute of Intelligent Control and Systems, Harbin Institute of Technology, Harbin, 150080, China; Research Institute of Intelligent Control and Systems, Harbin Institute of Technology, Harbin, 150080, China; Research Institute of Intelligent Control and Systems, Harbin Institute of Technology, Harbin, 150080, China","2016 31st Youth Academic Annual Conference of Chinese Association of Automation (YAC)","5 Jan 2017","2016","","","357","362","Flexible control is widely used in the field of robot and it is a very important platform for human-robot interaction. In this paper, a new approach is proposed for flexible control of the robot end-effector using pneumatic system. The pneumatic system model consists of proportional valves and pneumatic actuators. The friction model based on the actual system was built. The open loop transfer function of the system was built based on linear system and selected parameters were used to analyze the system preliminarily. A speed control without force feedback was used to control the pneumatic system to contact the target object and an adaptive control system was designed to compensate the friction and the uncertainty of the effective load. A cylinder with a proportional valve was used as the control objects and the control method and model are verified through simulation and experiment.","","978-1-5090-4423-8","10.1109/YAC.2016.7804919","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7804919","constant contact force control;human-robot interaction;adaptive control","Decision support systems;Valves;Adaptive control;Pneumatic actuators;Pneumatic systems;Force control;Human-robot interaction","adaptive control;end effectors;human-robot interaction;linear systems;mechanical variables control;open loop systems;pneumatic actuators;valves;velocity control","proportional valve;adaptive control system;speed control;linear system;open loop transfer function;friction model;pneumatic actuators;proportional valves;robot end-effector;human-robot interaction;flexible control;contact force modelling","","4","","7","","5 Jan 2017","","","IEEE","IEEE Conferences"
"Framework for virtual collaboration emphasized by awareness information and asynchronous interaction","Tomo Matsuda; Naoki Shibata; Keiichi Yasumoto; Minoru Ito","Graduate School of Information Science, Nara Institute of Science and Technology, 630-0192, Japan; Department of Information Processing and Management, Shiga University, 522-8522, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, 630-0192, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, 630-0192, Japan","2008 IEEE International Conference on Multimedia and Expo","26 Aug 2008","2008","","","997","1000","In this paper, we propose a framework which allows remote users to form conversation groups based on spatial relationship in a shared virtual space. Our proposed framework can transport awareness information of real world by capturing and transferring user's audio visual information. Our framework also provides functions useful to CSCW, which allow each user to simultaneously join different conversation groups, and communicate with others asynchronously exchanging awareness information. We show a reference implementation architecture to realize the framework in an ordinary computing and networking environment.","1945-788X","978-1-4244-2570-9","10.1109/ICME.2008.4607605","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4607605","DVE;CSCW;collaboration;awareness","Avatars;Streaming media;Three dimensional displays;Aerospace electronics;Graphical user interfaces;Servers;Visualization","groupware;virtual reality","virtual collaboration;asynchronous interaction;conversation groups;spatial relationship;shared virtual space;audio visual information;CSCW;jawareness information exchange","","","","8","","26 Aug 2008","","","IEEE","IEEE Conferences"
"Finger-based manipulation in immersive spaces and the real world","E. Chapoulie; T. Tsandilas; L. Oehlberg; W. Mackay; G. Drettakis","Inria, France; Inria, Univ Paris-Sud, France; Inria, Univ Paris-Sud, France; Inria, Univ Paris-Sud, France; Inria, France","2015 IEEE Symposium on 3D User Interfaces (3DUI)","25 Jun 2015","2015","","","109","116","Immersive environments that approximate natural interaction with physical 3D objects are designed to increase the user's sense of presence and improve performance by allowing users to transfer existing skills and expertise from real to virtual environments. However, limitations of current Virtual Reality technologies, e.g., low-fidelity real-time physics simulations and tracking problems, make it difficult to ascertain the full potential of finger-based 3D manipulation techniques. This paper decomposes 3D object manipulation into the component movements, taking into account both physical constraints and mechanics. We fabricate five physical devices that simulate these movements in a measurable way under experimental conditions. We then implement the devices in an immersive environment and conduct an experiment to evaluate direct finger-based against ray-based object manipulation. The key contribution of this work is the careful design and creation of physical and virtual devices to study physics-based 3D object manipulation in a rigorous manner in both real and virtual setups.","","978-1-4673-6886-5","10.1109/3DUI.2015.7131734","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7131734","Immersive Cube-like Displays;Finger-based manipulation;Real/virtual world comparison","Three-dimensional displays;Haptic interfaces;Friction;Color;Visualization;Needles","virtual reality","finger-based manipulation;immersive spaces;real world;immersive environments;natural interaction;user sense-of-presence;performance improvement;users skills;virtual environments;virtual reality technologies;low-fidelity real-time physics simulations;tracking problems;finger-based 3D manipulation techniques;3D object manipulation;component movements;physical constraints;physical mechanics;physical devices;experimental conditions;immersive environment;ray-based object manipulation;physics-based 3D object manipulation","","4","","29","","25 Jun 2015","","","IEEE","IEEE Conferences"
"Experimental Verification of Force Interactions for Robinhand Prototype Motion Controller","L. Mucha; K. Lis; D. Krawczyk","Foundation of Cardiac Surgery Development; Foundation of Cardiac Surgery Development; Faculty of Mechanical Engineering, Department of Machine Technology","2019 12th International Workshop on Robot Motion and Control (RoMoCo)","5 Aug 2019","2019","","","56","61","In article, the design stages, principle of operation and static tests of the force that is exerted on the operator by the RobinHand motion controller were presented. Besides that, details of such issues as, the developed laboratory stand for testing the force interactions, all concepts and ways of implementing the transfer of tactile stimuli from real devices or virtual reality to the user/surgeon, subsequent variants of the developed devices with the short description of them, the project of the operator-surgeon stand that is based on the assumption that the method of control of this device is compatible with the natural work of the surgeon as well as the project of control console that is used to manipulate the surgical robot were presented.","2575-5579","978-1-7281-2975-4","10.1109/RoMoCo.2019.8787355","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8787355","","Surgery;Force;Robots;Haptic interfaces;Tools;Kinematics;Laparoscopes","control engineering computing;manipulators;medical computing;medical robotics;motion control;surgery;virtual reality","experimental verification;force interactions;static tests;tactile stimuli;virtual reality;operator-surgeon stand;Robinhand prototype motion controller;surgical robot","","","","16","","5 Aug 2019","","","IEEE","IEEE Conferences"
"Optimizing network 3D data transmissions for interactive applications","I. Harada; H. Sato; H. Kitazawa","Lifestyle & Environ. Technol. Labs., NTT, Japan; NA; NA","Proceedings the Eighth Pacific Conference on Computer Graphics and Applications","6 Aug 2002","2000","","","419","420","3D object data transfer was optimized to accelerate interactive 3D scene design and virtual-space layout applications. In these applications, downloading many 3D objects reduces the interactivity of the clients. We used level-of-detail based loading sequences and timing control methods to interleave data downloading and interactions. Experiments showed that the maximum interval between interactions was up to 6.42 times shorter.","","0-7695-0868-5","10.1109/PCCGA.2000.883974","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=883974","","Research and development;Local area networks;Wide area networks;Layout;Poles and towers;Design optimization;Application software;Timing;Data visualization","interactive systems;data communication;optimisation;sequences;timing;solid modelling;natural scenes;virtual reality","network 3D data transmission optimization;interactive applications;3D object data transfer;interactive 3D scene design;virtual-space layout applications;data downloading;level-of-detail based loading sequences;timing control methods","","","","6","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Pseudo-Haptic Feedback in Teleoperation","C. Neupert; S. Matich; N. Scherping; M. Kupnik; R. Werthschützky; C. Hatzfeld","Haptic Systems Group, Institute of Electromechanical Design, Technische Universität Darmstadt, Darmstadt, Germany; Haptic Systems Group, Institute of Electromechanical Design, Technische Universität Darmstadt, Darmstadt, Germany; Haptic Systems Group, Institute of Electromechanical Design, Technische Universität Darmstadt, Darmstadt, Germany; Haptic Systems Group, Institute of Electromechanical Design, Technische Universität Darmstadt, Darmstadt, Germany; Haptic Systems Group, Institute of Electromechanical Design, Technische Universität Darmstadt, Darmstadt, Germany; Haptic Systems Group, Institute of Electromechanical Design, Technische Universität Darmstadt, Darmstadt, Germany","IEEE Transactions on Haptics","19 May 2017","2016","9","3","397","408","In this paper, we develop possible realizations of pseudo-haptic feedback in teleoperation systems based on existing works for pseudo-haptic feedback in virtual reality and the intended applications. We derive four potential factors affecting the performance of haptic feedback (calculation operator, maximum displacement, offset force, and scaling factor), which are analyzed in three compliance identification experiments. First, we analyze the principle usability of pseudo-haptic feedback by comparing information transfer measures for teleoperation and direct interaction. Pseudo-haptic interaction yields well above-chance performance, while direct interaction performs almost perfectly. In order to optimize pseudo-haptic feedback, in the second study we perform a full-factorial experimental design with 36 subjects performing 6,480 trials with 36 different treatments. Information transfer ranges from 0.68 bit to 1.72 bit in a task with a theoretical maximum of 2.6 bit, with a predominant effect of the calculation operator and a minor effect of the maximum displacement. In a third study, short- and long-term learning effects are analyzed. Learning effects regarding the performance of pseudo-haptic feedback cannot be observed for single-day experiments. Tests over 10 days show a maximum increase in information transfer of 0.8 bit. The results show the feasibility of pseudo-haptic feedback for teleoperation and can be used as design basis for task-specific systems.","2329-4051","","10.1109/TOH.2016.2557331","Deutsche Forschungsgemeinschaft; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7457685","Haptics;pseudo-haptics;teleoperation;medical robotics","Haptic interfaces;Force;Iron;Manipulators;Actuators;Couplings;Virtual environments","haptic interfaces;medical robotics;surgery;telerobotics;virtual reality","pseudo-haptic feedback;teleoperation system;virtual reality;calculation operator;maximum displacement;offset force;scaling factor;compliance identification experiments;information transfer measures;direct interaction;minimal invasive surgery","Adult;Computer Simulation;Equipment Design;Feedback;Female;Humans;Learning;Male;Robotic Surgical Procedures;Robotics;Telemedicine;Touch;User-Computer Interface","9","","29","","21 Apr 2016","","","IEEE","IEEE Journals"
"Control of Dual-User Haptic Training System With Online Authority Adjustment: An Observer-Based Adaptive Robust Scheme","M. Motaharifar; H. D. Taghirad; K. Hashtrudi-Zaad; S. F. Mohammadi","Advanced Robotics and Automated Systems (ARAS), Industrial Control Center of Excellence, Faculty of Electrical Engineering, K. N. Toosi University of Technology, Tehran, Iran; Advanced Robotics and Automated Systems (ARAS), Industrial Control Center of Excellence, Faculty of Electrical Engineering, K. N. Toosi University of Technology, Tehran, Iran; Department of Electrical and Computer Engineering, BioRobotics Research Laboratory, Queen’s University, Kingston, ON, Canada; Translational Ophthalmology Research Center, Farabi Eye Hospital, Tehran University of Medical Sciences, Tehran, Iran","IEEE Transactions on Control Systems Technology","8 Oct 2020","2020","28","6","2404","2415","The design problem for the control a dual-user haptic surgical training system is studied in this article. The system allows the trainee to perform the task on a virtual environment, while the trainer is able to interfere in the operation and correct probable mistakes made by the trainee. The proposed methodology allows the trainer to transfer the task authority to or from the trainee in real time. The robust adaptive nature of the controller ensures position tracking. The stability of the closed-loop system is analyzed using the input-to-output stability approach and the small-gain theorem. Simulation and experimental results are presented to validate the effectiveness of the proposed control scheme.","1558-0865","","10.1109/TCST.2019.2946943","National Institute for Medical Research Development (NIMAD); Tehran University of Medical Sciences, Tehran, Iran; K. N. Toosi University of Technology, Tehran, Iran Research Grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886365","Dual-user haptics;robust adaptive control;stability;surgical training;task dominance","Haptic interfaces;Task analysis;Training;Stability analysis;Force;Robots;Surgery","adaptive control;closed loop systems;computer based training;control system synthesis;haptic interfaces;human computer interaction;medical control systems;robust control;surgery;virtual reality","control scheme;online authority adjustment;observer-based adaptive robust scheme;dual-user haptic surgical training system;virtual environment;task authority;closed-loop system;dual-user haptic training system control;design problem;position tracking;robust adaptive controller;input-to-output stability approach;small-gain theorem","","","","22","IEEE","30 Oct 2019","","","IEEE","IEEE Journals"
"Beyond DoD: non-defense training and education applications of DIS","E. A. Fitzsimmons; J. D. Fletcher","Office of Sci. & Technol. Policy, Washington, DC, USA; NA","Proceedings of the IEEE","6 Aug 2002","1995","83","8","1179","1187","Networked simulation for education and training is discussed as a functional capability though which distributed interactive simulation (DIS) may find application in the non-defense world. Effectiveness of networked simulation in defense education and training applications has yet to be conclusively demonstrated, but studies completed thus far have yielded positive results. Results from non-defense applications are also likely to be positive. The characteristics of networked simulation that are relevant to its transfer to non-defense applications include a focus on group performance, physical dispersion of participants, requirements for real-time response, emergent task environments, visual task environments, accessible performance data, provisions for practice, immersive realism, and interactions with many entities. These characteristics are matched with potential, non-defense applications of networked simulation such as training for crews, teams, and units, edutainment, education, training, school-to-work transitions, and lifelong learning. Remaining issues include further development of technical standards, legal standards, research and development, fiscal and regulatory policies, and development of the communications infrastructure.<>","1558-2256","","10.1109/5.400457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=400457","","US Department of Defense;Computational modeling;Computer simulation;Communication standards;Standards development;Computer networks;Military computing;Safety;Stress;Law","computer based training;training;computer aided instruction;digital simulation;simulation;standards;interactive systems;legislation;groupware;local area networks","nondefense training applications;nondefense education applications;DIS;functional capability;networked simulation;distributed interactive simulation;group performance;physical participant dispersion;real-time response;emergent task environments;visual task environments;accessible performance data;practice provisions;immersive realism;interactions;crews;teams;units;edutainment;school-to-work transitions;lifelong learning;technical standards","","4","","22","","6 Aug 2002","","","IEEE","IEEE Journals"
"Multitask Learning of Time-Frequency CNN for Sound Source Localization","C. Pang; H. Liu; X. Li","Key Laboratory of Machine Perception, Shenzhen Graduate School, Peking University, Beijing, China; Key Laboratory of Machine Perception, Shenzhen Graduate School, Peking University, Beijing, China; INRIA Grenoble Rhône-Alpes, Montbonnot Saint-Martin, France","IEEE Access","4 Apr 2019","2019","7","","40725","40737","Sound source localization (SSL) is an important technique for many audio processing systems, such as speech enhancement/recognition and human-robot interaction. Although many methods have been proposed for SSL, it still remains a challenging task to achieve accurate localization under adverse acoustic scenarios. In this paper, a novel binaural SSL method based on time-frequency convolutional neural network (TF-CNN) with multitask learning is proposed to simultaneously localize azimuth and elevation under unknown acoustic conditions. First, the interaural phase difference and interaural level difference are extracted from the received binaural signals, which are taken as the input of the proposed SSL neural network. Then, an SSL neural network is designed to map the interaural cues to sound direction, which consists of TF-CNN module and multitask neural network. The TF-CNN module learns and combines the time-frequency information of extracted interaural cues to generate the shared feature for multitask SSL. With the shared feature, a multitask neural network is designed to simultaneously estimate azimuth and elevation through multitask learning, which generates the posterior probability for candidate directions. Finally, the candidate direction with the highest probability is taken as the final direction estimation. The experiments based on public head-related transfer function (HRTF) database demonstrate that the proposed method achieves preferable localization performance compared with other popular methods.","2169-3536","","10.1109/ACCESS.2019.2905617","National Natural Science Foundation of China; Shenzhen Key Laboratory for Intelligent Multimedia and Virtual Reality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8668414","Sound source localization;time-frequency;convolutional neural network;multitask learning","Azimuth;Neural networks;Time-frequency analysis;Acoustics;Feature extraction;Estimation;Noise measurement","acoustic generators;audio signal processing;convolutional neural nets;human-robot interaction;learning (artificial intelligence);probability;speech enhancement;speech recognition;time-frequency analysis","multitask learning;time-frequency CNN;sound source localization;audio processing systems;adverse acoustic scenarios;novel binaural SSL method;unknown acoustic conditions;interaural phase difference;interaural level difference;received binaural signals;SSL neural network;TF-CNN module;multitask neural network;extracted interaural cues;shared feature;multitask SSL;candidate direction;preferable localization performance;speech enhancement;human-robot interaction;time-frequency convolutional neural network;time-frequency information;speech recognition;azimuth localization;elevation localization;posterior probability;public head-related transfer function database;public HRTF database","","1","","56","","17 Mar 2019","","","IEEE","IEEE Journals"
"Exploiting 3D virtual environments for supporting role playing games","A. Deligiannakou; A. Papavasileiou; E. Polymeraki; C. Volioti; A. Mavridis; T. Tsiatsos; Y. Revtyuk; L. Kolesnyk","Department of Informatics, Aristotle University of Thessaloniki, Greece; Department of Informatics, Aristotle University of Thessaloniki, Greece; Department of Informatics, Aristotle University of Thessaloniki, Greece; Department of Informatics, Aristotle University of Thessaloniki, Greece; Department of Informatics, Aristotle University of Thessaloniki, Greece; Department of Informatics, Aristotle University of Thessaloniki, Greece; Faculty of Management, Ivano-Frankivsk National Technical University of Oil and Gas Ukraine; Faculty of Management, Ivano-Frankivsk National Technical University of Oil and Gas Ukraine","2012 15th International Conference on Interactive Collaborative Learning (ICL)","7 Jan 2013","2012","","","1","7","This paper describes the international electronic collaboration among students of two universities in order to create a digital educational space for supporting a role playing educational activity. The paper also presents the virtual place that has been implemented in order to transfer the role playing game activity students from the traditional classroom as well as the assessment of the whole activity from the pedagogical and technological viewpoint.","","978-1-4673-2427-4","10.1109/ICL.2012.6402170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402170","3D Game Based Learning;Simulated Environments;OpenSim","Games;Educational institutions;Collaboration;Color;Investments;Virtual environments;Educational activities","computer aided instruction;computer games;human computer interaction;virtual reality","3D virtual environments;role playing game activity;international electronic collaboration;digital educational space;role playing educational activity;virtual place;pedagogical viewpoint;technological viewpoint;virtual learning environments;VLE;game based learning;GBL;OpenSim","","1","","6","","7 Jan 2013","","","IEEE","IEEE Conferences"
"Using haptics to probe human contact control strategies for six degree-of-freedom tasks","E. Klingbeil; S. Menon; K. Go; O. Khatib","Stanford University, USA; Stanford University, USA; Stanford University, USA; Stanford University, USA","2014 IEEE Haptics Symposium (HAPTICS)","20 Mar 2014","2014","","","93","95","Transferring human contact-manipulation skills to robots is complicated by the combinatorial growth in contact state descriptions with object and environment complexity, with no systematic method to characterize the subset of contact states that humans actually control. In this paper, we present an approach to determine whether human subjects control specific contact states. Subjects used a six degree-of-freedom haptic interface to place a box on a plane, and insert L- and S-shaped objects into corresponding holes, while using either their (undetermined) natural strategies or explicitly controlling a pre-specified sequence of contact states. We found that the vast majority of contact states were visited for time periods of less than 40ms, which negates the possibility of human feedback control due to physiological delay limits. Next, using force, moment and velocity trajectories around contact state transitions as a metric, we found that certain states were readily discriminable across natural and explicit control strategies (~ 85%), which indicates that they were not controlled during natural motions. Less discriminable states, in contrast, were likely to have been controlled in both natural and explicit strategies. Our results suggest that humans explicitly control a small subset of contact states, and that their control strategies are reflected in local force and velocity profiles. We thus demonstrate that six degree-of-freedom haptic simulations are effective for characterizing human contact-state invariant control strategies.","2324-7355","978-1-4799-3131-6","10.1109/HAPTICS.2014.6775438","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6775438","Perception and psychophysics;haptic;Force rendering;Virtual environment modeling;Manufacturing/assembly","Haptic interfaces;Robots;Force;Trajectory;Educational institutions;Dynamics;Rendering (computer graphics)","control engineering computing;feedback;haptic interfaces;human-robot interaction;physiology","human contact control strategies;six degree-of-freedom tasks;human contact-manipulation skills;robots;object complexity;environment complexity;L-shaped objects;S-shaped objects;human feedback control;physiological delay limits;haptic simulations;contact-state invariant control strategies","","4","","15","","20 Mar 2014","","","IEEE","IEEE Conferences"
"Real-time stereo-vision system for 3D teleimmersive collaboration","R. Vasudevan; Z. Zhou; G. Kurillo; E. Lobaton; R. Bajcsy; K. Nahrstedt","Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Laboratory of Virtual Reality Technology and Systems, Beihang University; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Laboratory of Virtual Reality Technology and Systems, Beihang University","2010 IEEE International Conference on Multimedia and Expo","23 Sep 2010","2010","","","1208","1213","Though the variety of desktop real time stereo vision systems has grown considerably in the past several years, few make any verifiable claims about the accuracy of the algorithms used to construct 3D data or describe how the data generated by such systems, which is large in size, can be effectively distributed. In this paper, we describe a system that creates an accurate (on the order of a centimeter), 3D reconstruction of an environment in real time (under 30 ms) that also allows for remote interaction between users. This paper addresses how to reconstruct, compress, and visualize the 3D environment. In contrast to most commercial desktop real time stereo vision systems our algorithm produces 3D meshes instead of dense point clouds, which we show allows for better quality visualizations. The chosen representation of the data also allows for high compression ratios for transfer to remote sites. We demonstrate the accuracy and speed of our results on a variety of benchmarks.","1945-788X","978-1-4244-7493-6","10.1109/ICME.2010.5582538","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5582538","3D video;compression;real time;teleimmersion","Three dimensional displays;Image coding;Real time systems;Accuracy;Pixel;Image reconstruction;Transform coding","data compression;data structures;data visualisation;image reconstruction;real-time systems;stereo image processing;teleconferencing;virtual reality","real-time stereo-vision system;3D teleimmersive collaboration;desktop real time stereo vision systems;3D reconstruction;remote interaction;3D environment;3D meshes;dense point clouds;quality visualizations;data representation;compression ratios","","11","","18","","23 Sep 2010","","","IEEE","IEEE Conferences"
"Source Localization in the Presence of Dispersion for Next Generation Touch Interface","A. Sulaiman; K. Poletkin; A. W. H. Khong","Sch. of Electr. & Electron. Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Electr. & Electron. Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Electr. & Electron. Eng., Nanyang Technol. Univ., Singapore, Singapore","2010 International Conference on Cyberworlds","3 Dec 2010","2010","","","82","86","We propose a new paradigm of touch interface that allows one to convert daily objects to a touch pad through the use of surface mounted sensors. To achieve a successful touch interface, localization of the finger tap is important. We present an inter-disciplinary approach to improve source localization on solids by means of a mathematical model. It utilizes mechanical vibration theories to simulate the output signals derived from sensors mounted on a physical surface. Utilizing this model, we provide an insight into how phase is distorted in vibrational waves within an aluminium plate which in turn serves as a motivation for our work. We then propose a source localization algorithm based on the phase information of the received signals. We verify the performance of our algorithm using both simulated and recorded data.","","978-1-4244-8301-3","10.1109/CW.2010.72","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5655110","time-differences-of-arrival;acoustic propagation;dispersion;phase difference","Sensors;Mathematical model;Transfer functions;Dispersion;Estimation;Aluminum;Human computer interaction","haptic interfaces;human computer interaction;surface mount technology;tactile sensors;touch sensitive screens;vibrations","next generation touch interface;surface mounted sensor;finger tap localization;interdisciplinary approach;mathematical model;mechanical vibration theory;vibrational wave;aluminium plate","","6","","10","","3 Dec 2010","","","IEEE","IEEE Conferences"
"Effect on Social Connectedness and Stress Levels by Using a Huggable Interface in Remote Communication","E. Nunez; M. Hirokawa; M. Perusquia-Hernandez; K. Suzuki","University of Tsukuba,Faculty of Engineering Information and Systems,Tsukuba,Japan; University of Tsukuba,Faculty of Engineering Information and Systems,Tsukuba,Japan; Human Information Science Laboratory, NTT Communication Science Laboratories,Atsugi,Japan; University of Tsukuba,Faculty of Engineering Information and Systems,Tsukuba,Japan","2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)","9 Dec 2019","2019","","","1","7","Affective communication technologies are designed to enhance awareness, social connectedness, and affectivity. Design strategies involve alternative methods to convey affection in computer-mediated scenarios, emphasizing on the importance of mediated physical contact. Therefore, we proposed a huggable interface to mediate social touch by sensing the user's hug gestures, transferring them to a paired device, and delivering them as simple cues. We investigated the effect of the huggable interface as a mediator with a physical embodiment and compared it with a similar communication interface represented by an agent with a virtual embodiment on a touch screen. During the experiments, we set up a scenario in which individuals with a close relationship watched movies and communicated with each other. Results showed the effect of both interfaces in terms of perceived social connectedness and stress levels. The discussion pointed out the potential and limitations of the proposed evaluation method, as well as of each type of interface as affective communication technology.","2156-8111","978-1-7281-3888-6","10.1109/ACII.2019.8925457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8925457","Computer-mediated communication;Affective technology;Intimate communication;Touch-based interaction","Stress;Skin;Robots;Motion pictures;Communications technology;Sensors;Touch sensitive screens","computer mediated communication;haptic interfaces;human computer interaction;social sciences computing;user interfaces","communication interface;perceived social connectedness;stress levels;affective communication technology;huggable interface;remote communication;computer-mediated scenarios;mediated physical contact;social touch;physical embodiment","","2","","31","","9 Dec 2019","","","IEEE","IEEE Conferences"
"Enabling virtual assembly training in and beyond the automotive industry","A. Stork; N. Sevilmis; D. Weber; D. Gorecky; C. Stahl; M. Loskyll; F. Michel","Interactive Engineering, Technologies, Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany; Interactive Engineering, Technologies, Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany; Interactive Engineering, Technologies, Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany; Innovative Factory Systems, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany; Innovative Factory Systems, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany; Innovative Factory Systems, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany; Augmented Vision, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany","2012 18th International Conference on Virtual Systems and Multimedia","3 Dec 2012","2012","","","347","352","Virtual assembly training systems show a high potential to complement or even replace physical setups for training of assembly processes in and beyond the automotive industry. The precondition for the breakthrough of virtual training is that it overcomes the problems of former approaches. The paper presents the design approach taken during the development of a game-based, virtual training system for procedural assembly knowledge in the EU-FP7 project VISTRA. One key challenge to address when developing virtual assembly training is the extensive authoring effort for setting up virtual environments. Although knowledge from the product and manufacturing design is available and could be used for virtual training, a concept for integration of this data is still missing. This paper presents the design of a platform which transfers available enterprise data into a unified model for virtual training and thus enables virtual training of workers at the assembly line before the physical prototypes exist. The data requirements and constraints stemming from industrial partners involved in the project will be discussed. A second hurdle for virtual training is the insufficient user integration and acceptance. In this context, the paper introduces an innovative hardware set-up for game-based user interaction, which has been chosen to enhance user involvement and acceptance of virtual training.","","978-1-4673-2563-9","10.1109/VSMM.2012.6365944","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365944","Data Integration;Industrial Training;PLM;User-Interaction;Virtual Reality","Training;Assembly;Data models;Solid modeling;Hardware;Production;Geometry","assembling;automobile industry;business data processing;computer based training;data integration;human factors;product design;virtual manufacturing;virtual reality","automotive industry;virtual assembly training systems;game-based virtual training system;procedural assembly knowledge;EU-FP7 project;VISTRA;virtual environments;manufacturing design;product design;data integration;enterprise data;unified model;assembly line;user integration;game-based user interaction;user involvement;user acceptance","","26","","12","","3 Dec 2012","","","IEEE","IEEE Conferences"
"Human brain-teleoperated robot between remote places","C. Escolano; J. Antelis; J. Minguez","I3A and Dpto. de Informática e Ingeniería de Sistemas, Universidad de Zaragoza, Spain; I3A and Dpto. de Informática e Ingeniería de Sistemas, Universidad de Zaragoza, Spain; I3A and Dpto. de Informática e Ingeniería de Sistemas, Universidad de Zaragoza, Spain","2009 IEEE International Conference on Robotics and Automation","6 Jul 2009","2009","","","4430","4437","This paper describes an EEG-based human brain-actuated robotic system, which allows performing navigation and visual exploration tasks between remote places via Internet, using only brain activity. In operation, two teleoperation modes can be combined: robot navigation and camera exploration. In both modes, the user faces a real-time video captured by the robot camera merged with augmented reality items. In this representation, the user concentrates on a target area to navigate to or visually explore; then, a visual stimulation process elicits the neurological phenomenon that enables the brain-computer system to decode the intentions of the user. In the navigation mode, the target destination is transferred to the autonomous navigation system, which drives the robot to the desired place while avoiding collisions with the obstacles detected by the laser scanner. In the camera mode, the camera is aligned with the target area to perform an active visual exploration of the remote scenario. In June 2008, within the framework of the experimental methodology, five healthy subjects performed pre-established navigation and visual exploration tasks for one week between two cities separated by 260 km. On the basis of the results, a technical evaluation of the device and its main functionalities is reported. The overall result is that all the subjects were able to successfully solve all the tasks reporting no failures, showing a high robustness of the system.","1050-4729","978-1-4244-2788-8","10.1109/ROBOT.2009.5152639","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5152639","","Humans;Navigation;Robot vision systems;Cameras;Internet;Brain;Augmented reality;Decoding;Laser modes;Cities and towns","augmented reality;brain-computer interfaces;collision avoidance;electroencephalography;human-robot interaction;Internet;optical scanners;telerobotics","EEG based human brain actuated robotic system;Internet;human brain teleoperated robot;robot navigation;augmented reality;visual stimulation process;autonomous navigation system;brain computer system;collision avoidance;obstacle detection;laser scanner","","20","","22","","6 Jul 2009","","","IEEE","IEEE Conferences"
"A model for sharing haptic interaction","M. Nakao; R. Kitamura; T. Sato; K. Minato","Nara Institute of Science and Technology, Nara; Nara Institute of Science and Technology, Nara; Nara Institute of Science and Technology, Nara; Nara Institute of Science and Technology, Nara","IEEE Transactions on Haptics","29 Nov 2010","2010","3","4","292","296","In this paper, we present new methods for sharing haptic interactions with other persons when touching real-world objects. Unlike the previous approaches, our system does not rely on a virtual model of the object being explored or the integration of visual/auditory modalities to augment the user's perception. We developed a prototype system that makes it possible to capture active haptic interactions on a transmitting side, and then, display them passively to a receiving side. To demonstrate the concept, we conducted human experiments using rubber samples and found that the relationship between the haptic sensations of the transmitting and receiving sides follows a power function, and the parameters of this function can be calibrated for the users of the system.","2329-4051","","10.1109/TOH.2010.35","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5520658","Haptic sharing;haptic transfer;interaction capture and presence.","Haptic interfaces;Humans;Fingers;IEEE members;Space technology;Prototypes;Auditory displays;Rubber;Pressing;Virtual reality","haptic interfaces;prototypes;rubber","haptic interaction;prototype system;rubber samples;haptic sensation;transmitting side;receiving side;power function","","6","","15","","23 Jul 2010","","","IEEE","IEEE Journals"
"Egocentric Field-of-View Localization Using First-Person Point-of-View Devices","V. Bettadapura; I. Essa; C. Pantofaru","Google Inc., Mountain View, CA, USA; Google Inc., Mountain View, CA, USA; Google Inc., Mountain View, CA, USA","2015 IEEE Winter Conference on Applications of Computer Vision","23 Feb 2015","2015","","","626","633","We present a technique that uses images, videos and sensor data taken from first-person point-of-view devices to perform egocentric field-of-view (FOV) localization. We define egocentric FOV localization as capturing the visual information from a person's field-of-view in a given environment and transferring this information onto a reference corpus of images and videos of the same space, hence determining what a person is attending to. Our method matches images and video taken from the first-person perspective with the reference corpus and refines the results using the first-person's head orientation information obtained using the device sensors. We demonstrate single and multi-user egocentric FOV localization in different indoor and outdoor environments with applications in augmented reality, event understanding and studying social interactions.","1550-5790","978-1-4799-6683-7","10.1109/WACV.2015.89","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7045943","","Videos;Cameras;Glass;Head;Painting;Google;Art","augmented reality;image matching;indoor environment;video signal processing","egocentric field-of-view localization;first-person point-of-view devices;egocentric FOV localization;visual information;image reference corpus;video reference corpus;first-person head orientation information;augmented reality;event understanding;social interactions;indoor environments;outdoor environments","","16","","32","","23 Feb 2015","","","IEEE","IEEE Conferences"
"Motion capture and classification for real-time interaction with a bipedal robot using on-body, fully wireless, motion capture specknets","D. K. Arvind; M. M. Bartosik","School of Informatics, University of Edinburgh, 10 Crichton Street, EH8 9AB, Scotland, U. K.; School of Informatics, University of Edinburgh, UK","RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication","10 Nov 2009","2009","","","1087","1092","This paper presents, to the best of our knowledge, the first instance of real-time human-robot interaction using motion capture (mocap) data obtained from fully wireless, on-body sensor networks. During the learning phase, data for motion such as waving of the hands, standing on a leg, performing sit-ups and squats is captured from a human strapped with the orient motion capture specks. Key features are extracted from the captured motion data using unsupervised learning algorithms. During subsequent interactions with the robot, the motion of the operator, speckled with orients, is classified and the robot selects to play the closest motion. This approach is particularly useful in situations where the robot operates a well defined vocabulary of motion, and the advantages are the real-time interaction and the rapidity (in a matter of minutes) in programming new behaviour compared to a heuristics-based approach. This paper compares the performances of three unsupervised learning algorithms: c-means, k-means and expectation maximisation (EM) for the four motion scenarios. Nine best candidates for the three learning algorithms for each of the four motion scenarios were selected in the Webots robot simulator and then transferred to the real robot. Metrics were defined for each motion scenario and their performances compared for the three learning algorithms. In all the cases the motions were able to be imitated; c-means was the best, followed closely by the k-means algorithms, and the reasons have been analysed.","1944-9437","978-1-4244-5081-7","10.1109/ROMAN.2009.5326151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5326151","","Wireless sensor networks;Unsupervised learning;Robot sensing systems;Leg;Humans;Feature extraction;Data mining;Vocabulary;Robot programming;Motion analysis","expectation-maximisation algorithm;feature extraction;fuzzy set theory;human-robot interaction;learning systems;legged locomotion;manipulators;motion control;pattern classification;pattern clustering;real-time systems;unsupervised learning;wireless sensor networks","bipedal robot;full on-body sensor network;wireless sensor network;real-time human-robot interaction;orient motion capture specknet;learning phase algorithm;feature extraction;unsupervised learning algorithm;pattern classification;motion vocabulary;heuristics-based approach;fuzzy c-means algorithm;k-means algorithm;expectation maximisation;Webots robot simulator;robot hands;robot arm waving;motionviewer software","","2","","16","","10 Nov 2009","","","IEEE","IEEE Conferences"
"Touchscreen Everywhere: On Transferring a Normal Planar Surface to a Touch-Sensitive Display","J. Dai; C. R. Chung","Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Vocational Training Council of Hong Kong, Wan Chai, Hong Kong","IEEE Transactions on Cybernetics","15 Jul 2014","2014","44","8","1383","1396","We address how a human-computer interface with small device size, large display, and touch-input facility can be made possible by a mere projector and camera. The realization is through the use of a properly embedded structured light sensing scheme that enables a regular light-colored table surface to serve the dual roles of both a projection screen and a touch-sensitive display surface. A random binary pattern is employed to code structured light in pixel accuracy, which is embedded into the regular projection display in a way that the user perceives only regular display but not the structured pattern hidden in the display. With the projection display on the table surface being imaged by a camera, the observed image data, plus the known projection content, can work together to probe the 3-D workspace immediately above the table surface, like deciding if there is a finger present and if the finger touches the table surface, and if so, at what position on the table surface the contact is made. All the decisions hinge upon a careful calibration of the projector-camera-table surface system, intelligent segmentation of the hand in the image data, and exploitation of the homography mapping existing between the projector's display panel and the camera's image plane. Extensive experimentation including evaluation of the display quality, hand segmentation accuracy, touch detection accuracy, trajectory tracking accuracy, multitouch capability and system efficiency are shown to illustrate the feasibility of the proposed realization.","2168-2275","","10.1109/TCYB.2013.2284512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6651770","Accuracy evaluation;hand segmentation;homography;imperceptible structured light embedding;touch detection;touch-sensitive display;Accuracy evaluation;hand segmentation;homography;imperceptible structured light embedding;touch detection;touch-sensitive display","Cameras;Arrays;Sensors;Encoding;Image segmentation;Accuracy;Computers","cameras;human computer interaction;image segmentation;touch sensitive screens;user interfaces","touchscreen;touch-sensitive display surface;human-computer interface;embedded structured light sensing scheme;light-colored table surface;projection screen;random binary pattern;projection display;3-D workspace;projector-camera-table surface system;intelligent hand segmentation;homography mapping;projector display panel;camera image plane;touch detection;trajectory tracking;multitouch capability","Algorithms;Cybernetics;Equipment Design;Fingers;Humans;Information Science;Touch;User-Computer Interface","16","","45","","1 Nov 2013","","","IEEE","IEEE Journals"
"AVATAR: Contribution to Human-Computer interaction processes through the adaptation of semi-personalized virtual agents","L. F. Guerrero-Vásquez; D. X. Landy-Rivera; J. F. Bravo-Torres; M. López-Nores; R. Castro-Serrano; P. E. Vintimilla-Tapia","Electronic Engineering, Universidad Politécnica Salesiana, Cuenca, Ecuador; Electronic Engineering, Universidad Politécnica Salesiana, Cuenca, Ecuador; Electronic Engineering, Universidad Politécnica Salesiana, Cuenca, Ecuador; AtlantTIC Research Center, University of Vigo, Vigo, España; Electronic Engineering, Universidad Politécnica Salesiana, Cuenca, Ecuador; Electronic Engineering, Universidad Politécnica Salesiana, Cuenca, Ecuador","2018 IEEE Biennial Congress of Argentina (ARGENCON)","21 Feb 2019","2018","","","1","4","In this article a process of animation of 3D models is proposed to transform them into virtual agents or avatars with the possibility of being used in Human-Computer interaction processes. The resulting virtual agents have been adapted as tools that serve as a starting point for the development of real-time interaction algorithms. The characteristics of the generated tools allows to deepen in techniques of machine learning and artificial intelligence, endowing to the virtual agents of movements with natural and real characteristics. It is possible to use them as puppets, capturing the movements of a person and transferring them to the animation; it is also possible to program specific sequences whose interaction processes are completely determined. Finally, the idea of developing algorithms involving artificial intelligence combined with human intelligence to improve interaction processes is proposed.","","978-1-5386-5032-5","10.1109/ARGENCON.2018.8646055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8646055","","Avatars;Tools;Solid modeling;Three-dimensional displays;Adaptation models;Artificial intelligence;Autism","artificial intelligence;avatars;computer animation;human computer interaction;learning (artificial intelligence);software agents;solid modelling;transforms;virtual reality","artificial intelligence;human intelligence;Human-Computer interaction processes;semipersonalized virtual agents;avatars;machine learning;3D model animation","","2","","17","","21 Feb 2019","","","IEEE","IEEE Conferences"
"Training with Virtual Operating Room Teammates to Influence Team Behaviors","B. Lok","Univ. of Florida, Gainesville, FL, USA","2016 International Conference on Collaboration Technologies and Systems (CTS)","6 Mar 2017","2016","","","615","616","Imagine you are an operating room nurse. Could training with virtual human teammates empower you to speak up to a bullying teammate? Could virtual teammates change the way you speak as to reduce errors? How about learn new patient safety policies or efficiently transfer care?In this talk, we will explore the emerging area of using virtual humans to subtly influence healthcare teams' teamwork and communication skills. This application of virtual humans could have significant patient safety impact as teamwork and communication is the top reason for adverse events in critical care areas, such as the emergency room, intensive care unit, and operating room.","","978-1-5090-2300-4","10.1109/CTS.2016.0115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7871053","","Training;Virtual reality;Teamwork;Surgery;Virtual groups;Computers","health care;human computer interaction;team working;training;virtual reality","virtual operating room teammates;team behaviors;patient safety policies;virtual humans;healthcare team teamwork;healthcare communication skills;team training","","","","5","","6 Mar 2017","","","IEEE","IEEE Conferences"
"Computer modeling for pile-soil response under the horizontal head load","Dun-hua Lu; Shu-jun Cui","Department of Resources and Environmental Engineering, Henan Institute of Engineering, Zhengzhou, 451191, China; Department of Resources and Environmental Engineering, Henan Institute of Engineering, Zhengzhou, 451191, China","2010 2nd International Conference on Computer Engineering and Technology","17 Jun 2010","2010","7","","V7-168","V7-172","Piles are widely used in foundation engineering. Much work has been done in the area of dragload on piles subjected to surcharge or consolidation of surrounding soils; much less work has been done on pile behavior under the horizontal pile head load. The writers believe that the effects of horizontal pile head load on dragload changes remain ambiguous among engineers. To obtain detailed information on the behavior, it is necessary to simulate the 3D geometry and nonlinear behavior of the soil. So in the present paper, the behavior of pile subjected to horizontal pile head load is analyzed by the three-dimensional (3D) interaction between the soil and the piles, whose result reveals the mechanism of pile with soil under the load of gravitation and load transferring mode along pile shaft for different horizontal pile head loads.","","978-1-4244-6349-7","10.1109/ICCET.2010.5485289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5485289","Computer Modeling;pile;soil;interaction;horizontal pile head load","Soil;Springs;Shafts;Solid modeling;Information geometry;Compressive stress;Structural beams;Cables;Load modeling;Skin","foundations;soil;user interfaces","computer modeling;pile-soil response;foundation engineering;horizontal pile head load;3D geometry;three-dimensional interaction;load of gravitation;load transferring mode","","","","15","","17 Jun 2010","","","IEEE","IEEE Conferences"
"PSO algorithm based thermal contact resistance estimation for variable force hand/object interaction","F. Maamir; M. Guiatni; Y. Morsly; A. Kheddar","Control Laboratory, Ecole Militaire Polytechnique, Algiers, Algeria 16111; Control Laboratory, Ecole Militaire Polytechnique, Algiers, Algeria 16111; Control Laboratory, Ecole Militaire Polytechnique, Algiers, Algeria 16111; Centre National de la Recherche Scientifique, France","22nd Mediterranean Conference on Control and Automation","20 Nov 2014","2014","","","499","504","Integrating thermal interactions in multimodal systems requires understanding both users sensory abilities and the thermal behaviors of the surrounding environment. Thermal feedback, as a part of haptic feedback can assist in object identification, or in the creation of a more complete haptic signature of a given object. However, the heat exchange occurring between a fingertip and a given touched object is affected by the contact conditions. This paper proposes a Particle Swarm Optimization (PSO) algorithm for identification of thermal contact resistance. This resistance is estimated for variable force Hand/Object Interaction using a thermal model describing the heat exchange. Experimental results validating the proposed approach are evaluated when touching real and simulated objects.","","978-1-4799-5901-3","10.1109/MED.2014.6961422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6961422","","Thermal resistance;Materials;Force;Heating;Contact resistance;Temperature measurement;Thermal sensors","haptic interfaces;heat transfer;particle swarm optimisation","PSO algorithm;thermal contact resistance estimation;variable force hand-object interaction;multimodal systems;thermal behavior;thermal feedback;haptic feedback;object identification;heat exchange;particle swarm optimization","","1","","14","","20 Nov 2014","","","IEEE","IEEE Conferences"
"An Augmented Social Interactive Learning Approach through Web2.0","L. Jin; Z. Wen","Sch. of Comput. Sci., Univ. of Westminster, London, UK; Imagination Technol. Ltd., Watford, UK","2009 33rd Annual IEEE International Computer Software and Applications Conference","22 Sep 2009","2009","1","","607","611","With the rapid development of the Internet, Web2.0 as the next generation of networking services emphasizes social interaction and share of user-generated content in a collaborative environment. It has evolved and transferred the Internet into a platform by supporting rich digital media technology for the development of innovative business and educational applications. In conjunction with Web 3D technology, social networking has already begun to foster an intuitive and immersive system that allows effective visual communication and delivers real time natural interactive experience for enhancing user motivation and engagement compared with the traditional static and text-oriented Web. This paper presents an augmented social interactive learning approach to incorporating social networking services on Web2.0 into traditional distance learning and on-site teaching for blended learning. This paper also discusses the key issues including user interaction and communication forms and examines different educational activities involving user content generation, e-tutoring, and role-playing.","0730-3157","978-0-7695-3726-9","10.1109/COMPSAC.2009.86","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5254206","Social networking;e-Learning","Social network services;IP networks;Web and internet services;Next generation networking;User-generated content;Collaboration;Educational technology;Visual communication;Real time systems;Computer aided instruction","augmented reality;computer aided instruction;distance learning;groupware;human computer interaction;human factors;social networking (online);teaching","augmented social interactive learning approach;Web2.0;Internet platform;social networking service;user-generated content sharing;collaborative environment;digital media technology;innovative business application development;innovative educational application development;3D social virtual world;immersive system;visual communication;real-time natural interactive experience;user motivation;user engagement;static text-oriented Web;distance learning;on-site teaching;blended learning;user interaction;e-tutoring;user role-playing;e-learning","","3","","17","","22 Sep 2009","","","IEEE","IEEE Conferences"
"Novel biomimetic control of a power assist robot for horizontal transfer of objects","S. M. M. Rahman; R. Ikeura; H. Yu","Dept. of Bioengineering, Faculty of Engineering, National University of Singapore, 9 Engineering Drive 1, Singapore 117576; Dept. of Mechanical Engineering, Faculty of Engineering, Mie University, Tsu, Mie 514-8507, Japan; Dept. of Bioengineering, Faculty of Engineering, National University of Singapore, 9 Engineering Drive 1, Singapore 117576","2011 IEEE International Conference on Robotics and Biomimetics","12 Apr 2012","2011","","","2181","2186","This paper presents a power assist robot system developed for manipulating objects in horizontal direction in cooperation with a human. Weight perception was included in robot dynamics and control. The robot was simulated and optimum maneuverability conditions for object manipulation in horizontal direction were determined. Psychophysical relationships between actual and perceived weights were determined, and load forces and motion features were analyzed for manipulating objects with the robot. Then, the human characteristics were used to design and implement a novel biomimetic control scheme to reduce the excessive load forces and accelerations, and thus to improve the system performances. The novel control reduced excessive load forces and accelerations, and thus improved the performances in terms of maneuverability, safety, operability etc. We compared the findings for horizontal manipulation of objects with power-assist to that for vertical lifting of objects. Finally, we proposed to use the findings to develop human-friendly power assist robots for manipulating heavy objects in industries.","","978-1-4577-2138-0","10.1109/ROBIO.2011.6181615","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6181615","","Acceleration;Force;Robots;Humans;Safety;Industries;Biomimetics","acceleration control;biomimetics;control system synthesis;human-robot interaction;industrial manipulators;lifting equipment;manipulator dynamics;motion control;occupational safety","horizontal object transfer;weight perception;robot dynamics;robot simulation;optimum maneuverability conditions;object manipulation;psychophysical relationships;motion features;excessive load force reduction;biomimetic control scheme design;system performance improvement;maneuverability;operability;safety;vertical object lifting;human-friendly power assist robots;heavy object manipulation","","3","","27","","12 Apr 2012","","","IEEE","IEEE Conferences"
"Smart Surrogate Widgets for Direct Volume Manipulation","S. Stoppel; S. Bruckner",NA; NA,"2018 IEEE Pacific Visualization Symposium (PacificVis)","28 May 2018","2018","","","36","45","Interaction is an essential aspect in volume visualization, yet common manipulation tools such as bounding boxes or clipping plane widgets provide rather crude tools as they neglect the complex structure of the underlying data. In this paper, we introduce a novel volume interaction approach based on smart widgets that are automatically placed directly into the data in a visibility-driven manner. By adapting to what the user actually sees, they act as proxies that allow for goal-oriented modifications while still providing an intuitive set of simple operations that is easy to control. In particular, our method is well-suited for direct manipulation scenarios such as touch screens, where traditional user interface elements commonly exhibit limited utility. To evaluate out approach we conducted a qualitative user study with nine participants with various backgrounds.","2165-8773","978-1-5386-1424-2","10.1109/PacificVis.2018.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8365974","[Human-centered computing]: Interaction;Interaction Design;User interface design","Data visualization;Three-dimensional displays;Shape;Tools;Transfer functions;Rendering (computer graphics);Lenses","data visualisation;user interfaces","direct volume manipulation;volume visualization;bounding boxes;clipping plane widgets;crude tools;complex structure;intuitive set;direct manipulation scenarios;qualitative user study;volume interaction approach;smart surrogate widgets","","","","36","","28 May 2018","","","IEEE","IEEE Conferences"
"Dynamic model of cable-conduit actuation for interaction with non-passive environments","A. Borowski; A. Metz; F. Sergi","Human Robotics Laboratory, Department of Biomedical Engineering, and with the Department of Mechanical Engineering. University of Delaware, Newark, DE 19713; Human Robotics Laboratory, Department of Biomedical Engineering, University of Delaware, Newark, DE 19713; Human Robotics Laboratory, Department of Biomedical Engineering, and with the Department of Mechanical Engineering. University of Delaware, Newark, DE 19713","2018 IEEE Haptics Symposium (HAPTICS)","10 May 2018","2018","","","40","45","Remote actuation is useful in human-interacting robots to reduce dynamic loading on distal joints. Cable-conduit transmissions, sometimes referred to as Bowden cable or tendon-sheath actuation, are a lightweight option for transferring power to a distal joint from a remotely located actuator. However, the nature of such transmissions causes the system to suffer from diminished efficiency and high reflected impedance as a result of distributed frictional effects between cable and conduit. A dynamic model is useful to produce controllers capable of accurately tracking force or displacement at the system's output. In this paper, we present a new computational model for cable-conduit systems that describes interaction with non-passive environments. Unlike previous models, our model features bi-directional propagation of motion within the cable-conduit system. This allows for simulation of human-interacting systems where both the human and the robot have the capability to impose motion or force. Because of this feature, the developed model is applicable to a wide range of physical systems. The model is validated in a physical prototype through experiments involving physical interaction with a human subject. We show that our model accurately predicts behaviors observed in the experimental system.","2324-7355","978-1-5386-5424-8","10.1109/HAPTICS.2018.8357150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8357150","","Mathematical model;Friction;Cable shielding;Torque;Motion segmentation;Pulleys","actuators;cables (mechanical);force control;friction;human-robot interaction;position control","human-interacting robots;remote actuation;cable-conduit actuation;physical interaction;physical systems;human-interacting systems;nonpassive environments;cable-conduit system;high reflected impedance;remotely located actuator;tendon-sheath actuation;Bowden cable;cable-conduit transmissions;distal joint;dynamic loading","","","","18","","10 May 2018","","","IEEE","IEEE Conferences"
"A case study of Jawi Editor in the XO-laptop simulated environment","K. Ismail; R. J. Raja Yusof; N. Jomhari","Faculty of Computer Science & Information Technology, University of Malaya, Malaysia; Faculty of Computer Science & Information Technology, University of Malaya, Malaysia; Faculty of Computer Science & Information Technology, University of Malaya, Malaysia","2010 International Conference on User Science and Engineering (i-USEr)","22 Feb 2011","2010","","","21","25","Jawi script is an important Malay heritage that has been in general, replaced by the Roman script. From a dominant writing in Malay world, the usage of Jawi is confined mostly in Islamic religious context nowadays. As an initiative to encourage the learning of Jawi, this research proposed a Jawi Editor running on the XO-laptop which considered as a new technology used in education, this technology introduced by One Laptop per Child (OLPC) organization. OLPC concerned of giving a laptop for every child in the developing countries to encourage them in education. XO-laptop allows collaboration and cooperation between teacher and students and between students themselves by working in groups. In this new technology of education the XO-laptop plays a main role of transferring the teacher and students roles in the class from the traditional way to the computerize technology. The aim of this research is to develop and contribute a Jawi Editor in the XO-laptop simulated environment to help the Jawi teachers and students in classes, to compile several development guidelines of Jawi-like systems in the XO-laptop simulated environment and to conduct a case study of teacher-student interaction using the Jawi Editor in the XO-laptop simulated environment.","","978-1-4244-9049-3","10.1109/IUSER.2010.5716716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5716716","Jawi;OLPC;XO-laptop;CSCW","Portable computers;Educational institutions;Writing;Collaboration;Measurement;Manuals","computer aided instruction;groupware;laptop computers","Jawi Editor;XO laptop simulated environment;Jawi script;Malay heritage;Roman script;one laptop per child organization;teacher student interaction","","1","","5","","22 Feb 2011","","","IEEE","IEEE Conferences"
