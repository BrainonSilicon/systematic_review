"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Transferring Visuomotor Learning from Simulation to the Real World for Robotics Manipulation Tasks","P. D. H. Nguyen; T. Fischer; H. J. Chang; U. Pattacini; G. Metta; Y. Demiris","Istituto Italiano di Tecnologia, Icub Facility, Genova, 16163, Italy; Imperial College, Personal Robotics Lab, London, SW7 2AZ, UK; Imperial College, Personal Robotics Lab, London, SW7 2AZ, UK; Istituto Italiano di Tecnologia, Icub Facility, Genova, 16163, Italy; Istituto Italiano di Tecnologia, Icub Facility, Genova, 16163, Italy; Imperial College, Personal Robotics Lab, London, SW7 2AZ, UK","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","6 Jan 2019","2018","","","6667","6674","Hand-eye coordination is a requirement for many manipulation tasks including grasping and reaching. However, accurate hand-eye coordination has shown to be especially difficult to achieve in complex robots like the iCub humanoid. In this work, we solve the hand-eye coordination task using a visuomotor deep neural network predictor that estimates the arm's joint configuration given a stereo image pair of the arm and the underlying head configuration. As there are various unavoidable sources of sensing error on the physical robot, we train the predictor on images obtained from simulation. The images from simulation were modified to look realistic using an image-to-image translation approach. In various experiments, we first show that the visuomotor predictor provides accurate joint estimates of the iCub's hand in simulation. We then show that the predictor can be used to obtain the systematic error of the robot's joint measurements on the physical iCub robot. We demonstrate that a calibrator can be designed to automatically compensate this error. Finally, we validate that this enables accurate reaching of objects while circumventing manual fine-calibration of the robot.","2153-0866","978-1-5386-8094-0","10.1109/IROS.2018.8594519","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594519","","Robot kinematics;Head;Task analysis;Robot sensing systems;Visualization;Manipulators","calibration;humanoid robots;learning (artificial intelligence);manipulators;motion control;neural nets;robot vision;stereo image processing","robotic manipulation tasks;physical iCub robot;joint measurements;systematic error;accurate joint estimates;visuomotor predictor;image-to-image translation approach;physical robot;sensing error;unavoidable sources;underlying head configuration;stereo image pair;visuomotor deep neural network predictor;hand-eye coordination task;iCub humanoid;complex robots;accurate hand-eye coordination;visuomotor learning","","4","","36","","6 Jan 2019","","","IEEE","IEEE Conferences"
"Affordance Learning for End-to-End Visuomotor Robot Control","A. Hämäläinen; K. Arndt; A. Ghadirzadeh; V. Kyrki","Aalto University,Espoo,Finland; Aalto University,Espoo,Finland; Aalto University,Espoo,Finland; Aalto University,Espoo,Finland","2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","28 Jan 2020","2019","","","1781","1788","Training end-to-end deep robot policies requires a lot of domain-, task-, and hardware-specific data, which is often costly to provide. In this work, we propose to tackle this issue by employing a deep neural network with a modular architecture, consisting of separate perception, policy, and trajectory parts. Each part of the system is trained fully on synthetic data or in simulation. The data is exchanged between parts of the system as low-dimensional latent representations of affordances and trajectories. The performance is then evaluated in a zero-shot transfer scenario using Franka Panda robot arm. Results demonstrate that a low-dimensional representation of scene affordances extracted from an RGB image is sufficient to successfully train manipulator policies. We also introduce a method for affordance dataset generation, which is easily generalizable to new tasks, objects and environments, and requires no manual pixel labeling.","2153-0866","978-1-7281-4004-9","10.1109/IROS40897.2019.8968596","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8968596","","","control engineering computing;learning (artificial intelligence);manipulators;neural nets","affordance learning;end-to-end visuomotor robot control;training end-to-end deep robot policies;hardware-specific data;deep neural network;trajectory parts;synthetic data;low-dimensional latent representations;zero-shot transfer scenario;Franka Panda robot arm;low-dimensional representation;scene affordances;manipulator policies;affordance dataset generation","","3","","33","","28 Jan 2020","","","IEEE","IEEE Conferences"
"Simulating closed- and open-loop voluntary movement: a nonlinear control-systems approach","P. R. Davidson; R. D. Jones; J. H. Andreae; H. R. Sirisena","Dept. of Electr. & Electron. Eng., Canterbury Univ., Christchurch, New Zealand; Dept. of Electr. & Electron. Eng., Canterbury Univ., Christchurch, New Zealand; Dept. of Electr. & Electron. Eng., Canterbury Univ., Christchurch, New Zealand; Dept. of Electr. & Electron. Eng., Canterbury Univ., Christchurch, New Zealand","IEEE Transactions on Biomedical Engineering","10 Dec 2002","2002","49","11","1242","1252","In many recent human motor control models, including feedback-error learning and adaptive model theory (AMT), feedback control is used to correct errors while an inverse model is simultaneously tuned to provide accurate feedforward control. This popular and appealing hypothesis, based on a combination of psychophysical observations and engineering considerations, predicts that once the tuning of the inverse model is complete the role of feedback control is limited to the correction of disturbances. This hypothesis was tested by looking at the open-loop behavior of the human motor system during adaptation. An experiment was carried out involving 20 normal adult subjects who learned a novel visuomotor relationship on a pursuit tracking task with a steering wheel for input. During learning, the response cursor was periodically blanked, removing all feedback about the external system (i.e., about the relationship between hand motion and response cursor motion). Open-loop behavior was not consistent with a progressive transfer from closed to open-loop control. Our recently developed computational model of the brain-a novel nonlinear implementation of AMT-was able to reproduce the observed closed- and open-loop results. In contrast, other control-systems models exhibited only minimal feedback control following adaptation, leading to incorrect open-loop behavior. This is because our model continues to use feedback to control slow movements after adaptation is complete. This behavior enhances the internal stability of the inverse model. In summary, our computational model is currently the only motor control model able to accurately simulate the closed- and open-loop characteristics of the experimental response trajectories.","1558-2531","","10.1109/TBME.2002.804601","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1046932","","Open loop systems;Feedback control;Inverse problems;Computational modeling;Humans;Motor drives;Programmable control;Adaptive control;Error correction;Psychology","physiological models;biocontrol;feedback;feedforward;transfer functions;nonlinear dynamical systems;nonlinear control systems;adaptive control;inverse problems;optimal control;neurophysiology;muscle","human motor control models;closed-loop voluntary movement;open-loop voluntary movement;nonlinear control-systems approach;feedback-error learning;adaptive model theory;feedback control;inverse model;feedforward control;psychophysical observations;adaptation;visuomotor relationship;pursuit tracking task;steering wheel input;computational model;internal stability;hybrid system;nonlinear implementation;nonlinear dynamic systems;musculoskeletal system;forward-model observer;transfer function;convergence","Adaptation, Biological;Computer Simulation;Feedback;Female;Humans;Learning;Male;Models, Biological;Movement;Muscle, Skeletal;Nonlinear Dynamics;Psychomotor Performance;Reproducibility of Results;Sensitivity and Specificity;Stochastic Processes;Vision","15","2","29","","10 Dec 2002","","","IEEE","IEEE Journals"
"An Evaluation of Inanimate and Virtual Reality Training for Psychomotor Skill Development in Robot-Assisted Minimally Invasive Surgery","G. Caccianiga; A. Mariani; E. De Momi; G. Cantarero; J. D. Brown","Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Biorobotics Institute, Scuola Superiore Sant’Anna, Pisa, Italy; Department of Electronics, Information, and Bioengineering, Politecnico di Milano, Milan, Italy; Department of Physical Medicine and Rehabilitation, Johns Hopkins Medical Institute, Baltimore, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA","IEEE Transactions on Medical Robotics and Bionics","20 May 2020","2020","2","2","118","129","Robot-assisted minimally invasive surgery (RAMIS) is gaining widespread adoption in many surgical specialties, despite the lack of a standardized training curriculum. Current training approaches rely heavily on virtual reality simulators, in particular for basic psychomotor and visuomotor skill development. It is not clear, however, whether training in virtual reality is equivalent to inanimate model training. In this manuscript, we seek to compare virtual reality training to inanimate model training, with regard to skill learning and skill transfer. Using a custom-developed needle-driving training task with inanimate and virtual analogs, we investigated the extent to which N=18 participants improved their skill on a given platform post-training, and transferred that skill to the opposite platform. Results indicate that the two approaches are not equivalent, with more salient skill transfer after inanimate training than virtual training. These findings support the claim that training with real physical models is the gold standard, and suggest more inanimate model training be incorporated into training curricula for early psychomotor skill development.","2576-3202","","10.1109/TMRB.2020.2990692","JHU internal fundings; Tesi All’estero Scholarship of Politecnico di Milano; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9080087","Automated;inanimate;minimally invasive;objective;robot-assisted;sensors;simulation;skill transfer;surgery;training;virtual reality","Training;Task analysis;Solid modeling;Robot sensing systems;Needles","computer based training;control engineering computing;medical computing;medical robotics;surgery;training;virtual reality","current training approaches;virtual reality simulators;basic psychomotor;visuomotor skill development;inanimate model training;virtual reality training;skill learning;custom-developed needle-driving training task;inanimate analogs;virtual analogs;given platform post-training;salient skill transfer;inanimate training;virtual training;training curricula;early psychomotor skill development;robot-assisted minimally invasive surgery;standardized training curriculum","","","","53","IEEE","28 Apr 2020","","","IEEE","IEEE Journals"
"Effects of 2D/3D visual feedback and visuomotor collocation on motor performance in a Virtual Peg Insertion Test","M. Fluet; O. Lambercy; R. Gassert","Rehabilitation Engineering Lab, ETH Zurich, Switzerland; Rehabilitation Engineering Lab, ETH Zurich, Switzerland; Rehabilitation Engineering Lab, ETH Zurich, Switzerland","2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society","10 Nov 2012","2012","","","4776","4779","This paper evaluates the influence of three different types of visual feedback on the motor performance of healthy subjects during the repeated execution of a Virtual Peg Insertion Test developed for the assessment of sensorimotor function of arm and hand in neurologically impaired subjects. One test trial consists of the grasping and insertion of 9 pegs into 9 holes using a haptic display with instrumented grasping handle. Three groups performed 10 trials initially on three different setups (group 1 with standard 2D visual feedback, group 2 with 3D, and group 3 with collocated 3D visual feedback) followed by 10 more trials with the setup with 2D visual feedback. The total execution time and the mean collision force as well as the time and the collision force for 6 different movement phases were compared between groups and analyzed in function of the number of repetitions. Results showed significantly lower time to approach and align the visual cursor with the peg with the 2D setup over the first 10 trials compared to the two other groups, suggesting limitations of the 3D setup. Furthermore, a significant decrease of the total execution time was found in the first 10 trials for all groups. For the 10 following trials, only group 3 showed a significant decrease in the total execution time, suggesting that the learning did not transfer to the 2D setup for this group.","1558-4615","978-1-4577-1787-1","10.1109/EMBC.2012.6347035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6347035","","Force;Visualization;Two dimensional displays;Grasping;Virtual reality;Three dimensional displays","haptic interfaces;mechanoception;neurophysiology;patient rehabilitation","2D visual feedback;3D visual feedback;visuomotor collocation;motor performance;virtual peg insertion test;sensorimotor function;arm;hand;neurologically impaired subject;grasping;haptic display;total execution time;mean collision force;visual cursor","Adult;Biofeedback, Psychology;Biofeedback, Psychology;Feedback, Sensory;Female;Humans;Imaging, Three-Dimensional;Movement;Psychomotor Performance;Reaction Time;User-Computer Interface;Young Adult","6","","10","","10 Nov 2012","","","IEEE","IEEE Conferences"
"Adaptive Curriculum Generation from Demonstrations for Sim-to-Real Visuomotor Control","L. Hermann; M. Argus; A. Eitel; A. Amiranashvili; W. Burgard; T. Brox","University of Freiburg,Germany; University of Freiburg,Germany; University of Freiburg,Germany; University of Freiburg,Germany; University of Freiburg,Germany; University of Freiburg,Germany","2020 IEEE International Conference on Robotics and Automation (ICRA)","15 Sep 2020","2020","","","6498","6505","We propose Adaptive Curriculum Generation from Demonstrations (ACGD) for reinforcement learning in the presence of sparse rewards. Rather than designing shaped reward functions, ACGD adaptively sets the appropriate task difficulty for the learner by controlling where to sample from the demonstration trajectories and which set of simulation parameters to use. We show that training vision-based control policies in simulation while gradually increasing the difficulty of the task via ACGD improves the policy transfer to the real world. The degree of domain randomization is also gradually increased through the task difficulty. We demonstrate zero-shot transfer for two real-world manipulation tasks: pick-and-stow and block stacking. A video showing the results can be found at https://lmb.informatik.uni-freiburg.de/projects/curriculum/.","2577-087X","978-1-7281-7395-5","10.1109/ICRA40945.2020.9197108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197108","","Task analysis;Training;Robots;Trajectory;Learning (artificial intelligence);Adaptation models;Stacking","computer vision;control engineering computing;learning (artificial intelligence)","shaped reward functions;ACGD;policy transfer;real-world manipulation tasks;sim-to-real visuomotor control;reinforcement learning;adaptive curriculum generation;vision-based control policies","","","","37","","15 Sep 2020","","","IEEE","IEEE Conferences"
"A Data-Efficient Framework for Training and Sim-to-Real Transfer of Navigation Policies","H. Bharadhwaj; Z. Wang; Y. Bengio; L. Paull","Department of Computer Science and Engineering, IIT Kanpur, India; Division of Engineering Science, University of Toronto, Canada; Mila, Universite de Montreal; Mila, Universite de Montreal","2019 International Conference on Robotics and Automation (ICRA)","12 Aug 2019","2019","","","782","788","Learning effective visuomotor policies for robots purely from data is challenging, but also appealing since a learning-based system should not require manual tuning or calibration. In the case of a robot operating in a real environment the training process can be costly, time-consuming, and even dangerous since failures are common at the start of training. For this reason, it is desirable to be able to leverage simulation and off-policy data to the extent possible to train the robot. In this work, we introduce a robust framework that plans in simulation and transfers well to the real environment. Our model incorporates a gradient-descent based planning module, which, given the initial image and goal image, encodes the images to a lower dimensional latent state and plans a trajectory to reach the goal. The model, consisting of the encoder and planner modules, is first trained through a meta-learning strategy in simulation. We subsequently perform adversarial domain transfer on the encoder by using a bank of unlabelled but random images from the simulation and real environments to enable the encoder to map images from the real and simulated environments to a similarly distributed latent representation. By fine tuning the entire model (encoder + planner) with only a few real world expert demonstrations, we show successful planning performances in different navigation tasks.","2577-087X","978-1-5386-6027-0","10.1109/ICRA.2019.8794310","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794310","","Robots;Data models;Planning;Task analysis;Trajectory;Training;Navigation","gradient methods;image coding;learning (artificial intelligence);mobile robots;path planning","data-efficient framework;sim-to-real transfer;navigation policies;effective visuomotor policies;learning-based system;manual tuning;robot operating;training process;leverage simulation;off-policy data;initial image;lower dimensional latent state;planner modules;meta-learning strategy;adversarial domain transfer;simulated environments;similarly distributed latent representation;fine tuning;encoder + planner;planning performances;navigation tasks;unlabelled random images","","3","","42","","12 Aug 2019","","","IEEE","IEEE Conferences"
"Enhancing Visuomotor Adaptation by Reducing Error Signals: Single-step (Aware) versus Multiple-step (Unaware) Exposure to Wedge Prisms","C. Michel; L. Pisella; C. Prablanc; G. Rode; Y. Rossetti","1INSERM U864, Espace et Action, Bron, France; Université Claude Bernard, Lyon 1; Institut Fédératif des Neurosciences de Lyon (IFNL), Lyon, France; 1INSERM U864, Espace et Action, Bron, France; Université Claude Bernard, Lyon 1; Institut Fédératif des Neurosciences de Lyon (IFNL), Lyon, France; 1INSERM U864, Espace et Action, Bron, France; Université Claude Bernard, Lyon 1; Institut Fédératif des Neurosciences de Lyon (IFNL), Lyon, France; 1INSERM U864, Espace et Action, Bron, France; Université Claude Bernard, Lyon 1; Institut Fédératif des Neurosciences de Lyon (IFNL), Lyon, France; 1INSERM U864, Espace et Action, Bron, France; Université Claude Bernard, Lyon 1; Institut Fédératif des Neurosciences de Lyon (IFNL), Lyon, France","Journal of Cognitive Neuroscience","19 May 2014","2007","19","2","341","350","Neglect patients exhibit both a lack of awareness for the spatial distortions imposed during visuomanual prism adaptation procedures, and exaggerated postadaptation negative after-effects. To better understand this unexpected adaptive capacity in brain-lesioned patients, we investigated the contribution of awareness for the optical shift to the development of prism adaptation. The lack of awareness found in neglect was simulated in a multiple-step group where healthy subjects remained unaware of the optical deviation because of its progressive stepwise increase from 2° to 10°. We contrasted this method with the classical single-step group in which subjects were aware of the visual shift because they were directly exposed to the full 10° shift. Because the number of pointing trials was identical in the two groups, the total amount of deviation exposure was 50% larger in the single-step group. Negative after-effects were examined with an open-loop pointing task performed with the adapted hand, and generalization was tested with open-loop pointing with the nonexposed hand to visual and auditory targets. The robustness of adaptation was assessed by an open-loop pointing task after a simple de-adaptation procedure. The progressive, unaware condition was associated with larger negative after-effects, transfer to the non-exposed hand for the visual and auditory pointing tasks, and greater robustness. The amount of adaptation obtained remained, nevertheless, lower than the exaggerated adaptive capacity seen in patients with neglect. Implications for the functional mechanisms and the anatomical substrates of prism adaptation are discussed.","0898-929X","","10.1162/jocn.2007.19.2.341","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6794480","","","","","","","","","","19 May 2014","","","MIT Press","MIT Press Journals"
