"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Data Acquisition for Real-Time Decision-Making under Freshness Constraints","S. Hu; S. Yao; H. Jin; Y. Zhao; Y. Hu; X. Liu; N. Naghibolhosseini; S. Li; A. Kapoor; W. Dron; L. Su; A. Bar-Noy; P. Szekely; R. Govindan; R. Hobbs; T. F. Abdelzaher",NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA,"2015 IEEE Real-Time Systems Symposium","18 Jan 2016","2015","","","185","194","The paper describes a novel algorithm for timely sensor data retrieval in resource-poor environments under freshness constraints. Consider a civil unrest, national security, or disaster management scenario, where a dynamic situation evolves and a decision-maker must decide on a course of action in view of latest data. Since the situation changes, so is the best course of action. The scenario offers two interesting constraints. First, one should be able to successfully compute the course of action within some appropriate time window, which we call the decision deadline. Second, at the time the course of action is computed, the data it is based on must be fresh (i.e., within some corresponding validity interval). We call it the freshness constraint. These constraints create an interesting novel problem of timely data retrieval. We address this problem in resource-scarce environments, where network resource limitations require that data objects (e.g., pictures and other sensor measurements pertinent to the decision) generally remain at the sources. Hence, one must decide on (i) which objects to retrieve and (ii) in what order, such that the cost of deciding on a valid course of action is minimized while meeting data freshness and decision deadline constraints. Such an algorithm is reported in this paper. The algorithm is shown in simulation to reduce the cost of data retrieval compared to a host of baselines that consider time or resource constraints. It is applied in the context of minimizing cost of finding unobstructed routes between specified locations in a disaster zone by retrieving data on the health of individual route segments.","1052-8725","978-1-4673-9507-6","10.1109/RTSS.2015.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7383576","","Roads;Decision making;Sensors;Bandwidth;Earthquakes;Real-time systems;Heuristic algorithms","data acquisition;decision making;information retrieval;minimisation;resource allocation;sensor fusion","data acquisition;decision making;data freshness constraint;decision deadline constraint;sensor data retrieval;resource-scarce environment;cost minimization","","14","","39","","18 Jan 2016","","","IEEE","IEEE Conferences"
"Computing C-space entropy for view planning based on beam sensor model","P. Wang; K. Gupta","Sch. of Eng. Sci., Simon Fraser Univ., Burnaby, BC, Canada; Sch. of Eng. Sci., Simon Fraser Univ., Burnaby, BC, Canada","IEEE/RSJ International Conference on Intelligent Robots and Systems","10 Dec 2002","2002","3","","2389","2394 vol.3","The concept of C-space entropy was recently introduced by the authors (2000, 2001), as a measure of knowledge of C-space for sensor-based path planning and exploration for general robot-sensor systems. The robot plans the next sensing action to maximally reduce the expected C-space entropy, also called the maximal expected entropy reduction, or MER criterion. The expected C-space entropy computation, however, made two idealized assumptions. The first was that the sensor field of view (FOV) is a point; and the second was that no visibility (or occlusion) constraints are taken into account, i.e., as if the obstacles are transparent. We extend the expected C-space entropy formulation where the sensor FOV is a beam and furthermore, it is subject to visibility constraints, as is the case with real range sensors. Planar simulations show that this new formulation results in more efficient exploration.","","0-7803-7398-7","10.1109/IRDS.2002.1041625","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1041625","","Entropy;Robot sensing systems;Mobile robots;Orbital robotics;Humanoid robots;Sensor systems;Path planning;Manipulators;Zinc compounds;Computational geometry","robots;path planning;entropy","C-space entropy;view planning;beam sensor model;sensor-based path planning;sensor-based exploration;expected C-space entropy reduction;maximal expected entropy reduction;MER criterion;expected C-space entropy computation;visibility constraints;occlusions;planar simulations;path planning","","8","","12","","10 Dec 2002","","","IEEE","IEEE Conferences"
"3D Shape Understanding for the Visually Impaired by using Virtual Haptic Senses based on Fuzzy Logic","H. Tatsumi; Y. Murai; M. Kobayashi; I. Sekita; M. Miyakawa","Tsukuba University of Technology,Dept. of Computer Science,Tsukuba, Ibaraki,Japan; Nihon Pharmaceutical University,Dept. of Pharmaceutical Medical Business Sciences,Bunkyo-ku, Tokyo,Japan; Tsukuba University of Technology,Dept. of Computer Science,Tsukuba, Ibaraki,Japan; Tsukuba University of Technology,Dept. of Computer Science,Tsukuba, Ibaraki,Japan; Tsukuba University of Technology,Dept. of Computer Science,Tsukuba, Ibaraki,Japan","2020 IEEE 50th International Symposium on Multiple-Valued Logic (ISMVL)","7 Jan 2021","2020","","","94","99","This research aims to provide information accessibility support for visually impaired individuals perform actions and behaviors that recognize objects by themselves or reflect their understanding of the situation in the environment. For that reason, we will develop an object recognition method to them that improves the shape understanding of target object to be recognized by touching virtual haptic senses created from the pseudo object in a computer that mimics an object in the environment. In general, the shape information of objects is difficult to verbalize. Even if its information is transformed to spoken words, it is hard to understand the shape of an object with a one-dimensional transmission through hearing. Therefore, it is necessary to expand context awareness into two- or three-dimensions while collaborating with visually impaired individuals who rely on haptic sensation. In this report, for pseudo objects created by combining 2D and 3D basic shapes in a computer, we consider the process of shape understanding and object recognition under visual impairment based on virtual haptic senses. Presentation of these pseudo objects to visually impaired individuals is provided so that they can understand by touching a two-dimensional figure with a tactile display and by feeling a three-dimensional shape with a force feedback device.","2378-2226","978-1-7281-5406-0","10.1109/ISMVL49045.2020.00-23","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9308552","visual impairment;virtual haptic sense;3D shape understanding;object recognition support;pseudo object","Shape;Haptic interfaces;Three-dimensional displays;Two dimensional displays;Thumb;Object oriented modeling;Force","force feedback;handicapped aids;haptic interfaces;object recognition;virtual reality","shape understanding;virtual haptic senses;information accessibility support;visually impaired individuals;object recognition method;target object;pseudoobject;shape information;haptic sensation;3D basic shapes;visual impairment;three-dimensional shape","","","","8","","7 Jan 2021","","","IEEE","IEEE Conferences"
"Robust Information Fusion on Social Networks","T. Chuang; K. Chen","Grad. Inst. of Commun. Eng., Nat. Taiwan Univ., Taipei, Taiwan; Grad. Inst. of Commun. Eng., Nat. Taiwan Univ., Taipei, Taiwan","2011 IEEE Global Telecommunications Conference - GLOBECOM 2011","19 Jan 2012","2011","","","1","6","This paper introduces the general framework of statistical information fusion on social network, which plays an important role on understanding the human interaction and cooperation in the society. On many existing information platforms on the social network, people's relationship affects their decision on both static and dynamic way. We consider the scenario that agents refer others decisions which are made earlier as an information for taking any action. Thus how agents on the information platform connect to each other has great impact on the information fusion. With the help of percolation theory, we provide a minimax robust decision scheme for information fusion due to often the lack of complete information of social network structure. The simulations demonstrate that our proposed information fusion rule retains fine performance compared with classical one on different network structures, and thus great potential for social network applications.","1930-529X","978-1-4244-9268-8","10.1109/GLOCOM.2011.6134403","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6134403","","Social network services;Robustness;Probability;Correlation;Network topology;IEEE Communications Society;Extraterrestrial phenomena","decision making;percolation;sensor fusion;social networking (online)","robust information fusion;social network;statistical information fusion;human interaction;society cooperation;percolation theory;minimax robust decision scheme;network structure","","","","20","","19 Jan 2012","","","IEEE","IEEE Conferences"
"A Hybrid CNN-LSTM Architecture for Path Planning of Mobile Robots in Unknow Environments","Y. Lu; W. Wang; L. Xue","Beihang University,School of Automation Science and Electrical Engineering,Beijing,China,100191; Beihang University,School of Automation Science and Electrical Engineering,Beijing,China,100191; Beijing Institute of Control Engineering,Beijing,China,100094","2020 Chinese Control And Decision Conference (CCDC)","11 Aug 2020","2020","","","4775","4779","Path planning algorithms generally require several steps including mapping, localization, sensor data processing, etc. Deep learning-based approach has been proposed to achieve end-to-end path planning, alleviating human design tasks and saving the cost of building maps. In this paper, a CNN-LSTM model which combines convolutional neural network (CNN) with Long Short-Term Memory (LSTM) is constructed to accomplish the path planning task of mobile robots. The CNN structure extracts environment features from the sensor data and calculates the proper command velocity while the LSTM module aims to learn the relationship between continuous actions and smooth the velocity of the robot. The input data of the model is acquired by a lidar, which abstracts the environment information and increases the generalization capability of different environments. In the Robot Operating System (ROS)-based simulator, the proposed model is tested in both the training map and a more complex new map. It performs well in the path planning task even in the untrained map. Compared to CNN model, the CNN-LSTM model has a great advantage in continuous planning and velocity smoothing. Furthermore, both the linear and angular velocity calculated by this model is within limited range and real time performance of this algorithm is satisfactory.","1948-9447","978-1-7281-5855-6","10.1109/CCDC49329.2020.9164775","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9164775","Path Planning;End-to-end;CNN-LSTM;Smooth Velocity","Robot sensing systems;Path planning;Training;Data models;Computational modeling;Mobile robots","control engineering computing;convolutional neural nets;learning (artificial intelligence);mobile robots;operating systems (computers);path planning;recurrent neural nets;robot programming","unknow environments;deep learning;end-to-end path planning;convolutional neural network;long short-term memory;mobile robots;environment information;generalization capability;continuous planning;velocity smoothing;hybrid CNN-LSTM architecture;robot operating system","","","","12","","11 Aug 2020","","","IEEE","IEEE Conferences"
"Combined Mining: Discovering Informative Knowledge in Complex Data","L. Cao; H. Zhang; Y. Zhao; D. Luo; C. Zhang","University of Technology, Sydney (UTS), Sydney, Australia; Centrelink, Canberra, Australia; Centrelink, Canberra, Australia; University of Technology, Sydney (UTS), Sydney, Australia; University of Technology, Sydney (UTS), Sydney, Australia","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","16 May 2011","2011","41","3","699","712","Enterprise data mining applications often involve complex data such as multiple large heterogeneous data sources, user preferences, and business impact. In such situations, a single method or one-step mining is often limited in discovering informative knowledge. It would also be very time and space consuming, if not impossible, to join relevant large data sources for mining patterns consisting of multiple aspects of information. It is crucial to develop effective approaches for mining patterns combining necessary information from multiple relevant business lines, catering for real business settings and decision-making actions rather than just providing a single line of patterns. The recent years have seen increasing efforts on mining more informative patterns, e.g., integrating frequent pattern mining with classifications to generate frequent pattern-based classifiers. Rather than presenting a specific algorithm, this paper builds on our existing works and proposes combined mining as a general approach to mining for informative patterns combining components from either multiple data sets or multiple features or by multiple methods on demand. We summarize general frameworks, paradigms, and basic processes for multifeature combined mining, multisource combined mining, and multimethod combined mining. Novel types of combined patterns, such as incremental cluster patterns, can result from such frameworks, which cannot be directly produced by the existing methods. A set of real-world case studies has been conducted to test the frameworks, with some of them briefed in this paper. They identify combined patterns for informing government debt prevention and improving government service objectives, which show the flexibility and instantiation capability of combined mining in discovering informative knowledge in complex data.","1941-0492","","10.1109/TSMCB.2010.2086060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5621927","Actionable knowledge discovery;combined mining;complex data;data mining;multiple source data mining;public service data mining","Association rules;Government;Itemsets;Measurement;Distributed databases","business data processing;data mining;decision making","informative knowledge discovery;enterprise data mining;data source;decision making;pattern based classifier;multifeature combined mining;multisource combined mining;multimethod combined mining","Algorithms;Artificial Intelligence;Computer Simulation;Data Mining;Decision Support Techniques;Models, Theoretical;Pattern Recognition, Automated","24","","31","","9 Nov 2010","","","IEEE","IEEE Journals"
"Configuration space based efficient view planning and exploration with occupancy grids","L. Torabi; M. Kazemi; K. Gupta","Robotic Algorithms &Motion Planning (RAMP) Lab, School of Engineering Science, Simon Fraser University, Burnaby, BC V5A 1S6, Canada; Robotic Algorithms &Motion Planning (RAMP) Lab, School of Engineering Science, Simon Fraser University, Burnaby, BC V5A 1S6, Canada; Robotic Algorithms &Motion Planning (RAMP) Lab, School of Engineering Science, Simon Fraser University, Burnaby, BC V5A 1S6, Canada","2007 IEEE/RSJ International Conference on Intelligent Robots and Systems","10 Dec 2007","2007","","","2827","2832","The concept of C-space entropy for sensor-based exploration and view planning for general robot-sensor systems has been introduced in [?], [?], [?], [?]. The robot plans the next sensing action (also called the next best view) to maximize the expected C-space entropy reduction, (known as Maximal expected Entropy Reduction, or MER). It gives priority to those areas that increase the maneuverable space around the robot, taking into account its physical size and shape, thereby facilitating reachability for further views. However, previous work had assumed a Poisson point process model for obstacle distribution in the physical space, a simplifying assumption. In this paper we derive an expression for MER criterion assuming an occupancy grid map, a commonly used representation for workspace representation in much of the mobile robot community. This model is easily obtained from typical range sensors such as laser range finders, stereo vision, etc., and furthermore, we can incorporate occlusion constraints and their effect in the MER formulation, making it more realistic. Simulations show that even for holonomic mobile robots with relatively simple geometric shapes (such as a rectangle), the MER criterion yields improvement in exploration efficiency (number of views needed to explore the C-space) over physical space based criteria.","2153-0866","978-1-4244-0911-2","10.1109/IROS.2007.4399451","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4399451","sensor-based path planning;occupancy grid model;C-space entropy;view planning","Robot sensing systems;Orbital robotics;Entropy;Mobile robots;Shape;Path planning;Motion planning;Intelligent robots;Laser modes;Laser theory","entropy;mobile robots;path planning;reachability analysis;sensors;stochastic processes","configuration space entropy;view planning;occupancy grids;sensor-based exploration;robot-sensor systems;maximal expected entropy reduction;reachability;Poisson point process;mobile robot","","10","","25","","10 Dec 2007","","","IEEE","IEEE Conferences"
"Reinforcement Learning-based Hierarchical Control for Path Following of a Salamander-like Robot","X. Zhang; X. Guo; Y. Fang; W. Zhu","Nankai University,College of Artificial Intelligence,Institute of Robotics and Automatic Information System,China; Nankai University,College of Artificial Intelligence,Institute of Robotics and Automatic Information System,China; Nankai University,College of Artificial Intelligence,Institute of Robotics and Automatic Information System,China; Nankai University,College of Artificial Intelligence,Institute of Robotics and Automatic Information System,China","2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","10 Feb 2021","2020","","","6077","6083","Path following is a challenging task for legged robots. In this paper, we present a hierarchical control architecture for path following of a quadruped salamander-like robot, in which, the tracking problem is decomposed into two sub-tasks: high-level policy learning based on the framework of reinforcement learning (RL) and low-level traditional controller design. More specifically, the high-level policy is learned in a physics simulator with a low-level controller designed in advance. To improve the tracking accuracy and to eliminate static errors, a soft Actor-Critic algorithm with state integral compensation is proposed. Additionally, to enhance the generalization and transferability, a compact state representation, which only contains the information of the target path and the abstract action similar to front-back and left-right, is proposed. The proposed algorithm is trained offline in the simulation environment and tested on the self-developed real quadruped salamander-like robot for different path following tasks. Simulation and experiments results validate the satisfactory performance of the proposed method.","2153-0866","978-1-7281-6212-6","10.1109/IROS45743.2020.9341656","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9341656","","Training;Target tracking;Neural networks;Reinforcement learning;Robot sensing systems;Task analysis;Robots","control engineering computing;control system synthesis;hierarchical systems;learning (artificial intelligence);legged locomotion;path planning;tracking","reinforcement learning;legged robots;hierarchical control architecture;high-level policy learning;low-level traditional controller design;physics simulator;soft actor-critic algorithm;state integral compensation;compact state representation;quadruped salamander-like robot;path following task","","","","19","","10 Feb 2021","","","IEEE","IEEE Conferences"
"Efficient touch based localization through submodularity","S. Javdani; M. Klingensmith; J. A. Bagnell; N. S. Pollard; S. S. Srinivasa","The Robotics Institute, Carnegie Mellon University, USA; The Robotics Institute, Carnegie Mellon University, USA; The Robotics Institute, Carnegie Mellon University, USA; The Robotics Institute, Carnegie Mellon University, USA; The Robotics Institute, Carnegie Mellon University, USA","2013 IEEE International Conference on Robotics and Automation","17 Oct 2013","2013","","","1828","1835","Many robotic systems deal with uncertainty by performing a sequence of information gathering actions. In this work, we focus on the problem of efficiently constructing such a sequence by drawing an explicit connection to submodularity. Ideally, we would like a method that finds the optimal sequence, taking the minimum amount of time while providing sufficient information. Finding this sequence, however, is generally intractable. As a result, many well-established methods select actions greedily. Surprisingly, this often performs well. Our work first explains this high performance - we note a commonly used metric, reduction of Shannon entropy, is submodular under certain assumptions, rendering the greedy solution comparable to the optimal plan in the offline setting. However, reacting online to observations can increase performance. Recently developed notions of adaptive submodularity provide guarantees for a greedy algorithm in this online setting. In this work, we develop new methods based on adaptive submodularity for selecting a sequence of information gathering actions online. In addition to providing guarantees, we can capitalize on submodularity to attain additional computational speedups. We demonstrate the effectiveness of these methods in simulation and on a robot.","1050-4729","978-1-4673-5643-5","10.1109/ICRA.2013.6630818","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6630818","","Uncertainty;Noise measurement;Trajectory;Robots;Entropy;Noise","entropy;greedy algorithms;mobile robots;path planning;tactile sensors","online information gathering action sequence;greedy algorithm;adaptive submodularity;offline setting;greedy solution;Shannon entropy reduction;optimal sequence;robotic systems;touch based localization","","23","","36","","17 Oct 2013","","","IEEE","IEEE Conferences"
"Robot plans execution for information gathering tasks with resources constraints","M. Wang; R. Dearden; N. Hawes","School of Computer Science, University of Birmingham, UK; Schlumberger Gould Research Center, Cambridge, UK; School of Computer Science, University of Birmingham, UK","2015 European Conference on Mobile Robots (ECMR)","12 Nov 2015","2015","","","1","6","Partially observable Markov decision processes (POMDPs) have been widely used to model real world problems because of their abilities to capture uncertainty in states, actions and observations. In robotics, there are also constraints imposed on the problems, such as time constraints or resources constraints for executing actions. In this work, we seek to address the problems of planning in the presence of both uncertainty and constraints. Constrained POMDPs extend the general POMDPs by explicitly representing constraints in the goal conditions. The method we take in this paper is to use a translation-based approach to generate an MDP policy off-line, and apply value of information calculation on-line to stochastically select the observation action by taking into account of information they gain and their resource usage. This on-line selection scheme was evaluated in a number of scenarios and simulations, and the preliminary results show that our approach can achieve better performance compared to deterministic schemes.","","978-1-4673-9163-4","10.1109/ECMR.2015.7324216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7324216","","Robots;Rocks;Uncertainty;Stochastic processes;Planning;Search problems;Time factors","decision theory;Markov processes;mobile robots;path planning","resources constraints;partially observable Markov decision processes;robot planning;translation-based approach;on-line selection scheme;deterministic schemes;constrained POMDPs;mobile robot","","","","18","","12 Nov 2015","","","IEEE","IEEE Conferences"
"V-D D3QN: the Variant of Double Deep Q-Learning Network with Dueling Architecture","Y. Huang; G. Wei; Y. Wang","School of Optical-Electrical and Computer Engineering, University of of Shanghai for Science and Technology, Shanghai, 200093, P. R. China; School of Optical-Electrical and Computer Engineering, University of of Shanghai for Science and Technology, Shanghai, 200093, P. R. China; School of Optical-Electrical and Computer Engineering, University of of Shanghai for Science and Technology, Shanghai, 200093, P. R. China","2018 37th Chinese Control Conference (CCC)","7 Oct 2018","2018","","","9130","9135","The fashionable DQN algorithm suffers from substantial overestimations of action-state value in reinforcement learning problem, such as games in the Atari 2600 domain and path planning domain. To reduce the overestimations of action values during learning, we present a novel combination of double Q-learning and dueling DQN algorithm, and design an algorithm called Variant of Double dueling DQN (V-D D3QN). We focus on the idea behind V-D D3QN algorithm and propose the feasible idea of using two dueling DQN networks to reduce the overestimations of action values during training, and the specific approach is to randomly select one dueling DQN network at each time step to update its parameters, by exploiting the remaining dueling DQN network to determine the update targets. And then we do our experiments in the customized virtual environment-gridmap. Our experiments demonstrate that our proposed algorithm not only reduces the overestimations more efficiently than Double DQN(DDQN) algorithm, but also leads to much better performance on route planning domain with great generalization ability of the new and rapidly changing environments.","1934-1768","978-988-15639-5-8","10.23919/ChiCC.2018.8483478","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8483478","Deep Reinforcement Learning;Path Planning;Overestimations;Double Q-Iearning","Training;Approximation algorithms;Planning;Neural networks;Buffer storage;Path planning;Learning (artificial intelligence)","estimation theory;learning (artificial intelligence);path planning;planning (artificial intelligence)","Double deep Q-learning network;dueling architecture;reinforcement learning problem;double Q-learning;Double dueling DQN;V-D D3QN;route planning domain;variant of double dueling DQN;DDQN algorithm;Double DQN","","","","16","","7 Oct 2018","","","IEEE","IEEE Conferences"
"Research and Application of Predictive Control Based on EMRAN in Superheated Steam Temperature Control System","X. Qiu; L. Zhang; J. Zhou; F. Si; Z. Xu","Sch. of Energy & Environ., Southeast Univ., Nanjing; Sch. of Energy & Environ., Southeast Univ., Nanjing; Sch. of Energy & Environ., Southeast Univ., Nanjing; Sch. of Energy & Environ., Southeast Univ., Nanjing; Sch. of Energy & Environ., Southeast Univ., Nanjing","2009 International Conference on Advanced Computer Control","16 Mar 2009","2009","","","742","746","The temperature of superheated steam of thermal power plants is characterized by large inertia and time delay. Its dynamic characteristics vary with the unit load. General strategy for the temperature control doesnpsilat satisfy the performance requirement. We propose a predictive control approach based on extended minimal resource allocation network to address this issue. In brief, a neural network model based on on-line identification of superheated steam temperature is proposed to predict future plant behavior. A receding horizon optimization of the predictive control is finalized with a on-line one-dimensional golden section algorithm, yielding the optimal control actions at each sampling time point. The simulation study shows the proposed control method has excellent control performance and enhanced self-adaptability, thus fits well the superheated steam temperature system.","","978-1-4244-3330-8","10.1109/ICACC.2009.71","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4777441","Thermal power engineering;Predictive control;extended minimal resource allocation network;Superheated steam temperature","Predictive control;Temperature control;Neural networks;Optimal control;Control systems;Predictive models;Power generation;Resource management;Sampling methods;Computer networks","delays;identification;neurocontrollers;optimal control;optimisation;power generation control;predictive control;resource allocation;steam power stations;temperature control","superheated steam temperature control system;predictive control;EMRAN;thermal power plants;time delay;minimal resource allocation network;neural network model;online identification;horizon optimization;online one-dimensional golden section algorithm","","","1","9","","16 Mar 2009","","","IEEE","IEEE Conferences"
"On Models for Game Input with Delay — Moving Target Selection with a Mouse","M. Claypool","Comput. Sci. & Interactive Media & Game Dev., Worcester Polytech. Inst., Worcester, MA, USA","2016 IEEE International Symposium on Multimedia (ISM)","19 Jan 2017","2016","","","575","582","Networks and local systems add delays to user actions in computer games, increasing the time between user input and rendering on the screen. Top-down studies using games have helped understand the impact of delays, but often do not generalize nor lend themselves to analytic modeling. Bottom-up studies isolating user input can better generalize and be used in models, but have yet to be applied to computer games. Our work builds a custom game for studying delay and the fundamental user input of selecting a moving target with a mouse. Analysis of data from a large user study shows target selection time is exponential with delay, and provides for an analytic model based on delay and the interaction between delay and target speed.","","978-1-5090-4571-6","10.1109/ISM.2016.0125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823692","","Delays;Games;Mice;Computers;Mathematical model;Computational modeling;Analytical models","computer games;delays;human computer interaction;mouse controllers (computers);rendering (computer graphics)","game input;moving target selection;mouse;user action delays;local systems;network systems;computer games;rendering;analytic modeling;computer games;data analysis;target selection time","","","","24","","19 Jan 2017","","","IEEE","IEEE Conferences"
"The application of cognitive artificial intelligence within C4ISR framework for national resilience","A. D. Wahyudi Sumari; A. S. Ahmad; C. Artificial","The Deputy of Political and Strategy Affairs, Secretariat General of National Resilience Council, Jalan Medan Merdeka Barat No. 15, Jakarta - 10110, Indonesia; Cognitive Artificial Intelligence Research Group (CAIRG), School of Electrical Engineering and Informatics., Institut Teknologi Bandung, Achmad Bakrie Building. 3 Floor. Jalan Ganesha No. 10, Bandung - 40132. Jawa Barat, Indonesia; Intelligence Research Group (CAIRG), School of Electrical Engineering and Informatics., Institut Teknologi Bandung, Achmad Bakrie Building. 3 Floor. Jalan Ganesha No. 10, Bandung - 40132. Jawa Barat, Indonesia","2017 Fourth Asian Conference on Defence Technology - Japan (ACDT)","18 Jan 2018","2017","","","1","8","Cognitive Artificial Intelligence (CAI) is a new perspective in Artificial Intelligence (AI) which is aimed to emulate how human brain works in generating knowledge. Human becomes intelligent because of knowledge which grows over time in his brain. With comprehensive knowledge, he can understand the world (environment) and is able to make decision and or action on it. On the other hand, strategic decision which impacts to the continuance of having a nation and having state is a critical and crucial matter, and it should be done in precise and quick manner especially in the case of contingency and faced to mutiple-data multiple-decision-alternative problems. The most precise decision has to be based on the knowledge from extracted comprehensive information. In this paper we show you the application of CAI for National Security with Knowledge-Growing System (KGS) as the engine of decision making system. We apply the CAI to a framework called Cognitive Command, Control, Communications, Computers, Intelligence, Surveillance and Reconnaissance (C4ISR) with examples taken from a simulated of real-life case in the Defense-Security domain.","","978-1-5386-2490-6","10.1109/ACDTJ.2017.8259600","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259600","A3S;C4ISR;Cognitive Artificial Intelligence;decision making;Knowledge-Growing System;National Resilience","Artificial intelligence;Resilience;Data mining;Decision making;Sensors;National security;Brain modeling","artificial intelligence;brain;cognitive systems;command and control systems;decision making;military computing;national security","CAI;National Security;Knowledge-Growing System;decision making system;Cognitive Command;cognitive artificial intelligence;C4ISR framework;KGS;Cognitive Command, Control, Communications, Computers, Intelligence, Surveillance and Reconnaissance;Defense-Security domain;extracted comprehensive information;precise decision;mutiple-data multiple-decision-alternative problems;strategic decision;comprehensive knowledge;human brain;national resilience","","","","9","","18 Jan 2018","","","IEEE","IEEE Conferences"
"A threat evaluation model for small-scale naval platforms with limited capability","M. Çöçelli; E. Arkın","Defense Systems Technologies, Aselsan A.Ş, Ankara, TURKEY; Defense Systems Technologies, Aselsan A.Ş, Ankara, TURKEY","2016 IEEE Symposium Series on Computational Intelligence (SSCI)","13 Feb 2017","2016","","","1","8","Naval command and control (C2) systems guide the operators to fulfill combat actions under time-constrained circumstances. Selecting proper targets among hundreds is an important decision making process with no compensation. Hereby, threat evaluation is a critical fusion operation to accelerate this process and increase situational awareness level in military domain services. However, combat management system could suffer from small-scale platforms supplying insufficient inputs that allow only limited foresight of common tactical picture. In this paper we present an experience on deriving threat evaluation value by pruning general approaches to meet operational needs of small-scale naval platforms along decision making process. We represent a method to obtain tactical information from only kinematics of target in two dimensional space. In the meanwhile, there is no knowledge about characteristics and identification of target which are strategically very important. Threat evaluation model is composed of the extraction of threat assessment cues, threat selection step supported by Bayesian Inference and the calculation of threat assessment rating. We have analyzed performance of proposed threat evaluation model simulating a set of synthetic scenarios and observed real-life results on functioning naval platform.","","978-1-5090-4240-1","10.1109/SSCI.2016.7850075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7850075","Threat Evaluation;Decision-Making;Situational Awareness;Information Fusion;Command and Control (C2)","Kinematics;Marine vehicles;Target tracking;Command and control systems;Sea measurements;Decision making;Atmospheric modeling","Bayes methods;command and control systems;decision making;inference mechanisms;naval engineering computing;sensor fusion","functioning naval platform;threat assessment rating;Bayesian inference;threat assessment cues;threat selection step;target characteristics;target identification;two-dimensional space;tactical information;combat management system;military domain services;situational awareness level;critical fusion operation;decision making process;limited capability;small-scale naval platforms;threat evaluation model","","1","","20","","13 Feb 2017","","","IEEE","IEEE Conferences"
"Neural Network Learning and Robust Stabilization of Nonlinear Systems With Dynamic Uncertainties","D. Wang; D. Liu; C. Mu; Y. Zhang","State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Automation, Guangdong University of Technology, Guangzhou, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Automation, Guangdong University of Technology, Guangzhou, China","IEEE Transactions on Neural Networks and Learning Systems","16 Mar 2018","2018","29","4","1342","1351","Due to the existence of dynamical uncertainties, it is important to pay attention to the robustness of nonlinear control systems, especially when designing adaptive critic control strategies. In this paper, based on the neural network learning component, the robust stabilization scheme of nonlinear systems with general uncertainties is developed. Through system transformation and employing adaptive critic technique, the approximate optimal controller of the nominal plant can be applied to accomplish robust stabilization for the original uncertain dynamics. The neural network weight vector is very convenient to initialize by virtue of the improved critic learning formulation. Under the action of the approximate optimal control law, the stability issues for the closed-loop form of nominal and uncertain plants are analyzed, respectively. Simulation illustrations via a typical nonlinear system and a practical power system are included to verify the control performance.","2162-2388","","10.1109/TNNLS.2017.2749641","National Natural Science Foundation of China; Beijing Natural Science Foundation; Early Career Development Award of SKLMCCS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8053899","Adaptive critic;dynamical uncertainty;learning systems;neural networks;optimal control;robust stabilization","Robustness;Uncertainty;Optimal control;Nonlinear systems;Cost function;Robust control;Adaptive systems","adaptive control;closed loop systems;learning systems;neurocontrollers;nonlinear control systems;optimal control;robust control;uncertain systems","neural network weight vector;improved critic learning formulation;approximate optimal control law;stability issues;nonlinear systems;dynamical uncertainties;nonlinear control systems;adaptive critic control strategies;neural network learning component;robust stabilization scheme;approximate optimal controller;original uncertain dynamics;adaptive critic technique","","21","","32","","29 Sep 2017","","","IEEE","IEEE Journals"
"A stochastic model for layered defense: Ballistic missile defense and harbor protection","B. Nguyen; H. Yip","Defence Research and Development Canada Centre for Operational Research and Analysis, Ottawa, ON; NATO, Allied Command Transformation Capability Requirements Division/CG&S, Moris, Belgium","2010 International WaterSide Security Conference","14 Mar 2011","2010","","","1","8","Asymmetrical attacks can come in multiple scenarios such as diver threats carrying improvised explosive devices to destroy critical assets, or hijacked civilian aircraft aimed to crash into critical assets in a 9-11 style approach. To defend critical assets, we need to understand the effectiveness of the defensive systems against the potential asymmetrical threats. In this paper, we propose a general methodology that characterizes a layered defense system of systems that mimics the OODA loop, i.e., a model that simulates the processes of Observation, Orientation, Decision and Action. Our model considers the capabilities of the threats such as the payload of explosives, their speeds and ranges. It also models the defensive surveillance systems such as detection and tracking performances, in addition to the capabilities of the interceptors such as speeds, weapon ranges and reaction times. The model can be used to simulate a layered defense in the sense that if a threat leaks (a leaker) through an outer defense system, it will be re-engaged by the following inner defense system if time permits. Specific applications of this model have been implemented in a number of studies of harbor protection, as well as in air defense, and even ballistic missile defense. We provide a model that integrates the defense capabilities into a globally stochastic metric called PISE (probability of integrated system effectiveness). PISE depends on a number of probabilistic parameters such as the probability of detecting and the probability of tracking a threat, the probability of neutralizing a threat given the type of weapon, and the probability of neutralization assessment. PISE is also a function of the geometry of the problem, the terrain surrounding the critical asset and the critical asset itself. This model yields a map of PISE values that allows identifying the strengths and weaknesses of the defensive systems and thereby guides the capability developers in determining solutions (Doctrine, Organization, Training, Material, Leadership, Personnel, Facilities, & Interoperability) to defend critical assets. We emphasize the fact that this paper describes a unified model that combines the underlying methodologies.","2166-1804","978-1-4244-8893-3","10.1109/WSSC.2010.5730267","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5730267","layered defense;modelling and simulation;integrated systems;barriers","Trajectory;Missiles;Sensors;Firing;Atmospheric modeling;Explosives","decision making;military systems;missiles;stochastic processes;surveillance","layered defense stochastic model;explosive devices;civilian aircraft hijacking;OODA loop;defense system of systems;defensive surveillance system;ballistic missile defense;neutralization assessment;interoperability;probability of integrated system effectiveness","","1","","17","","14 Mar 2011","","","IEEE","IEEE Conferences"
"Real-time navigation of a mobile robot using Kohonen's topology conserving neural network","I. J. Nagrath; L. Behera; K. M. Krishna; K. D. Rajasekar","Dept. of Electr. & Electron. Eng., Birla Inst. of Technol., Rajasthan, India; NA; NA; NA","1997 8th International Conference on Advanced Robotics. Proceedings. ICAR'97","6 Aug 2002","1997","","","459","464","This paper proposes a real-time sensor based navigation method using Kohonen's topology conserving network for navigation of a mobile robot in any uncertain environment. The sensory information including target location with respect to current location of the mobile robot, have been discretely conserved using a two dimensional Kohonen lattice. Reinforcement learning based on a stochastic real valued technique have been implemented to compute the action space for this Kohonen lattice. The proposed scheme learns the input and output weight space of the Kohonen lattice which is generalized to any workspace. The effectiveness of the proposed scheme has been established by simulation where the complete domain of the input-space is quantized based on experience on sensory data encountered in real-time. The input-output mapping conserved by the Kohonen lattice during simulation was used to guide a mobile robot in a real-time environment. Successful navigation of the mobile robot without further training confirms the robustness of the proposed scheme.","","0-7803-4160-0","10.1109/ICAR.1997.620222","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=620222","","Navigation;Mobile robots;Network topology;Neural networks;Path planning;Lattices;Circuit topology;Learning;Robot sensing systems;Orbital robotics","mobile robots;path planning;learning (artificial intelligence);self-organising feature maps","real-time navigation;mobile robot;Kohonen's topology conserving neural network;uncertain environment;target location;two dimensional Kohonen lattice;reinforcement learning;stochastic real valued technique;input-output mapping;real-time environment","","9","1","12","","6 Aug 2002","","","IEEE","IEEE Conferences"
"A bio-inspired geomagnetic navigation model based on course constraint strategy under anomalies field disturbing for AUV","K. Liu; M. Liu; X. Zhang; H. Li","School of Marine Science and Technology, Northwestern Polytechnical University, Xi'an, China, 710072; School of Marine Science and Technology, Northwestern Polytechnical University, Xi'an, China, 710072; School of Marine Science and Technology, Northwestern Polytechnical University, Xi'an, China, 710072; School of Marine Science and Technology, Northwestern Polytechnical University, Xi'an, China, 710072","OCEANS 2016 - Shanghai","9 Jun 2016","2016","","","1","5","The bio-inspired geomagnetic navigation is inspired from animals navigation behavior which dispense with the priori geomagnetic data. It can be employed by AUV for a navigation task that arrived to targeting point which is characterized with geomagnetic multi-parameter through magnetotaxis searching behavior. However, the geomagnetic anomalies area could form an extreme value region and disturb the magnetotaxis behavior to make AUV lost in the navigation space. This paper proposes an improved navigation model using a course constraint strategy to force AUV escaping from extreme value region. Firstly, we generalize disturbance to navigation process as a problem of population prematurity in evolution algorithm. The behavior constraints strategy is designed in order to avoid the prematurity of the population, forcing the AUV perform a specific action, expanding the scope of the exploration, thus bypass the abnormal area. Then, the statistics characteristics of magnetotaxis and convergence state of multi-objective functions are utilized to construct the trigger and termination conditions of behavioral constraints, and better historical data of magnetotaxis is taken as the constraint course. The evolution population is updated with the movement of vehicle and finally leads the vehicle to get to the destination potion. Finally, compared the present model with probability evolution strategy. The simulation results show that this method can effectively overcome the abnormal disturbance to the bio-inspired geomagnetic navigation and enhance the success rate of autonomous long-distance navigation.","","978-1-4673-9724-7","10.1109/OCEANSAP.2016.7485469","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7485469","","Navigation;Sociology;Statistics;Biological system modeling;Convergence;Geomagnetism;Animals","autonomous underwater vehicles;biomimetics;evolutionary computation;mobile robots;path planning","bio-inspired geomagnetic navigation model;course constraint strategy;anomalies field;AUV;autonomous underwater vehicles;animals navigation behavior;geomagnetic multiparameter;magnetotaxis searching behavior;extreme value region;evolution algorithm;population prematurity problem;multiobjective functions;probability evolution strategy","","2","","15","","9 Jun 2016","","","IEEE","IEEE Conferences"
"Using a model of the reachable workspace to position mobile manipulators for 3-d trajectories","F. Zacharias; W. Sepp; C. Borst; G. Hirzinger","Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany","2009 9th IEEE-RAS International Conference on Humanoid Robots","15 Jan 2010","2009","","","55","61","Humanoid robots are envisioned in general household tasks. To be able to fulfill a given task the robot needs to be equipped with knowledge concerning the manipulation and interaction in the environment and with knowledge about its own capabilities. When performing actions, e.g. opening doors or imitating human reach to grasp movements special 3-d trajectories are followed with the robot's end-effector. These trajectories can not be executed in every part of the robot's arm workspace. Therefore a task planner has to determine if and how additional degrees of freedom such as the robot's upper body or the robot's base can be moved in order to execute the task-specific trajectory. An approach is presented that computes placements for a mobile manipulator online given a task-related 3-d trajectory. A discrete representation of the robot arm's reachable workspace is used. Task-specific trajectories are interpreted as patterns and searched in the reachability model using multi-dimensional correlation. The relevance of the presented approach is demonstrated in simulated positioning tasks.","2164-0580","978-1-4244-4597-4","10.1109/ICHR.2009.5379601","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5379601","","Manipulators;Humanoid robots;Humans;Biological system modeling;Trajectory;Mobile robots;Orbital robotics;Mobile computing;Computational modeling;Navigation","end effectors;humanoid robots;mobile robots;path planning","position mobile manipulators;humanoid robots;grasp movements;robot end-effector;task-related 3d trajectory;task-specific trajectories;multidimensional correlation;simulated positioning tasks","","25","","13","","15 Jan 2010","","","IEEE","IEEE Conferences"
"Recognizing Emotions Evoked by Music Using CNN-LSTM Networks on EEG Signals","S. Sheykhivand; Z. Mousavi; T. Y. Rezaii; A. Farzamnia","Biomedical Engineering Department, Faculty of Electrical and Computer Engineering, University of Tabriz, Tabriz, Iran; Department of Mechanical Engineering, Faculty of Mechanical Engineering, University of Tabriz, Tabriz, Iran; Biomedical Engineering Department, Faculty of Electrical and Computer Engineering, University of Tabriz, Tabriz, Iran; Faculty of Engineering, Universiti Malaysia Sabah, Kota Kinabalu, Malaysia","IEEE Access","5 Aug 2020","2020","8","","139332","139345","Emotion is considered to be critical for the actual interpretation of actions and relationships. Recognizing emotions from EEG signals is also becoming an important computer-aided method for diagnosing emotional disorders in neurology and psychiatry. Another advantage of this approach is recognizing emotions without clinical and medical examination, which plays a major role in completing the Brain-Computer Interface (BCI) structure. Emotions recognition ability, without traditional utilization strategies such as self-assessment tests, is of paramount importance. EEG signals are considered the most reliable technique for emotions recognition because of the non-invasive nature. Manual analysis of EEG signals is impossible for emotions recognition, so an automatic method of EEG signals should be provided for emotions recognition. One problem with automatic emotions recognition is the extraction and selection of discriminative features that generally lead to high computational complexity. This paper was design to prepare a new approach to automatic two-stage classification (negative and positive) and three-stage classification (negative, positive, and neutral) of emotions from EEG signals. In the proposed method, directly apply the raw EEG signal to the convolutional neural network and long short-term memory network (CNN-LSTM), without involving feature extraction/selection. In prior literature, this is a challenging method. The suggested deep neural network architecture includes 10-convolutional layers with 3-LSTM layers followed by 2-fully connected layers. The LSTM network in a fusion of the CNN network has been used to increase stability and reduce oscillation. In the present research, we also recorded the EEG signals of 14 subjects with music stimulation for the process. The simulation results of the proposed algorithm for two-stage classification (negative and positive) and three-stage classification (negative, neutral and positive) of emotion for 12 active channels showed 97.42% and 96.78% accuracy and Kappa coefficient of 0.94 and 0.93 respectively. We also compared our proposed LSTM-CNN network (end-to-end) with other hand-crafted methods based on MLP and DBM classifiers and achieved promising results in comparison with similar approaches. According to the high accuracy of the proposed method, it can be used to develop the human-computer interface system.","2169-3536","","10.1109/ACCESS.2020.3011882","Research and Innovation Management Center (PPPI) and the Faculty of Engineering, Universiti Malaysia Sabah (UMS); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9148598","Emotions Recognition;CNN;LSTM;EEG","Electroencephalography;Feature extraction;Emotion recognition;Brain modeling;Music;Physiology;Multiple signal classification","brain-computer interfaces;convolutional neural nets;electroencephalography;emotion recognition;feature extraction;image classification;medical signal processing;multilayer perceptrons;music;neurophysiology;psychology;recurrent neural nets","CNN-LSTM networks;EEG signals;computer-aided method;emotional disorders;emotions recognition ability;automatic emotions recognition;convolutional neural network;long short-term memory network;deep neural network architecture;brain-computer interface structure;feature extraction;high computational complexity;two-stage classification;three-stage classification;convolutional layers;music stimulation","","1","","48","CCBY","27 Jul 2020","","","IEEE","IEEE Journals"
"DeepDriving: Learning Affordance for Direct Perception in Autonomous Driving","C. Chen; A. Seff; A. Kornhauser; J. Xiao",NA; NA; NA; NA,"2015 IEEE International Conference on Computer Vision (ICCV)","18 Feb 2016","2015","","","2722","2730","Today, there are two major paradigms for vision-based autonomous driving systems: mediated perception approaches that parse an entire scene to make a driving decision, and behavior reflex approaches that directly map an input image to a driving action by a regressor. In this paper, we propose a third paradigm: a direct perception approach to estimate the affordance for driving. We propose to map an input image to a small number of key perception indicators that directly relate to the affordance of a road/traffic state for driving. Our representation provides a set of compact yet complete descriptions of the scene to enable a simple controller to drive autonomously. Falling in between the two extremes of mediated perception and behavior reflex, we argue that our direct perception representation provides the right level of abstraction. To demonstrate this, we train a deep Convolutional Neural Network using recording from 12 hours of human driving in a video game and show that our model can work well to drive a car in a very diverse set of virtual environments. We also train a model for car distance estimation on the KITTI dataset. Results show that our direct perception approach can generalize well to real driving images. Source code and data are available on our project website.","2380-7504","978-1-4673-8391-2","10.1109/ICCV.2015.312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7410669","","Roads;Games;Automobiles;Training;Neural networks;Robots;Testing","computer games;computer vision;neural nets;road traffic;traffic engineering computing;virtual reality","KITTI dataset;car distance estimation;virtual environments;video game;convolutional neural network;direct perception representation;behavior reflex;traffic state;road state;mediated perception approaches;vision-based autonomous driving systems","","497","7","22","","18 Feb 2016","","","IEEE","IEEE Conferences"
"Optimal control of affine nonlinear discrete-time systems","T. Dierks; S. Jagannthan","Department of Electrical and Computer Engineering, Missouri University of Science and Technology, Rolla, 65409, USA; Department of Electrical and Computer Engineering, Missouri University of Science and Technology, Rolla, 65409, USA","2009 17th Mediterranean Conference on Control and Automation","14 Jul 2009","2009","","","1390","1395","In this paper, direct neural dynamic programming techniques are utilized to solve the Hamilton Jacobi-Bellman equation in real time for the optimal control of general affine nonlinear discrete-time systems. In the presence of partially unknown dynamics, the optimal regulation control problem is addressed while the optimal tracking control problem is addressed in the presence of known dynamics. Each design entails two portions: an action neural network (NN) that is designed to produce a nearly optimal control signal, and a critic NN which evaluates the performance of the system. Novel weight update laws for the critic and action NN's are derived, and all parameters are tuned online. Lyapunov techniques are used to show that all signals are uniformly ultimately bounded (UUB) and that the output of the action NN approaches the optimal control input with small bounded error. Simulation results are also presented to demonstrate the effectiveness of the approach.","","978-1-4244-4684-1","10.1109/MED.2009.5164741","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5164741","online nolinear optimal control;Hamilton Jacobi-Bellman;neural networks;adaptive critic","Optimal control;Neural networks;Control systems;Nonlinear equations;Cost function;Dynamic programming;Nonlinear control systems;Nonlinear dynamical systems;Riccati equations;Jacobian matrices","discrete time systems;dynamic programming;Jacobian matrices;neurocontrollers;nonlinear control systems;optimal control","affine nonlinear discrete-time systems;direct neural dynamic programming techniques;Hamilton Jacobi-Bellman;action neural network;optimal tracking control problem;uniformly ultimately bounded;Lyapunov techniques","","23","","10","","14 Jul 2009","","","IEEE","IEEE Conferences"
"Benchmarking End-to-End Behavioural Cloning on Video Games","A. Kanervisto; J. Pussinen; V. Hautamäki","University of Eastern Finland,School of Computing,Joensuu,Finland; University of Eastern Finland,School of Computing,Joensuu,Finland; University of Eastern Finland,School of Computing,Joensuu,Finland","2020 IEEE Conference on Games (CoG)","20 Oct 2020","2020","","","558","565","Behavioural cloning, where a computer is taught to perform a task based on demonstrations, has been successfully applied to various video games and robotics tasks, with and without reinforcement learning. This also includes end-to-end approaches, where a computer plays a video game like humans do: by looking at the image displayed on the screen, and sending keystrokes to the game. As a general approach to playing video games, this has many inviting properties: no need for specialized modifications to the game, no lengthy training sessions and the ability to re-use the same tools across different games. However, related work includes game-specific engineering to achieve the results. We take a step towards a general approach and study the general applicability of behavioural cloning on twelve video games, including six modern video games (published after 2010), by using human demonstrations as training data. Our results show that these agents cannot match humans in raw performance but do learn basic dynamics and rules. We also demonstrate how the quality of the data matters, and how recording data from humans is subject to a state-action mismatch, due to human reflexes.","2325-4289","978-1-7281-4533-4","10.1109/CoG47356.2020.9231600","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9231600","video game;behavioral cloning;imitation learning;reinforcement learning;learning environment;neural networks","Games;Cloning;Training;Task analysis;Delays;Tools;Signal resolution","computer games;human computer interaction;human factors;learning (artificial intelligence)","video game;game-specific engineering;end-to-end behavioural cloning;reinforcement learning;human demonstrations;data quality;human reflexes","","","","40","","20 Oct 2020","","","IEEE","IEEE Conferences"
"Cognitive Neural Network Driving DoF-Scalable Limbs in Time-Evolving Situations","C. C. Tapia; J. A. Villacorta-Atienza; I. Kastalskiy; S. Diez-Hermano; A. Sánchez-Jiménez; V. A. Makarov","Instituto de Matemática Interdisciplinar, Facultad de CC. Matemáticas Universidad Complutense de Madrid; Instituto de Matemática Interdisciplinar, Faculty of Biology Universidad Complutense de Madrid; Lobachevsky State University Gagarin Ave. 23, Nizhny Novgorod, 603950, Russia; Biomathematics Unit BEE Department, Faculty of Biology Universidad Complutense de Madrid; Instituto de Matemática Interdisciplinar, Faculty of Biology Universidad Complutense de Madrid; Instituto de Matemática Interdisciplinar Universidad Complutense de Madrid Av. Complutense s/n, 28040, Madrid, Spain","2018 International Joint Conference on Neural Networks (IJCNN)","14 Oct 2018","2018","","","1","7","Object handling and manipulation are vital skills for humans and autonomous humanoid robots. The fundamental bases of how our brain solves such tasks remain largely unknown. Here we develop a novel approach that addresses the problem of limb movements in time-evolving situations at an abstract cognitive level. We exploit the concept of generalized cognitive maps constructed in the so-called handspace by a neural network simulating a wave simultaneously exploring different subject actions, independently on the number of objects in the workspace. We show that the approach is scalable to limbs with minimalistic and redundant numbers of degrees of freedom (DOF). It also allows biasing the effort of reaching a target among different DOF.","2161-4407","978-1-5090-6014-6","10.1109/IJCNN.2018.8489562","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489562","","Neural networks;Wrist;Manipulators;Elbow;Task analysis;Robot sensing systems","cognitive systems;humanoid robots;neurocontrollers","manipulation;autonomous humanoid robots;limb movements;generalized cognitive maps;cognitive neural network;DoF-scalable limbs","","","","27","","14 Oct 2018","","","IEEE","IEEE Conferences"
"Quantifying Good Seamanship For Autonomous Surface Vessel Performance Evaluation","P. Stankiewicz; M. Heistand; M. Kobilarov","Johns Hopkins Applied Physics Laboratory,Laurel,MD,USA,20723; Johns Hopkins Applied Physics Laboratory,Laurel,MD,USA,20723; Johns Hopkins University,Department of Mechanical Engineering,Baltimore,MD,USA,21218","2020 IEEE International Conference on Robotics and Automation (ICRA)","15 Sep 2020","2020","","","8309","8315","The current state-of-the-art for testing and evaluation of autonomous surface vehicle (ASV) decision-making is currently limited to one-versus-one vessel interactions by determining compliance with the International Regulations for Prevention of Collisions at Sea, referred to as COLREGS. Strict measurement of COLREGS compliance, however, loses value in multi-vessel encounters, as there can be conflicting rules which make determining compliance extremely subjective. This work proposes several performance metrics to evaluate ASV decision-making based on the concept of ""good seamanship,"" a practice which generalizes to multi-vessel encounters. Methodology for quantifying good seamanship is presented based on the criteria of reducing the overall collision risk of the situation and taking early, appropriate actions. Case study simulation results are presented to showcase the seamanship performance criteria against different ASV planning strategies.","2577-087X","978-1-7281-7395-5","10.1109/ICRA40945.2020.9197572","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197572","","Marine vehicles;Safety;Geometry;Decision making;Navigation;Risk management;Planning","collision avoidance;decision making;marine safety;marine vehicles;mobile robots;remotely operated vehicles;ships","performance metrics;ASV decision-making;collision risk;ASV planning strategies;International Regulations for Prevention of Collisions at Sea;quantified good seamanship;COLREGS compliance;vessel interactions;autonomous surface vehicle decision-making;autonomous surface vessel performance evaluation;seamanship performance criteria","","","","28","","15 Sep 2020","","","IEEE","IEEE Conferences"
"Adaptive Critic Designs-based autonomous unmanned vehicles navigation: Application to robotic farm vehicles","H. D. Patino; S. Tosetti; F. Capraro","Instituto de Automatica, School of Engineering, Universidad Nacional de San Juan, (5400), Argentina; CONICET at the Instituto de Automatica, School of Engineering, Universidad Nacional de San Juan, (5400), Argentina; CONICET at the Instituto de Automatica, School of Engineering, Universidad Nacional de San Juan, (5400), Argentina","2009 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning","15 May 2009","2009","","","233","237","This paper addresses the problem of generating autonomously an optimal control action sequence for robotic autonomous unmanned vehicles based on adaptive critic designs (ACDs) for their use in autonomous agriculture vehicles, in the context of precision agriculture. The main objective is to design autonomously an optimal controller that steers the center of the vehicle through a number of waypoints in a particular order using a minimum amount of time and energy consumption. The last aspect is very important for the endurance performance in autonomous unmanned vehicles. In general, the steering of unmanned robotic vehicles depends on the interactions between the vehicle and its supporting medium. Planning for the future encounters with the waypoints should be part of the current control decision, since the vehicles position and orientation as it moves through one gate greatly alter the case of navigation through successive points. The proposed ACD-based intelligent controller learns to guide the vehicle through a set of points autonomously. The simulation results show the performance of the proposed approach for a simple case of mobile robotics.","2325-1867","978-1-4244-2761-1","10.1109/ADPRL.2009.4927550","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4927550","","Remotely operated vehicles;Mobile robots;Navigation;Optimal control;Agriculture;Programmable control;Adaptive control;Energy consumption;Current control;Intelligent robots","adaptive control;control system synthesis;electric current control;intelligent control;mobile robots;optimal control;path planning;position control;remotely operated vehicles","adaptive critic designs;autonomous unmanned vehicles navigation;robotic farm vehicles;optimal control action sequence;autonomous agriculture vehicles;time consumption;energy consumption;planning;current control decision;vehicle position;vehicle orientation;mobile robotics","","2","","14","","15 May 2009","","","IEEE","IEEE Conferences"
"Task Planning with Belief Behavior Trees","E. Safronov; M. Colledanchise; L. Natale","Istituto Italiano di Tecnologia,Genoa,Italy; Istituto Italiano di Tecnologia,Genoa,Italy; Istituto Italiano di Tecnologia,Genoa,Italy","2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","10 Feb 2021","2020","","","6870","6877","In this paper, we propose Belief Behavior Trees (BBTs), an extension to Behavior Trees (BTs) that allows to automatically create a policy that controls a robot in partially observable environments. We extend the semantic of BTs to account for the uncertainty that affects both the conditions and action nodes of the BT. The tree gets synthesized following a planning strategy for BTs proposed recently: from a set of goal conditions we iteratively select a goal and find the action, or in general the subtree, that satisfies it. Such action may have preconditions that do not hold. For those preconditions, we find an action or subtree in the same fashion. We extend this approach by including, in the planner, actions that have the purpose to reduce the uncertainty that affects the value of a condition node in the BT (for example, turning on the lights to have better lighting conditions). We demonstrate that BBTs allows task planning with non-deterministic outcomes for actions. We provide experimental validation of our approach in a real robotic scenario and - for sake of reproducibility - in a simulated one.","2153-0866","978-1-7281-6212-6","10.1109/IROS45743.2020.9341562","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9341562","","Uncertainty;Semantics;Lighting;Turning;Probabilistic logic;Planning;Task analysis","iterative methods;mobile robots;path planning;planning (artificial intelligence);trees (mathematics)","Behavior Trees;BTs;partially observable environments;planning strategy;goal conditions;condition node;lighting conditions;BBTs;task planning;belief behavior trees","","","","23","","10 Feb 2021","","","IEEE","IEEE Conferences"
"Controlling three dimensional swarms of robots","N. Michael; C. Belta; V. Kumar","GRASP Lab., Pennsylvania Univ.; NA; NA","Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.","26 Jun 2006","2006","","","964","969","We address the problem of modeling and controlling a swarm of fully actuated point-like robots in three dimensions by generalizing the planar framework from (C. Belta and V. Kumar, 2004). We define a nine-dimensional abstraction of the swarm that has a product structure of the six-dimensional Euclidean group and a three-dimensional shape, and is independent of the number of robots. The group captures the pose of an ellipsoid spanning the swarm with semiaxes given by the shape variables. The overall abstract description is invariant to robot permutations. In addition, the shape is also invariant to left actions of the group. This description allows one to define and control the behavior of the swarm at a high level, with automatic generation of individual robot control laws. We present simulation results for controlling swarms of rotorcrafts","1050-4729","0-7803-9505-0","10.1109/ROBOT.2006.1641834","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1641834","","Shape;Robot kinematics;Orbital robotics;Communication system control;Robot sensing systems;Laboratories;Systems engineering and theory;Robotics and automation;Power engineering computing;Motion planning","aerospace robotics;helicopters;mobile robots;multi-robot systems;path planning","actuated point-like robots;three dimensional robot swarm;Euclidean group;rotorcrafts;robot permutations","","18","2","20","","26 Jun 2006","","","IEEE","IEEE Conferences"
"Application of multivariable 2-DOF PID controller with neural network tuning method to the heat exchange","Kim Dong Hwa","Dept. of I&C, Taejon Nat. Univ. of Technol., South Korea","FUZZ-IEEE'99. 1999 IEEE International Fuzzy Systems. Conference Proceedings (Cat. No.99CH36315)","6 Aug 2002","1999","1","","574","578 vol.1","A heat exchange system such as the boiler of a power plant, gas turbine, and radiator require a high rate heat efficiency. But the efficiency of these systems depend on the control methods. In order to properly apply control equipment to boilers or any other heat process, it is necessary to understand the basic aspects of the process that relate control, interrelationships of the process characteristics, and the dynamics that are involved. But it is difficult to understand these complex dynamics and the tuning method of controller. Generally, PID controllers are used in these systems but they cannot be controlled because of the coupling action and disturbance in the system loop. We study an application of the multivariable 2-DOF PID controller to the fuel flow system through simulation and experiments and a backpropagation leaning algorithm of the neural network is used as it's tuning methods. The experimental results represent good responses to a change of the setpoint and have a robustness against disturbances.","1098-7584","0-7803-5406-0","10.1109/FUZZY.1999.793304","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=793304","","Three-term control;Control systems;Boilers;Power generation;Turbines;Control equipment;Temperature control;Process control;Fuels;Backpropagation","multivariable control systems;three-term control;heat exchangers;intelligent control;neurocontrollers;flow control;tuning","multivariable 2 DOF PID controller;neural network tuning;heat exchange system;high rate heat efficiency;fuel flow system;backpropagation leaning algorithm;robustness","","2","","6","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Neural network modeling and adaptive critic control of automotive fuel-injection systems","O. Kovalenko; Derong Liu; H. Javaherian","Dept. of Electr. & Comput. Eng., Illinois Univ., Chicago, IL, USA; Dept. of Electr. & Comput. Eng., Illinois Univ., Chicago, IL, USA; NA","Proceedings of the 2004 IEEE International Symposium on Intelligent Control, 2004.","31 Jan 2005","2004","","","368","373","We investigate the applications of a class of adaptive critic designs that can be classified as (model-free) action-dependent heuristic dynamic programming (ADHDP). Adaptive critic designs are defined as designs that approximate dynamic programming in the general case, i.e., approximate optimal control over time in noisy, nonlinear environment. The goals of the present learning control design for automotive engines include improved performance, reduced emissions, and maintained optimum performance under various operating conditions. Using the data obtained from a test vehicle, we first develop a neural network model of the engine. The neural network controller is then designed based on the idea of approximate dynamic programming to achieve optimal control. In the simulation studies, the initial controller is trained using the neural network engine model developed rather than the actual engine. We have developed and tested self-learning neural network controllers for both engine torque and exhaust air-fuel ratio control. The goal of the engine torque control is to track the commanded torque. The objective of the air-fuel ratio control is to regulate the engine air-fuel ratio at specified set points. For both control problems, good transient performance of the neural network controller has been observed. A distinct feature of the present technique is the controller's real-time adaptation capability which allows the neural network controller to be further refined and improved in real-time vehicle operation through continuous learning and adaptation.","2158-9860","0-7803-8635-3","10.1109/ISIC.2004.1387711","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1387711","","Neural networks;Adaptive systems;Programmable control;Adaptive control;Automotive engineering;Engines;Dynamic programming;Optimal control;Torque control;Vehicles","neurocontrollers;control system synthesis;adaptive control;automobiles;fuel systems;dynamic programming;torque control;learning systems","automotive fuel-injection systems;adaptive critic control;neural network modeling;action-dependent heuristic dynamic programming;approximate optimal control;learning control design;neural network controller;exhaust air-fuel ratio control;engine torque control","","11","","24","","31 Jan 2005","","","IEEE","IEEE Conferences"
"Development of Driving Intention Prediction System Based on Human Cognitive Mechanism","T. Sakuma; S. Miura; T. Miyashita; M. G. Fujie; S. Sugano","Faculty of Science and Engineering, Waseda University, Tokyo, 169-8555, Japan; Faculty of Science and Engineering, Waseda University, Tokyo, 169-8555, Japan; Faculty of Science and Engineering, Waseda University, Tokyo, 169-8555, Japan; Faculty of Science and Engineering, Waseda University, Tokyo, 169-8555, Japan; Faculty of Science and Engineering, Waseda University, Tokyo, 169-8555, Japan","2018 IEEE International Conference on Real-time Computing and Robotics (RCAR)","24 Jan 2019","2018","","","573","578","The advance of driving assistance technologies such as Electronic Stability Control (ESC) or auto break system, drivers are released from complicated driving tasks. On the other hand, there is concern that it reduces pleasure feelings of a driver if these system's behaviors are different from the driver's intention. To avoid such problem, it is important to evaluate the driver's intention and decision-making process, and design the assistance system to fit it. Although methods such as sensory subjective evaluation are commonly used, the human cognitive mechanism design behind them is not yet fully understood. In this paper, we introduce a novel method for evaluating driver's decision-making process based on the numerical simulation of the driver's behavior. By using this method, the assistance system can substitute the driver appropriately and driver can accept the system's maneuver because which is same as the driver's intention. As an example of this method we evaluate the relationship between decision- making timing and estimation time length of the driver's model. One possible method to simulate the driver's decision- making is machine learning. Reinforcement learning has been studied for simulating the human's brain function to learn and decide as action and state model. We used machine learning to create the reinforcement learning driver model, and a simple vehicle simulation model which are combined as a human-vehicle model. We used the simple vehicle and driver model because the aim of this research is to investigate whether the driver's decision-making process can be simulated or not. Then the model is simulated to learn to drive on a highway with 3 lanes and other vehicles. The simulated driver made some single lane change to pass a slower vehicle in front or to go out from highway at an interchange. Results showed that the decision- making timing depend on the estimation time of the reinforcement learning model. We exposed that the model behaves similar to general driver's behavior when the estimation time was settled as 7sec which is derived from human brain's cognitive mechanism. In conclusion, our simulation model based on human cognitive mechanism can simulate the driver's lane change decision- making behavior adequately.","","978-1-5386-6869-6","10.1109/RCAR.2018.8621765","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8621765","","Vehicles;Brain modeling;Task analysis;Decision making;Numerical models;Data models","cognition;decision making;driver information systems;learning (artificial intelligence);traffic engineering computing","vehicle simulation model;human cognitive mechanism;driving assistance technologies;decision-making process;intention prediction system;reinforcement learning model;human-vehicle model;machine learning","","2","","23","","24 Jan 2019","","","IEEE","IEEE Conferences"
"Local search particle filter applied to human-computer interaction","J. J. Pantrigo; A. S. Montemayor; A. Sanchez","Rey Juan Carlos Univ., Mostoles, Spain; Rey Juan Carlos Univ., Mostoles, Spain; Rey Juan Carlos Univ., Mostoles, Spain","ISPA 2005. Proceedings of the 4th International Symposium on Image and Signal Processing and Analysis, 2005.","24 Oct 2005","2005","","","279","284","This paper presents an hybridization of particle filter and local search algorithms, called local search particle filter (LSPF), and its application to human-computer interaction. The proposed algorithm combines both sequential Monte Carlo (particle filter - PF) and local search methods to achieve an accurate real-time hand tracking. The system allows to control different mouse actions through a reduced set of hand movements and gestures. Hand are segmented using a skin-color model based on explicit RGB region definition. The proposed hybrid tracking method increases the performance of general particle filter. It also improves the quality of the hand tracking task (the standard deviation between hand spatial positions for LSPF is reduced a 75% with respect to the PF algorithm). More precisely, a local search enhances a hand-simulated mouse cursor to smoothly move and thus recognize gestures for performing their associate actions.","1845-5921","953-184-089-X","10.1109/ISPA.2005.195423","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1521302","","Particle filters;Mice;Particle tracking;Computer vision;Face detection;Control systems;Humans;Motion analysis;User interfaces;Artificial intelligence","particle filtering (numerical methods);Monte Carlo methods;image segmentation;image colour analysis;human computer interaction;search problems;gesture recognition","local search particle filter;human-computer interaction;particle filter hybridization;sequential Monte Carlo methods;real-time hand tracking;image segmentation;skin-color model","","","","16","","24 Oct 2005","","","IEEE","IEEE Conferences"
"Combining motion planning and optimization for flexible robot manipulation","J. Scholz; M. Stilman","Interactive Computing, Georgia Institute of Technology, 801, Atlantic Drive, Atlanta, 30332; Interactive Computing, Georgia Institute of Technology, 801, Atlantic Drive, Atlanta, 30332","2010 10th IEEE-RAS International Conference on Humanoid Robots","13 Jan 2011","2010","","","80","85","Robots that operate in natural human environments must be capable of handling uncertain dynamics and underspecified goals. Current solutions for robot motion planning are split between graph-search methods, such as RRT and PRM which offer solutions to high-dimensional problems, and Reinforcement Learning methods, which relieve the need to specify explicit goals and action dynamics. This paper addresses the gap between these methods by presenting a task-space probabilistic planner which solves general manipulation tasks posed as optimization criteria. Our approach is validated in simulation and on a 7-DOF robot arm that executes several tabletop manipulation tasks. First, this paper formalizes the problem of planning in underspecified domains. It then describes the algorithms necessary for applying this approach to planar manipulation tasks. Finally it validates the algorithms on a series of sample tasks that have distinct objectives, multiple objects with different shapes/dynamics, and even obstacles that interfere with object motion.","2164-0580","978-1-4244-8690-8","10.1109/ICHR.2010.5686849","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5686849","","Planning;Optimization;Robot kinematics;Learning;Computational modeling;Humans","flexible manipulators;graph theory;learning (artificial intelligence);manipulator dynamics;optimisation;path planning","motion planning;optimization;flexible robot manipulation;uncertain dynamics handling;graph-search methods;RRT;PRM;reinforcement learning methods;action dynamics;task-space probabilistic planner;7-DOF robot arm","","20","","24","","13 Jan 2011","","","IEEE","IEEE Conferences"
"Learning Mobility Aid Assistance via Decoupled Observation Models","J. Poon; Y. Cui; J. V. Miro; T. Matsubara","Faculty of Engineering and IT, University of Technology, Sydney, Australia; Nara Institute of Science and Technology, Graduate School of Information Science, Japan; Faculty of Engineering and IT, University of Technology, Sydney, Australia; Nara Institute of Science and Technology, Graduate School of Information Science, Japan","2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)","20 Dec 2018","2018","","","1903","1910","This paper presents an active assistance framework for mobility systems, such as Power Mobility Devices (PMD), with the distinctive goal of being able to operate within a local moving window, as opposed to the common reliance upon persistent global environments and objectives. Demonstration data from able experts driving a simulated mobility aid in a representative indoor setting is used off-line to build behavioral models of navigation postulated separately upon user joystick inputs and on-board sensor data. These models are built respectively via Gaussian Processes for the joystick signals, and a Deep Convolutional Neural Network for the sensor data; in this case a planar LIDAR. Their combined outputs form a continuous distribution of estimated traversal likelihood within the user's immediate space, allowing for real-time stochastic optimal path planning to guide a user to its intended local destination. Moreover, the computational efficiency of the decoupled models permits rapid replanning on-the-fly for a smooth assistive action. On-line and off-line evaluations substantiate the advantages of the framework in generalising intelligent navigational assistance, of particular relevance for users who experience difficulty in safe mobility.","","978-1-5386-9582-1","10.1109/ICARCV.2018.8581375","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8581375","","Heating systems;Path planning;Data models;Training data;Laser radar;Training;Gaussian processes","control engineering computing;convolution;feedforward neural nets;Gaussian processes;handicapped aids;interactive devices;mobile robots;optical radar;optimisation;path planning","behavioral models;user joystick inputs;on-board sensor data;Gaussian Processes;joystick signals;planar LIDAR;decoupled observation models;active assistance framework;PMD;local moving window;deep convolutional neural network;power mobility devices;mobility aid assistance;intelligent navigational assistance;stochastic optimal path;traversal likelihood estimation","","","","26","","20 Dec 2018","","","IEEE","IEEE Conferences"
"A new way of understanding position error in wheeled mobile robots control problem","S. Pan; J. Dai","Department of Electronic Engineering, Tsinghua Uni-versity, Beijing 100084, China; Department of Electrical Engineering, University of Notre Dame, Notre Dame, IN 46556, USA","2013 10th IEEE International Conference on Control and Automation (ICCA)","22 Jul 2013","2013","","","1471","1478","The problem of path-tracking of wheeled mobile robot (WMR) has been well studied and many algorithms have been presented to solve the problem. However, most of the existed methods are based on Lyapunov function while few works have been done on error analysis of the control law caused by imperfect conditions, especially by inaccurate controlling. In this paper, a discrete-time system model is established to obtain both theoretical and simulative results of a ground robot's position error caused by inaccurate control actions. We provide a general framework to analyze the problem, which enables other position error calculations adopting similar method. As indicated by the experimental results on Pioneer-3DX robots, the theoretical work is valid.","1948-3457","978-1-4673-4708-2","10.1109/ICCA.2013.6564899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6564899","","Mathematical model;Wheels;Robots;Equations;Lyapunov methods;Analytical models;Differential equations","discrete time systems;mobile robots;path planning;robust control","wheeled mobile robot control problem;path-tracking problem;WMR;discrete-time system model;ground robot position error calculation;Pioneer-3DX robots","","","","9","","22 Jul 2013","","","IEEE","IEEE Conferences"
"Distributed Nash equilibrium seeking by gossip in games on graphs","F. Salehisadaghiani; L. Pavel","Department of Electrical and Computer Engineering, University of Toronto, ON M5S 3G4, Canada; Department of Electrical and Computer Engineering, University of Toronto, ON M5S 3G4, Canada","2016 IEEE 55th Conference on Decision and Control (CDC)","29 Dec 2016","2016","","","6111","6116","We consider a gossip approach for finding a Nash equilibrium in a distributed multi-player network game. We extend previous results on Nash equilibrium seeking to the case when the players' cost functions may be affected by the actions of any subset of players. An interference graph is employed to illustrate the partially-coupled cost functions and the asymmetric information requirements. For a given interference graph, we design a generalized communication graph so that players with possibly partially-coupled cost functions exchange only their required information and make decisions based on them. Using a set of standard assumptions on the cost functions, interference and communication graphs, we prove almost sure convergence to a Nash equilibrium for diminishing step sizes. We then quantify the effect of the second largest eigenvalue of the expected communication matrix on the convergence rate, and illustrate the trade-off between the parameters associated with the communication and the interference graphs. Finally, the efficacy of the proposed algorithm on a large-scale networked game is demonstrated via simulation.","","978-1-5090-1837-6","10.1109/CDC.2016.7799208","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7799208","","Games;Cost function;Nash equilibrium;Interference;Convergence;Optical transmitters;Signal to noise ratio","decision making;eigenvalues and eigenfunctions;game theory;graph theory;matrix algebra;network theory (graphs)","distributed Nash equilibrium;gossip approach;distributed multiplayer network game;player cost functions;interference graph;partially-coupled cost functions;asymmetric information requirements;generalized communication graph;decision making;eigenvalues;communication matrix;convergence rate","","4","","23","","29 Dec 2016","","","IEEE","IEEE Conferences"
"Computing C-space entropy for view planning with a generic range sensor model","Pengpeng Wang; K. Gupta","Sch. of Eng. Sci., Simon Fraser Univ., Burnaby, BC, Canada; Sch. of Eng. Sci., Simon Fraser Univ., Burnaby, BC, Canada","2003 IEEE International Conference on Robotics and Automation (Cat. No.03CH37422)","10 Nov 2003","2003","2","","2406","2411 vol.2","We have recently introduced the concept of C-space entropy as a measure of knowledge of C-space for sensor-based path planning and exploration for general robot-sensor systems. The robot plans the next sensing action to maximally reduce the expected C-space entropy, also called the maximal expected entropy reduction, or MER criterion. The expected C-space entropy computation, however, made two idealized assumptions. The first was that the sensor field of view (FOV) is a point; and the second was that no occlusion (or visibility) constraints are taken into account, i.e., as if the obstacles are transparent. We extend the expected C-space entropy formulation where these two assumptions are relaxed, and consider a generic range sensor with non-zero volume FOV and occlusion constraints, thereby modelling a real range sensor. Planar simulations show that: (1) MER criterion results in significantly more efficient exploration than the naive physical space based criterion (such as maximize the unknown physical space volume), and (2) the new formulation with non-zero volume FOV results in further improvement over the point FOV based MER formulation. Preliminary experiments with the SFU eye-in-hand system, a PUMA 560 equipped with a wrist mounted range scanner corroborate the simulation results, however, for lack of space they are not reported here.","1050-4729","0-7803-7736-2","10.1109/ROBOT.2003.1241953","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1241953","","Entropy;Robot sensing systems;Orbital robotics;Mobile robots;Path planning;Sensor systems;Humanoid robots;Wrist;Knowledge engineering;Extraterrestrial measurements","mobile robots;path planning;robot vision;image sensors;maximum entropy methods","C-space entropy computation;robot view planning;generic range sensor model;sensor-based path planning;robot sensor systems;maximal expected entropy reduction;sensor field-of-view;occlusion constraints;real range sensor model;planar simulations;naive physical space criterion;eye-in-hand system;wrist mounted range scanner","","1","","15","","10 Nov 2003","","","IEEE","IEEE Conferences"
"Uncertain decision-making analysis method based on information entropy principles","J. Jin; R. Shen; M. Zhang; C. Zhou; Z. Pan","Chengdu Institute of Plateau Meteorology, CMA, 610072, China; School of Civil Engineering, Hefei University of Technology, 230009, China; College of Hydrology and Water Resources, Hohai University, Nanjing 210098, China; School of Civil Engineering, Hefei University of Technology, 230009, China; School of Natural Resources and Environmental Engineering, Hefei University of Technology, 230009, China","2009 Chinese Control and Decision Conference","7 Aug 2009","2009","","","2241","2246","Benefit and loss matrix of uncertain decision-making analysis reflects both the objective information structure of uncertain decision-making problem and the risk information of benefit chance and loss chance faced by decision-maker. The transform vector consisted of the natural state weights is quantitative expression of uncertain decision-making rule adopted by decision-maker. The essential for resolving uncertain decision-making problem is how to transform benefit and loss matrix into compressed real vector with one dimension, where the biggest weight of the vector corresponds to the best action scheme. Now the information of benefit and loss matrix has been not mined sufficiently using the common methods for uncertain decision-making problems. Therefore in this paper, the whole difference weights of the natural states can be determined using projection pursuit method, the local difference weights of the natural states can be determined directly using information entropy and accelerating genetic algorithm based fuzzy analytic hierarchy process, and the two kinds of weights can be combined into comprehensive weights according to the minimum relative information entropy principle, which can form a new uncertain decision-making analysis method based on information entropy principles, named UDM-IEP for short. The application result show that the information of benefit and loss matrix can be mined more sufficiently using UDM-IEP than the common methods, that the decision-making information can be more provided by UDM-IEP than the common methods, that decision-maker can actively or safely choose the best scheme based on the comparison between of benefit chance risk and loss chance risk contained in the benefit and loss matrix, that UDM-IEP is both simple and general, that its computation result is objective and stability, and that UDM-IEP can be widely applied in theory and practice of systems engineering.","1948-9447","978-1-4244-2722-2","10.1109/CCDC.2009.5192192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5192192","uncertain decision-making analysis method;benefit and loss matrix;information entropy principle;combination weight;projection pursuit;fuzzy analytic hierarchy process;genetic algorithm","Decision making;Information analysis;Information entropy;Decision support systems;Virtual reality","decision making;decision theory;entropy;fuzzy set theory;genetic algorithms","uncertain decision-making analysis method;objective information structure;transform vector;natural state weight;compressed real vector;benefit matrix;loss matrix;projection pursuit method;genetic algorithm;fuzzy analytic hierarchy process;minimum relative information entropy principle;UDM-IEP;decision-maker;benefit chance risk;loss chance risk","","2","","16","","7 Aug 2009","","","IEEE","IEEE Conferences"
"Analyzing Knowledge Codification for Planning Military Operations","L. Ouriques; C. E. Barbosa; G. Xexéo; J. d. Souza","Programa de Engenharia de Sistemas e Computação, COPPE/UFRJ,Brazil; Programa de Engenharia de Sistemas e Computação, COPPE/UFRJ,Brazil; Programa de Engenharia de Sistemas e Computação, COPPE/UFRJ,Brazil; Programa de Engenharia de Sistemas e Computação, COPPE/UFRJ,Brazil","2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)","28 Nov 2019","2019","","","2620","2625","The Joint Planning Process of the Brazilian Ministry of Defense comprises the elaboration of possible courses of action (COA) to be adopted in a joint operation. The Commander, advised by his General Staff, assesses each COA and selects subjectively the one that best meets the mission statement. Such decision-making process has no simulation tool to assist the Commander and his General Staff in confronting their own COA with possible enemy COAs. We analyzed how the Brazilian Ministry of Defense (MD) codifies knowledge in such simulated confrontation, their structures and the knowledge flow. Starting with the information from MD doctrines, we structured the explicit knowledge in models and diagrams, which describe business processes, taxonomies, conceptual maps, and mental maps. Understanding the knowledge creation process increases the efficiency of an operation, while reduces confrontation errors, minimizing revision efforts and optimizing the use of the operational capabilities of the Armed Forces.","2577-1655","978-1-7281-4569-3","10.1109/SMC.2019.8914150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8914150","knowledge management;knowledge codification;knowledge combination;military operation planning","Planning;Military aircraft;Organizations;Force;Unified modeling language;Taxonomy;Decision making","decision making;knowledge management;military computing","COA;decision-making process;business processes;knowledge creation process;knowledge codification;military operations planning;joint planning process;courses of action;Brazilian Ministry of Defense;armed forces","","","","29","","28 Nov 2019","","","IEEE","IEEE Conferences"
"Reinforcement Learning based Decoding Using Internal Reward for Time Delayed Task in Brain Machine Interfaces","X. Shen; X. Zhang; Y. Huang; S. Chen; Y. Wang","Hong Kong University of Science and Technology,Department of Electronic and Computer Engineering,Hong Kong; Department of Electronic and Computer Engineering; Department of Electronic and Computer Engineering; Hong Kong University of Science and Technology,Department of Electronic and Computer Engineering,Hong Kong; Department of Electronic and Computer Engineering","2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)","27 Aug 2020","2020","","","3351","3354","Reinforcement learning (RL) algorithm interprets neural signals into movement intentions with the guidance of the reward in Brain-machine interfaces (BMIs). Current RL algorithms generally work for the tasks with immediate rewards delivery, and lack of efficiency in delayed reward task. Prefrontal cortex, including medial prefrontal cortex(mPFC), has been demonstrated to assign credit to intermediate steps, which reinforces preceding action more efficiently. In this paper, we propose to simulate the functionality of mPFC activities as intermediate rewards to train a RL based decoder in a two-step movement task. A support vector machine (SVM) is adopted to verify if the subject expects a reward due to the accomplishment of a subtask from mPFC activity. Then this discrimination result will be utilized to guide the training of the RL decoder for each step respectively. Here, we apply the Sarsa-style attention-gated reinforcement learning (SAGREL) as the decoder to interpret motor cortex(M1) activity to action states. We test on in vivo primary motor cortex (M1) and mPFC data collected from rats, where the rats need to first trigger the start and then press lever for rewards using M1 signals. SAGREL using intermediate rewards from mPFC activities achieves a prediction accuracy of 66.8% ± 2.0.% (mean ± std) %, which is significantly better than the one using the reward by the end of trial (45.9.% ± 1.2%). This reveals the potentials of modelling mPFC activities as intermediate rewards for the delayed reward tasks.","2694-0604","978-1-7281-1990-8","10.1109/EMBC44109.2020.9175964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9175964","","Task analysis;Decoding;Rats;Support vector machines;Presses;Firing;Learning (artificial intelligence)","brain-computer interfaces;electroencephalography;learning (artificial intelligence);medical signal processing;neurophysiology;support vector machines","movement intentions;brain-machine interfaces;delayed reward task;mPFC activity;intermediate rewards;RL based decoder;two-step movement task;support vector machine;Sarsa-style attention-gated reinforcement learning;internal reward;time delayed task;in vivo primary motor cortex","Animals;Brain-Computer Interfaces;Learning;Prefrontal Cortex;Rats;Reinforcement, Psychology;Reward","","","14","","27 Aug 2020","","","IEEE","IEEE Conferences"
"Complex-valued computational model of hippocampal CA3 recurrent collaterals","A. S. Shiva; M. Gogate; N. Howard; B. Graham; A. Hussain","Department of Computing Science & Mathematics, School of Natural Science, University of Stirling, Stirling, FK9 4LA; Department of Computing Science & Mathematics, School of Natural Science, University of Stirling, Stirling, FK9 4LA; Computational Neuroscience Lab, Nuffield Department of Surgical Sciences, University of Oxford, UK; Department of Computing Science & Mathematics, School of Natural Science, University of Stirling, Stirling, FK9 4LA; Department of Computing Science & Mathematics, School of Natural Science, University of Stirling, Stirling, FK9 4LA","2017 IEEE 16th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC)","16 Nov 2017","2017","","","161","166","Complex planes are known to simplify the complexity of real world problems, providing a better comprehension of their functionality and design. The need for complex numbers in both artificial and biological neural networks is equally well established. In the latter, complex numbers allows neuroscientists to consider and analyze the phase component of brain oscillations occurring during chains of action potentials. This paper implements complex-valued weights and inputs in the real valued recurrent collaterals model introduced by Káli & Dayan for the CA3 region of the hippocampus, with equations appropriately modified to include the phase component. Complex models can generally be implemented by solving the real and complex parts separately resulting from solving the model equations twice. This implementation is simulated here and the results demonstrate the model's potential utility for further mathematical and neurobiological analysis to define a proper phase function which oscillates in the theta frequency range.","","978-1-5386-0771-8","10.1109/ICCI-CC.2017.8109745","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8109745","Hippocampus;CA3;theta oscillation;complex-valued;recurrent collaterals","Mathematical model;Oscillators;Brain modeling;Complexity theory;Biological neural networks;Biological system modeling","brain;brain models;neural nets;neurophysiology;recurrent neural nets","theta frequency range;neurobiological analysis;recurrent collaterals model;complex-valued computational model;phase function;model equations;complex models;phase component;biological neural networks;artificial networks;complex numbers;design;functionality;world problems;complex planes;hippocampal CA3 recurrent collaterals","","1","","20","","16 Nov 2017","","","IEEE","IEEE Conferences"
"Neural network-based optimal control for autonomous mobile vehicle navigation","H. D. Patino; R. Carelli","Fac. de Ingenieria, Univ. Nat. de San Juan, Argentina; Fac. de Ingenieria, Univ. Nat. de San Juan, Argentina","Proceedings of the 2004 IEEE International Symposium on Intelligent Control, 2004.","31 Jan 2005","2004","","","391","396","This work addresses the problem of generating autonomously an optimal control action sequence for an autonomous vehicle based on artificial neural networks (ANN). The principal objective is to autonomously design an optimal controller that steers the center of the vehicle through a number of via points in a particular order using a minimum amount of time. In general, the steering of robotic vehicles depends on the interactions between the vehicle and its supporting medium. Planning for the future encounters with the via points should be part of the current control decision, since the vehicle's position and orientation as it moves through one gate greatly alter the case of navigation through successive points. The proposed neural network-based intelligent controller learns to guide the vehicle through a set of points autonomously. The simulation results show the performance of the proposed approach for a simple case.","2158-9860","0-7803-8635-3","10.1109/ISIC.2004.1387715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1387715","","Neural networks;Optimal control;Remotely operated vehicles;Mobile robots;Navigation;Angular velocity;Robot kinematics;Control systems;Vehicle dynamics;Cost function","control system synthesis;neurocontrollers;remotely operated vehicles;optimal control;learning systems;adaptive control;dynamic programming;navigation;mobile robots","autonomous mobile vehicle navigation;optimal control;artificial neural networks;learning control;steering;neural network-based intelligent controller;dynamic programming","","","","20","","31 Jan 2005","","","IEEE","IEEE Conferences"
"Path-planning in Discretized Environments with Optimized Waypoints Computation","E. Vitolo; C. Mahulea; M. Kloetzer","Aragón Institute for Engineering Research (I3A), University of Zaragoza, Spain; Aragón Institute for Engineering Research (I3A), University of Zaragoza, Spain; Dept. of Automatic Control and Applied Informatics, Technical University of Iasi, Romania","2018 IEEE 23rd International Conference on Emerging Technologies and Factory Automation (ETFA)","25 Oct 2018","2018","1","","729","735","This paper considers the path-planning problem in discretized environments, obtained for example by a cell decomposition approach. The specification for the mobile robot can be the classical navigation problem (reach a given region by avoiding the obstacles) or a high-level specification as a Boolean and/or temporal logic formula. We propose a general methodology to compute piecewise linear trajectories consisting in a sequence of intermediate points (waypoints). The waypoints are computed by solving optimization problems whose solutions permit to optimally select the intermediate points on the common facets of traversed cells from the decomposition. The proposed solution is similar to a Model Predictive Control (MPC) strategy, in each step an optimization problem is solved over a finite horizon, the first action is considered and the problem is iterated. The method developed in this paper has been implemented and integrated in Robot Motion Toolbox allowing a comparison with other methods by simulation.","1946-0759","978-1-5386-7108-5","10.1109/ETFA.2018.8502504","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502504","","Cost function;Trajectory;Euclidean distance;Mobile robots;Electronic mail","mobile robots;optimisation;path planning;piecewise linear techniques","discretized environments;cell decomposition approach;mobile robot;high-level specification;temporal logic formula;piecewise linear trajectories;optimization problem;Robot Motion Toolbox;optimized waypoints computation;path-planning problem;navigation problem;optimization problems","","1","","27","","25 Oct 2018","","","IEEE","IEEE Conferences"
"LyRN (Lyapunov Reaching Network): A Real-Time Closed Loop approach from Monocular Vision","Z. Zhuang; X. Yu; R. Mahony","The Australian National University,""Australian Centre for Robotic Vision"", Research School of Engineering,Canberra,ACT,Australia,2601; The Australian National University,""Australian Centre for Robotic Vision"", Research School of Engineering,Canberra,ACT,Australia,2601; The Australian National University,""Australian Centre for Robotic Vision"", Research School of Engineering,Canberra,ACT,Australia,2601","2020 IEEE International Conference on Robotics and Automation (ICRA)","15 Sep 2020","2020","","","8331","8337","We propose a closed-loop, multi-instance control algorithm for visually guided reaching based on novel learning principles. A control Lyapunov function methodology is used to design a reaching action for a complex multi-instance task in the case where full state information (poses of all potential reaching points) is available. The proposed algorithm uses monocular vision and manipulator joint angles as the input to a deep convolution neural network to predict the value of the control Lyapunov function (cLf) and corresponding velocity control. The resulting network output is used in real-time as visual control for the grasping task with the multi-instance capability emerging naturally from the design of the control Lyapunov function. We demonstrate the proposed algorithm grasping mugs (textureless and symmetric objects) on a table-top from an over-the-shoulder monocular RGB camera. The manipulator dynamically converges to the best-suited target among multiple identical instances from any random initial pose within the workspace. The system trained with only simulated data is able to achieve 90.3% grasp success rate in the real-world experiments with up to 85Hz closed-loop control on one GTX 1080Ti GPU and significantly outperforms a Pose-Based-Visual-Servo (PBVS) grasping system adapted from a state-of-the-art single shot RGB 6D pose estimation algorithm. A key contribution of the paper is the inclusion of a first-order differential constraint associated with the cLf as a regularisation term during learning, and we provide evidence that this leads to more robust and reliable reaching/grasping performance than vanilla regression on general control inputs.","2577-087X","978-1-7281-7395-5","10.1109/ICRA40945.2020.9196781","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9196781","","Lyapunov methods;Grasping;Feature extraction;Computer architecture;Task analysis;Pose estimation;Velocity control","cameras;closed loop systems;convolutional neural nets;image colour analysis;learning (artificial intelligence);Lyapunov methods;manipulator dynamics;neurocontrollers;pose estimation;robot vision;velocity control;visual servoing","GTX 1080Ti GPU;grasping mugs;multiinstance control;real-time closed loop;LyRN;single shot RGB 6D pose estimation;complex multiinstance task;reaching action;control Lyapunov function;learning principles;visually guided reaching;Lyapunov reaching network;pose-based-visual-servo grasping system;closed-loop control;over-the-shoulder monocular RGB camera;multiinstance capability;visual control;velocity control;deep convolution neural network;manipulator joint angles;monocular vision;reaching points;frequency 85.0 Hz","","","","30","","15 Sep 2020","","","IEEE","IEEE Conferences"
"Self-Supervised Learning of State Estimation for Manipulating Deformable Linear Objects","M. Yan; Y. Zhu; N. Jin; J. Bohg","School of Engineering, Stanford University, Stanford, CA, USA; School of Engineering, Stanford University, Stanford, CA, USA; Stanford University, Stanford, CA, USA; School of Engineering, Stanford University, Stanford, CA, USA","IEEE Robotics and Automation Letters","19 Feb 2020","2020","5","2","2372","2379","We demonstrate model-based, visual robot manipulation of deformable linear objects. Our approach is based on a state-space representation of the physical system that the robot aims to control. This choice has multiple advantages, including the ease of incorporating physics priors in the dynamics model and perception model, and the ease of planning manipulation actions. In addition, physical states can naturally represent object instances of different appearances. Therefore, dynamics in the state space can be learned in one setting and directly used in other visually different settings. This is in contrast to dynamics learned in pixel space or latent space, where generalization to visual differences are not guaranteed. Challenges in taking the state-space approach are the estimation of the high-dimensional state of a deformable object from raw images, where annotations are very expensive on real data, and finding a dynamics model that is both accurate, generalizable, and efficient to compute. We are the first to demonstrate self-supervised training of rope state estimation on real images, without requiring expensive annotations. This is achieved by our novel self-supervising learning objective, which is generalizable across a wide range of visual appearances. With estimated rope states, we train a fast and differentiable neural network dynamics model that encodes the physics of mass-spring systems. Our method has a higher accuracy in predicting future states compared to models that do not involve explicit state estimation and do not use any physics prior, while only using 3% of training data. We also show that our approach achieves more efficient manipulation, both in simulation and on a real robot, when used within a model predictive controller.","2377-3766","","10.1109/LRA.2020.2969931","Toyota Research Institute (“TRI”); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8972568","Visual learning;deep learning in robotics and automation;perception for grasping and manipulation","State estimation;Predictive models;Image segmentation;Robots;Physics;Deformable models;Aerospace electronics","control engineering computing;manipulator dynamics;mobile robots;neural nets;path planning;predictive control;robot vision;supervised learning","deep learning;visual learning;manipulation action planning;self-supervising learning;model predictive controller;neural network dynamics;rope state estimation;self-supervised training;visual robot manipulation;deformable linear objects;self-supervised learning","","5","","31","IEEE","28 Jan 2020","","","IEEE","IEEE Journals"
"Online adaptation of controller parameters based on approximate dynamic programming","W. Guo; F. Liu; J. Si; S. Mei","State Key Laboratory of Power Systems, Department of Electrical Engineering, Tsinghua University, Beijing 100084, China; State Key Laboratory of Power Systems, Department of Electrical Engineering, Tsinghua University, Beijing 100084, China; Department of Electrical Engineering, Arizona State University, Tempe, AZ 85287, USA; State Key Laboratory of Power Systems, Department of Electrical Engineering, Tsinghua University, Beijing 100084, China","2014 International Joint Conference on Neural Networks (IJCNN)","4 Sep 2014","2014","","","256","262","Controller parameter tuning is an integral part of control engineering practice. Existing tuning methods usually start with an accurate mathematical model of the controlled system, which may pose some challenges for practicing engineers dealing with real systems. As such, parameter optimization and adaptation are treated as two independent steps during tuning. To address these issues, we propose a new, online parameterized controller tuning method for a general nonlinear dynamic system. This tuning method is based on direct heuristic dynamic programming (direct HDP), a model-free algorithm in the approximated dynamic programming (ADP) family. By using a Lyapunov stability approach, we provide uniformly ultimately bounded (UUB) results under some mild conditions for controller parameters, the critic neural network weights, and the action neural network weights. Simulation studies based on the benchmark cart-pole system demonstrate adaptability and optimization capabilities of the proposed controller parameter tuning method.","2161-4407","978-1-4799-1484-5","10.1109/IJCNN.2014.6889869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6889869","","Artificial neural networks;Tuning;Dynamic programming;Function approximation;Convergence","control engineering;dynamic programming;heuristic programming;learning (artificial intelligence);Lyapunov methods;neurocontrollers;nonlinear dynamical systems;stability","online controller parameter adaptation;approximate dynamic programming;controller parameter tuning methods;control engineering practice;real systems;controlled system mathematical model;parameter optimization;online parameterized controller tuning method;nonlinear dynamic system;direct heuristic dynamic programming;direct HDP;model-free algorithm;ADP family;Lyapunov stability approach;uniformly ultimately bounded results;UUB results;critic neural network weights;action neural network weights;cart-pole system","","","","28","","4 Sep 2014","","","IEEE","IEEE Conferences"
"A Cooperative Motion Control of 2-dof Robot Arms by Neuro-evolved Agents","Y. Dai; M. Konishi; J. Imai","Okayama Univ., Okayama; Okayama Univ., Okayama; Okayama Univ., Okayama","Second International Conference on Innovative Computing, Informatio and Control (ICICIC 2007)","14 Jan 2008","2007","","","109","109","In the paper we propose the method of agent-based neural network model to enhance the behaviors and the communication functions of real planner two degrees of freedom (2-dof) robot arms. Each joint of the manipulator is respectively provided a learning method to optimize trajectory by training RNN model. The evolutionary process in our experiments is carried out entirely on the robot by the proposed controller without human intervention. In addition, the master/slave manipulator system is proposed. The slave arm cooperates with the master like the action of human. Each joint is controlled by the distributed sub- agent. The method is first evaluated on a relatively simple task and then on increasingly complex behaviors towards the goal tasks. Simulation results show the effectiveness of this approach, and that the proposed RNN model can successfully learning the inverse dynamics of robot manipulators, perform accurate tracking for a general trajectory.","","0-7695-2882-1","10.1109/ICICIC.2007.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4427754","","Motion control;Robots;Recurrent neural networks;Humans;Master-slave;Manipulator dynamics;Neural networks;Learning systems;Optimization methods;Communication system control","learning (artificial intelligence);manipulator dynamics;motion control;neurocontrollers;recurrent neural nets","cooperative motion control;agent-based neural network model;robot arms;master-slave manipulator system;robot manipulator inverse dynamics;RNN model training;recurrent type neural network","","2","","7","","14 Jan 2008","","","IEEE","IEEE Conferences"
"Control of Nonaffine Nonlinear Discrete-Time Systems Using Reinforcement-Learning-Based Linearly Parameterized Neural Networks","Q. Yang; J. B. Vance; S. Jagannathan","Dept. of Electr. & Comput. Eng., Missouri Univ. of Sci. & Technol., Rolla, MO; Dept. of Electr. & Comput. Eng., Missouri Univ. of Sci. & Technol., Rolla, MO; Dept. of Electr. & Comput. Eng., Missouri Univ. of Sci. & Technol., Rolla, MO","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","16 Jul 2008","2008","38","4","994","1001","A nonaffine discrete-time system represented by the nonlinear autoregressive moving average with eXogenous input (NARMAX) representation with unknown nonlinear system dynamics is considered. An equivalent affinelike representation in terms of the tracking error dynamics is first obtained from the original nonaffine nonlinear discrete-time system so that reinforcement-learning-based near-optimal neural network (NN) controller can be developed. The control scheme consists of two linearly parameterized NNs. One NN is designated as the critic NN, which approximates a predefined long-term cost function, and an action NN is employed to derive a near-optimal control signal for the system to track a desired trajectory while minimizing the cost function simultaneously. The NN weights are tuned online. By using the standard Lyapunov approach, the stability of the closed-loop system is shown. The net result is a supervised actor-critic NN controller scheme which can be applied to a general nonaffine nonlinear discrete-time system without needing the affinelike representation. Simulation results demonstrate satisfactory performance of the controller.","1941-0492","","10.1109/TSMCB.2008.926607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4567550","Adaptive critic;adaptive dynamic programming;Lyapunov stability;neural network control;reinforcement learning control","Nonlinear control systems;Control systems;Neural networks;Nonlinear dynamical systems;Cost function;Nonlinear systems;Error correction;Signal design;Trajectory;Stability","autoregressive moving average processes;closed loop systems;discrete time systems;learning (artificial intelligence);linear systems;Lyapunov methods;minimisation;neurocontrollers;nonlinear control systems;optimal control;stability;tracking","nonaffine nonlinear discrete-time system control;reinforcement-learning;linear parameterized neural network;nonlinear autoregressive moving average-exogenous input;nonlinear system dynamics;tracking error dynamics;near-optimal control signal;cost function minimization;Lyapunov approach;closed-loop system stability","Algorithms;Computer Simulation;Feedback;Models, Theoretical;Neural Networks (Computer);Nonlinear Dynamics;Programming, Linear;Reinforcement (Psychology);Signal Processing, Computer-Assisted","53","","12","","16 Jul 2008","","","IEEE","IEEE Journals"
"Minimum variance control based on an uncertain neural networks and global optimization method","A. Mnasser; F. Bouani","Tunis El Manar University, Faculty of Sciences of Tunis, Tunis, Tunisia; Tunis El Manar University, National Engineering School of Tunis, Tunis, Tunisia","2015 4th International Conference on Systems and Control (ICSC)","13 Jul 2015","2015","","","486","491","In this paper, we propose a robust minimum variance controller for nonlinear systems based on feedforward neural networks. Based on input-output system measurements, a neural network model with uncertain parameters is trained to approximate the unknown dynamic behavior of the system. The control law is formulated as a min-max optimization problem which minimizes the worst case of the quadratic objective function subject to the uncertain parameters of the model and the control signal constraints. When classic optimization methods are used to optimize this kind of problem, a local solution is then obtained. In order to reach the global solution of the control problem which corresponds to the optimal control actions, the Generalized Geometric Programming technique is used to reduce the constrained non-convex problem to a convex one. The performances of the proposed neural controller are illustrated by a simulation example.","2379-0067","978-1-4799-8318-6","10.1109/ICoSC.2015.7153294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7153294","","Optimization;Linear programming;Computational modeling;Neural networks;Mathematical model;Fuzzy control;Polynomials","control system synthesis;feedforward neural nets;mathematical programming;minimax techniques;neurocontrollers;nonlinear control systems;robust control;uncertain systems","uncertain neural networks;global optimization method;robust minimum variance controller;nonlinear systems;feedforward neural networks;input-output system measurements;uncertain parameters;control law;min-max optimization problem;quadratic objective function;control signal constraints;generalized geometric programming technique","","","","16","","13 Jul 2015","","","IEEE","IEEE Conferences"
"Data-Driven Adaptive Dynamic Programming for H2/H∞ Control of Unknown Nonlinear System","J. Pu; Q. Ma; F. Gu; Y. Li","Xi'an Research Institute of High-Tech, Xi'an, 710025, P.R.China; Xi'an Research Institute of High-Tech, Xi'an, 710025, P.R.China; Xi'an Research Institute of High-Tech, Xi'an, 710025, P.R.China; Xi'an Research Institute of High-Tech, Xi'an, 710025, P.R.China","2018 37th Chinese Control Conference (CCC)","7 Oct 2018","2018","","","971","976","In order to solve the practical problems that exact analytic solution of the coupled Hamilton-Jacobi-Isaacs (HJI) equations arising from the mixed H2/H∞ control of nonlinear systems and the nonlinear system dynamics models is not generally known. According to the model-based iterative algorithm, a data-driven approximate dynamic programming algorithm for solving mixed H2/H∞ control problems is derived by adding known noise into control strategy and disturbance strategy. The Nash equilibrium strategy of nonlinear system is obtained online by using input-output data of nonlinear system, which does not depend on the specific model information of the system. Two critic neural networks and two action neural networks are used to synchronously update two value functions, control strategy and disturbance strategy online. The unknown parameters of neural network are estimated by generalized least squares. The simulation results verify the feasibility of the algorithm.","1934-1768","978-988-15639-5-8","10.23919/ChiCC.2018.8483002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8483002","Adaptive dynamic programming;data-driven;control;Optimum control;Neural network","Mathematical model;Nonlinear systems;Neural networks;Heuristic algorithms;Dynamic programming;Approximation algorithms;Analytical models","approximation theory;control system synthesis;dynamic programming;game theory;iterative methods;Jacobian matrices;least squares approximations;neurocontrollers;nonlinear control systems","unknown nonlinear system;nonlinear system dynamics models;Nash equilibrium strategy;Hamilton-Jacobi-Isaacs equations;H2-H∞ control;HJI equations;iterative algorithm;neural networks;least squares generation;approximate dynamic programming algorithm","","","","17","","7 Oct 2018","","","IEEE","IEEE Conferences"
"Bayesian optimization with adaptive kernels for robot control","R. Martinez-Cantin","Centro Universitario de la Defensa, Zaragoza, Spain. and SigOpt, Inc.","2017 IEEE International Conference on Robotics and Automation (ICRA)","24 Jul 2017","2017","","","3350","3356","Active policy search combines the trial-and-error methodology from policy search with Bayesian optimization to actively find the optimal policy. First, policy search is a type of reinforcement learning which has become very popular for robot control, for its ability to deal with complex continuous state and action spaces. Second, Bayesian optimization is a sample efficient global optimization method that uses a surrogate model, like a Gaussian process, and optimal decision making to carefully select each sample during the optimization process. Sample efficiency is of paramount importance when each trial involves the real robot, expensive Monte Carlo runs, or a complex simulator. Black-box Bayesian optimization generally assumes a cost function from a stationary process, because nonstationary modeling is usually based on prior knowledge. However, many control problems are inherently nonstationary due to their failure conditions, terminal states and other abrupt effects. In this paper, we present a kernel function specially designed for Bayesian optimization, that allows nonstationary modeling without prior knowledge, using an adaptive local region. The new kernel results in an improved local search (exploitation), without penalizing the global search (exploration), as shown experimentally in well-known optimization benchmarks and robot control scenarios. We finally show its potential for the design of the wing shape of a UAV.","","978-1-5090-4633-1","10.1109/ICRA.2017.7989380","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7989380","","Kernel;Optimization;Bayes methods;Gaussian processes;Robots;Adaptation models;Learning (artificial intelligence)","autonomous aerial vehicles;Bayes methods;decision making;Gaussian processes;learning (artificial intelligence);mobile robots;Monte Carlo methods;optimisation","adaptive kernels;robot control;active policy search;trial-and-error methodology;reinforcement learning;global optimization;Gaussian process;optimal decision making;Monte Carlo method;black-box Bayesian optimization;UAV","","3","","32","","24 Jul 2017","","","IEEE","IEEE Conferences"
"Stochastic Optimal Controller Design for Uncertain Nonlinear Networked Control System via Neuro Dynamic Programming","H. Xu; S. Jagannathan","Department of Electrical and Computer Engineering, Missouri University of Science and Technology, Rolla, MI, USA; Department of Electrical and Computer Engineering, Missouri University of Science and Technology, Rolla, MI, USA","IEEE Transactions on Neural Networks and Learning Systems","1 Feb 2013","2013","24","3","471","484","The stochastic optimal controller design for the nonlinear networked control system (NNCS) with uncertain system dynamics is a challenging problem due to the presence of both system nonlinearities and communication network imperfections, such as random delays and packet losses, which are not unknown a priori. In the recent literature, neuro dynamic programming (NDP) techniques, based on value and policy iterations, have been widely reported to solve the optimal control of general affine nonlinear systems. However, for realtime control, value and policy iterations-based methodology are not suitable and time-based NDP techniques are preferred. In addition, output feedback-based controller designs are preferred for implementation. Therefore, in this paper, a novel NNCS representation incorporating the system uncertainties and network imperfections is introduced first by using input and output measurements for facilitating output feedback. Then, an online neural network (NN) identifier is introduced to estimate the control coefficient matrix, which is subsequently utilized for the controller design. Subsequently, the critic and action NNs are employed along with the NN identifier to determine the forward-in-time, time-based stochastic optimal control of NNCS without using value and policy iterations. Here, the value function and control inputs are updated once a sampling instant. By using novel NN weight update laws, Lyapunov theory is used to show that all the closed-loop signals and NN weights are uniformly ultimately bounded in the mean while the approximated control input converges close to its target value with time. Simulation results are included to show the effectiveness of the proposed scheme.","2162-2388","","10.1109/TNNLS.2012.2234133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6410432","Neuro dynamic programming;nonlinear networked control system;stochastic optimal control","Artificial neural networks;Delay;Packet loss;Optimal control;Communication networks;Dynamic programming","control nonlinearities;control system synthesis;delays;dynamic programming;feedback;iterative methods;Lyapunov methods;networked control systems;neurocontrollers;nonlinear control systems;optimal control;stochastic systems;uncertain systems","stochastic optimal controller design;uncertain nonlinear networked control system;neuro dynamic programming;NNCS;system nonlinearities;communication network imperfections;random delays;packet losses;general affine nonlinear systems;real-time control;value iterations-based methodology;policy iterations-based methodology;time-based NDP techniques;output feedback-based controller designs;online neural network identifier;time-based stochastic optimal control;Lyapunov theory;NN weight update laws;approximated control input","Neural Networks (Computer);Nonlinear Dynamics;Stochastic Processes","64","","31","","14 Jan 2013","","","IEEE","IEEE Journals"
"Theory of functional systems, adaptive critics and neural networks","V. G. Red'ko; D. V. Prokhorov; M. S. Burtsev","Inst. of Opt. Neural Technol., Acad. of Sci., Moscow, Russia; NA; NA","2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541)","17 Jan 2005","2004","3","","1787","1792 vol.3","We propose a general scheme of intelligent adaptive control system based on the Petr K. Anokhin's theory of functional systems. This scheme is aimed at controlling adaptive purposeful behavior of an animat (a simulated animal) that has several natural needs (e.g., energy replenishment, reproduction). The control system consists of a set of hierarchically linked functional systems and enables predictive and goal-directed behavior. Each functional system includes a neural network based adaptive critic design. We also discuss schemes of prognosis, decision making, action selection and learning that occur in the functional systems and in the whole control system of the animat.","1098-7576","0-7803-8359-1","10.1109/IJCNN.2004.1380879","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1380879","","Adaptive systems;Neural networks;Adaptive control;Animation;Control systems;Intelligent systems;Intelligent control;Programmable control;Animals;Decision making","adaptive control;zoology;intelligent control;neurocontrollers;decision making;learning (artificial intelligence)","functional systems theory;adaptive critic design;neural network;intelligent adaptive control system;decision making;action selection","","6","","23","","17 Jan 2005","","","IEEE","IEEE Conferences"
"An active micro-electrode array with spike detection and asynchronous readout","T. Datta-Chaudhuri; B. Senevirathna; A. Castro; E. Smela; P. Abshire","Department of Electrical and Computer Engineering, University of Maryland, College Park, USA; Department of Electrical and Computer Engineering, University of Maryland, College Park, USA; Department of Electrical and Computer Engineering, University of Maryland, College Park, USA; Department of Mechanical Engineering, University of Maryland, College Park, USA; Department of Electrical and Computer Engineering, University of Maryland, College Park, USA","2014 IEEE Biomedical Circuits and Systems Conference (BioCAS) Proceedings","11 Dec 2014","2014","","","588","591","We present an active micro-electrode array for neural recording with integrated spike detection and an asynchronous readout architecture. Neural amplifier arrays generate voluminous data because of the necessary per-channel sampling rates and number of channels in a dense array. Most of the time, neural cells produce well below 100 spikes per second, with action potential durations generally on the order of 1 ms, and accordingly much of the recorded data from a neural amplifier is not of interest. In the case of dense arrays recording from single units, only the timing of action potentials is relevant and spike sorting is not required. In such a case, the bandwidth requirement of the neural array can be reduced by employing an event-driven data communication protocol such as address event representation (AER). In our array, these events are generated by the spike detection circuits and then relayed to AER modules that send the address of the spiking neuron off-chip using a digital encoding scheme. Based on simulation data, the system implemented here reduces bandwidth requirements by a factor of 1600 in comparison to traditional synchronous sampling.","2163-4025","978-1-4799-2346-5","10.1109/BioCAS.2014.6981794","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6981794","AER;neural amplifier;bio-potential;spike detection;NEO","Arrays;Bandwidth;Detectors;Feature extraction;Electrodes;Algorithm design and analysis;Data acquisition","bioelectric potentials;biomedical electrodes;data communication;neurophysiology;readout electronics","active microelectrode array;asynchronous readout;neural recording;integrated spike detection;neural amplifier arrays;neural cells;action potential duration;event driven data communication protocol;address event representation;AER modules","","2","","24","","11 Dec 2014","","","IEEE","IEEE Conferences"
"Humanoid Robot Grasping with a Soft Gripper Through a Learned Inverse Model of a Central Pattern Generator and Tactile Servoing","Y. Pan; F. Hamker; J. Nassour","University of Technology, Artificial Intelligence, Computer Science Chemnitz, Chemnitz, 09111, Germany; University of Technology, Artificial Intelligence, Computer Science Chemnitz, Chemnitz, 09111, Germany; University of Technology, Artificial Intelligence, Computer Science Chemnitz, Chemnitz, 09111, Germany","2018 IEEE-RAS 18th International Conference on Humanoid Robots (Humanoids)","24 Jan 2019","2018","","","1","9","Grasping and manipulation are essential skills that humanoid robots need in order to operate in the human environment. Model-based methods require a precise calibration and suffer from high order non-linearity. While, neural-based representations does not require a dedicated calibration process to solve these tasks. However, some suffer from high generalization error that reduces the accuracy or require large-scale data collection. The role of sensory feedback is therefore important to adapt the action. We present a control framework to learn grasping with a soft gripper attached to a humanoid robot arm. The inverse kinematic model of the arm is acquired through motor babbling of a central pattern generator and encoded by a feed-forward neural network. To overcome the generalization error we provide the gripper with a tactile sensors array at each finger. The tactile servoing is used to correct the action before grasping. The proposed model has been tested in simulation, and on the real robot where a soft sensory gripper was used to interact with a human subject (Tactile Servoing). Successful grasping was achieved thanks to the integration of a learned inverse model with the sensory feedback.","2164-0580","978-1-5386-7283-9","10.1109/HUMANOIDS.2018.8625035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8625035","","Neurons;Robot sensing systems;Grasping;Kinematics;Grippers;Robot kinematics","calibration;feedback;feedforward neural nets;grippers;humanoid robots;manipulators;neurocontrollers;position control;tactile sensors","central pattern generator;feed-forward neural network;tactile sensors array;tactile servoing;soft sensory gripper;sensory feedback;humanoid robot grasping;soft gripper;humanoid robots;human environment;high order nonlinearity;neural-based representations;dedicated calibration process;large-scale data collection;humanoid robot arm;inverse kinematic model","","","","9","","24 Jan 2019","","","IEEE","IEEE Conferences"
"Incorporating an Affective Model to an Intelligent Tutor for Mobile Robotics","Y. Hernandez; J. Noguez; E. Sucar; G. Arroyo-Figueroa","Instituto de Investigaciones Eléctricas, Gerencia de Sistemas Informáticos, Cuernavaca, Morelos, México, myhp@iie.org.mx; Tecnológico de Monterrey, Campus Cd. de México, México, D. F., México, noguez@itesm.mx; Instituto Nacional de Astrofísica, Óptica y Electrónica, Tonantzintla, Puebla, México, esucar@inaoep.mx; Instituto de Investigaciones Eléctricas, Gerencia de Sistemas Informáticos, Cuernavaca, Morelos, México, garroyo@iie.org.mx","Proceedings. Frontiers in Education. 36th Annual Conference","5 Mar 2007","2006","","","22","27","Emotions have been identified as important players in motivation, and motivation is very important for learning. When a tutor recognizes the affective state of the student and responds accordingly, the tutor may be able to motivate students and improve the learning process. We propose a general affective behavior model which integrates information from the student's pedagogical state, affective state, and the tutorial situation, to decide the best tutorial action, considering the tutor preferences from a pedagogical and affective point of view. Our proposal is based on emotions models, personality theories and teachers' expertise. The affective model is implemented as a dynamic decision network, with utility measures on both learning and motivation, and is being incorporated to an intelligent tutor within a virtual laboratory for learning mobile robotics. This paper presents preliminary results in the construction of the affective behavior model","2377-634X","1-4244-0256-5","10.1109/FIE.2006.322407","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4116913","Affective state;decision networks;intelligent tutoring systems;student model;virtual laboratories","Intelligent robots;Mobile robots;Biological system modeling;Laboratories;Intelligent systems;Intelligent networks;Cognitive robotics;Artificial intelligence;Humans;Appraisal","intelligent tutoring systems;learning (artificial intelligence);mobile robots;virtual reality","intelligent tutor;mobile robotics;motivation;learning;dynamic decision network;virtual laboratory","","10","","17","","5 Mar 2007","","","IEEE","IEEE Conferences"
"The Arm Planning with Dynamic Movement Primitive for Humanoid Service Robot","M. Lin; Z. Lu; S. Wang; R. Wang","School of Mechanical Engineering and Automation, Northeastern University,Shenyang,China; School of Mechanical Engineering and Automation, Northeastern University,Shenyang,China; School of Mechanical Engineering and Automation, Northeastern University,Shenyang,China; School of Mechanical Engineering and Automation, Northeastern University,Shenyang,China","2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM)","14 Sep 2020","2020","","","513","518","In order to realize the autonomous motor learning skills of humanoid service robot, we propose a systematic framework for trajectory planning and learning of robotic arms in this paper. The system is presented as a series of differential equations with good attractor properties called dynamic movement primitive (DMP). The core of DMP is to extract the motion characteristics from the human body demonstration, and then realize the reproduction and generalization of human actions by adjusting the nonlinear terms online. In this paper, a dynamic motion capture equipment is used to acquire the human's demonstration. The nonlinear terms of DMP is learned through local weighted regression (LWR) algorithm. Finally, the effectiveness of this method is verified by simulating the one-dimensional and two-dimensional trajectories in MATLAB and applying it to the existing household humanoid service robot in the laboratory.","","978-1-7281-6479-3","10.1109/ICARM49381.2020.9195273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195273","","Trajectory;Hidden Markov models;Manipulators;Service robots;Dynamics;Planning","differential equations;humanoid robots;learning (artificial intelligence);mobile robots;motion control;nonlinear control systems;path planning;regression analysis;robot dynamics;service robots;trajectory control","arm planning;dynamic movement primitive;trajectory planning;robotic arms;differential equations;DMP;human body demonstration;human actions;nonlinear terms;dynamic motion capture equipment;household humanoid service robot;autonomous motor learning skills;systematic framework;local weighted regression algorithm;two-dimensional trajectories;one-dimensional trajectories;MATLAB","","","","26","","14 Sep 2020","","","IEEE","IEEE Conferences"
"Autonomous Robot Navigation System Without Grid Maps Based on Double Deep Q-Network and RTK-GNSS Localization in Outdoor Environments","Y. Kato; K. Morioka","Graduate School of Advanced Mathematical Sciences, Network Design Program, Meiji University, Japan; Graduate School of Advanced Mathematical Sciences, Network Design Program, Meiji University, Japan","2019 IEEE/SICE International Symposium on System Integration (SII)","29 Apr 2019","2019","","","346","351","This paper proposes an autonomous mobile robot navigation system without grid maps in outdoor environments. The system integrates local navigation based on deep reinforcement learning and localization using RTK-GNSS. Local navigation is to travel between waypoints by using a learned policy. Localization is required for state of learning-based navigation and arrival evaluation of waypoints. First, a robot learns a policy traveling between waypoints in an environment that imitates an actual outdoor environment and avoiding collision with obstacles in our original simulator. DDQN(Double Deep Q-Network) is applied as an learning algorithm. We aim for learning that a robot can take an adequate action from obstacle positions obtained from 2D-LiDAR, a relative distance and a relative angle to a destination. Then, a robot performs navigation in outdoor environments based on the learned policy. Experimental results include learning in several environments, accuracy of RTK-GNSS and the integrated navigation system in an actual outdoor environment. Especially, our proposed system could travel approximately 600[m] in a general urban environments.","2474-2325","978-1-5386-3615-2","10.1109/SII.2019.8700426","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8700426","","Navigation;Robot kinematics;Robot sensing systems;Mobile robots;Collision avoidance;Path planning","collision avoidance;learning systems;mobile robots;navigation;neurocontrollers;robot vision","autonomous mobile robot navigation system;local navigation;deep reinforcement learning;learning-based navigation;learning algorithm;integrated navigation system;general urban environments;RTK-GNSS localization;outdoor environment;collision avoidance;double deep Q-network;2D-LiDAR;DDQN","","2","","10","","29 Apr 2019","","","IEEE","IEEE Conferences"
"Distributed Attack-Robust Submodular Maximization for Multi-Robot Planning","L. Zhou; V. Tzoumas; G. J. Pappas; P. Tokekar","Virginia Tech,Department of Electrical and Computer Engineering,Blacksburg,VA,USA,24061; Massachusetts Institute of Technology,Laboratory of Information and Decision Systems,Cambridge,MA,USA,02139; University of Pennsylvania,Department of Electrical and Systems Engineering,Philadelphia,PA,USA,19104; Virginia Tech,Department of Electrical and Computer Engineering,Blacksburg,VA,USA,24061","2020 IEEE International Conference on Robotics and Automation (ICRA)","15 Sep 2020","2020","","","2479","2485","We aim to guard swarm-robotics applications against denial-of-service (DoS) attacks that result in withdrawals of robots. We focus on applications requiring the selection of actions for each robot, among a set of available ones, e.g., which trajectory to follow. Such applications are central in large-scale robotic applications, e.g., multi-robot motion planning for target tracking. But the current attack-robust algorithms are centralized, and scale quadratically with the problem size (e.g., number of robots). In this paper, we propose a general-purpose distributed algorithm towards robust optimization at scale, with local communications only. We name it distributed robust maximization (DRM). DRM proposes a divide-and-conquer approach that distributively partitions the problem among K cliques of robots. The cliques optimize in parallel, independently of each other. That way, DRM also offers computational speed-ups up to 1/K2 the running time of its centralized counterparts. K depends on the robots' communication range, which is given as input to DRM. DRM also achieves a close-to-optimal performance. We demonstrate DRM's performance in Gazebo and MATLAB simulations, in scenarios of active target tracking with multiple robots. We observe DRM achieves significant computational speed-ups (it is 3 to 4 orders faster) and, yet, nearly matches the tracking performance of its centralized counterparts.","2577-087X","978-1-7281-7395-5","10.1109/ICRA40945.2020.9197243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197243","","Planning;Target tracking;Robot kinematics;Partitioning algorithms;Robot sensing systems;Robustness","control system security;distributed algorithms;divide and conquer methods;multi-robot systems;optimisation;path planning;target tracking","distributed attack-robust submodular maximization;multirobot planning;swarm-robotics applications;multirobot motion;attack-robust algorithms;robust optimization;distributed robust maximization;DRM performance;multiple robots;denial-of-service attacks;DoS attacks;large-scale robotic applications;general-purpose distributed algorithm;divide-and-conquer approach;robot communication range;close-to-optimal performance;active target tracking","","","","36","","15 Sep 2020","","","IEEE","IEEE Conferences"
"A self-learning reactive navigation method for mobile robots","Xin Xu; Xue-Ning Wang; Han-Gen He","Sch. of Comput., Nat. Univ. of Defense Technol., Changsha, China; NA; NA","Proceedings of the 2003 International Conference on Machine Learning and Cybernetics (IEEE Cat. No.03EX693)","19 Feb 2004","2003","4","","2384","2388 Vol.4","This paper addresses the navigation problem of mobile robots in unknown environments, where global path planning methods cannot be applied. In such cases, reactive navigation controllers are commonly employed to deal with the uncertainties in motion planning and control. To realize the automatic design of reactive navigation controllers, a self-learning navigation method is proposed in this paper. The self-learning reactive navigation method is based on a Markov decision model of the navigation problem and uses reinforcement learning algorithms to optimize the action policies of mobile robots. Neural networks are employed to approximate value functions in continuous state spaces so that the self-learning navigation controller has good generalization ability and learning efficiency. Simulation results illustrate the effectiveness of the proposed method.","","0-7803-7865-2","10.1109/ICMLC.2003.1259909","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1259909","","Navigation;Mobile robots;Motion planning;Automatic control;Motion control;Path planning;Uncertainty;Learning;Optimization methods;Neural networks","mobile robots;computerised navigation;path planning;unsupervised learning;Markov processes;dynamic programming;optimisation","self-learning reactive navigation method;mobile robots;unknown environments;global path planning methods;motion planning;automatic design;reactive navigation controllers;Markov decision model;reinforcement learning algorithms","","2","","9","","19 Feb 2004","","","IEEE","IEEE Conferences"
"Improving the REP in an SGC: Multi-Objective Predictive optimization Algorithms Based On Fuzzy Multi-Criteria Decision-Making.","A. Katkout; T. Nasser; A. Essadki","Mohammed V University,ERERA, Research Center STIS, ENSET,Rabat,Morocco; Mohammed V University,ERERA, Research Center STIS, ENSIAS,Rabat,Morocco; Mohammed V University,ERERA, Research Center STIS, ENSET,Rabat,Morocco","2020 3rd International Conference on Advanced Communication Technologies and Networking (CommNet)","18 Sep 2020","2020","","","1","6","With increasing needs for the development of both Smart-Green Community (SGC) and Renewable Energy Penetration Systems (REPSs), the applications of multi-level power converter structure have been emerged in recent years. Therefore, and due to the multiple advantages (eg; simple concept, easy application of MIMO systems, good dynamic and steady-state performances), the predictive control (PC) is considered as an alternative tool to control the power converters. A cost-function, synthetizes the control objectives, presents the mismatch between the desired and actual behaviors of the system is evaluated every sampling period to generate the optimal action. The tradeoff between controlled variables is defined by weighting factors that are specified by the `heuristic approach' or `trial and error manner'. Generally, the process requires a large number of simulations/experiments and significant development time period. In this work, a fuzzy multi-criteria decision-making (FMDM) based on membership functions (MFs) is presented to avoid the weighting factors tuning processes. The stability, robustness and compensation of computational delay are embedded in the formulation of the predictive control by modified prediction, modified Lyapunov-function and long horizon of prediction approach, respectively. The proposed predictive scheme based on the FMDM' optimization has demonstrated superior performance in simulation as compared to that of scheme with the weightings factors optimization. The switching frequency rate is reduced by 48.81 %.","","978-1-7281-8704-4","10.1109/CommNet49926.2020.9199637","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9199637","smart-green community;multi-level power converter structure;predictive control;fuzzy multi-criteria decision-making;stability;robustness.","Predictive control;Inverters;Switches;Standards;Optimization;Predictive models","decision making;fuzzy set theory;Lyapunov methods;optimisation;power convertors;predictive control;stability","SGC;multiobjective predictive optimization algorithms;fuzzy multicriteria decision-making;multilevel power converter structure;MIMO systems;steady-state performances;predictive control;power converters;cost-function;control objectives;desired behaviors;actual behaviors;optimal action;controlled variables;weighting factors;modified prediction;modified Lyapunov-function;prediction approach;predictive scheme;FMDM optimization;weightings factors optimization;smart-green community;renewable energy penetration systems","","","","20","","18 Sep 2020","","","IEEE","IEEE Conferences"
"Low-Level Control of a Quadrotor With Deep Model-Based Reinforcement Learning","N. O. Lambert; D. S. Drew; J. Yaconelli; S. Levine; R. Calandra; K. S. J. Pister","Department of Electrical Engineering and Computer Sciences, University of California–Berkeley, Berkeley, CA, USA; Department of Electrical Engineering and Computer Sciences, University of California–Berkeley, Berkeley, CA, USA; University of Oregon, Eugene, OR, USA; Department of Electrical Engineering and Computer Sciences, University of California–Berkeley, Berkeley, CA, USA; Facebook AI Research, Menlo Park, CA, USA; Department of Electrical Engineering and Computer Sciences, University of California–Berkeley, Berkeley, CA, USA","IEEE Robotics and Automation Letters","15 Aug 2019","2019","4","4","4224","4230","Designing effective low-level robot controllers often entail platform-specific implementations that require manual heuristic parameter tuning, significant system knowledge, or long design times. With the rising number of robotic and mechatronic systems deployed across areas ranging from industrial automation to intelligent toys, the need for a general approach to generating low-level controllers is increasing. To address the challenge of rapidly generating low-level controllers, we argue for using model-based reinforcement learning (MBRL) trained on relatively small amounts of automatically generated (i.e., without system simulation) data. In this letter, we explore the capabilities of MBRL on a Crazyflie centimeter-scale quadrotor with rapid dynamics to predict and control at ≤50 Hz. To our knowledge, this is the first use of MBRL for controlled hover of a quadrotor using only on-board sensors, direct motor input signals, and no initial dynamics knowledge. Our controller leverages rapid simulation of a neural network forward dynamics model on a graphic processing unit enabled base station, which then transmits the best current action to the quadrotor firmware via radio. In our experiments, the quadrotor achieved hovering capability of up to 6 s with 3 min of experimental training data.","2377-3766","","10.1109/LRA.2019.2930489","Berkeley Sensors & Actuator Center SUPERB REU; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8769882","Deep learning in robotics and automation;aerial systems: mechanics and control","Data models;Vehicle dynamics;Robots;Pulse width modulation;Attitude control;Trajectory;Predictive models","aircraft control;control engineering computing;helicopters;learning (artificial intelligence);mechatronics;mobile robots;multi-robot systems;path planning;trajectory control","rapid simulation;platform-specific implementations;on-board sensors;direct motor input signals;neural network forward dynamics model;quadrotor firmware;robotic systems;low-level robot controllers;deep model-based reinforcement learning;low-level control;controlled hover;Crazyflie centimeter-scale quadrotor;MBRL;low-level controllers;mechatronic systems;frequency 50.0 Hz;time 6.0 s;time 3.0 min","","9","","30","Traditional","23 Jul 2019","","","IEEE","IEEE Journals"
"Reinforcement Learning based Method for Autonomous Navigation of Mobile Robots in Unknown Environments","R. Van Hoa; T. D. Chuyen; N. T. Lam; T. N. Son; N. D. Dien; V. T. T. Linh","University of Economics - Technology for Industries,Faculty of Electrical Engineering,Ha Noi,Viet Nam; Hanoi University of Science and Technology,School of Electrical Engineering,Department of Industrial Automation,Ha Noi,Viet Nam; University of Economics - Technology for Industries,Faculty of Electrical Engineering,Ha Noi,Viet Nam; University of Economics - Technology for Industries,Faculty of Electrical Engineering,Ha Noi,Viet Nam; University of Economics - Technology for Industries,Faculty of Electrical Engineering,Ha Noi,Viet Nam; University of Economics - Technology for Industries,Faculty of Electrical Engineering,Ha Noi,Viet Nam","2020 International Conference on Advanced Mechatronic Systems (ICAMechS)","6 Jan 2021","2020","","","266","269","The Reinforcement Learning is a subset of machine learning that deals with learning decisions from rewards given by the environment. The model classic reinforcement learning (RL) algorithms are usually applied to small sets of states and an action. However, in real applications, the state spaces are of a large scale and this will bring the problems in the generalization and the curse of dimensionality. In this research, authors integrate neural networks into reinforcement learning methods to generalize the value of all the states. The simulation results on the Gazebo software framework show the feasibility of the model proposed method algorithm. The robot can safely navigate an unprotected work environment and becomes a truly intelligent system with the ability to learn and adapt itself to the model.","2325-0690","978-1-7281-6530-1","10.1109/ICAMechS49982.2020.9310129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9310129","Artificial Intelligence;Reinforcement Learning;Neural Network;Autonomous Navigation;Mobile Robots","Robots;Reinforcement learning;Robot sensing systems;Navigation;Service robots;Electrical engineering;Autonomous robots","learning (artificial intelligence);mobile robots;navigation;neural nets;path planning","unprotected work environment;autonomous navigation;mobile robots;machine learning;reinforcement learning algorithms;unknown environments;Gazebo software framework;neural networks","","","","23","","6 Jan 2021","","","IEEE","IEEE Conferences"
"Development of an automatic travel system for electric wheelchairs using reinforcement learning systems and CMACs","R. Kurozumi; S. Fujisawa; T. Yamamoto; Y. Suita","Takamatsu Nat. Coll. of Technol., Japan; Takamatsu Nat. Coll. of Technol., Japan; NA; NA","Proceedings of the 2002 International Joint Conference on Neural Networks. IJCNN'02 (Cat. No.02CH37290)","7 Aug 2002","2002","2","","1690","1695 vol.2","The existing method for establishing travel routes provides modeled environmental information, but it is difficult to create an environment model for the environments where electric wheelchairs travel because the environment changes constantly due to the existence of moving objects including pedestrians. In this study, we propose an automatic travelling system for an electric wheelchair using reinforcement learning systems and CMACs. We select the best travel route by utilizing these reinforcement learning systems. When a CMAC learns the value function of Q-learning, an improved learning speed is achieved by utilizing the generalizing action. CMACs enable one to reduce the time needed to select the best travel route. Using simulation, a path planning experiment was performed.","1098-7576","0-7803-7278-6","10.1109/IJCNN.2002.1007772","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1007772","","Wheelchairs;Learning;Path planning;Educational institutions;Aging;Space exploration;Elevators;Absorption;Convergence;Power system modeling","handicapped aids;electric vehicles;path planning;computerised navigation;cerebellar model arithmetic computers;learning (artificial intelligence)","electric wheelchairs;automatic travel system;reinforcement learning;CMAC neural nets;travel route selection;reinforcement learning systems;Q-learning;path planning","","","","13","","7 Aug 2002","","","IEEE","IEEE Conferences"
"Managing search complexity in linguistic geometry","B. Stilman","Dept. of Comput. Sci. & Eng., Colorado Univ., Denver, CO, USA","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","6 Aug 2002","1997","27","6","978","998","This paper is a new step in the development of linguistic geometry. This formal theory is intended to discover and generalize the inner properties of human expert heuristics, which have been successful in a certain class of complex control systems, and apply them to different systems. In this paper, we investigate heuristics extracted in the form of hierarchical networks of planning paths of autonomous agents. Employing linguistic geometry tools the dynamic hierarchy of networks is represented as a hierarchy of formal attribute languages. The main ideas of this methodology are shown in the paper on two pilot examples of the solution of complex optimization problems. The first example is a problem of strategic planning for the air combat, in which concurrent actions of four vehicles are simulated as serial interleaving moves. The second example is a problem of strategic planning for the space comb of eight autonomous vehicles (with interleaving moves) that requires generation of the search tree of the depth 25 with the branching factor 30. This is beyond the capabilities of modern and conceivable future computers (employing conventional approaches). In both examples the linguistic geometry tools showed deep and highly selective searches in comparison with conventional search algorithms. For the first example a sketch of the proof of optimality of the solution is considered.","1941-0492","","10.1109/3477.650058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=650058","","Geometry;Strategic planning;Remotely operated vehicles;Interleaved codes;Humans;Control systems;Path planning;Autonomous agents;Vehicle dynamics;Optimization methods","strategic planning;computational linguistics;formal languages;search problems;path planning;software agents;computational geometry","linguistic geometry;search complexity;formal theory;planning paths;autonomous agents;strategic planning;proof of optimality;formal attribute languages;complex optimization;air combat;autonomous vehicles","","15","","62","","6 Aug 2002","","","IEEE","IEEE Journals"
"Stochastic modeling of the neuronal activity in the thalamus of Essential Tremor patient","I. Basu; D. Tuninetti; D. Graupe; K. V. Slavin","Univ. of Illinois at Chicago, USA; Univ. of Illinois at Chicago, USA; Univ. of Illinois at Chicago, USA; Univ. of Illinois at Chicago, USA","2010 Annual International Conference of the IEEE Engineering in Medicine and Biology","11 Nov 2010","2010","","","1461","1464","Several stochastic models, with various degrees of complexity, have been proposed to model the neuronal activity from different parts of the human brain. In this paper, we use an Ornstein-Uhlenbeck Process (OUP) to model the spike activity recorded from the thalamus of a patient suffering from Essential Tremor at the time of implantation of the electrodes for Deep Brain Stimulation. From the recorded data, which contains information about the spike times of a single neuron, we identify the model parameters of the OUP. We then use these parameters to numerically simulate the inter-spike interval distribution. We show that the OUP provides excellent fits to the data recorded both without any external stimulation as well as with stimulation. We finally compare the fits with other stochastic models commonly used and we show the superiority of the OUP model in general.","1558-4615","978-1-4244-4123-5","10.1109/IEMBS.2010.5626855","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5626855","","Neurons;Brain models;Biomembranes;Data models;Electrodes;Satellite broadcasting","bioelectric potentials;biomedical electrodes;brain models;medical signal processing;neurophysiology;prosthetics;stochastic processes","stochastic modeling;neuronal activity;thalamus;essential tremor patient;brain;Ornstein-Uhlenbeck process;spike activity;implant;electrodes;deep brain stimulation;spike times;interspike interval distribution","Action Potentials;Biological Clocks;Essential Tremor;Humans;Models, Neurological;Models, Statistical;Nerve Net;Neurons;Stochastic Processes;Thalamus","1","","17","","11 Nov 2010","","","IEEE","IEEE Conferences"
"Adaptation learning control scheme for a high-performance permanent-magnet stepper motor using online random training of neural networks","A. Rubaai; R. Kotaru","Dept. of Electr. Eng., Howard Univ., Washington, DC, USA; NA","IEEE Transactions on Industry Applications","7 Aug 2002","2001","37","2","495","502","This paper addresses the problem of controlling the speed of a permanent-magnet stepper motor assumed to operate in a high-performance drives environment. An artificial neural network (ANN) control scheme which uses continual online random training (with no offline training) to simultaneously identify and adaptively control the speed of the stepper motor is proposed. The control scheme utilizes two three-layer feedforward ANNs: (1) a tracker identification neural network which captures the nonlinear dynamics of the motor over any arbitrary time interval in its range of operation; and (2) a controller neural network to provide the necessary control actions to achieve trajectory tracking of the motor speed. The inputs to the controller neural network are not constructed from the actual motor/load dynamics, but as a feedback signal, from the estimated state variables of the motor supplied by the neural identifier and the reference trajectory to be tracked by the actual speed. A full nonlinear model (with no simplifying assumptions) is used to model the motor dynamics, and to the best of the authors' knowledge this represents the first such attempt for this device. This paper also makes use of a very realistic and practical scheme to estimate and adaptively learn the noise content in the speed-load torque characteristic of the motor. Simulations reveal that the neural controller adapts and generalizes its learning rate to a wide variety of loads, in addition to providing the necessary abstraction when measurements are contaminated with noise.","1939-9367","","10.1109/28.913714","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=913714","","Artificial neural networks;Neural networks;Feedforward neural networks;Trajectory;Neurofeedback;State feedback;Signal processing;State estimation;Torque;Noise measurement","permanent magnet motors;stepping motors;feedback;neurocontrollers;feedforward neural nets;angular velocity control;adaptive control;AC motor drives;learning (artificial intelligence);machine control","adaptation learning control scheme;high-performance permanent-magnet stepper motor;online random training;neural networks;speed control;high-performance drives environment;artificial neural network control scheme;ANN;continual online random training;adaptive control;three-layer feedforward ANN;tracker identification neural network;nonlinear dynamics;arbitrary time interval;controller neural network;nonlinear model;feedback signal;estimated state variables;speed-load torque characteristic;learning rate;AC motors","","16","","16","","7 Aug 2002","","","IEEE","IEEE Journals"
"Scalable sparsification for efficient decision making under uncertainty in high dimensional state spaces","K. Elimelech; V. Indelman","Robotics and Autonomous Systems Program (TASP), Technion - Israel Institute of Technology, Haifa 32000, Israel; Department of Aerospace Engineering, Technion - Israel Institute of Technology, Haifa 32000, Israel","2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","14 Dec 2017","2017","","","5668","5673","In this paper we introduce a novel sparsification method for efficient decision making under uncertainty and belief space planning in high dimensional state spaces. By using a sparse version of the state's information matrix, we are able to improve the high computational cost of examination of all candidate actions. We also present an in-depth analysis for the general case of approximated decision making, and use it in order to set bounds over the induced error in potential revenue. The scalability of the method allows balancing between the degree of sparsification and the tolerance for this error, in order to maximize its benefits. The approach differs from recent methods by focusing on improving the decision making process directly, and not as a byproduct of a sparsification of the state inference. Eventually, we demonstrate the superiority of the approach in a SLAM simulation, where we manage to maintain the accuracy of the solution, while demonstrating a significant improvement in run time.","2153-0866","978-1-5386-2682-5","10.1109/IROS.2017.8206456","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8206456","","Decision making;Uncertainty;Jacobian matrices;Simultaneous localization and mapping;Computational efficiency;Entropy;Planning","decision making;SLAM (robots);sparse matrices","high-dimensional state spaces;SLAM simulation;approximated decision making;belief space planning;novel sparsification method;scalable sparsification;state inference","","","","15","","14 Dec 2017","","","IEEE","IEEE Conferences"
"Neural Fault Diagnosis Method for Voltage Source Inverter with a Neural Direct Torque Control of Induction Motor","T. Younes; K. Farid; C. Fella; B. Abderrazak","University of Kasdi Merbah-Ouargla,Department of Electronics and Telecommunications,Ouargla,Algeria,30000; University of Kasdi Merbah-Ouargla,Department of Electronics and Telecommunications,Ouargla,Algeria,30000; University of Kasdi Merbah-Ouargla,Department of Electronics and Telecommunications,Ouargla,Algeria,30000; University of Kasdi Merbah-Ouargla,Department of Electronics and Telecommunications,Ouargla,Algeria,30000","2020 1st International Conference on Communications, Control Systems and Signal Processing (CCSSP)","29 Jul 2020","2020","","","480","486","Electrical drives in general incorporate an inverter and an induction machine. Thus, these both elements must be well considered to provide a relevant diagnosis of these electrical systems. So it is important to detect early different defects that can occur in these systems in order to find ways to allow us to monitor the operation and preventive action to avoid frequent breakdowns. The objective of this paper is to investigate the feasibility of detecting and diagnosing faults in a three-phase inverter supplying an induction motor. We present the simulation results of a neural direct torque control of (NDTC) of induction motor associating a fault diagnosis system by using the contribution of artificial intelligence. In this work, we give a detailed description of inverter switching faults with a simple method for feature extraction to study the possibility of detecting and diagnosing these defects. Detection and identification of faulty switches is realized within a few currents periods. The use of an intelligent technique improves the classification performance for one and only fault occurrence.","","978-1-7281-5835-8","10.1109/CCSSP49278.2020.9151552","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9151552","direct torque control;induction motor;neural network control;fault diagnosis;voltage source inverter","Inverters;Stators;Switches;Feature extraction;Circuit faults;Torque;Neural networks","fault diagnosis;feature extraction;induction motor drives;invertors;machine control;neurocontrollers;torque control;voltage-source convertors","intelligent technique;feature extraction;inverter switching faults;artificial intelligence;NDTC;three-phase inverter;electrical systems;induction machine;electrical drives;induction motor;neural direct torque control;voltage source inverter;neural fault diagnosis method","","","","29","","29 Jul 2020","","","IEEE","IEEE Conferences"
"Tracking Operator Intent in Tactical Operations","M. F. Schneider; M. E. Miller; J. M. McGuirl","Air Force Institute of Technology,Department of Systems Engineering and Management,Dayton,USA; Air Force Institute of Technology,Department of Systems Engineering and Management,Dayton,USA; LLC,Senior Scientist Centauri,Beavercreek,USA","2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","14 Dec 2020","2020","","","3214","3220","Effective teams coordinate their actions to achieve shared goals. In Human-Agent teams, the Artificial Intelligent Agents (AIAs) struggle to coordinate effectively due to a lack of understanding of their human teammate's intent. This places a burden on the human teammate to extensively communicate explicitly what goals they are pursuing and how they are pursuing them. To improve the AIAs ability to coordinate, we have proposed Operationalized Intent as a means to explicitly model how an operator qualitatively desires a task to be performed. In this paper, we report the results of a study to track operator intent through a tactical scenario. The focus of this paper is on the dynamics of intent and it's cohesiveness across operators. The study employed an immersive, advanced research, remotely piloted aircraft (RPA) simulator to study intent in a synthetic task environment. Using operational pilots and sensor operators in realistic scenarios we were able to elicit their intent under naturalistic conditions in the midst of challenging tactical situations to study the real-time dynamics. Analysis indicates that the method models intent which is dynamically responsive to changes in the situation and the data are suitably cohesive across operators to generalize to an operator role. When the intent data is coupled to situated data from the simulator it provides a labeled data source for future AIAs to estimate intent in real-time.","2577-1655","978-1-7281-8526-2","10.1109/SMC42975.2020.9283017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283017","Human-Machine Cooperation and Systems;Mental Models;Augmented Cognition","Conferences;Real-time systems;Data models;Intelligent agents;Task analysis;Man-machine systems;Cybernetics","human computer interaction;military computing;software agents","operator intent;tactical operations;human-agent teams;artificial intelligent agents;AIA;operationalized intent;tactical scenario;remotely piloted aircraft simulator;operational pilots;sensor operators;tactical situations;RPA simulator","","","","14","","14 Dec 2020","","","IEEE","IEEE Conferences"
"Learning hierarchical observable Markov decision process models for robot navigation","G. Theocharous; K. Rohanimanesh; S. Maharlevan","Dept. of Comput. Sci. & Eng., Michigan State Univ., East Lansing, MI, USA; NA; NA","Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164)","18 Apr 2006","2001","1","","511","516 vol.1","We propose and investigate a general framework for hierarchical modeling of partially observable environments, such as office buildings, using hierarchical hidden Markov models (HHMMs). Our main goal is to explore hierarchical modeling as a basis for designing more efficient methods for model construction and usage. As a case study we focus on indoor robot navigation and show how this framework can be used to learn a hierarchy of models of the environment at different levels of spatial abstraction. We introduce the idea of model reuse that can be used to combine already learned models into a larger model. We describe an extension of the HHMM model to includes actions, which we call hierarchical POMDPs, and describe a modified hierarchical Baum-Welch algorithm to learn these models. We train different families of hierarchical models for a simulated and a real world corridor environment and compare them with the standard ""flat"" representation of the same environment. We show that the hierarchical POMDP approach, combined with model reuse, allows learning hierarchical models that fit the data better and train faster than flat models.","1050-4729","0-7803-6576-3","10.1109/ROBOT.2001.932601","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=932601","","Robots;Navigation;Hidden Markov models;Artificial intelligence;Tree data structures;Computer science;Buildings;Design methodology;Learning;Decision making","mobile robots;navigation;learning (artificial intelligence);hidden Markov models;path planning","hierarchical hidden Markov models;navigation;mobile robot;spatial learning;model reuse;Baum-Welch algorithm","","4","1","8","","18 Apr 2006","","","IEEE","IEEE Conferences"
"Learning Synergies Between Pushing and Grasping with Self-Supervised Deep Reinforcement Learning","A. Zeng; S. Song; S. Welker; J. Lee; A. Rodriguez; T. Funkhouser",Princeton University; Princeton University; Google; Google; Massachusetts Institute of Technology; Princeton University,"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","6 Jan 2019","2018","","","4238","4245","Skilled robotic manipulation benefits from complex synergies between non-prehensile (e.g. pushing) and prehensile (e.g. grasping) actions: pushing can help rearrange cluttered objects to make space for arms and fingers; likewise, grasping can help displace objects to make pushing movements more precise and collision-free. In this work, we demonstrate that it is possible to discover and learn these synergies from scratch through model-free deep reinforcement learning. Our method involves training two fully convolutional networks that map from visual observations to actions: one infers the utility of pushes for a dense pixel-wise sampling of end-effector orientations and locations, while the other does the same for grasping. Both networks are trained jointly in a Q-learning framework and are entirely self-supervised by trial and error, where rewards are provided from successful grasps. In this way, our policy learns pushing motions that enable future grasps, while learning grasps that can leverage past pushes. During picking experiments in both simulation and real-world scenarios, we find that our system quickly learns complex behaviors even amid challenging cases of tightly packed clutter, and achieves better grasping success rates and picking efficiencies than baseline alternatives after a few hours of training. We further demonstrate that our method is capable of generalizing to novel objects. Qualitative results (videos), code, pre-trained models, and simulation environments are available at http://vpg.cs.princeton.edu/","2153-0866","978-1-5386-8094-0","10.1109/IROS.2018.8593986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593986","","Grasping;Training;Three-dimensional displays;Reinforcement learning;Planning;Manipulators","convolutional neural nets;end effectors;learning (artificial intelligence);motion control;neurocontrollers","learning synergies;self-supervised deep reinforcement learning;cluttered objects;pushing movements;model-free deep reinforcement learning;fully convolutional networks;end-effector orientations;Q-learning framework;pushing motions;grasping success rates;picking efficiencies;skilled robotic manipulation;grasping;prehensile action;pixel-wise sampling","","58","","39","","6 Jan 2019","","","IEEE","IEEE Conferences"
"EEG Signals Classification: Motor Imagery for Driving an Intelligent Wheelchair","O. R. Pinheiro; L. R. G. Alves; J. R. D. Souza","SENAI CIMATEC, Salvador, Brazil; SENAI CIMATEC, Salvador, Brazil; UNEB, Salvador, Brazil","IEEE Latin America Transactions","14 Feb 2018","2018","16","1","254","259","The activities pertaining to body control performed by human beings utilize neuromuscular tracts. Tasks' performance such as moving the arms or walking demand the planning of the task to be performed. People diagnosed with clinical conditions such as Amyotrophic Lateral Sclerosis, Spine lesions or Cerebrovascular Accident, for instance, have their neuromuscular tracts damaged. One of the alternatives to bypass that problem is the development of technologies which can partially replace the loss functioning of people with severe motor impairment. The imagination of the movement is considered as a cognitive state which corresponds to the mental simulation of a given motor action. The general aim of this investigative research is to develop a brain-computer based interface for the movement imagination of the left fist, right fist, both fists and both feet in order to control an intelligent wheelchair. The electroencephalography signals were acquired through the database eegmmidb - EEG Motor Movement/Imagery Dataset. Electroencephalography signals samples of 106 individuals were utilized in order to validate the computational model. The proposed model obtained an efficiency of 74,96% in the correct classification of the events related to movement imagination. The developed techniques are promising. The model intends to contribute as a complementation of an improvement towards the mobility of people suffering from severe motor impairment.","1548-0992","","10.1109/TLA.2018.8291481","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291481","Brain-Computer Interface;Electroencephalography;Intelligent wheelchair","Electroencephalography;Brain modeling;RNA;Computational modeling;Support vector machines;Pattern classification;Wheelchairs","brain-computer interfaces;cognition;electroencephalography;handicapped aids;medical signal processing;neurophysiology;signal classification","severe motor impairment;body control;human beings;neuromuscular tracts;cognitive state;mental simulation;brain-computer based interface;electroencephalography signals;EEG signal classification;amyotrophic lateral sclerosis;cerebrovascular accident;spine lesions;database eegmmidb-EEG Motor Movement-Imagery Dataset","","5","","","","14 Feb 2018","","","IEEE","IEEE Journals"
"Speeding up top-down attention control learning by using full observation knowledge","N. Noori; M. N. Ahmadabadi; M. S. Mirian; B. N. Araabi","Department of Electrical and Computer Engineering, University of Tehran. Tehran, Iran; Department of Electrical and Computer Engineering, University of Tehran. Tehran, Iran; Department of Electrical and Computer Engineering, University of Tehran. Tehran, Iran; Department of Electrical and Computer Engineering, University of Tehran. Tehran, Iran","2009 IEEE International Symposium on Computational Intelligence in Robotics and Automation - (CIRA)","1 Mar 2010","2009","","","369","374","We present a general mathematical description of the top-down attention control problem. Three important components are identified in the model: context extraction, attention focus and decision making. The context gives a coarse blurry representation of the whole input; the attention module models the focus of attention on a limited part of input, and the decision making component accounts the final decision of the agent for its motory actions. In order to achieve a faster convergence of attention learning in the online phase, an offline optimization step is performed in advance. To do so, we incorporate the knowledge of a full observer agent that has approximately learned the optimal decision making of the task. The simulation results show that by employing our algorithm, the learning speed is improved.","","978-1-4244-4808-1","10.1109/CIRA.2009.5423179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5423179","","Context modeling;Decision making;Layout;Focusing;Convergence;Information filtering;Information filters;Robot sensing systems;Bayesian methods;Humans","decision making;image processing;optimisation","speeding up topdown attention control;full observation knowledge;mathematical description;context extraction;attention focus;decision making;coarse blurry representation;motory actions;offline optimization step;Bayesian networks;visual information","","1","","16","","1 Mar 2010","","","IEEE","IEEE Conferences"
"A Model-Free Algorithm to Safely Approach the Handling Limit of an Autonomous Racecar","A. Wischnewski; J. Betz; B. Lohmann","Chair of Automatic Control, Technical University of Munich,Munich,Germany; Chair of Automotive Technology, Technical University of Munich,Munich,Germany; Chair of Automatic Control, Technical University of Munich,Munich,Germany","2019 IEEE International Conference on Connected Vehicles and Expo (ICCVE)","23 Jan 2020","2019","","","1","6","One of the key aspects in racing is the ability of the driver to find the handling limits of the vehicle to minimize the resulting lap time. Many approaches for raceline optimization assume the tire-road friction coefficient to be known. However, this neglects the fact that the ability of the system to realize such a race trajectory depends on complex interdependencies between the online trajectory planner, the control systems and the non-modelled uncertainties. In general, a high quality control system can approach the physical limit more reliable, as it applies less corrective actions. We present a model-free learning method to find the minimum achievable lap-time for a given controller using online adaption of a scale factor for the maximum longitudinal and lateral accelerations in the online trajectory planner. In contrast to existing concepts, our approach can be applied as an extension to already available planning and control algorithms instead of replacing them. We demonstrate reliable and safe operation for different vehicle setups in simulation and demonstrate that the algorithm works successfully on a full-size racecar.","2378-1297","978-1-7281-0142-2","10.1109/ICCVE45908.2019.8965218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8965218","Autonomous Racing;Learning Control;Model-Free","","learning systems;minimisation;path planning;position control;quality control;road safety;road vehicles;trajectory control;tyres","model-free algorithm;safely approach;raceline optimization;tire-road friction coefficient;race trajectory;complex interdependencies;online trajectory planner;nonmodelled uncertainties;high quality control system;physical limit;model-free learning method;full-size racecar;autonomous racecar handling limit;vehicle setups;lap time minimization","","1","","15","","23 Jan 2020","","","IEEE","IEEE Conferences"
"Prospective Optimization","T. J. Sejnowski; H. Poizner; G. Lynch; S. Gepshtein; R. J. Greenspan","Salk Inst. for Biol. Sci., Howard Hughes Med. Inst., Howard, WI, USA; Inst. for Neural Comput., Univ. of California at San Diego, La Jolla, CA, USA; Dept. of Psychiatry & Human Behavior, Univ. of California at Irvine, Irvine, CA, USA; Syst. Neurobiol. Labs., Univ. of California at San Diego, La Jolla, CA, USA; Kavli Inst. for Brain & Mind, Univ. of California at San Diego, La Jolla, CA, USA","Proceedings of the IEEE","29 Apr 2014","2014","102","5","799","811","Human performance approaches that of an ideal observer and optimal actor in some perceptual and motor tasks. These optimal abilities depend on the capacity of the cerebral cortex to store an immense amount of information and to flexibly make rapid decisions. However, behavior only approaches these limits after a long period of learning while the cerebral cortex interacts with the basal ganglia, an ancient part of the vertebrate brain that is responsible for learning sequences of actions directed toward achieving goals. Progress has been made in understanding the algorithms used by the brain during reinforcement learning, which is an online approximation of dynamic programming. Humans also make plans that depend on past experience by simulating different scenarios, which is called prospective optimization. The same brain structures in the cortex and basal ganglia that are active online during optimal behavior are also active offline during prospective optimization. The emergence of general principles and algorithms for goal-directed behavior has consequences for the development of autonomous devices in engineering applications.","1558-2256","","10.1109/JPROC.2014.2314297","U.S. Office of Naval Research (ONR); National Institutes of Health; National Science Foundation (NSF); Howard Hughes Medical Institute; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6803897","Basal ganglia;cerebral cortex;classical conditioning;dynamic programming;hippocampus;ideal observer;limbic system;optimization;reinforcement learning;temporal-difference learning;Basal ganglia;cerebral cortex;classical conditioning;dynamic programming;hippocampus;ideal observer;limbic system;optimization;reinforcement learning;temporal-difference learning","Basal ganglia;Optimization;Learning (artificial intelligence);Observers;Brain modeling;Uncertainty;Educational institutions","brain models;cognition;neurophysiology","prospective optimization;human performance;perceptual tasks;motor tasks;cerebral cortex;basal ganglia;vertebrate brain;action sequences;reinforcement learning;dynamic programming approximation;past experience;optimal behavior;goal directed behavior","","10","","86","","22 Apr 2014","","","IEEE","IEEE Journals"
"Ensemble Bootstrapped Deep Deterministic Policy Gradient for Vision-Based Robotic Grasping","W. Liu; L. Peng; J. Cao; X. Fu; Y. Liu; Z. Pan; J. Yang","Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; China Research and Development Academy of Machinery Equipment, Beijing, China","IEEE Access","3 Feb 2021","2021","9","","19916","19925","With sufficient practice, humans can grab objects they have never seen before through brain decision-making. However, the manipulators, which has a wide range of applications in industrial production, can still only grab specific objects. Because most of the grasp algorithms rely on prior knowledge such as hand-eye calibration results, object model features, and can only target specific types of objects. When the task scenario and the operation target change, it cannot perform effective redeployment. In order to solve the above problems, academia often uses reinforcement learning to train grasping algorithms. However, the method of reinforcement learning in the field of manipulators grasping mainly encounters these main problems: insufficient sample utilization, poor algorithm stability, and limited exploration. This article uses LfD, BC, and DDPG to improve sample utilization. Use multiple critics to integrate and evaluate input actions to solve the problem of algorithm instability. Finally, inspired by Thompson's sampling idea, the input action is evaluated from different angles, which increases the algorithm's exploration of the environment and reduces the number of interactions with the environment. EDDPG and EBDDPG algorithm is designed in the article. In order to further improve the generalization ability of the algorithm, this article does not use extra information that is difficult to obtain directly on the physical platform, such as the real coordinates of the target object and the continuous motion space at the end of the manipulator in the Cartesian coordinate system is used as the output of the decision. The simulation results show that, under the same number of interactions, the manipulators' success rate in grabbing 1000 random objects has increased more than double and reached state-of-the-art(SOTA) performance.","2169-3536","","10.1109/ACCESS.2021.3049860","Guangdong Provincial Key R&D Programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9316755","Robotic grasping;reinforcement learning;ensemble learning;Thompson sampling","Grasping;Robot kinematics;Manipulators;Reinforcement learning;Training;Task analysis;Markov processes","decision making;deep learning (artificial intelligence);manipulators;object detection;robot vision","ensemble bootstrapped deep deterministic policy gradient;vision-based robotic grasping;reinforcement learning;Thompson sampling;manipulators;continuous motion space;Cartesian coordinate system","","","","23","CCBY","8 Jan 2021","","","IEEE","IEEE Journals"
"A fluid dynamics approach for self-reconfiguration planning of modular robots","E. Masehian; H. Ahmadzadeh","Faculty of Engineering, Tarbiat Modares University, Tehran, Iran; Faculty of Engineering, Tarbiat Modares University, Tehran, Iran","2015 3rd RSI International Conference on Robotics and Mechatronics (ICROM)","4 Jan 2016","2015","","","139","145","Modular Robotic Systems (MRS) are arrays of interconnected simple robots which can change their morphology in order to perform various tasks. In modular robotics, Self-Reconfiguration Planning (SRP) is the problem of finding a sequence of module-level actions to transform an MRS from an initial configuration into a goal configuration considering modules' kinematic constraints. SRP is very challenging problem as its solution approaches have to deal with exponential growth of configuration space, preserve connectedness of modular robot structure, and avoid deadlock configurations. SRP is proved to be NP-Complete and thus its solution methods generally suffer from limited scalability. In this paper, we introduce a novel approach for solving SRP inspired from the behavior of incompressible fluids in assuming shape of containers. Our approach formulates a given SRP problem as virtual casting model called Corresponding Casting Model (CCM) in which modules (as fluid cells) flow and fill a virtual mold analogous to the goal configuration. We also propose an SRP planning engine called Incompressible Fluid Flow (IFF) engine which computationally solves the CCM model and generates SRP plans. The proposed approach is independent from configuration space, and does not require explicit connectivity checking of modules. As it is shown and verified by the complexity analysis and simulation results, the proposed IFF engine can solve an SRP problem in O(n) time and thus is highly scalable to SRP problems with many modules.","","978-1-4673-7234-3","10.1109/ICRoM.2015.7367774","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367774","Modular Robots;Self-Reconfiguration Planning;Flow;Fluid Dynamics","Robots;Planning;Casting;Solids;Fluid dynamics","computational complexity;fluid dynamics;path planning;robot kinematics","fluid dynamics approach;self-reconfiguration planning;MRS;modular robotic system;SRP;kinematic constraints;configuration space;NP-complete problem;modular robot structure;corresponding casting model;virtual casting model;goal configuration;incompressible fluid flow;IFF engine;time complexity","","","","30","","4 Jan 2016","","","IEEE","IEEE Conferences"
"Analyzing EEG signals using the probability estimating guarded neural classifier","T. Felzer; B. Freisieben","Dept. of Math. & Comput. Sci., Marburg Univ., Germany; Dept. of Math. & Comput. Sci., Marburg Univ., Germany","IEEE Transactions on Neural Systems and Rehabilitation Engineering","30 Jan 2004","2003","11","4","361","371","This paper introduces a neural network architecture for classifying feature vectors symbolizing portions (or segments) of an electroencephalogram (EEG) trace of a human subject. This classification task is the one that is typically required when developing a so-called brain-computer interface (BCI), which analyzes the EEG signals of a subject in order to ""understand"" the subject's thoughts. However, instead of merely saying which ""category of thoughts"" (i.e., which class) the respective input feature vector belongs to, the network described here estimates the probabilities of an EEG segment being associated with each individual class. The network, which is called PeGNC (for probability estimating guarded neural classifier), is tested with two kinds of experiments. In the first experiment, the /spl alpha/-rhythm associated with a human subject closing the eyes is detected online with the help of a frequency-based representation. Since the EEG signal is, in general, always a mixture of numerous action potentials generated simultaneously and it is, thus, very likely that mental activities result in overlapping classes, it is reasonable to believe that the PeGNC network - which does not select any one single class, but determines probability values for each mental category - is particularly suitable for this kind of EEG analysis. The second experiment deals with this issue on the basis of an offline analysis of simulated data.","1558-0210","","10.1109/TNSRE.2003.819785","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1261746","","Signal analysis;Electroencephalography;Humans;Biological neural networks;Brain computer interfaces;Testing;Eyes;Frequency;Signal generators;Data analysis","electroencephalography;neurophysiology;bioelectric potentials;neural net architecture;user interfaces","EEG signals;probability estimating guarded neural classifier;neural network architecture;electroencephalogram;brain-computer interface;feature vector;action potentials;mental activities","Adult;Algorithms;Artificial Intelligence;Brain;Cognition;Electroencephalography;Evoked Potentials;Humans;Male;Models, Neurological;Models, Statistical;Neural Networks (Computer);Reproducibility of Results;Sensitivity and Specificity;User-Computer Interface","33","","30","","30 Jan 2004","","","IEEE","IEEE Journals"
"Reinforcement Learning Controller Design for Affine Nonlinear Discrete-Time Systems using Online Approximators","Q. Yang; S. Jagannathan","State Key Laboratory of Industrial Control Technology, Department of Control Science and Engineering, Zhejiang University, Hangzhou, China; Department of Electrical and Computer Engineering, Missouri University of Science and Technology (formerly, University of Missouri–Rolla), Rolla, MO, USA","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","15 Mar 2012","2012","42","2","377","390","In this paper, reinforcement learning state- and output-feedback-based adaptive critic controller designs are proposed by using the online approximators (OLAs) for a general multi-input and multioutput affine unknown nonlinear discretetime systems in the presence of bounded disturbances. The proposed controller design has two entities, an action network that is designed to produce optimal signal and a critic network that evaluates the performance of the action network. The critic estimates the cost-to-go function which is tuned online using recursive equations derived from heuristic dynamic programming. Here, neural networks (NNs) are used both for the action and critic whereas any OLAs, such as radial basis functions, splines, fuzzy logic, etc., can be utilized. For the output-feedback counterpart, an additional NN is designated as the observer to estimate the unavailable system states, and thus, separation principle is not required. The NN weight tuning laws for the controller schemes are also derived while ensuring uniform ultimate boundedness of the closed-loop system using Lyapunov theory. Finally, the effectiveness of the two controllers is tested in simulation on a pendulum balancing system and a two-link robotic arm system.","1941-0492","","10.1109/TSMCB.2011.2166384","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6025310","Adaptive critic;dynamic programming (DP);Lyapunov method;neural networks (NNs);online approximators (OLAs);online learning;reinforcement learning","Artificial neural networks;Cost function;Learning;Approximation error;Mathematical model;Equations","adaptive control;approximation theory;closed loop systems;control system synthesis;discrete time systems;dynamic programming;learning systems;Lyapunov methods;neurocontrollers;nonlinear control systems;state feedback","reinforcement learning controller design;online approximators;output feedback based adaptive critic controller designs;state feedback based adaptive critic controller designs;multiinput affine unknown nonlinear discrete time systems;multioutput affine unknown nonlinear discrete time systems;critic network;neural networks;heuristic dynamic programming;recursive equations;radial basis functions;splines;fuzzy logic;NN weight tuning laws;closed loop system;Lyapunov theory;pendulum balancing system;two-link robotic arm system","","105","","31","","23 Sep 2011","","","IEEE","IEEE Journals"
"Path planning for mobile robots using an improved reinforcement learning scheme","R. Kurozumi; S. Fujisawa; T. Yamamoto; Y. Suita","Hiroshima Univ., Japan; NA; NA; NA","Proceedings of the 41st SICE Annual Conference. SICE 2002.","29 Apr 2003","2002","4","","2178","2183 vol.4","The current method for establishing travel routes provides modeled environmental information. However, it is difficult to create an environment model for the environments in which mobile robot travel because the environment changes constantly due to the existence of moving objects, Including pedestrians. In this study, we propose a path planning system for mobile robots using reinforcement-learning systems and cerebellar model articulation controllers (CMACs). We selected the best travel route utilizing these reinforcement-learning systems. When a CMAC learns the value function of Q-learning, it improves learning speed by utilizing the generalizing action. CMACs enable us to reduce the time needed to select the best travel route. Using simulation and real robots, we performed a path-planning experiment. We report the results of simulation and experiment on traveling by online learning.","","0-7803-7631-5","10.1109/SICE.2002.1195737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1195737","","Path planning;Mobile robots;Orbital robotics;Gravity;Presses;Learning systems;Equations","mobile robots;path planning;learning (artificial intelligence);cerebellar model arithmetic computers;optimisation","path planning;mobile robots;reinforcement learning scheme;environmental information;pedestrians;reinforcement-learning systems;CMAC;cerebellar model articulation controllers;Q-learning;online learning","","3","","7","","29 Apr 2003","","","IEEE","IEEE Conferences"
"Sequential Decision Making With Limited Observation Capability: Application to Wireless Networks","K. Kaza; R. Meshram; V. Mehta; S. N. Merchant","Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India; University of Waterloo, Waterloo, Canada; Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India; Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India","IEEE Transactions on Cognitive Communications and Networking","10 Jun 2019","2019","5","2","237","251","This paper studies a generalized class of restless multi-armed bandits with hidden states and allow cumulative feedback, as opposed to the conventional instantaneous feedback. We call them lazy restless bandits (LRBs) as the events of decision making are sparser than the events of state transition. Hence, feedback after each decision event is the cumulative effect of the following state transition events. The states of arms are hidden from the decision maker and rewards for actions are state dependent. The decision maker needs to choose one arm in each decision interval, such that the long-term cumulative reward is maximized. As the states are hidden, the decision maker maintains and updates its belief about them. It is shown that LRBs admit an optimal policy which has threshold structure in belief space. The Whittle-index policy for solving the LRB problem is analyzed; indexability of LRBs is shown. Further, the closed-form index expressions are provided for two sets of special cases; for more general cases, an algorithm for index computation is provided. An extensive simulation study is presented; Whittle-index, modified Whittle-index, and myopic policies are compared. The Lagrangian relaxation of the problem provides an upper bound on the optimal value function; it is used to assess the degree of sub-optimality various policies.","2332-7731","","10.1109/TCCN.2019.2898000","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8636263","Sequential decision making;weakly coupled partially observable Markov decision processes;restless bandits;cumulative feedback;dynamic programming;Whittle index;relay selection","Indexes;Relays;Decision making;Markov processes;Fading channels;Optimization;Productivity","decision making;multi-agent systems;network theory (graphs)","state transition events;Whittle-index policy;closed-form index expressions;sequential decision making;limited observation capability;restless multiarmed bandits;cumulative feedback;lazy restless bandits;wireless networks","","2","","46","","6 Feb 2019","","","IEEE","IEEE Journals"
"Adaptation learning control scheme for a high performance permanent magnet stepper motor using online random training of neural networks","A. Rubaai; R. Kotaru","Dept. of Electr. Eng., Howard Univ., Washington, DC, USA; NA","Conference Record of the 1999 IEEE Industry Applications Conference. Thirty-Forth IAS Annual Meeting (Cat. No.99CH36370)","6 Aug 2002","1999","4","","2386","2392 vol.4","This paper addresses the problem of controlling the speed of a permanent magnet stepper motor assumed to operate in a high-performance drives environment. An artificial neural network control scheme which uses continual on-line random training (with no off-line training) to simultaneously identify and adaptively control the speed of the stepper motor is proposed. The control scheme utilizes two three-layer feed-forward artificial neural networks: (1) a tracker identification neural network which captures the nonlinear dynamics of the motor over any arbitrary time interval in its range of operation and (2) a controller neural network to provide the necessary control actions to achieve trajectory tracking of the motor speed. The inputs to the controller neural network are not constructed from the actual motor/load dynamics, but as a feedback signal, from the estimated state variables of the motor supplied by the neural identifier and the reference trajectory to be tracked by the actual speed. This paper also makes use of a very realistic and practical scheme to estimate and adaptively learn the noise content in the speed-load torque characteristic of the motor. Simulations reveal that the neuro-controller adapts and generalizes its learning rate to a wide variety of loads, in addition to providing the necessary abstraction when measurements are contaminated with noise.","0197-2618","0-7803-5589-X","10.1109/IAS.1999.799176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=799176","","Artificial neural networks;Neural networks;Permanent magnet motors;Feedforward neural networks;Trajectory;Feedforward systems;Neurofeedback;State feedback;Signal processing;State estimation","permanent magnet motors;stepping motors;machine control;adaptive control;learning (artificial intelligence);neurocontrollers;feedforward neural nets;feedback","adaptation learning control scheme;high performance permanent magnet stepper motor;online random training;neural networks;speed control;high-performance drives environment;artificial neural network control;continual on-line random training;off-line training;three-layer feed-forward artificial neural networks;tracker identification neural network;nonlinear dynamics;controller neural network;motor speed trajectory tracking;load dynamics;feedback signal;estimated state variables;neural identifier;noise content;speed-load torque characteristic;neuro-controller","","","2","17","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Data-Driven Nonlinear Near-Optimal Regulation Based on Multi-Dimensional Taylor Network Dynamic Programming","Q. Sun; C. Zhang; N. Jiang; J. Yu; L. Xu","College of Information Science and Technology, Nanjing Forestry University, Nanjing, China; School of Electrical Engineering and Automation, Henan Institute of Technology, Xinxiang, China; Department of Economics and Management, Nanjing Tech University, Nanjing, China; China Railway Shanghai Design Institute Group Co., Ltd., Shanghai, China; College of Information Science and Technology, Nanjing Forestry University, Nanjing, China","IEEE Access","28 Feb 2020","2020","8","","36476","36484","Using the data-driven control formulation, an iterative dynamic programming approach which is based on a multi-dimensional Taylor network is established to design the near optimal regulation of discrete-time nonlinear systems. For discrete-time general nonlinear systems, the iterative adaptive dynamic programming algorithm is developed and proved to guarantee the property of convergence and optimality. Three networks are constructed, namely, the identification network, critic network and action network. Moreover, a globalized dual heuristic programming technique with detailed implementation is developed. The cost function and its derivative can be approximated by this novel architecture. Besides, without the consideration of the system dynamics, this technique can learn the near-optimal control law simultaneously and adaptively. In addition, this technique greatly improves the existing results of the iterative adaptive dynamic programming algorithm in terms of reducing the requirement of the control matrix. Furthermore, because of the approach that is based on the multi-dimensional Taylor network, the amount of calculation needed is also greatly reduced. The simulation experiment is described to illustrate the effectiveness of the data-driven optimal regulation method proposed in this paper.","2169-3536","","10.1109/ACCESS.2020.2975391","Natural Science Foundation of the Higher Education Institutions of Jiangsu Province, China; Nanjing Forestry University; High-Level Talent Research Foundation of Henan Institute of Technology; Special Research and Promotion Program of Henan Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9004604","Adaptive dynamic programming;data-driven control;multi-dimensional Taylor network;nonlinear control","Optimal control;Cost function;Dynamic programming;Heuristic algorithms;Nonlinear systems;Approximation algorithms","continuous time systems;discrete time systems;dynamic programming;heuristic programming;iterative methods;neurocontrollers;nonlinear control systems;optimal control","multidimensional Taylor network dynamic programming;data-driven control formulation;iterative dynamic programming;discrete-time general nonlinear systems;iterative adaptive dynamic programming algorithm;globalized dual heuristic programming technique;near-optimal control law;data-driven optimal regulation method;data-driven nonlinear near-optimal regulation","","2","","40","CCBY","20 Feb 2020","","","IEEE","IEEE Journals"
"A Nearer Optimal and Faster Trained Value Iteration ADP for Discrete-Time Nonlinear Systems","J. Hu; G. Yang; Z. Hou; G. Zhang; W. Yang; W. Wang","College of Mechanical and Electrical Engineering, Central South University, Changsha, China; College of Mechanical and Electrical Engineering, Central South University, Changsha, China; Guangzhou Institute of Advanced Technology, Chinese Academy of Sciences, Guangzhou, China; Guangzhou Institute of Advanced Technology, Chinese Academy of Sciences, Guangzhou, China; Guangzhou Institute of Advanced Technology, Chinese Academy of Sciences, Guangzhou, China; Guangzhou Institute of Advanced Technology, Chinese Academy of Sciences, Guangzhou, China","IEEE Access","26 Jan 2021","2021","9","","14933","14944","Adaptive dynamic programming (ADP) is generally implemented using three neural networks: model network, action network, and critic network. In the conventional works of the value iteration ADP, the model network is initialized randomly and trained by the backpropagation algorithm, whose results are easy to get trapped in a local minimum; both the critic network and action network are trained in each outer-loop, which is time-consuming. To approximate the optimal control policy more accurately and decrease the value iteration ADP training time, we propose a nearer optimal and faster trained value iteration ADP for discrete-time nonlinear systems in this study. First, before training the model network with a backpropagation algorithm, we use a global searching method, i.e., genetic algorithm, to evolve the weights and biases of the neural network for a few generations. Second, in the outer-loop training process, we propose a trigger mechanism to decide whether to train the action network or not, which can save much training time. Examples of both linear and nonlinear systems are induced to verify the superiority of the proposed method compared with the conventional value iteration ADP. The simulation results show that the proposed algorithm can provide a nearer optimal control policy and save more training time than the conventional value iteration ADP.","2169-3536","","10.1109/ACCESS.2021.3051984","China Postdoctoral Science Foundation; Natural Science Foundation of Guangdong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9326299","ADP;value iteration;genetic algorithm;trigger mechanism","Neural networks;Training;Biological cells;Approximation algorithms;Nonlinear systems;Heuristic algorithms;Genetic algorithms","adaptive control;backpropagation;discrete time systems;dynamic programming;genetic algorithms;iterative methods;learning (artificial intelligence);neurocontrollers;nonlinear control systems;optimal control","faster trained value;ADP training time;approximate the optimal control policy;critic network;model network;adaptive dynamic programming;discrete-time nonlinear systems;nearer optimal control policy;conventional value;action network;outer-loop training process;neural network;backpropagation algorithm","","","","34","CCBY","18 Jan 2021","","","IEEE","IEEE Journals"
"Acting under uncertainty: discrete Bayesian models for mobile-robot navigation","A. R. Cassandra; L. P. Kaelbling; J. A. Kurien","Dept. of Comput. Sci., Brown Univ., Providence, RI, USA; NA; NA","Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems. IROS '96","6 Aug 2002","1996","2","","963","972 vol.2","Discrete Bayesian models have been used to model uncertainty for mobile-robot navigation, but the question of how actions should be chosen remains largely unexplored. This paper presents the optimal solution to the problem, formulated as a partially observable Markov decision process. Since solving for the optimal control policy is intractable, in general, it goes on to explore a variety of heuristic control strategies. The control strategies are compared experimentally, both in simulation and in runs on a robot.","","0-7803-3213-X","10.1109/IROS.1996.571080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=571080","","Uncertainty;Bayesian methods;Navigation;Robot kinematics;Robot sensing systems;Mobile robots;Predictive models;Probability distribution;Orbital robotics;Computer science","navigation;uncertainty handling;Bayes methods;Markov processes;decision theory;mobile robots;path planning","acting under uncertainty;discrete Bayesian models;mobile-robot navigation;partially observable Markov decision process;heuristic control strategies","","144","2","19","","6 Aug 2002","","","IEEE","IEEE Conferences"
"BaRC: Backward Reachability Curriculum for Robotic Reinforcement Learning","B. Ivanovic; J. Harrison; A. Sharma; M. Chen; M. Pavone","Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, 94305, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, 94305, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, 94305, USA; School of Computing Science, Simon Fraser University, Burnaby, BC, V5A 1S6, Canada; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, 94305, USA","2019 International Conference on Robotics and Automation (ICRA)","12 Aug 2019","2019","","","15","21","Model-free Reinforcement Learning (RL) offers an attractive approach to learn control policies for high dimensional systems, but its relatively poor sample complexity often necessitates training in simulated environments. Even in simulation, goal-directed tasks whose natural reward function is sparse remain intractable for state-of-the-art model-free algorithms for continuous control. The bottleneck in these tasks is the prohibitive amount of exploration required to obtain a learning signal from the initial state of the system. In this work, we leverage physical priors in the form of an approximate system dynamics model to design a curriculum for a model-free policy optimization algorithm. Our Backward Reachability Curriculum (BaRC) begins policy training from states that require a small number of actions to accomplish the task, and expands the initial state distribution backwards in a dynamically-consistent manner once the policy optimization algorithm demonstrates sufficient performance. BaRC is general, in that it can accelerate training of any model-free RL algorithm on a broad class of goal-directed continuous control MDPs. Its curriculum strategy is physically intuitive, easy-to-tune, and allows incorporating physical priors to accelerate training without hindering the performance, flexibility, and applicability of the model-free RL algorithm. We evaluate our approach on two representative dynamic robotic learning problems and find substantial performance improvement relative to previous curriculum generation techniques and naive exploration strategies.","2577-087X","978-1-5386-6027-0","10.1109/ICRA.2019.8794206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794206","","Robots;Task analysis;Training;Computational modeling;Heuristic algorithms;Complexity theory;Approximation algorithms","learning (artificial intelligence);Markov processes;optimisation;path planning;robots","BaRC;initial state distribution backwards;model-free RL algorithm;goal-directed continuous control MDPs;curriculum strategy;representative dynamic robotic learning problems;goal-directed tasks;learning signal;model-free policy optimization algorithm;backward reachability curriculum;curriculum generation techniques;robotic reinforcement learning;model-free reinforcement learning;model-free algorithms;reward function;exploration strategies","","3","","43","","12 Aug 2019","","","IEEE","IEEE Conferences"
"Can a Robot Become a Movie Director? Learning Artistic Principles for Aerial Cinematography","M. Gschwindt; E. Camci; R. Bonatti; W. Wang; E. Kayacan; S. Scherer","Technische Universität München (TUM),Department of Computer Science,Munich,Germany; Nanyang Technological University (NTU), 50 Nanyang Avenue,School of Mechanical and Aerospace Engineering (MAE),Singapore,639798; Carnegie Mellon University,The Robotics Institute, School of Computer Science,Pittsburgh,PA; Carnegie Mellon University,The Robotics Institute, School of Computer Science,Pittsburgh,PA; Aarhus University,Department of Engineering,Aarhus C,Denmark,DK-8000; Carnegie Mellon University,The Robotics Institute, School of Computer Science,Pittsburgh,PA","2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","28 Jan 2020","2019","","","1107","1114","Aerial filming is constantly gaining importance due to the recent advances in drone technology. It invites many intriguing, unsolved problems at the intersection of aesthetical and scientific challenges. In this work, we propose a deep reinforcement learning agent which supervises motion planning of a filming drone by making desirable shot mode selections based on aesthetical values of video shots. Unlike most of the current state-of-the-art approaches that require explicit guidance by a human expert, our drone learns how to make favorable viewpoint selections by experience. We propose a learning scheme that exploits aesthetical features of retrospective shots in order to extract a desirable policy for better prospective shots. We train our agent in realistic AirSim simulations using both a hand-crafted reward function as well as reward from direct human input. We then deploy the same agent on a real DJI M210 drone in order to test the generalization capability of our approach to real world conditions. To evaluate the success of our approach in the end, we conduct a comprehensive user study in which participants rate the shot quality of our methods. Videos of the system in action can be seen at https://youtu.be/qmVw6mfyEmw.","2153-0866","978-1-7281-4004-9","10.1109/IROS40897.2019.8967592","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8967592","","","aerospace robotics;cinematography;path planning;remotely operated vehicles;robot programming;supervised learning","movie director;artistic principles;aerial cinematography;drone technology;deep reinforcement learning agent;video shots;realistic AirSim simulations;DJI M210 drone;supervised motion planning;aerial filming drone","","4","","37","","28 Jan 2020","","","IEEE","IEEE Conferences"
"Nonlinear neural network internal model control with fuzzy adjustable parameter","X. P. Chen; Ding Ke; Li Wei; Duxiaoning","Dept. of Eng. Control, Gansu Univ. of Technol., Lanzhou, China; NA; NA; NA","Proceedings of the IEEE International Conference on Industrial Technology (ICIT'96)","6 Aug 2002","1996","","","834","838","A novel nonlinear internal model control (NIMC) strategy based on neural network is proposed. The neural network is trained from system input-output data using a conjugate gradient algorithm to speed-up the convergence. The NIMC controller consists of a model inverse controller and a robust filter with single adjustable parameter. Two alternative control schemes, direct and indirect control, are discussed and improved. In the direct control, the neural network (controller) is used as a inverse process dynamics whose output is explicitly calculated as control action. On the contrary, the indirect control calculates the control action by directly inverting the network describing the process dynamics and thus constructs a rigorous inverse process model. To accommodate general uncertainty descriptions and ensure offset-free performance, a fuzzy neural network is proposed here. Two highly nonlinear processes, an exothermic stirred tank reactor and pH neutralization, are simulated to demonstrate the effectiveness of the strategy proposed. Extensions for measured disturbances are also presented.","","0-7803-3104-4","10.1109/ICIT.1996.601716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=601716","","Neural networks;Fuzzy control;Fuzzy neural networks;Nonlinear control systems;Robustness;Inverse problems;Filters;Feedforward neural networks;Robust control;Signal processing","nonlinear control systems;neurocontrollers;fuzzy control;fuzzy neural nets;conjugate gradient methods;process control;dynamics;chemical industry","fuzzy neural network;nonlinear internal model control;fuzzy adjustable parameter;conjugate gradient algorithm;convergence;model inverse controller;robust filter;direct control;indirect control;process dynamics;exothermic stirred tank reactor;pH neutralization","","","10","10","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Least mean p-power extreme learning machine for obstacle avoidance of a mobile robot","Jing Yang; Pengpeng Chen; Hai-Jun Rong; Badong Chen","Institute of Control Engineering, School of Electronic and Information Engineering, Xi'an Jiaotong University, China 710049; Institute of Control Engineering, School of Electronic and Information Engineering, Xi'an Jiaotong University, China 710049; State Key Laboratory for Strength and Vibration of Mechanical Structures, School of Aerospace, Xi'an Jiaotong University, China 710049; Institute of Artificial Intelligence and Robotics, School of Electronic and Information Engineering, Xi'an Jiaotong University, China 710049","2016 International Joint Conference on Neural Networks (IJCNN)","3 Nov 2016","2016","","","1968","1976","This paper proposes an obstacle avoidance method for navigation of a mobile robot in uncertain environments based on a novel neural learning algorithm, namely least mean p-norm extreme learning machine (LMP-ELM) and Q-learning. The proposed obstacle avoidance method comprises of two behavior modules, Viz., an avoidance behavior and goal-seeking behavior. At the learning phase, the two modules are independently designed using the proposed LMP-ELM and Q-Learning. And then they are combined to navigate the mobile to the goal position without colliding with obstacles based on a switching function at the running phase. The LMP-ELM is used to realize the state-action mapping of the Q-learning. In the novel LMP-ELM, the computationally simple extreme learning machine architecture is maintained but a novel error criterion, namely the least mean p-power (LMP) error criterion provides a mechanism to update the output weights sequentially. The LMP error criterion aims to minimize the mean p-power of the error that is the generalization of the mean square error criterion used in the ELM. The effectiveness of the proposed method is verified by a series of simulations.","2161-4407","978-1-5090-0620-5","10.1109/IJCNN.2016.7727441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727441","","Mobile robots;Robot kinematics;Collision avoidance;Robot sensing systems;Force","collision avoidance;control engineering computing;learning (artificial intelligence);least mean squares methods;mobile robots;neurocontrollers","obstacle avoidance;mobile robot navigation;neural learning algorithm;least mean p-norm extreme learning machine;LMP-ELM;Q-learning;avoidance behavior;goal-seeking behavior;function switching;phase running;mean square error criterion","","","","27","","3 Nov 2016","","","IEEE","IEEE Conferences"
"iX-BSP: Belief Space Planning through Incremental Expectation","E. I. Farhi; V. Indelman","Technion Autonomous Systems Program (TASP), Technion - Israel Institute of Technology, Haifa, 32000, Israel; Department of Aerospace Engineering, Technion - Israel Institute of Technology, Haifa, 32000, Israel","2019 International Conference on Robotics and Automation (ICRA)","12 Aug 2019","2019","","","7180","7186","Belief space planning (BSP) is a fundamental problem in robotics. Determining an optimal action quickly grows intractable as it involves calculating the expected accumulated cost (reward), where the expectation accounts for all future measurement realizations. State of the art approaches therefore resort to simplifying assumptions and approximations to reduce computational complexity. Importantly, while in robotics re-planning is essential, these approaches calculate each planning session from scratch. In this work we contribute a novel approach, iX-BSP, that is based on the key insight that calculations in consecutive planning sessions are similar in nature and can be thus re-used. Our approach performs incremental calculation of the expectation by appropriately re-using computations already performed in a precursory planing session while accounting for the information obtained in inference between the two planning sessions. The formulation of our approach considers general distributions and accounts for data association aspects. We evaluate iX-BSP in statistical simulation and show that incremental expectation calculations significantly reduce runtime without impacting performance.","2577-087X","978-1-5386-6027-0","10.1109/ICRA.2019.8793548","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8793548","","Planning;Current measurement;Robots;Uncertainty;History;Time measurement;Linear programming","computational complexity;mobile robots;path planning;statistical analysis","robotics replanning;statistical simulation;incremental expectation calculations;planning session;computational complexity;belief space planning;iX-BSP","","1","","27","","12 Aug 2019","","","IEEE","IEEE Conferences"
"Health-aware Optimization-based Control Design: Application to Autonomous Racing based State of Charge","F. K. Pour; D. Theilliol; V. Puig; G. Cembrano","Universite de Lorraine, CRAN, CNRS, UMR 7039, Campus Sciences, B.P. 70239, Vandoeuvre-les-Nancy, 54506, Cedex France; Universite de Lorraine, CRAN, CNRS, UMR 7039, Campus Sciences, B.P. 70239, Vandoeuvre-les-Nancy, 54506, Cedex France; Universite de Lorraine, CRAN, CNRS, UMR 7039, Campus Sciences, B.P. 70239, Vandoeuvre-les-Nancy, 54506, Cedex France; Universite de Lorraine, CRAN, CNRS, UMR 7039, Campus Sciences, B.P. 70239, Vandoeuvre-les-Nancy, 54506, Cedex France","2019 4th Conference on Control and Fault Tolerant Systems (SysTol)","14 Oct 2019","2019","","","244","249","In this paper, an innovative health-aware control approach is presented for autonomous racing vehicles. Based on a dynamical model of the vehicle, a controller is computed with the general objective is maximize progress on the track subject to win racing and save energy. The main contribution of the paper consists in preserving the state of charge (SoC) and optimizing a lap time to achieve the best path of a racing vehicle. The control design is divided into two parts, path planner and controller. The first optimization problem is related to the path planner where the objective is to optimize the lap time and maximize the SoC to obtain the best trajectory under the constraints of the circuit. The proposed approach is solved by LMI based Model Predictive Control (MPC) driven from Lyapunov stability. The second part is focused on a controller gain synthesis solved by LMI formulation with integral action for tracking the trajectory obtained by the planner. The proposed approach is evaluated in simulation and results show the effectiveness of the proposed planner for optimizing the lap time and especially for maximizing the SoC of the battery.","2162-1209","978-1-7281-0380-8","10.1109/SYSTOL.2019.8864759","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8864759","Autonomous racing;State of Charge;Health monitoring;LMI control design","Batteries;Trajectory;Optimization;State of charge;Kinematics;Predictive control;Integrated circuit modeling","control system synthesis;convex programming;linear matrix inequalities;Lyapunov methods;optimal control;path planning;predictive control;road traffic control;road vehicles;robust control;stability;trajectory control","autonomous racing based state;innovative health-aware control approach;autonomous racing vehicles;racing vehicle;path planner;optimization problem;SoC;controller gain synthesis;LMI based model predictive control;health-aware optimization-based control design;Lyapunov stability;trajectory tracking","","","","19","","14 Oct 2019","","","IEEE","IEEE Conferences"
"Blended local planning for generating safe and feasible paths","Ling Xu; A. Stentz","Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15213, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15213, USA","2008 IEEE/RSJ International Conference on Intelligent Robots and Systems","14 Oct 2008","2008","","","709","716","Many planning approaches adhere to the two-tiered architecture consisting of a long-range, low fidelity global planner and a short-range high fidelity local planner. While this architecture works well in general, it fails in highly constrained environments where the available paths are limited. These situations amplify mismatches between the global and local plans due to the smaller set of feasible actions. We present an approach that dynamically blends local plans online to match the field of global paths. Our blended local planner generates paths from control commands to ensure the safety of the robot as well as achieve the goal. Blending also results in more complete plans than an equivalent unblended planner when navigating cluttered environments. These properties enable the blended local planner to utilize a smaller control set while achieving more efficient planning time. We demonstrate the advantages of blending in simulation using a kinematic car model navigating through maps containing tunnels, cul-de-sacs, and random obstacles.","2153-0866","978-1-4244-2057-5","10.1109/IROS.2008.4651141","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4651141","","Vehicles;Planning;Robots;Kinematics;Mathematical model;Aerospace electronics;Vehicle dynamics","mobile robots;path planning","blended local planning;safe paths generation;two-tiered architecture;low fidelity global planner;short-range high fidelity local planner;cluttered environment navigation;kinematic car model","","","","8","","14 Oct 2008","","","IEEE","IEEE Conferences"
"Event-based optimization with lagged state information","J. Qing-Shan","CFINS, Department of Automation, TNLIST, Tsinghua University, Beijing 100084, P.R. China","Proceedings of the 31st Chinese Control Conference","24 Dec 2012","2012","","","2055","2060","Event-based optimization (EBO) has provided a general framework for many control, decision-making, and optimization problems, where the actions can be taken only when certain events occur. In many large-scale networked systems, the sensors periodically report the system state to a remote center. The long-distant wireless communication usually suffers from random or deterministic delay. It is thus of great practical interest to understand how to solve EBO with such lagged state information. We consider this important problem in this paper, and make the following major contributions. First, we mathematically formulate finite-stage EBO with lagged state information (EBOLSI). Second, we prove that such an EBOLSI can be converted to a partially observable Markov decision process (POMDP) with lagged state information. Then existing exact and approximate solution methods can be applied. Third, we use numerical experiments on evacuation problems to demonstrate the impact of information delay on the performance of the simulation-based policy improvement method in EBOLSI. We hope this work sheds insight on EBOLSI in more general situations.","2161-2927","978-988-15638-1-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6390263","Discrete event dynamic systems;event-based optimization;lagged state information;evacuation","Roads;Delay;Decision making;Optimization;History;Approximation methods;Aerospace electronics","approximation theory;decision making;information theory;Markov processes;optimisation;wireless sensor networks","event-based optimization;lagged state information;decision-making problem;large-scale networked systems;long-distant wireless communication;random delay;deterministic delay;finite-stage EBO;EBOLSI;partially observable Markov decision process;POMDP;exact solution methods;approximate solution methods;information delay;simulation-based policy improvement method","","1","","43","","24 Dec 2012","","","IEEE","IEEE Conferences"
"Target-driven visual navigation in indoor scenes using deep reinforcement learning","Y. Zhu; R. Mottaghi; E. Kolve; J. J. Lim; A. Gupta; L. Fei-Fei; A. Farhadi",Stanford University; Allen Institute for AI; Allen Institute for AI; Stanford University; Allen Institute for AI; Stanford University; Allen Institute for AI,"2017 IEEE International Conference on Robotics and Automation (ICRA)","24 Jul 2017","2017","","","3357","3364","Two less addressed issues of deep reinforcement learning are (1) lack of generalization capability to new goals, and (2) data inefficiency, i.e., the model requires several (and often costly) episodes of trial and error to converge, which makes it impractical to be applied to real-world scenarios. In this paper, we address these two issues and apply our model to target-driven visual navigation. To address the first issue, we propose an actor-critic model whose policy is a function of the goal as well as the current state, which allows better generalization. To address the second issue, we propose the AI2-THOR framework, which provides an environment with high-quality 3D scenes and a physics engine. Our framework enables agents to take actions and interact with objects. Hence, we can collect a huge number of training samples efficiently. We show that our proposed method (1) converges faster than the state-of-the-art deep reinforcement learning methods, (2) generalizes across targets and scenes, (3) generalizes to a real robot scenario with a small amount of fine-tuning (although the model is trained in simulation), (4) is end-to-end trainable and does not need feature engineering, feature matching between frames or 3D reconstruction of the environment.","","978-1-5090-4633-1","10.1109/ICRA.2017.7989381","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7989381","","Navigation;Training;Visualization;Learning (artificial intelligence);Three-dimensional displays;Physics;Robots","learning (artificial intelligence);path planning;robot vision","target-driven visual navigation;indoor scenes;deep reinforcement learning;actor-critic model;AI2-THOR framework;high-quality 3D scenes;physics engine;real robot scenario","","220","","53","","24 Jul 2017","","","IEEE","IEEE Conferences"
