"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"VIVR: Presence of Immersive Interaction for Visual Impairment Virtual Reality","J. Kim","Division of Computer Engineering, Hansung University, Seoul, South Korea","IEEE Access","6 Nov 2020","2020","8","","196151","196159","The immersive virtual reality (VR) to provide a realistic walking experience for the visually impaired is proposed in this study. To achieve this, a novel immersive interaction using a walking aid, i.e., a white cane, is designed. The key structure of the proposed interaction consists of a walking process that enables users with visual impairments to process the ground recognition and inference processes realistically by connecting the white cane to the VR controller. Additionally, a decision-making model using deep learning is proposed to design interactions that can be applied to real-life situations instead of being limited to virtual environment experiences. A learning model is designed that can accurately and efficiently process sensing of braille block, which is an important process in the walking of visually impaired people using a white cane assistance tool. The goal is to implement a white cane walking system that can be used in the real world in addition to a virtual environment. Finally, a survey is conducted to confirm that the proposed immersive interaction provides a walking experience with high presence in virtual reality when compared with the real-world experience. The applicability of the proposed deep-learning-based decision-making model in the real world is verified by its high accuracy in recognition of braille block.","2169-3536","","10.1109/ACCESS.2020.3034363","Hansung University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9241733","Immersive virtual reality;presence;immersive interaction;visual impairment;deep learning","Legged locomotion;Visualization;Haptic interfaces;Solid modeling;Virtual environments;Deep learning","decision making;gait analysis;handicapped aids;learning (artificial intelligence);neural nets;virtual reality","realistic walking experience;immersive interaction;walking aid;walking process;ground recognition;inference processes;VR controller;decision-making;deep learning;virtual environment experiences;braille block;visually impaired people;white cane assistance tool;white cane walking system;real-world experience;visual impairment virtual reality;immersive virtual reality;VIVR","","","","34","CCBY","28 Oct 2020","","","IEEE","IEEE Journals"
"Augmented Reality to Improve Surgical Simulation: Lessons Learned Towards the Design of a Hybrid Laparoscopic Simulator for Cholecystectomy","R. M. Viglialoro; N. Esposito; S. Condino; F. Cutolo; S. Guadagni; M. Gesi; M. Ferrari; V. Ferrari","EndoCAS Center, Department of Translational Research and New Technologies in Medicine and Surgery, University of Pisa, Pisa, Italy; EndoCAS Center, Department of Translational Research and New Technologies in Medicine and SurgeryUniversity of Pisa; EndoCAS Center, Department of Translational Research and New Technologies in Medicine and SurgeryUniversity of Pisa; EndoCAS Center, Department of Translational Research and New Technologies in Medicine and SurgeryUniversity of Pisa; Department of General Surgery UnitCisanello University Hospital AOUP; Department of Translational Research on New Technologies in Medicine and SurgeryUniversity of Pisa; EndoCAS Center, Department of Translational Research and New Technologies in Medicine and SurgeryUniversity of Pisa; EndoCAS Center, Department of Translational Research and New Technologies in Medicine and SurgeryUniversity of Pisa","IEEE Transactions on Biomedical Engineering","21 Jun 2019","2019","66","7","2091","2104","Hybrid surgical simulators based on augmented reality (AR) solutions benefit from the advantages of both the box trainers and the virtual reality simulators. This paper reports on the results of a long development stage of a hybrid simulator for laparoscopic cholecystectomy that integrates real and the virtual components. We first outline the specifications of the AR simulator and then we explain the strategy adopted for implementing it based on a careful selection of its simulated anatomical components, and characterized by a real-time tracking of both a target anatomy and of the laparoscope. The former is tracked by means of an electromagnetic field generator, while the latter requires an additional camera for video tracking. The new system was evaluated in terms of AR visualization accuracy, realism, and hardware robustness. Obtained results show that the accuracy of AR visualization is adequate for training purposes. The qualitative evaluation confirms the robustness and the realism of the simulator. In conclusion, the proposed AR simulator satisfies all the initial specifications in terms of anatomical appearance, modularity, reusability, minimization of spare parts cost, and ability to record surgical errors and to track in real-time the Calot's triangle and the laparoscope. Thus, the proposed system could be an effective training tool for learning the task of identification and isolation of Calot's triangle in laparoscopic cholecystectomy. Moreover, the presented strategy could be applied to simulate other surgical procedures involving the task of identification and isolation of generic tubular structures, such as blood vessels, biliary tree, and nerves, which are not directly visible.","1558-2531","","10.1109/TBME.2018.2883816","Augmented Reality Simulation; Italian Minister of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8550677","Surgical simulator;laparoscopic simulation;augmented reality;hybrid simulators;physical anatomical model;cholecystectomy training","Laparoscopes;Solid modeling;Visualization;Training;Task analysis;Minimally invasive surgery","augmented reality;blood vessels;computer based training;data visualisation;medical computing;surgery;virtual reality","surgical simulation;hybrid laparoscopic simulator;hybrid surgical simulators;virtual reality simulators;hybrid simulator;laparoscopic cholecystectomy;virtual components;AR simulator;simulated anatomical components;real-time tracking;laparoscope;electromagnetic field generator;video tracking;AR visualization accuracy;hardware robustness;surgical errors;Calot's triangle;surgical procedures;augmented reality solutions","","2","","50","","28 Nov 2018","","","IEEE","IEEE Journals"
"Dynamic neural network control through fuzzy Q-learning algorithms","Z. D. Deng; D. P. Kwok","State Key Lab. of Intelligent Tech. & Syst., Tsinghua Univ., Beijing, China; NA","1997 IEEE International Conference on Intelligent Processing Systems (Cat. No.97TH8335)","6 Aug 2002","1997","1","","381","386 vol.1","An efficient Q-learning paradigm implemented on a fuzzy CMAC network is proposed. The fuzzy CMAC network topological architecture is described. First, the continuous states of the system are partitioned into a number of fuzzy boxes. Second, the proposed fuzzy CMAC evaluates the Q-values of agents in the fired fuzzy boxes and chooses control actions with maximum Q-values. Then a critic generates an external reinforcement signal according to the outcome or the effect of the control at every time-step, which is used later for further improving the estimation of these Q-values. To speed up the convergence of reinforcement learning, the traditional PID controller with several groups of different parameters is adopted so as to collect a number of taught-lessons. These taught-lessons together with the experienced lessons generated automatically, are sequentially replayed and learned, respectively, under the guidance of different reinforcement mechanisms. The hybrid adaptive and learning control system is applied to the control of a pH-neutralization process. Simulation investigations show that the fuzzy connectionist Q-learning control system has more adaptive, higher intelligence, and stronger generalization ability compared to neural network or fuzzy neural network control techniques using supervised learning.","","0-7803-4253-4","10.1109/ICIPS.1997.672805","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=672805","","Neural networks;Fuzzy control;Fuzzy neural networks;Automatic control;Fuzzy systems;Programmable control;Adaptive control;Control systems;Partitioning algorithms;Signal generators","cerebellar model arithmetic computers;learning (artificial intelligence);learning systems;neurocontrollers;intelligent control;fuzzy control;fuzzy neural nets;neural net architecture;software agents;pH control;simulation;adaptive systems;generalisation (artificial intelligence)","dynamic neural network control;fuzzy Q-learning algorithms;efficient Q-learning paradigm;fuzzy CMAC network;topological architecture;continuous states;fuzzy boxes;agents;control actions;maximum Q-values;external reinforcement signal;reinforcement learning;convergence;PID controller;taught lesson;hybrid adaptive/learning control system;pH neutralization process control;simulation;fuzzy connectionist Q-learning control system;intelligence;adaptive ability;generalization ability","","3","","17","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Mobile Augmented Reality in Nursing Educational Environments","E. Quqandi; M. Joy; M. Rushton; I. Drumm","Computer Science Department, Warwick University, Coventry, UK; Computer Science Department, Warwick University, Coventry, UK; School of Health and Society, The University of Salford, Manchester, UK; Computer, Science and Engineer, The University of Salford, Manchester, UK","2018 10th Computer Science and Electronic Engineering (CEEC)","28 Mar 2019","2018","","","266","269","The possibility of using Augmented Reality (AR) in learning and training has become more straightforward than before, as a result of the extensive use of Information and Communication Technologies (ICT) in the computer and mobile industries. Even though AR is used in education, and it is generally acknowledged that it has a positive impact on learning outcomes, the value of integrating AR applications into learning environments has not yet been fully investigated [1]. This in progress work considers the integration of AR technology into nursing clinical lab training, introduces new ways of interacting with manikins, and allows students to view patient scenarios instead of relying on teacher explanations. AR allows students to visualize hidden objects such as internal organs, which makes simulations more realistic and immersive. The study investigates the potential of this technology in terms of enhancing nursing students' self-regulation skills.","","978-1-5386-7275-4","10.1109/CEEC.2018.8674182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8674182","Augmented Reality;Mobile Learning;Nursing;Higher Education;Self-learning;Self-Regulation;Clinical skills","Medical services;Education;Augmented reality;Three-dimensional displays;Solid modeling;Videos;Task analysis","augmented reality;biomedical education;computer aided instruction;medical computing;mobile computing;patient care","learning environments;AR technology;clinical lab training;patient scenarios;nursing educational environments;ICT;mobile augmented reality;information and communication technologies;hidden objects visualization;nursing students self-regulation skills;manikins","","","","17","","28 Mar 2019","","","IEEE","IEEE Conferences"
"Decentralized Control for Large-Scale Irregular Systems via Iterative Learning Algorithm","P. Yu; Q. Fu; Z. Chen; D. Zhang","School of Mathematics and Physics, Suzhou University of Science and Technology,Suzhou,P. R. China,215009; School of Mathematics and Physics, Suzhou University of Science and Technology,Suzhou,P. R. China,215009; School of Mathematics and Physics, Suzhou University of Science and Technology,Suzhou,P. R. China,215009; School of Mathematics and Physics, Suzhou University of Science and Technology,Suzhou,P. R. China,215009","2019 IEEE 8th Data Driven Control and Learning Systems Conference (DDCLS)","25 Nov 2019","2019","","","213","217","This thesis discusses the decentralized iterative learning control problem for general interconnected discrete-time systems, which are interlinked by non-affine nonlinear dynamics. And each subsystem does not have direct transmission from input to output. That is to say, each system is irregular. According to the structural characteristics of the system, a D-type learning algorithm is constructed. Using the iterative converge principle, it is shown that the output tracking error of each subsystem can converge to zero along the iteration axis. The effectiveness of the algorithm is verified by simulation.","","978-1-7281-1454-5","10.1109/DDCLS.2019.8908841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908841","Iterative learning control;Non-affine nonlinear systems;Irregular;The D-type learning algorithm","Discrete-time systems;Iterative learning control;Trajectory;Mathematical model;Iterative algorithms;Large-scale systems","adaptive control;control system synthesis;decentralised control;discrete time systems;interconnected systems;iterative learning control;learning systems;nonlinear control systems","iteration axis;decentralized control;large-scale irregular systems;control problem;general interconnected discrete-time systems;nonaffine nonlinear dynamics;direct transmission;structural characteristics;D-type learning algorithm;iterative converge principle;output tracking error","","","","31","","25 Nov 2019","","","IEEE","IEEE Conferences"
"Using Augmented Reality Technology to Learn Cube Expansion Diagram in Spatial Geometry of Elementary Mathematics","S. Wu; C. Liu; H. Shi; S. Cai","Beijing Normal University,VR/AR+Education Lab, School of Educational Technology, Faculty of Education,Beijing,China; Beijing Normal University,VR/AR+Education Lab, School of Educational Technology, Faculty of Education,Beijing,China; Beijing Normal University,VR/AR+Education Lab, School of Educational Technology, Faculty of Education,Beijing,China; Beijing Normal University,VR/AR+Education Lab, School of Educational Technology, Faculty of Education, Beijing Advanced Innovation Center for Future Education,Beijing,China","2019 IEEE International Conference on Engineering, Technology and Education (TALE)","15 Oct 2020","2019","","","1","6","Spatial geometry has always been the key and difficult part in the curriculum of elementary mathematics. Compared with traditional teaching methods using, Augmented Reality (AR) technology shows its potential to teach spatial geometry through visualization, interaction and situation. This study focused on cube expansion diagram in spatial geometry and developed an AR learning tool based on inquiry for the course. The research aimed to examine the effectiveness of AR-assisted math lesson by designing and implementing two lessons in an elementary school. Two classes including 92 students in grade 5 participated in this study, and they were assigned to an experimental and a control group. This study adopted mixed methods methodology and utilized pre/post-tests, questionnaires and interviews. Results showed that students can general accept of using AR to learn spatial geometry, and AR-assisted teaching methods significantly improved students' learning outcome. It is also noticed that students' learning level affected their performance in AR-assisted math lessons.","2470-6698","978-1-7281-2665-4","10.1109/TALE48000.2019.9225978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9225978","augmented reality;elementary mathematics;spatial geometry;education","Education;Geometry;Tools;Interviews;Three-dimensional displays;Animation","augmented reality;computer aided instruction;educational courses;educational institutions;mathematics computing;teaching","augmented reality technology;cube expansion diagram;spatial geometry;elementary mathematics;AR-assisted math lesson;AR learning tool;elementary school;experimental group;control group;AR-assisted teaching methods","","","","22","","15 Oct 2020","","","IEEE","IEEE Conferences"
"Robotics and virtual reality: the development of a life-sized 3-D system for the rehabilitation of motor function","J. L. Patton; G. Dawe; C. Scharver; F. A. Mussa-Ivaldi; R. Kenyon","Rehabilitation Inst. of Chicago, IL, USA; NA; NA; NA; NA","The 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","14 Mar 2005","2004","2","","4840","4843","We have been developing and combining state-of-art devices that allow humans to visualize and feel synthetic objects superimposed on the real world. This effort stems from the need of platform for extending experiments on motor control and learning to realistic human motor tasks and environments, not currently represented in the practice of research. This paper's goal is to outline our motivations, progress, and objectives. Because the system is a general tool, we also hope to motivate researchers in related fields to join in. The platform under development, an augmented reality system combined with a haptic-interface robot, will be a new tool for contributing to the scientific knowledge base in the area of human movement control and rehabilitation robotics. Because this is a prototype, the system will also guide new methods by probing the levels of quality necessary for future design cycles and related technology. Inevitably, it should also lead the way to commercialization of such systems.","","0-7803-8439-3","10.1109/IEMBS.2004.1404339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1404339","Human;Motor learning;Adaptation;Human-machine interface;Teaching;Neurorehabilitation","Rehabilitation robotics;Virtual reality;Humans;Visualization;Motor drives;Augmented reality;Robot control;Control systems;Prototypes;Commercialization","medical robotics;virtual reality;patient rehabilitation;haptic interfaces;biocontrol;biomechanics","rehabilitation robotics;virtual reality;life-sized 3-D system;motor control;motor learning;realistic human motor tasks;haptic-interface robot;human movement control","","13","","12","","14 Mar 2005","","","IEEE","IEEE Conferences"
"Virtual and Augmented Reality: Enhancing the learning experience in higher education in the U.A.E. Current standing & research directions","D. Xanthidis; C. Manolas; S. Paul; O. K. Xanthidou","Computer and Information Science, Higher Colleges of Technology,Dubai,U.A.E.; Music and Sound Design for Media Ravensbourne University,London,U.K.; Computer and Information Science, Higher Colleges of Technology,Dubai,U.A.E.; University of Malaya,Computer Science and Information Technology,Kuala Lumpur,Malaysia","2020 Seventh International Conference on Information Technology Trends (ITT)","19 Jan 2021","2020","","","206","211","In addition to the established and widespread technological tools and trends of the past decades, such as the surge of mobile computing, high-speed networks and social media, new technologies utilizing the increased power and capabilities of modern computers is developing rapidly. Perhaps, no better example of this can be found than the rapid developments in Virtual and Augmented Reality (VR/AR), that have recently made the step from the laboratories and specialized, bespoke training applications of the past, to the mainstream. Advances in VR/AR have opened the floodgates to digital internships, virtual labs, and novel collaborative and experiential learning. The magnitude and impact of these emerging technologies is also evident on the significant interest in their application and use in various commercial, professional, and industrial contexts. Examples of these include, but are not limited to, the entertainment industries, specialized training, corporate demonstrations and conferencing, and prototyping and modelling in the technical and engineering areas. Since universities play a vital role in moulding tomorrow's talents, integrating such technologies can help them not only by supporting teaching and learning, but also by contributing to related research and enhancing the learning technology frameworks in their entirety. The aim of this research paper is to briefly discuss the position of these emerging technologies in the educational sector in general, and explore what their role, impact, and structure may be in the educational systems of the future with a focus on higher education in the U.A.E. Eventually, it will contribute by suggesting areas of interest for its future use in higher education in the U.A.E.","","978-1-7281-8379-4","10.1109/ITT51279.2020.9320882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9320882","Higher Education;Augmented Reality;Virtual Reality;Learning Object;U.A.E.","Three-dimensional displays;Training;Tools;Market research;Technological innovation;Visualization;Solid modeling","augmented reality;computer aided instruction;educational institutions;entertainment;further education;mobile learning;social networking (online);teaching","augmented reality;learning experience;higher education;mobile computing;high-speed networks;social media;digital internships;virtual labs;experiential learning;entertainment industries;corporate demonstrations;learning technology frameworks;educational sector;educational systems;virtual reality","","","","35","","19 Jan 2021","","","IEEE","IEEE Conferences"
"A Virtual-Reality System Integrated With Neuro-Behavior Sensing for Attention-Deficit/Hyperactivity Disorder Intelligent Assessment","S. -C. Yeh; S. -Y. Lin; E. H. -K. Wu; K. -F. Zhang; X. Xiu; A. Rizzo; C. -R. Chung","Computer Science and Information Engineering Department, National Central University, Taoyuan, Taiwan; Computer Science and Information Engineering Department, National Central University, Taoyuan, Taiwan; Computer Science and Information Engineering Department, National Central University, Taoyuan, Taiwan; Department of Child Health Care, Children’s Hospital of Fudan University, Shanghai, China; Department of Child Health Care, Children’s Hospital of Fudan University, Shanghai, China; Institute for Creative Technologies, University of Southern California, Los Angeles, CA, USA; Computer Science and Information Engineering Department, National Central University, Taoyuan, Taiwan","IEEE Transactions on Neural Systems and Rehabilitation Engineering","7 Sep 2020","2020","28","9","1899","1907","Attention-deficit/Hyperactivity disorder(ADHD) is a common neurodevelopmental disorder among children. Traditional assessment methods generally rely on behavioral rating scales (BRS) performed by clinicians, and sometimes parents or teachers. However, BRS assessment is time consuming, and the subjective ratings may lead to bias for the evaluation. Therefore, the major purpose of this study was to develop a Virtual Reality (VR) classroom associated with an intelligent assessment model to assist clinicians for the diagnosis of ADHD. In this study, an immersive VR classroom embedded with sustained and selective attention tasks was developed in which visual, audio, and visual-audio hybrid distractions, were triggered while attention tasks were conducted. A clinical experiment with 37 ADHD and 31 healthy subjects was performed. Data from BRS was compared with VR task performance and analyzed by rank-sum tests and Pearson Correlation. Results showed that 23 features out of total 28 were related to distinguish the ADHD and non-ADHD children. Several features of task performance and neuro-behavioral measurements were also correlated with features of the BRSs. Additionally, the machine learning models incorporating task performance and neuro-behavior were used to classify ADHD and non-ADHD children. The mean accuracy for the repeated cross-validation reached to 83.2%, which demonstrated a great potential for our system to provide more help for clinicians on assessment of ADHD.","1558-0210","","10.1109/TNSRE.2020.3004545","Ministry of Science and Technology Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9123917","Attention deficit and hyperactivity disorder;virtual reality;neuro-behavior;machine learning;assessment","Task analysis;Pediatrics;Machine learning;Medical services;Virtual environments;Computer science;Medical diagnostic imaging","cognition;diseases;learning (artificial intelligence);medical computing;medical diagnostic computing;medical disorders;neurophysiology;paediatrics;patient diagnosis;statistical analysis;virtual reality","virtual-reality system;neuro-behavior;common neurodevelopmental disorder;behavioral rating scales;BRS assessment;subjective ratings;Virtual Reality classroom;intelligent assessment model;immersive VR classroom;sustained attention tasks;selective attention tasks;visual-audio hybrid distractions;VR task performance;nonADHD children;neuro-behavioral measurements","","","","24","IEEE","24 Jun 2020","","","IEEE","IEEE Journals"
"Simulation as an aided tool in the EE learning","M. Castro; J. Perez; A. Hilario; S. Acha; A. Vara; A. Lopez-Rey; J. V. Miguez; F. Yeves; J. Peire","Dept. of Electr. & Comput. Eng., UNED, Madrid, Spain; NA; NA; NA; NA; NA; NA; NA; NA","FIE'99 Frontiers in Education. 29th Annual Frontiers in Education Conference. Designing the Future of Science and Engineering Education. Conference Proceedings (IEEE Cat. No.99CH37011","6 Aug 2002","1999","1","","12A9/20 vol.1","","Nowadays simulation has become one of the most used aided tools in all fields of science and technology in general. Professionals and researchers use it in their work as an essential tool. The analysis and design of actual systems, which are becoming increasingly complex, would be very complicated or impossible without simulation. So that, for the past five years the Electrical and Computer Engineering Department (DIEEC) of the Spanish University for Distance Education (UNED) have a research area of work which main objective is to promote the use of simulation as a tool to support the teaching of electronic engineering. Within this objective, guided exercises via simulation have been developed based on these principles. The project is also working on the application of multimedia tools within electronic engineering teaching allowing integrating it with simulation.","0190-5848","0-7803-5643-8","10.1109/FIE.1999.839297","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=839297","","Circuit simulation;Computational modeling;Computer simulation;Books;Analytical models;Application software;Education;Electronic circuits;Postal services;Distance learning","electronic engineering education;teaching;multimedia systems;computer aided instruction;circuit simulation;distance learning","electronic engineering education;learning tools;distance education;guided exercises;multimedia tools;teaching;Spain;computer simulation","","2","","","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Evaluating Multiple Levels of an Interaction Fidelity Continuum on Performance and Learning in Near-Field Training Simulations","A. Bhargava; J. W. Bertrand; A. K. Gramopadhye; K. C. Madathil; S. V. Babu",Clemson University; Clemson University; Clemson University; Clemson University; Clemson University,"IEEE Transactions on Visualization and Computer Graphics","13 Mar 2018","2018","24","4","1418","1427","With costs of head-mounted displays (HMDs) and tracking technology decreasing rapidly, various virtual reality applications are being widely adopted for education and training. Hardware advancements have enabled replication of real-world interactions in virtual environments to a large extent, paving the way for commercial grade applications that provide a safe and risk-free training environment at a fraction of the cost. But this also mandates the need to develop more intrinsic interaction techniques and to empirically evaluate them in a more comprehensive manner. Although there exists a body of previous research that examines the benefits of selected levels of interaction fidelity on performance, few studies have investigated the constituent components of fidelity in a Interaction Fidelity Continuum (IFC) with several system instances and their respective effects on performance and learning in the context of a real-world skills training application. Our work describes a large between-subjects investigation conducted over several years that utilizes bimanual interaction metaphors at six discrete levels of interaction fidelity to teach basic precision metrology concepts in a near-field spatial interaction task in VR. A combined analysis performed on the data compares and contrasts the six different conditions and their overall effects on performance and learning outcomes, eliciting patterns in the results between the discrete application points on the IFC. With respect to some performance variables, results indicate that simpler restrictive interaction metaphors and highest fidelity metaphors perform better than medium fidelity interaction metaphors. In light of these results, a set of general guidelines are created for developers of spatial interaction metaphors in immersive virtual environments for precise fine-motor skills training simulations.","1941-0506","","10.1109/TVCG.2018.2794639","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260967","Bimanual Interaction;Interaction Fidelity;Empirical Evaluation;Educational Virtual Reality","Training;Aerospace electronics;Solid modeling;Metrology;Mice;Virtual environments","computer based training;helmet mounted displays;virtual reality","Interaction Fidelity Continuum;near-field training simulations;virtual reality applications;education;real-world interactions;safe risk-free training environment;intrinsic interaction techniques;near-field spatial interaction task;learning outcomes;discrete application points;performance variables;medium fidelity interaction metaphors;spatial interaction metaphors;immersive virtual environments;fine-motor skills training simulations;bimanual interaction metaphors;restrictive interaction metaphors;head-mounted displays;tracking technology","Adolescent;Adult;Cognition;Female;High Fidelity Simulation Training;Humans;Male;Surveys and Questionnaires;Task Performance and Analysis;User-Computer Interface;Virtual Reality;Young Adult","1","","33","Traditional","17 Jan 2018","","","IEEE","IEEE Journals"
"Tablet VR-Learning System: Chemical Laboratory Experience System","K. Uchiyama; K. Funahashi","Nagoya Inst. of Technol., Nagoya, Japan; Nagoya Inst. of Technol., Nagoya, Japan","2013 International Conference on Signal-Image Technology & Internet-Based Systems","30 Jan 2014","2013","","","416","423","Education builds culture of human for many years. The method of education has been developed from oral communication and textbook to broadcasting and e-learning. According to development, children have become to be free for place, time and teacher who gives some advice. On the other hand, the opportunities that children contact with real things and experience is getting decrease. Generally speaking, experience is important for the education such as physical education, art and also science. In addition, it is usually difficult to have a good environment for experience at a self learning situation and e-learning systems. In this paper, we describe a chemical laboratory experience system using VR technology for primary school students, as a VR-learning system. In addition, we confirm the usefulness through experiments that several primary school students use this system.","","978-1-4799-3211-5","10.1109/SITIS.2013.74","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6727223","Education culture;VR-learning;Chemical laboratory system;3D tablet interface","Liquids;Containers;Three-dimensional displays;Equations;Educational institutions;Mathematical model","chemistry computing;computer aided instruction;notebook computers;student experiments;virtual reality","tablet VR-learning system;culture;oral communication;textbook;broadcasting;physical education;art;science;self learning situation;e-learning systems;chemical laboratory experience system;VR technology;primary school students","","","","15","","30 Jan 2014","","","IEEE","IEEE Conferences"
"A Physiology-Based QoE Comparison of Interactive Augmented Reality, Virtual Reality and Tablet-Based Applications","C. Keighrey; R. Flynn; S. Murray; N. Murray","Athlone Institute of Technology, Athlone, Ireland; Athlone Institute of Technology, Athlone, Ireland; Health Service Executive, Primary Care Centre, Longford, Ireland; Athlone Institute of Technology, Athlone, Ireland","IEEE Transactions on Multimedia","17 Dec 2020","2021","23","","333","341","The availability of affordable head-mounted display technology has facilitated new, potentially more immersive, interactive multimedia experiences. These technologies were traditionally focused on entertainment; however, academia and industry are now exploring applications in other domains such as health, learning and training. Key to the success of these new multimedia experiences is the understanding of a user's perceived quality of experience (QoE). Subjective user ratings have been the primary mechanism to capture insights into a user's experience. Such ratings have generally been captured post experience and reflected using a mean opinion score (MOS). However, user perception is multifactorial and subjective ratings alone do not express the true measure of an experience. As a result, recent efforts to capture QoE have included exploring the use of implicit metrics (e.g., physiological measures). This article presents the results of an experimental QoE evaluation and comparison of immersive applications delivered across three multimedia platforms. The platforms compared were augmented reality, tablet and virtual reality. The QoE methodology employed considered explicit (post-test questionnaire) and implicit (heart rate and electrodermal activity) assessment methods. The results indicate comparatively higher levels of QoE for users of the augmented reality and tablet platforms.","1941-0077","","10.1109/TMM.2020.2982046","Irish Research Council - Government of Ireland Postgraduate Scholarship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9042281","Quality of experience;augmented reality;virtual reality;physiological;speech language pathology;aphasia","Quality of experience;Semantics;Multimedia systems;Augmented reality;Biomedical monitoring","augmented reality;helmet mounted displays;human computer interaction;mobile computing;multimedia systems;quality of experience;user interfaces","user experience;perceived quality of experience;tablet based applications;physiology based QoE comparison;physiological measures;mean opinion score;interactive multimedia experiences;immersive multimedia experiences;head mounted display;virtual reality;interactive augmented reality","","7","","35","IEEE","19 Mar 2020","","","IEEE","IEEE Journals"
"Towards a Machine-Learning Approach for Sickness Prediction in 360° Stereoscopic Videos","N. Padmanaban; T. Ruban; V. Sitzmann; A. M. Norcia; G. Wetzstein",Stanford Electrical Engineering Department; Stanford Electrical Engineering Department; Stanford Electrical Engineering Department; Stanford Psychology Department; Stanford Electrical Engineering Department,"IEEE Transactions on Visualization and Computer Graphics","19 Mar 2018","2018","24","4","1594","1603","Virtual reality systems are widely believed to be the next major computing platform. There are, however, some barriers to adoption that must be addressed, such as that of motion sickness - which can lead to undesirable symptoms including postural instability, headaches, and nausea. Motion sickness in virtual reality occurs as a result of moving visual stimuli that cause users to perceive self-motion while they remain stationary in the real world. There are several contributing factors to both this perception of motion and the subsequent onset of sickness, including field of view, motion velocity, and stimulus depth. We verify first that differences in vection due to relative stimulus depth remain correlated with sickness. Then, we build a dataset of stereoscopic 3D videos and their corresponding sickness ratings in order to quantify their nauseogenicity, which we make available for future use. Using this dataset, we train a machine learning algorithm on hand-crafted features (quantifying speed, direction, and depth as functions of time) from each video, learning the contributions of these various features to the sickness ratings. Our predictor generally outperforms a naïve estimate, but is ultimately limited by the size of the dataset. However, our result is promising and opens the door to future work with more extensive datasets. This and further advances in this space have the potential to alleviate developer and end user concerns about motion sickness in the increasingly commonplace virtual world.","1941-0506","","10.1109/TVCG.2018.2793560","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8267239","Virtual reality;simulator sickness;vection;machine learning","Videos;Stereo image processing;Three-dimensional displays;Visualization;Virtual environments;Machine learning algorithms;Trajectory","human factors;image motion analysis;learning (artificial intelligence);medical image processing;stereo image processing;video signal processing;virtual reality;visual perception","sickness ratings;commonplace virtual world;virtual reality systems;stereoscopic videos;sickness prediction;machine-learning approach;machine learning algorithm;stereoscopic 3D videos;relative stimulus depth;motion velocity;motion sickness","Adult;Algorithms;Computer Graphics;Databases, Factual;Depth Perception;Female;Humans;Machine Learning;Male;Middle Aged;Motion Sickness;User-Computer Interface;Video Recording;Virtual Reality;Young Adult","18","","40","","23 Jan 2018","","","IEEE","IEEE Journals"
"Computer-aided 3D Virtual Training in Power System Education","A. N. Angelov; Z. A. Styczynski","Member, IEEE, Faculty of Electrical Engineering and Information Technology, Otto-von-Guericke-Univeristy-Magdeburg, Magdeburg, 39106 Germany. e-mail: angel.angelov@e-technik.uni-magdeburg.de; Senior Member, IEEE, Faculty of Electrical Engineering and Information Technology, Otto-von-Guericke-Univeristy-Magdeburg, Magdeburg, 39106 Germany","2007 IEEE Power Engineering Society General Meeting","23 Jul 2007","2007","","","1","4","The implementation of computer-aided three dimensional (3D) virtual training and the combination of traditional evaluated learning programs with virtual reality systems in the area of power system education will be presented in this paper. As new complex systems, electric plants and machines are becoming increasingly more intricate, such learning methods provide effective training and fast adjustment with operation, control and process sequences. Without these new methods, the understanding and operation of such systems would be very time consuming. For specialized engineers a regular and high-quality training is additionally necessary. The interactive computer-aided three dimensional representation allows online development and utilization of 3D environments and assures deeper contact, than any drawing or written description. During the development of the computer-aided learning modules a distinction was drawn between teaching / training scenarios and research scenarios. The learning modules consist of didactic model and learning form. The special feature of this work is the use of three-dimensional presentation in the service and schooling area of power systems.","1932-5517","1-4244-1296-X","10.1109/PES.2007.386078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4275844","electrical engineering;virtual reality;learning scenarios;virtual seminar;e-learning","Power systems;Computer science education;Educational programs;Power system modeling;Virtual reality;Learning systems;Process control;Control systems;Engineering drawings;Computer aided instruction","computer aided instruction;computer based training;power engineering education;power system analysis computing;teaching;virtual reality","interactive computer-aided 3D virtual training;power system education;learning programs;virtual reality systems;electric plants;electric machines;didactic model;teaching scenario","","16","","9","","23 Jul 2007","","","IEEE","IEEE Conferences"
"Experience with head-mounted virtual reality (HMD-VR) predicts transfer of HMD-VR motor skills","J. M. Juliano; D. Saldana; A. Schmiesing; S. Liew","University of Southern California (USC),Neuroscience Graduate Program,Los Angeles,CA,USA; University of Southern California,Chan Division of Occupational,Los Angeles,CA,USA; University of Southern California,Chan Division of Occupational,Los Angeles,CA,USA; University of Southern California,Chan Division of Occupational,Los Angeles,CA,USA","2019 International Conference on Virtual Rehabilitation (ICVR)","13 Feb 2020","2019","","","1","2","Immersive, head-mounted virtual reality (HMD-VR) has the potential to be a useful tool for motor rehabilitation. However, when developing tools for rehabilitation, it is essential to design interventions that will be most effective for generalizing to the real world. Therefore, it is important to understand what factors facilitate transfer from HMD-VR to non-HMD-VR environments. Here we used a well-established test of skilled motor learning, the Sequential Visual Isometric Pinch Task (SVIPT), to train healthy individuals in an HMD-VR environment. We examined whether learned motor skills transferred to a more conventional (non-HMD-VR) environment and what factors facilitated transfer. Our results suggest that on average, learned motor skills from this task transfer from an immersive virtual environment to a conventional environment; however, some individuals did not transfer the learned motor skills. We then examined individual differences between those that did show transfer and those that did not. We found that individuals who had previous exposure to HMD-VR were more likely to transfer their learned motor skills than those who did not. Individual differences in previous exposure to HMD-VR environments prior to training may serve as a predictor to whether learned motor skills will transfer out of HMD-VR.","2331-9569","978-1-7281-1285-5","10.1109/ICVR46560.2019.8994345","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994345","head-mounted virtual reality;skilled motor learning;transfer","","biomechanics;helmet mounted displays;learning (artificial intelligence);patient rehabilitation;virtual reality","HMD-VR environment;learned motor skills;head-mounted virtual reality;HMD-VR motor skills;motor rehabilitation;nonHMD-VR environments;skilled motor learning;immersive virtual environment","","","","9","","13 Feb 2020","","","IEEE","IEEE Conferences"
"Design and construction of a Virtual Reality wire cut Electrical Discharge Machining system","Y. Kao; J. Tsai; H. Cheng; C. Chao","Department of Mechanical Engineering, National Kaohsiung University of Applied Sciences, Kaohsiung City, Taiwan; Department of Computer Science and Information, Engineering, Far East University Tainan County, Taiwan; Department of Computer Science and Information, Engineering, Far East University Tainan County, Taiwan; Department of Mechanical Engineering, National Kaohsiung University of Applied Sciences, Kaohsiung City, Taiwan","2010 International Symposium on Computer, Communication, Control and Automation (3CA)","29 Jul 2010","2010","2","","45","48","Wire Electrical Discharge Machining (WEDM) uses a metallic wire to cut a product profile such as extrusion dies and blanking punches. The cost of possession and maintenance of the WEDM equipment is generally high. Hence, it is important to reduce the machine operation training cost, to provide simulation verification, and to investigate the correctness of the NC codes. This paper presents the development of a Virtual Reality (VR) based WEDM system which can emulate a real WEDM machine. The research result can be adopted to serve as a cost-effective tutoring system that has the benefits of improving the inefficient and dangerous drawbacks in operating the real machine. The developed system can provide an effective application in digital education and training environment for academics and industries.","2324-8017","978-1-4244-5568-3","10.1109/3CA.2010.5533343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5533343","Virtual Reality (VR);Virtual Machine Tool;Digital Education and Training","Virtual reality;Wire;Design automation;Layout;Virtual machining;Costs;Industrial training;Object oriented modeling;Machine learning;Unified modeling language","blanking;computer based training;cutting;dyes;electrical discharge machining;extrusion;production engineering computing;virtual reality;wires","virtual reality wire cut electrical discharge machining system;wire electrical discharge machining;metallic wire;product profile;extrusion dies;blanking punches;simulation verification;cost-effective tutoring system;digital education;training environment","","2","","6","","29 Jul 2010","","","IEEE","IEEE Conferences"
"The Introduction of a Novel Virtual Reality Training System for Gynecology Learning and Its User Experience Research","C. Chang; S. Yeh; M. Li; E. Yao","School of Journalism, Fudan University, Shanghai, China; School of Information Science and Technology, Fudan University, Shanghai, China; Department of Psychology, Fudan University, Shanghai, China; Iforeal Intelligent Technology, Shanghai, China","IEEE Access","11 Apr 2019","2019","7","","43637","43653","The researchers of this study designed a new virtual reality (VR)-assisted training system, IFOREAL, for gynecology students at their university and introduced it to potential trainees. Two versions of IFOREAL, each employing different devices, were developed. The consumer version uses a traditional LCD display and computer mouse, whereas the professional version utilizes a head-mounted display (HMD) and joystick controller for the virtual learning. Trainees watched simulated videos and interacted with the system to accomplish tasks. IFOREAL consists of several major learning modules of gynecology. This study used the normal spontaneous delivery module to research user experience and perceptions of the IFOREAL VR training system. The results suggested that most of the trainees' user experiences and perceptions of IFOREAL, using both the types of VR-assisted technology, were positively reported. Trainees who used the consumer version of IFOREAL perceived a stronger internal control, whereas trainees using the professional version perceived a better sense of virtual presence. Overall, trainees perceived the usefulness of the IFOREAL system which predicted their future intention to use the system and other similar VR-assisted training systems for learning. Furthermore, whether the virtual content of IFOREAL grabbed the trainees' attention predicted their future intenon to use professional devices of HMD/joysck for learning other subjects. The gender difference was also explored in the study. Generally speaking, female trainees gave better evaluations of IFOREAL compared to their male counterparts. They perceived a better internal control while using the consumer version than the professional version. Male trainees believed that the gadgets used in the professional version provided a better virtual presence and met their expectation of a virtual experience better. This study suggested that different versions of IFOREAL could serve trainees' different needs. Technology developers and trainers should tailor the application of different VR devices to assist with the training/learning in accordance with different conditions/trainees.","2169-3536","","10.1109/ACCESS.2019.2905143","Iforreal Intelligent Technology (Shanghai) Co., Ltd.; Fudan University; Xijia Great Education Technology Co., Ltd.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8667417","Virtual reality;training/learning system;immersive and interactive design;user experience;acceptance and adoption of systems","Training;Gynecology;Visualization;Fetus;Standards;Videos;Pregnancy","biomedical education;computer based training;gynaecology;helmet mounted displays;interactive devices;medical computing;virtual reality","novel virtual reality training system;gynecology learning;user experience research;virtual reality-assisted training system;potential trainees;consumer version;computer mouse;professional version utilizes;joystick controller;virtual learning;research user experience;IFOREAL VR training system;VR-assisted technology;virtual presence;IFOREAL system;similar VR-assisted training systems;virtual content;female trainees;male trainees;virtual experience;VR devices","","7","","48","","14 Mar 2019","","","IEEE","IEEE Journals"
"Ginput: a tool for fast hi-fi prototyping of gestural interactions in virtual reality","J. R. Fonseca; J. Abreu; L. Figueredo; J. G. Neto; V. Teichrieb; J. P. Quintino; F. Q. B. da Silva; A. L. M. Santos; H. Pinho","Universidade Federal de,Voxar Labs / CIn,Pernambuco; Universidade Federal de,Voxar Labs / CIn,Pernambuco; Universidade Federal de,Voxar Labs / CIn,Pernambuco; Universidade Federal de,Voxar Labs / CIn,Pernambuco; Universidade Federal de,Voxar Labs / CIn,Pernambuco; Universide Federal de,Projeto CIn-Samsung,Pernambuco; CIn / Universidade Federal de,Pernambuco; CIn / Universidade Federal de,Pernambuco; Desenvolvimento para a Informática,Samsung Instituto de","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","63","64","Gestural interfaces in virtual reality (VR) expand the design space for user interaction, allowing spatial metaphors with the environment and more natural and immersive experiences. Typically, machine learning approaches recognize gestures with models that rely on a large number of samples for the training phase, which is an obstacle for rapidly prototyping gestural interactions. In this paper, we propose a solution designed for hi-fi prototyping of gestures within a virtual reality environment through a high-level Domain-Specific Language (DSL), as a subset of the natural language. The proposed DSL allows non-programmer users to intuitively describe a broad domain of poses and connect them for compound gestures. Our DSL was designed to be general enough for multiple input classes, such as body tracking, hand tracking, head movement, motion controllers, and buttons. We tested our solution for wands with VR designers and developers. Results showed that the tool gives non-programmers the ability to prototype gestures with ease and refine its recognition within a few minutes.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288432","Human-centered computing;Visualization;Visualization techniques;Treemaps; Human-centered computing;Visualization;Visualization design and evaluation methods","Training;Solid modeling;Tracking;Natural languages;Tools;DSL;Task analysis","gesture recognition;high level languages;human computer interaction;learning (artificial intelligence);motion control;object tracking;software prototyping;virtual reality","gestural interfaces;design space;user interaction;spatial metaphors;immersive experiences;machine learning;virtual reality environment;high-level domain-specific language;DSL;natural language;nonprogrammer users;compound gestures;prototype gestures;fast hi-fi prototyping;natural experience;gesture recognition;gestural interaction rapid prototyping;body tracking;hand tracking;head movement;motion controllers;buttons;Ginput","","","","7","","16 Dec 2020","","","IEEE","IEEE Conferences"
"Work-in-Progress—A Generalizable Virtual Reality Training and Intelligent Tutor for Additive Manufacturing","M. Mogessie; S. D. Wolf; M. Barbosa; N. Jones; B. M. McLaren","Carnegie Mellon University,Human-Computer Interaction Institute,Pittsburgh,PA,United States; Carnegie Mellon University,NextManufacturing Center,Pittsburgh,PA,United States; Carnegie Mellon University,Human-Computer Interaction Institute,Pittsburgh,PA,United States; Carnegie Mellon University,NextManufacturing Center,Pittsburgh,PA,United States; Carnegie Mellon University,Human-Computer Interaction Institute,Pittsburgh,PA,United States","2020 6th International Conference of the Immersive Learning Research Network (iLRN)","4 Aug 2020","2020","","","355","358","There is currently significant demand for training in how to use metals additive manufacturing (AM) machines. Such training is important not only for the technicians who run and maintain the machines, but also for engineers and strategic decision makers who need to support AM part fabrication. Furthermore, there are a variety of AM machines, each with different details to be learned and potential hazards to overcome, and it is difficult to train more than a handful of users at one time. To address these challenges, a prototype training system has been developed, the AM Training Tutor, which uses interactive virtual reality (VR) to train users on a specific AM machine - the EOS M290. To make the training technology more widely available and expand its use across a variety of different AM machines, efforts are underway to develop a modularized and generic version of the AM Training Tutor that can be customized with relatively little effort to train users to operate other AM machines. This work-in-progress paper details the progress to-date, challenges and proposed solutions with the aim to demonstrate how standalone VR-based training systems can be redesigned for relatively easy repurposing and generalization.","","978-1-7348995-0-4","10.23919/iLRN47897.2020.9155119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155119","generalized VR;VR-based training;workforce training;cognitive tutor;advanced manufacturing;additive manufacturing;3D printing","Training;Tutorials;Three-dimensional printing;Three-dimensional displays;Solid modeling;Earth Observing System","computer based training;decision making;human computer interaction;intelligent tutoring systems;interactive systems;production engineering computing;rapid prototyping (industrial);virtual reality","intelligent tutor;strategic decision makers;AM machines;prototype training system;AM Training Tutor;interactive virtual reality;specific AM machine;training technology;standalone VR-based training systems;generalizable virtual reality training;metals additive manufacturing machines;EOS M290","","","","17","","4 Aug 2020","","","IEEE","IEEE Conferences"
"Generalized predictive control of time-delay nonlinear systems based on extreme learning machine","L. Muwei; Z. Ying; W. Qiang","Nanjing University of Posts and Telecommunications, College of Automation, Nanjing 210046; Nanjing University of Posts and Telecommunications, College of Automation, Nanjing 210046; Nanjing University of Posts and Telecommunications, College of Automation, Nanjing 210046","2018 Chinese Control And Decision Conference (CCDC)","9 Jul 2018","2018","","","789","794","For a class of nonlinear controlled objects with time-delay, this paper proposes a generalized predictive self-tuning control method based on extreme learning machine. In the generalized predictive self-tuning control (GPC), the predictive model of the nonlinear controlled object is established by the extreme learning machine (ELM), and constantly revising forecast output data to improve the accuracy of the prediction. The controller adopts a GPC implicit correction algorithm, without to identify the model parameters, the calculated amount is greatly reduced. The simulation shows that the method in this paper is superior and practical, the prediction output track the reference trajectory better than the commonly used PID self-tuning method.","1948-9447","978-1-5386-1244-6","10.1109/CCDC.2018.8407238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8407238","nonlinear time-delay;generalized predictive control;extreme learning machine;multi-step prediction","Neurons;Predictive models;Predictive control;Mathematical model;Training;Prediction algorithms;Biological neural networks","adaptive control;control system synthesis;delays;learning (artificial intelligence);nonlinear control systems;predictive control;self-adjusting systems;three-term control","PID self-tuning method;time-delay nonlinear systems;generalized predictive control;prediction output;GPC implicit correction algorithm;predictive model;extreme learning machine;generalized predictive self-tuning control method;nonlinear controlled object","","1","","14","","9 Jul 2018","","","IEEE","IEEE Conferences"
"The Design and Evaluate of Virtual Reality Immersive Learning - the Case of Serious Game “Calcium Looping for Carbon Capture”","S. Wang; L. Liu; S. Wang","The National Taipei University of Technology, Taipei, 10608, Taiwan; The National Taipei University of Technology, Taipei, 10608, Taiwan; The National Taipei University of Technology, Taipei, 10608, Taiwan","2018 International Conference on System Science and Engineering (ICSSE)","4 Nov 2018","2018","","","1","4","This research focuses on design and evaluation of using virtual reality (VR) serious game for general science energy education immersive learning and uses the case study of learning knowledge from calcium looping carbon capture technology. The ARCS model of motivation design is used in this research as the core for promoting and sustaining motivation in the learning process. The domain knowledge of calcium looping carbon capture technology has been analyzed and integrated to develop a VR serious game. This research deployment a pilot study to 30 gifted students in an elementary school for collecting results by using questionnaire, drawing activities, and focus group interview. The five aspects of STEAM education that combine with the ARCS motivation model are then using for analyzing the results. The research results show that the VR immersive learning mechanism designed in this research can effectively trigger the motivation of learners for learning new knowledge as well as improve the learning results.","2325-0925","978-1-5386-6285-4","10.1109/ICSSE.2018.8520002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8520002","Virtual Reality;Immersive learning;ARCS motivation model;Serious Game;STEAM education","Games;Education;Solid modeling;Calcium;Carbon;Virtual reality;Interviews","carbon capture and storage;computer aided instruction;evolution (biological);human factors;physics computing;serious games (computing);virtual reality","general science energy education immersive learning;calcium looping carbon capture technology;ARCS model;motivation design;learning process;domain knowledge;VR serious game;research deployment;pilot study;STEAM education;ARCS motivation model;VR immersive learning mechanism;learning results;virtual reality immersive learning;Calcium Looping for Carbon Capture","","","","8","","4 Nov 2018","","","IEEE","IEEE Conferences"
"VEC3D: a 3-D virtual English classroom for second language learning","Yong-Yuan Lin; Ya-Chun Shih; Mau-Tsuen Yang","Media Lab., Nat. Dong Hwa Univ., Shoufeng, Taiwan; NA; NA","Fifth IEEE International Conference on Advanced Learning Technologies (ICALT'05)","19 Sep 2005","2005","","","906","908","The traditional e-learning systems are generally less attractive to students due to their lack of 3D immersion and real voice interaction. The technology of virtual reality can be exploited to compensate these weaknesses. We propose a realistic and interactive virtual English classroom entitled VEC3D by integrating vivid 3D graphics and real-time voice communication. The goal of VEC3D aims to help undergraduate students develop the overall English communicative competence in listening, speaking, reading and writing.","2161-377X","0-7695-2338-2","10.1109/ICALT.2005.302","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1508852","","Natural languages;Virtual reality;Writing;Avatars;Educational institutions;Space technology;Education;Electronic learning;Graphics;Appropriate technology","computer aided instruction;linguistics;natural language interfaces;virtual reality;solid modelling;voice communication;real-time systems","VEC3D;3D virtual English classroom;second language learning;e-learning systems;3D immersion;voice interaction;virtual reality;interactive virtual English classroom;3D graphics;real-time voice communication;undergraduate students;English communicative competence;listening;speaking;reading;writing","","","","6","","19 Sep 2005","","","IEEE","IEEE Conferences"
"The research and education application of distributed virtual reality platform based on Web3D","R. Yang","College of Communication, LinYi Normal University, LinYi, China","2010 2nd International Conference on Signal Processing Systems","23 Aug 2010","2010","3","","V3-489","V3-492","At present, many virtual learning communities are just simple two-dimensional replicas of former teaching materials, most virtual learning environments are not capable of realizing multi-person cooperation, and lots of educational researchers lack basics about computer network server programming. In addressing to these problems, first a Web3D-based distributed virtual reality platform is introduced and analyzed, then a general Web3D-based distributed virtual reality platform ABNet is introduced, finally its education application is elaborated, hoping to provide basis and references for the design of distributed virtual learning environments and the education application.","","978-1-4244-6893-5","10.1109/ICSPS.2010.5555718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5555718","Web3D;Distributed Virtual Veality;Virtual Learning Environment","Education;Virtual environment;Avatars;Servers;Solid modeling;Art","computer aided instruction;Internet;virtual reality","education application;distributed virtual reality platform;Web3D;virtual learning communities;teaching materials;ABNet;computer network server programming","","","","13","","23 Aug 2010","","","IEEE","IEEE Conferences"
"Game of Blazons: Helping Teachers Conduct Learning Situations That Integrate Web Tools and Multiple Types of Augmented Reality","J. A. Muñoz-Cristóbal; V. Gallego-Lema; H. F. Arribas-Cubero; J. I. Asensio-Pérez; A. Martínez-Monés","Universidad de Valladolid, Valladolid, Spain; Universidad del País Vasco, San Sebastián, Guipúzcoa, Spain; Universidad de Valladolid, Valladolid, Spain; Universidad de Valladolid, Valladolid, Spain; Universidad de Valladolid, Valladolid, Spain","IEEE Transactions on Learning Technologies","23 Dec 2018","2018","11","4","506","519","Several studies have explored how to help teachers carry out learning situations involving Augmented Reality (AR), a technology that has shown different affordances for learning. However, these works tend to rely on specific types of AR, focus on particular types of spaces, and are generally disconnected from other technologies widely used in education, such as VLEs or Web 2.0 tools. These constraints limit the possible range of activities that can be conducted and their integration into the existing classroom practice. GLUEPS-AR is a system that can help overcome these limitations, aiding teachers in the creation and enactment of learning situations that may combine multiple types of AR with other common web tools. This paper presents an evaluation study conducted on Game of Blazons, a learning situation carried out by two university teachers using GLUEPS-AR, and framed within two days of outdoor activities in a village in Spain. The evaluation showed that GLUEPS-AR provided an affordable support to the participant teachers to integrate several activities that made use of multiple types of AR, common web tools, and augmented paper, into a unique learning situation.","1939-1382","","10.1109/TLT.2018.2808491","Spanish Ministry of Economy and Competitiveness; Regional Government of Castilla y León; University of the Basque Country; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8300658","Learning technologies;virtual and augmented reality;computer uses in education;education;ubiquitous computing;mobile environments;authoring tools","Education;Learning systems;Games;Web 2.0;Ubiquitous computing;Augmented reality;Two dimensional displays;Authoring systems;Mobile communication","augmented reality;computer aided instruction;educational institutions;Internet;teaching","Game of Blazons;Web tools;augmented reality;learning situations;university teachers;GLUEPS-AR","","","","82","","22 Feb 2018","","","IEEE","IEEE Journals"
"Layered Software Architecture for the Development of Mobile Learning Objects With Augmented Reality","L. A. Rivera Alvarado; E. López Domínguez; Y. Hernández Velázquez; S. Domínguez Isidro; C. B. Excelente Toledo","National Laboratory of Advanced Informatics, Xalapa, Mexico; National Laboratory of Advanced Informatics, Xalapa, Mexico; National Laboratory of Advanced Informatics, Xalapa, Mexico; National Laboratory of Advanced Informatics, Xalapa, Mexico; National Laboratory of Advanced Informatics, Xalapa, Mexico","IEEE Access","25 Oct 2018","2018","6","","57897","57909","According to the m-learning paradigm, mobile learning objects (MLOs) are fundamental elements within the teaching-learning process. In this context, the integration of technology such as augmented reality (AR), incorporates an additional value to an MLO, generating by this, more interactive and attractive learning environments, which promotes higher involvement and engagement by being immersed in a virtually enhanced world. Our research postulates that the development of such MLOs must be based on standards, methodologies, and/or a layered software architecture which provide the adequate mechanisms to achieve the structure and quality attributes needed. Specifically, this paper presents the design and development of such architecture which allows obtaining MLO complying with the requirements and quality attributes. To achieve that, the architecture is composed of five layers: data persistence, learning personalization, interactivity, general structure, and standards. The layers are independent among them and the lower layers provide services to upper layers. In order to probe the benefits of the architecture, two prototypes of MLOs with AR were implemented and evaluated by a 20 master's degree students focusing on of pedagogical, technological, and usability aspects. The results show that the architecture contributes no only to integrate AR in MLOs but more importantly to obtain MLOs with the quality attributes required as a digital educational resource.","2169-3536","","10.1109/ACCESS.2018.2873976","Consejo Nacional de Ciencia y Tecnología; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8485281","Mobile learning;software architecture;augmented reality;mobile learning objects","Augmented reality;Computer architecture;Software architecture;Standards;Usability;Mobile handsets;Education","augmented reality;computer aided instruction;computer science education;mobile learning;software architecture;teaching","layered software architecture;mobile learning objects;augmented reality;teaching-learning process;interactive learning environments;attractive learning environments;MLO;m-learning;AR","","1","","28","","7 Oct 2018","","","IEEE","IEEE Journals"
"Technology Enhanced Learning with CONNECT: Visualising the invisible","A. Lazoudis",NA,"2008 Eighth IEEE International Conference on Advanced Learning Technologies","15 Jul 2008","2008","","","1089","1090","The main objective of the CONNECT project is to create a pedagogical framework that attempts to blend informal and formal learning and to situate learning in real-world contexts. The introduction of a technologically advanced approach for learning by connecting a wide range of learning environments (school, home, science museums, research centers, science thematic parks and exhibitions) and the bridging of theoretical and applied aspects of every day personal activities is expected to lead to the development of a new science learning scheme for all. This scheme will demonstrate innovative ways of science communication as well as ways to augment human abilities by capturing, recalling and generalizing from situated events.","2161-377X","978-0-7695-3167-0","10.1109/ICALT.2008.161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4561926","augmented reality;authoring tool;virtual museum visits;technology enhanced learning","Visualization;Educational institutions;Multimedia systems;Educational technology;Joining processes;Humans;Cognitive science;Psychology;Collaboration;Augmented reality","computer aided instruction;distance learning;natural sciences computing","technology enhanced learning;CONNECT project;pedagogical framework;informal learning;learning environment;science learning;science communication","","","","2","","15 Jul 2008","","","IEEE","IEEE Conferences"
"Training simulators-quantification of benefits and lessons learnt: a user's perspective","C. C. Hotblack","BP Chemicals Ltd., Hull, UK","IEE Colloquium on Operator Training Simulators","6 Aug 2002","1992","","","2/1","2/6","BP Chemicals has installed training simulators at four of its five major European locations. Three of these simulators were bought initially to train operators prior to commissioning and start up of major new plants. The other two were bought for general site training particularly where reinstrumentation is a significant feature. The total investment in these systems is significant and not surprisingly needed a thorough justification before funds were released. The primary justification for the simulators has been productivity. Improved operational safety also featured strongly, but productivity provided the quantifiable benefits. Other benefits identified are: licence to operate safely, plant design/operability, operator validation of training and publicity. Lessons learnt during the building, installing and using of the training simulators are also discussed.<>","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=168409","","Chemical industry;Computer aided instruction;Simulation;Training","chemical engineering computing;chemical industry;computer aided instruction;digital simulation;training","training simulators;European locations;major new plants;general site training;reinstrumentation;investment;operational safety;productivity;licence;plant design/operability;operator validation;publicity","","","","","","6 Aug 2002","","","IET","IET Conferences"
"VREdu: A Framework for Interactive Immersive Lectures using Virtual Reality","M. Misbhauddin","Information Systems Department, College of Computer Sciences and Information Technology, King Faisal University, Al-Ahsa, Saudi Arabia","2018 21st Saudi Computer Society National Computer Conference (NCC)","30 Dec 2018","2018","","","1","6","In the current education system, we expect the comprehension level of all the students in a classroom to be same. However, this is not the case. There are many factors that may affect the comprehension of lectures in the classroom including class size, visibility of the whiteboard, student's level of concentration, student's level of comprehension to name a few. Our main aim is to find a better way to offer the best education experience for students using the latest innovative solutions in technology. During our survey of Virtual Reality (VR) applications, we identified several readily available applications most of which were related to either medical education, tourism or other domains of sciences. None of the applications were available for general education where a complete classroom is transported into virtual reality. In this paper, we developed a VR framework that enhances the learning experience of students who face difficulties in the classroom. Moreover, we developed a complete prototype system to validate the framework. The proposed framework makes learning immersive, interactive and narrative offering enhanced motivation to students. The prototype system setup involves setting up a camera in the classroom to capture the whiteboard. Visuals from the whiteboard augmented with the course material (lecture slides) are compiled together to create a virtual space for the students. Students can interact with the virtual classroom by a provided set of tools in the virtual space. The VR application is developed using Unity 3D Engine and interaction is implemented using a handheld Bluetooth device.","","978-1-5386-4110-1","10.1109/NCG.2018.8593095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593095","Virtual reality in education;Classroom VR;3D Engine","Education;Virtual reality;Aerospace electronics;Prototypes;Engines;Streaming media;Visualization","computer aided instruction;educational courses;interactive systems;virtual reality","interactive immersive lectures;education experience;general education;VR framework;learning experience;course material;virtual space;virtual classroom;VR application;education system;virtual reality applications","","1","","20","","30 Dec 2018","","","IEEE","IEEE Conferences"
"Kinect for interactive AR anatomy learning","Ma Meng; P. Fallavollita; T. Blum; U. Eck; C. Sandor; S. Weidert; J. Waschke; N. Navab","Technische Universität München, Germany; Technische Universität München, Germany; Technische Universität München, Germany; University of South Australia, Adelaide, Australia; University of South Australia, Adelaide, Australia; Chirurgischen Klinik und Poliklinik - Innenstadt, LMU, München, Germany; Anatomische Anstalt der LMU, München, Germany; Technische Universität München, Germany","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","277","278","Education of anatomy is a challenging but crucial element in educating medical professionals, but also for general education of pupils. Our research group has previously developed a prototype of an Augmented Reality (AR) magic mirror which allows intuitive visualization of realistic anatomical information on the user. However, the current overlay is imprecise as the magic mirror depends on the skeleton output from Kinect. These imprecisions affect the quality of education and learning. Hence, together with clinicians we have defined bone landmarks which users can touch easily on their body while standing in front of the sensor. We demonstrate that these landmarks allow the proper deformation of medical data within the magic mirror and onto the human body, resulting in a more precise augmentation.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671803","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671803","Augmented Reality;Kinect;Anatomy Learning","Mirrors;Biomedical imaging;Education;Augmented reality;Bones;Computed tomography","augmented reality;biomedical education;bone;computer aided instruction;data visualisation;medical computing","interactive AR anatomy learning;anatomy education;augmented reality;AR magic mirror;intuitive visualization;realistic anatomical information;skeleton output;Kinect;education quality;learning quality;bone landmarks;sensor;medical data deformation;human body","","30","","12","","23 Dec 2013","","","IEEE","IEEE Conferences"
"Knowledge Spaces in VR: Intuitive Interfacing with a Multiperspective Hypermedia Environment","P. Gerjets; M. Lachmair; M. V. Butz; J. Lohmann",Leibniz-Institut für Wissensmedien; Leibniz-Institut für Wissensmedien; University of Tübingen; University of Tübingen,"2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","555","556","Virtual reality technologies, along with motion based input devices allow for the design of innovative interfaces between learners and digital knowledge resources. These interfaces might facilitate knowledge work in educational and scientific contexts. Compared to 2D interfaces, immersive 3D environments provide greater flexibility regarding the interface design, however, so far no general, theory-driven and validated design principles are available. Seeing that complex learning environments can foster the development of various cognitive abilities, like multiperspective reasoning skills (MPRS), such design principles are highly desirable. Using multiperspective hypermedia environments (MHEs) as a testbed, the presented project aims to identify and evaluate design principles, derived from cognitive science. We will create and study interactive, immersive 3D-interface to MHEs using virtual reality technology. To evaluate the developed system, we will contrast the acquisition of MPRS in 2D and 3D learning environments. We expect that the developed design principles will be directly applicable for enhancing the accessibility of other knowledge environments.","","978-1-5386-3365-6","10.1109/VR.2018.8446137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446137","VR;Hypermedia Environment;HCI;Interaction Design;H.5.1 [Multimedia Information Systems]: Artificial, augmented and virtual realities;H.5.2 [User Interfaces]: Theory and Methods","Conferences;Virtual reality;Three-dimensional displays;User interfaces","cognition;computer aided instruction;hypermedia;interactive systems;virtual reality","knowledge spaces;intuitive interfacing;multiperspective hypermedia environment;virtual reality technology;motion based input devices;innovative interfaces;digital knowledge resources;knowledge work;educational contexts;scientific contexts;immersive 3D environments;interface design;general theory-driven;complex learning environments;cognitive abilities;multiperspective reasoning skills;MPRS;MHEs;3D learning environments;developed design principles;knowledge environments;VR","","1","","15","","30 Aug 2018","","","IEEE","IEEE Conferences"
"Using Eye Tracked Virtual Reality to Classify Understanding of Vocabulary in Recall Tasks","J. Orlosky; B. Huynh; T. Hollerer",Osaka University; Osaka University; University of California Santa Barbara,"2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","27 Dec 2019","2019","","","66","667","In recent years, augmented and virtual reality (AR/VR) have started to take a foothold in markets such as training and education. Although AR and VR have tremendous potential, current interfaces and applications are still limited in their ability to recognize context, user understanding, and intention, which can limit the options for customized individual user support and the ease of automation. This paper addresses the problem of automatically recognizing whether or not a user has an understanding of a certain term, which is directly applicable to AR/VR interfaces for language and concept learning. To do so, we first designed an interactive word recall task in VR that required non-native English speakers to assess their knowledge of English words, many of which were difficult or uncommon. Using an eye tracker integrated into the VR Display, we collected a variety of eye movement metrics that might correspond to the user's knowledge or memory of a particular word. Through experimentation, we show that both eye movement and pupil radius have a high correlation to user memory, and that several other metrics can also be used to help classify the state of word understanding. This allowed us to build a support vector machine (SVM) that can predict a user's knowledge with an accuracy of 62% in the general case and and 75% for easy versus medium words, which was tested using cross-fold validation. We discuss these results in the context of in-situ learning applications.","","978-1-7281-5604-0","10.1109/AIVR46125.2019.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942340","virtual reality;eye tracking;memory;cognition;pupillometry;classification","Measurement;Gaze tracking;Pupils;Virtual reality;Task analysis;Cognition;Head","augmented reality;computer aided instruction;gaze tracking;interactive systems;linguistics;support vector machines;user interfaces;vocabulary","concept learning;interactive word recall task;eye tracker;VR display;eye movement metrics;pupil radius;user memory;support vector machine;in-situ learning applications;virtual reality;vocabulary understanding classification;AR/VR interfaces;language learning","","2","","28","","27 Dec 2019","","","IEEE","IEEE Conferences"
"Connecting User Experience to Learning in an Evaluation of an Immersive, Interactive, Multimodal Augmented Reality Virtual Diorama in a Natural History Museum & the Importance of Story","M. C. R. Harrington","University of Central Florida,Games and Interactive Media,Orlando,Florida,USA","2020 6th International Conference of the Immersive Learning Research Network (iLRN)","4 Aug 2020","2020","","","70","78","Reported are the findings of user experience and learning outcomes from a July 2019 study of an immersive, interactive, multimodal augmented reality (AR) application, used in the context of a museum. The AR Perpetual Garden App is unique in creating an immersive multisensory experience of data. It allowed scientifically naïve visitors to walk into a virtual diorama constructed as a data visualization of a springtime woodland understory and interact with multimodal information directly through their senses. The user interface comprised of two different AR data visualization scenarios reinforced with data based ambient bioacoustics, an audio story of the curator's narrative, and interactive access to plant facts. While actual learning and dwell times were the same between the AR app and the control condition, the AR experience received higher ratings on perceived learning. The AR interface design features of ""Story"" and ""Plant Info"" showed significant correlations with actual learning outcomes, while ""Ease of Use"" and ""3D Plants"" showed significant correlations with perceived learning. As such, designers and developers of AR apps can generalize these findings to inform future designs.","","978-1-7348995-0-4","10.23919/iLRN47897.2020.9155202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155202","augmented reality;bioacoustics;data visualization;immersive;information fidelity;informal learning;interactive;multimodal;museums;narrative;photorealistic;place illusion;presence;virtual dioramas;virtual reality","Data visualization;Virtual reality;Forestry;History;Biomedical acoustics;Three-dimensional displays;Games","augmented reality;bioacoustics;computer aided instruction;data visualisation;history;human computer interaction;learning (artificial intelligence);museums;user interfaces;virtual reality","user experience;natural history museum;July 2019 study;immersive, interactive, multimodal augmented reality application;AR Perpetual Garden App;immersive multisensory experience;scientifically naïve visitors;virtual diorama;data visualization;springtime woodland understory;multimodal information;user interface;audio story;interactive access;AR app;AR experience;perceived learning;actual learning outcomes","","","","29","","4 Aug 2020","","","IEEE","IEEE Conferences"
"Research Study Design for Teaching and Testing Fire Safety Skills with AR and VR Games","K. Tarkkanen; A. Lehto; D. Oliva; B. Somerkoski; T. Haavisto; M. Luimula","ICT, Turku University of Applied Sciences,Turku,Finland; RDI Services, Turku University of Applied Sciences,Turku,Finland; ICT, Turku University of Applied Sciences,Turku,Finland; University of Turku,Department of Teacher Education,Turku,Finland; ICT, Turku University of Applied Sciences,Turku,Finland; ICT, Turku University of Applied Sciences,Turku,Finland","2020 11th IEEE International Conference on Cognitive Infocommunications (CogInfoCom)","2 Nov 2020","2020","","","000167","000172","Virtual and augmented reality (VR & AR) games can provide innovative methods for teaching and learning important skills relating to fire safety. However, in an emergency context, testing the acquired knowledge and skills, i.e. verifying the learning, can be challenging. In this paper, we ask how the interplay between AR and VR could support learning verification. We describe two standalone games of both types, which interchangeably teach fire safety skills to children and verify their learning results. In particular, we describe the planned learning paths and research study designs for verification studies within and between these games to answer the above question. By operationalizing the two cases, the paper ends in proposing more generalized study design for AR and VR research in a fire safety context.","2380-7350","978-1-7281-8213-1","10.1109/CogInfoCom50765.2020.9237831","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237831","virtual reality;augmented reality;fire safety;serious games;research design","Conferences;Education;Games;Data collection;Augmented reality;Fire safety;Testing","augmented reality;computer aided instruction;computer games;emergency management;teaching","emergency context;learning verification;standalone games;augmented reality games;innovative methods;learning paths planning;fire safety skills teaching;fire safety skills testing;virtual reality games;AR games;VR games","","","","20","","2 Nov 2020","","","IEEE","IEEE Conferences"
"On the Design and Analysis of a Learning Control Algorithm for Point-to-point Tracking Tasks","N. Lin; R. Chi; R. Zhang","School of Automation & Electronic Engineering, Qingdao University of Science & Technology, Qingdao, 266042; School of Automation & Electronic Engineering, Qingdao University of Science & Technology, Qingdao, 266042; School of Mathematics and Physics, Qingdao University of Science & Technology, Qingdao, 266042","2018 IEEE 7th Data Driven Control and Learning Systems Conference (DDCLS)","1 Nov 2018","2018","","","189","193","A simple iterative learning control approach is proposed to track specific target points in this work. For a general linear system, a P-type point-to-point ILC and a PD-type point-to-point ILC laws are designed, respectively. The two control laws only use the tracking error at the specified point to update the input signal at the corresponding specified point. The input signal between two consecutive specified points remains the same as the input signal at the previous specified point. The proposed method has the advantages of simple structure and easy application. The convergence analysis and simulation results further confirmed the availability of the method.","","978-1-5386-2618-4","10.1109/DDCLS.2018.8516011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516011","Iterative learning control;Point-to-point;P-type;PD-type","Target tracking;Convergence;Trajectory;Task analysis;Inductors;Iterative learning control;Simulation","control system synthesis;convergence;iterative learning control;learning systems;linear systems;PD control","PD-type point-to-point ILC laws;tracking error;learning control algorithm;point-to-point tracking tasks;simple iterative learning control approach;general linear system;P-type point-to-point ILC laws;convergence analysis","","","","14","","1 Nov 2018","","","IEEE","IEEE Conferences"
"Virtual reality sickness detection: an approach based on physiological signals and machine learning","N. Martin; N. Mathieu; N. Pallamin; M. Ragot; J. -M. Diverrez","IRT b<>com,Cesson-Sevigne,France; Ubisoft,Montreuil,France; IRT b<>com,Cesson-Sevigne,France; IRT b<>com,Cesson-Sevigne,France; IRT b<>com,Cesson-Sevigne,France","2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","14 Dec 2020","2020","","","387","399","Virtual Reality (VR) is spreading to the general public but still has a major issue: VR sickness. To take it into consideration and minimize its occurrence, evaluation methods are required. The current methods are mainly based on subjective measurements and therefore have several drawbacks (e.g., non-continuous, intrusive). Physiological signals combined with Machine Learning (ML) methods seem an interesting approach to go beyond these limits. In this paper, we present a large-scale experimentation (103 participants) where physiological data (cardiac and electrodermal activities) and subjective data (perceived VR sickness) were gathered during 30-minute VR video game sessions. Using ML methods, models were trained to predict VR sickness level (based on the physiological data labeled with the subjective data). Results showed an explained variance up to 75% (in a regression approach) and an accuracy up to 91% (in a classification approach). Despite generalization issues, this method seems promising and valuable for a real time, automatic and continuous evaluation of VR sickness, based on physiological signals and ML models.","1554-7868","978-1-7281-8508-8","10.1109/ISMAR50242.2020.00065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284654","H.1.2 [Models and principles]: User/Machine Systems;Human factors;I.3.6 [Computer graphics]: Methodology and Techniques;Ergonomics","Solid modeling;Machine learning;Games;Predictive models;Particle measurements;Physiology;Real-time systems","ergonomics;learning (artificial intelligence);regression analysis;virtual reality","machine learning;general public;evaluation methods;subjective measurements;physiological signals;large-scale experimentation;subjective data;perceived VR sickness;30-minute VR video game sessions;VR sickness level;physiological data;regression approach;classification approach;generalization issues;automatic evaluation;continuous evaluation;ML models;virtual reality sickness detection","","","","133","","14 Dec 2020","","","IEEE","IEEE Conferences"
"Deepdive: Using AI, Machine Learning, and Virtual Reality to Explore Ancient Submerged Civilizations","T. Palazzolo; A. Lemke; S. Saad; C. Zhang; S. P. Jayanti; J. O’Shea; R. G. Reynolds","Wayne State University,Dept. of Computer Science,Detroit,USA; University of Texas,Dept. of Archaeology,Arlington,USA; Wayne State University,Dept. of Computer Science,Detroit,USA; Wayne State University,Dept. of Computer Science,Detroit,USA; Wayne State University,Dept. of Computer Science,Detroit,USA; University of Michigan,Dept. of Archaeology,Ann Arbor,USA; Wayne State University,Dept. of Computer Science,Detroit,USA","2020 Third International Conference on Artificial Intelligence for Industries (AI4I)","13 Nov 2020","2020","","","79","82","This paper provides an overview of the DeepDive system and its use to uncover ancient submerged sites. While this paper focuses on one example, the system is designed to be generally applicable to other environments that are difficult to access and contain unknown components. The incorporated AI tool learns to identify systematic patterns in the environment of an ancient civilization resources and can also provide an opportunity to generate and test Anthropological and Archaeological theories. This paper demonstrates some of these basic capabilities and their potential to aid in the generic exploration of ancient sites and the civilizations that produced them.","","978-1-7281-8701-3","10.1109/AI4I49448.2020.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9253122","n/a","Industries;Systematics;Virtual reality;Machine learning;Tools","archaeology;learning (artificial intelligence);virtual reality","machine learning;virtual reality;ancient submerged civilizations;DeepDive system;AI tool;ancient civilization resources;generic exploration;ancient sites","","","","8","","13 Nov 2020","","","IEEE","IEEE Conferences"
"K-12 VR Applications Based on ViveFocus Platform","C. Zhang; X. Wen; W. Yao",NA; NA; NA,"2018 International Conference on Virtual Reality and Visualization (ICVRV)","26 Aug 2019","2018","","","135","135","In the traditional teaching mode, students generally learn knowledge through words and pictures. This method sometimes increases the difficulty of learning and reduces the efficiency of learning because it is not intuitive. We explore a new teaching model that applies virtual reality technology to K-12 education to change the traditional teaching method. In this article, we use the two knowledge points of science and Chinese(the shape of the earth, and poem Snow) to display in the form of virtual reality, providing students with an immersive and rich sensory experience, deepening Students' memory and understanding of knowledge points.","2375-141X","978-1-5386-8497-9","10.1109/ICVRV.2018.00043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8710846","Virtual Reality, education, K-12","Virtual reality;Visualization","computer aided instruction;teaching;virtual reality","sensory experience;students memory;K-12 VR applications;immersive experience;virtual reality technology;teaching model;traditional teaching mode;ViveFocus platform;knowledge points","","","","0","","26 Aug 2019","","","IEEE","IEEE Conferences"
"Applying Role Reversal Strategy to Conduct the Virtual Job Interview: A Practice in Second Life Immersive Environment","B. Chang; J. Lee; Y. Chen; F. Yu","Dept. of E-Learning Design & Manage., Nat. Chiayi Univ., Chiayi, Taiwan; Dept. of E-Learning Design & Manage., Nat. Chiayi Univ., Chiayi, Taiwan; Dept. of E-Learning Design & Manage., Nat. Chiayi Univ., Chiayi, Taiwan; Inst. of Educ., Nat. Cheng Kung Univ., Tainan, Taiwan","2012 IEEE Fourth International Conference On Digital Game And Intelligent Toy Enhanced Learning","19 Apr 2012","2012","","","177","181","College students are going to face a new stage career as soon as they graduate from school, and how to assist college students to step into the career well is a very crucial issue in the college career counseling programming. Regarding the college career counseling programming, in general, the student-oriented activity helping the student to have the self-reflection is considered as a much more effective approach. Among the student-oriented activities, the role reversal strategy is the one that encourages students to actively take part in the activity and help students organize their thinking skills. Moreover, the role reversal strategy makes students have the empathy ability to make a right response in an opposite position. The study aims to apply the role reversal strategy to conduct the virtual job interview in Second Life immersive environment. Second Life which is an immersive technology can provide the innovative learning method and situated learning to reduce the obstacles where happened in the traditional classroom when applying role play and role reversal activities. Twenty-eight undergraduate students were recruited in the study. The study result indicates that most of the students prefer being the interviewers than to being the interviewees. And that they like to play role reversal activity in Second Life immersive environment to gain the interview experiences and improve their interview skills.","","978-1-4673-0885-4","10.1109/DIGITEL.2012.51","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6185614","role play;role reversal strategy;immersive environment;Second Life","Second Life;Interviews;Employee welfare;Engineering profession;Educational institutions;Internet","computer aided instruction;further education;virtual reality","role reversal strategy;virtual job interview;college students;college career counseling programing;self-reflection;student-oriented activities;empathy ability;second life immersive environment;immersive technology;innovative learning method;undergraduate students","","4","","10","","19 Apr 2012","","","IEEE","IEEE Conferences"
"[DC] Self-Adaptive Technologies for Immersive Trainings","J. Heyse","Ghent University - imec, IDLab","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1381","1382","Online learning is the preferred option for professional training, e.g. Industry 4.0 or e-health, because it is more cost efficient than on-site organisation of realistic training sessions. However, current online learning technologies are limited in terms of personalisation, interactivity and immersiveness that are required by applications such as surgery and pilot training. Virtual Reality (VR) technologies have the potential to overcome these limitations. However, due to its early stage of research, VR requires significant improvements to fully unlock its potential. The focus of this PhD is to tackle research challenges to enable VR for online training in three dimensions: (1) dynamic adaptation of the training content for personalised trainings, by incorporating prior knowledge and context data into self-learning algorithms; (2) mapping of sensor data onto what happens in the VR environment, by focusing on motion prediction techniques that use past movements of the users, and (3) investigating immersive environments with intuitive interactions, by gaining a better understanding of human motion in order to improve interaction. The designed improvements will be characterised though a prototype VR training platform for multiple use cases. This work will not only advance the state of the art on VR training, but also on online e-learning applications in general.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798207","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality;Applied computing;Life and medical sciences;Health informatics","Training;Virtual reality;Tracking;Resists;Haptic interfaces;Surgery;Prototypes","computer based training;sensors;virtual reality","online training;training content;personalised trainings;context data;self-learning algorithms;sensor data;VR environment;motion prediction techniques;immersive environments;intuitive interactions;prototype VR training platform;online e-learning applications;immersive trainings;on-site organisation;immersiveness;surgery;pilot training;training sessions;online learning technologies;self-adaptive technologies;virtual reality technologies","","","","6","","15 Aug 2019","","","IEEE","IEEE Conferences"
"Cellular automata simulation on FPGA for training neural networks with virtual world imagery","O. Van Acker; O. Lachish; G. Burnett","Department of Computer Science and Information Systems, Birkbeck, University of London, London, United Kingdom; Department of Computer Science and Information Systems, Birkbeck, University of London, London, United Kingdom; Enhyper Ltd., London, United Kingdom","2017 IEEE Conference on Computational Intelligence and Games (CIG)","26 Oct 2017","2017","","","304","305","We present ongoing work on a tool that consists of two parts: (i) A raw micro-level abstract world simulator with an interface to (ii) a 3D game engine, translator of raw abstract simulator data to photorealistic graphics. Part (i) implements a dedicated cellular automata (CA) on reconfigurable hardware (FPGA) and part (ii) interfaces with a deep learning framework for training neural networks. The bottleneck of such an architecture usually lies in the fact that transferring the state of the whole CA significantly slows down the simulation. We bypass this by sending only a small subset of the general state, which we call a 'locus of visibility', akin to a torchlight in a darkened 3D space, into the simulation. The torchlight concept exists in many games but these games generally only simulate what is in or near the locus. Our chosen architecture will enable us to simulate on a micro level outside the locus. This will give us the advantage of being able to create a larger and more fine-grained simulation which can be used to train neural networks for use in games.","2325-4289","978-1-5386-3233-8","10.1109/CIG.2017.8080450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8080450","Cellular Automata;FPGA;Simulation;Machine learning;Neural networks;Unreal Engine","Neural networks;Games;Engines;Field programmable gate arrays;Computer architecture;Training;Automata","cellular automata;computer games;computer graphics;digital simulation;field programmable gate arrays;learning (artificial intelligence);virtual reality","cellular automata simulation;FPGA;virtual world imagery;raw microlevel abstract world simulator;raw abstract simulator data;photorealistic graphics;dedicated cellular automata;reconfigurable hardware;deep learning framework;darkened 3D space;fine-grained simulation;neural network training;3D game engine","","","","6","","26 Oct 2017","","","IEEE","IEEE Conferences"
"Teaching High School Computer Science with Videos of Historical Figures -- An Augmented Reality Approach","C. Hsu; M. Chen; C. Wu","Grad. Inst. of Inf. & Comput. Educ., Nat. Taiwan Normal Univ., Taipei, Taiwan; Grad. Inst. of Inf. & Comput. Educ., Nat. Taiwan Normal Univ., Taipei, Taiwan; Grad. Inst. of Inf. & Comput. Educ., Nat. Taiwan Normal Univ., Taipei, Taiwan","2015 International Conference on Learning and Teaching in Computing and Engineering","18 Jun 2015","2015","","","22","25","This study investigated the effects of teaching history of computing with videos of historical figures. Augmented reality (AR) techniques were applied to assist student accessing the videos of historical figures while reading a printed textbook. Whenever a student was interested in a historical figure, one could use a tablet PC to scan the figure's picture, and the corresponding video about the person would then be played on the screen. We adapted thirteen videos of historical figures in computer network field and adopted a quasi-experimental method to evaluate the effectiveness of the AR-based learning approach. Two classes of high school students, with a total of 84 students, participated in the experiment. One class of the students used Tablet PCs to access the videos of historical figures, and the other class using traditional didactic instruction served as the control group. The data collected for analysis are students' achievement test scores and answers to a questionnaire, which consists of questions on attitudes toward learning, perspectives of nature of science, and perceptions on the AR activities. Our findings showed that the AR-based historical figure videos helped students comprehend learning contents and promoted their attitudes toward learning. Students appreciated the convenience of using AR tools to access the history videos. Future research should investigate other approaches to integrate AR with the videos of historical figure, and in general, to integrate AR with other media format of computing history.","","978-1-4799-9967-5","10.1109/LaTiCE.2015.30","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7126226","history of computing;videos;historical figures;augmented reality","Videos;History;Education;Computers;Augmented reality;Context;Computer networks","augmented reality;computer aided instruction;computer science education;notebook computers","high school computer science teaching;videos;historical figures;augmented reality approach;computing history;AR-based learning approach;printed textbook;tablet PC computer network field;quasiexperimental method;didactic instruction;AR activities;media format;learning contents","","2","","8","","18 Jun 2015","","","IEEE","IEEE Conferences"
"VR Sickness Prediction for Navigation in Immersive Virtual Environments using a Deep Long Short Term Memory Model","Y. Wang; J. -R. Chardonnet; F. Merienne","Arts et Metiers, LISPEN EA7515, HESAM, UBFC, Institut Image; Arts et Metiers, LISPEN EA7515, HESAM, UBFC, Institut Image; Arts et Metiers, LISPEN EA7515, HESAM, UBFC, Institut Image","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1874","1881","This paper proposes a new objective metric of visually induced motion sickness (VIMS) in the context of navigation in virtual environments (VEs). Similar to motion sickness in physical environments, VIMS can induce many physiological symptoms such as general discomfort, nausea, disorientation, vomiting, dizziness and fatigue. To improve user satisfaction with VR applications, it is of great significance to develop objective metrics for VIMS that can analyze and estimate the level of VR sickness when a user is exposed to VEs. One of the well-known objective metrics is the postural instability. In this paper, we trained a LSTM model for each participant using a normal-state postural signal captured before the exposure, and if the postural sway signal from post-exposure was sufficiently different from the pre-exposure signal, the model would fail at encoding and decoding the signal properly; the jump in the reconstruction error was called loss and was proposed as the proposed objective measure of simulator sickness. The effectiveness of the proposed metric was analyzed and compared with subjective assessment methods based on the simulator sickness questionnaire (SSQ) in a VR environment, achieving a Pearson correlation coefficient of. 89. Finally, we showed that the proposed method had the potential to be deployed within a closed-loop system and get real-time performance to predict VR sickness, opening new insights to develop user-centered and customized VR applications based on physiological feedback.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798213","Human-centered computing;Virtual reality;Walkthrough evaluations;User interface design;Interaction devices;Computing methodologies;Machine learning;Machine learning approaches;Neural networks","Navigation;Virtual environments;Physiology;Real-time systems;Three-dimensional displays;Logic gates;Deep learning","closed loop systems;human factors;physiology;recurrent neural nets;virtual reality","VR sickness prediction;navigation;immersive virtual environments;deep long short term memory model;visually induced motion sickness;VIMS;VEs;physical environments;physiological symptoms;general discomfort;dizziness;fatigue;user satisfaction;VR applications;postural instability;LSTM model;normal-state postural signal;postural sway signal;post-exposure;pre-exposure signal;objective measure;simulator sickness questionnaire;VR environment;user-centered VR applications","","1","","34","","15 Aug 2019","","","IEEE","IEEE Conferences"
"Comparison of a Gamified and Non-Gamified Virtual Reality Training Assembly Task","F. Palmas; D. Labode; D. A. Plecher; G. Klinker","Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Research Group Augmented Reality, Technical University of Munich, Munich, Germany","2019 11th International Conference on Virtual Worlds and Games for Serious Applications (VS-Games)","14 Oct 2019","2019","","","1","8","By using simulations in virtual reality (VR), people have the chance to train without supervision in a safe and controlled environment. VR simulation training allows users to gain new skills and apply them to real-life situations. However, the learning curve of this technology from a novice level could influence the expected learning results of a training session. A training approach based on the combination of VR and gamification could speed up this overall learning process and not just for a novice. In this paper we evaluate how gamification in a VR training session can improve the efficiency of the training and the accuracy of the task execution in a real-world practical test. In the training scenario of this study, 50 randomly assigned participants were divided into two groups. The groups were assigned to a gamified and a non-gamified version of the same VR training and were then guided through a step-by-step tutorial outlining how to solve an assembly task. Performance differences were evaluated based on time taken and specific errors made during the training session. The results of this study show, in general, that beneficial effects can be attributed to the use of gamification in the conducted VR training simulation, particularly for the VR novice participants.","2474-0489","978-1-7281-4540-2","10.1109/VS-Games.2019.8864583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8864583","virtual training;virtual reality;gamification;training;learning transfer;assembly task","Training;Task analysis;Games;Tutorials;Solid modeling;Augmented reality","computer based training;computer simulation;serious games (computing);virtual reality","VR simulation training;learning curve;novice level;gamification;learning process;VR training session;task execution;virtual reality training assembly task","","3","","44","","14 Oct 2019","","","IEEE","IEEE Conferences"
"Augmented Reality Learning Resources in Anatomy","L. F. García Arias; N. D. Duque Méndez; C. Dias Flores",Universidad Nacional de Colombia; Universidad Nacional de Colombia; Universidade Federal de Ciências,"2018 XIII Latin American Conference on Learning Technologies (LACLO)","1 Aug 2019","2018","","","476","483","Augmented reality can be applied in different areas of knowledge and one of the most explored fields has been health. The objective of this article is to present the results obtained from the evaluation of learning resources developed using augmented reality technology. The evaluation was made by students of health undergraduate programs who participated in the Academic Day of the Biomedicine program of a Brazilian higher education institution. 8 educational resources were evaluated, all related to the area of general anatomy. The resources were evaluated by 41 students who answered a validated questionnaire for the evaluation of educational resources with questions about: learning, interactivity, engagement, attractiveness, functionality and autonomy. The evaluation was considered valid. The challenge is to find interactive alternatives that stimulate and simultaneously incorporate content, with a depth appropriate to the objective of the subject. Critics in the evaluation will serve as the basis for adjustments in the next learning resources to be developed.","","978-1-7281-0382-2","10.1109/LACLO.2018.00085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8783620","Augmented reality;general anatomy;learning resource","Three-dimensional displays;Visualization;Augmented reality;Education;Solid modeling;Software;Two dimensional displays","augmented reality;biomedical education;computer aided instruction;educational institutions;further education","Brazilian higher education institution;augmented reality learning resources;health undergraduate programs;biomedicine program","","","","","","1 Aug 2019","","","IEEE","IEEE Conferences"
"Inverse Kinematics and Temporal Convolutional Networks for Sequential Pose Analysis in VR","D. C. Jeong; J. J. Xu; L. C. Miller","Santa Clara University,Department of Communication,Santa Clara,USA; University of Southern California,Annenberg School for Communication,Los Angeles,USA; University of Southern California,Annenberg School for Communication,Los Angeles,USA","2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","15 Jan 2021","2020","","","274","281","Drawing from a recent call to advance generalizability and causal inference in psychological science using contextually representative research designs [1], we introduce a conceptual framework that integrates techniques in machine perception of poses with VR-driven inverse kinematic character animation, leveraging the Unity game engine to mediate between the human user and the machine learner. This Computational Virtual Reality (C-VR) system contains the following components: a) Human motion capture (VR), b) Human to avatar character animation (inverse kinematics), c) character animation recordings (virtual cameras), d) avatar pose detection (OpenPose), d) avatar pose classification (SVM), and e) sequential avatar moving pose analyses (TCN). By leveraging the precision in representation afforded in virtual environments and agents and the precision in perception afforded in computer vision and machine learning in a unified system, we may take steps towards understanding a wider range of human complexity.","","978-1-7281-7463-1","10.1109/AIVR50618.2020.00056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319069","avatars;neural networks;computer vision","Kinematics;Psychology;Avatars;Pose estimation;Computer vision;Animation;Skeleton","avatars;computer animation;computer games;computer vision;convolutional neural nets;human computer interaction;learning (artificial intelligence);pose estimation;psychology;solid modelling;virtual reality","human complexity;sequential pose analysis;causal inference;psychological science;contextually representative research designs;machine perception;VR-driven inverse kinematic character animation;Unity game engine;human user;machine learner;C-VR;human motion capture;avatar character animation;inverse kinematics;virtual cameras;virtual environments;computer vision;machine learning;computational virtual reality system","","","","81","","15 Jan 2021","","","IEEE","IEEE Conferences"
"Virtual Reality and Statistical Thinking Enhancement","O. L. Ríos; L. J. L. López","Ind. Eng. Dept., ITESM, Monterrey, Mexico; UNAM, USA","2019 IEEE Integrated STEM Education Conference (ISEC)","24 Oct 2019","2019","","","367","370","For decades, simulation has been a highly reliable tool for decision making. Even before its fundamental origin, the mathematical branch of system dynamics led to pioneering advances in research, technology and business. Today, virtual reality has become a mainstream technique for employee training. The combination of augmented and virtual reality technologies along with traditional methods of simulation has led to the development of a new powerful instrument of learning applied to complex systems. Our work is the first step of an ambitious project which aims to reinforce the Statistical Thinking of undergraduate students at the Monterrey Institute of Technology and Higher Education. Using virtual reality and numerical simulation methods our project connects processes and statistics. The student faces the challenge to solve a process problem, which is presented in a first step as a 3D video. By using virtual reality, we expect to develop strong and soft skills in our students enhanced by what we call the five S linked by the five C: Scope-Strategy-Standard-Seamless and Success with Choice-Collaboration-Communication-Critical-Thinking and Creativity. We have measured the impact of using this strategy on student learning. For the last two semesters the outcome has been positive for our learning model, in both quantitative and qualitative variables. We have carried out a parametric hypotheses test, comparing the mean grades obtained in a similar final exam, by students having followed our new method with those having a traditional learning method. Finally, by means of a general survey, we obtained that the student's general opinion, concerning learning statistics by visualizing the 3D real process and challenges, is highly motivating and rewarding.","2330-331X","978-1-7281-1502-3","10.1109/ISECon.2019.8881966","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8881966","Statistical Thinking;STEM;Virtual Reality;Educational Innovation","Three-dimensional displays;Virtual reality;Education;Industries;Creativity;Headphones;Solid modeling","computer aided instruction;educational institutions;further education;mathematics computing;statistical analysis;virtual reality","virtual reality;learning method;statistical thinking enhancement;system dynamics;employee training;augmented reality;undergraduate students;Monterrey Institute of Technology;higher education","","1","","5","","24 Oct 2019","","","IEEE","IEEE Conferences"
"Explore Convolutional Neural Networks in Virtual Reality","N. Meissler; A. Wohlan; N. Hochgeschwender; A. Schreiber",German Aerospace Center (DLR); German Aerospace Center (DLR); German Aerospace Center (DLR); German Aerospace Center (DLR),"2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","27 Dec 2019","2019","","","249","2491","We visualize the functionality of Convolutional Neural Networks (CNN) in Virtual Reality to help newcomers understand the general functioning of these algorithms. Our interactive visualization allows users to explore CNNs layer by layer.","","978-1-7281-5604-0","10.1109/AIVR46125.2019.00056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942281","virtual-reality;neural-networks;interactive-learning","Visualization;Conferences;Virtual reality;Learning (artificial intelligence);Convolutional neural networks","convolutional neural nets;data visualisation;virtual reality","convolutional neural networks;virtual reality;general functioning;interactive visualization;CNN","","","","4","","27 Dec 2019","","","IEEE","IEEE Conferences"
"In-Situ Labeling for Augmented Reality Language Learning","B. Huynh; J. Orlosky; T. Höllerer","University of California, Santa Barbara; Osaka University; University of California, Santa Barbara","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1606","1611","Augmented Reality is a promising interaction paradigm for learning applications. It has the potential to improve learning outcomes by merging educational content with spatial cues and semantically relevant objects within a learner's everyday environment. The impact of such an interface could be comparable to the method of loci, a well known memory enhancement technique used by memory champions and polyglots. However, using Augmented Reality in this manner is still impractical for a number of reasons. Scalable object recognition and consistent labeling of objects is a significant challenge, and interaction with arbitrary (unmodeled) physical objects in AR scenes has consequently not been well explored. To help address these challenges, we present a framework for in-situ object labeling and selection in Augmented Reality, with a particular focus on language learning applications. Our framework uses a generalized object recognition model to identify objects in the world in real time, integrates eye tracking to facilitate selection and interaction within the interface, and incorporates a personalized learning model that dynamically adapts to student's growth. We show our current progress in the development of this system, including preliminary tests and benchmarks. We explore challenges with using such a system in practice, and discuss our vision for the future of AR language learning applications.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798358","Human-centered computing;Mixed and augmented reality;Theory and algorithms for application domains;Semi-supervised learning","Three-dimensional displays;Real-time systems;Two dimensional displays;Labeling;Augmented reality;Object recognition;Cameras","augmented reality;computer aided instruction;linguistics;natural languages","language learning applications;generalized object recognition model;personalized learning model;augmented reality language learning;semantically relevant objects;memory champions;polyglots;scalable object recognition;arbitrary physical objects;in-situ object;memory enhancement technique","","2","","33","","15 Aug 2019","","","IEEE","IEEE Conferences"
"Group immersive education with digital fulldome planetariums","K. C. Yu; K. Saham; V. Sahami; L. Sessions; G. Denn","Denver Museum of Nature & Science, USA; Metropolitan State University of Denver, USA; Metropolitan State University of Denver, USA; Metropolitan State University of Denver, USA; Metropolitan State University of Denver, USA","2017 IEEE Virtual Reality (VR)","6 Apr 2017","2017","","","237","238","Although fulldome video digital theaters evolved from traditional planétariums, they are more akin to virtual reality (VR) theaters that create large-scale, group immersive experiences. In order to help understand how immersion and wide fields-of-view (FOV) impact learning, we studied the use of visualizations on topics that do and do not require spatial understanding in astronomy classes. We find a significant difference between students who viewed visualizations in the dome versus those that saw non-immersive content in their classrooms, with the former showing the greatest retention. Our results suggest that immersive visuals help free up cognitive resources that can be used to build mental models requiring spatial understanding, and the physical display size combined with the wide FOV may result in greater attention. Although fulldome is a complementary medium to traditional VR, our results have implications for future head-mounted displays.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892264","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892264","1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism — Virtual reality;1.4.0 [Image Processing and Computer Vision]: General — Image displays","Visualization;Education;Astronomy;Virtual environments;Three-dimensional displays;Cognitive science","virtual reality","group immersive education;digital fulldome planetariums;virtual reality;cognitive resources;FOV;fulldome video digital theaters","","","","15","","6 Apr 2017","","","IEEE","IEEE Conferences"
"Transform children's library into a mixed-reality learning environment: Using smartwatch navigation and information visualization interfaces","K. Wu; C. Chen; T. Chiu; I. Chiang","Department of Interaction Design, National Taipei University of Technology, Taipei, Taiwan; Department of Interaction Design, National Taipei University of Technology, Taipei, Taiwan; Center for General Education, Taipei Medical University, Taipei, Taiwan; Graduate Institute of Data Science, Taipei Medical University, Taipei, Taiwan","2017 Pacific Neighborhood Consortium Annual Conference and Joint Meetings (PNC)","14 Dec 2017","2017","","","1","8","Digital natives are born into an information-dense resource-plentiful world, which greatly stimuluses their numerous needs with regard to libraries. Children have insufficient conceptual framework of knowledge and hard to understand the correlation between call numbers and themes. Young readers need an interactive, learning environment to enable them to find the books which are interested in by thematic order. Researchers apply the Cognitive-developmental theory and children's information seeking behaviors into the invention of a mixed-reality futuristic library for children using cutting-edge technologies. We first created a visualized children's book classified system using facet structured thesaurus, and employed beacon indoor positioning technologies to locate categorization of themes in non-linear arrangement of bookshelves. We then designed navigation interfaces to help children search for books using smartwatches. An integration of RFID smart bookshelf for popular books (placed in thematic-random-order), and visualized browsing interfaces were designed for children. Digital wall screens in clustering (inspired) and categorization (discovering) representations developed to recommend books for children in different cognitive-development groups. For children learning library-use instruction in a virtual-world environment, we created a mixed-reality corridor, in which children were immersed in interactive games and learn what the classification numbers mean. The world children live in is a three-dimensional space. Children at the concrete operational stage of development are apt to use their experiences in this physical world to navigate virtual worlds. Researchers proposed and examined various spatial-metadata schemes for a mixed-reality environment designed for children to find books. Smart library with innovative technologies has the power to transform informationseeking behavior and brings libraries to life, allowing children readers to benefit from digital learning in a state-of-the-art library environment.","","978-9-8695-3170-2","10.23919/PNC.2017.8203526","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8203526","Digital library for children;Library navigation;Visualized interface;Customized classification scheme for children books;Serious game","Libraries;Navigation;Virtual reality;Visualization;Knowledge engineering;Pediatrics;Games","cognition;computer aided instruction;data visualisation;digital libraries;human computer interaction;information retrieval;meta data;mobile computing;radiofrequency identification;technology management;user interfaces;virtual reality","mixed-reality futuristic library;children readers;mixed-reality learning environment;smartwatch navigation;information visualization interfaces;visualized children book classified system;children library;cognitive-developmental theory;children information seeking behaviors;RFID smart bookshelf;cutting-edge technologies;facet structured thesaurus;spatial-metadata schemes","","","","8","","14 Dec 2017","","","IEEE","IEEE Conferences"
"ARCoins. An Augmented Reality App for Learning about Numismatics","M. -. Juan; M. Loachamín-Valencia; I. Garcia-Garcia; J. M. Melchor; J. Benedito","Inst. Univ. de Autom. e Inf. Ind., Univ. Politec. de Valencia, Valencia, Spain; Inst. Univ. de Autom. e Inf. Ind., Univ. Politec. de Valencia, Valencia, Spain; DSIC, Univ. Politec. de Valencia, Valencia, Spain; Univ. Jaume I, Castellón, Spain; Univ. Jaume I, Castellón, Spain","2017 IEEE 17th International Conference on Advanced Learning Technologies (ICALT)","7 Aug 2017","2017","","","466","468","Museum visitors need support tools to facilitate their informal learning. In this paper, we present ARCoins, an augmented reality app to support informal learning about numismatics. Our app helps museum visitors to read the deteriorated text of coins and also shows additional information that offers a clear idea of the general meaning of the coinage of the coins. The app recognizes the real coins. We carried out a study to determine the potential of the app. A total of twenty-eight subjects between 19 and 65 years old participated in the study. The participants observed the real coins using ARCoins and a magnifying glass. From the results, ARCoins allows the participants to read the deteriorated text and even observe the most imperceptible details of the coins. There were statistically significant differences for reading the text when the participants used ARCoins and the magnifying glass in favour of ARCoins. The participants preferred ARCoins for a more enriching museum experience. ARCoins could be a valuable AR app for informal learning about numismatics in museums.","2161-377X","978-1-5386-3870-5","10.1109/ICALT.2017.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8001834","ARCoins;Augmented Reality;informal learning;museums;numismatics;cultural heritage","Glass;Augmented reality;Androids;Humanoid robots;Mobile handsets;Cameras;Cultural differences","augmented reality;computer aided instruction;museums","ARCoins;augmented reality app;numismatics;museum visitors;informal learning;coinage;coins;museum experience;valuable AR app","","","","6","","7 Aug 2017","","","IEEE","IEEE Conferences"
"A Structure to Integrate Natural Interaction into VR Systems for Education in Health","D. d. S. Ferreira; L. S. Machado","NA; Lab. de Tecnol. para o Ensino Virtual e Estatistica (LabTEVE), Univ. Fed. da Paraiba (UFPB), Joao Pessoa, Brazil","2013 XV Symposium on Virtual and Augmented Reality","7 Nov 2013","2013","","","208","211","The use of virtual reality (VR) systems for education can improve the learning process in health, providing more motivation and realism to users. In general, specific devices are used to increase immersion and, in general, demand an adaptation period. Natural Interaction (NI) can provide an intuitive way to interact in VR systems since it can improve and make the communication between users and the system easier. The present work investigated NI techniques provided by VR frameworks for health. As a result, was designed a structure to integrate NI techniques into a framework.","","978-0-7695-5001-5","10.1109/SVR.2013.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6655781","Natural Interaction;Virtual Reality;Optical Tracking;Health Education","Visualization;Education;Virtual reality;Three-dimensional displays;Mice;Nickel;Multimedia communication","biomedical education;computer aided instruction;health care;human computer interaction;medical computing;virtual reality","VR frameworks;NI techniques;user communication;natural Interaction;adaptation period;user realism;user motivation;learning process;health education;VR systems;virtual reality","","","","21","","7 Nov 2013","","","IEEE","IEEE Conferences"
"Can Virtual Reality Enhance Learning: A Case Study in Materials Science","V. Caro; B. Carter; S. Dagli; M. Schissler; J. Millunchick","Materials Science and Engineering, University of Michigan, Ann Arbor, Michigan, USA; Materials Science and Engineering, University of Michigan, Ann Arbor, Michigan, USA; Materials Science and Engineering, University of Michigan, Ann Arbor, Michigan, USA; Stamps School of Art & Design, University of Michigan, Ann Arbor, Michigan, USA; Materials Science and Engineering, University of Michigan, Ann Arbor, Michigan, USA","2018 IEEE Frontiers in Education Conference (FIE)","7 Mar 2019","2018","","","1","4","This Innovative Practice Work in Progress tests whether virtual reality (VR) can enhance students' understanding in scientific fields, specifically Materials Science and Engineering (MSE), when compared to more traditional approaches. Of interest is how VR-based learning activities impact the performance of individuals with experience ranging from none to expert level in MSE compared to paper-based learning activities. To test this, an activity related to crystal structures, similar to what students would see in an introductory level MSE course, was administered to a group of students with varying knowledge levels in MSE. Each participant completed the same worksheet in either VR or on paper. The testing group was composed of seven students, which was too small of a sample size to draw definitive conclusions, yet significant observations could be made. On questions that required recall of prior knowledge, participants using paper-based activities generally performed better, whereas on questions requiring more spatial reasoning and critical thinking, VR participants generally performed better. Most of the participants reported enjoying the VR activities and platform, indicating high usability. These results suggest that VR may be beneficial in teaching complex spatial concepts.","2377-634X","978-1-5386-1174-6","10.1109/FIE.2018.8659267","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8659267","Virtual Reality;Engineering;Education;Materials;Science","Materials science and technology;Virtual reality;Crystals;Education;Three-dimensional displays;Solid modeling;Computational modeling","computer aided instruction;materials science;materials science computing;teaching;virtual reality","Innovative Practice Work;scientific fields;expert level;crystal structures;paper-based activities;VR participants;VR activities;virtual reality enhance learning;knowledge levels;Materials Science and Engineering;introductory level MSE course","","","","11","","7 Mar 2019","","","IEEE","IEEE Conferences"
"A Novel Approach for Training Crane Operators: Serious Game on Crane Simulator","A. K. George; M. L. McLain; K. Bijlani; R. Jayakrishnan; R. R. Bhavani","Sch. of Eng., Amrita e-Learning Res. Lab., Amrita Univ., Amritapuri, India; Sch. of Eng., AMMACHI Labs., Amrita Univ., Amritapuri, India; Sch. of Eng., Amrita e-Learning Res. Lab., Amrita Univ., Amritapuri, India; Sch. of Eng., Amrita e-Learning Res. Lab., Amrita Univ., Amritapuri, India; Sch. of Eng., Amrita e-Learning Res. Lab., Amrita Univ., Amritapuri, India","2016 IEEE Eighth International Conference on Technology for Education (T4E)","16 Jan 2017","2016","","","116","119","Any large scale construction related activity generally requires the use of cranes. A crane operator must be appropriately skilled to avoid any mishap at the construction site. This can be accomplished by training crane operators on all the safety procedures and methods of crane operation to be practiced. In this paper we explore a method whereby anyone who is being trained as a crane operator, must first learn all the operational procedures and safety norms by playing a simulation of operating a crane in a serious game. Once the user successfully completes the different levels of this serious game, he can then 'graduate' to operate an actual crane. Serious games are proven method of cost effective and risk free simulated environments where a player can learn all the nuances of any simulated activity, herein operating a crane. We implemented a learning methodology, Gagne's 9 Events of Learning, in order to ensure the player develops a high level of understanding. We used an actual crane as a reference model (Ace14XW) for this game. We surveyed several crane operators and found that this crane model game enhanced their knowledge of handling and precautionary measures. The users also reported an increased confidence level while operating a real crane.","","978-1-5090-6115-0","10.1109/T4E.2016.030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814805","Unity3D;Animations;Crane Simulation;Mobile crane;Simulator;Training system;Serious Game;Gagne's 9 events model","Cranes;Games;Training;Solid modeling;Mobile communication;Accidents;Vehicles","computer aided instruction;cranes;digital simulation;serious games (computing)","crane operator training;serious game;crane simulator;large scale construction related activity;safety procedures;risk free simulated environments;Gagne's 9 events of learning;learning methodology","","2","","12","","16 Jan 2017","","","IEEE","IEEE Conferences"
"A taxonomy and comparison of haptic actions for disassembly tasks","A. Bloomfield; Yu Deng; J. Wampler; P. Rondot; D. Harth; M. McManus; N. Badler","Center for Human Modeling & Simulation, Pennsylvania Univ., PA, USA; Center for Human Modeling & Simulation, Pennsylvania Univ., PA, USA; NA; NA; NA; NA; NA","IEEE Virtual Reality, 2003. Proceedings.","2 Apr 2003","2003","","","225","231","The usefulness of modern day haptics equipment for virtual simulations of actual maintenance actions is examined. In an effort to categorize which areas haptic simulations may be useful, we have developed a taxonomy for haptic actions. This classification has two major dimensions: the general type of action performed and the type of force or torque required. Building upon this taxonomy, we selected three representative tasks from the taxonomy to evaluate in a virtual reality simulation. We conducted a series of human subject experiments to compare user performance and preference on a disassembly task with and without haptic feedback using CyberGlove, Phantom, and SpaceMouse interfaces. Analysis of the simulation runs shows Phantom users learned to accomplish the simulated actions significantly more quickly than did users of the CyberGlove or the SpaceMouse. Moreover, a lack of differences in the post-experiment questionnaire suggests that haptics research should include a measure of actual performance speed or accuracy rather than relying solely on subjective reports of a device's ease of use.","1087-8270","0-7695-1882-6","10.1109/VR.2003.1191143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1191143","","Taxonomy;Haptic interfaces;Data gloves;Imaging phantoms;Analytical models;Torque;Virtual reality;Humans;Feedback;Velocity measurement","haptic interfaces;virtual reality;digital simulation;assembling","haptic actions;disassembly tasks;haptic simulations;virtual reality simulation;human subject experiments;user performance;disassembly task;haptic feedback;CyberGlove;Phantom;SpaceMouse interfaces;simulation runs;simulated actions;haptics research","","17","","14","","2 Apr 2003","","","IEEE","IEEE Conferences"
"Development and application of a surgical process simulation system using VR technology","L. Zhou; R. Sato","Osaka Electro-Communication University,Faculty of Information Science and Arts,Department of Digital Games,Shijonawateshi,Osaka,Japan; Osaka Electro-Communication University,Faculty of Information Science and Arts,Department of Digital Games,Shijonawateshi,Osaka,Japan","2020 IEEE 9th Global Conference on Consumer Electronics (GCCE)","21 Dec 2020","2020","","","655","657","For medical students, instruction via on-site observation of surgery is often a mandatory part of their training. Being present in an operating room allows students to deepen their understanding of various surgical procedures while giving them an opportunity to experience the hands-on environment and general atmosphere. However, traditional instruction methods through observation contain many disadvantages that make learning surgical procedures difficult and problematic. For example, during long sessions of endoscopic surgery, the pictures taken display only a small portion of the internal body, making it difficult for students to fully understand the details of the entire process. Locating the positions of internal organs and understanding the direction of instrument movement is also inconvenient. However, with the aid of a virtual reality support system, students can learn through real-time interactive demonstrations of the surgical process that include details about operating position and other specificities. The result is increased accessibility to facilitate the understanding of the entire surgery process coupled with the reduction of fatigue and other distractions that arise from prolonged observation in a traditional operating room. So far, in medical research, the ""Production of patient explanation video for transrectal prostate biopsy"" jointly researched and produced with the Department of Renal Urology, Kansai Medical University, has been reviewed by the Research Ethics Review Board (IRB) and obtained permission for use Later, through actual use by patients and medical practitioners, great results have been obtained.","2378-8143","978-1-7281-9802-6","10.1109/GCCE50665.2020.9291758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9291758","Robot-assisted laparoscopic radical prostatectomy;surgical apprenticeship for medical students;virtual reality support;Process Demonstration System","Training;Solid modeling;Surgery;Virtual reality;Production;Real-time systems;Robots","biological organs;biomedical education;cancer;computer aided instruction;endoscopes;medical computing;medical robotics;surgery;virtual reality","surgical process simulation system;VR technology;medical students;on-site observation;mandatory part;surgical procedures;hands-on environment;general atmosphere;traditional instruction methods;long sessions;endoscopic surgery;internal body;internal organs;instrument movement;virtual reality support system;real-time interactive demonstrations;operating position;entire surgery process;prolonged observation;traditional operating room;medical research;Kansai Medical University;medical practitioners","","","","4","","21 Dec 2020","","","IEEE","IEEE Conferences"
"Application of Augmented Reality technology to promote interactive learning","R. Chang; Z. Yu","Taiwan Police College, Taipei, Taiwan, R.O.C.; Department of Digital Media Design, Asia University, Taichung, Taiwan, R.O.C.","2017 International Conference on Applied System Innovation (ICASI)","24 Jul 2017","2017","","","1673","1674","In recent years, the learning tools based on AR (Augmented Reality) technology have been highly recommended to be applied in educational sites. Teachers display abstract scientific changes in specific images by applying AR technology. By way of applying AR inter-operation to enhance students' interests in learning as well as reduce their cognitive load. This study has applied AR technology to establish a virtual biological laboratory App to be provided for college freshmen to carry out biological experiments as a curriculum preview and experiencing. The content of Virtual biology laboratory App includes units such as virtual microscope, biological anatomy concept, cell division process, and frog's bones. Through the introduction of digital technology into the general biology curriculums are then emerged with AR technology so as to confer how AR technology affects students study effects and biological experimental knowledge recognition. The study has implemented an experiment in object to college freshmen and the experiment results indicate that the integration of AR technology with teaching has made students' attitude towards learning more positive. Through interactive operation and learning, students are better able to master knowledge of fundamental biological experiments. Through the process of the study, the researcher has found the importance that students study scientific knowledge with interactive technology. Consequently, the Institute has designed a virtual biology laboratory App to achieve the benefits of action learning, situational simulation and interactive experiencing.","","978-1-5090-4897-7","10.1109/ICASI.2017.7988257","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7988257","Augmented Reality;Biology Experimental Curriculum;Interactive learning","Biology;Microscopy;Education;Media;Augmented reality;Tools;Mobile handsets","augmented reality;biology computing;computer aided instruction;digital simulation","augmented reality technology;interactive learning;AR technology;educational sites;abstract scientific changes;AR interoperation;student interests;cognitive load reduction;virtual biological laboratory app;college freshmen;biological experiments;curriculum preview;digital technology;general biology curriculums;biological experimental knowledge recognition;student attitude;interactive operation;fundamental biological experiments;interactive technology;action learning;situational simulation;interactive experiencing","","4","","5","","24 Jul 2017","","","IEEE","IEEE Conferences"
"Teaching Marker-based Augmented Reality in a PBL Based Online Robotics Competition","A. Sarkar; K. Arya","Indian Institute of Technology Bombay,Department of Computer Science & Engineering,Powai Mumbai,India,400076; Indian Institute of Technology Bombay,Department of Computer Science & Engineering,Powai Mumbai,India,400076","2020 IEEE 20th International Conference on Advanced Learning Technologies (ICALT)","4 Aug 2020","2020","","","338","340","e-Yantra is a robotics outreach project funded by MHRD, Govt of India, and hosted at IIT Bombay. It organizes e-Yantra Robotics Competition (eYRC), an annual robotics competition that teaches robotics concepts scalably to college students. Last year 34500+ students registered in the competition out of which 800 students participated in a theme called “Thirsty Crow” which taught augmented reality concepts. In this paper, we illustrate how “project-based learning” may be used to teach complex skills in a “game-like” context. We demonstrate how we designed, experimented and implemented the concepts of “Marker Based Augmented Reality” using open source technologies such as OpenCV, OpenGL, and Blender. We demonstrate in this paper that the average completion rate of our theme (which is essentially a hardware-based MOOC) is 11% which is greater than the overall average completion rate of all themes in eYRC-2018 (which is 6.2%). Our work is useful to anyone wishing to incorporate augmented reality in teaching courses, generally in the area of computer science.","2161-377X","978-1-7281-6090-0","10.1109/ICALT49669.2020.00108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155685","Project Based Learning (PBL);Online Competition;Robotics Competition;eYRC;e-Yantra;Augmented Reality","Task analysis;Robots;Augmented reality;Three-dimensional displays;Education;Software;Solid modeling","augmented reality;computer aided instruction;control engineering computing;control engineering education;educational courses;educational institutions;educational robots;engineering education;student experiments;teaching","average completion rate;teaching courses;robotics outreach project;IIT Bombay;e-Yantra Robotics Competition;annual robotics competition;robotics concepts;college students;Thirsty Crow;open source technologies;marker based augmented reality teaching;hardware-based MOOC;online robotics competition;OpenCV;OpenGL;Blender","","","","8","","4 Aug 2020","","","IEEE","IEEE Conferences"
"The Use of Virtual Reality as the Object of Mathematics Learning","B. V. Frade; P. H. C. C. Gondim; P. Moises De Sousa","Cienc. Exatas e TecnoIogicas, Univ. Fed. de Vicοsa, Rio Paranalba, Brazil; Cienc. Exatas e TecnoIogicas, Univ. Fed. de Vicοsa, Rio Paranalba, Brazil; Cienc. Exatas e TecnoIogicas, Univ. Fed. de Vicοsa, Rio Paranalba, Brazil","2015 XVII Symposium on Virtual and Augmented Reality","26 Oct 2015","2015","","","137","141","Combining education the fun, it designed are creational / educational game, in order to support the idea that the teacher must have the knowledge to develop and find new, more appropriate teaching strategies to help in the learning ability of students, It emphasized that the use of technology, specifically the integrated virtual reality tithe concept of learning object, together with the knowledge presented by teachers and traditional teaching methods, there may be changes and improvements in the learning capacity of students. Therefore, it is expected that the game can be used as a learning object in mathematics education, improving the performance of students during their school year and evaluation programs of knowledge of Brazilian education in general.","","978-1-4673-7204-6","10.1109/SVR.2015.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7300739","games;education;virtual reality;mathematics","Software;Games;Education;Virtual reality;Mathematics;Visualization;Rabbits","computer aided instruction;computer games;mathematics computing;teaching;virtual reality","virtual reality;educational game;teaching strategies;mathematics education;Brazilian education","","1","","11","","26 Oct 2015","","","IEEE","IEEE Conferences"
"Exploitation of games and virtual environments for e-learning","O. H. Graven; L. MacKinnon","Buskerud University College, Kongsberg, Norway. phone: +47 32869500; e-mail: Olaf.Hallan.Graven@hibu.no.; School of Computing and Creative Technology, University of Abertay Dundee, Uk, e-mail: l.mackinnon@abertay.ac.uk.","2006 7th International Conference on Information Technology Based Higher Education and Training","2 Apr 2007","2006","","","409","421","There has been a significant body of work in recent years in the development of e-learning tools and products. The main focus has been on models that are developed from the constructivist tradition, based on the notion that learners actively construct their own understanding and knowledge from their experiences. The topic of this paper is the possible future use of computer games technologies and games based narrative to support e-learning and as a tool for lifelong learning. Computer games metaphors and underpinning models are inherently constructivist, the gaming format is also chosen for its ability to engage. The gaming format also lends itself to support the known advantages of narrative from oral traditions and fits with the younger generation's interest in current trends in the entertainment industry. The decision to adopt a game-based approach to the development of e-learning follows on from a survey of current state-of-the art support for lifelong learning that was carried out by the authors, a key element of that investigation being the different techniques to improve learning and retention through engagement of the student. The increased availability of high bandwidth connections to support multi-user, graphics-rich environments such as gaming environments supports the use of these gaming technologies for virtual learning environments. The use of storytelling in education provides us with a mechanism to establish a relationship between games and virtual learning environments, there have been numerous trials of the use of on-line games setups suitable for this purpose in the form of simulations, MUDs and adventure games. During the last few years multiple virtual worlds have been developed for general communication between users from different parts of the world, and these can be used to support all the important social aspects of learning. From the perspective of our research we are interested in designing a model for an online games-based leaning environment using narrative models, witch will then be developed as an exemplar of this particular approach","","1-4244-0405-3","10.1109/ITHET.2006.339793","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4141656","computer games e-learning;simulation;virtual environment","Virtual environment;Electronic learning;Games;Educational institutions;Computer science education;Art;Availability;Bandwidth;Internet;Educational technology","computer aided instruction;computer games;virtual reality","computer games;e-learning tools;lifelong learning;storytelling;virtual learning environment","","5","","38","","2 Apr 2007","","","IEEE","IEEE Conferences"
"A Participatory Design in Developing Prototype an Augmented Reality Book for Deaf Students","N. M. M. Zainuddin; H. B. Zaman; A. Ahmad","Dept. of Inf. Sci., Univ. Kebangsaan Malaysia, Bangi, Malaysia; Dept. of Inf. Sci., Univ. Kebangsaan Malaysia, Bangi, Malaysia; Dept. of Inf. Sci., Univ. Kebangsaan Malaysia, Bangi, Malaysia","2010 Second International Conference on Computer Research and Development","21 Jun 2010","2010","","","400","404","One of Augmented Reality applications is known as Augmented Reality Book. Due to this, particular AR-Book is based on visually oriented technique and deaf students are generally classified as visual learners. The aim of this paper is to identify the criteria in developing an AR-Book for the deaf students. The AR-Book for deaf students is not the same as normal students because it has to include the sign language. In this ongoing study, qualitative approaches such as participatory design philosophy were used in designing and developing an AR-Book for deaf students. Three deaf students and three teachers who taught the deaf students were involved in this study. Two main findings showed that the sign language marker should be avoided and meanwhile, for the 3D model marker, it can work with the 2D picture or text. Therefore, it is more suitable to use sign language symbols in the AR-Book.","","978-0-7695-4043-6","10.1109/ICCRD.2010.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5489589","Augemted reality;deaf;special education","Prototypes;Augmented reality;Books;Deafness;Virtual reality;Information science;Handicapped aids;Augmented virtuality;Job design;Research and development","augmented reality;computer aided instruction;handicapped aids;human computer interaction","augmented reality book;deaf students;visually oriented technique;visual learners;3D model marker;sign language symbols","","13","","33","","21 Jun 2010","","","IEEE","IEEE Conferences"
"A stochastic learning algorithm for generalization problems","C. V. Ramamoorthy; S. Shekhar","Div. of Comput. Sci., California Univ., Berkeley, CA, USA; Div. of Comput. Sci., California Univ., Berkeley, CA, USA","International 1989 Joint Conference on Neural Networks","6 Aug 2002","1989","","","612 vol.2","","Summary form only given, as follows. Neural networks have traditionally been applied to recognition problems, and most learning algorithms are tailored to those problems. The authors discuss the requirements of learning for generalization, which is NP-complete and cannot be approached by traditional methods based on gradient descent. They present a stochastic learning algorithm based on simulated annealing in weight space. The authors verify the convergence properties and feasibility of the algorithm.<>","","","10.1109/IJCNN.1989.118446","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=118446","","Learning systems;Neural networks","learning systems;neural nets","stochastic learning algorithm;generalization problems;requirements;learning for generalization;NP-complete;simulated annealing in weight space;convergence properties;feasibility","","","","","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Real-time VR Simulation of Laparoscopic Cholecystectomy based on Parallel Position-based Dynamics in GPU","J. Pan; L. Zhang; P. Yu; Y. Shen; H. Wang; H. Hao; H. Qin","Beihang University Peng Cheng Lab,State Key Lab of VR Tech & Syst; Beihang University,State Key Lab of VR Tech & Syst; Beihang University,State Key Lab of VR Tech & Syst; Beijing Normal University,Faculty of Education; Beijing Aerospace General Hospital; Beihang University,Peng Cheng Lab; Stony Brook University,Department of Computer Science","2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","11 May 2020","2020","","","548","556","In recent years, virtual reality (VR) based training has greatly changed surgeons learning mode. It can simulate the surgery from the visual, auditory, and tactile aspects. VR medical simulator can greatly reduce the risk of the real patient and the cost of hospitals. Laparoscopic cholecystectomy is one of the typical representatives in minimal invasive surgery (MIS). Due to the large incidence of cholecystectomy, the application of its VR-based simulation is vital and necessary for the residents' surgical training. In this paper, we present a VR simulation framework based on position-based dynamics (PBD) for cholecystectomy. To further accelerate the deformation of organs, PBD constraints are solved in parallel by a graph coloring algorithm. We introduce a bio-thermal conduction model to improve the realism of the fat tissue electrocautery. Finally, we design a hybrid multi-model connection method to handle the interaction and simulation of the liver-gallbladder separation. This simulation system has been applied to laparoscopic cholecystectomy training in several hospitals. From the experimental results, users can operate in real-time with high stability and fidelity. The simulator is also evaluated by a number of digestive surgeons through preliminary studies. They believed that the system can offer great help to the improvement of surgical skills.","2642-5254","978-1-7281-5608-8","10.1109/VR46266.2020.00076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9089572","Human-centered computing—Human computer interaction—Interactive systems and tools—User interface programming;Computer systems organization—Real-time systems—Real- time system architecture","Surgery;Biological system modeling;Strain;Biological tissues;Image color analysis;Deformable models;Solid modeling","biological tissues;computer based training;graphics processing units;liver;medical computing;surgery;virtual reality","minimal invasive surgery;VR-based simulation;PBD constraints;graph coloring algorithm;hybrid multimodel connection method;laparoscopic cholecystectomy;parallel position-based dynamics;virtual reality based training;visual aspects;tactile aspects;VR medical simulator;GPU;auditory aspects;biothermal conduction model;fat tissue electrocautery;liver-gallbladder separation","","","","30","","11 May 2020","","","IEEE","IEEE Conferences"
"How different in cultural acceptance of tutoring robots serving augmented reality?","J. Han; E. Hyun; M. Kim; H. Cho; T. Kanda; T. Nomura","Cheongju National University of Education, Chungbuk, Korea; SungKyunKwan University, Seoul, Korea; SungKyunKwan University, Seoul, Korea; Hansung University, Seoul, Korea; ATR Intelligent Robotics and Communication Labs, Japan; Ryukoku University, Japan","2009 11th International Conference on Advanced Communication Technology","3 Apr 2009","2009","03","","2006","2008","The difference of user's perception seems to have been well reflected in the development of robot technology. In this study, we attempted to compare and analyze how cultural features in three different countries i.e. Korea, Japan, and Europe affect parents and children in accommodating tutoring robots for education. It was revealed that parents in Europe representing western countries are generally more inflexible and negative on purchasing tutoring robots than those of Korea and Japan. The expectations of parents on the practical use, service of augmented reality, of tutoring robots turned out to be higher in Korea than in Europe and Japan. Japanese and Europe parents hold more conservative attitudes toward tutoring robots than Korean. In contrast, Korean parents are most liberal and less resistant to educating their children by robots, probably due to the fact that e-Learning is widely used and has just begun to enter r-Learning in the Korean society. The fact that a substantial number of students felt pressed despite positive expectation for contents based on identification in a class may provide useful information in setting up new guidelines for children served augmented reality by tutoring robots.","1738-9445","978-89-5519-138-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809473","Tutoring Robots;User Perception;Augmented Reality;e-Learning;r-Learning","Cultural differences;Augmented reality;Educational robots;Intelligent robots;Europe;Educational technology;Technological innovation;Global communication;Electronic learning;Service robots","augmented reality;computer aided instruction;human factors;robots;social aspects of automation","tutoring robots;augmented reality;user perception;robot technology;e-Learning;r-Learning;cultural acceptance","","","","14","","3 Apr 2009","","","IEEE","IEEE Conferences"
"Templates for selecting PC-based synthetic environments for application to human performance enhancement and training","C. S. Morris; R. W. Tarr","Adv. Learning Technol., Central Florida Univ., Orlando, FL, USA; NA","Proceedings IEEE Virtual Reality 2002","7 Aug 2002","2002","","","109","115","This report covers two analyses that were conducted on commercial off-the-shelf (COTS) synthetic environments (SEs), in this case games. (1.) Analysis 1 used a factor analysis on a set of 19 self-reported cognitive skills exercised while respondents played various PC-based games. The results verified the hypothesis that a few general cognitive phases could be drawn from the 19 variables. The four meaningful and predictable factors were detection (D), understanding (U), decision-making (DM), and execution (E). These factors represent general cognitive stages found in human factors literature such as situational awareness theory. (2.) The second analysis correlated the four derived factors with the participants' self-report of specific game enjoyment features. The outcome of this project provided a set of blueprints or templates for proper selection of COTS SEs and their components when attempting to apply them for enhancing human performance or training utility.","1087-8270","0-7695-1492-8","10.1109/VR.2002.996513","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=996513","","Humans;Game theory;Artificial intelligence;Performance analysis;Computer simulation;Computational modeling;Aerospace simulation;Analytical models;Computer graphics;Computer interfaces","computer based training;computer games;user interfaces;human factors;digital simulation;virtual reality","PC-based synthetic environments;human performance enhancement;computer based training;commercial off-the-shelf system;factor analysis;computer games;simulation games;virtual reality;cognitive skills;human factors;situational awareness theory;COTS","","1","","22","","7 Aug 2002","","","IEEE","IEEE Conferences"
"Framework for Contemporary Inquiry-based Augmented Reality Learning","M. Pedaste; G. Mitt","Institute of Education University of Tartu,Tartu,Estonia; Institute of Education University of Tartu,Tartu,Estonia","2020 IEEE 20th International Conference on Advanced Learning Technologies (ICALT)","4 Aug 2020","2020","","","327","328","The aim of this discussion paper is to propose a framework to apply contemporary learning approach in using augmented reality (AR) for inquiry-based learning. Our literature review shows that AR is mainly used in learning on a very simplistic level and the potential of AR has not been opened. Therefore, we propose a new framework for applying contemporary inquiry-based learning using augmented reality. This framework specifies how the affordances and features of AR could be applied in instructional design according to the five general phases of inquiry-based learning and how the principles and goals of the contemporary learning approach are supported in this learning approach.","2161-377X","978-1-7281-6090-0","10.1109/ICALT49669.2020.00105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155829","augmented reality;inquiry-based learning;contemporary learning approach;theozy-building","Conferences","augmented reality;computer aided instruction","contemporary inquiry-based augmented reality learning;AR;instructional design","","","","8","","4 Aug 2020","","","IEEE","IEEE Conferences"
"Augmented Reality for Learning of Children and Adolescents With Autism Spectrum Disorder (ASD): A Systematic Review","K. Khowaja; B. Banire; D. Al-Thani; M. T. Sqalli; A. Aqle; A. Shah; S. S. Salim","Information and Computing Technology,College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Information and Computing Technology,College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Information and Computing Technology,College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Information and Computing Technology,College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Information and Computing Technology,College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Department of Information Systems, Kulliyah of Information and Information Technology, International Islamic University Malaysia, Kuala Lumpur, Malaysia; Department of Software Engineering, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia","IEEE Access","6 May 2020","2020","8","","78779","78807","This paper presents a systematic review of relevant primary studies on the use of augmented reality (AR) to improve various skills of children and adolescents diagnosed with autism spectrum disorder (ASD) from years 2005 to 2018 inclusive in eight bibliographic databases. This systematic review attempts to address eleven specific research questions related to the learing skills, participants, AR technology, research design, data collection methods, settings, evaluation parameters, intervention outcomes, generalization, and maintenance. The social communication skill was the highly targeted skill, and individuals with ASD were part of all the studies. Computer, smartphone, and smartglass are more frequently used technologies. The commonly used research design was pre-test and post-test. Almost all the studies used observation as a data collection method, and classroom environment or controlled research environment were used as a setting of evaluation. Most of the evaluation parameters were human-assisted. The results of the studies show that AR benefited children with ASD in learning skills. The generalization test was conducted in one study only, but the results were not reported. The results of maintenance tests conducted in five studies during a short-term period following the withdrawal of intervention were positive. Although the effect of using AR towards the learning of individuals was positive, given the wide variety of skills targeted in the studies, and the heterogeneity of the participants, a summative conclusion regarding the effectiveness of AR for teaching or learning of skills related to ASD based on the existing literature is not possible. The review also proposes the research taxonomy for ASD. Future research addressing the effectiveness of AR among more participants, different technologies supporting AR for the intervention, generalization, and maintenance of learning skills, and the evaluation in the inslusive classroom environment and other settings is warranted.","2169-3536","","10.1109/ACCESS.2020.2986608","Hamad Bin Khalifa University (HBKU) Innovation Centre Idea Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9060971","Augmented reality;autism spectrum disorder;computer;data collection;intervention;mixed reality;research design;smartglass;smartphone;social communication;tablet;technology;virtual reality;inclusive education","Databases;Augmented reality;Autism;Maintenance engineering;Systematics;Data collection","age issues;augmented reality;computer aided instruction;data handling;medical computing;medical disorders;mobile learning;smart phones;teaching","augmented reality;children learning;adolescent learning;autism spectrum disorder;ASD;systematic review;learing skills;data collection method;evaluation parameters;social communication skill;maintenance tests;teaching;research taxonomy;intervention outcomes;generalization;smartphone;smartglass;computer","","4","","104","CCBY","8 Apr 2020","","","IEEE","IEEE Journals"
"Application of sensors in Augmented Reality based interactive learning environments","C. V. Ramdas; N. Parimal; M. Utkarsh; S. Sumit; K. Ramya; B. P. Smitha","MARS Lab, C-DAC, Knowledge Park, Bangalore, India; MARS Lab, C-DAC, Knowledge Park, Bangalore, India; MARS Lab, C-DAC, Knowledge Park, Bangalore, India; MARS Lab, C-DAC, Knowledge Park, Bangalore, India; MARS Lab, C-DAC, Knowledge Park, Bangalore, India; MARS Lab, C-DAC, Knowledge Park, Bangalore, India","2012 Sixth International Conference on Sensing Technology (ICST)","14 Feb 2013","2012","","","173","178","Context awareness, user friendliness, and interactivity are very important and powerful concepts in building useful teaching/learning environments for the benefit of mankind. Advancements in technology are enabling us to look at new use cases in the methods of teaching, information sharing, knowledge dissemination, and self-learning. Learning environments are not only for teaching things to people., but also for providing more information to them on any subject that they may require from time to time. User friendliness can be enhanced with clever use of sensors to give hands free interactivity with the devices/gadgets. Context aware applications require sensors to get the context information. Mobile devices like smart phones and tablets today come with a hand full of sensors mounted on them which include one or two cameras, a microphone, a touch screen, an accelerometer to sense motion, and in addition have GPS and digital compass to provide location information to applications requiring these sensory inputs. The computational power packed in the processors used in these devices/gadgets including special support for graphics processing, the near general purpose computer like operating system environments, and the quality of cameras available, are all enabling application developers to map some serious computer vision based applications on today's mobile devices. This reality has encouraged us to get into development of Augmented Reality (AR) based interactive learning environments on mobile devices, leading to our development of a software framework for AR applications development and also development of an AR book and an AR board. AR has been called the eighth mass medium, after print, recordings, cinema, radio, television, Internet and mobile phones. There is ample scope for enhancing the learning/teaching experiences of the users with AR based learning environments. AR makes learning more effective and an enjoyable experience by providing more realistic information with the use of 3D graphics and animated models.","2156-8073","978-1-4673-2248-5","10.1109/ICSensT.2012.6461664","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6461664","Augmented Reality;AR;context awareness;AR learning","Augmented reality;Context;Context-aware services;Sensors;Mobile communication;Mobile handsets;Software","augmented reality;computer aided instruction;educational aids;interactive devices;sensors;ubiquitous computing","sensor application;augmented reality;interactive learning environments;context awareness;user friendliness;hands free interactivity;mobile device;eighth mass media;after print;Internet;mobile phones;3D graphics;animated model","","4","","11","","14 Feb 2013","","","IEEE","IEEE Conferences"
"A Steering Algorithm for Redirected Walking Using Reinforcement Learning","R. R. Strauss; R. Ramanujan; A. Becker; T. C. Peck",Davidson College; Davidson College; Davidson College; Davidson College,"IEEE Transactions on Visualization and Computer Graphics","31 Mar 2020","2020","26","5","1955","1963","Redirected Walking (RDW) steering algorithms have traditionally relied on human-engineered logic. However, recent advances in reinforcement learning (RL) have produced systems that surpass human performance on a variety of control tasks. This paper investigates the potential of using RL to develop a novel reactive steering algorithm for RDW. Our approach uses RL to train a deep neural network that directly prescribes the rotation, translation, and curvature gains to transform a virtual environment given a user's position and orientation in the tracked space. We compare our learned algorithm to steer-to-center using simulated and real paths. We found that our algorithm outperforms steer-to-center on simulated paths, and found no significant difference on distance traveled on real paths. We demonstrate that when modeled as a continuous control problem, RDW is a suitable domain for RL, and moving forward, our general framework provides a promising path towards an optimal RDW steering algorithm.","1941-0506","","10.1109/TVCG.2020.2973060","Davidson Research Initiative; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8998570","Virtual Reality;Locomotion;Redirected Walking;Steering Algorithms;Reinforcement Learning","Legged locomotion;Learning (artificial intelligence);Prediction algorithms;Meters;Tracking;Heuristic algorithms;Space exploration","learning (artificial intelligence);neural nets;virtual reality","RL;reactive steering algorithm;deep neural network;learned algorithm;steer-to-center;simulated paths;optimal RDW steering algorithm;reinforcement learning;human-engineered logic;human performance;control tasks;redirected walking steering algorithms","Algorithms;Computer Graphics;Deep Learning;Humans;Video Games;Virtual Reality;Walking","","","58","","13 Feb 2020","","","IEEE","IEEE Journals"
"Virtual Reality Video Game Paired with Physical Monocular Blurring as Accessible Therapy for Amblyopia","O. Hurd; S. Kurniawan; M. Teodorescu","University of California, Santa Cruz; University of California, Santa Cruz; University of California, Santa Cruz","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","492","499","This paper discusses a virtual reality (VR) therapeutic video game for treatment of the neurological eye disorder, Amblyopia. Amblyopia is often referred to as lazy eye, and it entails weaker vision in one eye due to a poor connection between the eye and the brain. Until recently it was thought to be untreatable in adults, but new research has proven that with consistent therapy even adults can improve their Amblyopia, especially through perceptual learning and video games. Even so, therapy compliance remains low due to the fact that conventional therapies are perceived as either invasive, dull and/or boring. Our game aims to make Amblyopia therapy more immersive, enjoyable and playful. The game was perceived by our users to be a fun and accessible alternative, as it involves adhering a Bangerter foil (an opaque sticker) on a VR headset to blur vision in an Amblyopic person's dominant eye while having them playa VR video game. To perform well in the video game, their brain must adapt to rely on seeing with their weaker eye, thereby reforging that neurological connection. While testing our game, we also studied users behavior to investigate what visual and kinetic components were more effective therapeutically. Our findings generally show positive results, showing that visual acuity in adults increases with 45 minutes of therapy. Amblyopia has many negative symptoms including poor depth perception (nec-essary for daily activities such as driving), so this therapy could be life changing for adults with Amblyopia.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797997","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797997","Visual acuity—Visual stereopsis—LogMAR—Crowding","Games;Vision defects;Medical treatment;Visualization;Virtual reality;Headphones;Testing","computer games;eye;medical computing;neurophysiology;patient treatment;virtual reality;vision;vision defects;visual perception","accessible therapy;virtual reality therapeutic video game;neurological eye disorder;lazy eye;consistent therapy;Amblyopia therapy;Amblyopic person;playa VR video game;weaker eye;VR headset;kinetic components;visual components;depth perception","","","","31","","15 Aug 2019","","","IEEE","IEEE Conferences"
"GPSS for e-learning environment","M. S. Despotović; B. L. Radenković; D. M. Barać","Organizational Sciences, University of Belgrade, Serbia; Organizational Sciences, University of Belgrade, Serbia; Organizational Sciences, University of Belgrade, Serbia","2009 9th International Conference on Telecommunication in Modern Satellite, Cable, and Broadcasting Services","18 Dec 2009","2009","","","318","321","The main issue in this paper is an implementation of GPSS (general purpose simulation system) for learning discrete event simulation in e-learning environment. Primary goal of the research is to develop interactive and user-friendly for creating, testing and analyzing discrete event system models and integrate it in existing e-learning system. We propose a new solution for learning simulation via Web - FONWebGPSS. Architecture and key concepts of FONWebGPSS application are described in the paper. In addition, we present an example of applying FONWebGPSS in solving a typical problem of discrete event simulation.","","978-1-4244-4382-6","10.1109/TELSKS.2009.5339513","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5339513","GPSS;FONWebGPSS;Discrete event simulation;e-learning","Electronic learning;Discrete event simulation;Computational modeling;Discrete event systems;Education;Computer simulation;Electronic mail;System testing;Laboratories;Stochastic systems","computer aided instruction;discrete event simulation;distance learning;user interfaces","GPSS;general purpose simulation system;e-learning;discrete event simulation;interactive environment;user-friendiness;Web-FONWebGPSS","","","","10","","18 Dec 2009","","","IEEE","IEEE Conferences"
"A Desktop VR-based HCI framework for programming instruction","M. Chandramouli; J. Heffron",Purdue University Calumet; Purdue University Calumet,"2015 IEEE Integrated STEM Education Conference","11 Jun 2015","2015","","","129","134","Programming skills are becoming increasingly important in both academia and industry. While this signifies numerous opportunities for students, it also inherently involves the challenge of preparing students suitably for these opportunities. Students, especially those at the beginner level, encounter difficulties when learning to program and the lack of efficient tools to overcome such difficulties can affect students' motivation. Over time, this creates to a drastic and negative impact in their attitude towards `learning programming', which is undesirable for student success in engineering education. To rectify this, a suitable approach that can motivate students needs to be developed to change students' mindset towards learning programming. To this end, to facilitate interactive and fun-filled learning, this research employs a learner-centric, user-friendly Virtual Environment (VE) to teach programming concepts. The impact of this research extends beyond engineering and technology education as this framework can serve as a tool to strengthen STEM education and enhance general programming literacy.","","978-1-4799-1829-4","10.1109/ISECon.2015.7119905","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119905","HCI;Desktop VR;Programing Instruction","Programming profession;Containers;Conferences;Visualization;Human computer interaction;Indexes","computer aided instruction;computer science education;engineering education;human computer interaction;human factors;programming;virtual reality","desktop VR-based HCI framework;programming instruction;student motivation;engineering education;interactive fun-filled learning;learner-centric user-friendly virtual environment;programming concepts;teaching;technology education;programming literacy;programming skills;STEM education","","2","","7","","11 Jun 2015","","","IEEE","IEEE Conferences"
"Haptically enabled interactive virtual reality prototype for general assembly","A. Bhatti; Yong Bing Khoo; D. Creighton; J. Anticev; S. Nahavandi; Mingwei Zhou","Deakin University, Australia; CSIRO, Australia; Deakin University, Australia; CSIRO, Australia; Deakin University, Australia; CSIRO, Australia","2008 World Automation Congress","9 Dec 2008","2008","","","1","6","Desktop computers based virtual training systems are attracting paramount attention from manufacturing industries due to their potential advantages over the conventional training practices. Significant cost savings can be realized due to the shorter training-scenarios development times and reuse of existing engineering models. In addition, by using computer based virtual reality (VR) training systems, the time span from the product design to commercial production can be shortened due to non-reliance on hardware parts. Within the aforementioned conceptual framework, a haptically enabled interactive and immersive virtual reality (HIIVR) system is presented. Unlike existing VR systems, the presented idea tries to imitate real physical training scenarios by providing comprehensive user interaction, constrained within the physical limitations of the real world imposed by the haptics devices within the virtual environment. As a result, in contrast to the existing VR systems, capable of providing knowledge generally about assembly sequences only, the proposed system helps in procedural learning and procedural skill development as well, due to its high physically interactive nature.","2154-4824","978-1-889335-38-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4699035","Haptics;virtual assembly;interactive and immersive","Virtual reality;Virtual prototyping;Assembly;Industrial training;Computer aided manufacturing;Manufacturing industries;Costs;Design engineering;Product design;Production systems","assembling;computer based training;haptic interfaces;industrial training;production engineering computing;virtual reality","haptically enabled interactive virtual reality prototype;general assembly;manufacturing industries;computer-based virtual reality training systems;immersive virtual reality","","","","9","","9 Dec 2008","","","IEEE","IEEE Conferences"
"Using Visualization of Convolutional Neural Networks in Virtual Reality for Machine Learning Newcomers","N. Meissler; A. Wohlan; N. Hochgeschwender; A. Schreiber",German Aerospace Center (DLR); German Aerospace Center (DLR); German Aerospace Center (DLR); German Aerospace Center (DLR),"2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","27 Dec 2019","2019","","","152","1526","Software systems and components are increasingly based on machine learning methods, such as Convolutional Neural Networks (CNNs). Thus, there is a growing need for common programmers and machine learning newcomers to understand the general functioning of these algorithms. However, as neural networks are complex in nature, novel presentation means are required to enable rapid access to the functionality. For that purpose, we examine how CNNs can be visualized in Virtual Reality (VR), as it offers the opportunity to focus users on content through effects such as immersion and presence. With a first exploratory study, we confirmed that our visualization approach is both intuitive to use and conductive to learning. Moreover, users indicated an increased motivation to learning due to the unusual virtual environment. Based on our findings, we propose a follow-up study that specifically compares the benefits of a virtual visualization approach to a traditional desktop visualization.","","978-1-7281-5604-0","10.1109/AIVR46125.2019.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942366","neural networks, visualization, virtual reality, knowledge learning","Data visualization;Visualization;Virtual environments;Neurons;Convolutional neural networks","convolutional neural nets;data visualisation;learning (artificial intelligence);virtual reality","convolutional neural networks;virtual reality;machine learning newcomers;machine learning methods;CNNs","","1","","32","","27 Dec 2019","","","IEEE","IEEE Conferences"
"A review of tele-immersive applications in the CAVE research network","J. Leigh; A. E. Johnson; T. A. DeFanti; M. Brown; M. D. Ali; S. Bailey; A. Banerjee; P. Benerjee; Jim Chen; K. Curry; J. Curtis; F. Dech; B. Dodds; I. Foster; S. Fraser; K. Ganeshan; D. Glen; R. Grossman; R. Heiland; J. Hicks; A. D. Hudson; T. Imai; M. A. Khan; A. Kapoor; R. V. Kenyon; J. Kelso; R. Kriz; C. Lascara; X. Liu; Y. Lin; T. Mason; A. Millman; K. Nobuyuki; K. Park; B. Parod; P. J. Rajlich; M. Rasmussen; M. Rawlings; D. H. Robertson; S. Thongrong; R. J. Stein; K. Swartz; S. Tuecke; H. Wallach; Hong Yee Wong; G. H. Wheless","Nat. Center for Supercomput. Appl., Illinois Univ., Urbana, IL, USA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA","Proceedings IEEE Virtual Reality (Cat. No. 99CB36316)","6 Aug 2002","1999","","","180","187","This paper presents an overview of the tele-immersion applications that have been built by collaborators around the world using the CAVERNsoft toolkit, and the lessons learned from building these applications. In particular the lessons learned are presented as a set of rules-of-thumb for developing tele-immersive applications in general.","1087-8270","0-7695-0093-5","10.1109/VR.1999.756949","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=756949","","Intelligent networks;Laboratories;Visualization;Virtual reality;Collaborative work;Virtual environment;Image databases;Industrial training;Computer networks;Sea measurements","virtual reality;groupware;teleconferencing;user interfaces;application generators","tele-immersive applications;CAVE research network;CAVERNsoft toolkit;videoconferencing;collaborative virtual reality","","37","17","18","","6 Aug 2002","","","IEEE","IEEE Conferences"
"On Benchmarking Iris Recognition within a Head-mounted Display for AR/VR Applications","F. Boutros; N. Damer; K. Raja; R. Ramachandra; F. Kirchbuchner; A. Kuijper","Mathematical and Applied Visual Computing, TU Darmstadt,Darmstadt,Germany; Mathematical and Applied Visual Computing, TU Darmstadt,Darmstadt,Germany; Norwegian Biometrics Laboratory, NTNU,Gjovik,Norway; Norwegian Biometrics Laboratory, NTNU,Gjovik,Norway; Mathematical and Applied Visual Computing, TU Darmstadt,Darmstadt,Germany; Mathematical and Applied Visual Computing, TU Darmstadt,Darmstadt,Germany","2020 IEEE International Joint Conference on Biometrics (IJCB)","6 Jan 2021","2020","","","1","10","Augmented and virtual reality is being deployed in different fields of applications. Such applications might involve accessing or processing critical and sensitive information, which requires strict and continuous access control. Given that Head-Mounted Displays (HMD) developed for such applications commonly contains internal cameras for gaze tracking purposes, we evaluate the suitability of such setup for verifying the users through iris recognition. In this work, we first evaluate a set of iris recognition algorithms suitable for HMD devices by investigating three well-established handcrafted feature extraction approaches, and to complement it, we also present the analysis using four deep learning models. While taking into consideration the minimalistic hardware requirements of stand-alone HMD, we employ and adapt a recently developed miniature segmentation model (EyeMMS) for segmenting the iris. Further, to account for non-ideal and non-collaborative capture of iris, we define a new iris quality metric that we termed as Iris Mask Ratio (IMR) to quantify the iris recognition performance. Motivated by the performance of iris recognition, we also propose the continuous authentication of users in a non-collaborative capture setting in HMD. Through the experiments on a publicly available OpenEDS dataset, we show that performance with EER = 5% can be achieved using deep learning methods in a general setting, along with high accuracy for continuous user authentication.","2474-9699","978-1-7281-9186-7","10.1109/IJCB48548.2020.9304919","German Federal Ministry of Education and Research and the Hessen State Ministry for Higher Education, Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9304919","","Iris recognition;Resists;Feature extraction;Image segmentation;Cameras;Pupils;Authentication","authorisation;biometrics (access control);feature extraction;helmet mounted displays;image recognition;iris recognition;learning (artificial intelligence);virtual reality","recently developed miniature segmentation model;minimalistic hardware requirements;deep learning models;HMD devices;iris recognition algorithms;gaze tracking purposes;internal cameras;Head-Mounted Displays;continuous access control;strict access control;sensitive information;critical information;virtual reality;augmented reality;Head-mounted display;benchmarking Iris recognition;continuous user authentication;noncollaborative capture setting;iris recognition performance;Iris Mask Ratio;iris quality","","","","50","","6 Jan 2021","","","IEEE","IEEE Conferences"
"Virtual frog dissection for anatomical learning","T. Yamada; B. Tsagaan; H. Nakatani","Department of Computer Science, Shizuoka University, Hamamatsu 432-8011, Japan; Department of Computer Science, Shizuoka University, Hamamatsu 432-8011, Japan; Department of Computer Science, Shizuoka University, Hamamatsu 432-8011, Japan","The First Asian Conference on Pattern Recognition","12 Mar 2012","2011","","","135","138","Frog dissection practice used to be a student's laboratory work in Japanese elementary schools. It was an effective approach for learning animal's anatomy. However this practice has been stopped due to animal protection issues and implemental cost. In this study, we aimed to simulate interactive dissecting practice in the virtual space. The presented virtual frog dissection system consists of virtual reality software in conjunction with head-mounted stereoscopic crystal glasses and a haptic device that allows users to touch and manipulate virtual objects. The developed system was evaluated by examining learning ability of students. Participants were divided in four groups of different learning styles, took a written test on the same questions and their resultant scores were compared. Two findings were obtained from this evaluation exam. First, students who have experienced virtual frog dissection were more correct on the appearance related questions, while students who have used paper materials were more concrete on the function-related questions in general. This general tendency may be conducted in accordance with their habitual learning style. Second, in the aspect of convenience and preparing time of each learning style, students who have used conventional paper materials demonstrated more balanced learning than did students of virtual paper materials. These findings suggest that our virtual frog dissection system can show potential benefits in the structural anatomical learning of students; and in contrast, a habitual learning style is likely to produce better outcomes if the new technique provides only the same amount of information.","0730-6512","978-1-4577-0121-4","10.1109/ACPR.2011.6166690","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6166690","virtual frog dissection;virtual reality;3D vision;haptic device;multi-modal interaction","Materials;Three dimensional displays;Solid modeling;Haptic interfaces;Biological systems;Virtual reality;Educational institutions","biological organs;biology computing;computer aided instruction;haptic interfaces;stereo image processing;student experiments;virtual reality","student laboratory work;Japanese elementary school;animal anatomy learning;animal protection issues;interactive dissecting practice;virtual space;virtual frog dissection system;virtual reality software;head-mounted stereoscopic crystal glass;haptic device;virtual object touching;virtual object manipulation;student learning ability;habitual learning style;virtual paper material;structural anatomical learning","","","","13","","12 Mar 2012","","","IEEE","IEEE Conferences"
"Towards a social virtual reality learning environment in high fidelity","C. Zizza; A. Starr; D. Hudson; S. S. Nuguri; P. Calyam; Z. He",Grinnell College; Pomona College; Truman State University; University of Missouri; University of Missouri; University of Missouri,"2018 15th IEEE Annual Consumer Communications & Networking Conference (CCNC)","19 Mar 2018","2018","","","1","4","Virtual Learning Environments (VLEs) are spaces designed to educate students remotely via online platforms. Although traditional VLEs such as iSocial have shown promise in educating students, they offer limited immersion that diminishes learning effectiveness. This paper outlines a virtual reality learning environment (VRLE) over a high-speed network, which promotes educational effectiveness and efficiency via our creation of flexible content and infrastructure which meet established VLE standards with improved immersion. This paper further describes our implementation of multiple learning modules developed in High Fidelity, a “social VR” platform. Our experiment results show that the VR mode of content delivery better stimulates the generalization of lessons to the real world than non-VR lessons and provides improved immersion when compared to an equivalent desktop version.","2331-9860","978-1-5386-4790-5","10.1109/CCNC.2018.8319187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319187","Virtual Reality;Virtual Learning Environment;High Fidelity;Multi-user Network Application","Avatars;Games;Servers;Web pages;Education;Cloud computing","computer aided instruction;human computer interaction;virtual reality","multiple learning modules;social VR platform;social virtual reality learning environment;online platforms;high-speed network;educational effectiveness;VRLE;VLE standards","","4","","11","","19 Mar 2018","","","IEEE","IEEE Conferences"
"Design and Implementation of the Interactive Virtual Reality Touring System - A Case Study of Shulin Ji'an Temple in Taiwan","J. -H. Lo; M. -J. You","Fo-Guang University,Department of Applied Informatics,Yilan,Taiwan,26247; Fo-Guang University,Department of Applied Informatics,Yilan,Taiwan,26247","202020 3rd IEEE International Conference on Knowledge Innovation and Invention (ICKII)","18 Jan 2021","2020","","","115","117","Most current tour guiding methods for Taiwanese temples employ graphic webpage frameworks combined with captioned pictures for introduction. This type of tour guiding lacks interactive presence. In addition, the audience may not be able to focus on browsing webpages or learn essential information from the introduction. This study adopted the Delphi method to evaluate the current developed system. This system was aimed at designing VR-based interaction that differs from conventional tour guiding methods to aid users in viewing the display space from their viewpoints. Users can not only control camera view angles but also select the paths and guiding information as if they were walking in the temple. The analysis results revealed that in general, the users perceived Web VR tour guiding as convenient and easy to use. The display and content of the tour guiding system presented clear information to the users, aiding them in gaining further understanding of the introduced item. Finally, the study results can serve as a reference for design research on VR applications in tour guiding.","","978-1-7281-9333-5","10.1109/ICKII50300.2020.9318862","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9318862","A-Frame;Delphi method;Questionnaire for User Interface Satisfaction (QUIS);Virtual Reality (VR)","Internet;Technological innovation;Social networking (online);Graphics;Statistical analysis;Cultural differences;Usability","interactive systems;Internet;virtual reality","interactive virtual reality touring system;Taiwanese temples;graphic webpage frameworks;captioned pictures;interactive presence;webpages;Delphi method;VR-based interaction;conventional tour;camera view angles;guiding information;Web VR tour;tour guiding system;design research;Shulin Ji'an Temple","","","","8","","18 Jan 2021","","","IEEE","IEEE Conferences"
"Where Does My Augmented Reality Learning Experience (ARLE) Belong? A Student and Teacher Perspective to Positioning ARLEs","N. Drljević; L. H. Wong; I. Botički","Directorate-General for Innovation and Technological Support of the European Parliament, Plateau de Kirchberg, Luxembourg; National Institute of Education, Nanyang Technological University, Singapore; University of Zagreb Faculty of Electrical Engineering and Computing, Zagreb, Croatia","IEEE Transactions on Learning Technologies","14 Dec 2017","2017","10","4","419","435","The paper provides a high-level review of the current state of techno-pedagogical design in Augmented Reality Learning Experiences (ARLEs). The review is based on a rubric constructed from the Meaningful Learning with ICT framework and the Orchestration Load reduction framework, providing, respectively, a view of primarily student- and primarily teacher-focused dimensions in ARLEs. Fifty-nine ARLEs are reviewed based on an extensive search for papers based on both previous work in the field as well as academic databases. Exemplars for specific situations are provided as well as a correlation analysis between dimensions and an overall view of the maturity of the field in terms of relevant techno-pedagogical considerations, giving ARLE practitioners practical information on the current state of the field as well as assistance in better positioning their future ARLE design efforts.","1939-1382","","10.1109/TLT.2017.2690426","Croatian Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7891552","Virtual and augmented reality;augmented reality learning experience;meaningful learning;orchestration load","Augmented reality;Education;Mobile communication;Electronic mail;Context modeling;Databases;Virtual reality","augmented reality;computer aided instruction;educational courses;teaching","augmented reality learning experience;orchestration load reduction framework;correlation analysis;academic databases;ARLE practitioners practical information;ICT framework;techno-pedagogical design;positioning ARLEs","","5","","109","Traditional","3 Apr 2017","","","IEEE","IEEE Journals"
"Online Learning Control Using Adaptive Critic Designs With Sparse Kernel Machines","X. Xu; Z. Hou; C. Lian; H. He","College of Mechatronics and Automation, National University of Defense Technology, Changsha, China; Advanced Control Systems Laboratory of School of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, China; College of Mechatronics and Automation, National University of Defense Technology, Changsha, China; Department of Electrical, Computer, and Biomedical Engineering, University of Rhode Island, Kingston, RI, USA","IEEE Transactions on Neural Networks and Learning Systems","11 Mar 2013","2013","24","5","762","775","In the past decade, adaptive critic designs (ACDs), including heuristic dynamic programming (HDP), dual heuristic programming (DHP), and their action-dependent ones, have been widely studied to realize online learning control of dynamical systems. However, because neural networks with manually designed features are commonly used to deal with continuous state and action spaces, the generalization capability and learning efficiency of previous ACDs still need to be improved. In this paper, a novel framework of ACDs with sparse kernel machines is presented by integrating kernel methods into the critic of ACDs. To improve the generalization capability as well as the computational efficiency of kernel machines, a sparsification method based on the approximately linear dependence analysis is used. Using the sparse kernel machines, two kernel-based ACD algorithms, that is, kernel HDP (KHDP) and kernel DHP (KDHP), are proposed and their performance is analyzed both theoretically and empirically. Because of the representation learning and generalization capability of sparse kernel machines, KHDP and KDHP can obtain much better performance than previous HDP and DHP with manually designed neural networks. Simulation and experimental results of two nonlinear control problems, that is, a continuous-action inverted pendulum problem and a ball and plate control problem, demonstrate the effectiveness of the proposed kernel ACD methods.","2162-2388","","10.1109/TNNLS.2012.2236354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6461419","Adaptive critic designs;approximate dynamic programming;kernel machines;learning control;Markov decision processes;reinforcement learning","Kernel;Approximation methods;Learning systems;Dictionaries;Approximation algorithms;Vectors;Machine learning","adaptive control;approximation theory;dynamic programming;generalisation (artificial intelligence);heuristic programming;learning (artificial intelligence);learning systems;nonlinear control systems;sparse matrices","adaptive critic designs;sparse kernel machines;heuristic dynamic programming;dual-heuristic programming;dynamical system online learning control;continuous state space;continuous action space;generalization capability improvement;learning efficiency improvement;computational efficiency improvement;sparsification method;approximately linear dependence analysis;kernel-based ACD algorithms;kernel HDP;KHDP;kernel DHP;KDHP;representation learning;nonlinear control problems;continuous-action inverted pendulum problem;ball-and-plate control problem","Algorithms;Artificial Intelligence;Computer Simulation;Decision Support Techniques;Feedback;Humans;Learning;Markov Chains;Online Systems","89","","48","","13 Feb 2013","","","IEEE","IEEE Journals"
"Grasp Recognition with Uncalibrated Data Gloves - A Comparison of Classification Methods","G. Heumer; H. B. Amor; M. Weber; B. Jung","VR and Multimedia Group, Institute of Informatics, TU Bergakademie Freiberg, Germany. e-mail: guido.heumer@informatik.tu-freiberg.de; VR and Multimedia Group, Institute of Informatics, TU Bergakademie Freiberg, Germany. e-mail: amor@informatik.tu-freiberg.de; VR and Multimedia Group, Institute of Informatics, TU Bergakademie Freiberg, Germany. e-mail: matthias.weber@informatik.tu-freiberg.de; VR and Multimedia Group, Institute of Informatics, TU Bergakademie Freiberg, Germany. e-mail: jung@informatik.tu-freiberg.de","2007 IEEE Virtual Reality Conference","23 Apr 2007","2007","","","19","26","This paper presents a comparison of various classification methods for the problem of recognizing grasp types involved in object manipulations performed with a data glove. Conventional wisdom holds that data gloves need calibration in order to obtain accurate results. However, calibration is a time-consuming process, inherently user-specific, and its results are often not perfect. In contrast, the present study aims at evaluating recognition methods that do not require prior calibration of the data glove, by using raw sensor readings as input features and mapping them directly to different categories of hand shapes. An experiment was carried out, where test persons wearing a data glove had to grasp physical objects of different shapes corresponding to the various grasp types of the Schlesinger taxonomy. The collected data was analyzed with 28 classifiers including different types of neural networks, decision trees, Bayes nets, and lazy learners. Each classifier was analyzed in six different settings, representing various application scenarios with differing generalization demands. The results of this work are twofold: (1) We show that a reasonably well to highly reliable recognition of grasp types can be achieved - depending on whether or not the glove user is among those training the classifier - even with uncalibrated data gloves. (2) We identify the best performing classification methods for recognition of various grasp types. To conclude, cumbersome calibration processes before productive usage of data gloves can be spared in many situations.","2375-5334","1-4244-0905-5","10.1109/VR.2007.352459","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4161001","Data Glove;Calibration;Grasp Recognition;Classification Methods;I.3.6 [Computer Graphics]: Methodology and Techniques¿Interaction techniques;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism¿[Virtual Reality]","Data gloves;Calibration;Shape;Sensor phenomena and characterization;Testing;Taxonomy;Data analysis;Classification tree analysis;Neural networks;Decision trees","calibration;data gloves;pattern classification;virtual prototyping;virtual reality","grasp recognition;uncalibrated data gloves;classification methods;object manipulation;Schlesinger taxonomy;cumbersome calibration","","31","","24","","23 Apr 2007","","","IEEE","IEEE Conferences"
"Using Virtual Reality to Enhance Learning in a Chinese Architectures Course: A Flipped Classroom Approach","S. W. T. Im; P. H. P. Chiu; C. H. Shek; M. Ng; L. Li","Office of Education Development and Gateway Education, City University of Hong Kong, Hong Kong SAR; Office of Education Development and Gateway Education, City University of Hong Kong, Hong Kong SAR; Office of Education Development and Gateway Education, City University of Hong Kong, Hong Kong SAR; Office of Education Development and Gateway Education, City University of Hong Kong, Hong Kong SAR; Chinese Civilization Centre, City University of Hong Kong, Hong Kong SAR","2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)","17 Jan 2019","2018","","","624","629","This paper reports a flipped classroom strategy to encourage students to adopt self-learning and peer-learning pedagogies, by using virtual reality technologies to provide immersive environment for the learners. A course of General Education modules in the Arts and Humanities area was selected to design relevant teaching and learning activities. It has always been a challenge to plan activities that engage students from different colleges and departments to learn architectural terminologies. All students enrolled in this module were requested to accomplish VR group activities with assigned mini-tasks, and a questionnaire to assess their perceived learning experience. Also, feedbacks from the survey in open-ended questions of this cohort were collected and analysed qualitatively.","2470-6698","978-1-5386-6522-0","10.1109/TALE.2018.8615369","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8615369","technology-enhanced learning;virtual reality;Chinese architectures;flipped learning","5G mobile communication;Australia;Conferences;Education","architecture;computer aided instruction;educational courses;structural engineering computing;teaching;virtual reality","chinese architectures course;flipped classroom approach;flipped classroom strategy;peer-learning pedagogies;virtual reality technologies;immersive environment;General Education modules;relevant teaching;plan activities;architectural terminologies;VR group activities;perceived learning experience;colleges","","2","","16","","17 Jan 2019","","","IEEE","IEEE Conferences"
"An In-Depth Exploration of the Effect of 2D/3D Views and Controller Types on First Person Shooter Games in Virtual Reality","D. Monteiro; H. -N. Liang; J. Wang; H. Chen; N. Baghaei",Xi’an Jiaotong-Liverpool University; Xi’an Jiaotong-Liverpool University; Xi’an Jiaotong-Liverpool University; Xi’an Jiaotong-Liverpool University; Massey University,"2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","14 Dec 2020","2020","","","713","724","The amount of interest in Virtual Reality (VR) research has significantly increased over the past few years, both in academia and industry. The release of commercial VR Head-Mounted Displays (HMDs) has been a major contributing factor. However, there is still much to be learned, especially how views and input techniques, as well as their interaction, affect the VR experience. There is little work done on First-Person Shooter (FPS) games in VR, and those few studies have focused on a single aspect of VR FPS. They either focused on the view, e.g., comparing VR to a typical 2D display or on the controller types. To the best of our knowledge, there are no studies investigating variations of 2D/3D views in HMDs, controller types, and their interactions. As such, it is challenging to distinguish findings related to the controller type from those related to the view. If a study does not control for the input method and finds that 2D displays lead to higher performance than VR, we cannot generalize the results because of the confounding variables. To understand their interaction, we propose to analyze in more depth, whether it is the view (2D vs. 3D) or the way it is controlled that gives the platforms their respective advantages. To study the effects of the 2D/3D views, we created a 2D visual technique, PlaneFrame, that was applied inside the VR headset. Our results show that the controller type can have a significant positive impact on performance, immersion, and simulator sickness when associated with a 2D view. They further our understanding of the interactions that controllers and views have and demonstrate that comparisons are highly dependent on how both factors go together. Further, through a series of three experiments, we developed a technique that can lead to a substantial performance, a good level of immersion, and can minimize the level of simulator sickness.","1554-7868","978-1-7281-8508-8","10.1109/ISMAR50242.2020.00102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284718","Virtual Reality;2D/3D Views;Controller types;First Person Shooter;Gaming;Head-Mounted Displays","Performance evaluation;Visualization;Three-dimensional displays;Two dimensional displays;Keyboards;Games;Turning","computer games;data visualisation;helmet mounted displays;virtual reality","virtual reality;input techniques;VR experience;VR FPS;typical 2D display;controller type;2D visual technique;VR headset;first person shooter games;commercial VR head-mounted displays;2D-3D views;PlaneFrame","","","","54","","14 Dec 2020","","","IEEE","IEEE Conferences"
"Virtual reality based training to resolve visio-motor conflicts in surgical environments","M. Vankipuram; K. Kahol; A. Ashby; J. Hamilton; J. Ferrara; M. Smith","Human Machine Symbiosis Lab, Department of Biomedical Informatics, Arizona State University, Phoenix 85004 USA; Human Machine Symbiosis Lab, Department of Biomedical Informatics, Arizona State University, Phoenix 85004 USA; Human Machine Symbiosis Lab, Department of Biomedical Informatics, Arizona State University, Phoenix 85004 USA; Phoenix Integrated Surgical Residency Program, Banner Good Samaritan Medical Center, AZ 850016 USA; Phoenix Integrated Surgical Residency Program, Banner Good Samaritan Medical Center, AZ 850016 USA; Simulation and Training Center (SimET Center), Banner Good Samaritan Medical Center, Phoenix AZ 850016 USA","2008 IEEE International Workshop on Haptic Audio visual Environments and Games","21 Nov 2008","2008","","","7","12","An issue that complicates movement training, specifically in minimally invasive surgery, is that often there is no one to one correlation between the visual feedback provided on a screen and the movement required to perform the given task. This paper presents a simulator that specifically addresses the intermodal conflict between motor actuation and visual feedback. We developed a virtual reality visio-haptic simulator to assist surgical residents in training to resolve visio-motor conflict. The developed simulator offers individuals the flexibility to train in various scenarios with different levels of visio-motor conflicts. The levels of conflict were simulated by creating a linear functional relation between movement in the real environment and the virtual environment. The haptic rendering was consistent with the visual feedback. Experiments were conducted with expert pediatric surgeons and general surgery residents. Baseline data on performance in conditions of visio-motor conflict were assimilated from expert surgeons. Residents were divided into experimental group that was exposed to visio-motor conflict and the control group which wasnpsilat exposed to visio-motor conflict training. When the performance was compared on a standard surgical suturing task, the residents with inter-modal conflict training performed better than the control group suggesting the construct validity of the training and that visio-motor training can accelerate learning.","","978-1-4244-2668-3","10.1109/HAVE.2008.4685290","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4685290","Virtual Reality;Medical Simulation;Haptic User Interfaces;Surgical Simulation","Virtual reality;Minimally invasive surgery;Feedback;Humans;Cameras;Haptic interfaces;Medical simulation;Ergonomics;Biological system modeling;Patient monitoring","computer based training;haptic interfaces;medical computing;rendering (computer graphics);surgery;virtual reality","virtual reality based training;visio-motor conflicts;surgical environments;minimally invasive surgery;visual feedback;linear functional relation;haptic rendering;visio-motor training","","3","","10","","21 Nov 2008","","","IEEE","IEEE Conferences"
"Does virtual reality affect visual perception of egocentric distance?","T. Rousset; C. Bourdin; C. Goulon; J. Monnoyer; J. Vercher","Aix Marseille Université, CNRS, ISM UMR 7287, 13288, Marseille, France; Aix Marseille Université, CNRS, ISM UMR 7287, 13288, Marseille, France; Aix Marseille Université, CNRS, ISM UMR 7287, 13288, Marseille, France; PSA Peugeot Citroën, Velizy Villacoublay; Aix Marseille Université, CNRS, ISM UMR 7287, 13288, Marseille, France","2015 IEEE Virtual Reality (VR)","27 Aug 2015","2015","","","277","278","Virtual reality (driving simulators) tends to generalize for the study of human behavior in mobility. It is thus crucial to ensure that perception of space and motion is little or not affected by the virtual environment (VE). The aim of this study was to determine a metrics of distance perception in VEs and whether this metrics depends on interactive factors: stereoscopy and motion parallax. After a training session, participants were asked, while driving, to estimate the relative location (5 to 80 m) of a car on the same road. The overall results suggest that distance perception in this range does not depend on interactive factors. In average, as generally reported, subjects underestimated the distances whatever the vision conditions. However, the study revealed a large interpersonal variability: two profiles of participants were defined, those who quite accurately perceived distances in VR and those who underestimated distances as usually reported. Overall, this classification was correlated to the level of performance of participants during the training phase. Furthermore, learning performance is predictive of the behavior of participants.","2375-5334","978-1-4799-1727-3","10.1109/VR.2015.7223403","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223403","Driving simulation;distance perception;stereoscopy;parallax;variability","Virtual environments;Training;Vehicles;Measurement;Roads;Three-dimensional displays","human factors;traffic engineering computing;virtual reality","virtual reality;visual perception;egocentric distance;driving simulators;human behavior;space perception;motion perception;virtual environment;distance perception;VE;stereoscopy factor;motion parallax factor;interpersonal variability","","1","","8","","27 Aug 2015","","","IEEE","IEEE Conferences"
"Level of Presence in Max Where Virtual Reality","B. Berki","Széchenyi Istvân University, Doctoral School of Multidisciplinary Engineering Sciences,Győr,Hungary","2020 11th IEEE International Conference on Cognitive Infocommunications (CogInfoCom)","2 Nov 2020","2020","","","000485","000490","Presence is the sense of being inside a virtual environment, that can be experienced also in desktop virtual realities not only in full-immersive VRs. MaxWhere is a desktop virtual reality that is used in education and for collaborative work. This VR can be considered as a 3D browser because in the space there are several smartboards where any web-content, document, or image can be displayed. This study compares the sense of presence in MaxWhere virtual reality to other desktop virtual realities with the Igroup Presence Questionnaire. This VR is in focus of numerous scientific research, thus this comparison of presence level could be a great starting point for them. The analysis showed that the level of presence in MaxWhere virtual reality corresponds to the average presence level in other desktop virtual realities. The analysis of the presence profile has shown that the general sense of presence and the spatial presence are relatively high in this VR. The experienced realism scale is the lowest because this VR is designed to foster working and learning inside the virtual space and not for having a high fidelity.","2380-7350","978-1-7281-8213-1","10.1109/CogInfoCom50765.2020.9237826","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237826","virtual reality;presence;desktop virtual reality;IPQ","Three-dimensional displays;Conferences;Education;Virtual environments;Virtual reality;Collaborative work;Browsers","virtual reality","MaxWhere virtual reality;Igroup presence questionnaire;desktop virtual reality;virtual environment;virtual space;VR","","","","26","","2 Nov 2020","","","IEEE","IEEE Conferences"
"Helicopter visual signaling simulation: Integrating VR and ML into a low-cost solution to optimize Brazilian Navy training","A. L. C. Doneda; J. C. de Oliveira","Military Institute of Engineering (IME),Computer Engineering Department,Rio de Janeiro,Brazil; Laboratory of Applied Multimedia and Virtual Environments, National Laboratory for Scientific Computing (LNCC),Petrópolis,Brazil","2020 22nd Symposium on Virtual and Augmented Reality (SVR)","23 Nov 2020","2020","","","434","442","Landing Signalman (LS) is the military in charge of visually signaling the helicopter pilot when landing and taking off from a moving ship, ensuring general safety conditions of the flight deck area. It requires self-confidence, knowledge, skills, team coordination, and appropriate reaction capacity only achieved with intensive training. After studying the theory, Brazilian Navy LS trainees go directly to the practice stage at sea. This hands-on training phase straight after classroom reveals a series of limitations on LS trainee's performance. To better prepare the LS trainee, reduce training costs and provide a safe environment to perform unlimited training opportunities, we developed a lightweight, portable, and low-cost VR simulator for training optimization, denominated Helicopter Visual Signal Simulator (HVSS). Due to its specificities, a Machine Learning gesture recognition method was integrated into the virtual environment, and two datasets were created. This study details the process of achieving the design goals, developing the VR simulator prototype, and analyzing the tests we performed With 15 experienced instructors. The results indicate that HVSS meets all requirements to provide a reliable training solution.","","978-1-7281-9231-4","10.1109/SVR51698.2020.00071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262459","Simulation;Virtual Reality;Machine Learning;Gesture Recognition","Training;Visualization;Helicopters;Virtual environments;Prototypes;Safety;Reliability","computer based training;gesture recognition;helicopters;learning (artificial intelligence);ships;virtual reality","general safety conditions;flight deck area;intensive training;hands-on training phase;unlimited training opportunities;lightweight cost VR simulator;training optimization;machine learning;virtual environment;VR simulator prototype;helicopter pilot;helicopter visual signal simulator;gesture recognition;landing signalman;Brazilian navy training","","","","46","","23 Nov 2020","","","IEEE","IEEE Conferences"
"Immersive and non-immersive virtual reality system to learn relative motion concepts","M. Kozhevnikov; J. Gurlitt","Department of Engineering, Norfolk State University, VA USA; Department of Educational Science, University of Freiburg, Germany","2013 3rd Interdisciplinary Engineering Design Education Conference","10 Jun 2013","2013","","","168","172","The focus of the current study is to understand the strength and limits of immersive virtual environments as a new media for learning and teaching relative motion concepts. Our results show that while training in both Immersive Virtual Environment (IVE) and Desktop (non-immersive) Virtual Environment (DVE) resulted in a significant improvement on relative motion problem solving test in general, the IVE group performed significantly better than the DVE group on solving two-dimensional relative motion problems after training in the simulations. This result supports our hypothesis that egocentric encoding of the scene in IVE (where the learner constitutes a part of a scene being immersed in it) as compared to allocentric encoding on a computer screen in DVI (where the earner is looking on the scene from “outside”) is beneficial for studying two-dimensional problems.","","978-1-4673-5112-6","10.1109/IEDEC.2013.6526781","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6526781","Virtual Environment;Educational Technology;Immersivity;Relative Motion","Computational modeling;Solid modeling;Switches;Abstracts;Reliability;Real-time systems;Virtual reality","computer aided instruction;human computer interaction;teaching;user interfaces;virtual reality","immersive virtual reality system;non immersive virtual reality system;relative motion concept learning;relative motion concept teaching;desktop virtual environment;IVE;DVE;motion problem solving test;educational technology","","2","","14","","10 Jun 2013","","","IEEE","IEEE Conferences"
"Development and evaluation of a mobile AR assisted learning system for English learning","M. Hsieh","Fortune Institute of Technology, No. 288, Chihshiue Rd., Daliao District, Kaohsiung City 83158, Taiwan","2016 International Conference on Applied System Innovation (ICASI)","11 Aug 2016","2016","","","1","4","Increasing researches have indicated that digital media learning materials are emerged to education in recent years. Multimedia learning environments have offered new ways for learners to interact with various educational resources. Some studies have mentioned that the AR technologies should better employment in learning environments. This paper presents AR-based technologies to develop and evaluate a mobile English learning system. The learning content was based on English prepositions. The multimedia formats included text, image, movie, and interaction. Furthermore, this paper utilizes questionnaire and observation, to explore the system acceptance and learning behavior of students learning. The results found that the mobile AR English learning system could enhance students' attention and affect their learning behaviors. Students generally accepted the mobile AR English assisted learning environment.","","978-1-4673-9888-6","10.1109/ICASI.2016.7539743","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539743","augmented reality;augmented reality learning environment;English learning;user acceptance","Decision support systems;Conferences;Computers;Urban areas;Encoding;Education;Information technology","augmented reality;computer aided instruction;ergonomics;linguistics;multimedia systems","digital media learning materials;educational resources;AR-based technologies;English prepositions;multimedia learning environments;multimedia formats;student attention;learning behaviors;mobile AR assisted English learning system","","","","18","","11 Aug 2016","","","IEEE","IEEE Conferences"
"Are virtual learning environments appropriate for dyscalculic students? A theoretical approach on design optimization of virtual worlds used in mixed-reality simulators","L. Lenz; A. Richert; K. Schuster; S. Jeschke","IMA/ZLW & IfU, RWTH Aachen University, Aachen, Germany; IMA/ZLW & IfU, RWTH Aachen University, Aachen, Germany; IMA/ZLW & IfU, RWTH Aachen University, Aachen, Germany; IMA/ZLW & IfU, RWTH Aachen University, Aachen, Germany","2015 IEEE Games Entertainment Media Conference (GEM)","11 Jan 2016","2015","","","1","8","In Germany, there are more than four million people (almost 6% of Germany's entire population) living with dyscalculia, a disorder which alludes numbers as well as general arithmetic and is closely related to dyslexia [1]. The estimated number of unreported cases is probably even higher. Medical researchers talk about a ""forestalled elite"" since these people are commonly not less intelligent than non-handicapped individuals. Still, they rarely make it to a university-entrance diploma; they get lost on the way because of missing standby facilities offered in primary and continuative schools [2]. They require special needs and attention in order to learn and show their de facto potential. This paper deals with the dyscalculic-friendliness of learning environments provided by mixed-reality simulators. After a presentation of the scientific state of the art on the specific needs of affected students, it will be elaborated in how far virtual environments used in the education of mechanical engineering students can sufficiently not only meet those needs but support them in their study.","","978-1-4673-7452-1","10.1109/GEM.2015.7377205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7377205","dyscalculia;dyslexics and dyscalculics in academia;virtual learning environments;learning content adaptation;mixed reality simulator;Dybuster Calcularis","Games;Software;Visualization;Education;Virtual reality;Finite element analysis;Mechanical engineering","augmented reality;computer aided instruction;educational institutions;engineering education;handicapped aids;mechanical engineering computing;medical disorders","virtual learning environments;dyscalculic students;design optimization;virtual worlds;mixed-reality simulators;Germany entire population;dyslexia;forestalled elite;nonhandicapped individuals;university-entrance diploma;continuative schools;primary schools;dyscalculic-friendliness;learning environments;virtual environments;mechanical engineering students","","1","","18","","11 Jan 2016","","","IEEE","IEEE Conferences"
"Leveraging Mixed Reality and the Three Apprenticeships Model to Facilitate & Assess Authentic Learning Experiences for Civil Engineering Students","L. Perry; J. London; W. Wu; S. Ayer; K. Smith; K. Patil","Virginia Tech,Department of Engineering Education,Blacksburg,USA; Virginia Tech,Department of Engineering Education,Blacksburg,USA; California State University, Fresno,Department of Construction Management,Fresno,USA; Arizona State University,School of Sustainable Engineering and the Built Environment,Tempe,USA; Arizona State University,School of Sustainable Engineering and the Built Environment,Tempe,USA; Arizona State University,School of Sustainable Engineering and the Built Environment,Tempe,USA","2020 IEEE Frontiers in Education Conference (FIE)","4 Dec 2020","2020","","","1","4","This work-in-progress paper presents highlights from a multi-year study aiming to develop and assess the impact of a mixed reality experience that sufficiently replicates the learning civil engineering students experience during a physical design and construction task. Human Centered Design principles and tenets of the Carnegie Foundation's Three Apprenticeships Model (i.e., learning related to ""Head"", ""Hand"", and ""Heart"") inform the project design, development, and assessments. The development of heart-focused assessments is one focus during the second year in this three-year project. This paper includes a brief overview of the project progress, in general, along with preliminary findings regarding the instrument development. It summarizes the results of a pilot study, including an item analysis of the survey responses. These findings offer preliminary evidence for the content validity and substantive validity of the instrument. Next steps and implications for the engineering education community are also discussed.","2377-634X","978-1-7281-8961-1","10.1109/FIE44824.2020.9274289","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9274289","mixed reality;civil engineering;instrument development","Instruments;Industries;Heart;Safety;Engineering students;Particle measurements;Civil engineering","civil engineering;computer aided instruction;engineering education;human computer interaction;user centred design","instrument development;engineering education community;authentic learning experiences;work-in-progress paper presents highlights;multiyear study;mixed reality experience;construction task;project design;Carnegie foundation;apprenticeships model;civil engineering students experience;human centered design","","","","11","","4 Dec 2020","","","IEEE","IEEE Conferences"
"New learning spaces? M-learning's, in particular the iPad's potentials in education","G. Molnár","Department of Technical Education, Budapest University of Technology and Economics, Budapest, Hungary","2012 15th International Conference on Interactive Collaborative Learning (ICL)","7 Jan 2013","2012","","","1","5","The iPad is a very popular touchscreen tablet computer, which was introduced approximately two, two and a half years ago. It runs the MAC operating system making it suitable for different general and special uses. The paper focuses on the fact how the use of iPads can help education, make teaching and learning more efficient. In addition to the technical, infrastructural parameters, which are essential as much as the user's experience and it usability are concerned, the paper provides a few concrete applications as well. Today, the use of iPads is general either in everyday life, or in public education or tertiary education. The author analysis his experiences from the viewpoint of students, but also mentions applications useful for teachers. Students can use iPads with the appropriate applications in any stage of the learning process, e.g. using notes, course materials, schedules and assignments, cooperation, group assignments by collaboration. The paper also describes such solutions or respectively suggestions by means of which the monitoring of shared content and data can be realized by the teacher. A few professional applications (e.g. used by students of medicine, engineering and natural sciences) are also listed.","","978-1-4673-2427-4","10.1109/ICL.2012.6402204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402204","Learning support ICT devices;M-learning;IPad;Iphone;iOS;tablet PC","Tablet computers;Educational institutions;Mobile communication;Materials;Smart phones;Electronic learning","computer aided instruction;mobile computing;notebook computers;operating systems (computers);touch sensitive screens","learning spaces;m-learning;iPad;touchscreen tablet computer;MAC operating system;public education;tertiary education;learning process;shared content monitoring","","","","9","","7 Jan 2013","","","IEEE","IEEE Conferences"
"Supporting mixed-mode role-play activities in a virtual environment","E. Jambi; M. Gardner; V. Callaghan","Department of Computer Science, University of Essex, UK; Department of Computer Science, University of Essex, UK; Department of Computer Science, University of Essex, UK","2017 9th Computer Science and Electronic Engineering (CEEC)","9 Nov 2017","2017","","","49","54","This paper introduces an approach to harness the advantages of 3D virtual environments in a more effective way in order to benefit the student's learning in understanding abstract concepts. It is a proposal for a generalized framework that generates a mixed-simulation role-play activity. In this activity, the student functions as a part of a working system in a virtual environment in order to complete different tasks. This framework acts as a template that can be used to design different role-play activities for diverse subjects.","","978-1-5386-3007-5","10.1109/CEEC.2017.8101598","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8101598","Virtual Reality;Role-Play;Immersive Learning;Virtual Environment;Mix-Simulation","Object oriented modeling;Virtual environments;Containers;Three-dimensional displays;Education;Computational modeling","computer aided instruction;computer games;virtual reality","mixed-simulation role-play activity;virtual environment;mixed-mode role-play activities;3D virtual environments;student learnning","","","","13","","9 Nov 2017","","","IEEE","IEEE Conferences"
"wavEMS: Improving Signal Variation Freedom of Electrical Muscle Stimulation","M. Kono; J. Rekimoto","The University of Tokyo; The University of Tokyo, Sony Computer Science Laboratories, Inc.","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1529","1532","There has been a long history in electrical muscle stimulation (EMS), which has been used for medical and interaction purposes. Human-computer interaction (HCI) researchers are now working on various applications, including virtual reality (VR), notification, and learning. For the electric signals applied to the human body, various types of waveforms have been considered and tested. In typical applications, pulses with short duration are applied, however, many perspectives are required to be considered. In addition to the duration and polarity of the pulse/waves, the wave shapes can also be an essential factor to consider. A problem of conventional EMS toolkits and systems are that they have a limitation to the variety of signals that it can produce. For example, some may be limited to monophonic pulses. Furthermore, they are usually limited to rectangular pulses and a limited range of frequencies, and other waveforms cannot be produced. These kinds of limitations make us challenging to consider variations of EMS signals in HCI research and applications. The purpose of “wavEMS” is to encourage testing of a variety of waveforms for EMS, which can be manipulated through audio output. We believe that this can help improve HCI applications, and to open up new application areas.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798102","Human-centered computing;Human computer interaction (HCI);Interaction devices;Haptic devices;General and reference;Document types;General literature","Energy management;Human computer interaction;Medical services;Muscles;Safety;History","electromyography;human computer interaction;medical signal processing;virtual reality","EMS signals;wavEMS;HCI applications;electrical muscle stimulation;medical interaction purposes;virtual reality;electric signals;human body;wave shapes;monophonic pulses;rectangular pulses;human computer interaction researchers;signal variation freedom;EMS toolkits;VR;waves polarity","","","","34","","15 Aug 2019","","","IEEE","IEEE Conferences"
"Conceptual Model for Human Anatomy Learning Based Augmented Reality on Marker Puzzle 3D Printing","W. Hidayat; A. E. Permanasari; P. I. Santosa; N. Arfian; L. Choridah","Universitas Gadjah Mada,Department of Electrical Engineering and Information Engineering,Yogyakarta,Indonesia; Universitas Gadjah Mada,Department of Electrical Engineering and Information Engineering,Yogyakarta,Indonesia; Universitas Gadjah Mada,Department of Electrical Engineering and Information Engineering,Yogyakarta,Indonesia; Faculty of Medicine, Universitas Gadjah Mada,Departement of Anatomy,Yogyakarta,Indonesia; Faculty of Medicine, Universitas Gadjah Mada,Departement of Anatomy,Yogyakarta,Indonesia","2019 3rd International Conference on Informatics and Computational Sciences (ICICoS)","6 Feb 2020","2019","","","1","5","Learning medicine not only requires students to master a variety of abilities but also must follow some doctoral standards. In general, the learning process within the Faculty of Medicine students is still conducted by using cadaver. However, several obstacles were encountered when using that media. To overcome the limitations, the use of Augmented Reality (AR) technology has become a medium used for learning. A systematic review method of the study and research of human anatomy on AR in the field of medicine is presented. Based on this review, a model for developing human anatomy learning media using AR that uses 3D printing object marker puzzles was created. The concept model is expected to be able to overcome some of the problems. Potential challenges in developing human anatomy learning models using 3D printing puzzle markers present more specific information and location of a part of human anatomy.","","978-1-7281-4610-2","10.1109/ICICoS48119.2019.8982471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8982471","human anatomy learning;human anatomy;skeleton;sugmented reality;marker puzzle 3D printing","","augmented reality;biomedical education;computer aided instruction;medical computing;solid modelling;three-dimensional printing","3D printing object marker puzzles;human anatomy learning models;3D printing puzzle markers;doctoral standards;learning process;augmented reality technology;systematic review method;marker puzzle 3D printing;Faculty of Medicine students;cadaver;human anatomy learning media","","1","","21","","6 Feb 2020","","","IEEE","IEEE Conferences"
"Identifying Accessibility Conditions for Children with Multiple Disabilities: A Virtual Reality Wheelchair Simulator","N. Rodriguez",L1RMM - University of Montpellier - CNRS,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","370","372","Training is one of the main domain applications of Virtual Reality (VR). Simulation and visual realism provide training situations very close to practice with real systems while reducing cost and with greater safety. Furthermore, VR offers the possibility of change time or space scales, visualize from different perspectives, experience inaccessible real environments, all under the user's control, without risks, at her own pace. This allows to develop skills and to have confidence to work thereafter in real conditions with real equipment. Interaction technologies are now more widely available and affordable. But generally devices are conceived for “standard” people leaving behind people with impairments and further accentuating the digital gap. In this paper, we present our work in the development of an accessible wheelchair simulator designed to allow children with multiple disabilities to familiarize themselves with the wheelchair, and practitioners to better understand children capabilities.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699276","virtual reality;simulator;disability;multiple disabilities;wheelchair;learning;augmented and alternative communication;interaction devices;I.3.1 [Computer Graphics]: Hardware Architecture — Input devices;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism – Virtual reality;H.5.1 [Information Interfaces And Presentation]: Multimedia Information Systems — Artificial, augmented, and virtual realities;H.5.2 [Information Interfaces And Presentation]: User Interfaces — Input devices and strategies","Wheelchairs;Virtual reality;Tools;Solid modeling;Visualization;Games;Adaptation models","computer based training;computer simulation;handicapped aids;virtual reality;wheelchairs","accessibility conditions;VR;visual realism;interaction technologies;accessible wheelchair simulator;virtual reality wheelchair simulator;children with multiple disabilities","","","","12","","29 Apr 2019","","","IEEE","IEEE Conferences"
"Effects of Image Size and Structural Complexity on Time and Precision of Hand Movements in Head Mounted Virtual Reality","A. U. Batmaz; M. de Mathelin; B. Dresp-Langley","University of Strasbourg CNRS, ICube Laboratory, UMR 7357 Strasbourg, France; University of Strasbourg CNRS, ICube Laboratory, UMR 7357 Strasbourg, France; University of Strasbourg CNRS, ICube Laboratory, UMR 7357 Strasbourg, France","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","167","174","The effective design of virtual reality (VR) simulators requires a deeper understanding of VR mediated human actions such as hand movements, with specifically tailored experiments testing how different design parameters affect performance. The present experiment investigates the time and precision of hand (index finger) movements under varying conditions of structural complexity and image size in VR without tactile feed-back from object to hand/finger. 18 right-handed subjects followed a complex and a simple physiological structure of small, medium and large size in VR, with the index finger of one of their two hands, from right to left, and from left to right. The results show that subjects performed best with small-size-simple structures and large-size-complex structures in VR. Movement execution was generally faster and more precise on simple structures. Performance was less precise when the dominant hand was used to follow the complex structures and small object size in VR. It is concluded that both size and structural complexity critically influence task execution in VR when no tactile feed-back from object to finger is generated. Individual learning curves should be monitored from the beginning of the training as suggested by the individual speed-precision analyses.","","978-1-5386-3365-6","10.1109/VR.2018.8446217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446217","Computing methodologies-Computer Graphics-Graphic systems and interfaces-Virtual reality;Human-centered computing-Human computer interaction (HCI)-Interaction paradigms-Virtual reality;Human-centered computing-Human computer interaction (HCI)-Interaction devices;Human-centered computing-Interaction design;Software and its engineering-Software organization and properties-Virtual worlds software-Virtual worlds training simulations","Indexes;Complexity theory;Three-dimensional displays;Head;Software;Image color analysis;Virtual reality","biomechanics;feedback;helmet mounted displays;image processing;physiological models;virtual reality","structural complexity;image size;hand movements;virtual reality simulators;VR mediated human actions;index finger;tactile feedback;physiological structure;complex structures;speed-precision analyses;head mounted virtual reality;learning curves","","2","","41","","30 Aug 2018","","","IEEE","IEEE Conferences"
"Age and technology: Adult learning performance in desktop virtual reality environments","D. Steele; S. Fulbright; A. N. Nichols","College of Applied Science and Technology University of Arkansas Fort Smith; Surgical Technology University of Arkansas Fort Smith; Computer-Aided Drafting & Design, University of Arkansas Fort Smith","2010 IEEE Frontiers in Education Conference (FIE)","23 Dec 2010","2010","","","S1F-1","T1A-3","The research project was conducted by the University of Arkansas Fort Smith (UAFS) and the Occupational Education virtual reality research team at Oklahoma State University with the purpose of the learning effects of desktop virtual reality (VR) in college and technical training. Participants were from the UAFS two year surgical Technicians program and students from a career tech center. The paper presents findings from a five-year program of research on desktop virtual reality (VR) in college and technical education and describes what the research team has discovered to be important factors in its successful implementation. It defines desktop VR, outlines theoretical and empirical foundations for desktop VR research, summarizes important findings from research on desktop VR in technical education, and draws conclusions regarding implementation and further research in this field.","2377-634X","978-1-4244-6262-9","10.1109/FIE.2010.5673624","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5673624","VR/VEs;ATI;Supplantation Theory;General Efficacy;SPT1","Virtual reality;Computers;Training;Navigation;Solid modeling;Surgery","computer aided instruction;educational institutions;engineering education;further education;virtual reality","adult learning performance;desktop virtual reality environments;University of Arkansas Fort Smith;occupational education virtual reality research team;Oklahoma state university;college training;technical training;surgical technicians program;career tech center;technical education","","1","","4","","23 Dec 2010","","","IEEE","IEEE Conferences"
