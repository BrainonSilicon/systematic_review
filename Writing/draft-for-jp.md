###### tags: `transfer report`, `introduction`, `draft`

# Transfer Report Draft for JP

```
Updates: 
- written out study designs for 0,1,2, & 3


----- TODO ----- 
- abstract 
- introduction
- background 
- systematic review menthods, findings, and relevance 
- study design for study 4 and 5 
- analyses 
- training plan 


```

# Learning to learn in Virtual Reality 


# Introduction


Virtual Reality (VR) is a technology defined by the ability to build and experience a computer generated world and is now synonymous with the head-mounted-displays from Oculus, HTC, Microsoft, and many other commercial ventures. 

There is a increasing level of interest in using VR technologies as a training tool for  

* train pilots, surgeons, and teach people anything from mathematics, surgery, race car assembly, to how to fly a plane (****)
* and military sim (…, Bossard, Kermarrec, Buche, & Tisseau, 2008 ; Holden, 2005), For training nurses, training pilots, practice and assessment of laparoscopic surgery, the education of chemistry and electrical engineering concepts and geography, as well as various sports.
* While this interest may stem from a Matrix-born ‘I know Kung-Fu’ hope, there is a profound danger in using Virtual Reality as a training medium if what you learn in VR does not transfer to the real “Natural” world.

**Without clarity and knowledge of if, how, and under what conditions newly acquired skills will transfer; VR may not be an appropriate medium for training. This is of particular concern when VR is being used as a substitute training environment for highly dangerous situations such as the training of surgeons, nuclear powerplant engineers, and emergency services().**

The enclosed transfer report details a 5 stage project that is proposed to investigate the conditions that support the transfer of learning from Virtual Reality to Reality.

---


# A Note on Terminology

The literature on VR transfer studies have used the term ‘VR’ to describe a wide range of technologies (Smith, ). The shared element of all these technologies is the 

A deeper analysis and summary of these will be entered into my final dissertation, however for the purposes of this transfer report, the separation between HMD based VR (HMD-VR) and other VR technologies will be made. The acronym ‘VR’ will be used as an umbrella term to describe the range of virtual reality technologies used to present computer generated stimuli that users may interact with, and the term Natural will be used to denote the ‘real world’. 

Learning rate refers to the rate of skill acquisition and/or relative changes in performance over time. 


Transfer of Learning exists from its constituents 
Transfer of Learning inherently has two constituent parts
* Learning
* And a transfer of that learning out of the context it was acquired 

In order to address transfer of learning, we have to assess each part. 


### What is learning
Learning is typically defined as a relatively permanent change in a person’s capability to perform a skill (Schmidt & Lee, 2005).

### What is a skill?
I am defining skill by 1) something not known prior/something new, 2) able to be measured, 3) able to be improved through training (Adams, 1987)

Some work has indicated that there is an equivalence in terms of complex skill learning between the real and simulated environments (Alicea, 2020) however previous reviews have struggled to produce conclusive results due to wide variation in technologies that claim the name “VR” and


#### VR Skill acquisition has been assessed in x way - how we learn a skill in VR
- Anglin 
- Harris/Buckingham 
- 
How we learn in VR (strategy) Anglin & Liew ⚠️ to add 2-3 studies to this section ⚠️

(Anglin et al., 2017) Focused their investigation of sensorimotor learning by looking at visuomotor adaptation wherein a participant learns or “adapts” to a perturbation introduced by the experimenters in order to correctly perform a movement (Krakauer, 2009). Similar to how a sharp shooter will have to learn the rigged weighting of a carnival target practice game in order to win the prize. The study had participants sitting at a desk viewing a computer screen in Virtual Reality and in Natural. The study’s aims were to investigate a visuomotor adaptation and compare the strategies and adaptation acquired in VR compared with the same task in Natural. Implicit and explicit strategy and VR and Natural Participants in both VR and Natural required the same time to adapt to the perturbation and reduce their errors for the task indicating that Training block, baseline, rotation, block where participants did not receive visual feedback, then washout n=24 (12 per group), participants were not requested to report on their previous VR experience Hmd group felt difference with the quality of the interface statistically significant difference (p=0.064) This will be discussed later

No significant difference in reaction time No significant different in early or late adaption, or aftereffect (also called washout) which is the effect that having learnt the adaptation has on a non-perturbed movement (similar to the colloquial experience of “sea-legs” after sailors return to land).

Anglin and colleagues found no significant difference in the pure performance of the task in that The aiming angle was larger in the VR group compared to the natural group The same target error

HMD-VR participants utilized a greater cognitive strategy than CT participants, and CT participants engaged in greater implicit learning than HMD-VR participants Participants were able to adapt to perturbations in regardless of the medium Suggested that the implicit adaptation acquired in VR may not generalize

Criticism of the Anglin and Liew task Habituation to VR Mentioned this and how this may have contributed to the use of a cognitive or “explicit” strategy Comfort may impact task performance Visual acuity IPD and contrast Ocular dominance Also just a computer screen task ** NOTE Loop in Gavin’s paper and Saijo & Gomi, 2010 - how we use multiple strategies

**_Gavin’s Paper_**
golf simulator 

ergonomic and biomechanical fidelity (Harris et al., 2019) - does it allow for realistic motor movements - comparison between motor amplitude and speed, or joint between a real and a computer created task

The acquisition of a skill, and then performance of that skill beyond its training environment owes its foundations to Psychology’s First law of ‘the ability to learn in one context, and demonstrate what was learnt to a novel one’ (Shepard, 1987). Where Shepard’s definition discusses the generalization of learning in a cognitive sense, contemporary motor learning researchers differentiate between 
* Generalization  
* And Transfer of Learning 

To this extent Transfer of Learning (ToL) can be defined as the gain (or loss) in the capability for performance of one task as a result of practice on some other task (Schmidt and Lee, 1982). 
* The ‘task’ difference is the Natural vs VR 

The literature on VR is dominated by research on transfer of learning in the areas of education, rehabilitation, organizational management, and surgery (***) 
* as the effectiveness of a simulator is defined by its ability to teach skills that transfer to the real world (Gopher, 2012).


## **Transfer of Learning and Skill**

Transfer of learning (ToL) between virtual and real has been demonstrated in sports (Gray, 2017; 2019; Neumann et al., 2018), laparoscopic surgery, rehabilitation (Adamovich et al., 2009), and a handful of visuomotor tasks (*****). 

### Sports
**Gray, 2017** CAVE with the addition of a handheld actual bat (with tracking sensor attached) - Batters received visual, auditory, and tactile feedback during the movement and at the conclusion of their movement regarding the success of their swing

1. Adaptive training in a batting VE, (ii) extra sessions of batting practice in the VE, (iii) extra on-field sessions of real batting practice, and (iv) a control condition involving no additional training to the players’ regular practice.

pre-test (2x45min)x6 weeks | 2 weeks buffer post-test. Retention tests 1mo after post-test as well as a 5 year post experiment follow up which captured the progression of the player’s career and batting statistics So it was a study that indicated adaptive training administered in a VE was the most effective training the results can most likely be attributed to the fact that the training was designed in a way to challenge the players (it was stepwise) rather than because it was administered in VR


### Rehabilitation
- stroke rehab 
- DMD 
- CP
- [Lohse et al., 2014](https://scite.ai/reports/virtual-reality-therapy-for-adults-E4YRrW) 
- [Corbetta, Imeri, & Gatti., 2015](https://scite.ai/reports/rehabilitation-that-incorporates-virtual-reality-MMEZjm) 
- [Hatem et al., 2016](https://scite.ai/reports/rehabilitation-of-motor-function-after-DyPVLz) 
- [Laver et al., 2017](https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD008349.pub4/full) 
- [de Rooij, van de Port, & Meijer, 2016](https://academic.oup.com/ptj/article/96/12/1905/2866292)
 - [Ravi, Kumar, & Singhi, 2017](https://scite.ai/reports/effectiveness-of-virtual-reality-rehabilitation-rvaORV) 

 A 2010 study looked at the effect of VR with haptic feedback from movement on gait and balance, in stroke participants (Mirelman, et. al. 2010). The trainings for both groups consisted on 3 weekly, 1 hour sessions, for 4 weeks. Both groups received identical movement trainings based around dorsiflexion, plantar flexion, inversion, eversion, and combination movements; the non-VR group completed these movements at the instruction of a trainer whereas the VR group manipulated a virtually presented boat or plane towards a target. Results post analysis showed the VR group reporting greater improvement, and at faster rates, across multiple different measures. In all measures, the VR group showed significantly superior improvement, which was consistent with previous literature (Reid et. al., 2002; 2005; 2007).

Mirelmen conducted a follow up study using a CAVE (a reflexive acronym used to describe a 4 walled ‘room’ that constitutes ‘VR’ due to the projection of an environment that is viewed through glasses using alternating shutters thus allowing projections to appear ‘3D’). The study investigated the efficacy of VR on gait training and motor learning in patients with Parkinson’s (Mirelman et. al., 2011). The study found a 31% improvement in all motor and gait tasks, and a significant improvement at specific tasks that were reported four times larger than the threshold for significance.These results were persistent as found in a 1 month follow up.

VR was used by Bryanton and colleagues (2006) to assess the efficacy of using VR in motor rehabilitation for children with cerebral palsy. The use of the VE was to provide an engaging task, “gamifying” the rehabilitation to aid with rehabilitation protocol adherence, while also investigating the efficacy of VR to ensure exercise “correctness” which would allow for children to complete their rehabilitation at home, thus lower costs and barriers to accessing therapists. Same rehab exercises VRE reported more fun and higher interest/engagement completion of the exercises with greater correctness (as determined by the length of time held in dorsiflexion) VR participants reached a greater range of motion on average than the non-VR groups

The literature supports VR at home (for rehab) but can that be done with validity? 
- VEs that can be individualized—for example, by replicating the users’ home environment or modifying stimulus presentation according to user needs and capabilities—should enhance transfer and generalization of learning (Schultheis & Rizzo, 2001). 
- A study on balance (static, against perturbation, and goal directed movements), gait training, and yoga training using VR with Parkinson's patients did not find any difference between the effectiveness of the ‘home-based’ VR training compared to traditional ‘not in VR’ home training. All measures were rated equally in improving balance, walking, and quality of life. (Yang et al., 2016)

 
### Surgical Training
As surgical training and assessment is not the focus of the project - would not be able to contribute past the extensive systematic reviews that have been done

Extensive systematic reviews have been conducted 
- Nagendran et al., 2013 
- Alaker, Wynn & Arulampalam, 2016 
- Larsen et al., 2009 https://www.bmj.com/content/338/bmj.b1802/rapid-responses 
- this one will be good for critique 
- Systematic Reviews have found high risks of bias (Nagendran et al., 2013)
 - https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD006575.pub3/full 
- [Ahlberg et al., 2007](https://scite.ai/reports/proficiency-based-virtual-reality-training-significantly-Aakp6j) 
- [Gallagher et al., 2013](https://journals.lww.com/annalsofsurgery/Abstract/2013/06000/Prospective,_Randomized_Assessment_of_Transfer_of.7.aspx)
- [Seymour et al., 2002](https://journals.lww.com/annalsofsurgery/Abstract/2002/10000/Virtual_Reality_Training_Improves_Operating_Room.8.aspx)
transition citations [Wilson et al., 2011](https://scite.ai/reports/perceptual-impairment-and-psychomotor-control-3jQY0A), [Gallagher & Satava, 2002](https://scite.ai/reports/virtual-reality-as-a-metric-zXreL9).

---
# Current Work
> systematic review menthods, findings, and relevance
> - use it to defend why a novel task is best 

A systematic review has been in progress to catalogue 
> Put the methods and findings to date 

> Explain how there is confusion and therefore project originality (maybe mention FIFA if there is space) 

---

# Rationale (Project Originality)
> to provide evidence of project originality. this part goes at the end of the background section and intro the project originality defense part 
> Introduce project and show how it should help to address the deficiencies of other work (i.e. demonstrate how you evaluate your approved topic).

### 1. lots of VR research but not HMD research 
Despite the breadth of simulation and VR literature, research on modern virtual reality technologies is sparse. 
* There is a wealth of historic and contemporary literature on non-HMD-VR that assess transfer of learning. And yet HMDs are ubiquitous with vr training in industry

- surgery 
- previous motor studies 
- CAVE research 

### 2. All reviews have been inconclusive of transfer therefore there is an open question 
Of the existing literature there is
* Cite the sys review that had 1 paper left 
* Cite the other sys reviews 

and it is largely conflicting on if VR training will transfer 
- systematic reviews are inconclusive

### 3. HMD research has been largely carried out on impaired populations 
The HMD literature is largely focused on rehabilitation applications _Majority of literature in HMD-VR is focused on rehabilitation and has been conducted on impaired or non-normative populations._
* Undermining the conclusions we may draw to normative populations (citation)

### 4. Lack of matched control conditions (not like for like or no control)
Furthermore the assessment of VR and ToL lacks rigor (lacking matched control condition)

* There is existing literature on AR and VR technologies that assess learning when additional didactic material (such as instructional pop ups) have been added (Pletz et al. 2020).

Technological pedagogical knowledge (TPK) refers to the specific features of a technology that can be used to support pedagogical methods (Mishra & Koehler, 2006).

Affordances of virtual reality technologies to make motor learning better than reality (Levac & Sveistrup, 2014)

It is widely accepted that haptic feedback, spatialized audio, and added pedagogical overlays improve learning in virtual reality (…, …) . However much in the same way that one could learn stoichiometry via a textbook, an experiment, or a podcast listened to while riding the tube; the setting itself has been demonstrated to affect the “learning” itself. I do not aim to answer why virtual reality may be better at teaching something such as chemistry, but the extent to which a task learnt in virtual reality compared to the same task being taught not in VR.


### 5. Lack of follow up/longitudinal
As per the systematic review 

* Gray and Mierlman are the core ones that actually follows up (cite the two systematic reviews)

 
#### 6. Lack of knowledge about the ecological validity of remote VR
- ie. Does the home environment impact transfer of learning?

> Put the sentences on museums here 



--- 

These gaps in the literature cannot be filled by a single PhD, however the proposed projects seek to address and provide insight in the aforementioned gaps in our understanding. The following section details out 8 Research Questions that address gaps in our understanding on (1) skill acquisition in VR, and/or (2) the transfer (ToL) of skills acquired in VR. 


# Specific Aims and Objectives

For clarity, the aims and hypotheses sections have been merged. 

### Question 1: How we acquire skills in Virtual Reality
_How we learn is not a causal question_
> intro sentences about how this question addresses the gaps in the literature 
> sets up the thesis
> and how it answers the main question 
> why is this question important 

* Hypothesis 1: subjects will improve at the task after training 
* Hypothesis 2: skill acquisition is comparable between VR and Natural 
* Hypothesis 3: you will learn faster in VR 

### Question 2: Can skills learnt in VR transfer
> intro sentences about how this question builds off the literature 

> why is this question important 
* Ability to transfer from low fidelity to higher 
* Weak fusion 

> and how it answers the main question


- Hypothesis 4: skills learnt in VR will transfer to the real world 
- Hypothesis 5: the transfer between VR and Natural will be greater than the transfer from Natural to VR


### Question 3: how will environmental context affect skill acquisition in VR

> why is this question important 
> give background about how context matters 

It is thought that learnt skills may be closely linked to the context that they were acquired in (Desmurget et al. 1997; Michel et al. 2007; Krakauer et al. 2000; Taylor and Ivry 2013) so there is an open question as to if changing the context has an effect on tasks learnt in VR. 

if you’re in HMD-VR you’re immersed so it may still illicit a reaction (slater walking with a tail) 
- psychological sense of ‘being there’ (Slater, 2009) 
- is VR close enough to the real world for experimental context not to matter - does that context affect a participant's ability to learn a skill in VR?
- 
- Hypothesis 6: subjects will improve at the task after training in remote-VR 
- Hypothesis 7: there will be no difference in skill acquisition between in-lab-VR and remote-VR 


### Question 4: Does the training context impact Transfer of Learning?

> why is this question important 
> give background about how context matters 

- Hypothesis 8: subjects that are tested in the medium they were trained in will perform better than subjects who are tested in a medium different to the one they trained in 

(Remote-VR who test remotely will perform better than remote-VR who test in-lab)

* Remote VR will have an impact on the ability to transfer to natural compared with the transfer from in-lab remote 
    * I.e. the setting/context of VR will have an effect on transfer 
    * there will be a difference between training remotely and training in the lab
    * Such that the remote-VR group will have a harder time transferring to the Natural task 
        * This is because there are 2 context changes that must be overcome in order to transfer the skill 
        * Medium (ie. VR to Natural) and context (ie. remote to in-lab) 


### Question 5: what effect does training medium have on how long training effects last 
> why is this question important 


- Hypothesis 9: subjects that are tested in the medium they were trained in will perform better than subjects who are tested in a medium different to the one they trained in at a 4 week follow up 
- Hypothesis 10: VR trained will be better

### Question 6: effect of training medium on skill acquisition / is VR as effective as Natural as a training tool
> background 
> how does this answer the research question 

### Question 7: is there a ‘novelty effect’ from VR conditions that impacts skill acquisition
> background 
> how does this answer the research question 

VR-novel subjects will perform worse than VR-XP subjects at a 4 week follow up
* Due to novelty and extinction 

VR-novel subjects in VR conditions will perform worse at t0 and then ‘catch up’ to their peers 
* Faster initial learning rate 


### Question 8: will the ‘novelty effect’ impact ability to transfer 
* VR-novel who receive Natural training will display the least transfer between mediums 

Based on this, 4 studies and a pilot are proposed to investigate :warning:  [TODO: transfer of learning from VR to the real world.] 

---

# Methods

## Subjects

>inclusion/exclusion criteria 
Pre-Screening questionnaire to capture demographic information (age, sex, education level), previous experience with VR, gaming habits, and and previous exposure to motor learning paradigms (this is important as subjects may belong to the University of Leeds medical or dental schools and thus have recieved training on a VR simulator as part of their course).

Inclusion criteria will be participants aged 18-30 with normal vision, normative cognitive faculties, and normative motor f
* Normative motor 

Exclusion criteria for the study were subjects who had self-reported risk of epilepsy, visual impairments (even if corrected through the use of lenses), engaged in recreational drug use over the course of the study, used or were exposed to other motor learning trainings (such as those used by the dental and surgical programs). 

### Recruitment strategy
Participant recruitment will have four phases based on the paradigm participants are needed for; (1) pilot testing, (2) lab setting, (3) follow up experiment, (4) remote setting.

1. Pilot testing subjects will be recruited from ICON and Center for Immersive Technologies at the University of Leeds as well as available person networks who are unfamiliar with the proposed study aims.
2. Lab or ‘in person’ participants will be recruited from the University of Leeds School of Psychology, School of Engineering, School of Computing, Center for Immersive Technologies, and the Extended Reality Society. Undergraduate Psychology students receive course credit for experimental participation and it is therefore expected for those students to represent the greatest portion of participants.
3. Follow up participants will be recruited from the previous participant pool. Participants will be informed of an available follow up experiment at the conclusion of Study 1 and given the option to register their email address to receive sign up information.
4. Remote or ‘at home’ participants will also use the recruitment channels recruitment channels from (2) with the addition of virtual VR communities (such as The Virtual World Society, Circuit Stream, ARVR Women & Allies, ARVRinEDU, VREducatorsSpatial Network, and Side Quest).
 
### Group Assignment

#### Blinding
The studies will not be traditionally blinded as participants would be aware of the paradigm they were being tested on (i.e. in a HMD or Natural), although participants will not be informed of other groupings across the studies.


#### Matched groups
Groups will be matched as recruitment allows based on the pre-screening questionnaire. - VR experience - Demographics (based on the screening questionnaire)

#### Sample Size
As a novel task is proposed for the project it is difficult to definitively state the sample sizes necessary for investigation.

In order to remediate; analyses (Bayes factor) of pilot data will supplement the guidance from relevant literature in setting appropriate sample sizes.

Literature on transfer of learning from VR laparoscopic surgical trainers supports a 

Current group size is based on the effect size of ***** (citation, citation, citation). This may require adjustment after pilot data is collected (see Gantt chart for information). (Crochet et al., 2011) The choice of at least 10 subjects per group was based on a 2-tailed test, with α = 0.05 and power (1 – β) = 0.80, and an intended reduction of 30% in time taken to complete tasks for intervention versus control groups, based on data from previous studies of VR simulations for skill learning


> [Resources to inform protocol](https://docs.google.com/document/d/1G3faachWDk2HV6hwygLH_ah4gsJ5vzlTKMrKCaC6gE4/edit?usp=sharing) - Larsen CR, Soerensen JL, Grantcharov TP, Dalsgaard T, Schouenborg L, Ottosen C, et al. Effect of virtual reality training on laparoscopic surgery: randomised controlled trial. Br Med J. 2009;338:b1802. - Grantcharov 2004 - Hamilton 2002 - (Brunner et al., 2004) - (Crochet et al., 2011) - (Aggarwal et al., 2006) - (Chaudhry et al., 1999) - (Brown et al., 2019) - (Grantcharov et al., 2003) - Bric et al., 2015 - Stegemann et al., 2013 - Kang et al., 2014 - Foell et al., 2013 - Cho et al., 2013 - Kunert et al., 2021 - Mulla et al., 2012 - Mazue et al., 2018 - Aim et al., 2016

## Materials
> this is important because the smallest thing going wrong might confound results [Craig, Bastian, & Montagne, 2011](https://scite.ai/reports/how-information-guides-movement-intercepting-MMZbY9)


### Hardware
An Oculus Quest and accompanying touch controllers will be used for VR sessions.

#### Haptics
> Resources https://www.tandfonline.com/doi/abs/10.3200/JMBR.40.6.545-557 Haptic feedback (in VR) has been demonstrated to improve performance Surgery (Kim et al., 2004; Pan et al., 2015; Panait et al., 2009) & Movement (Weller & Zachmann, 2012)

Haptics are important (citation, citation) Questionnaires during pilot testing will collect qualitative data on perceived differences in haptic feedback quality Citation, citation, citation indicates that the proposed use of built-in haptics from the existing VR controllers is good enough low latency haptic feedback which was triggered by the ball hitting a VR maze wall to simulate the force feedback participants received in Natural Force testing is not feasible in the given timeframe (nor is the required hardware available to the student) and is an avenue for further research


#### Mazes
Laser-cut mazes out of MDF measuring 350mm x 350mm x 70mm (external measurements) with a clear top (plexi-glass or acrylic depending on availbility). 

Box dimensions were informed by anthropomorphic design in order to reduce the risk of ergonomically caused fatigue during trials. - to reduce ergonomic load and therefore fatigue - based on anthropomorphic average - https://www.cdc.gov/nchs/data/series/sr_11/sr11_252.pdf - https://multisite.eos.ncsu.edu/www-ergocenter-ncsu-edu/wp-content/uploads/sites/18/2016/06/Anthropometric-Detailed-Data-Tables.pdf See Appendix for mock-up

In VR conditions controllers will be affixed to the box 1/3 up from bottom edge.

The "lid" for the maze will be used to reduce the risk of participants "hacking" the maze by flicking the apparatus and causing the ball to jump over holes or walls. This lid will be replicated in the VR environment using colliders and collision levels. 

A wall will sit at the equivalent height as the Natural condition which will interact with the gameObjects in the scene but not be rendered on the screen therefore not visually perceptable to participants. 

Participants in all conditions will be informed of the lids presence in order to further reduce the risk of "hacking" attempts. 



Drop holes 

![](https://i.imgur.com/2aaFFbC.png)



#### Maze Design 
The maze will be designed such that no single ‘hack’ or strategy may be used. - this will ensure that the task measures the motor skill that is being acquires as opposed to being confounded by or reflecting a strategy learning or use of a ‘hack’ (such as building up velocity thus lowering chance of falling in a drop hole).

Beta testers will be used pre-pilot testing to ensure appropriate difficulty. This was determined such that a beta tester with no previous maze experience should not be able to solve the maze in under 5 minutes, and no more than 5 solves in a 12 minute time period.

At home Laser cut separator with slots compatible with either the right or left controller to ensure correct controller placement - same width and weight (± 10%) as box


### Software
For rendering the environment in VR, Unity 2019.4 will be used as it, at time of writing, the most stable release for VR development and receives long-term support (LTS) from Unity.


#### Physics simulator
Current VR research on sensorimotor adaptation uses the inbuilt physics engines of Unity or Unreal Engine (the two main commercial platforms used for VR development). It is unknown how closely the inbuilt parameters (e.g. friction coefficients) match reality, however in absence of any concerns raised by previous research, I will also use Unity’s OTS system.

If pilot data (qualitative survey responses and physics simulation benchmarking) indicates that the OTS physics engines are not sufficient, a custom physics engine was built for similar ‘marble maze’ experimentation by the author in 2017 and checked against similar materials (plywood, metal, glass, and acrylic). This engine can be updated to the current software standards and used as a better alternative to Unity’s physics simulator. It is out of project scope to create a novel physics engine for the purposes of the proposed research.


#### Spatialized Audio
Audio feedback important for learning (citation, citation, citation) Spatialized audio is super super important in VR (citation, citation, citation) Spatialized audio cues will be given for the ball hitting the wall, ambient room 

* Delivered via the built in speakers
* Designed and coded using Dolby (citation, citation, citation)

 
#### DeepLab Cut 
As the real world does not have the same omniscient world design, a Razer Kiyo camera will be used to capture movement data in Natural. The data will then be processed by DeepLabCut (Mathis et al 2018: 10.1038/s41593-018-0209-y) on a computer meeting the listed requirements for DeepLabCut. - HPC at Leeds - my machine will do it with a RAM update - Turing Clusters

It is noted that time will need to be allocated for learning how to use DeepLabCut. Various youtube tutorials and extensive documentation is provided by the Mathis lab and that has been addressed in the Gantt chart.


### Data Storage
On laptop on device in database 
> how long for statement of withdrawal (in writing) **Please see the attached form (Appendix Item #) for Data Management Plan**
> talk about the DB for remote-VR 

## Measures 

a "run" is the attempt 
- i.e. 110 attempts will output data for 110 runs. The run number is the same as the attempt number. 


--- 
# Research Design


## Pilot Study
> justification for task used 

As we are using a novel paradigm for the assessment of skill learning in VR, a pilot study will be conducted to in order to establish learning rates at the task and inform experimental design, sample size, and statistical analyses (ie. skew, kurtosis, variance).

> specific questions

**The core questions for the pilot study are:**

#### How the task is learnt. 

Different sensorimotor tasks exhibit different learning rates and plateaus (citation, citation). The length of training required for the task will better inform our study design as well as give insight into plateaus (which are of particular concern for the training of surgical skills).

#### Effect size

Pilot data will be analysed to assess the observed effect size (if present) which will better inform the sample size needed for recruitment during the full experiments.


> methods

10 participants who are unfamilair with the task or research goals will be recruited and sorted into VR or Natural groups. 

Each participant will complete one 25 minute session every second day  for 4 weeks (13 total sessions). 



> data outputs 

A Pre-session questionnaire will 

1) capture the task start time 
    - participants will be asked (to the best of their ability) complete the task in a similar time of the day (early morning 6-8, mid-morning 9-11, midday 12-1, afternoon 2-4, early evening 5-7, evening 8-10), 

2) provide information about cognitive state as impaired states will affect study results. Questions may include 
    - on a scale of 1-5 how awake do you feel 
    - do you currently feel rushed 
    - do you feel prepared to practice the task 

Performance on the task will be measured by a subset of the avalible measures. This is because our key question centers around how long it takes to acquire the skill and overall task improvement. These will be measured by number and placement of errors made, time in motion (ball) and placement of rest points (when a participant uses a wall and does not move the ball), total attempts made, number and time of successful completitions (relative to start and relative to run). 

A Post-session questionaire will capture information on 
- percieved performance
    - as reported by a qualitatively assessed question (eg. "how did you feel that went?")
    - did you try something different to last session to solve the maze 
    - did you have a strategy for how to perform the task 
- an adapted SSQ scale given to participants in the VR condition



## Study 1

#### specific questions addressed
Study 1 will address the effect of training medium on skill acquisition and subsequent ToL by comparing changes in participants’ performance across time as they test and/or train in either VR or Natural.

It will form the ‘backbone’ of the thesis and the data collected in Study 1 will be used in all subsequent analyses. 


#### justification for task used

> Study 1 will provide insight into the effect training medium has on skill acquisition and if the skill taught in VR affects task performance in the real world 

```
IF RYAN PROVIDES INFO THEN THIS IS WHERE WE CHANGE THINGS
```


### Methods

#### Participants 
Based on the effect size indicated from pilot data, 80-120 participants will be recruited and randomly sorted into 4 matched groups. Groups A and D will serve as control conditions, and Groups B and C are switch groups. 

> group design
![](https://i.imgur.com/z7NBgoh.png)

Groups A and D will be used to establish how subjects learn the task (Research Question 1), Group B and C are "transfer of learning" groups where they learn in one medium (VR or Natural) and are tested in the other. This will address Research Question 2. 

#### Study Design 

Sessions will take place spaced no fewer than 1 and no more than 2 days apart. 
> do I need to add justification for this? 


Participants will stand holding the apparatus at a self-guided height while guiding a ball bearing around a trap maze by tilting a box. In the Natural setting, the maze will be held at opposing vertical sides of the box via Oculus controllers affixed to the box.

In the VR setting, a wooden separator of the same dimensions and weight (+-10%) with slots will be used to hold the controllers in orientation.

Each session will last for no more than 24 minutes which is the recommended time to reduce fatigue caused by ergonomic load from the Quest (citation), and simulator sickness (citation). 

All participants in VR groups will complete Oculus’ “First Encounter” in order to familiarize subjects with a VRE and the controls at the first session. 


#### data outputs

Data will be excluded if participants employed a 'task hack' such as jolting the apparatus in order to make the ball jump over a hole, if the task was practiced outside of the experimental setting, and if participants engaged in substance use during the experiment. 

The Pre-session questionnaire will assess factors that may impair performance (such as sleep quality and mental status). 

#### Task Performance Data

Quantitative measures collected will include number of attempts (successful, total number, and time) as well as run specific data such as the number of errors (as defined by the ball falling in one of the trap holes), ball tracking (location, acceleration, velocity, and path taken), controller tracking (orientation represented by x,y,z data taken continuously across task, and at error) and the location of errors.

The ball movement tracking will support investigation into the path taken, velocity and acceleration, and ‘rests’ (ie. a participant uses a mazewall to rest the ball against before moving) which will provide data on rests taken, total rest time, and location of rests. In VR these measures will be collected via software variables (Unity), whereas DeepLabCut will be used to processes Natural data. 

A Post-experiment questionnaire will include measures of presence, immersion, simulator sickness (Kennedy et. al., 1993), and perceived improvement rating. In addition, participants in Group B and C will be asked if they noticed any differences between the VRE and Natural in order to collect qualitative information. 

Study 1 investigated ToL between a replicated “lab” environment in VR and the real-world lab wherein both the VR and Natural conditions take place in a physical lab space.
Study 2 and 3 will deliver the “VR lab” to participants outside of the lab setting to investigate the impact location/context has on transfer. 
- as opposed to a VR lab co-located with the physical lab

Study 2 & 3 are proposed to investigate the impact context (specicially the environment) has on skill acquisition and ToL. Both studies use VR mediums to train participants. 

Study 2 focuses on how training outside of a lab (aka. remote-VR) impacts skill acquisition and transfer, and Study 3 examines the effects of testing in remote-VR. 

> why this is important 

```
Study 2 & 3
```

## Study 2 


> specific questions addressed

Study 2 assesses the impact remote-VR training has on performance and transfer of learning (Research Questions 3 & 4). 

### Methods

#### Participants 

40-60 participants will be recruited and  sorted into 2 matched groups. Participants will train in VR remotely and be assessed in-lab in either the VR or Natural condition. Group E will test in Natural, Group F will test in the lab in VR (in-lab-VR). 

![](https://i.imgur.com/iBFCT7d.png)

#### Remote Sessions 
remote-VR participants will be sent a weblink to their Pre-session and Post-session questionnaires to fill out no greater than 15minutes prior (for pre-session) and 15minutes after (for post-session) their experiment session. This will be logged through the updating of the database which will timestamp session start and end. 

Study design will follow Study 1's procedure with the exception of remote-VR participants recieving the wooden separator by mail. 

A "Get Started" manual will be sent to all remote participants containing information and resources on how to set up the VR device, how to start the experiment, how to report hardware or software failures. 


> data outputs

All measures from Study 1 will also be collected in Study 2 with further additions of qualitative survey questions aimed at assessing the percieved differences between training in VR and testing in the lab (on either medium). 

remote-VR data will be collected using UXF (Brookes et al., 2020), a Unity package developed for the collection of data for psychology experiments, and stored in a secure Data Store as per University of Leeds guidelines. 

> justification for task used

The results from Study 2 will give insight into how training a skill in VR outside-the-lab affects the transfer of that skill to the real world, as well as insight into the impact context has on skill learning and transfer. Both these insights have implications for VR’s use in rehabilitation (citation, citation), and the future of training as ‘remote’ training - if supported - would allow for distributed training and remote 



## Study 3
While Study 2 examines the effect that remote training has on skill acquisition and ToL, the participants of Study 2  return to the physical lab environment to test. In order to fully assess the effect that context has, Study 3 assesses if being in remote VR for the test sessions influences any observed ToL.

> specific questions addressed

Study 3 will directly compare VR settings (either at home or in the lab) for their impact on task performance and transfer of learning. 

### Methods
40-60 participants will be recruited and  sorted into 2 matched groups. Participants will either train in remote-VR or train in-lab-VR. All participants will perform the tests in-lab-VR. Group G will train in-lab-VR, Group H will train in remote-VR.

![](https://i.imgur.com/wQiEXPx.png)

> data outputs

Data ouputs will be the same as Study 1 and Study 2 with the substitution of "percieved impact training medium had on your performance" for "percieved impact testing medium had on performance".
> note: these are hypothetical questions as final versions of the Questionnaires have not been determined.  


> Justification for task used

VR has been adopted by the psychology field for its ability to simulate a ‘real world’ environment such as pedestrian crossings and forest fires (****). Published VR experiments on sensorimotor skill learning have been conducted in museums, shopping malls, and using stalls set up in the thoroughfare of a festival (****), however it has not been investigated (to our knowledge) if data gained outside the lab is different to the results seen ‘in-lab’. Study 3 builds from Study 2 and compares in-lab and remote VR conditions. 

---

## Study 4 
:warning: TODO :warning: [link to draft](https://hackmd.io/PCFnBLWrSBaNeu4BdVmBRg?edit)

> specific questions addressed

Study 4 aims to address 

It is currently unknown how VR training will affect the retention of acquired skills.

- this wil address Research Question 5 

> justification for task used


### Methods 

1. To assess the impact training medium has on skill retention.
    * subjects from Study 1 will be asked to complete a single follow up 4 weeks after their final session and will be sorted into two groups based on task medium (VR or Natural.) Depending on recruitment each group with have matched representation of their Study 1 groups (i.e. 50% of respondents that received training in a VR group in Study 1 in VR will complete Study 4 in VR and 50% in Natural).
2. To assess the impact training medium has on skill resilience
    * They will complete 2 blocks, the first on something they recognize and the second on one they don’t.
    * Same training maze
    * Different testing maze
 

> data outputs 

---

## Study 5 
:warning: TODO :warning: [link to draft](https://hackmd.io/650yJfJeRZGQ2SC_vF9cVA?edit)


Study 5 is an analyses on data collected across Study 1-4 in order to address **Research Question 7 and 8.** 

**- specific questions addressed**

Habituation: assess impact VR XP has on task performance

> is there a relationship between XP and performance? 
> analysis of collected data from studies 1, 2, and 3.

**- justification for task used**


**- methods**
Matched groups were designed based on data collected from the Screening survey.
This included previous experience with VR as a measure of hours a (continuous variable) and a self reported nomial varible ranging from "no experience", "novice", "very experienced", to "VR expert". 



**- data outputs**

---


# Study Analyses 

The following section will refer to studies, research questions, and hypotheses by their assigned number. 
- Studies are denoted as Study N (N being 1...5), Reseach Questions as RQ N (N being 1...8), Hypotheses as Hypothesis N (N being 1...x)
> update this once I've finished writing the hypotheses out 

## Global Measures 

Initial descriptive statistics will be used to give insight into the skew, kurtosis, and variance of the collected data. 

### Task performance
A Welch t-test will be used to assess the variance between groups.

Starting point 
- to assess if the task was of matched difficulty 
- to assess if the groups started at the same level 

### Task improvement 

Group-wise analyses will be performed to assess the average improvement across the sessions for each condition. 

Task improvement has ** corresponding measures 

- Error reduction across sessions



### Learning Curve 

:warning: The rate of improvement can be understood as the learning curve :warning: 
 
Graphical analysis will be used to assess learning curve (Ramsay, et al., 2001) using regression analyses. Once data has been collected, a regression may not model the data well. If this is the case then an ‘analysis of best fit’ will be used where stepwise and exponentials models may be compared for goodness of fit against traditional regression models. 

### Transfer of Learning

RQ 2, RQ 4, and RQ 8 address the transfer of learning from one context to the other. 


## Specific Research Questions


A Welch t-test will be used to assess the variance between groups. 
* Bayes factor (evidence favors the alt vs evidence favors the null) 


**Research Question 6** (the effect of training medium on skill acquisition) will be answered through analyses of data from Studies 1-4 

---


# Predicted Outcomes 

> do I restate the hypotheses again here with some of what we expect to happen? 
[draft 1](https://hackmd.io/NPKKtgF6Tq-DzRzyQbolAw?both)
[draft 2](https://hackmd.io/NPKKtgF6Tq-DzRzyQbolAw?both)

---


# Barriers to Data Collection
> to outline the barriers to data collection and to indicate that you have thought out the feasibility of the proposed plan to outline how I plan to execute on this plan

It is important to address the risks and barriers associated with a project that proposes the collection of new data. The following section details the barriers this project may face as well as the plans to mitigate identified risks. > Equipment (e.g. hardware and software), COVID-19 planning (risk assessment and contingency plans), Resource Allocation (time, compensation, ) Data Collection Barriers,


### Equipment
There are several concerns when using hardware and software - Project feasibility and risk mitigation has been informed by a duFMEA (Stamatis, 2003) (appendix ***) - such as failure in tracking (Deutsch et al., 2011) - Deutsch, J. E., Brettler, A., Smith, C., Welsh, J., John, R., Guarrera-Bowlby, P., et al. (2011). Nintendo Wii sports and Wii fi t game analysis, validation, and application to stroke rehabilitation. Topics in Stroke Rehabilitation, 18 (6), 701–719.



### Experimental Design
> novel experiment (construct validity) Note: it will be critical to control variables ie. errors should not be coming from person, should be coming from the medium

This is not a mechanistic study in that it does not give insight into why. 



* I could just change it to a sandbox, but does the center out sandbox tell you why? 

In addition to the above methodological design, it is important to address attrition rates when proposing multi-session human experimentation.

To mitigate the risk of participants forgetting session sign up email reminders will be sent the day before, morning of, and an hour prior.

In accordance with GDPR, permission will be requested for email contact of the participants. These email records will be stored for either 3 years, or until the completion of this student’s PhD (whichever happens first).

If the participant does not wish for their email to be used, a confirmation of session time with be given verbally and in writing to the participant at the conclusion of each session - e.g. “Your next session is Tuesday, the 31st of August at 8am.”

As discussed in Section *** the estimated participant recruiment minimum to see an effect is ** (maybe 15). - Budgeting for attrition rates during recruitment (ie. recruiting more participants than needed to meet the minimum sample size to find an effect)

    
### Task Choice / Engagement
* A maze provides engagement, difficult but solvable with a defined goal (good for ‘flow’ (citation, citation)

Historically based motor learning tasks (such as cursor representation during a center-out-reach) have been used to examine motor learning strategies in VR (citation, citation, citation) and it is apparent from systematic literature reviews that there is a need for methodical rigor in this field (smith, motor, levac, m-thingy, mine, citation). Traditional reach experiments used by citation, citation, citation would not win in a war of attrition. 
- Bryanton et al, 2006 gamified VR for motor rehab at home 
- children with CP

Resources (building space, headsets from where, hardware from where) 

Compensation for Participation 
- RPP 
- Monetary compensation based on time spent at standard rate 
- time

Analyses over the compared “best path” would need to be gained using methods such as Control Theory
* currently outside of scope  


### Resource Allocation
The time and resources required to complete the proposed experiments is the greatest feasibility concern > Use this section to reiterate the need for insight into feasibility of remote data collection for VR research (which will reduce hours spent in lab testing) > time estimation

### COVID-19 
> put covid statement back in 
> following SOP's 


# Discussion
[Dalgarno & Lee, 2009](https://scite.ai/reports/what-are-the-learning-affordances-4wWDGa)

Previous studies have assessed the TPK that VR offers VR may be better suited to learning because it does

A larger discussion of these will be explored in the dissertation 

What is needed to learn a skill

Is it logical to assume that we would acquire skills using the same mechanisms, or is it inane to assume such owing to the fact that virtual reality is not, in fact, reality 


## Implications


* using marble maze (this task) for ML robotic motor learning
* fills in gaps
* supports so much future work in VR
* knowing what the differences are between VR in lab and remote

#### remote research


* can we substitute lab for remote
    * can we collect data remotely
* back inference
    * if VR remote is different using VR in lab to study real world behaviours is moot (ie. cannot support the ‘ecological validity’ claim that VR has)
* impact context/environment has on ToL
    * important for rehabilitation


# Gantt Chart

![](https://i.imgur.com/UvHyXNI.png)



# Training Plan
