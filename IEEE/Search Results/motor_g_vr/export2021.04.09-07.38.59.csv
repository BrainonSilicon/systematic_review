"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"See-through window vs. magic mirror: A comparison in supporting visual-motor tasks","Zhen Bai; A. F. Blackwell","University of Cambridge, UK; University of Cambridge, UK","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","239","240","There are two alternative display metaphors for Augmented Reality (AR) screens: a see-through window or a magic mirror. Commonly used by task-support AR applications, the see-through display has not been compared with the mirror display in terms of user's task performance, even though the “mirror” hardware is more accessible to general users. We conducted a novel experiment to compare participants' performance when following object rotation cues with the two display metaphors. Results show that participants' overall performance under the mirror view was comparable to the see-through view, which indicates that the augmented mirror display may be a promising alternative to the window display for AR applications which guide moderately complex three-dimensional manipulations with physical objects.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671784","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671784","Augmented Reality;display metaphor;visual-motor","Mirrors;Cameras;Monitoring;Face;Augmented reality;Educational institutions;Three-dimensional displays","augmented reality;computer displays;mirrors","see-through window;magic mirror;visual-motor tasks;display metaphors;augmented reality screens;AR screens;task-support AR applications;see-through display;augmented mirror display;three-dimensional manipulations;physical objects","","1","","4","","23 Dec 2013","","","IEEE","IEEE Conferences"
"New applications of multimodal human-computer interfaces","A. Czyżewski","Gdansk University of Technology, Multimedia Systems Department 80-233 Gdansk, Poland, ul. Narutowicza 11/12","2012 Joint Conference New Trends In Audio & Video And Signal Processing: Algorithms, Architectures, Arrangements And Applications (NTAV/SPA)","16 Apr 2015","2012","","","19","24","Multimodal computer interfaces and examples of their applications to education software and for the disabled people are presented. The proposed interfaces include the interactive electronic whiteboard based on video image analysis, application for controlling computers with gestures and the audio interface for speech stretching for hearing impaired and stuttering people. Application of the eye-gaze tracking system to awareness evaluation is demonstrated. The proposed method assumes analysis of visual activity of patients remaining in vegetative state. The scent emitting multimo-dal computer interface is an important supplement of the polysen-soric stimulation process, playing an essential role in education and therapy of children with developmental disorders. A new approach to diagnosing Parkinson's disease is shown. The progression of the disease can be measured by the UPDRS (Unified Parkinson Disease Rating Scale) scale which is used for evaluating motor and behavioral symptoms of Parkinson's disease, employing the multimo-dal interface called Virtual-Touchpad (VTP) to support medical diagnosis. The paper is concluded with some general remarks concerning the role of multimodal computer interfaces applied to learning, therapy and everyday usage of computerized devices.","2326-0319","978-8-3620-6514-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7085506","multimodal interfaces;video processing;speech processing","Speech;Streaming media;Auditory system;Cameras;Signal processing algorithms;Algorithm design and analysis;Training","computer aided instruction;diseases;gaze tracking;gesture recognition;handicapped aids;human computer interaction;interactive systems;medical diagnostic computing;medical disorders;patient diagnosis;speech-based user interfaces;touch sensitive screens;video signal processing","scent emitting multimodal human-computer interfaces;education software;disabled people;interactive electronic whiteboard;video image analysis;audio interface;gestures;speech stretching;hearing impaired people;stuttering people;eye-gaze tracking system;awareness evaluation;visual activity analysis;vegetative state;polysensoric stimulation process;developmental disorders;Parkinson's disease diagnosis;UPDRS scale;unified Parkinson disease rating scale;motor symptoms;behavioral symptoms;virtual-touchpad;VTP;medical diagnosis;computerized devices","","","","9","","16 Apr 2015","","","IEEE","IEEE Conferences"
"Wearable tactile device using mechanical and electrical stimulation for fingertip interaction with virtual world","V. Yem; H. Kajimoto","The University of Electro-Communications, Tokyo, Japan; The University of Electro-Communications, Tokyo, Japan","2017 IEEE Virtual Reality (VR)","6 Apr 2017","2017","","","99","104","We developed “Finger Glove for Augmented Reality” (FinGAR), which combines electrical and mechanical stimulation to selectively stimulate skin sensory mechanoreceptors and provide tactile feedback of virtual objects. A DC motor provides high-frequency vibration and shear deformation to the whole finger, and an array of electrodes provide pressure and low-frequency vibration with high spatial resolution. FinGAR devices are attached to the thumb, index finger and middle finger. It is lightweight, simple in mechanism, easy to wear, and does not disturb the natural movements of the hand. All of these attributes are necessary for a general-purpose virtual reality system. User study was conducted to evaluate its ability to reproduce sensations of four tactile dimensions: macro roughness, friction, fine roughness and hardness. Result indicated that skin deformation and cathodic stimulation affect macro roughness and hardness, whereas high-frequency vibration and anodic stimulation affect friction and fine roughness.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892236","FinGAR;mechanical stimulation;electrical stimulation;virtual touch","Vibrations;Thumb;Skin;Electrodes;DC motors;Electrical stimulation","augmented reality;data gloves;DC motors;haptic interfaces;shear deformation;vibrations","wearable tactile device;electrical stimulation;mechanical stimulation;virtual world;fingertip interaction;finger glove for augmented reality;skin sensory mechanoreceptors;tactile feedback;virtual objects;DC motor;high-frequency vibration;shear deformation;electrode array;low-frequency vibration;high spatial resolution;FinGAR devices;general-purpose virtual reality system;tactile dimensions;macro roughness;friction;fine roughness;hardness;anodic stimulation","","33","","34","","6 Apr 2017","","","IEEE","IEEE Conferences"
"Cellphone Augmented Reality Game-based Rehabilitation for Improving Motor Function and Mental State after Stroke","X. Song; L. Ding; J. Zhao; J. Jia; P. Shull","State Key Laboratory of Mechanical System and Vibration, Shanghai Jiaotong University, Shanghai, China; Department of Rehabilitation Medicine, Huashan Hospital, Fudan University, Shanghai, China; Nanjing University of Chinese Medicine, Nanjing, China; Department of Rehabilitation Medicine, Huashan Hospital, Fudan University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiaotong University, Shanghai, China","2019 IEEE 16th International Conference on Wearable and Implantable Body Sensor Networks (BSN)","25 Jul 2019","2019","","","1","4","Effective stroke rehabilitation typically involves improving both motor function and mental state. Traditional rehabilitation systems are generally expensive, not portable and difficult to operate. As a first step toward overcoming these existing shortcomings, we developed a cellphone augmented reality (AR) rehabilitation system for stroke rehabilitation. Three serious games for upper limb motor function and cognitive training were developed in which patients move their arms to touch virtual targets generated in the three-dimensional AR environment. Patients received visual and vibration feedback after successfully touching each target. Eight stroke patients with upper limb dysfunction performed pilot validation testing with the cellphone AR system. Motor function performance was evaluated based on performance in the AR games and mental state was evaluated via questionnaires self-reporting various aspects of mental state. Results showed that motor performance improved by the last trial as compared to the first trial (p<;0.05). In addition, the majority of patients reported that they felt `relaxed' and `happy' while playing the AR rehabilitation games. These results demonstrate the potential of cellphone AR rehabilitation to improve upper-limb motor function and mental state for stroke patients and lay a foundation for a future home-based rehabilitation paradigm.","2376-8894","978-1-5386-7477-2","10.1109/BSN.2019.8771093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8771093","stroke;upper-limb rehabilitation;mental state;cellphone;serious AR games","Games;Stroke (medical condition);Training;Robot sensing systems;Hospitals;Color","augmented reality;biomechanics;computer games;feedback;medical robotics;neurophysiology;patient rehabilitation;patient treatment","motor function performance;mental state;motor performance;AR rehabilitation games;upper-limb motor function;stroke patients;future home-based rehabilitation paradigm;reality game-based rehabilitation;effective stroke rehabilitation;traditional rehabilitation systems;cellphone augmented reality rehabilitation system;serious games;upper limb motor function;upper limb dysfunction performed pilot validation testing","","2","","24","","25 Jul 2019","","","IEEE","IEEE Conferences"
"Visuo-motor tracking with coordinated wrist movements under different combinations of visual and kinesthetic disturbances","L. Masia; V. Squeri; M. Casadio; P. Morasso; V. Sanguineti; G. Sandini","Robotics Brain and Cognitive Sciences, Italian Institute of Technology, Genoa, Italy; Robotics Brain and Cognitive Sciences, Italian Institute of Technology, Genoa, Italy; Department of Informatics, Systems and Telecommunications, University of Genoa, Italy; Department of Informatics, Systems and Telecommunications, University of Genoa, Italy; Robotics Brain and Cognitive Sciences, Italian Institute of Technology, Genoa, Italy; Robotics Brain and Cognitive Sciences, Italian Institute of Technology, Genoa, Italy","2009 2nd Conference on Human System Interactions","23 Jun 2009","2009","","","715","718","This study addresses a major problem in the design of HCI (human-computer interface) systems: how to avoid or reduce the long learning/adaptation process and the corresponding attentional load of the underlying hand-eye coordination task that frequently affects HCI systems. In particular, we considered a 2D tracking task with two degrees of freedom of the wrist to a visual target whose frame of reference was rotated with respect to a body-fixed frame in a time varying manner. We investigated it by means of a wrist robot coupled with a virtual reality system. The experimental protocol consisted of applying kinesthetic and visual disturbances in a unimodal or bimodal manner and observing the tracking performance. The kinesthetic disturbance was provided by passively rotating the forearm of the subjects by the third degree of freedom of the wrist robot, while the visual disturbance was provided by rotating the visual scene. The results suggest that the combination of a suitable proprioceptive feedback with the kinematic redundancy of the HCI system might be a rather general principle for improving the efficiency of HCI systems.","2158-2254","978-1-4244-3959-1","10.1109/HSI.2009.5091065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5091065","wrist robot;visuo-proprioceptive disturbance;tracking;virtual reality","Tracking;Wrist;Robot kinematics;Human computer interaction;Motor drives;Mice;Virtual reality;Brushes;Cognitive robotics;Informatics","control engineering computing;human computer interaction;robots;virtual reality","visuomotor tracking;coordinated wrist movements;visual-kinesthetic disturbances;human-computer interface;learning-adaptation process;hand-eye coordination task;virtual reality system;kinematic redundancy","","1","","12","","23 Jun 2009","","","IEEE","IEEE Conferences"
"Elucidating Factors that can Facilitate Veridical Spatial Perception in Immersive Virtual Environments","W. B. Thompson; J. E. Swan; D. Proffitt; J. K. Kearney; V. Interrante; W. B. Thompson; J. E. Swan; D. Proffitt; J. K. Kearney; V. Interrante","NA; NA; NA; NA; Minnesota Univ., MN; NA; NA; NA; NA; Minnesota Univ., MN","2007 IEEE Virtual Reality Conference","23 Apr 2007","2007","","","11","18","Enabling veridical spatial perception in immersive virtual environments (IVEs) is an important yet elusive goal, as even the factors implicated in the often-reported phenomenon of apparent distance compression in HMD-based IVEs have yet to be satisfactorily elucidated. In recent experiments (Interrante et al., 2006), we have found that participants appear less prone to significantly underestimate egocentric distances in HMD-based IVEs, relative to in the real world, in the special case that they unambiguously know, through first-hand observation, that the presented virtual environment is a high fidelity 3D model of their concurrently occupied real environment. We had hypothesized that this increased veridicality might be due to participants having a stronger sensation of 'presence' in the IVE under these conditions of co-location, which state of mind leads them to act on their visual input in the IVE similarly as they would in the real world (the presence hypothesis). However, alternative hypotheses are also possible. Primary among these is the visual calibration hypothesis: participants could be relying on metric information gleaned from their exposure to the real environment to calibrate their judgments of sizes and distances in the matched virtual environment. It is important to disambiguate between the presence and visual calibration hypotheses because they suggest different directions for efforts to facilitate veridical distance perception in general (non-co-located) IVEs. In this paper, we present the results of an experiment that seeks novel insight into this question. Using a mixed within- and between-subjects design, we compare participants' relative ability to accurately estimate egocentric distances in three different virtual environment models: one that is an identical match to the occupied real environment; one in which each of the walls in our virtual room model has been surreptitiously moved ~10% inward towards the center of the room; and one in which each of the walls has been surreptitiously moved ~10% outwards from the center of the room. If the visual calibration hypothesis holds, then we should expect to see a degradation in the accuracy of peoples' distance judgments in the surreptitiously modified models, manifested as an underestimation of distances when the IVE is actually larger than the real room and as an overestimation of distances when the IVE is smaller. However, what we found is that distances were significantly underestimated in the virtual environment relative to in the real world in each of the surreptitiously modified room environments, while remaining reasonably accurate (consistent with our previous findings) in the case of the faithfully size-matched room environment. In a post-test survey, participants in each of the three room size conditions reported equivalent subjective levels of presence and did not indicate any overt awareness of the room size manipulation","2375-5334","1-4244-0905-5","10.1109/VR.2007.352458","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4161000","egocentric distance perception;immersive virtual environments","Virtual environment;Calibration;Computer graphics;Displays;Computer science;Computer architecture;Degradation;Chromium;Virtual reality;USA Councils","augmented reality;computer graphics;visual perception","spatial perception;immersive virtual environments;human perception;3D spatial relationships;augmented reality;optical-motor information;ocular-motor information","","19","","13","","23 Apr 2007","","","IEEE","IEEE Conferences"
"An innovative augmented reality educational framework with gamification to assist the learning process of children with intellectual disabilities","R. Colpani; M. R. Petrucelli Homem","Department of Science Computer, Federal University of São Carlos - UFSCar, Sorocaba, Brazil; Department of Science Computer, Federal University of São Carlos - UFSCar, São Carlos, Brazil","2015 6th International Conference on Information, Intelligence, Systems and Applications (IISA)","21 Jan 2016","2015","","","1","6","Currently, several studies are making use of multimedia systems, and Virtual Reality (VR) technology has been applied to people with special needs. However, its main limitations are the need for qualified human resources and the high costs. On the other hand, Augmented Reality (AR) technology has been increasing and it has become more and more popular because of its specificities. However, most studies involving these technologies are focused on the treatment of people with motor disabilities. Thus, this paper presents a proposal of an AR framework with gamification to assist the learning process of children with intellectual disabilities in general. Finally, the study will present some ways on how teachers might work some concepts and cognitive skills on children with intellectual disabilities with the aid of the framework.","","978-1-4673-9311-9","10.1109/IISA.2015.7387964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7387964","Augmented Reality;Gamification;Intellectual Disability","Games;Animals;Computers;Software;Augmented reality;Education;Three-dimensional displays","augmented reality;computer aided instruction;computer games;handicapped aids;multimedia systems","innovative augmented reality educational framework;gamification;learning process;children;intellectual disabilities;multimedia systems;VR technology","","7","","18","","21 Jan 2016","","","IEEE","IEEE Conferences"
"Toward memory-based human motion simulation: development and validation of a motion modification algorithm","Woojin Park; D. B. Chaffin; B. J. Martin","Dept. of Mech., Univ. of Cincinnati, OH, USA; NA; NA","IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans","19 Apr 2004","2004","34","3","376","386","Computer simulation of human motions helps test hypotheses on human motion planning and fosters timely and high-quality human-machine/environment interaction design. The current study introduces a novel simulation approach termed memory-based motion simulation (MBMS), and presents its key element ""motion modification"" (MoM) algorithm. The proposed approach implements a computational model inspired by the generalized motor program (GMP) theory. Operationally, when a novel motion scenario is submitted to the MBMS system, its motion database is searched to find relevant existing motions. The selected motions, referred to as ""root motions"", most likely do not meet exactly the novel motion scenario, and therefore, they need to be modified by the MoM algorithm. This algorithm derives a parametric representation of possible variants of a root motion in a GMP-like manner, and adjusts the parameter values such that the new modified motion satisfies the novel motion scenario, while retaining the root motion's overall angular movement pattern and inter-joint coordination. An evaluation of the prediction capability of the algorithm, using both seated upper body reaching and whole-body load-transfer motions, indicated that the algorithm can accurately predict various human motions with errors comparable to the inherent variability in human motions when repeated under identical task conditions.","1558-2426","","10.1109/TSMCA.2003.822965","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1288349","","Humans;Biological system modeling;Ergonomics;Computational modeling;Predictive models;Testing;Design automation;Man machine systems;Algorithm design and analysis;Prototypes","human computer interaction;ergonomics;digital simulation;motion estimation;CAD","memory-based human motion simulation;motion modification algorithm;computer simulation;human motion planning;human machine interaction;generalized motor program theory;motion database;parametric representation;root motion;angular movement pattern;interjoint coordination;load transfer motions;human motions","","49","2","51","","19 Apr 2004","","","IEEE","IEEE Journals"
"Information Constrained Control Analysis of Eye Gaze Distribution Under Workload","R. M. Hecht; A. B. Hillel; A. Telpaz; O. Tsimhoni; N. Tishby","Rachel and Selim Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem, Israel; Department of Industrial Engineering and Management, Ben-Gurion University of the Negev—Faculty of Engineering Sciences, Beersheba, Israel; Advanced Technical Center Israel, General Motors, Herzliya, Israel; General Motors Technical Center, Warren, MI, USA; Rachel and Selim Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem, Israel","IEEE Transactions on Human-Machine Systems","4 Dec 2019","2019","49","6","474","484","We describe a novel model of human eye gaze behavior under workload, derived from the basic principle of information constrained control. The model assumes two distributions over the visual field: A saliency distribution, which is nongoal oriented, and a reward task-related distribution. The eye gaze behavior is determined by the tradeoff between these two distributions, where the goal is to preserve the task-related constraints, while remaining as close as possible to the saliency distribution representing a comfort zone. Based on minimum Kullback-Liebler divergence principles, the model gives rise to a family of gaze distributions controlled by a single tradeoff parameter. The model was evaluated experimentally in a driving simulator that consisted of an immersive environment with clear tasks and accurate monitoring capabilities. The findings confirm the theoretical predictions with respect to the low rank manifold and order relations in the data. We show that the model can be used to visualize the unknown reward function associated with a task, and predict human workload based on gaze pattern.","2168-2305","","10.1109/THMS.2019.2930996","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8821410","Eye gazing distribution;information constrained control (ICC)","Gaze tracking;Visual systems;Computational modeling;Task analysis;Visualization;Position measurement","control engineering computing;data visualisation;distributed control;human computer interaction;statistical distributions","Kullback-Liebler divergence principles;human eye gaze behavior;visual field;information constrained control","","","","43","IEEE","30 Aug 2019","","","IEEE","IEEE Journals"
"Evaluation of multimodal feedback effects on the time-course of motor learning in multimodal VR platform for rowing training","K. Maria; A. Filippeschi; E. Ruffaldi; Y. Shorr; D. Gopher","Department of Occupational Therapy, University of Haifa, Haifa, Israel; Scuola Superiore Sant'Anna TECIP, Pisa, Italy; Scuola Superiore Sant'Anna TECIP, Pisa, Italy; William Davidson Faculty of Industrial Engineering and Management, Technion, Israel Institute of Technology, Haifa, Israel; William Davidson Faculty of Industrial Engineering and Management, Technion, Israel Institute of Technology, Haifa, Israel","2015 International Conference on Virtual Rehabilitation (ICVR)","17 Dec 2015","2015","","","158","159","This study focused on the benefits of feedback augmentation for multi-session training of a complex motor-cognitive skill of indoor rowing in virtual environment. Specifically, we compared the effectiveness of augmented information feedback provided per training trial either visually, haptically or visual-haptically to the non-augmented condition, where no on-line feedback on task performance was afforded during training sessions. Surprisingly, the non-augmented training group was in general as successful in the long-term learning of a rowing skill as the augmented groups and according to some measures even superior to them. Our results also highlight important differences in the course of learning and skill representation upon different feedback conditions provided during training and may provide useful insights to the optimization for both sport and rehabilitation training protocols in VR.","2331-9569","978-1-4799-8984-3","10.1109/ICVR.2015.7358628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358628","indoor rowing;long-term training;augmented feedback;visual feedback;haptic feedback;motor learning;skill acquisition;VR","","augmented reality;cognition;gait analysis;medical computing;patient rehabilitation;sport","multimodal feedback effects;motor learning time-course;multimodal VR platform;rowing training;feedback augmentation;multisession training;complex motor-cognitive skill;indoor rowing;virtual environment;augmented information feedback;nonaugmented condition;online feedback;task performance;training sessions;nonaugmented training group;long-term learning;rowing skill;skill representation;sport;rehabilitation training protocols","","1","","6","","17 Dec 2015","","","IEEE","IEEE Conferences"
"BCI decoder performance comparison of an LSTM recurrent neural network and a Kalman filter in retrospective simulation","T. Hosman; M. Vilela; D. Milstein; J. N. Kelemen; D. M. Brandman; L. R. Hochberg; J. D. Simeral","School of Engineering and Carney Institute for Brain Science, Brown University, Providence, RI, 02912; School of Engineering and Carney Institute for Brain Science, Brown University, Providence, RI, 02912; Department of Computer Science and Carney Institute for Brain Science, Brown University; Department of Neurology, Massachusetts General Hospital (MGH), Boston, MA; School of Engineering, Brown University; Dept. of VA Med. Ctr., VA Rehabilitation R&D Center for Neurorestoration and Neurotechnology, Providence, RI; Dept. of VA Med. Ctr., VA Rehabilitation R&D Center for Neurorestoration and Neurotechnology, Providence, RI","2019 9th International IEEE/EMBS Conference on Neural Engineering (NER)","20 May 2019","2019","","","1066","1071","Intracortical brain computer interfaces (iBCIs) using linear Kalman decoders have enabled individuals with paralysis to control a computer cursor for continuous point-and-click typing on a virtual keyboard, browsing the internet, and using familiar tablet apps. However, further advances are needed to deliver iBCI-enabled cursor control approaching able-bodied performance. Motivated by recent evidence that nonlinear recurrent neural networks (RNNs) can provide higher performance iBCI cursor control in nonhuman primates (NHPs), we evaluated decoding of intended cursor velocity from human motor cortical signals using a long-short term memory (LSTM) RNN trained across multiple days of multi-electrode recordings. Running simulations with previously recorded intracortical signals from three BrainGate iBCI trial participants, we demonstrate an RNN that can substantially increase bits-per-second metric in a high-speed cursor-based target selection task as well as a challenging small-target high-accuracy task when compared to a Kalman decoder. These results indicate that RNN decoding applied to human intracortical signals could achieve substantial performance advances in continuous 2-D cursor control and motivate a real-time RNN implementation for online evaluation by individuals with tetraplegia.","1948-3554","978-1-5386-7921-0","10.1109/NER.2019.8717140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8717140","","Decoding;Task analysis;Kalman filters;Recurrent neural networks;Bit rate;Data models;Brain modeling","biomedical electrodes;brain;brain-computer interfaces;decoding;handicapped aids;human computer interaction;Kalman filters;medical signal processing;neural nets;neurocontrollers;neurophysiology;recurrent neural nets","retrospective simulation;intracortical brain computer interfaces;linear Kalman decoders;computer cursor;continuous point;virtual keyboard;familiar tablet apps;cursor control;able-bodied performance;nonlinear recurrent neural networks;higher performance;intended cursor velocity;human motor cortical signals;long-short term memory RNN;multielectrode recordings;recorded intracortical signals;BrainGate iBCI trial participants;high-speed cursor-based target selection task;challenging small-target high-accuracy task;Kalman decoder;human intracortical signals;substantial performance advances;BCI decoder performance comparison;LSTM recurrent neural network;Kalman filter","","3","","31","","20 May 2019","","","IEEE","IEEE Conferences"
"ARBlocks: A projective augmented reality platform for educational activities","R. A. Roberto; V. Teichrieb","Voxar Labs, Informatics Center, Federal University of Pernambuco; Voxar Labs, Informatics Center, Federal University of Pernambuco","2012 IEEE Virtual Reality Workshops (VRW)","12 Apr 2012","2012","","","175","176","This demonstration will allow visitors to use different applications builded for the ARBlocks, a dynamic blocks platform based on projective augmented reality and tangible user interfaces aiming early childhood educational activities. Those applications, along with the platform itself, were designed to be useful tools for educators to teach general subjects for children, such as mathematical and language skills, as well as develop important abilities, like motor coordination and collaboration.","2375-5334","978-1-4673-1246-2","10.1109/VR.2012.6180937","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180937","augmented reality;education;tangible user interface","Augmented reality;Education;Laboratories;Data visualization;Games","augmented reality;computer aided instruction;teaching;user interfaces","ARBlocks;projective augmented reality platform;dynamic blocks platform;tangible user interfaces;early childhood educational activities;general subject teaching;mathematical skills;language skills;motor coordination;motor collaboration","","3","","6","","12 Apr 2012","","","IEEE","IEEE Conferences"
"Effects of an in-car augmented reality system on improving safety of younger and older drivers","Wai-Tat Fu; J. Gasper; S. Kim","Beckman Institute of Science and Technology, University of Illinois at Urbana-Champaign, USA; Beckman Institute of Science and Technology, University of Illinois at Urbana-Champaign, USA; Beckman Institute of Science and Technology, University of Illinois at Urbana-Champaign, USA","2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","23 Dec 2013","2013","","","59","66","We designed and tested the effects of an in-car augmented reality system (ARS) on younger and older drivers, with and without a secondary distraction task. When potential danger is detected, the ARS alerts the driver by progressively indicating the time to collision to the lead vehicle as well as merging vehicles from side lanes by an AR display that overlaps with the lead or merging vehicles. We tested the ARS with younger (18-30) and older (65-75) drivers in a high-fidelity driving simulator. Results showed that the ARS could significantly reduce collisions caused by hazard events such as sudden slowing of the lead vehicle or merging of vehicles from sides lanes. Consistent with previous results, older drivers, despite age-related decline in cognitive and motor abilities, could leverage their driving experience to avoid forward collisions with the lead vehicle as much as younger drivers. However, older drivers were poorer in avoiding collisions caused by sudden merging events than younger drivers. The ARS was found to be most useful in helping older adults to avoid collision caused by sudden hazard events, especially with the presence of a distraction task. The ARS was also more effective for older than younger drivers to encourage a safe driving distance with the lead vehicle. Interestingly, there seemed to be differential effects of the ARS on the general driving behavior of younger and older drivers. While older drivers in general became more careful and safer in how they drive with the ARS, younger drivers seemed to rely on the ARS to alert them to potential hazard events without adopting safer driving behavior.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671764","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671764","","Vehicles;Augmented reality;Merging;Hazards;Visualization;Accidents;Analysis of variance","accident prevention;augmented reality;human computer interaction;traffic engineering computing","in-car augmented reality system;younger driver;older driver;distraction task;high-fidelity driving simulator;hazard event;cognitive ability;motor ability;forward collision;driving behavior","","3","","30","","23 Dec 2013","","","IEEE","IEEE Conferences"
"Givs: Fine-Grained Gesture Control for Mobile Devices in Driving Environments","L. Jiang; M. Xia; X. Liu; F. Bai","School of Computer Science, McGill University, Montreal, Canada; School of Computer Science, McGill University, Montreal, Canada; School of Computer Science, McGill University, Montreal, Canada; General Motors Global R&D, Detroit, MI, USA","IEEE Access","17 Mar 2020","2020","8","","49229","49243","New media and communication technologies like mobile devices are nowadays widely used everywhere for providing rich functionalities and highly personalized services. However, using such a device in a driving environment is still very inconvenient and unsafe to be controlled by the driver. The touchscreen operations are one major obstacle since multi-touchscreen is optimized for hand-held usage scenarios. To overcome this limitation, we propose to replace some most used touch operations with gesture controls for mobile devices in a driving environment. Gesture control is simple, more flexible and requires less eye focus, which makes it more suitable for in-vehicle usages. In this paper, we design Givs, a fully functional gesture control system for mobile devices in a driving environment. Givs leverages the latest motion sensing technology to enable ubiquitous and driving-friendly gestures. Compared to other off-the-shelf gesture recognition solutions, Givs is optimized for in-vehicle use cases and is designed to overcome various limitations caused by real driving conditions, including bumpy road conditions, significant noise introduced by car vibration and technical limitations of motion sensors. Our extensive in-vehicle tests and participant experience experiments demonstrate that Givs well assists users in accomplishing various types of tasks and support human-machine interaction in driving environments such as personal vehicle and public transport, with high accuracy and fast responsiveness, while promoting drivnig convenience and safety.","2169-3536","","10.1109/ACCESS.2020.2971849","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8984325","Human-machine interaction;smart sensing;mobile computing;driving safety","Sensors;Motion detection;Mobile handsets;Delays;Hardware;Automobiles;Tracking","gesture recognition;human computer interaction;mobile computing;road vehicles;touch sensitive screens;traffic engineering computing","fine-grained gesture control;mobile devices;driving environment;hand-held usage scenarios;fully functional gesture control system;driving-friendly gestures;off-the-shelf gesture recognition solutions;driving conditions;Givs","","1","","40","CCBY","5 Feb 2020","","","IEEE","IEEE Journals"
"Poster: Improving motor rehabilitation process through a natural interaction based system using Kinect sensor","A. Da Gama; T. Chaves; L. Figueiredo; V. Teichrieb",Voxar Labs at Center of Informatics of the Federal University of Pemambuco; Voxar Labs at Center of Informatics of the Federal University of Pemambuco; Voxar Labs at Center of Informatics of the Federal University of Pemambuco; Voxar Labs at Center of Informatics of the Federal University of Pemambuco,"2012 IEEE Symposium on 3D User Interfaces (3DUI)","19 Apr 2012","2012","","","145","146","In general, the motor rehabilitation process can take advantage of natural interaction based systems, including measurements from patient performance to track its evolution during time and therapy direction. Thus, the aim of this research is the analysis of the use of Kinect sensor as interaction support tool for rehabilitation systems. The Kinect sensor gives three-dimensional information about the user body, recognizing skeleton and joint positions, however does not provide the detection of the body specific movements. This way, the correct description of a rehabilitation movement (shoulder abduction, for instance) was implemented in a system prototype. A scoring mechanism was also developed in order to measure the patient performance, as well as to stimulate his improvement by displaying a positive feedback.","","978-1-4673-1205-9","10.1109/3DUI.2012.6184203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6184203","Rehabilitation;Natural Interaction;Body Tracking;Kinect","Prototypes;Vectors;Medical treatment;Elbow;Shoulder;Virtual reality;Usability","human computer interaction;patient rehabilitation;user interfaces","motor rehabilitation process;natural interaction based system;patient performance;therapy direction;Kinect sensor;skeleton positions;joint positions;system prototype;scoring mechanism","","30","","5","","19 Apr 2012","","","IEEE","IEEE Conferences"
"Depth Perception and Action in Wearable Augmented Reality: A Pilot Study","S. Baldassi",NA,"2015 IEEE International Symposium on Mixed and Augmented Reality Workshops","3 Dec 2015","2015","","","12","14","Wearable Augmented Reality (AR) is arguably closing the gaps of interaction of user with computers, and computers with the real world. This generates a strong need to understand the neural, cognitive and perceptual mechanisms leveraged by this technology. Because the most advanced wearable AR technologies support gestural interaction with real content, in our study we exploit the well known dissociation between vision-for-perception and vision-for-action to understand how the user's cognitive systems encode the AR space, to introduce novel methodologies to support UI design in AR, and to provide general guidelines for designing visual and interactive spaces in AR. In two experiments we find a dissociation between visual-only estimates of depth and motor finger-reaching to similar elements, supporting the idea that AR space leverages similar mechanisms as the real world, and can be designed accordingly.","","978-1-4673-8471-1","10.1109/ISMARW.2015.12","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344748","Mixed/Augmented Reality;Psychophysics;Depth Perception;Gestural Interactions","Visualization;Sensitivity;Three-dimensional displays;Context;Yttrium;Augmented reality;Presses","augmented reality;cognitive systems;gesture recognition;wearable computers","depth perception;wearable augmented reality;AR;user interaction;neural mechanisms;cognitive mechanisms;perceptual mechanisms;gestural interaction;vision-for-perception;vision-for-action;UI design","","","","5","","3 Dec 2015","","","IEEE","IEEE Conferences"
"Design Recommendations for Augmented Reality Games for Objective Assessment of Upper Extremity Motor Dysfunction","M. A. Cidota; P. J. M. Bank; S. G. Lukosch","Faculty of Mathematics and Computer Science, University of Bucharest, Romania; Leiden University Medical Center, The Netherlands; Faculty of Technology, Policy and Management, Delft University of Technology, The Netherlands","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1430","1438","In clinical practice, objective and quantitative assessment of motor dysfunction is required for monitoring disease progression over time and evaluating response to therapeutic interventions. Thereby, clinicians typically want their patients to make movements to their full physical potential. Augmented reality (AR) games using 3D hand and body tracking that engage patients, could motivate them to perform repetitive tasks to the limit of their physical capabilities in a safe environment. This paper reports on different AR games developed for objective upper extremity motor dysfunction assessment of Parkinson's Disease (PD) patients and stroke patients. Quantitative and qualitative evaluations of various user studies involving 23 PD patients, 22 stroke patients and 39 healthy persons are discussed to make design recommendations for designing engaging AR games for objective assessment of upper extremity motor dysfunction.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797729","Augmented reality;engagement;games design;motor function assessment;PD;stroke;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, augmented and virtual realities;K.8.0 [Personal Computing]: General—Games;J.3 [Life and Medical Sciences]: Health","Games;Task analysis;Extremities;Visualization;Three-dimensional displays;Usability;Augmented reality","augmented reality;biomechanics;computer games;diseases;medical computing;medical disorders;neurophysiology;patient diagnosis;patient rehabilitation","stroke patients;Parkinson's disease patients;objective upper extremity motor dysfunction assessment;body tracking;physical potential;augmented reality games","","1","","39","","15 Aug 2019","","","IEEE","IEEE Conferences"
"[Front cover]","",,"2011 IEEE International Conference on Control System, Computing and Engineering","26 Apr 2012","2011","","","c1","c1","The following topics are dealt with: output membership function; fuzzy logic controller; self adaptive neuro-fuzzy control; FES-assisted paraplegics indoor rowing exercise; indoor empirical path loss prediction model; 2.4 GHz 802.11N network; moving vehicle detection; RGB removal shadow segmentation; modeling virtual driving environment; regressive linear prediction; speech signals; wheel acceleration/deceleration; integrated stability control systems; nonlinear PID control; multiple input-single output model; MPPT; electronically tunable voltage-mode MIMO universal filter; high input impedance voltage-mode universal filter; OTA; parallel distributed fuzzy LQR controller; double-pendulum-type overhead cranes; ANFIS based modeling; overtaking maneuver trajectory; ASTER satellite data; spline interpolation technique; sea bed logging method; evolutionary normal-boundary intersection method; heterogeneous wireless sensor network; high precision laser tracker system; contactless position measurement; semantic Web ontologies; social network sites; Malay text-to-speech system; allophone synthesis; dynamic programming approach; pipelined optical bus systems; mainstream software sharing platform; oil & gas exploration and development; remotely operated vehicle control system; surrogate modeling; model based sensor fault tolerant control system; micromachined thermal conductivity sensor; dual stack IPv4/IPv6 testbed; malware detection; digital evidence container; security convergence; global stability; continuous time delayed linear system; LMI based approach; robust adaptive controller; observer design; discrimination electrical power; multistage centrifugal compressors; remote controlled HD videoconference system; knowledge management; wave generator system; STATCOM; blood cell image segmentation; wireless controller area ;ARM microcontroller; ECG signals based mental stress assessment; wavelet transform; genetic-optimized neuro-fuzzy inference system; meshless local Petrov-Galerkin method; power plant automation; SCADA systems:; energy potential detection; autarkic smart object design; liquid level control; focal epileptic seizure forecasting; artificial neural networks; patch antennas arrayanti-swing control; double-pendulum-type overhead crane; distributed fuzzy LQR controller; genetic fuzzy rule set selection;force control; SMA actuated gripper; self tuning fuzzy PID controller; multivariable system; recurrent diagonal neural network; customized mobile learning management system; multi-flow rate mode selection; pneumatic dispensing valve system; clonal selection based artificial immune system algorithm; adaptive nonlinear PID controller; nonholonomic mobile robot; data compression technique; global solar radiation;1.8GHz electromagnetic field exposure; electro-hydraulic actuator; Methyl Tert-butyl Ether production; reactive distillation; robust control design; spacecraft attitude systems; level drum process control training system; time-delayed feedback control; chaotic T-S fuzzy systems; photovoltaic panels Perturbation; MPPT Method; island-mode doubly-fed induction generator; reactive power control; active power control; contactless optical sensor system; automatic column-based data object clustering; multilingual databases; mycobacterium tuberculosis detection; intelligent software agents; auditory wavelet packet filters; multiple intersections traffic signal timing optimization; overlapping vehicle tracking; adaptive particle filter; endoscopic image compression; double density discrete wavelet transform; Malaysian English accents identification; AR modeling techniques; online news management; double weight codes amplitude coding optical CDMA system network; output feedback sliding mode control; chaotic trajectory tracking; electro-hydraulic actuator system; discrete sliding mode control; retentive backtracking bit ; anti-collision algorithm; RFID systems; humanoid robot NAO; face detection technique; robotic assistive therapy; fractional order PI controller; modular general purpose controller board; biologically inspired robot; bundle branch blocks; multilayered perceptron network; helical antenna prototype; wireless power transmission; optimal control; nonlinear inverted pendulum dynamical system; 1.8 GHz radio frequency signal radiation effects; WiFi electromagnetic radiation; MRI brain classification; principal component analysis; electromagnetic generator; speed sensorless field oriented control; parallel- connected dual PMSM; solar radiation data analysis; Daubechies wavelets; dual-power PV-grid energy system; thermal energy storage system; single ortho-rectified high resolution satellite imagery; TopoMap revision; free swinging shank; hemiplegics; scanning resolution and laser scanner.","","978-1-4577-1642-3","10.1109/ICCSCE.2011.6190480","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6190480","","","adaptive control;artificial immune systems;asynchronous generators;attitude control;augmented reality;biomedical MRI;code division multiple access;compressors;computer aided instruction;continuous time systems;cranes;data analysis;data compression;delays;discrete wavelet transforms;distributed control;dynamic programming;electrocardiography;electrohydraulic control equipment;face recognition;fault tolerance;force control;fuzzy control;helical antennas;humanoid robots;image coding;image segmentation;interpolation;invasive software;knowledge management;level control;linear matrix inequalities;linear systems;maximum power point trackers;medical image processing;MIMO systems;mobile computing;mobile robots;multilayer perceptrons;multivariable systems;natural language processing;nonlinear control systems;observers;ontologies (artificial intelligence);optical scanners;optical sensors;optical tracking;optimal control;particle filtering (numerical methods);pendulums;permanent magnet motors;photovoltaic power systems;PI control;power plants;principal component analysis;radiofrequency identification;reactive power control;recurrent neural nets;robust control;SCADA systems;semantic Web;social networking (online);software agents;space vehicles;speech synthesis;splines (mathematics);stability;static VAr compensators;thermal energy storage;three-term control;traffic engineering computing;velocity control;wireless LAN;wireless sensor networks","output membership function;fuzzy logic controller;self adaptive neuro-fuzzy control;FES-assisted paraplegics indoor rowing exercise;indoor empirical path loss prediction model;2.4 GHz 802.11N network;moving vehicle detection;RGB removal shadow segmentation;modeling virtual driving environment;regressive linear prediction;speech signals;wheel acceleration/deceleration;integrated stability control systems;nonlinear PID control;multiple input-single output model;MPPT;electronically tunable voltage-mode MIMO universal filter;high input impedance voltage-mode universal filter;OTA;parallel distributed fuzzy LQR controller;double-pendulum-type overhead cranes;ANFIS based modeling;ASTER satellite data;spline interpolation technique;sea bed logging method;evolutionary normal-boundary intersection method;heterogeneous wireless sensor network;high precision laser tracker;contactless position measurement;semantic Web ontologies;social network sites;Malay text-to-speech system;allophone synthesis;dynamic programming approach;pipelined optical bus systems;mainstream software sharing platform;gas exploration;remotely operated vehicle control system;surrogate modeling;model based sensor fault tolerant control system;micromachined thermal conductivity sensor;dual stack IPv4/IPv6 testbed;malware detection;digital evidence container;security convergence;global stability;continuous time delayed linear system;LMI based approach;robust adaptive controller;observer design;discrimination electrical power;multistage centrifugal compressors;knowledge management;wave generator system;STATCOM;blood cell image segmentation;wireless controller area;ARM microcontroller;ECG signals based mental stress assessment;genetic-optimized neuro-fuzzy inference system;meshless local Petrov-Galerkin method;power plant automation;SCADA systems;energy potential detection;autarkic smart object design;liquid level control;focal epileptic seizure forecasting;artificial neural networks;patch antennas arrayanti-swing control;double-pendulum-type overhead crane;distributed fuzzy LQR controller;genetic fuzzy rule set selection;SMA actuated gripper;force control;self tuning fuzzy PID controller;multivariable system;recurrent diagonal neural network;customized mobile learning management system;multiflow rate mode selection;pneumatic dispensing valve system;clonal selection based artificial immune system algorithm;adaptive nonlinear PID controller;nonholonomic mobile robot;data compression technique;global solar radiation;1.8GHz electromagnetic field exposure;electro-hydraulic actuator;Methyl Tert-butyl Ether production;reactive distillation;robust control design;spacecraft attitude systems;level drum process control training system;time-delayed feedback control;chaotic T-S fuzzy systems;photovoltaic panels perturbation;MPPT Method;island-mode doubly-fed induction generator;reactive power control;active power control;contactless optical sensor system;automatic column-based data object clustering;multilingual databases;mycobacterium tuberculosis detection;intelligent software agents;auditory wavelet packet filters;multiple intersections traffic signal timing optimization;overlapping vehicle tracking;adaptive particle filter;endoscopic image compression;double density discrete wavelet transform;Malaysian English accents identification;AR modeling techniques;online news management;double weight codes amplitude coding;optical CDMA system network;output feedback sliding mode control;chaotic trajectory tracking;electro-hydraulic actuator system;discrete sliding mode control;RFID systems;humanoid robot NAO;face detection technique;robotic assistive therapy;fractional order PI controller;modular general purpose controller;biologically inspired robot;bundle branch blocks;multilayered perceptron network;helical antenna prototype;wireless power transmission;optimal control;nonlinear inverted pendulum dynamical system;1.8 GHz radio frequency signal radiation effects;WiFi electromagnetic radiation;MRI brain classification;principal component analysis;electromagnetic generator;speed sensorless field oriented control;parallel- connected dual PMSM;solar radiation data analysis;Daubechies wavelets;dual-power PV-grid energy system;thermal energy storage system;single ortho-rectified high resolution satellite imagery;TopoMap revision;free swinging shank;hemiplegics;scanning resolution;laser scanner","","","","","","26 Apr 2012","","","IEEE","IEEE Conferences"
