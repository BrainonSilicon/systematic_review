"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"The recovery from task execution errors during time delayed teleoperation","M. R. Stein; C. P. Sayers; R. P. Paul","General Robotics & Active Sensory Perception, Pennsylvania Univ., Philadelphia, PA, USA; General Robotics & Active Sensory Perception, Pennsylvania Univ., Philadelphia, PA, USA; General Robotics & Active Sensory Perception, Pennsylvania Univ., Philadelphia, PA, USA","Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'94)","6 Aug 2002","1994","1","","547","554 vol.1","The teleprogramming system employs a supervisory control approach where operator interaction with a virtual environment directs the actions of a remote manipulator operating semi-autonomously. We focus on the detection, diagnosis, and recovery from unexpected situations frequently arising during normal operation. The teleprogramming system employs a single thread approach to error recovery that is inherent in the system design. We perform two experimental tasks, each highlighting a different role for the operator, using the teleprogramming system with a simulated communication time delay of 10 seconds. In the first task of inserting and extracting bolts, the operator assumes the role of ""task level reasoning"" or task planning and sequencing, task state reasoning, and diagnostic procedure generation. In the second task, puncturing and slicing duct tape, the operator performs ""action level reasoning"" or diagnosing and correcting unexpected situations and determining success of actions. Our experimental results indicate that complex tasks can be accomplished when the operator is provided multiple and overlapping forms of feedback.<>","","0-7803-1933-8","10.1109/IROS.1994.407425","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=407425","","Delay effects;Force control;Mechanical sensors;Virtual environment;Motion control;Displacement control;Force feedback;Force sensors;Robot sensing systems;Yarn","telerobotics;man-machine systems;delays;inference mechanisms;fault diagnosis;planning (artificial intelligence);user interfaces;virtual reality;system recovery","task execution error;time delayed teleoperation;teleprogramming system;supervisory control;operator interaction;virtual environment;remote manipulator;error detection;fault diagnosis;error recovery;task level reasoning;task planning;action level reasoning;feedback","","4","1","16","","6 Aug 2002","","","IEEE","IEEE Conferences"
"From analysis of human-human phone calls to intelligent user interfaces","O. Gerassimenko; R. Kasterpalu; M. Koit; A. Raabis; K. Strandson","Institute of Estonian and General Linguistics, University of Tartu, J. Liivi 2, Estonia; Institute of Estonian and General Linguistics, University of Tartu, J. Liivi 2, Estonia; Institute of Computer Science, University of Tartu, J. Liivi 2, Estonia; Institute of Estonian and General Linguistics, University of Tartu, J. Liivi 2, Estonia; Institute of Estonian and General Linguistics, University of Tartu, J. Liivi 2, Estonia","2008 4th International IEEE Conference Intelligent Systems","11 Nov 2008","2008","2","","10-30","10-35","Estonian institutional phone calls are analysed with the further aim to develop intelligent user interfaces. The analysis is based on the Estonian dialogue corpus. A clientpsilas initial request sets up a goal which will be achieved in collaboration with an official. Information-sharing sub-dialogues are initiated by both participants if either a request or a grant needs to be adjusted. User interfaces which enable to access two different data bases have being implemented. Users can make their requests in Estonian and get answers in synthesized speech.","1941-1294","978-1-4244-1739-1","10.1109/IS.2008.4670493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4670493","Dialogue acts;corpus analysis;human-machine interaction;linguistic features;Estonian","User interfaces;Natural languages;Intelligent systems;Virtual reality;Collaboration;Speech synthesis;Deductive databases;Decision support systems;Colon;Proposals","human computer interaction;natural language interfaces;speech synthesis;speech-based user interfaces","human-human phone call;intelligent user interface;Estonian institutional phone call;Estonian dialogue corpus;information-sharing subdialogue;speech synthesis;natural language interface;human-computer interaction","","1","","7","","11 Nov 2008","","","IEEE","IEEE Conferences"
"Impedance-Based Gaussian Processes for Modeling Human Motor Behavior in Physical and Non-Physical Interaction","J. R. Medina; H. Börner; S. Endo; S. Hirche","Franka Emika GmbH; Department of Electrical and Computer Engineering, Chair of Information-oriented Control, Technical University of Munich, Munich, Germany; Department of Electrical and Computer EngineeringChair of Information-oriented ControlTechnical University of Munich; Department of Electrical and Computer EngineeringChair of Information-oriented ControlTechnical University of Munich","IEEE Transactions on Biomedical Engineering","20 Aug 2019","2019","66","9","2499","2511","Objective: Modeling of human motor intention plays an essential role in predictively controlling a robotic system in human-robot interaction tasks. In most machine learning techniques, human motor behavior is modeled as a generic stochastic process. However, the integration of a priori knowledge about underlying system structures can provide insights on otherwise unobservable intrinsic states that yield the superior prediction performance and increased generalization capabilities. Methods: We present a novel method for modeling human motor behavior that explicitly includes a neuroscientifically supported model of human motor control, in which the dynamics of the human arm are modeled by a mechanical impedance that tracks a latent desired trajectory. We adopt a Bayesian setting by defining Gaussian process (GP) priors for the impedance elements and the latent desired trajectory. This enables exploitation of a priori human arm impedance knowledge for regression of interaction forces through inference of a latent desired human trajectory. Results: The method is validated using simulated data, with particular focus on effects of GP prior parameterization and intention estimation capabilities. The superior prediction performance is shown with respect to a naive GP prior. An experiment with human participants evaluates generalization capabilities and effects of training data sparsity. Conclusion: We derive the correlations of an impedance-based GP model of human motor behavior that exploits a priori knowledge. Significance: The model effectively predicts interaction forces by inferring a latent desired human trajectory in previously observed as well as unobserved regions of the input space.","1558-2531","","10.1109/TBME.2018.2890710","ERC Starting; Control based on Human Models; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8599006","Bayesian modeling;Gaussian processes;human motor control;human motor intention;human robot interaction;impedance;kernel structure","Impedance;Trajectory;Task analysis;Robots;Gaussian processes;Correlation;Motor drives","Bayes methods;Gaussian processes;human-robot interaction;regression analysis","nonphysical interaction;human motor intention;human-robot interaction tasks;generic stochastic process;neuroscientifically supported model;human motor control;a priori human arm impedance knowledge;latent desired human trajectory;intention estimation capabilities;impedance-based GP model;human motor behavior;impedance-based Gaussian processes;Bayesian setting","Adult;Algorithms;Arm;Computer Simulation;Electric Impedance;Female;Humans;Intention;Male;Models, Biological;Movement;Normal Distribution;Psychomotor Performance;Young Adult","1","","53","Traditional","1 Jan 2019","","","IEEE","IEEE Journals"
"A virtual environment for realistic testing and training of face detection and recognition systems","M. Correa; J. Ruiz-del-Solar; I. Parra-Tsunekawa","Elec. Eng. Dept. - Universidad de Chile, Chile; Elec. Eng. Dept. - Universidad de Chile, Chile; Elec. Eng. Dept. - Universidad de Chile, Chile","19th International Symposium in Robot and Human Interactive Communication","11 Oct 2010","2010","","","69","75","In this article, a virtual environment for realistic testing and training of face detection and recognition systems under uncontrolled conditions is proposed. The key elements of this tool are a simulator and real face and background images taken under real-world conditions with different acquisition conditions. Inside the simulated environment, an observing agent, the one with the ability to recognize faces, can navigate and observe the real face images, at different distances, angles and with indoor or outdoor illumination. During the face recognition process, the agent can actively change its viewpoint and relative distance to the faces in order to improve the recognition results. The virtual environment provides all behaviors to the agent (navigation, positioning, face's image composing under different angles, etc.), except the ones related with the recognition of faces. This tool could be of high interest in HRI applications related with the visual recognition of humans. It allows comparing and quantifying the face recognition capabilities of service robots, and in general intelligent machines, under exactly equal working conditions. The applicability of the proposed tool is validated in the comparison of state of the art face detection and recognition methods.","1944-9437","978-1-4244-7990-0","10.1109/ROMAN.2010.5598673","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5598673","","Face;Face recognition;Databases;Lighting;Testing;Detectors;Face detection","face recognition;human-robot interaction;robot vision;service robots;virtual reality","virtual environment;realistic testing;realistic training;face detection systems;face recognition systems;human-robot interaction;service robots;intelligent machines","","1","","30","","11 Oct 2010","","","IEEE","IEEE Conferences"
"Design and Implementation of the Radioactive Aerosol's Concentration Measurement System Based on Virtual Training","H. Wei-hua; H. Chang-qiang; D. Da-li","Eng. Inst., Air Force Eng. Univ., Xi'an, China; Eng. Inst., Air Force Eng. Univ., Xi'an, China; Eng. Inst., Air Force Eng. Univ., Xi'an, China","2011 International Conference on Business Computing and Global Informatization","25 Aug 2011","2011","","","509","511","A Virtual Training System of radioactive aerosol 's concentration measurement is constructed based on Virtual Reality. Firstly, 3-d geometric models about radioactive aerosol's outer environment, detector, intelligent scaler and air sampling pump etc. are constructed, the general radioactive law based on face radioactive source is presented. These models are driving in general program platform using human computer interaction technology. Furthermore, there are several functions about database sharing, fault diagnosis, examining evaluation and on-time help which realize the whole system virtual training. Program show this training system avoids ""nuclear fear"" psychology and improves staff's training effect.","2378-895X","978-1-4577-0788-9","10.1109/BCGIn.2011.134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6003961","Virtual Training;Radioactivity;Aerosol;Radiation Field component","Training;Atmospheric modeling;Aerosols;Nuclear measurements;Solid modeling;Instruments;Face","aerosols;computer aided instruction;human computer interaction;nuclear engineering computing;virtual reality","radioactive aerosol concentration measurement system;virtual training;virtual reality;3D geometric model;general program platform;human computer interaction technology;database sharing;fault diagnosis;nuclear fear psychology","","","","5","","25 Aug 2011","","","IEEE","IEEE Conferences"
"A model-view/controller approach to support visualization and online data analysis of Agent-based simulations","A. Grignard; A. Drogoul; J. Zucker","UPMC / UMI 209 UMMISCO, Institut de la Francophonie pour l'Informatique (IFI), Ha Noi, Viet Nam; IRD / UMI 209 UMMISCO, Institut de la Francophonie pour l'Informatique (IFI), Ha Noi, Viet Nam; IRD / UMI 209 UMMISCO, Institut de la Francophonie pour l'Informatique (IFI), Ha Noi, Viet Nam","The 2013 RIVF International Conference on Computing & Communication Technologies - Research, Innovation, and Vision for Future (RIVF)","23 Jan 2014","2013","","","233","236","Agent-based Modeling is playing a key role in an increasing number of approaches addressing modeling complex systems. Historically, such models were focused on describing the system modelled dynamics but not the interaction or visualization of the model itself. The new requirements for high-level realistic visualization and online analysis tools of ABM simulations raise key issues that are yet unsolved: how to visualize interaction between entities and more generally abstracting the key information from the system dynamics. Instead of ad-hoc existing approaches that require reification in the model, we propose an approach dedicated to visualize and discover emerging dynamics from the model. In this approach, the execution of the simulation and its representation is separated and building a visualization is like building a visualization model on top of the reference model. The techniques presented here have been implemented in an Agent-based simulation platform, Gama, and illustrate the new perspective on visualization in Agent-based Modeling.","","978-1-4799-1350-3","10.1109/RIVF.2013.6719899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719899","Agent-based model;visualization;interaction;online analysis;3D;complex systems","Data models;Analytical models;Visualization;Abstracts;Data visualization;Computational modeling;Biological system modeling","data analysis;data visualisation;digital simulation;multi-agent systems","model-view-controller approach;high-level realistic visualization;online data analysis;agent-based simulation;Gama;agent-based modeling","","4","","18","","23 Jan 2014","","","IEEE","IEEE Conferences"
"Virtual piano with real-time interaction using automatic marker detection","V. Chouvatut; W. Jindaluang","Department of Computer Science, Faculty of Science, Chiang Mai University, Chiang Mai 50200 Thailand; Department of Computer Science, Faculty of Science, Chiang Mai University, Chiang Mai 50200 Thailand","2013 International Computer Science and Engineering Conference (ICSEC)","2 Jan 2014","2013","","","222","226","This paper aims to apply the object detection used in Augmented Reality (AR) technology to a real-time application for musical instrument, a virtual piano. The proposed application does provide the sounds of musical notes and also display the corresponding notations of the playing notes. Both features allow people with hearing disability or muscular weakness or even ones who cannot exert their pressure on the general keyboard instruments to play music, due to their physical disabilities. The experimental results demonstrated that the error of the playback sounds is only 0.5 percent which is only 2 times measured from tapping 50 markers for 400 times in real time. However, all errors are because of the wrong positions of the player's hand as some of his fingers accidentally covered over the unexpected markers during playing the virtual piano.","","978-1-4673-5324-3","10.1109/ICSEC.2013.6694783","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6694783","Augmented Reality;Marker;Virtual Musical Instrument;Physical Disabilities","Three-dimensional displays;Augmented reality;Instruments;Labeling;Keyboards;Cameras;Image edge detection","augmented reality;handicapped aids;image matching;music;musical instruments;object detection","virtual piano;real-time interaction;automatic marker detection;object detection;augmented reality technology;AR technology;musical instrument;musical note sounds;note notations;muscular weakness;keyboard instruments;music playing;physical disabilities;playback sound error;marker tapping;player hand positions;hearing disability;image matching","","4","","17","","2 Jan 2014","","","IEEE","IEEE Conferences"
"Immersive Gastronomic Experience with Distributed Reality","P. Perez; E. Gonzalez-Sosa; R. Kachach; J. Ruiz; I. Benito; F. Pereira; A. Villegas",Nokia Bell Labs; Nokia Bell Labs; Nokia Bell Labs; Nokia Bell Labs; Nokia Bell Labs; Nokia Bell Labs; Nokia Bell Labs,"2019 IEEE 5th Workshop on Everyday Virtual Reality (WEVR)","22 Aug 2019","2019","","","1","6","We have developed an immersive gastronomic experience as a proof of concept of Distributed Reality, a type of Augmented Virtuality which combines a reality transmitted from a remote place, using 360° video, with a local reality, using video see-through. In order to reach fully immersive experience, local objects of interest such as hands and local food are segmented using red chrominance keying. Only those segmented objects are merged with the remote reality, enabling this way to increase self-presence and to allow user interaction. More concretely, the gastronomic experience consists of tasting small pieces of food, while being immersed in a remote place designed to pair with the food, thus creating an innovative concept with potential impact in hospitality and tourism industries. An evaluation performed with 66 users shows that it provides good levels of immersion, local interactivity, and general user satisfaction. The application achieves real time performance and has been developed for a smartphone mounted on a consumer headset, thus being easy to deploy and to reuse in other use cases.","","978-1-7281-4050-6","10.1109/WEVR.2019.8809591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809591","Human-centered computing;Human computer interaction (HCI);Interaction paradigms","Cameras;Streaming media;Virtual reality;Distortion;Real-time systems;Resists;Image segmentation","augmented reality;computer graphics;image colour analysis;image segmentation;interactive devices;smart phones","immersive gastronomic experience;distributed reality;fully immersive experience;local food;red chrominance keying;segmented objects;remote reality;local interactivity;augmented virtuality;user interaction;smart phone;consumer headset","","7","","26","","22 Aug 2019","","","IEEE","IEEE Conferences"
"A Tangible Information Explorer Using Vibratory Touch Screen","H. Nishino; Y. Fukakusa; A. Hatano; T. Kagawa; K. Utsumiya","Dept. of Comput. Sci. & Intell. Syst., Oita Univ., Oita, Japan; Dept. of Comput. Sci. & Intell. Syst., Oita Univ., Oita, Japan; Dept. of Comput. Sci. & Intell. Syst., Oita Univ., Oita, Japan; Dept. of Comput. Sci. & Intell. Syst., Oita Univ., Oita, Japan; Dept. of Comput. Sci. & Intell. Syst., Oita Univ., Oita, Japan","2012 IEEE 26th International Conference on Advanced Information Networking and Applications","19 Apr 2012","2012","","","671","677","Touch panel displays are becoming available for implementing futuristic human computer interaction (HCI) methods and are proven to be a useful infrastructure for creating intuitive HCI. In spite of their popularity, there are some drawbacks. The most serious one is their hardness to operate especially for the weak in information technology such as elderly and blind users. A tactile feedback function has a potential ability for enabling them to make full use of the devices. We propose an approach for effectively designing user-friendly HCI based on the tactile feedback. We exemplify our approach through the design and development of a practical application, a haptic web browser. It allows even the weak users to intuitively explore various web pages without heavily depending on the visual information. While the system targets at supporting the weak, the touch interactions are quite useful means for general public to improve the stability and the degree of satisfaction in web browsing operations. The proposed system uses a touch panel haptic display for helping the users to operate with intuitive touch sensations.","2332-5658","978-1-4673-0714-7","10.1109/AINA.2012.125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6184934","touch panel display;tactile feedback;web browsing;graphical user interface;assistive information technology","Browsers;Web pages;Tactile sensors;Graphical user interfaces;Force feedback;Vibrations","handicapped aids;haptic interfaces;human computer interaction;online front-ends;touch sensitive screens","tangible information explorer;vibratory touch screen;human computer interaction;elderly users;blind users;tactile feedback function;user-friendly HCI;haptic Web browser;Web pages;visual information;intuitive touch sensations;touch panel haptic displays","","8","1","16","","19 Apr 2012","","","IEEE","IEEE Conferences"
"Multi-task control of multi-contact manipulators during accidental interactions with robot body","A. Karami; M. Keshmiri; H. Sadeghian","Department of mechanical engineering, Isfahan University of technology, Isfahan, Iran; Department of mechanical engineering, Isfahan University of technology, Isfahan, Iran; Engineering department, University of Isfahan, Isfahan, Iran","2015 3rd RSI International Conference on Robotics and Mechatronics (ICROM)","4 Jan 2016","2015","","","463","468","In this paper, the problem of controlling multiple different tasks in various points on the robot body is considered. The proposed approach guarantees the execution of multiple various tasks (force, position and orientation control) in the presence of intentional or accidental interaction with robot body. The control law distinguish between desired and accidental external forces. Magnitude and/or orientation of the forces in the contact points can be controlled while various tasks may be defined and controlled in other contact points in the robot body. Controller-observer algorithm is proposed based on the generalized momentum of the robot. Asymptotically stability of task space errors are proved while a proper estimation of the external torque on robot is available. Performance of the proposed algorithm is confirmed by simulations.","","978-1-4673-7234-3","10.1109/ICRoM.2015.7367828","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367828","multi-task control;multi-contact robots;multi-priority control;disturbance;observer;force control;orientation control","Force;Torque;Observers;Robot kinematics;Aerospace electronics;Mathematical model","asymptotic stability;control system synthesis;human-robot interaction;manipulators;observers","multitask control;multicontact manipulators;accidental interactions;robot body;intentional interaction;control law;controller-observer algorithm;asymptotical stability;task space errors;generalized robot momentum","","","","13","","4 Jan 2016","","","IEEE","IEEE Conferences"
"Development of a Hybrid Simulator for Underwater Vehicles With Manipulators","M. Razzanelli; S. Casini; M. Innocenti; L. Pollini","Dipartimento di Ingegneria dell’Informazione, University of Pisa, Pisa, Italy; Dipartimento di Ingegneria dell’Informazione, University of Pisa, Pisa, Italy; Dipartimento di Ingegneria dell’Informazione, University of Pisa, Pisa, Italy; Dipartimento di Ingegneria dell’Informazione, University of Pisa, Pisa, Italy","IEEE Journal of Oceanic Engineering","12 Oct 2020","2020","45","4","1235","1251","This article describes a hybrid simulation approach meant to facilitate the realization of a simulator for underwater vehicles with one or more manipulators capable of simulating the interaction of the vehicle with objects and structures of the environment. The hybrid simulation approach is first described and motivated analytically, then an analysis of simulation accuracy is proposed, where, in particular, the implications of added mass simulation are discussed. Then, a possible implementation of the proposed architecture is shown, where a robotic simulator of articulated bodies, capable of stable and accurate simulation of contact forces, although unfit to simulate any serious hydrodynamic model, is tightly interfaced with a general purpose dynamic systems simulator that is used to simulate the hydrodynamic forces, the vehicle guidance, navigation, and control system, and also a man-machine interface. Software details and the technicalities needed to interface the two simulators are also briefly presented. Finally, the results of the simulation of three operational scenarios are proposed as qualitative assessment of the simulator capabilities.","1558-1691","","10.1109/JOE.2019.2935801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862914","Remotely operated vehicle;robotic intervention;simulation;underwater vehicle manipulator systems","Mathematical model;Underwater vehicles;Hydrodynamics;Unmanned vehicles;Vehicle dynamics;Manipulator dynamics;Simulations","computer simulation;control engineering computing;hydrodynamics;manipulator dynamics;mobile robots;navigation;stability;underwater vehicles;user interfaces","underwater vehicles;robotic simulator;simulation stability;general purpose dynamic systems simulator;vehicle guidance;hybrid simulator;manipulators;hydrodynamic model;navigation;control system;man-machine interface;software details;Mathworks Simulink","","","","55","IEEE","8 Oct 2019","","","IEEE","IEEE Journals"
"Perceptually Augmented Simulator Design","T. Edmunds; D. K. Pai","University of British Columbia, Vancouver; University of British Columbia, Vancouver","IEEE Transactions on Haptics","9 Mar 2012","2012","5","1","66","76","Training simulators have proven their worth in a variety of fields, from piloting to air-traffic control to nuclear power station monitoring. Designing surgical simulators, however, poses the challenge of creating trainers that effectively instill not only high-level understanding of the steps to be taken in a given situation, but also the low-level “muscle-memory” needed to perform delicate surgical procedures. It is often impossible to build an ideal simulator that perfectly mimics the haptic experience of a surgical procedure, but by focussing on the aspects of the experience that are perceptually salient we can build simulators that effectively instill learning. We propose a general method for the design of surgical simulators that augment the perceptually salient aspects of an interaction. Using this method, we can increase skill-transfer rates without requiring expensive improvements in the capability of the rendering hardware or the computational complexity of the simulation. In this paper, we present our decomposition-based method for surgical simulator design, and describe a user-study comparing the training effectiveness of a haptic-search-task simulator designed using our method versus an unaugmented simulator. The results show that perception-based task decomposition can be used to improve the design of surgical simulators that effectively impart skill by targeting perceptually significant aspects of the interaction.","2329-4051","","10.1109/TOH.2011.42","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5975145","Haptic I/O;artificial;augmented;and virtual realities;life and medical sciences;surgical simulation.","Haptic interfaces;Surgery;Training;Needles;Rendering (computer graphics);Surface roughness;Rough surfaces","augmented reality;computer based training;haptic interfaces;medical computing;surgery","perceptually augmented simulator design;training simulator;air-traffic control;piloting;nuclear power station monitoring;surgical simulator;low-level muscle-memory;surgical procedure;haptic experience;salient interaction aspect;skill-transfer rate;rendering hardware;computational complexity;decomposition-based method;user study;haptic-search-task simulator;unaugmented simulator;perception-based task decomposition","","2","","21","","4 Aug 2011","","","IEEE","IEEE Journals"
"Search theory, agent-based simulation, and u-boats in the Bay of Biscay","Champagne; Carl; Hill","Dept. of Operational Sci., Air Force Inst. of Technol., Wright Patterson AFB, OH, USA; Dept. of Operational Sci., Air Force Inst. of Technol., Wright Patterson AFB, OH, USA; NA","Proceedings of the 2003 Winter Simulation Conference, 2003.","30 Jan 2004","2003","1","","991","998 Vol.1","To date, most search theory study has focused either on analytical models of specific situations requiring rigid assumptions, or, as in the case of search and rescue, operational experiments aimed at obtaining detection probabilities for a variety of scenarios. Analytical search theory results provide bounds on empirical results. This research introduces an agent-based simulation approach to the subject of offensive search operations in combat. Generally, the value of a combat simulation is measured in terms of insights gained through experimentation. Agent-based simulation enables insights with regards to the emergent behavior of the individual combatants, groups of combatants, or the system as a whole. Emergent behavior for the purposes of this research is system behavior, not explicitly programmed, arising from local interactions between agents. Such behavior with respect to search effectiveness is investigated within the context of a historical case study involving offensive search.","","0-7803-8131-9","10.1109/WSC.2003.1261521","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1261521","","Analytical models;Weapons;Counting circuits;Biomedical measurements;Gain measurement;Software agents;Human factors;Multiagent systems;Vents;Data analysis","military computing;digital simulation;multi-agent systems","search theory;agent-based simulation;u-boats;Bay of Biscay;analytical models;search and rescue;operational experiments;detection probabilities;combat search operations;combat simulation;emergent behavior;individual combatants;groups of combatants;system behavior;agent interactions;offensive search","","9","","17","","30 Jan 2004","","","IEEE","IEEE Conferences"
"Design of Cyber-Human Frameworks for Immersive Learning","A. Gupta; J. Cecil; O. Tapia; M. Sweet-Darter","Oklahoma State University,Center for Cyber-Physical Systems,Stillwater,USA; Oklahoma State University,Co-Director, Center for Cyber-Physical Systems,Stillwater,USA; Oklahoma State University,Center for Cyber-Physical Systems,Stillwater,USA; Director, Anselm Center, Edmond,Oklahoma,USA","2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)","28 Nov 2019","2019","","","1563","1568","This paper focuses on the creation of information centric Cyber-Human Learning Frameworks involving Virtual Reality based mediums. A generalized framework is proposed, which is adapted for two educational domains: one to support education and training of residents in orthopedic surgery and the other focusing on science learning for children with autism. Users, experts and technology based mediums play a key role in the design of such a Cyber-Human framework. Virtual Reality based immersive and haptic mediums were two of the technologies explored in the implementation of the framework for these learning domains. The proposed framework emphasizes the importance of Information-Centric Systems Engineering (ICSE) principles which emphasizes a user centric approach along with formalizing understanding of target subjects or processes for which the learning environments are being created.","2577-1655","978-1-7281-4569-3","10.1109/SMC.2019.8914205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8914205","Virtual Reality;Human-Computer Interaction;Virtual Learning","Haptic interfaces;Surgery;Human computer interaction;Training;Solid modeling","biomedical education;computer aided instruction;handicapped aids;medical computing;surgery;virtual reality","immersive learning;generalized framework;educational domains;science learning;technology based mediums;immersive mediums;haptic mediums;information-centric systems engineering principles;user centric approach;learning environments;cyber-human framework;virtual reality based mediums;information centric cyber-human learning frameworks","","","","48","","28 Nov 2019","","","IEEE","IEEE Conferences"
"Recommendation System with Association Rule Mining and Mobile Augmented Reality","K. U. Birant; P. Yildirim Taser; H. O. Dindar; D. Birant","Dokuz Eylul University,Department of Computer Engineering,Izmir,Turkey; İzmir Bakırçay University,Department of Computer Engineering,Izmir,Turkey; Dokuz Eylul University,Graduate School of Natural and Applied Sciences,Izmir,Turkey; Dokuz Eylul University,Department of Computer Engineering,Izmir,Turkey","2019 Innovations in Intelligent Systems and Applications Conference (ASYU)","2 Jan 2020","2019","","","1","6","Mobile augmented reality is a popular technology field that allows simultaneous interaction between the real world and the virtual world with the help of mobile devices. The notion of object recognition and classification, which plays an important role in mobile augmented reality applications, is the process of identifying an object on the image and assigning it to a certain class label. In this study, a novel three-dimensional and real time recommendation system has been developed with association rule mining and mobile augmented reality. The proposed system consists of three stages: (1) Recognition and classification of the object on the image (2) Determination of the related rules of the object with other objects in the dataset by using the Apriori algorithm (3) Adding recommendations that generated from the rules to the image as virtual objects with mobile augmented reality. Although the developed system in this study is a general recommendation system, it was applied in the field of market basket analysis as an experimental study.","","978-1-7281-2868-9","10.1109/ASYU48272.2019.8946401","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946401","mobile augmented reality;object recognition;association rule mining;data mining","Augmented reality;Object recognition;Data mining;Global Positioning System;Mobile handsets;Real-time systems;Image recognition","augmented reality;data mining;image classification;mobile computing;object recognition;recommender systems","association rule mining;mobile devices;object recognition;object classification;mobile augmented reality applications;real time recommendation system;virtual objects;three-dimensional recommendation system;apriori algorithm","","","","22","","2 Jan 2020","","","IEEE","IEEE Conferences"
"A Browser-Based Perceptual Experiment Platform for Visual Search Study in Augmented Reality System","D. Feng; D. Weng; W. Lu; C. Sun; E. Y. Do","Sch. of Optoelectron., Beijing Inst. of Technol., Beijing, China; Sch. of Optoelectron., Beijing Inst. of Technol., Beijing, China; Keio-NUS CUTE Center, Nat. Univ. of Singapore, Singapore, Singapore; Keio-NUS CUTE Center, Nat. Univ. of Singapore, Singapore, Singapore; Keio-NUS CUTE Center, Nat. Univ. of Singapore, Singapore, Singapore","2013 IEEE 10th International Conference on Ubiquitous Intelligence and Computing and 2013 IEEE 10th International Conference on Autonomic and Trusted Computing","30 Jan 2014","2013","","","466","473","This paper describes a real-time experiment platform for visual search in Augmented Reality (AR). Searching for a virtual object embedded in an AR environment is an example of a visual search task. However, systems implemented in the previous visual search studies have focused on static images and pre-recorded videos. Our system supports real-time video captured from a camera mounted in a Head-Worn-Display (HWD) as input. The system allows customization by the experiment administrator according to their specific requirements. A visual clutter analysis method known as Feature Congestion is utilized to analyze the visual clutter of video scene and optimized trying to meet the requirements of real-time operation. Different optimization techniques such as multithreading, general computation using GPU, fast matrix convolution are explored. The theoretical improvement and limitations of the optimizations have been discussed. By utilizing JavaScript and HTML, this browser-based platform is designed to be cross-platform and extensible. Many state-of-art HTML5 technologies are employed in the system to both improve the computation performance and strengthen the interactions between users and system.","","978-1-4799-2482-0","10.1109/UIC-ATC.2013.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6726245","Visual Search;HTML5 and Javascript;Browser-based Experiment Platform;Augmented Reality","Visualization;Real-time systems;Clutter;Videos;Browsers;Convolution;Hardware","augmented reality;clutter;graphics processing units;helmet mounted displays;human computer interaction;hypermedia markup languages;Java;multi-threading","browser-based perceptual experiment platform;visual search study;augmented reality system;virtual object;real-time video;head-worn-display;HWD;customization;visual clutter analysis;feature congestion;video scene;multithreading;general computation;GPU;fast matrix convolution;JavaScript;HTML5 technologies","","","","27","","30 Jan 2014","","","IEEE","IEEE Conferences"
"Efficient Execution on GPUs of Field-Based Vehicular Mobility Models","K. S. Perumalla","Oak Ridge Nat. Lab., Oak Ridge, TN","2008 22nd Workshop on Principles of Advanced and Distributed Simulation","20 Jun 2008","2008","","","154","154","Large-scale scenarios of vehicular traffic simulation problems are characterized by complex queuing effects, control mechanisms and other interactions of the traffic on the control and vice versa. While small-sized scenarios are relatively easy to explore and analyze, larger scenarios need specialized treatment for efficient execution. The simulation challenges of speed and scale become pronounced when network sizes are very large (millions of road intersections) and/or vehicular traffic load is immense (several million simultaneously active vehicles). Commonly used execution approaches roughly correspond to the two extremes of the simulation spectrum. Aggregate models correspond to one extreme, typically employed to achieve coarse results at a relatively high simulation speed. Micro-simulation represents the other extreme, employed for finer granularity at the expense of greatly decreased simulation speed. Hybrid methods are emerging as via media that provide medium level modeling granularity while still affording fast execution. In some of our active projects in real-time data- driven simulations, we are developing one such hybrid method. Two novel aspects of our hybrid method are: (1) formulation of a field-based model of vehicular traffic movement in a large road network (2) fast execution of the field-based hybrid model on data-parallel platforms of general-purpose graphics processing units (GPUs).","1087-4097","978-0-7695-3159-5","10.1109/PADS.2008.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4545342","","Traffic control;Communication system traffic control;Telecommunication traffic;Road vehicles;Aggregates;Laboratories;Large-scale systems;Graphics;Magnetic fields;Prototypes","computer graphic equipment;digital simulation;road traffic;traffic engineering computing","GPU;field-based vehicular mobility model;vehicular traffic simulation;queuing effects;control mechanism;traffic interaction;traffic control;network size;road intersection;vehicular traffic load;modeling granularity;real-time data-driven simulation;vehicular traffic movement;road network;data parallel platform;graphics processing units","","4","","","","20 Jun 2008","","","IEEE","IEEE Conferences"
"Analysis of correspondences between real and virtual worlds in general public applications","S. Natkin; C. Yan","CEDRIC, France; NA","International Conference on Computer Graphics, Imaging and Visualization (CGIV'05)","24 Oct 2005","2005","","","323","332","Using a mix of wireless telecommunication, digital audiovisuals and the Internet, the digital entertainments have evolved to a new form of interaction based on mobile ubiquitous computing and mixed reality. Our work is devoted to the application using both reality and virtuality in a complex mixed mode. Our research goal is to highlight constructive schemes (interfaces, narrative structure...) which can be used in the design of interactive media production. This paper is devoted to the analysis and the classification of the possible relationship between virtual worlds (VW) and real worlds (RW). It focuses on the general public, in particular entertainment applications. We discuss a general model of the RW/VW interactions and present a classification of applications. Some significant examples are discussed as a conclusion.","","0-7695-2392-7","10.1109/CGIV.2005.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1521083","","Mobile computing;Production;TV;Ubiquitous computing;Virtual reality;Mobile handsets;Topology;Augmented reality;Games;Computer interfaces","virtual reality;entertainment;multimedia computing","virtual world;general public application;digital entertainment;mobile ubiquitous computing;mixed reality;interactive media production;real world","","3","","50","","24 Oct 2005","","","IEEE","IEEE Conferences"
"Parameter-based lip modeling for facial animation of general objects","Ze-Jing Chuang; Chung-Hsien Wu","Dept. of Comput. Sci. & Inf. Eng., Nat. Cheng Kung Univ., Tainan, Taiwan; Dept. of Comput. Sci. & Inf. Eng., Nat. Cheng Kung Univ., Tainan, Taiwan","Proceedings. IEEE International Conference on Multimedia and Expo","7 Nov 2002","2002","1","","453","456 vol.1","For human-computer interaction, virtual characters become more and more important in many applications. However, the facial animation developed in the past years generally focused on the simulation of human face. For animation and interaction in virtual world the emphasis should be extended to general objects with human-like faces. We propose four parameter-based lip models that can apply the lip motion to general objects with lip-like meshes. We analyze the characteristics of lip motions and define four different lip models: inflexible-cylindrical model, flexible-cylindrical model, inflexible-square model, and flexible-square model. The parameters of lip motion in different lip models are extracted from the original real facial image sequence with lip motion. These parameters are then used to generate a lip-motion simulation system for general objects. Using the system, the user can apply the lip motion to any meshes by simply defining the lip model.","","0-7803-7304-9","10.1109/ICME.2002.1035816","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1035816","","Facial animation;Mouth;Humans;Face;Muscles;Skin;Computer science;Application software;Computational modeling;Image motion analysis","computer animation;image motion analysis;digital simulation;image sequences;parameter estimation","parameter-based lip modeling;general objects;human-computer interaction;virtual characters;human face simulation;lip motion analysis;inflexible-cylindrical model;lip-like meshes;flexible-cylindrical model;inflexible-square model;flexible-square model;facial image sequence;lip-motion simulation system;facial animation system","","","1","6","","7 Nov 2002","","","IEEE","IEEE Conferences"
"Teaching of assembly motion by demonstration-artificial constrained motion primitives and its implementation using virtual polyhedron","H. Onda","Electrotech. Lab., MITI, Tsukuba, Japan","Smc 2000 conference proceedings. 2000 ieee international conference on systems, man and cybernetics. 'cybernetics evolving to systems, humans, organizations, and their complex interactions' (cat. no.0","6 Aug 2002","2000","2","","949","954 vol.2","Teaching by demonstration is a method to generate a robot program that makes a robot do the same task as the task which a human operator demonstrates. The author developed a teaching by demonstration in VR system which automatically generates a robot program to work in the real world after a task is demonstrated by an operator in the virtual world. This system deals with a task of controlling contact states between bodies like the assembly task. When one body is not in contact with another, not only contact states but also other new states which can specify more general arrangement of the bodies are necessary in order to make the robot more skilful. The author introduced a virtual smallface (VSF) and an artificial constrained motion primitive (ACMP) for this purpose. A virtual polyhedron for constrained motion (VPCM) is newly introduced in order to implement more general ACMPs. An operator more easily and generally defines new states of the task by using VSFs and VPCMs, since VSFs are used to define intuitively new states of a task and since (virtual) contact states between VPCMs are also used as the new states.","1062-922X","0-7803-6583-6","10.1109/ICSMC.2000.885972","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=885972","","Education;Robotics and automation;Educational robots;Robotic assembly;Control systems;Humans;Automatic control;Assembly systems;Virtual reality;Robot kinematics","assembling;industrial robots;virtual reality","assembly motion teaching;artificial constrained motion primitives;virtual polyhedron;teaching by demonstration;robot program;human operator;virtual reality;virtual smallface;contact states","","","","10","","6 Aug 2002","","","IEEE","IEEE Conferences"
"The Umbra simulation framework as applied to building HLA federates","E. J. Gottlieb; M. J. McDonald; F. J. Oppel; J. B. Rigdon; P. G. Xavier","Orion Int. Technol. Inc., Albuquerque, NM, USA; NA; NA; NA; NA","Proceedings of the Winter Simulation Conference","29 Jan 2003","2002","1","","981","989 vol.1","Sandia's Umbra modular simulation framework was designed to enable the modeling of robots for manufacturing, military, and security system concept evaluation. Umbra generalizes data-flow-based simulation to enable modeling of heterogeneous interaction phenomena via a multiple worlds abstraction. This and other features make Umbra particularly suitable for developing simulation federates. Umbra's HLA interface library utilizes DMSO's HLA Run Time Infrastructure 1.3-Next Generation (RTI 1.3-NG) software library to federate Umbra-based models into HLA environments. Examples draw on a first application that provides component technologies for the US Army JPSD's Joint Virtual Battlespace (JVB) simulation environment for Objective Force concept analysis.","","0-7803-7614-5","10.1109/WSC.2002.1172990","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1172990","","Analytical models;Software libraries;Robot sensing systems;Virtual manufacturing;Mobile robots;Computer architecture;Unmanned aerial vehicles;Data security;Application software;Computational geometry","military computing;digital simulation;computer based training;software agents;multi-agent systems;robots","Umbra modular simulation framework;robots;manufacturing;military;security system concept evaluation;data-flow-based simulation;heterogeneous interaction phenomena;multiple worlds abstraction;simulation federates;high-level architecture interface library;HLA Run Time Infrastructure 1.3-Next Generation software library;US Army Joint Virtual Battlespace simulation environment;Objective Force concept analysis","","7","1","13","","29 Jan 2003","","","IEEE","IEEE Conferences"
"VEC3D: a 3-D virtual English classroom for second language learning","Yong-Yuan Lin; Ya-Chun Shih; Mau-Tsuen Yang","Media Lab., Nat. Dong Hwa Univ., Shoufeng, Taiwan; NA; NA","Fifth IEEE International Conference on Advanced Learning Technologies (ICALT'05)","19 Sep 2005","2005","","","906","908","The traditional e-learning systems are generally less attractive to students due to their lack of 3D immersion and real voice interaction. The technology of virtual reality can be exploited to compensate these weaknesses. We propose a realistic and interactive virtual English classroom entitled VEC3D by integrating vivid 3D graphics and real-time voice communication. The goal of VEC3D aims to help undergraduate students develop the overall English communicative competence in listening, speaking, reading and writing.","2161-377X","0-7695-2338-2","10.1109/ICALT.2005.302","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1508852","","Natural languages;Virtual reality;Writing;Avatars;Educational institutions;Space technology;Education;Electronic learning;Graphics;Appropriate technology","computer aided instruction;linguistics;natural language interfaces;virtual reality;solid modelling;voice communication;real-time systems","VEC3D;3D virtual English classroom;second language learning;e-learning systems;3D immersion;voice interaction;virtual reality;interactive virtual English classroom;3D graphics;real-time voice communication;undergraduate students;English communicative competence;listening;speaking;reading;writing","","","","6","","19 Sep 2005","","","IEEE","IEEE Conferences"
"Generating Task-Oriented Interactions of Service Robots","Y. Kim; W. C. Yoon","Integrated Safety Assessment Division, Korea Atomic Energy Research Institute, Daejeon-Shi, Korea; Department of Knowledge Service Engineering, KAIST, Daejeon, Korea","IEEE Transactions on Systems, Man, and Cybernetics: Systems","20 May 2017","2014","44","8","981","994","Human-robot interaction (HRI) may play a key role in enhancing a robot's capability in practical service tasks, allowing productive human-robot collaboration. To obtain appropriate human aid for conducting tasks, a robot should be capable of generating meaningful questions regarding the task procedures in real time and applying the results to modify its task plans or behaviors. However, few studies on integrating robot task management and HRI in such high-level task planning exist. In this paper, we propose a new scheme of script-based task planning and HRI that supports the planning and is generated by it. The planning operates on a set of plain and easily writable task procedures, or scripts. The approach produces robust, practical, and easy-to-manipulate robot behavior. Based on the scripts, the system identifies plan ambiguities that require interaction with humans, and resolves them using the human response. The interaction thus generated is highly relevant and task-oriented. The robot learns from the interaction history to improve its subsequent planning in general, or personalize it. Two simulation cases, of a home service and a museum-guide robot, are presented to show how the robots lead appropriate interaction and smoothly adjust their task plans to user commands or responses. Such close integration of HRI and robot task planning is expected to advance the practicality of service robots.","2168-2232","","10.1109/TSMC.2014.2298214","Nuclear Research and Development Program of the National Research Foundation grant funded by the Korean Government; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6718138","Human-robot interaction;script-based task planning;service robot;task-oriented interaction;Human–robot interaction;script-based task planning;service robot;task-oriented interaction","Planning;Service robots;Collaboration;Concrete;Cognition;Abstracts","human-robot interaction;intelligent robots;mobile robots;service robots","task-oriented service robot interaction generation;human-robot interaction;robot capability enhancement;human-robot collaboration;robot task management;HRI;high-level task planning;script-based task planning;robot behavior;human response;robot learning;museum-guide robot;home service robot;user commands","","17","","68","","21 Jan 2014","","","IEEE","IEEE Journals"
"Statistical Modeling of Visual Attention of Junior and Senior Anesthesiologists During the Induction of General Anesthesia in Real and Simulated Cases","T. Grundgeiger; T. Wurmb; O. Happel","Institute Human-Computer-Media, Julius-Maximilians Universität Würzburg, Würzburg, Germany; Department of Anaesthesia and Critical Care, University Hospital Würzburg, Würzburg, Germany; Department of Anaesthesia and Critical Care, University Hospital Würzburg, Würzburg, Germany","IEEE Transactions on Human-Machine Systems","15 Jul 2020","2020","50","4","317","326","In visually rich working environments, it is important for operators to distribute their visual attention in an optimal fashion in order to operate safely. Computational models can provide a systematic method of investigating the attention distribution of humans. In this article, we reanalyze eye tracking data from anesthesiologists when inducing general anesthesia to test whether the so-called expectancy value version of the salience, effort, expectancy, value (SEEV) model can accommodate the visual attention distribution of anesthesiologists, and to investigate the effect of case (real versus simulated cases) and experience (junior versus senior) on the expectancy value model fit. The overall model fit is good (predicted-observed percentage dwell time correlation of 0.810, R2 = 0.656). We observe that the model fit is better in simulated cases than real ones. In addition, the model fit is good for junior anesthesiologists independent of the case, but that there is an even better model fit in simulated cases than in real ones for senior anesthesiologists (case × experience interaction). Overall, the expectancy value model can be validated. However, at least within the context of anesthesiology, the full SEEV model may be needed to capture the large and distractive visual work environment of anesthesiologists. From a practical point of view, previous research suggested that anesthesiologists pay more attention to monitoring in simulated cases. However, the SEEV analysis suggests that anesthesiologists do not pay extra attention to monitoring equipment in simulated cases, but may not be able to pay enough attention to monitoring equipment in real cases.","2168-2305","","10.1109/THMS.2020.2983817","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9082594","Attention allocation;anesthesiology;salience;effort;expectancy;value (SEEV) model;simulation","Visualization;Task analysis;Data models;Monitoring;Anesthesia;Predictive models;Mathematical model","data visualisation;decision making;human computer interaction;statistical analysis;user interfaces","statistical modeling;senior anesthesiologists;visually rich working environments;computational models;general anesthesia;expectancy value version;visual attention distribution;simulated cases;expectancy value model fit;junior anesthesiologists;SEEV model;large work environment;distractive visual work environment;junior anesthesiologists","","","","35","IEEE","30 Apr 2020","","","IEEE","IEEE Journals"
"Observations on and modifications to the Rutgers Master to support a mixture of passive haptics and active force feedback","C. W. Borst; R. A. Volz","Center for Adv. Comput. Studies, Univ. of Louisiana, Lafayette, LA, USA; NA","11th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, 2003. HAPTICS 2003. Proceedings.","2 Apr 2003","2003","","","430","437","We are researching the use of haptic feedback during user interactions with a virtual control panel. One approach we consider is a combination of passive haptics and active force feedback. We use a static panel for the passive component and a Rutgers Master system for the active component. This mixed approach requires higher spatial accuracy and haptic quality than has been required by previous applications of force-feedback gloves. We relate the capabilities and limitations of the device to the requirements of our approach and describe a number of developments that result in a successful mix of passive haptics and active force feedback. These are useful for other applications of the device, and some can be generalized to other equipment.","","0-7695-1890-7","10.1109/HAPTIC.2003.1191335","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1191335","","Haptic interfaces;Force feedback;Virtual environment;Displays;Application software;Computer science;Force control;Virtual reality;Software systems;Control systems","haptic interfaces;force feedback;virtual reality;interactive devices","Rutgers Master;passive haptics;active force feedback;virtual environment;haptic feedback;user interactions;static panel;spatial accuracy;force-feedback gloves","","4","","10","","2 Apr 2003","","","IEEE","IEEE Conferences"
"Pattern recognition as a key technology for the next generation of user interfaces","M. Rauterberg; P. Steiger","Swiss Federal Inst. of Technol., Zurich, Switzerland; NA","1996 IEEE International Conference on Systems, Man and Cybernetics. Information Intelligence and Systems (Cat. No.96CH35929)","6 Aug 2002","1996","4","","2805","2810 vol.4","It is time to go beyond the established approaches in human-computer interaction. After a serious critic of command language, menu selection, and desktop interfaces we discuss the two known approaches to overcome the obstacles and limitations: virtual reality (VR), and augmented reality (AR). Both design strategies are diametrically opposed: VR enriches the virtual world with real humans, while AR augments the real world with intelligent features. Only with the AR design strategy humans are able to behave as much as possible in a natural way: behavior of humans in the real world with other humans and/or real world objects. Our interest in human centred design let us follow this idea. Based on the fundamental constraints of natural way of interacting we derive a set of recommendations for the next generation of user interfaces: the natural user interface (NUI). The concept of NUI is discussed in forms of general framework and several NUI-like applications. Finally, we describe the interdisciplinary research topics that must be taken into consideration for a well-designed NUI in the near future.","1062-922X","0-7803-3280-6","10.1109/ICSMC.1996.561385","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=561385","","Pattern recognition;User interfaces;Humans;Virtual reality;Mice;Computer displays;Augmented reality;Application software;Computer graphics;Workstations","human factors;user interfaces;interactive systems;virtual reality;technological forecasting;pattern recognition;computer vision","pattern recognition;natural user interfaces;human-computer interaction;command language;menu selection;desktop interfaces;virtual reality;augmented reality","","6","","51","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Accessibility of Immersive Serious Games for Persons with Cognitive Disabilities","P. Guitton; H. Sauzéon; P. Cinquin",University of Bordeaux; University of Bordeaux; University of Bordeaux,"2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","443","447","E-learning systems are still not very accessible for persons with disabilities, particularly those with cognitive impairments. It's well known that the training deficit is one of the cause of lower employment rates. In the past, we have addressed this issue by working on the accessibility of MOOCs. We have developed Aiana, a MOOC player with accessibility features based on the fragmentation of information streams and enabling user interface self-configuration. We are starting a new research program focused on the accessibility of immersive Serious Games for persons with cognitive impairments by first transposing some of Aiana's design principles. We believe that immersive Serious Games can provide effective assistance to learning for PWDs and we want to demonstrate this rigorously through large field studies. More generally, we wonder about the questions raised by the accessibility of Mixed Reality tools in immersive e-learning systems.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951894","accessibility;e-learning;serious-games;immersion","Augmented reality","cognition;computer based training;educational courses;handicapped aids;human computer interaction;serious games (computing);virtual reality","immersive serious games;cognitive impairments;training deficit;employment rates;MOOC player;immersive e-learning systems;Aiana design principles;user interface self-configuration;person with cognitive disabilities;information stream fragmentation;PWDs;mixed reality tools","","","","31","","9 Jan 2020","","","IEEE","IEEE Conferences"
"The Touch Thimble: Providing Fingertip Contact Feedback During Point-Force Haptic Interaction","K. J. Kuchenbecker; D. Ferguson; M. Kutzer; M. Moses; A. M. Okamura","General Robotics, Automation, Sensing, and Perception (GRASP) Lab, Mechanical Engineering and Applied Mechanics Department, University of Pennsylvania, kuchenbecker@seas.upenn.edu; Laboratory for Computational Sensing and Robotics (LCSR), Mechanical Engineering Department, Johns Hopkins University, dfergu11@jhu.edu; Laboratory for Computational Sensing and Robotics (LCSR), Mechanical Engineering Department, Johns Hopkins University; Applied Physics Laboratory, Johns Hopkins University, michael.kutzer@jhuapl.edu; Laboratory for Computational Sensing and Robotics (LCSR), Mechanical Engineering Department, Johns Hopkins University, matt.moses@jhu.edu; Laboratory for Computational Sensing and Robotics (LCSR), Mechanical Engineering Department, Johns Hopkins University, aokamura@jhu.edu","2008 Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems","31 Mar 2008","2008","","","239","246","Touching a real object with your fingertip provides simultaneous tactile and force feedback, yet most haptic interfaces for virtual environments can convey only one of these two essential modalities. To address this opportunity, we designed, prototyped, and evaluated the Touch Thimble, a new fingertip device that provides the user with the cutaneous sensation of making and breaking contact with virtual surfaces. Designed to attach to the endpoint of an impedance-type haptic interface like a SensAble Phantom, the Touch Thimble includes a slightly oversize cup that is suspended around the fingertip by passive springs. When the haptic interface applies contact forces from the virtual environment, the springs deflect to allow contact between the user's fingertip and the inner surface of the cup. We evaluated a prototype Touch Thimble against a standard thimble in a formal user study and found that it did not improve nor degrade subjects' ability to recognize smoothly curving surfaces. Although four of the eight subjects preferred it to the standard interface, overall the Touch Thimble made subjects slightly slower at recognizing the presented shapes. Detailed subject comments point out strengths and weaknesses of the current design and suggest avenues for future development of the device.","2324-7355","978-1-4244-2005-6","10.1109/HAPTICS.2008.4479950","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4479950","H.1.2 [Models and Principles]: User/Machine Systems¿Human Information Processing;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems¿Artificial, augmented, and virtual realities;H.5.2 [Information Interfaces and Presentation]: User Interfaces¿Haptic I/O","Haptic interfaces;Virtual environment;Springs;Force feedback;Virtual prototyping;Surface impedance;Imaging phantoms;Prototypes;Degradation;Shape","force feedback;haptic interfaces;springs (mechanical)","Touch Thimble;fingertip contact feedback;point-force haptic interaction;force feedback;haptic interfaces;virtual environments;cutaneous sensation;virtual surfaces;passive springs;contact forces","","35","1","24","","31 Mar 2008","","","IEEE","IEEE Conferences"
"Interaction-Oriented Service Entity Placement in Edge Computing","Y. Liang; J. Ge; S. Zhang; J. Wu; L. Pan; T. Zhang; B. Luo","State Key Lab. for Novel Software Technology, Software Institute, Nanjing University, Nanjing, China; State Key Lab. for Novel Software Technology, Software Institute, Nanjing University, Nanjing, China; Department of Computer Science and Technology, State Key Lab. for Novel Software Technology, Nanjing University, Nanjing, China; Center for Networked Computing, Temple University, Philadelphia, PA, USA; State Key Lab. for Novel Software Technology, Software Institute, Nanjing University, Nanjing, China; State Key Lab. for Novel Software Technology, Software Institute, Nanjing University, Nanjing, China; State Key Lab. for Novel Software Technology, Software Institute, Nanjing University, Nanjing, China","IEEE Transactions on Mobile Computing","3 Feb 2021","2021","20","3","1064","1075","Distributed Interactive Applications (DIAs) such as virtual reality and multiplayer online game usually require fast processing of tremendous data and timely exchange of delay-sensitive action data and metadata. This makes traditional mobile-based or cloud-based solutions no longer effective. Thanks to edge computing, DIA Service Providers (DSPs) can rent resources from Edge Infrastructure Providers (EIPs) to place service entities that store user states and run computation-intensive tasks. One fundamental problem for a DSP is to decide where to place service entities to achieve low-delay pairwise interactions between DIA users, under the constraint that the total placement cost is no more than a specified budget threshold. In this article, we formally model the service entity placement problem and prove that it is NP-complete by a polynomial reduction from the set cover problem. We present GPA, an efficient algorithm for service entity placement, and theoretically analyze its performance. We evaluated GPA with both real-world data trace-driven simulations, and observed that GPA performs close to the optimal algorithm and generally outperforms the baseline algorithm. We also output a curve showing the trade-off between the weighted average interaction delay and the budget threshold, so that a DSP can choose the right balance.","1558-0660","","10.1109/TMC.2019.2952097","National Key R&D Program of China; NSFC; Natural Science Foundation of Jiangsu Province; CCF-Tencent Open Fund; Collaborative Innovation Center of Novel Software Technology and Industrialization; Open Foundation of State key Laboratory of Networking and Switching Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894371","Edge computing;distributed interactive applications;interaction delay;service entity placement","Servers;Delays;Edge computing;Mobile computing;Cloud computing;Games;Task analysis","cloud computing;computational complexity;computer games;optimisation;virtual reality","edge computing;distributed interactive applications;DIA;virtual reality;delay-sensitive action data;metadata;edge infrastructure providers;service entities;computation-intensive tasks;low-delay pairwise interactions;total placement cost;specified budget threshold;service entity placement problem;set cover problem;GPA;real-world data trace-driven simulations;weighted average interaction delay;interaction-oriented service entity placement;mobile-based cloud-based solutions;DIA service providers","","2","","33","IEEE","8 Nov 2019","","","IEEE","IEEE Journals"
"Virtual environment for on-campus orientation","R. Larmore; M. Knaus; S. Dascalu; F. C. Harris","Dept. of Comput. Sci. & Eng., Nevada Univ., Reno, NV, USA; Dept. of Comput. Sci. & Eng., Nevada Univ., Reno, NV, USA; Dept. of Comput. Sci. & Eng., Nevada Univ., Reno, NV, USA; Dept. of Comput. Sci. & Eng., Nevada Univ., Reno, NV, USA","Proceedings of the 2005 International Symposium on Collaborative Technologies and Systems, 2005.","19 Dec 2005","2005","","","259","266","This paper presents details of the specification, design and functionality of the virtual UNR campus software (in short, VCampus), an interactive virtual environment that allows users to explore the 3D representation of the University of Nevada, Reno. VCampus provides a realistic-rendering of the university and allows users to obtain useful information such as building names and directories, university historical and statistical data, events scheduled to take place on campus, and area maps centered on specified locations. The users can navigate through the 3D representation of the campus by adopting either a first or a third person view and by selecting either a walking or a flying exploration mode. Various graphical objects can be accessed in the environment to obtain orientation data and general information, a guided tour is available, and communication and collaboration with peers is supported by a multi-user, multi-character real-time interaction facility. The paper also includes a comparison of VCampus with similar projects, a discussion of the environment's advantages and limitations, and a set of pointers to future research and development work","","0-7695-2387-0","10.1109/ISCST.2005.1553321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1553321","","Virtual environment;Legged locomotion;Collaborative work;Research and development;Collaborative software;Software design;Computer science;Design engineering;Buildings;Navigation","educational administrative data processing;formal specification;rendering (computer graphics);virtual reality","interactive virtual environment;on-campus orientation;virtual UNR campus software;realistic-rendering;3D representation;flying exploration mode;graphical object;multicharacter real-time interaction facility","","4","1","23","","19 Dec 2005","","","IEEE","IEEE Conferences"
"Building a General Purpose Pedagogical Agent in a Web-Based Multimedia Clinical Simulation System for Medical Education","Y. Cheng; L. Chen; H. Huang; S. Weng; Y. Chen; C. Lin","Shu Te University, Kaohsiung; National Cheng Kung University, Tainan; National Cheng Kung University, Tainan; National Cheng Kung University, Tainan; National Cheng Kung University, Tainan; National Cheng Kung University, Tainan","IEEE Transactions on Learning Technologies","11 Sep 2009","2009","2","3","216","225","In medical education, pedagogical agents are widely used by computer learning systems to simulate tutors and/or mimic tutoring interactions, as well as offering just-in-time and adaptive feedback. Although the theoretical aspect of the pedagogical agents has been well-documented in literature, relatively fewer efforts have been made on how a pedagogical agent should be implemented in a real multimedia computerized simulation learning environment. In this paper, we propose a general purpose pedagogical agent architecture and implement it in the multimedia medical simulation Web-based learning system called health information network teaching system (HINTS) to further facilitate students' learning and thereby make the HINTS a more helpful educational tool. Our focus is the design of the general purpose pedagogical architecture and its implementation in a multimedia computerized simulation learning environment. A preliminary students' performance evaluation result is also reported. We analyzed how to evaluate the students' performance and how the hints were given by the pedagogical agent. The system has been installed in the National Cheng Kung University Medical Center, Tainan, Taiwan for trial purposes. Some experiments have been conducted and the results have shown that the pedagogical agent indeed help the students in their learning process.","1939-1382","","10.1109/TLT.2009.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4815202","e-Learning for medical education;pedagogical agent;computer-assisted learning;virtual peers;human-computer interaction;learning companions.","Education;Multimedia communication;Computational modeling;Multimedia systems;Laboratories;Medical diagnostic imaging;Data mining","biomedical education;computer aided instruction;digital simulation;hospitals;Internet;medical computing;multimedia computing;teaching","medical education;Web-based multimedia clinical simulation;general purpose pedagogical agent architecture;computer learning system;adaptive feedback;HINTS;health information network teaching system;National Cheng Kung University Medical Center;Taiwan","","21","","35","","17 Apr 2009","","","IEEE","IEEE Journals"
"Simulating rigid robots constrained by stiff contact","G. Ferretti; C. Maffezzoni; G. Magnani","Dipartimento di Elettronica, Politecnico di Milano, Italy; Dipartimento di Elettronica, Politecnico di Milano, Italy; NA","Fifth International Conference on Advanced Robotics 'Robots in Unstructured Environments","6 Aug 2002","1991","","","1461","1464 vol.2","A simulation environment, based on a general purpose differential algebraic equation solver, for the dynamic simulation of robot manipulators moving either in the free space or in interaction with surfaces is presented in the paper. The collision surfaces are modelled either as compliant surfaces or as perfectly rigid surfaces. To show the performance of the simulation environment a case study is considered, that refers to the real robot MANUTEC R3.<>","","0-7803-0078-5","10.1109/ICAR.1991.240534","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=240534","","Manipulator dynamics;Orbital robotics;Differential algebraic equations;Joining processes;Robot motion;Packaging;Robot sensing systems;Sensor systems;Lagrangian functions;Kinematics","algebra;differential equations;digital simulation;mechanical engineering computing;robots","digital simulation;mechanical engineering computing;rigid robots;stiff contact;simulation environment;general purpose differential algebraic equation solver;dynamic simulation;robot manipulators;free space;interaction;collision surfaces;compliant surfaces;perfectly rigid surfaces;MANUTEC R3","","","","9","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Haptic interfaces: a new interaction paradigm","C. A. Avizzano; M. Bergamasco","Simultaneous Presence, Telepresence & Virtual Presence, PERCRO, Pisa, Italy; NA","Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289)","6 Aug 2002","1999","3","","1531","1536 vol.3","Haptic interfaces have ordinarily been used as tools in the exploration of virtual environments as well as masters in teleoperation systems. In these systems the haptic interfaces have been commonly employed only to reproduce and simulate contact experience with a simulated or remote environment. This use is good enough for the realization of high quality simulators such as VETIR. All actions in simulators are generated by a precise set of rules which determine the correct feedback stimuli to be presented to the operator. In the article, haptic interfaces are presented as stand alone systems having their own and independent control. Consequently we explore the control capabilities and we identify a new extended interaction paradigm which provides to the machine the capability of interpreting the human actions and organizing a new high level feedback. The paper introduces a general structure for such a type of systems called reactive systems. A large set of interactive systems, such as tutors, trainers as well as technological aids for rehabilitation can be easily realized with the presented architecture.","","0-7803-5184-3","10.1109/IROS.1999.811696","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=811696","","Haptic interfaces;Humans;Virtual reality;Control systems;Service robots;Rehabilitation robotics;Force feedback;Virtual environment;Organizing;Interactive systems","haptic interfaces;closed loop systems;telerobotics;virtual reality","interaction paradigm;stand alone systems;control capabilities;human actions;high level feedback;reactive systems;tutors;trainers;technological aids;rehabilitation","","3","","14","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Evaluating interactivity and presence in an online distance learning system","M. J. Dark; C. S. York; V. Popescu; C. Nita-Rotaru","Purdue University, USA; Purdue University, USA; Purdue University, USA; Purdue University, USA","2007 37th Annual Frontiers In Education Conference - Global Engineering: Knowledge Without Borders, Opportunities Without Passports","4 Jan 2008","2007","","","T2D-24","T2D-29","A new online distance learning system was created by an interdisciplinary team comprised of computer science, graphics, networking, security, and educational science faculty and graduate students to research, implement, and assess the ability to extend a face-to-face classroom to accommodate remotely located students. Comprised of a face-to-face classroom setting with remote students' images projected on the wall of the classroom, this ""virtual classroom"" is a 3-D rendering of a geometric model populated with real-time video avatars of remote students. Through increased presence, (i.e. being able to view remote students' facial expressions, general body language) and better integration of the virtual classroom into the local classroom, developers intended to increase both learning and motivation to learn. In a formative evaluation regarding the ""presence"" and ""interactivity"" afforded by the system, the following elements were analyzed: learning; social, cognitive, and physical presence; student-to-content interaction; and student-to-technology interaction. This paper reports on this new distance learning technology and the evaluation used to assess its effectiveness.","2377-634X","978-1-4244-1083-5","10.1109/FIE.2007.4417854","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4417854","Evaluation;Interaction;Online distance learning;Presence;Virtual environment","Computer aided instruction;Virtual environment;Avatars;Distance learning;Computer science;Computer graphics;Computer security;Rendering (computer graphics);Solid modeling;Prototypes","avatars;computer aided instruction;distance learning;human computer interaction;interactive video;real-time systems;rendering (computer graphics);solid modelling","online distance learning system;face-to-face classroom interactivity;virtual classroom;geometric model 3D rendering;real-time video avatar;student-to-content interaction;student-to-technology interaction","","2","","14","","4 Jan 2008","","","IEEE","IEEE Conferences"
"Numerical simulation of backward wave excitation in Helix-travelling wave tubes","T. M. Autonsen; D. Chernin; B. Levush","Vacuum Electron. Branch, Naval Res. Lab., Washington, DC, USA; NA; NA","IEEE Conference Record - Abstracts. 1999 IEEE International Conference on Plasma Science. 26th IEEE International Conference (Cat. No.99CH36297)","6 Aug 2002","1999","","","90","","Summary form only given. The maximum achievable gain in individual sections of helix type traveling wave amplifiers is limited by the requirement that the device be stable with respect to the excitation of backward waves, Generally, there is a critical length above which the backward wave is absolutely unstable. Whether this length is exceeded in a specific device depends on a number of details that must be computed numerically. We will present a model, based on the TWT simulation code CHRISTINE, in which BWO stability is determined including a number of important effects. These are: the placement of severs, their reflection and transmission coefficients, the profile of attenuation along the interaction length, the presence of a driven signal, and the coupling of forward and backward waves due to asymmetries in the helix support structure. Specifically our model calculates the gain for the coupled forward and backward waves in a specified frequency band. Asymmetries result in a stop band near the pi point formed by the coupling of the forward and backward waves. Here the beam interacts with a composite mode formed by the fundamental spatial harmonic of the forward wave and first spatial harmonic of the backward wave. These modes will have differing coupling coefficients with the beam which we calculate using an improved solution of the tape-helix dispersion equations.","0730-9244","0-7803-5224-6","10.1109/PLASMA.1999.829282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=829282","","Numerical simulation;Plasma waves;Plasma sources;Plasma density;Plasma devices;Laboratories;Couplings;Frequency;Particle beams;Educational institutions","backward wave tubes;digital simulation","numerical simulation;backward wave excitation;helix-travelling wave tubes;traveling wave amplifiers;critical length;absolutely unstable backward wave;CHRISTINE TWT simulation code;severs;reflection coefficients;transmission coefficients;attenuation profile;interaction length;driven signal;asymmetries;forward-backward wave coupling;coupled forward and backward waves;frequency band;stop band;pi point;fundamental spatial harmonic;coupling coefficients;tape-helix dispersion equations","","","","","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Stable haptic interaction with virtual environments","R. J. Adams; B. Hannaford","Dept. of Electr. Eng., Washington Univ., Seattle, WA, USA; NA","IEEE Transactions on Robotics and Automation","6 Aug 2002","1999","15","3","465","474","This paper addresses fundamental stability and performance issues associated with haptic interaction. It generalizes and extends the concept of a virtual coupling network, an artificial link between the haptic display and a virtual world, to include both the impedance and admittance models of haptic interaction. A benchmark example exposes an important duality between these two cases. Linear circuit theory is used to develop necessary and sufficient conditions for the stability of a haptic simulation, assuming the human operator and virtual environment are passive. These equations lead to an explicit design procedure for virtual coupling networks which give maximum performance while guaranteeing stability. By decoupling the haptic display control problem from the design of virtual environments, the use of a virtual coupling network frees the developer of haptic-enabled virtual reality models from issues of mechanical stability.","2374-958X","","10.1109/70.768179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=768179","","Haptic interfaces;Virtual environment;Coupling circuits;Displays;Circuit stability;Impedance;Admittance;Linear circuits;Sufficient conditions;Circuit simulation","virtual reality;force feedback;haptic interfaces;absolute stability;mechanical stability","haptic interface;virtual environments;absolute stability;virtual coupling network;impedance control;admittance models;linear circuit theory;haptic display;virtual reality;force feedback","","432","6","29","","6 Aug 2002","","","IEEE","IEEE Journals"
"Is talking to a simulated robot like talking to a child?","K. Fischer; K. Foth; K. Rohlfing; B. Wrede","University of Southern Denmark, IFKI, Alsion2, DK-6400 Sonderborg, Denmark; University of Hamburg, Department of Informatics, Vogt-Koelln-Str. 30, D-22527, Germany; Bielefeld University, Universitätsstr. 23-25, D-33615, Germany; Bielefeld University, Universitätsstr. 23-25, D-33615, Germany","2011 IEEE International Conference on Development and Learning (ICDL)","10 Oct 2011","2011","2","","1","6","Previous research has found people to transfer behaviors from social interaction among humans to interactions with computers or robots. These findings suggest that people will talk to a robot which looks like a child in a similar way as people talking to a child. However, in a previous study in which we compared speech to a simulated robot with speech to preverbal, 10 months old infants, we did not find the expected similarities. One possibility is that people were targeting an older child than a 10 months old. In the current study, we address the similarities and differences between speech to four different age groups of children and a simulated robot. The results shed light on how people talk to robots in general.","2161-9476","978-1-61284-990-4","10.1109/DEVLRN.2011.6037320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6037320","child-directed speech;human-robot interaction;mindless transfer;fine-tuning","","human computer interaction;human-robot interaction","simulated robot;social interaction;human computer interaction;human robot interaction","","8","","27","","10 Oct 2011","","","IEEE","IEEE Conferences"
"Study of Multimodal Interfaces and the Improvements on Teleoperation","E. Triantafyllidis; C. Mcgreavy; J. Gu; Z. Li","School of Informatics, The University of Edinburgh, Edinburgh, U.K.; School of Informatics, The University of Edinburgh, Edinburgh, U.K.; School of Informatics, The University of Edinburgh, Edinburgh, U.K.; School of Informatics, The University of Edinburgh, Edinburgh, U.K.","IEEE Access","5 May 2020","2020","8","","78213","78227","Research in multimodal interfaces aims to provide immersive solutions and to increase overall human performance. A promising direction is to combine auditory, visual and haptic interaction between the user and the simulated environment. However, no extensive comparison exists to show how combining audiovisuohaptic interfaces would affect human perception and by extent reflected on task performance. Our paper explores this idea and presents a thorough, full-factorial comparison of how all combinations of audio, visual and haptic interfaces affect performance during manipulation. We evaluated how each combination affects the performance in a study (N=25 ) consisting of manipulation tasks with various difficulties. The overall performance was assessed using both subjective measures, by assessing cognitive workload and system usability, and objective measurements, by incorporating time and spatial accuracy-based metrics. The results showed that regardless of task complexity, the combination of stereoscopic-vision with the virtual reality headset increased performance across all measurements by 40%, compared to monocular-vision from a generic display monitor. Besides, using haptic feedback improved outcomes by 10% and auditory feedback accounted for approximately 5% improvement.","2169-3536","","10.1109/ACCESS.2020.2990080","EPSRC Future AI and Robotics for Space; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9076603","Audiovisuohaptic;auditory feedback;haptic feedback;immersive manipulation;immersive teleoperation;multimodal interaction;multimodal interface;virtual reality","Task analysis;Visualization;Haptic interfaces;Robot sensing systems;Robot kinematics;Virtual reality","computer displays;control engineering computing;haptic interfaces;manipulators;stereo image processing;telerobotics;virtual reality","multimodal interfaces;immersive solutions;human performance;auditory interaction;visual interaction;haptic interaction;simulated environment;extensive comparison;audiovisuohaptic interfaces;human perception;task performance;full-factorial comparison;audio interfaces;visual interfaces;haptic interfaces;manipulation tasks;subjective measures;cognitive workload;system usability;objective measurements;spatial accuracy-based metrics;task complexity;haptic feedback improved outcomes","","","","68","CCBY","23 Apr 2020","","","IEEE","IEEE Journals"
"Application of the Analysis Federate in the Joint Advanced Distributed Simulation Joint Test Force Electronic Warfare Phase II test","W. S. Murphy; M. L. Roane","TRADOC Anal. Center, Monterey, CA, USA; NA","WSC'99. 1999 Winter Simulation Conference Proceedings. 'Simulation - A Bridge to the Future' (Cat. No.99CH37038)","6 Aug 2002","1999","2","","1109","1117 vol.2","The Analysis Federate (AF) is a general-purpose High Level Architecture (HLA) data collection, analysis and visualization tool. THe AF was designed to be composable across HLA federations that use different object model abstractions in their federation object models (FOM). This composability is provided by a conceptual framework that includes fourth-generation development tools that automate the procedures required for a federate to subscribe, publish and interpret federation data. Many of these automated procedures could not be used when the AF was applied in support of the Joint Advanced Distributed Simulation (JADS) Joint Test Force (JTF). The JADS federation did not take the mainstream HLA implementation approach; instead, they developed and implemented federation-specific policies that were necessary to provide the interoperability support that exceeded the HLA baseline. The approach they took was to include objects and interactions in the JADS FOM that were named byte streams of specified sizes. The data structure definitions that were required to decode these byte streams were not documented in the FOM. In the absence of these automation procedures, the AF was manually composed application in the JADS federation. Analysis of the manual composability procedures that were used suggests that they could have been automated if the problem was looked at from a different level of abstraction. A discussion of the application of the AF in the JADS federation and a system design for automating the composability of a federate in federations whose FOMs use named data structures is presented.","","0-7803-5780-9","10.1109/WSC.1999.816828","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=816828","","Analytical models;Computational modeling;Computer simulation;Electronic equipment testing;Automation;Data structures;Computer networks;Electronic warfare;Data analysis;Data visualization","digital simulation;electronic warfare;military computing;software architecture;distributed programming;open systems;data structures;naming services;testing;data analysis;data visualisation","Analysis Federate;Joint Advanced Distributed Simulation;Joint Test Force Electronic Warfare Phase II test;High Level Architecture;data collection tool;data analysis tool;data visualization tool;federate composability automation;HLA federations;object model abstractions;federation object models;4th-generation development tools;JADS federation;federation-specific policies;interoperability support;named byte streams;undocumented data structure definitions;abstraction level;system design;named data structures","","","","10","","6 Aug 2002","","","IEEE","IEEE Conferences"
"A coupling library for the force dimension haptic devices and the 20-sim modelling and simulation environment","F. Sanfilippo; P. B. T. Weustink; K. Y. Pettersen","Department of Maritime Technology and Operations, Aalesund University College, Postboks 1517, 6025 Aalesund, Norway; Controllab Products B.V. Hengelosestraat, 500, 7521 AN Enschede, Netherlands; Department of Engineering, Cybernetics, Norwegian University of Science and Technology, 7491 Trondheim, Norway","IECON 2015 - 41st Annual Conference of the IEEE Industrial Electronics Society","28 Jan 2016","2015","","","000168","000173","A haptic feedback device is a device that establishes a kinaesthetic link between a human operator and a computer-generated environment. This paper addresses the bidirectional coupling between a commercial off-the-shelf (COTS) haptic feedback device and a general-purpose modelling and simulation environment. In particular, an open-source library is developed to couple the Force Dimension omega.7 haptic device with the 20-sim modelling and simulation environment. The presented coupling interface is also compatible with all the different haptic devices produced by Force Dimension. The proposed integrated haptic interface makes it possible to track the user's motion, detect collisions between the user-controlled probe and virtual objects, compute reaction forces in response to motion or contacts and exert an intuitive force feedback on the user. A real-time one-to-one correspondence between reality and virtual reality can be transparently created. This allows for a variety of possible applications. Stability issues, performance issues, design and virtual prototyping challenges can be addressed and investigated for research purposes. In addition, design and virtual prototyping are also of interest to industry. Realistic training environments can be developed for the user considering different possible operations and stressing the importance of usability and user experience. Experiments based on using haptics technology in the field of education can also be easily performed. To demonstrate the potential of the proposed coupling, a case study is presented. Related simulations and experimental results are carried out.","","978-1-4799-1762-4","10.1109/IECON.2015.7392094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7392094","Haptics;Human-computer interaction;Simulation","Haptic interfaces;Solid modeling;Libraries;Couplings;Force;Computational modeling;Programming","force feedback;haptic interfaces;human computer interaction;motion estimation;public domain software;virtual reality","haptics technology;realistic training environments;virtual prototyping;virtual reality;real-time one-to-one correspondence;virtual objects;user-controlled probe;collision detection;user motion detection;integrated haptic interface;force dimension;coupling interface;haptic feedback devices;simulation environment;20-sim modelling;force dimension haptic devices;coupling library","","4","","13","","28 Jan 2016","","","IEEE","IEEE Conferences"
"A concept for the integrated process description, PLC programming and simulation using Petri nets: application in a production process","I. A. Antonzadis; V. I. N. Leopoulos","Machine Design & Control Syst. Sect., Nat. Tech. Univ. of Athens, Greece; NA","Smc 2000 conference proceedings. 2000 ieee international conference on systems, man and cybernetics. 'cybernetics evolving to systems, humans, organizations, and their complex interactions' (cat. no.0","6 Aug 2002","2000","4","","2443","2448 vol.4","Despite the development of a variety of PLC/DCS system programming tools and analysis methods, the programming and, more generally, the automation system synthesis approach still includes a significant degree of automation expertise, in order to overcome problems resulting from process complexity, inadequate process description or final application verification. For a more systematic design of the automation application, initial concepts and guidelines are proposed, based on the concurrent operation of a number of Petri-net based modules that are structured in the form of a cooperating network. This network can include modules ranging from the highest possible level of the application (""master coordinating module"") to the finest levels of the individual equipment (e.g ""motor"" or ""valve"" modules). These modules include not only the traditional ""automation"" or ""programming"" modules, but also modules for the modeling of physical behavior of the system under automation, as well as fault handling elements. These concepts are demonstrated in an industrial application. The use of a unified Petri-net structure for the integrated description of the application facilitates the overall analysis, radically reduces the design, installation and re-engineering time and increases the flexibility of the system.","1062-922X","0-7803-6583-6","10.1109/ICSMC.2000.884358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=884358","","Programmable control;Petri nets;Design automation;Automatic programming;Production planning;Control system synthesis;Automatic control;Guidelines;Electrical equipment industry;Industrial control","Petri nets;programmable controllers;production control;industrial control;digital simulation;programming;control system CAD;control system analysis computing;discrete event systems","integrated process description;PLC programming;simulation;Petri nets;production process;PLC/DCS system;automation system synthesis approach;cooperating network","","1","","14","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Joint manipulation management in collaborative virtual environments","Xiaojun Shen; N. D. Georganas","Sch. of Inf. Technol. & Eng., Ottawa Univ., Ont., Canada; Sch. of Inf. Technol. & Eng., Ottawa Univ., Ont., Canada","The 2nd IEEE Internatioal Workshop on Haptic, Audio and Visual Environments and Their Applications, 2003. HAVE 2003. Proceedings.","10 Nov 2003","2003","","","95","99","Some international standards have been developed that are very likely to make a major impact on CVE (Collaborative Virtual Environment) technology: the Distributed Interactive Simulation (DIS) (IEEE Standard 1278.1) and the High Level Architecture (HLA) (IEEE Standard 1516). Deriving from military-purpose simulations, DIS and HLA, however, have limitations on building large-scale general-purpose CVE applications. For instance, HLA object-attribute based ownership management only allows joint manipulation in a constraint-based solution. The purpose of this research effort is to realize joint manipulation management in CVE. This paper begins with a discussion of interaction requests and interaction model and proceeds to describe three generic approaches for joint manipulation management: Constraint-based, Synchronized and Non Synchronized.","","0-7803-8108-4","10.1109/HAVE.2003.1244732","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1244732","","Environmental management;Virtual environment;Standards development;International collaboration;Information technology;Electronic mail;Buildings;Large-scale systems;Computer networks;Control systems","virtual reality;groupware;IEEE standards","collaborative virtual environments;joint manipulation management;constraint-based interaction;nonsynchronized interaction;distributed interactive simulation;IEEE Standard 1278.1;high level architecture;IEEE Standard 1516;object-attribute based ownership management","","3","","10","","10 Nov 2003","","","IEEE","IEEE Conferences"
"High performance explicit force control for finger interaction haptic interface","S. Marcheschi; F. Salsedo; M. Fontana; F. Tarri; O. Portillo-Rodriguez; M. Bergamasco","PERCRO Scuola Superiore Sant'Anna, Italy; PERCRO Scuola Superiore Sant'Anna, Italy; PERCRO Scuola Superiore Sant'Anna, Italy; PERCRO Scuola Superiore Sant'Anna, Italy; PERCRO Scuola Superiore Sant'Anna, Italy; PERCRO Scuola Superiore Sant'Anna, Italy","Second Joint EuroHaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems (WHC'07)","2 Apr 2007","2007","","","464","469","The requirements for a high performance haptic interface (HI) can arise from demanding VR applications such as the marketing on line of novel textiles or garments. Aiming at the improvement of the performance of the device, the integration of an explicit force control (i.e. a control making use of force measurement) on a HI, originally conceived for open loop control, may prove to be very challenging from the system stability point of view. This paper proposes a methodology for the dimensioning of a motion based explicit force control on the basis of the dynamic parameters of the plant (HI + human). The methodology highlights how the design solutions generally adopted for His intended for open loop force control can hinder the stability of the system when integrated with a closed loop force control","","0-7695-2738-8","10.1109/WHC.2007.69","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4145218","","Force control;Fingers;Haptic interfaces;Open loop systems;Stability;Virtual reality;Textiles;Clothing;Control systems;Force measurement","force control;haptic interfaces;open loop systems;stability;virtual reality","force control;finger interaction haptic interface;open loop control;system stability","","9","","14","","2 Apr 2007","","","IEEE","IEEE Conferences"
"Teaming Up with Virtual Humans: How Other People Change Our Perceptions of and Behavior with Virtual Teammates","A. Robb; A. Cordar; S. Lampotang; C. White; A. Wendling; B. Lok","Department of Computer Science, Engineering at the University of Florida; Department of Computer Science, Engineering at the University of Florida; Department of AnesthesiologyUF College of Medicine; School of Medicine; Department of AnesthesiologyUF College of Medicine; Department of Computer Science, Engineering at the University of Florida","IEEE Transactions on Visualization and Computer Graphics","20 Mar 2015","2015","21","4","511","519","In this paper we present a study exploring whether the physical presence of another human changes how people perceive and behave with virtual teammates. We conducted a study (n = 69) in which nurses worked with a simulated health care team to prepare a patient for surgery. The agency of participants' teammates was varied between conditions; participants either worked with a virtual surgeon and a virtual anesthesiologist, a human confederate playing a surgeon and a virtual anesthesiologist, or a virtual surgeon and a human confederate playing an anesthesiologist. While participants perceived the human confederates to have more social presence (p <; 0.01), participants did not preferentially agree with their human team members. We also observed an interaction effect between agency and behavioral realism. Participants experienced less social presence from the virtual anesthesiologist, whose behavior was less in line with participants' expectations, when a human surgeon was present.","1941-0506","","10.1109/TVCG.2015.2391855","NSF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7014272","Virtual/digital characters;mixed reality;training;user studies;Virtual/digital characters;mixed reality;training;user studies","Surgery;Training;Avatars;Virtual environments;Virtual groups;Mathematical model;Speech","behavioural sciences computing;health care;human computer interaction;medical computing;surgery;telemedicine;virtual reality","virtual human;virtual teammates;health care;surgery;virtual surgeon;virtual anesthesiologist;interaction effect;social presence","Adult;Aged;Anesthesiology;Computer Graphics;Female;General Surgery;Humans;Male;Middle Aged;Patient Care Team;Social Perception;User-Computer Interface","7","","30","","19 Jan 2015","","","IEEE","IEEE Journals"
"Case study of the development app of infographics design with mobile augmented reality","C. Chiu; C. Lee","National Taipei University of Technology, No 1, Sec. 3, Zhongxiao E. Rd. Taipei 10608 Taiwan, R.O.C.; Lai-Chung Lee National Taipei University of Technology, No 1, Sec. 3, Zhongxiao E. Rd. Taipei 10608 Taiwan, R.O.C.","2016 International Conference on Advanced Materials for Science and Engineering (ICAMSE)","6 Feb 2017","2016","","","181","184","Today, cultural and creative centers exist in all of the cities and counties in Taiwan and hold numerous events to attract crowds. In response to the arrival of the digital humanities era, this study aimed to develop a novel app that posts information on cultural events. With the assistance of the app and a geographic information system (GIS), the general public or students in senior high school or above can receive the latest information on arts and culture events around them and then actively participate in them as well as gather companions. With numerous apps coming out or being eliminated every day, research has found that smartphone users rarely read information in text form carefully but prefer information presented in a simple and visualized form. The inclusion of augmented reality (AR) interactions makes users more willing to use an app. We first conducted a questionnaire survey to understand user preferences with regard to layout and interface operations. Based on the results, we developed prototypes for the IOS/Android OS environments and incorporated open data for synchronized updates on cultural events. In addition to providing information on cultural events, the app also offers instant access to desired information via AR and infographics. Furthermore, the app can serve as a future source of big data for the analysis of information such as user preferences with regard to cultural events and travel route planning. It is hoped that this achievement can help more people understand more about cultural events throughout Taiwan and be extended to private cultural events and exhibitions.","","978-1-5090-3869-5","10.1109/ICAMSE.2016.7840274","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7840274","geographic information system;digital humanities;mobile augmented reality;infographics","Cultural differences;Geographic information systems;Mobile communication;Art;Augmented reality;Mobile handsets","Android (operating system);augmented reality;educational institutions;geographic information systems;graphical user interfaces;humanities;iOS (operating system);mobile computing;smart phones","infographics design development app;mobile augmented reality;digital humanities;cultural events;geographic information system;GIS;senior high school;smartphone users;iOS environment;Android OS environment","","","","5","","6 Feb 2017","","","IEEE","IEEE Conferences"
"Active Exploration and Parameterized Reinforcement Learning Applied to a Simulated Human-Robot Interaction Task","M. Khamassi; G. Velentzas; T. Tsitsimis; C. Tzafestas","Inst. of Intell. Syst. & Robot., UPMC Univ. Paris 06, Paris, France; Sch. of Electr. & Comput. Eng., Nat. Tech. Univ. of Athens, Athens, Greece; Sch. of Electr. & Comput. Eng., Nat. Tech. Univ. of Athens, Athens, Greece; Sch. of Electr. & Comput. Eng., Nat. Tech. Univ. of Athens, Athens, Greece","2017 First IEEE International Conference on Robotic Computing (IRC)","15 May 2017","2017","","","28","35","Online model-free reinforcement learning (RL) methods with continuous actions are playing a prominent role when dealing with real-world applications such as Robotics. However, when confronted to non-stationary environments, these methods crucially rely on an exploration-exploitation trade-off which is rarely dynamically and automatically adjusted to changes in the environment. Here we propose an active exploration algorithm for RL in structured (parameterized) continuous action space. This framework deals with a set of discrete actions, each of which is parameterized with continuous variables. Discrete exploration is controlled through a Boltzmann softmax function with an inverse temperature β parameter. In parallel, a Gaussian exploration is applied to the continuous action parameters. We apply a meta-learning algorithm based on the comparison between variations of short-term and long-term reward running averages to simultaneously tune β and the width of the Gaussian distribution from which continuous action parameters are drawn. We first show that this algorithm reaches state-of-the-art performance in the non-stationary multi-armed bandit paradigm, while also being generalizable to continuous actions and multi-step tasks. We then apply it to a simulated human-robot interaction task, and show that it outperforms continuous parameterized RL both without active exploration and with active exploration based on uncertainty variations measured by a Kalman-Q-learning algorithm.","","978-1-5090-6724-4","10.1109/IRC.2017.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7926511","reinforcement learning;meta-learning;active exploration;multi-arm bandit;human-robot interaction","Robots;Learning (artificial intelligence);Human-robot interaction;Upper bound;Electronic mail;Gaussian distribution;Uncertainty","Gaussian distribution;human-robot interaction;learning (artificial intelligence)","parameterized reinforcement learning;human-robot interaction task;active exploration algorithm;RL;Boltzmann softmax function;inverse temperature parameter;Gaussian exploration;continuous action parameters;meta-learning algorithm;Gaussian distribution;nonstationary multiarmed bandit paradigm;Kalman-Q-learning algorithm","","5","","21","","15 May 2017","","","IEEE","IEEE Conferences"
"Using augmented reality in urban context: Georeferenced system for business localization using Google Glass","L. Ferrer; J. Garcia-Mancilla; V. M. Gonzalez; S. Bermudez; P. Bleier; C. Prieto","Department of Computer Science, Instituto Tecnológico Autonomo de México (ITAM) Mexico City, México; Department of Computer Science, Instituto Tecnológico Autonomo de México (ITAM) Mexico City, México; Department of Computer Science, Instituto Tecnológico Autonomo de México (ITAM) Mexico City, México; Department of Computer Science, Instituto Tecnológico Autonomo de México (ITAM) Mexico City, México; Department of Computer Science, Instituto Tecnológico Autonomo de México (ITAM) Mexico City, México; Department of Computer Science, Instituto Tecnológico Autonomo de México (ITAM) Mexico City, México","2015 IEEE First International Smart Cities Conference (ISC2)","28 Dec 2015","2015","","","1","6","Developing new paradigms of user interaction is always challenging. The introduction of the Google Glass platform presents a novel way to deliver content to users. Clearly, the Glass platform is not going to become a mainstream consumer electronics product as it is; however it was an experimental program from which important practical lessons can be learned. We, as part of the Google Glass Explorer Community, present this study as a contribution to the practical understanding of products that can be core for the development of micro-interaction-based interfaces for wearable gadgets in urban contexts. Throughout this paper we detail the development process of this kind of application by focusing on the challenges presented, the implementation and design decisions, and the usability tests we performed. The main results were that the use of the app is intuitive in general, but the users have problems identifying several components that were adapted for the size of the screen and the concept of the device.","","978-1-4673-6552-9","10.1109/ISC2.2015.7366157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7366157","Augmented reality;Google Glass;micro-interactions;georeferenced systems;usability test","5G mobile communication;Yttrium","augmented reality;geographic information systems;user interfaces;wearable computers","augmented reality;georeferenced system;business localization;user interaction;Google Glass explorer community;microinteraction-based interface;wearable gadget;usability test","","1","","10","","28 Dec 2015","","","IEEE","IEEE Conferences"
"Evaluation of virtual fixtures for a robot programming by demonstration interface","J. Aleotti; S. Caselli; M. Reggiani","Dipt. di Ingegneria dell'Informazione, Univ. of Parma, Italy; Dipt. di Ingegneria dell'Informazione, Univ. of Parma, Italy; Dipt. di Ingegneria dell'Informazione, Univ. of Parma, Italy","IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans","20 Jun 2005","2005","35","4","536","545","We investigate the effectiveness of several types of virtual fixtures in a robot programming by demonstration interface. We show that while all types of virtual fixtures examined yield a significant reduction in the number of errors in tight tolerance peg-in-hole tasks, color and sound fixtures generally outperform a tactile fixture in terms of both execution time of successful trials and error rate. We have found also that when users perceive that the task is very difficult but the system is providing some help by means of a virtual fixture, they tend to spend more time trying to achieve a successful task execution. Thus, for difficult tasks the benefits of virtual fixturing are better reflected in a reduction of the error rate than in a decreased execution time. We conjecture that these trends are related to the limitations of currently available interfaces for human-robot interaction through virtual environments and to the different strategies adopted by the users to cope with such limitations in high-accuracy tasks.","1558-2426","","10.1109/TSMCA.2005.850604","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1453701","Human factors;robot programming;user interfaces;virtual reality (VR)","Fixtures;Robot programming;Virtual environment;Error analysis;Virtual reality;Programming profession;Intelligent robots;Psychology;Feedback;User interfaces","robot programming;human computer interaction;task analysis;interactive systems","virtual fixtures;robot programming;demonstration interface;tight tolerance peg-in-hole tasks;task execution;human-robot interaction","","18","","26","","20 Jun 2005","","","IEEE","IEEE Journals"
"Design of an Integration Model for Multimedia Systems for Alternative Reality Games","J. S. V. V.; C. A. R. C.","Programa de Ingeniería en Multimedia, Universidad Militar Nueva Granada,Bogotá,Colombia; Programa de Ingeniería en Multimedia, Universidad Militar Nueva Granada,Bogotá,Colombia","2020 IEEE Games, Multimedia, Animation and Multiple Realities Conference (GMAX)","18 Nov 2020","2020","","","1","4","Alternative reality video games (ARG) have emerged thanks to their flexibility when using as a platform in the real world, proposing new forms of interaction. The objective of this study is to determine how a multimedia systems integration model can be integrated into an ARG game. To this end, the research question is as follows: How can a multimedia system be integrated into an alternative reality game? The research question is answered through the development of an integration model that is supported by the network narrative, which is generally the most widely used in this type of game, giving the possibility of integrating multimedia systems such as nodes of diffusion and interaction of the game narrative.","","978-1-7281-6147-1","10.1109/GMAX49668.2020.9256832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256832","Multimedia Systems;ARG;Augmented Reality;Transmedia","Games;Multimedia systems;Prototypes;Augmented reality;Solid modeling;Media;Computational modeling","augmented reality;computer games;multimedia systems","game narrative;alternative reality game;alternative reality video games;multimedia systems integration model;ARG game;network narrative;augmented reality","","","","7","","18 Nov 2020","","","IEEE","IEEE Conferences"
"Architectural design of ARTeMIS: A multi-tasking robot for people with disabilities","K. Mykoniatis; A. Angelopoulou; J. P. Kincaid","Institute for Simulation and Training, University of Central Florida, Orlando, USA; Institute for Simulation and Training, University of Central Florida, Orlando, USA; Institute for Simulation and Training, University of Central Florida, Orlando, USA","2013 IEEE International Systems Conference (SysCon)","1 Jul 2013","2013","","","269","273","Human-Robot Interaction (HRI) is a research field dedicated to understanding, designing, evaluating and improving the communication between a human and a robot. Technological progress in fields, such as artificial intelligence, computer science, speech simulation, image processing, and remote controls, has led to advances in robotic technology [1]. Interaction between human and robot can be separated into two general categories: remote, where the human and the robot are separated in space or time, and proximate, where the human and the robot may be found in the same location [2]. These two general categories can be further distinguished between applications that require mobility, physical manipulation, or social interaction. Social interactions with robots are more proximate rather than remote. The purpose of this paper is to design the architecture of a robotic system and understand how it might assist people with disabilities and help them stay independent longer. Future work includes verification and validation of the architecture and robotic construction. An experimentation plan will take place in order to evaluate the behavior and performance of the robotic system. The results will be used for the robotic construction.","","978-1-4673-3108-1","10.1109/SysCon.2013.6549893","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549893","Kinect;face recognition;human robot interaction;object recognition;facial expression;obstacle avoidance;gestures;disabilities","Navigation;Robot sensing systems;Robot kinematics;Face recognition;Unified modeling language;Face","architecture;handicapped aids;human-robot interaction;medical robotics","ARTeMIS;multitasking robot;people with disabilities;human-robot interaction;HRI;artificial intelligence;computer science;speech simulation;image processing;remote controls;robotic technology;mobility;physical manipulation;social interactions;robotic system architectural design;robotic construction","","2","","17","","1 Jul 2013","","","IEEE","IEEE Conferences"
"A-EXP4: Online Social Policy Learning for Adaptive Robot-Pedestrian Interaction","P. Jin; E. Ohn-Bar; K. Kitani; C. Asakawa","Authors are affiliated with the Robotics Institute, Carnegie Mellon University,Pittsburgh,USA,PA 15213; Max Planck Institute for Intelligent Systems.; Authors are affiliated with the Robotics Institute, Carnegie Mellon University,Pittsburgh,USA,PA 15213; Authors are affiliated with the Robotics Institute, Carnegie Mellon University,Pittsburgh,USA,PA 15213","2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","28 Jan 2020","2019","","","5086","5093","We study self-supervised adaptation of a robot's policy for social interaction, i.e., a policy for active communication with surrounding pedestrians through audio or visual signals. Inspired by the observation that humans continually adapt their behavior when interacting under varying social context, we propose Adaptive EXP4 (A-EXP4), a novel online learning algorithm for adapting the robot-pedestrian interaction policy. To address limitations of bandit algorithms in adaptation to unseen and highly dynamic scenarios, we employ a mixture model over the policy parameter space. Specifically, a Dirichlet Process Gaussian Mixture Model (DPMM) is used to cluster the parameters of sampled policies and maintain a mixture model over the clusters, hence effectively discovering policies that are suitable to the current environmental context in an unsupervised manner. Our simulated and real-world experiments demonstrate the feasibility of A-EXP4 in accommodating interaction with different types of pedestrians while jointly minimizing social disruption through the adaptation process. While the A-EXP4 formulation is kept general for application in a variety of domains requiring continual adaptation of a robot's policy, we specifically evaluate the performance of our algorithm using a suitcase-inspired assistive robotic platform. In this concrete assistive scenario, the algorithm observes how audio signals produced by the navigational system affect the behavior of pedestrians and adapts accordingly. Consequently, we find A-EXP4 to effectively adapt the interaction policy for gently clearing a navigation path in crowded settings, resulting in significant reduction in empirical regret compared to the EXP4 baseline.","2153-0866","978-1-7281-4004-9","10.1109/IROS40897.2019.8967737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8967737","","","audio signal processing;control engineering computing;Gaussian processes;human computer interaction;learning (artificial intelligence);mixture models;mobile robots;pedestrians","online social policy learning;Adaptive robot-pedestrian interaction;self-supervised adaptation;social interaction;active communication;audio signals;visual signals;social context;Adaptive EXP4;online learning algorithm;robot-pedestrian interaction policy;bandit algorithms;unseen scenarios;highly dynamic scenarios;policy parameter space;Dirichlet Process Gaussian Mixture Model;sampled policies;current environmental context;social disruption;adaptation process;continual adaptation;suitcase-inspired assistive robotic platform;EXP4 baseline;navigation path;crowded settings","","","","45","","28 Jan 2020","","","IEEE","IEEE Conferences"
"Human-centered robotics and haptic interaction: from assistance to surgery, the emerging applications","O. Khatib","Dept. of Comput. Sci., Stanford Univ., CA, USA","Proceedings of the Third International Workshop on Robot Motion and Control, 2002. RoMoCo '02.","19 Feb 2003","2002","","","137","139","Robots are moving towards applications beyond the structured environment of a manufacturing plant, making their way into the everyday world that people inhabit. The discussion focuses on the models, strategies, and algorithms associated with the basic capabilities needed for robots to work, interact, and cooperate with humans. In addition to the new capabilities they bring to the physical robot, these models and algorithms and more generally the overall body of developments in robotics is making a significant impact on the virtual world. Tactile or haptic interaction with an accurate dynamic simulation provides unique insights into the real-world behaviors of physical systems. The potential applications of this emerging technology include virtual prototyping, animation, surgery, teleoperation, cooperative work, and education among many others.","","83-7143-429-4","10.1109/ROMOCO.2002.1177098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1177098","","Human robot interaction;Haptic interfaces;Surgery;Robot kinematics;Orbital robotics;Service robots;Mobile robots;Application software;Motion control;Biological system modeling","telerobotics;robot dynamics;surgery;man-machine systems;haptic interfaces","human-centered robotics;haptic interaction;tactile interaction;virtual prototyping;teleoperation;dynamic environments;human robot interaction;surgery","","8","","4","","19 Feb 2003","","","IEEE","IEEE Conferences"
"A simulation platform for systems analysis theory and applications","D. Thevenard; M. Chandrashekar","Dept. of Syst. Design Eng., Waterloo Univ., Ont., Canada; NA","1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation","6 Aug 2002","1997","1","","896","901 vol.1","The analysis of systems can often benefit from the use of simulation. Simulation can be used to study the behavior of individual components in the system, study the interaction of various components, or fine-tune the set points of control devices. Prosim, a general-purpose simulation platform developed at the University of Waterloo, allows the interactive definition and simulation of individual components. Using drag and drop techniques, individual components can be assembled into larger systems which can be simulated. The outputs of the simulation are available either in numeric or graphical form. Prosim is characterized by its totally interactive approach to simulation, its use of graph-theoretic concepts such as through and nodal variables, and its innovative use of symbolic processing to solve for the state of the system. In this paper we show how Prosim can be used to study the interactions between various components of a system. The system chosen is a directly-coupled solar photovoltaic (PV) water-pumping system. The PV array is used to power an electric motor, which rotates a centrifugal pump circulating water in a closed loop. Inefficiencies resulting from mismatches between the characteristics of the array and the motor are shown with the help of simulations.","1062-922X","0-7803-4053-1","10.1109/ICSMC.1997.626216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=626216","","Analytical models;Systems engineering and theory;Assembly systems;Photovoltaic systems;Solar power generation;Equations;System analysis and design;Design engineering;Electric motors;Buildings","digital simulation;interactive systems;graph theory;engineering graphics;graphical user interfaces;solar cell arrays;power system analysis computing;pumps;photovoltaic power systems","simulation platform;systems analysis theory;control device set point fine-tuning;Prosim;interactive component definition;interactive component simulation;drag-and-drop techniques;totally interactive approach;symbolic processing;directly-coupled solar photovoltaic water-pumping system;PV array;electric motor;centrifugal pump;characteristics mismatches","","","","5","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Helping Robots Learn: A Human-Robot Master-Apprentice Model Using Demonstrations via Virtual Reality Teleoperation","J. DelPreto; J. I. Lipton; L. Sanneman; A. J. Fay; C. Fourie; C. Choi; D. Rus","MIT Distributed Robotics Lab,Cambridge,MA,02139; MIT Distributed Robotics Lab,Cambridge,MA,02139; MIT Interactive Robotics Group,Cambridge,MA,02139; MIT Distributed Robotics Lab,Cambridge,MA,02139; MIT Interactive Robotics Group,Cambridge,MA,02139; MIT Distributed Robotics Lab,Cambridge,MA,02139; MIT Distributed Robotics Lab,Cambridge,MA,02139","2020 IEEE International Conference on Robotics and Automation (ICRA)","15 Sep 2020","2020","","","10226","10233","As artificial intelligence becomes an increasingly prevalent method of enhancing robotic capabilities, it is important to consider effective ways to train these learning pipelines and to leverage human expertise. Working towards these goals, a master-apprentice model is presented and is evaluated during a grasping task for effectiveness and human perception. The apprenticeship model augments self-supervised learning with learning by demonstration, efficiently using the human's time and expertise while facilitating future scalability to supervision of multiple robots; the human provides demonstrations via virtual reality when the robot cannot complete the task autonomously. Experimental results indicate that the robot learns a grasping task with the apprenticeship model faster than with a solely self-supervised approach and with fewer human interventions than a solely demonstration-based approach; 100% grasping success is obtained after 150 grasps with 19 demonstrations. Preliminary user studies evaluating workload, usability, and effectiveness of the system yield promising results for system scalability and deployability. They also suggest a tendency for users to overestimate the robot's skill and to generalize its capabilities, especially as learning improves.","2577-087X","978-1-7281-7395-5","10.1109/ICRA40945.2020.9196754","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9196754","","Robots;Grasping;Task analysis;Three-dimensional displays;Solid modeling;Virtual reality;Pipelines","control engineering computing;human-robot interaction;learning (artificial intelligence);multi-robot systems;robot programming;telerobotics;virtual reality","grasping task;human perception;human-robot master-apprentice model;virtual reality teleoperation;artificial intelligence;self-supervised learning","","1","","50","","15 Sep 2020","","","IEEE","IEEE Conferences"
"Touchscreen-based input technique for people with intention tremor","A. Mertens; D. Koch-Körfges; N. Jochems; C. M. Schlick",Chair and Institute of Industrial Engineering and Ergonomics of RWTH Aachen University; Chair and Institute of Industrial Engineering and Ergonomics of RWTH Aachen University; Chair and Institute of Industrial Engineering and Ergonomics of RWTH Aachen University; Chair and Institute of Industrial Engineering and Ergonomics of RWTH Aachen University,"3rd International Conference on Human System Interaction","23 Jul 2010","2010","","","236","240","Patients with a tremor find it often very difficult to handle IT Systems and therefore attain very low levels of efficiency when doing so. The currently available user interfaces do not guarantee a sufficient precision when data input and selection is performed. People suffering from a intention tremor observe a significant increase in their tremor when approaching their input “destination” on the screen which further increases their discontent towards the process. For this target group a new method of data input has been developed and evaluated, which allows the patient or generally the affected user to input data with a wiping technique on a touch screen. Variations caused by the tremor are compensated with a continuous movement rather than a single direct movement towards a target area. Additionally, the screen surface causes a significant friction and helps to reduce the effects of the tremor. Specially designed heuristics help to identify the user input with a high accuracy and enable a barrier free access among the target group.","2158-2254","978-1-4244-7562-9","10.1109/HSI.2010.5514563","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5514563","HCI;interaction technique;tremor;touchscreen;AAL","User interfaces;Graphical user interfaces;Hardware;Costs;Senior citizens;Industrial engineering;Ergonomics;Friction;Human computer interaction;Parkinson's disease","human computer interaction;touch sensitive screens;user interfaces","touchscreen-based input technique;intention tremor;friction;user interfaces;wiping technique;screen surface","","5","","25","","23 Jul 2010","","","IEEE","IEEE Conferences"
"Teleplanning by human demonstration for VR-based teleoperation of a mobile robotic assistant","C. S. Tzafestas","Inst. of Informatics & Telecommun., Nat. Center for Sci. Res. ""Demokritos"", Athens, Greece","Proceedings 10th IEEE International Workshop on Robot and Human Interactive Communication. ROMAN 2001 (Cat. No.01TH8591)","6 Aug 2002","2001","","","462","467","Focuses on the integration of local path planning techniques in a multimodal teleoperation interface, for the efficient remote control of a mobile robotic assistant. The main principle underlying this scheme is related to finding new ways to establish an efficient human-robot cooperation framework, where humans and robots take charge of the parts of the tasks that they can perform more efficiently. For the teleoperation of a mobile robotic platform, a simple application of this general principle could be to commit the human operator in performing the necessary global planning operations, which are more demanding in terms of complex reasoning and required ""intelligence"", while other more local tasks such as collision avoidance and trajectory optimization are dedicated to the telerobotic system. We propose an implementation of this principle within a mobile robot teleoperation interface integrating virtual reality techniques and Web standards. The paper describes the multimodal interface and the design principles followed, as well as the integration of a local path planning method. This scheme, called ""computer-assisted teleplanning by human demonstration"", aims at providing active assistance to the human operator, enabling him to indicate in a natural way the desired global motion plan, for a more efficient teleoperation of a mobile robotic assistant.","","0-7803-7222-0","10.1109/ROMAN.2001.981947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=981947","","Mobile robots;Human robot interaction;Telerobotics;Path planning;Collision avoidance;Trajectory;Robot sensing systems;Virtual reality;Informatics;Telecommunication control","mobile robots;collision avoidance;telerobotics;virtual reality","teleplanning;human demonstration;VR-based teleoperation;mobile robotic assistant;local path planning techniques;efficient human-robot cooperation framework;complex reasoning;collision avoidance;trajectory optimization;virtual reality techniques;Web standards;local path planning method;wavefront expansion;trajectory modification technique;multimodal teleoperation interface","","6","","15","","6 Aug 2002","","","IEEE","IEEE Conferences"
"NaviBoard and NaviChair: Limited Translation Combined with Full Rotation for Efficient Virtual Locomotion","T. Nguyen-Vo; B. E. Riecke; W. Stuerzlinger; D. -M. Pham; E. Kruijff","School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC, Canada; School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC, Canada; School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC, Canada; School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC, Canada; Institute of Visual Computing, Bonn-Rhein-Sieg University of Applied Sciences, Sankt Augustin, Germany","IEEE Transactions on Visualization and Computer Graphics","24 Nov 2020","2021","27","1","165","177","Walking has always been considered as the gold standard for navigation in Virtual Reality research. Though full rotation is no longer a technical challenge, physical translation is still restricted through limited tracked areas. While rotational information has been shown to be important, the benefit of the translational component is still unclear with mixed results in previous work. To address this gap, we conducted a mixed-method experiment to compare four levels of translational cues and control: none (using the trackpad of the HTC Vive controller to translate), upper-body leaning (sitting on a “NaviChair”, leaning the upper-body to locomote), whole-body leaning/stepping (standing on a platform called NaviBoard, leaning the whole body or stepping one foot off the center to navigate), and full translation (physically walking). Results showed that translational cues and control had significant effects on various measures including task performance, task load, and simulator sickness. While participants performed significantly worse when they used a controller with no embodied translational cues, there was no significant difference between the NaviChair, NaviBoard, and actual walking. These results suggest that translational body-based motion cues and control from a low-cost leaning/stepping interface might provide enough sensory information for supporting spatial updating, spatial awareness, and efficient locomotion in VR, although future work will need to investigate how these results might or might not generalize to other tasks and scenarios.","1941-0506","","10.1109/TVCG.2019.2935730","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809840","Adaptive control;cognitive informatics;human computer interaction;human factors;user interface;virtual reality","Legged locomotion;Task analysis;Navigation;Resists;Wheelchairs;Virtual reality;Input devices","virtual reality","physical translation;rotational information;translational component;mixed-method experiment;HTC Vive controller;NaviChair;NaviBoard;task performance;embodied translational cues;walking;translational body-based motion cues;virtual locomotion;gold standard;navigation;virtual reality;upper-body leaning;whole-body leaning;whole-body stepping;task load;simulator sickness;low-cost leaning interface;low-cost stepping interface;sensory information;spatial updating;spatial awareness","","","","50","IEEE","22 Aug 2019","","","IEEE","IEEE Journals"
"Time domain analysis of harmonic interactions between traction vehicle and DC supply","A. M. Walczynka; P. Janiszewski","Railway Res. Inst., Poland; Railway Res. Inst., Poland","1995 International Conference on Electric Railways in a United Europe","6 Aug 2002","1995","","","186","196","Time domain computer simulation offers the possibility of calculation of harmonics of most complex systems. Although frequency based calculations often offer more general solutions, they cannot be applied in some cases (for example when the converter is controlled by free-running hysteresis control methods). In the paper models of a traction vehicle, substation and a novel model of a 3 kV contact line that represents frequency dependence of its parameters is presented. Selected results of a simulation study of harmonic interactions between a traction vehicle equipped with thyristor converters and the 3 kV supply systems are shown.<>","","0-85296-631-8","10.1049/cp:19950205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=396033","","Simulation;Power system harmonics;Rail transportation;Substations;Thyristor converters;Time domain analysis","digital simulation;electric locomotives;power overhead lines;power system analysis computing;power system harmonics;railways;substations;thyristor convertors;time-domain analysis;traction","traction vehicle;DC supply;time domain computer simulation;harmonic interactions;power converter;free-running hysteresis control;substation;contact line;frequency dependence;thyristor converters;railway;3 kV","","2","","","","6 Aug 2002","","","IET","IET Conferences"
"Mediface: anticipative data entry interface for general practitioners","J. R. Warren; A. Davidovic; S. Spenceley; P. Bolton","Adv. Comput. Rs. Centre, South Australia Univ., Warren, SA, Australia; NA; NA; NA","Proceedings 1998 Australasian Computer Human Interaction Conference. OzCHI'98 (Cat. No.98EX234)","6 Aug 2002","1998","","","192","199","The paper describes an effort to make computer interfaces more intelligent in facilitating the coding of clinical information. We believe the interface should be sufficiently efficient and easy-to-use that a physician can code information during the consultation without detracting from doctor-patient interaction. In this way the benefits of a ""clinical workstation"" setting, such as best practices guidance and drug interaction detection, are maximised. We pursue the strategy of applying machine learning to existing databases of electronic medical records to develop probabilistic models of general practice. Based on this model, we have simulated and prototyped data entry interfaces with ""hot lists"" (short pick list menus of relevant items) and dynamic graphical depictions of contextually likely clinical data.","","0-8186-9206-5","10.1109/OZCHI.1998.732214","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=732214","","Medical diagnostic imaging;Drugs;Medical treatment;Humans;Medical information systems;Machine learning;Hospitals;Identity-based encryption;Best practices;Context modeling","medical information systems;health care;user interfaces;interactive systems;learning (artificial intelligence);medical expert systems;data handling","Mediface;anticipative data entry interface;general practitioners;computer interfaces;clinical information coding;doctor-patient interaction;clinical workstation;best practices guidance;drug interaction detection;machine learning;electronic medical records;probabilistic models;general practice;hot lists;short pick list menus;relevant items;dynamic graphical depictions;contextually likely clinical data","","3","2","25","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Folkways in Wonderland: A Cyberworld Laboratory for Ethnomusicology","R. Ranaweera; M. Frishkopf; M. Cohen","Spatial Media Group, Univ. of Aizu, Aizu-Wakamatsu, Japan; Dept. of Music, Univ. of Alberta, Edmonton, AB, Canada; Spatial Media Group, Univ. of Aizu, Aizu-Wakamatsu, Japan","2011 International Conference on Cyberworlds","17 Nov 2011","2011","","","106","112","In this paper we describe a musical cyber world - a collaborative, immersive virtual environment for browsing musical databases - together with an experimental design launching a new sub discipline: the ethnomusicology of controlled musical cyberspaces. Research in ethnomusicology, the ethnographic study of music in its socio-cultural environment, has typically been conducted through qualitative fieldwork in uncontrolled, real-world settings. Recently, ethnomusicologists have begun to attend to the study of virtual environments, including pre-existing cyber worlds (such as video games). However, in this paper, we adopt an unprecedented approach by designing a custom musical cyber world to serve as a virtual laboratory for the ethnographic study of music. By constructing an immersive cyber world suitable for ethno musicological fieldwork, we aim for much greater control than has heretofore been possible in ethno musicological research, leading to results that may suggest better ways of designing musical cyber worlds for research, discovery, learning, entertainment, and e-commerce, as well as contributing towards our general understanding of the role of music in human interaction and community-formation. Such controlled research can usefully supplement traditional ethnography in the real world.","","978-1-4577-1453-5","10.1109/CW.2011.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6079353","Ethnomusicology;ethnography;fieldwork;cyberworlds;world music;collaborative virtual environment;groupware;Wonderland;spatial music;immersive environment;hypermedia","Avatars;Servers;Computer architecture;Three dimensional displays;Microprocessors;Virtual environments;Collaboration","cultural aspects;design of experiments;groupware;music;virtual reality","cyberworld laboratory;ethnomusicology;musical cyber world;collaborative virtual environment;immersive virtual environment;musical database browsing;experimental design;socio-cultural environment;ethnographic study;entertainment;e-commerce;human interaction;community-formation","","1","","17","","17 Nov 2011","","","IEEE","IEEE Conferences"
"A Stable and Real-Time Nonlinear Elastic Approach to Simulating Guidewire and Catheter Insertions Based on Cosserat Rod","W. Tang; T. R. Wan; D. A. Gould; T. How; N. W. John","School of Computing, the University of Teesside, Middlesbrough, U.K.; Bradford University, Bradford, U.K.; Royal Liverpool University Hospital, Liverpool, U.K.; Liverpool University, Liverpool, U.K.; Bangor University , Bangor, U.K.","IEEE Transactions on Biomedical Engineering","12 Jul 2012","2012","59","8","2211","2218","Interventional Radiology procedures (e.g., angioplasty, embolization, stent graft placement) provide minimally invasive therapy to treat a wide range of conditions. These procedures involve the use of flexible tipped guidewires to advance diagnostic or therapeutic catheters into a patient's vascular or visceral anatomy. This paper presents a real-time physically based hybrid modeling approach to simulating guidewire insertions. The long, slender body of the guidewire shaft is simulated using nonlinear elastic Cosserat rods, and the shorter flexible tip composed of a straight, curved, or angled design is modeled using a more efficient generalized bending model. Therefore, the proposed approach efficiently computes intrinsic dynamic behaviors of guidewire interactions within vascular structures. The efficacy of the proposed method is demonstrated using detailed numerical simulations inside 3-D blood vessel structures derived from preprocedural volumetric data. A validation study compares positions of four physical guidewires deployed within a vascular phantom, with the co-ordinates of the corresponding simulated guidewires within a virtual model of the phantom. An optimization algorithm is also implemented to further improve the accuracy of the simulation. The presented simulation model is suitable for interactive virtual reality-based training and for treatment planning.","1558-2531","","10.1109/TBME.2012.2199319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6200309","Cosserat theory of elastic rod;guidewire insertion;minimally invasive interventions;physically based simulation","Computational modeling;Solid modeling;Materials;Friction;Shafts;Accuracy;Real time systems","catheters;phantoms;radiology;surgery;virtual reality","stable nonlinear elastic approach;real time nonlinear elastic approach;guidewire simulation;catheter insertion simulation;Cosserat rod;interventional radiology;angioplasty;embolization;stent graft placement;minimally invasive therapy;vascular anatomy;visceral anatomy;vascular phantom;interactive virtual reality based training;treatment planning","Algorithms;Aorta, Abdominal;Aortic Aneurysm, Abdominal;Catheterization;Catheterization;Computer Simulation;Humans;Image Processing, Computer-Assisted;Models, Cardiovascular;Nonlinear Dynamics;Phantoms, Imaging;Reproducibility of Results","51","","26","","15 May 2012","","","IEEE","IEEE Journals"
"Where to look and who to be Designing attention and identity for search-and-rescue robots","L. D. Dole; D. M. Sirkin; R. M. Currano; R. R. Murphy; C. I. Nass","Dept. of Communication, Stanford University, CA, USA; Dept. of Communication, Stanford University, CA, USA; Dept. of Communication, Stanford University, CA, USA; Dept. of Computer Science and Engineering, Texas A&M University, College Station, USA; Dept. of Communication, Stanford University, CA, USA","2013 8th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","21 Mar 2013","2013","","","119","120","Participants taking cover from a simulated earthquake interacted with a search-and-rescue robot that paid attention either to them or to the environment, and that they thought was either controlled by a person or autonomous. In general, the robot elicited the strongest positive responses when it focused on participants who thought they were interacting with a person.","2167-2148","978-1-4673-3101-2","10.1109/HRI.2013.6483530","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6483530","human-robot interaction;search and rescue;attention;identity;pure medium;social actor","Educational robots;Atmospheric measurements;Particle measurements;Media;Educational institutions;Earthquakes","earthquakes;human-robot interaction;service robots","search-and-rescue robot;simulated earthquake;human-robot interaction;identity design;attention design","","4","","4","","21 Mar 2013","","","IEEE","IEEE Conferences"
"Virtual 3D Simulation of Fault Diagnosis and its Realization in the Electrical System of Certain Equipment","Z. Liu; S. An; Y. Wang; X. Wang","Dept. of Electron. Eng., Ordnance Eng. Coll., Shijiazhuang, China; Dept. of Electron. Eng., Ordnance Eng. Coll., Shijiazhuang, China; Dept. of Electron. Eng., Ordnance Eng. Coll., Shijiazhuang, China; NA","2012 Second International Conference on Instrumentation, Measurement, Computer, Communication and Control","4 Feb 2013","2012","","","1338","1341","Focusing on the problems existing in conventional maintenance training ways and means which can't adapt to the needs of equipment development, a set of desktop interactive in the electrical system of certain equipment by means of virtual reality techniques was developed. Aimed at the complicated structures and relationships within electrical maintenance, the general functional module of virtual maintenance system was established, the 3 dimension (3D) model nodes of electrical system were rebuilt, and the research on key techniques relevant to maintenance simulation interaction was carried out. The system is in practice proved to be a new way and mean for complicated electrical maintenance training.","","978-1-4673-5034-1","10.1109/IMCCC.2012.315","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6429151","fault diagnosis;virtual maintenance;modal node","Maintenance engineering;Circuit faults;Assembly;Training;Testing;Solid modeling;Instruments","fault diagnosis;geometry;maintenance engineering;power apparatus;power engineering computing;virtual reality","3D geometry model;3 dimension model;electrical maintenance;virtual reality technique;desktop interactive;maintenance training way;certain equipment;electrical system;fault diagnosis;virtual 3D simulation","","","","6","","4 Feb 2013","","","IEEE","IEEE Conferences"
"Decoding 2D kinematics of human arm for body machine interfaces","T. Gulrez; M. Kavakli-Thorne; A. Tognetti","Virtual and Simulations of Reality Research Lab, Department of Computing, Faculty of Science, Macquarie University, NSW 2109 Australia; Virtual and Simulations of Reality Research Lab, Department of Computing, Faculty of Science, Macquarie University, NSW 2109 Australia; Department of Bioengineering, Interdepartmental Research Center E. Piaggio, Faculty of Engineering, University of Pisa, Italy","2013 IEEE 8th Conference on Industrial Electronics and Applications (ICIEA)","25 Jul 2013","2013","","","719","722","Body-machine interface provides stroke and spinal cord injured patients a mean to participate in their activities of daily livings (ADLs). In this paper, electrophysiological signals from the human upper limb are used as a control interface between the user and a virtual robotic wheelchair. There is a general perception that these body signals contain an insufficient level of information for decoding or reconstructing kinematics of multi-joint limb activity. In this paper we present the results obtained in our virtual reality laboratory at Macquarie University, showing that non-invasive upper limb signals from high density wearable sensing shirt can be utilized to continuously decode the kinematics of 2D arm movements. Our results also show that body signals contain an information about the neural representation of movement. Moreover, they provide an alternative way for developing non-invasive body-machine interfaces, which have diverse clinical applications and access to these signals may provide understanding of functional brain states at various stages of development and aging.","2158-2297","978-1-4673-6322-8","10.1109/ICIEA.2013.6566461","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6566461","","Wheelchairs;Robot sensing systems;Mobile robots;Kinematics;Decoding","bioelectric potentials;biomechanics;brain;handicapped aids;human-robot interaction;injuries;kinematics;mechanoception;medical computing;medical disorders;medical robotics;mobile robots;neural nets;neurophysiology;user interfaces;virtual reality;wheelchairs","2D kinematics decoding;stroke;spinal cord injured patient;activities of daily living;ADL;electrophysiological signal;human upper limb;control interface;virtual robotic wheelchair;general perception;body signal;kinematics reconstruction;multijoint limb activity;virtual reality laboratory;noninvasive upper limb signal;high density wearable sensing shirt;2D arm movement kinematics;movement neural representation;noninvasive body-machine interface;functional brain states","","","","12","","25 Jul 2013","","","IEEE","IEEE Conferences"
"Immersive Representation of Objects in Virtual Reality Environment Implementing Impicit Properties","A. Bachvarov; S. Maleshkov; D. Chotrov; J. Katicic","FDIBA, Tech. Univ. of Sofia, Sofia, Bulgaria; FDIBA, Tech. Univ. of Sofia, Sofia, Bulgaria; FDIBA, Tech. Univ. of Sofia, Sofia, Bulgaria; Inst. for Inf. Manage. in Eng., Karlsruhe Inst. of Technol. (KIT), Karlsruhe, Germany","2011 Developments in E-systems Engineering","13 Feb 2012","2011","","","587","592","In this work we propose a new concept of so called implicit (or ""hidden"") properties implemented in material object models. These are some features of the material object model that cannot be perceived by the observer through his/her senses (i.e. magnetization, radiation, humidity). Exploration of such features requires additional means and techniques that expand the perception range of the observer's different sensory channels. Traditional approaches use only a few of the explicit properties of objects models (mainly its geometric, structural and topological characteristics) for their building. We believe that the supplement of implicit properties, the selection of an appropriate combination of stimuli for separate sensory channels, their effective presentation to the observer and the ability for their modification directly in the virtual world will turn this situation in a way that may lead to a disruption in the generally accepted practices for different research fields, thus allowing for the virtual reality to unfold its full potential as a significant engineering design tool. Respectively, this will considerably enhance and intensify the information perception of the observer during object exploration in the virtual environment. Here, a brief introduction in the Virtual Reality and its engineering application is presented. The concepts about the material objects and their properties, as well as systems and norms for standardized properties sets and classes, have been surveyed. The developed Aura-Dowsing interaction technique as a part of ongoing complex research on the possibility for implementation of the implicit properties concept is presented and discussed.","","978-1-4577-2186-1","10.1109/DeSE.2011.80","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6150058","implicit properties;material objects;virtual reality;multisensorial presentation","Materials;Virtual environments;Solid modeling;Visualization;Observers;Color","computer graphics;image representation;virtual reality","object representation;virtual reality environment;material object model;sensory channel;virtual world;engineering design tool;information perception;object exploration;standardized properties sets;Aura-Dowsing interaction technique","","2","3","8","","13 Feb 2012","","","IEEE","IEEE Conferences"
"A memory-saved and polynomial-based timing simulator for all-digital receivers","Jian Xiong; Lei Qin; Yantao Qiao; Jun Sun","Sch. of Electron. & Electron. Eng., Shanghai Jiao Tong Univ., China; Sch. of Electron. & Electron. Eng., Shanghai Jiao Tong Univ., China; Sch. of Electron. & Electron. Eng., Shanghai Jiao Tong Univ., China; Sch. of Electron. & Electron. Eng., Shanghai Jiao Tong Univ., China","2004 International Conference on Communications, Circuits and Systems (IEEE Cat. No.04EX914)","25 Oct 2004","2004","2","","1161","1164 Vol.2","Generally, the VCXO used in timing recovery is an analog device, so it is difficult to simulate the sampling error and to integrate the timing blocks with the system simulation. This paper presents a memory-saved and polynomial-based timing simulator for all-digital receivers. The Farrow structure is adopted in the simulator. The structure of the simulator is easy to carry out in time sequence simulation; furthermore, the simulator can be implemented in hardware. And it can be applied to all kinds of all-digital receivers. It is very convenient to test the interaction between timing algorithm and the other blocks, such as carrier recovery, equalizer and channel decoder etc.","","0-7803-8647-7","10.1109/ICCCAS.2004.1346381","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1346381","","Polynomials;Timing;Sampling methods;Oscillators;Digital simulation;Signal sampling;Frequency;Delay;Hardware;Testing","synchronisation;circuit simulation;radio receivers;digital simulation;digital radio;interpolation;digital circuits","VCXO;timing recovery;memory-saved simulator;polynomial-based timing simulator;all-digital receivers;Farrow structure;time sequence simulation","","","","10","","25 Oct 2004","","","IEEE","IEEE Conferences"
"Dataglove calibration with constructed grasping gesture database","Bin Wang; Shuling Dai","School of Automation Science and Electrical Engineering, State Key Laboratory of Virtual Reality Technology & Systems, BeiHang University, Beijing, China; School of Automation Science and Electrical Engineering, State Key Laboratory of Virtual Reality Technology & Systems, BeiHang University, Beijing, China","2009 IEEE International Conference on Virtual Environments, Human-Computer Interfaces and Measurements Systems","5 Jun 2009","2009","","","6","11","Data glove is widely used in the area of Human Computer Interaction (HCI), but its precise calibration is still an unsettled question. This paper establishes a human hand model suit for general-purpose instrumented glove application and presents a reliable and expedient calibration routine. Our calibration method can be simply carried through without the need for auxiliary calibration hardware, while still producing high visual-fidelity performance.","1944-9410","978-1-4244-3808-2","10.1109/VECIMS.2009.5068856","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5068856","data glove calibraion;human hand model;cross-coupling error;gesture synthesis","Data gloves;Calibration;Databases;Thumb;Humans;Fingers;Virtual reality;Instruments;Kinematics;Virtual environment","calibration;data gloves;gesture recognition;human computer interaction","data glove calibration;constructed grasping gesture database;human computer interaction;visual-fidelity performance","","5","","16","","5 Jun 2009","","","IEEE","IEEE Conferences"
"Augmented Reality Go: Extending Traditional Game Play with Interactive Self-Learning Support","T. Iwata; T. Yamabe; T. Nakajima","Dept. of Comput. Sci. & Eng., Waseda Univ., Tokyo, Japan; Dept. of Comput. Sci. & Eng., Waseda Univ., Tokyo, Japan; Dept. of Comput. Sci. & Eng., Waseda Univ., Tokyo, Japan","2011 IEEE 17th International Conference on Embedded and Real-Time Computing Systems and Applications","29 Sep 2011","2011","1","","105","114","The augmented reality (AR)-based learning support has several advantages over virtual reality or PC applications. AR enables to maintain the physical interaction that an activity originally offers, thus the skills and knowledge acquired in an augmented learning process can be intuitively applied to practice use. Whereas lots of AR-based self-learning support systems have been developed in previous studies, it has not been sufficiently evaluated how it influences a learner's mindset and the efficiency of training. In this paper, we investigate the user experience brought by AR technologies in a self-learning process. We chose the game of Go as a study program, and developed the Augmented Reality Go (ARGo) system to compare the AR and conventional PC-based learning assistance. We found that the physical interaction with the original game apparatus enhanced the subjects' intrinsic motivation towards self-learning. Moreover, the original look-and-feel induced deeper concentration and higher elaboration on problem solving. Design issues are also discussed to generalize the concept of AR self-learning support towards broader application domains.","2325-1301","978-1-4577-1118-3","10.1109/RTCSA.2011.43","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6029834","","Games;Visualization;User interfaces;Guidelines;Augmented reality;Sensors;Training","augmented reality;game theory;interactive systems;problem solving;unsupervised learning","augmented reality;game play;interactive self learning support;learning support;virtual reality;augmented learning process;AR-based self learning support system;PC-based learning assistance;look-and-feel induced deeper concentration;problem solving","","12","","19","","29 Sep 2011","","","IEEE","IEEE Conferences"
"Warping distributed system configurations","B. Thomas; D. Stotts; L. Kumar","Sch. of Comput. & Inf. Sci., Univ. of South Australia, SA, Australia; NA; NA","Proceedings. Fourth International Conference on Configurable Distributed Systems (Cat. No.98EX159)","6 Aug 2002","1998","","","136","143","We have developed interface animation techniques for distributed collaborative 3D virtual environments. Our methods communicate information about group interactions to the various individual users in the system; this information is traditionally absent (i.e., not needed) from single user systems and is difficult to convey with static interfaces. Interface animation is primarily accomplished by dynamically warping the shape of the objects in the virtual space. We describe our warping methods and a system, call MUVEE in which we have embedded them. We also describe an application of these ideas for configuring distributed systems in general: visualizing the configuration and performance of a distributed system as a warpable virtual environment. We have implemented our experimental prototypes with the Polylith toolbus.","","0-8186-8451-8","10.1109/CDS.1998.675767","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=675767","","Virtual environment;Animation;Visualization;Shape;Virtual prototyping;Distributed computing;Information science;Computer science;Australia;Collaborative tools","virtual reality;groupware;distributed processing;virtual machines","distributed system configurations;interface animation techniques;distributed collaborative 3D virtual environments;group interactions;dynamic warping;virtual space;warping method;MUVEE;configuring distributed systems;warpable virtual environment;Polylith toolbus","","4","","19","","6 Aug 2002","","","IEEE","IEEE Conferences"
"3D tracking of multi-objects using color and stereo for HCI","Ig-Jae Kim; Shwan Lee; S. C. Ahn; Yong-Moo Kwon; Hyoung-Gon Kim","Imaging Media Res. Center, Korea Inst. of Sci. & Technol., Seoul, South Korea; NA; NA; NA; NA","Proceedings 2001 International Conference on Image Processing (Cat. No.01CH37205)","7 Aug 2002","2001","3","","278","281 vol.3","We present a 3D tracking method of multi-objects by color and stereo. The results are applied to navigation and manipulation in a virtual environment. We choose a human face and hands as tracking targets for HCI. To extract the area of face and hands in a complex background, we transform an input color image using the GSCD (generalized skin color distribution). Based on the transformed image, we detect the area of face and hands by WUPC. Furthermore, the face and hands candidate region are estimated by a Kalman filter in the following frame. Then we can extract the depth information about the only corresponding region, respectively, by stereo matching. Finally, we can navigate and manipulate objects based on the extracted 3D information of face and hands naturally in the virtual environment without any additional device.","","0-7803-6725-1","10.1109/ICIP.2001.958105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=958105","","Human computer interaction;Face detection;Color;Data mining;Virtual environment;Skin;Navigation;Brightness;Target tracking;Pixel","image colour analysis;optical tracking;user interfaces;stereo image processing;object recognition;face recognition;target tracking;feature extraction;object detection;Kalman filters;image matching;virtual reality;video signal processing","3D tracking;multi-objects;HCI;color image;tracking targets;generalized skin color distribution;Kalman filter;depth information;stereo matching;sequential color video images","","","","8","","7 Aug 2002","","","IEEE","IEEE Conferences"
"Batmen beyond: Natural 3D manipulation with the BatWand","A. M. Rodrigues; O. Belloc; E. Z. Borba; M. Nagamura; M. K. Zuffo",Interdisciplinary Center in Interactive Technologies - Polytechnic School - University of São Paulo - Brazil; Interdisciplinary Center in Interactive Technologies - Polytechnic School - University of São Paulo - Brazil; Interdisciplinary Center in Interactive Technologies - Polytechnic School - University of São Paulo - Brazil; Interdisciplinary Center in Interactive Technologies - Polytechnic School - University of São Paulo - Brazil; Interdisciplinary Center in Interactive Technologies - Polytechnic School - University of São Paulo - Brazil,"2017 IEEE Symposium on 3D User Interfaces (3DUI)","6 Apr 2017","2017","","","258","259","In this work we present an interactive 3D object manipulation system using off the shelf mobile devices coupled with Augmented Reality (AR) technology that allows editing 3D objects by way of natural interactions based on tangible interfaces paradigms. The set-up consists of a mobile device, an interactive wand marker and AR markers laid on a table. The system allows users to change viewpoint and execute operations on 3D objects - simultaneous translation and rotation, scaling, cloning or deleting - by unconstrained natural interactions, leveraging user's proficiency on daily object manipulation tasks and speeding up such typical 3D manipulation operations. Depth perception was significantly enhanced with dynamic shadows, allowing fast alignment and accurate positioning of objects. The prototype presented here allows successful completion of the three challenges proposed by the 2017 3DUI Contest, as validated by a preliminary informal user study with participants from the target audience and also from the general public.","","978-1-5090-6716-9","10.1109/3DUI.2017.7893370","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7893370","I.3.6 [Computer Graphics]: Methodology and Techniques - Interaction Techniques","Three-dimensional displays;Mobile handsets;Cameras;Two dimensional displays;Augmented reality;User interfaces;Visualization","augmented reality;mobile computing;user interfaces","Batmen system;interactive 3D object manipulation system;BatWand;mobile device;augmented reality;AR;tangible interface","","1","","5","","6 Apr 2017","","","IEEE","IEEE Conferences"
"Online peer-to-peer discussions: A platform for automatic assessment of communication skill","S. Rasipuram; R. Das; S. B. P. Rao; D. B. Jayagopi","International Institute of Information Technology, Bangalore, India; International Institute of Information Technology, Bangalore, India; International Institute of Information Technology, Bangalore, India; International Institute of Information Technology, Bangalore, India","2017 Seventh International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)","1 Feb 2018","2017","","","68","73","This paper proposes a computational model to predict communication skill of individual participants in online peer-to-peer dyadic interactions. Participants interact using a web-interface (skype-like) developed to record videos of two participants separately and stream real-time. This platform allows interviews and group discussions to be conducted at any place without the need of colocation of all participants. Towards studying communication skill in such a setting, we collected 72 dyadic interactions of participants discussing on general topics. Manual rating of these interaction videos have been obtained from two external observers. Multimodal features related to non-verbal behavior: prosody, speaking activity, visual and verbal behavior are automatically extracted. The experimental results show that the multimodal fusion of features with reliefF feature ranking perform best with an accuracy of 74%. Also, we automatically rate the overall discussion by extracting features from both participants. Our best results on automatic discussion rating achieves an accuracy of 83%. Further to dyadic interactions, we make a comparative study of the communication skill rating of the same participants giving an interface-based interview. Our study indicates that participants communicate well in interaction based scenarios.","","978-1-5386-0680-3","10.1109/ACIIW.2017.8272588","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8272588","","Feature extraction;Interviews;Videos;Peer-to-peer computing;Observers;Speech;Visualization","behavioural sciences computing;feature extraction;human computer interaction;interactive video;Internet;peer-to-peer computing;virtual reality","individual participants;group discussions;interaction videos;automatic discussion rating;communication skill rating;interaction based scenarios;dyadic interactions;interface-based interview;relief feature ranking;multimodal fusion;nonverbal behavior;multimodal features;participants interaction;Web-interface;online peer-to-peer dyadic interactions;communication skill automatic assessment;online peer-to-peer discussions","","","","33","","1 Feb 2018","","","IEEE","IEEE Conferences"
"An architecture for virtual reality, audio, video, text, and document handling in applications supporting multi-person interactions","S. Pekkola; M. Robinson; J. Korhonen; S. Hujala; T. Toivonen; M. -. O. Saarinen","Dept. of Comput. Sci. & Inf. Syst., Jyvaskyla Univ., Finland; NA; NA; NA; NA; NA","Proceedings of the 26th Euromicro Conference. EUROMICRO 2000. Informatics: Inventing the Future","6 Aug 2002","2000","2","","150","157 vol.2","There are limitations to Internet, networked PC, and mobile device document handling and communication services and applications. In general, these do not provide for awareness of, and communication with others while working on documents. Limiting services in this way runs contrary to major findings from CSCW: users move between media and devices promiscuously; combine applications and media in effective, but idiosyncratic ways; and need awareness of others and their activities for successful accomplishment of much work. This awareness, whether backgrounded or foregrounded, needs to be constantly available/present. The paper presents a scalable architecture for handling multiple media (VR, video, audio, text, and documents) and devices where awareness of others/activities can be almost universally provided. Important features are presentation level integration and choices between media. These support new approaches to collaborations involving arbitrary combinations of documents, people, media and access devices.","1089-6503","0-7695-0780-8","10.1109/EURMIC.2000.874412","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=874412","","Virtual reality;Document handling;Collaborative work;Computer architecture;Mobile communication;Application software;Computer science;Information systems;Web and internet services;Computer applications","multimedia systems;virtual reality;document handling;groupware;Internet","virtual reality;audio;video;text;document handling;multi-person interactions;Internet;networked PC;mobile device;CSCW;multimedia;computer supported cooperative work","","","2","39","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Augmenting a historic house: Villa Ciani 3D","P. Schettino","Agenzia per l’Italia Digitale (AGID), Presidenza del Consiglio dei Ministri, Rome, Italy","2018 3rd Digital Heritage International Congress (DigitalHERITAGE) held jointly with 2018 24th International Conference on Virtual Systems & Multimedia (VSMM 2018)","26 Aug 2019","2018","","","1","4","This paper summarizes the main results of a qualitative study of Villa Ciani 3D, an augmented reality project at the historic house Villa Ciani in Lugano, Switzerland. At the moment the building is an empty shell, with a few canvases but without its original furniture. The project, developed in collaboration with the local historic archive and the historic house, allowed visitors to admire images from the archive projected onto glass while being guided on a tour by an actor playing the role of one of the two Ciani brothers, the original owners of the house. Interviews with visitors were collected after the visit and analyzed using grounded theory as the main method of study. On the one hand, the paper highlights the positive impact of the augmented storytelling when visitors explore empty spaces while, on the other, it outlines the limits of using an interaction model that does not allow visitors to interact with each other. The paper includes a more general analysis of the use of augmented reality in historic houses.","","978-1-7281-0292-4","10.1109/DigitalHeritage.2018.8810108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8810108","augmented reality;archives;historic houses;qualitative study;grounded theory;digital images;spaces","Three-dimensional displays;Cultural differences;Augmented reality;Glass;Buildings;Collaboration;Media","augmented reality;history","Villa Ciani 3D;augmented reality project;historic house Villa Ciani;local historic archive;augmented storytelling","","","","17","","26 Aug 2019","","","IEEE","IEEE Conferences"
"Study on developing a computerized model of human cognitive behaviors in monitoring and diagnosing plant transients","W. Wu; H. Yoshikawa","Graduate Sch. of Energy Sci., Kyoto Univ., Japan; NA","SMC'98 Conference Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.98CH36218)","6 Aug 2002","1998","2","","1121","1126 vol.2","A computerized model of human cognitive behavior in monitoring and diagnosing plant transient has been developed as a part of integrated simulation system of human-machine interaction (HCI) in nuclear power plant. The general framework used of human modeling is first described, followed by the description of detailed modeling of both the monitoring and diagnosing phases. For the usability validation of the developed human modeling, computer simulation experiments have been conducted to deduce human cognitive reliability curves, by connecting the computerized model of human cognitive information processing with the dynamic simulator of nuclear power plant through man-machine interface simulator. The results of computer simulation were well agreed with those of laboratory experiments.","1062-922X","0-7803-4778-1","10.1109/ICSMC.1998.727848","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=727848","","Power system modeling;Computer simulation;Computational modeling;Computerized monitoring;Power generation;Man machine systems;Human computer interaction;Usability;Joining processes;Computer interfaces","nuclear power stations;fault diagnosis;computerised monitoring;man-machine systems;digital simulation;user modelling","computerized model;human cognitive behaviors;monitoring;plant transient;human-machine interaction;nuclear power plant;dynamic simulator;man-machine interface;fault diagnosis","","3","","10","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Simulating 3-D bone tissue growth using repast HPC: Initial simulation design and performance results","J. T. Murphy; E. S. Bayrak; M. C. Ozturk; A. Cinar","Argonne National Laboratory Global Security Sciences, 9700 South Cass Avenue, Lemont, IL 60439, USA; Department of Chemical and Biological Engineering, Illinois Institute of Technology, 10 W 33rd St, Chicago, 60616, USA; Department of Chemical and Biological Engineering, Illinois Institute of Technology, 10 W 33rd St, Chicago, 60616, USA; Department of Chemical and Biological Engineering, Illinois Institute of Technology, 10 W 33rd St, Chicago, 60616, USA","2016 Winter Simulation Conference (WSC)","19 Jan 2017","2016","","","2087","2098","Bone is one of the most implanted tissues worldwide. Bone tissue engineering deals with the replacement and regeneration of bone tissue; outcomes are determined by complex biological interactions, making it difficult to design an optimal tissue growth environment. Agent-Based Modeling (ABM) is a powerful tool to simulate such a system. We present a simulation of engineered bone tissue growth using the Repast HPC toolkit, an ABM tool for high-performance computing environments. We use this example to provide preliminary performance tests on new features (not yet publicly released) of Repast HPC that accommodate operations common to biological modeling: 3-Dimensional parallelized spatial simulation and diffusion in 3 dimensions. Repast HPC is a general ABM toolkit, and the performance documented here should be representative of performance on other simulations. Using the baseline Repast HPC tools provides flexibility for continued model development and improvement.","1558-4305","978-1-5090-4486-3","10.1109/WSC.2016.7822252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822252","","Biological system modeling;Bone tissue;Bones;Agent-based modeling","bone;digital simulation;medical computing;multi-agent systems;parallel processing","3D bone tissue growth simulation;bone tissue engineering;bone tissue regeneration;bone tissue replacement;complex biological interactions;optimal tissue growth environment;agent-based modeling;ABM;Repast HPC toolkit;high-performance computing environments;biological modeling;3-dimensional parallelized spatial simulation;ABM toolkit;continued model development","","2","","23","","19 Jan 2017","","","IEEE","IEEE Conferences"
"Walking with Virtual People: Evaluation of Locomotion Interfaces in Dynamic Environments","A. Olivier; J. Bruneau; R. Kulpa; J. Pettré","INRIA Rennes, Rennes, France; INRIA Rennes, Rennes, France; INRIA Rennes, Rennes, France; INRIA Rennes, Rennes, France","IEEE Transactions on Visualization and Computer Graphics","25 May 2018","2018","24","7","2251","2263","Navigating in virtual environments requires using some locomotion interfaces, especially when the dimensions of the environment exceed the ones of the Virtual Reality system. Locomotion interfaces induce some biases both in the perception of the self-motion or in the formation of virtual locomotion trajectories. These biases have been mostly evaluated in the context of static environments, and studies need to be revisited in the new context of populated environments where users interact with virtual characters. We focus on a situation of collision avoidance between a real participant and a virtual character, and compared it to previous studies on real walkers. Our results show that, as in reality, the risk of future collision is accurately anticipated by participants, however with delay. We also show that collision avoidance trajectories formed in VR have common properties with real ones, with some quantitative differences in avoidance distances. More generally, our evaluation demonstrates that reliable results can be obtained for qualitative analysis of small scale interactions in VR. We discuss these results in the perspective of a VR platform for large scale interaction applications, such as in a crowd, for which real data are difficult to gather.","1941-0506","","10.1109/TVCG.2017.2714665","French National Research Agency ANR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7946183","Locomotion;interaction;evaluation;experiment;collision avoidance;virtual reality","Trajectory;Legged locomotion;Collision avoidance;Context;Measurement;Virtual environments","collision avoidance;navigation;virtual reality","populated environments;virtual character;collision avoidance;virtual people;locomotion interfaces;dynamic environments;virtual environments;Virtual Reality system;virtual locomotion trajectories;static environments;VR platform","","13","","51","","12 Jun 2017","","","IEEE","IEEE Journals"
"Immersive integration for virtual and human-centered environments","H. Fuchs","North Carolina Univ., Chapel Hill, NC, USA","2005 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC'05)","17 Oct 2005","2005","","","13","","Summary form only given. We envision future work and play environments that are more effectively human-centered with the user's computing interface being more closely integrated with the physical surroundings than today's conventional computer display screens and keyboards. We are working toward realizable versions of such environments, in which multiple video projectors and digital cameras enable every visible surface to be both measured in 3D and used for display. If the 3D surface positions are transmitted to a distant location, they may also enable distant collaborations to become more like working in adjacent offices connected by large windows. In one prototype, depth maps are calculated from streams of video images and the resulting 3D surface points are displayed to the user in head-tracked stereo. Another prototype allows direct ""painting"" onto movable objects - a dollhouse, for example. One long-term goal is advanced training for trauma surgeons by immersive replay of recorded procedures. More generally, we hope to demonstrate that the principal interface of a future computing environment need not be limited to a screen the size of one or two sheets of paper. Just as a useful physical environment is all around us, so too can the increasingly ubiquitous computing environment be all around us - becoming more effectively human-centered and integrated into our physical surroundings.","1943-6106","0-7695-2443-5","10.1109/VLHCC.2005.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1509481","","Computer displays;Computer interfaces;Prototypes;Physics computing;Keyboards;Digital cameras;Three dimensional displays;Large screen displays;Collaborative work;Streaming media","visual programming;solid modelling;virtual reality;human computer interaction;user centred design;user interfaces","immersive integration;virtual environments;human-centered environments;user interface;multiple video projectors;digital cameras;3D surface position;windows;video images;3D surface points;movable objects;ubiquitous computing","","","","","","17 Oct 2005","","","IEEE","IEEE Conferences"
"Interactive Simulation of rigid body interaction with friction-induced sound generation","F. Avanzini; S. Serafin; D. Rocchesso","Dipt. di Ingegneria dell'Informazione, Univ. of Padova, Italy; NA; NA","IEEE Transactions on Speech and Audio Processing","15 Aug 2005","2005","13","5","1073","1081","Acoustic simulation of friction is a particularly challenging task, because continuous (strong) contact conditions require a tight and veridical integration of the synthesis layer with the control input. This paper presents an algorithmic realization that combines recently proposed physical models of friction with the lumped modal description of resonating bodies. It is shown that the resulting nonlinear dynamical system can be discretized using a numerical technique that allows efficient and accurate simulation. Applications in the context of interactive audio-visual animation on low-cost general-purpose computers are demonstrated, and an approach to joint audio-visual synthesis is proposed that provides fine-scale synchronization and high coherence between the two modalities. The interactive animations show that the model is successful in reproducing several salient everyday sound phenomena, such as rubbing, braking, and squeaky doors.","1558-2353","","10.1109/TSA.2005.852984","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1495488","Audio-visual contact simulation;elasto-plastic friction models;modal synthesis;nonlinear acoustic systems;sound source modeling","Friction;Animation;Computational modeling;Control system synthesis;Application software;Coherence;Nonlinear acoustics;Computer graphics;Haptic interfaces;Computer simulation","acoustic signal processing;signal synthesis;nonlinear dynamical systems;digital simulation","interactive simulation;rigid body interaction;friction-induced sound generation;friction acoustic simulation;algorithmic realization;lumped modal description;resonating bodies;nonlinear dynamical system;interactive audio-visual animation;audio-visual synthesis;nonlinear acoustic systems;sound source modeling","","32","","33","","15 Aug 2005","","","IEEE","IEEE Journals"
"Effects of Target Trajectory Bandwidth on Manual Control Behavior in Pursuit and Preview Tracking","K. van der El; D. M. Pool; M. R. M. van Paassen; M. Mulder","Control and Simulation Section, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Control and Simulation Section, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Control and Simulation Section, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Control and Simulation Section, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands","IEEE Transactions on Human-Machine Systems","16 Jan 2020","2020","50","1","68","78","The 1960s crossover model is widely applied to quantitatively predict a human controller's (HC's) manual control behavior. Unfortunately, the theory captures only compensatory tracking behavior and, as such, a limited range of real-world manual control tasks. This article finalizes recent advances in manual control theory toward more general pursuit and preview tracking tasks. It is quantified how HCs adapt their control behavior to a final crucial task variable: the target trajectory bandwidth. Beneficial adaptation strategies are first explored offline with computer simulations, using an extended crossover model theory for pursuit and preview tracking. The predictions are then verified with data from a human-in-the-loop experiment, in which participants tracked a target trajectory with bandwidths of 1.5, 2.5, and 4 rad/s, using compensatory, as well as pursuit and preview displays. In stark contrast to the crossover regression found in compensatory tasks, humans attenuate only their feedforward response when tracking higher-bandwidth trajectories in pursuit tasks, while their behavior is generally invariant in preview tasks. A full quantitative theory is now available to predict HC manual control behavior in tracking tasks, which includes HC adaptation to all key task variables.","2168-2305","","10.1109/THMS.2019.2947577","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897675","Manual control;modeling;pursuit;preview;target trajectory bandwidth","Task analysis;Target tracking;Bandwidth;Trajectory;Adaptation models;Human factors;Predictive models","computer simulation;control engineering computing;feedback;feedforward;human factors;human-robot interaction;tracking","target trajectory bandwidth;preview tracking;human controller;compensatory tracking behavior;manual control theory;extended crossover model theory;human-in-the-loop experiment;crossover regression;compensatory tasks;tracking higher-bandwidth trajectories;HC manual control behavior;HC adaptation;pursuit tracking;computer simulations","","","","28","IEEE","13 Nov 2019","","","IEEE","IEEE Journals"
"Music in Extended Realities","L. Turchet; R. Hamilton; A. Çamci","Department of Information Engineering and Computer Science, University of Trento, Trento, Italy; Department of the Arts, Rensselaer Polytechnic Institute, Troy, NY, USA; School of Music, Theatre and Dance, University of Michigan, Ann Arbor, MI, USA","IEEE Access","28 Jan 2021","2021","9","","15810","15832","The intersection between music and Extended Reality (XR) has grown significantly over the past twenty years, amounting to an established area of research today. The use of XR technologies represents a fundamental paradigm shift for various musical contexts as they disrupt traditional notions of musical interaction by enabling performers and audiences to interact musically with virtual objects, agents, and environments. This article both surveys and expands upon the knowledge accumulated in existing research in this area to build a foundation for future works that bring together Music and XR. To this end, we created a freely available dataset of 260 publications in this space and conducted an in-depth analysis covering 199 works in the last decade. We conducted this analysis using a list of conceptual dimensions belonging to technical, artistic, perceptual and methodological domains. This review of the literature is complemented with a set of interviews with domain experts with the goal of establishing a definition for the emergent field of Musical XR, i.e., the field of music in Extended Realities. Based on the results of the conducted review, a research agenda for the field is proposed.","2169-3536","","10.1109/ACCESS.2021.3052931","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9328440","Music;extended reality;virtual reality;augmented reality;augmented virtuality;mixed reality;digital musical instruments;Internet of Musical Things","X reality;Music;Visualization;Extended reality;Virtual environments;Mixed reality;Tracking","augmented reality;music","musical contexts;musical interaction;music;extended reality;XR technologies;virtual objects","","","","169","CCBY","19 Jan 2021","","","IEEE","IEEE Journals"
"Bamboo-a portable system for dynamically extensible, real-time, networked, virtual environments","K. Watsen; M. Zyda","Naval Postgraduate Sch., Monterey, CA, USA; NA","Proceedings. IEEE 1998 Virtual Reality Annual International Symposium (Cat. No.98CB36180)","6 Aug 2002","1998","","","252","259","Bamboo is a portable system supporting real-time, networked, virtual environments. Unlike previous efforts, this design focuses on the ability of the system to dynamically configure itself without explicit user interaction, allowing applications to take on new functionality after execution. In particular, this framework facilitates the discovery of virtual environments on the network at runtime. Fundamentally, Bamboo offers a compatible set of mechanisms needed for a wide variety of real-time, networked applications. Also included is a particular combination of these mechanisms supporting a dynamically extensible runtime environment. This paper serves as a general introduction to Bamboo. It describes the system's architecture, implementation and future directions. It also shows how the system can facilitate the rapid development of robust applications by promoting code reuse via community-wide exchange.","","0-8186-8362-7","10.1109/VRAIS.1998.658503","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=658503","","Real time systems;Virtual environment;Graphics;Runtime;Virtual reality;Layout;Electrical capacitance tomography;Minimally invasive surgery","software portability;real-time systems;distributed processing;virtual reality;software tools;software reusability","Bamboo;portable system;real-time networked virtual environments;self-configuration;user interaction;application functionality;virtual environment discovery;dynamically extensible runtime environment;system architecture;implementation;robust applications development;code reuse;community-wide exchange;multi-platform system;virtual reality","","23","","28","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Simulation Bridge: a framework for multi-processor simulation","G. D. Nagendra; V. G. P. Kumar; B. S. Sheshadri","Software Dev. Syst., Texas Instruments India Ltd, Bangalore, India; Software Dev. Syst., Texas Instruments India Ltd, Bangalore, India; Software Dev. Syst., Texas Instruments India Ltd, Bangalore, India","Proceedings of the Tenth International Symposium on Hardware/Software Codesign. CODES 2002 (IEEE Cat. No.02TH8627)","7 Aug 2002","2002","","","49","54","Multi-processor solutions in the embedded world axe being designed to meet the ever increasing computational demands of the emerging applications. Such architectures comprise two or more processors (often a mix of general purpose and digital signal processors) together with a rich peripheral mix to provide a high performance computational platform. While there are many simulation solutions in the industry available to address the system partitioning issues and also the verification of HW-SW interactions in these complex systems, there are very few solutions targetted towards the SW application developers' needs. The primary concern of the SW application developers is to debug and optimize their code. Hence, cycle accuracy and performance of the simulation solution becomes the key enablers. Desired observability and controllability of the models are additional careabouts. Secondly, application developers are more comfortable at instruction level simulations than they are with RTL or gate level simulation. These specific requirements have a bearing on the choices in the simulation solutions. This paper describes the design of a generic, C based multi-processor instruction set simulator framework in the context of the above parameters. This framework, termed the ""simulation bridge"", facilitates highly accurate, yet efficient simulation. The SimBridge performs clock correct lock-step simulation of the models in the architecture using a global simulation engine that handles both intra-processor and inter-processor communication in a homogenous fashion. It addresses the multiple key issues of execution control, synchronization, connectivity and communication. The paper concludes with the performance analysis of the SimBridge in an experimental test setup as well as in the Texas Instruments (TI) TMS320C54x-based simulators.","","1-58113-542-4","10.1145/774789.774800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1003600","","Bridges;Computational modeling;Embedded computing;Computer architecture;Digital signal processors;Computer peripherals;High performance computing;Observability;Controllability;Context modeling","multiprocessing systems;embedded systems;hardware-software codesign;performance evaluation;digital simulation;program debugging","Simulation Bridge;multi-processor simulation framework;embedded systems;system partitioning;HW-SW interactions verification;software debug;observability;controllability;instruction level simulations;gate level simulation;C based multi-processor instruction set simulator framework;SimBridge;performance analysis;TMS320C54x-based simulators","","6","2","12","","7 Aug 2002","","","IEEE","IEEE Conferences"
"A distributed architecture for large collaborative virtual environments","S. Benford","Dept. of Comput. Sci., Nottingham Univ., UK","IEE Colloquium on Distributed Virtual Reality","6 Aug 2002","1993","","","9/1","9/7","The development of virtual environments that can support cooperative work between large numbers of simultaneous users distributed over computer networks, is discussed. Work within the COMIC project has developed and prototyped a 'spatial model of interaction' where people use the properties of virtual space to control their interactions with other objects. Developments in distributed processing have also produced mechanisms for interaction between objects in distributed systems; one of the most significant of these is the notion of 'trading' as a means of brokering services and interfaces between objects. The author proposes key extensions to the trading model and also proposes a generalised architecture where the trader co-operates with a set of collision managers to provide a general and flexible platform for building distributed virtual environments.<>","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=243229","","Computer networks;Collaborative work;Interactive systems;Virtual reality","computer networks;groupware;interactive systems;virtual reality","large collaborative virtual environments;cooperative work;simultaneous users;computer networks;COMIC project;spatial model;virtual space;distributed processing;key extensions;trading model;generalised architecture;collision managers;flexible platform","","","6","","","6 Aug 2002","","","IET","IET Conferences"
"Proposed Usability Heuristics for Testing Gestural Interaction","N. K. Chuan; A. Sivaji; W. F. W. Ahmad","MIMOS Berhad, Kuala Lumpur, Malaysia; MIMOS Berhad, Kuala Lumpur, Malaysia; Dept. of Comput. & Inf. Sci., Univ. Teknol. PETRONAS, Tronoh, Malaysia","2014 4th International Conference on Artificial Intelligence with Applications in Engineering and Technology","10 Dec 2015","2014","","","233","238","Heuristic evaluation is a fast and effective method of usability testing. However, usability heuristics framework used for general testing may not be suitable to evaluate gesture vocabulary of mainstream gestural interaction found in touchscreen devices or emerging technologies natural user interface that uses motion tracking. There is a need to do so during early stages of product development. The objective of this study is to create a set of gesture-specific heuristics that would complement existing general usability heuristics for design and testing of new gestural interaction. The method to do so is to review previous studies of gestural interaction design and usability testing. The result of the study is condensed set of four gesture-specific heuristics.","","978-1-4799-7910-3","10.1109/ICAIET.2014.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7351840","gestural input; usability testing; heuristic evaluation; interaction styles; natural language; user-centered design","Usability;Testing;Organizations;Guidelines;Assistive technology;Vocabulary;Human computer interaction","gesture recognition;human computer interaction;mobile computing;product design;touch sensitive screens;vocabulary","gestural interaction testing;usability testing;usability heuristics framework;gesture vocabulary;touchscreen devices;natural user interface;motion tracking;product development;gesture-specific heuristics","","3","","27","","10 Dec 2015","","","IEEE","IEEE Conferences"
"A general simulation algorithm for the accurate assessment of isolated diesel-wind turbines systems interaction. Part II: Implementation of the algorithm and case-studies with induction generators","G. N. Kariniotakis; G. S. Stavrakakis","Dept. of Electron. & Comput. Eng., Tech. Univ. of Crete, Chania, Greece; Dept. of Electron. & Comput. Eng., Tech. Univ. of Crete, Chania, Greece","IEEE Transactions on Energy Conversion","6 Aug 2002","1995","10","3","584","590","In the second part of this two-part paper, a general algorithm to simulate and assess the dynamic behavior of any isolated diesel-wind turbine power system is analyzed and implemented. It is presented how the various power system and wind energy conversion system (WECS) component models described in detail in Part I of the paper can be implemented in order to create integrated simulation software. Case studies for the small size isolated power system on the French island of Desirade are given and analyzed. The algorithm is validated and its usefulness to determine the wind energy penetration level at any disturbed operation conditions is demonstrated.<>","1558-0059","","10.1109/60.464886","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=464886","","Power system simulation;Power system modeling;Power system transients;Power system stability;Power system analysis computing;Power system interconnection;Computational modeling;Wind turbines;Power system dynamics;Analytical models","diesel-electric generators;diesel-electric power stations;wind power plants;wind turbines;power system interconnection;power system analysis computing;digital simulation;asynchronous generators;electric machine analysis computing;machine theory","isolated diesel-wind power systems;wind turbines;induction generators;algorithm;dynamic behavior;wind energy conversion system;integrated simulation software;case studies;Desirade;computer simulation;wind energy penetration level;disturbed operation conditions","","44","","9","","6 Aug 2002","","","IEEE","IEEE Journals"
"Comparison of interaction forces of robot arm on Force-free Control and impedance control by model based simulations","A. Pallegedara; Y. Matsuda; N. Egashira; T. Sugi; S. Goto","Department of Science and Technology, Graduate School of Science and Engineering, Saga University, 1 Honjo-machi, Saga 840-8502, Japan; Department of Advanced Technology Fusion, Graduate School of Science and Engineering, Saga University, 1 Honjo-machi, Saga 840-8502, Japan; Department of Control and Information Systems Engineering, Kurume National College of Technology, Fukuoka 830-8555, Japan; Department of Advanced Technology Fusion, Graduate School of Science and Engineering, Saga University, 1 Honjo-machi, Saga 840-8502, Japan; Department of Advanced Technology Fusion, Graduate School of Science and Engineering, Saga University, 1 Honjo-machi, Saga 840-8502, Japan","2012 Proceedings of SICE Annual Conference (SICE)","4 Oct 2012","2012","","","1695","1700","This paper presents the comparison of Force-Free Control (FFC) against a Impedance Control (IC) method in cartesian space. The study of interaction forces between a robot arm and the environment is carried out. Main objective of this investigation is to find how to regulate and tune force-free control for safe and feasible operation. And how proposed force-free control compliances against an external force given from the environment, and compares the behavior with general impedance control method. A concise description of analyzing procedure is given for modeling and simulation of a robot arm and also how it interacts with environment under force-free and impedance controls schemes. The modeling and comparison are made by adopting Matlab/Simulink environment. Furthermore, the intention is also focused to make use of actual industrial robots whose factory fitted dynamical control loops are not accessible.","","978-1-4673-2259-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6318726","Force-free control (FFC);Impedance control (IC);Matlab/Simulink;Interaction forces;Environment modeling","Mathematical model;Impedance;Force;Dynamics;Joints;Service robots","digital simulation;force control;industrial manipulators;mathematics computing","interaction force comparison;robot arm;impedance control;model based simulations;FFC;IC method;Cartesian space;force-free control regulation;force-free control tuning;Matlab-Simulink environment;industrial robots;dynamical control loops","","","","12","","4 Oct 2012","","","IEEE","IEEE Conferences"
"Multimodal virtual navigation of a cultural heritage site: The medieval ceiling of Steri in Palermo","S. Andolina; A. Santangelo; M. Cannella; A. Gentile; F. Agnello; B. Villa","Dipartimento di Ingegneria Informatica, University of Palermo, Viale delle Scienze Ed. 6, Italy; Dipartimento di Ingegneria Informatica, University of Palermo, Viale delle Scienze Ed. 6, Italy; Dipartimento di Rappresentazione, University of Palermo, Via Cavour 118, Italy; Dipartimento di Ingegneria Informatica, University of Palermo, Viale delle Scienze Ed. 6, Italy; Dipartimento di Rappresentazione, University of Palermo, Via Cavour 118, Italy; Dipartimento di Rappresentazione, University of Palermo, Via Cavour 118, Italy","2009 2nd Conference on Human System Interactions","23 Jun 2009","2009","","","562","567","The advance of information technology has enabled in recent years new fruition scenarios for cultural heritage sites. Multidisciplinary approaches integrate survey techniques with multimodal interfaces to allow enhanced fruition for larger group of users. In this paper we propose a multimodal interface to a virtual representation of a medieval ceiling, built in the XIV century, which covers the ldquoSala Magnardquo of Steri, the historical headquarters of the University of Palermo, in Italy. This research deals with the definition of a process for the integration of surveying techniques, modelling processes and communication technologies for the documentation of such artifacts. This is a two-stage process: in the first stage, a 3D digital document is produced that describes the artifact; in the second stage, a multimodal guide interacting with the 3D model is developed. A prototype multimodal guide has been implemented to narrate the Trojan Cycle, depicted on two of the rafters in the ceiling. This prototype was demonstrated to the general public and is detailed in the paper.","2158-2254","978-1-4244-3959-1","10.1109/HSI.2009.5091039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5091039","Cultural heritage fruition;survey techniques;multimodal interaction;human-computer interaction","Navigation;Cultural differences;Painting;Art;Prototypes;Cities and towns;Visualization;Image restoration;Internet;Virtual prototyping","data visualisation;history;human computer interaction;solid modelling;user interfaces;virtual reality","multimodal virtual navigation;cultural heritage site;medieval ceiling;Palermo;information technology;multimodal interface;Steri historical headquarter;3D digital document model;3D visualization;human-computer interaction","","2","1","9","","23 Jun 2009","","","IEEE","IEEE Conferences"
"Interactive SPEEDES","J. S. Steinman","Jet Propulsion Lab., California Inst. of Technol., Pasadena, CA, USA","[1991] Proceedings of the 24th Annual Simulation Symposium","6 Aug 2002","1991","","","149","158","Interactive parallel simulations involving humans or external software modules can be difficult to support. While many parallel simulation algorithms avoid acknowledging the need for external interactions, most real-world applications demand this capability. A new general purpose synchronous parallel environment for emulation and discrete event simulation (SPEEDES) has been developed which easily supports interactive simulations. The SPEEDES algorithm is described, basic elements of interactive simulations are discussed, and the solution which was implemented in SPEEDES is given.<>","","0-8186-2169-9","10.1109/SIMSYM.1991.151499","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=151499","","Computational modeling;Discrete event simulation;Humans;Aerospace simulation;Computer simulation;Emulation;Propulsion;Laboratories;Application software;Computer graphics","discrete event simulation;interactive systems","interactive parallel simulations;synchronous parallel environment for emulation and discrete event simulation","","7","","4","","6 Aug 2002","","","IEEE","IEEE Conferences"
"The Effects of Two Game Interaction Modes on Cortical Activation in Subjects of Different Ages: A Functional Near-Infrared Spectroscopy Study","R. Ge; Z. Wang; X. Yuan; Q. Li; Y. Gao; H. Liu; Z. Fan; L. Bu","School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore","IEEE Access","20 Jan 2021","2021","9","","11405","11415","Increasing age and various pathological factors lead to cognitive function decline among the elderly. The most serious cognitive dysfunctions among the elderly include mild cognitive impairment (MCI), Alzheimer's disease (AD), and vascular dementia (VAD). Cognitive training is an effective approach to mitigate the decline in cognitive function. Recent studies have confirmed that emerging training methods using new technologies, such as virtual reality (VR) and mobile phones, can be used effectively for cognitive training. This study used functional near-infrared spectroscopy (fNIRS) to compare the brain activation of young and elderly people during VR and mobile phone training when performing a cognitive training game. fNIRS has been shown to be an effective tool for monitoring cognitive decline. In the current study, the MMSE scale was used to measure cognitive performance and fNIRS was used to measure brain activation among 20 youth (mean age 25.33± 1.59 years) and 17 elderly people (mean age 63± 4.35 years). The results showed that the mobile phone game produced significant activation of the prefrontal lobe (PFC) and the VR game produced significant activation of the parietal lobe (MC). The average MMSE scale score of the elderly group was lower than that of the young group and was strongly correlated with PFC activation. This study confirms that elderly people have reduced cognitive function compared to young people. The results indicate that mobile phone games have a positive training effect on reducing cognitive decline, and that VR is a suitable means for cognitive function training among the elderly.","2169-3536","","10.1109/ACCESS.2021.3050210","Ministry of Education in China (MOE) Project of Humanities and Social Sciences; Shandong Social Science Planning Fund Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9317849","Virtual reality;functional near-infrared spectroscopy;cortical activation;game experience;cognitive decline","Games;Training;Senior citizens;Mobile handsets;Spectroscopy;Land mobile radio;Task analysis","biomedical optical imaging;brain;cognition;computer games;diseases;geriatrics;infrared spectroscopy;neurophysiology;virtual reality","game interaction modes;cortical activation;cognitive function decline;mild cognitive impairment;mobile phones;near-infrared spectroscopy;fNIRS;brain activation;mobile phone training;cognitive training game;cognitive decline;cognitive performance;mobile phone game;VR game;PFC activation;cognitive function training","","","","50","CCBY","8 Jan 2021","","","IEEE","IEEE Journals"
"DTI-based Virtual Reality System for Neurosurgery","C. Lo; Y. Chao; K. Chou; W. Guo; J. Su; C. Lin","Institute of Biomedical Engineering, Chung-Yuan Christian University. Dept. of BME, CYCU, 200, Chung Pei Rd., Chung Li, Taiwan 32023. e-mail: lgjbear@bclab.ym.edu.tw; Institute of Electrical Engineering, National Taiwan University. R304, EE II Building, Dept. of EE, NTU, No.1, Roosevelt Rd. Sec. 4, Taipei, Taiwan, 106. e-mail: catpin@me.ee.ntu.edu.tw; Institute of Biomedical Engineering, National Yang Ming University. e-mail: dargon@bclab.ym.edu.tw; Departments of Radiology, Taipei Veterans General Hospital. e-mail: wyguo@vghtpe.gov.tw; Institute of Biomedical Engineering, Chung-Yuan Christian University. Dept. of BME, CYCU, 200, Chung Pei Rd., Chung Li, Taiwan 32023. e-mail: jls@cycu.edu.tw; Institute of Neuroscience, National Yang-Ming University. phone: +886-2-28267338, email: cplin@ym.edu.tw","2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","22 Oct 2007","2007","","","1326","1329","The relationship between tumor mass and peritumoral structures including peritumoral edema is important for planning surgical trajectory and crucial for diagnosis, tumor excision, and post-surgical outcome. The recent development of diffusion tensor MRI has shown its feasibility in grading tumor, monitoring therapeutic effects, and post-surgery outcome. To visualize the tumor mass and the peritumoral structure, a 3D virtual reality environment was developed. Neural tractography and peritumoral anatomy were integrated in this interaction VR system. Using a 3D controller, suitable surgical trajectory can be defined by manipulating the tumor mass, peritumoral microstructure, and brain tissues before neurosurgery. Post-surgery evaluation showed that this system was useful to design pre-surgerical plan and optimize therapeutic outcome.","1558-4615","978-1-4244-0787-3","10.1109/IEMBS.2007.4352542","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4352542","","Virtual reality;Neurosurgery;Neoplasms;Surgery;Trajectory;Tensile stress;Magnetic resonance imaging;Visualization;Anatomy;Weight control","biodiffusion;biomedical MRI;brain;cancer;neurophysiology;surgery;tumours;virtual reality","DTI-based virtual reality system;neurosurgery;brain tumor mass;peritumoral structures;peritumoral edema;surgical trajectory planning;tumor excision;postsurgery evaluation;diffusion tensor MRI;therapeutic effects monitoring;3D virtual reality environment;neural tractography;peritumoral anatomy;3D controller;brain tissue microstructure;presurgerical plan design","Computer Graphics;Diffusion Magnetic Resonance Imaging;Diffusion Magnetic Resonance Imaging;Equipment Design;Equipment Failure Analysis;Image Interpretation, Computer-Assisted;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Imaging, Three-Dimensional;Neurosurgical Procedures;Neurosurgical Procedures;Surgery, Computer-Assisted;Surgery, Computer-Assisted;User-Computer Interface","2","","10","","22 Oct 2007","","","IEEE","IEEE Conferences"
"Towards a Proximal resource-based architecture to support augmented reality applications","C. Taylor; J. Pasquale","Computer Science and Engineering, University of California, San Diego, La Jolla, CA; Computer Science and Engineering, University of California, San Diego, La Jolla, CA","2010 Cloud-Mobile Convergence for Virtual Reality Workshop (CMCVR 2010) Proceedings","2 Sep 2010","2010","","","5","9","We are developing a new enhanced cloud-based computing architecture, called the Proximal Workspace architecture to allow access and interaction between lightweight devices, e.g., video glasses, earphones, wrist displays, body sensors, etc., and applications that represent a new generation of computationand-data-intensive programs in areas such as augmented reality. While lightweight devices offer an easy way for these applications to collect user data and offer feedback, the applications cannot be run natively and completely on these devices because of high resource demands. Making these applications available via a cloud, while promoting ubiquitous access and providing the necessary resources to execute the applications, induces large delays due to network latency. To solve these problems, we are developing a new system architecture based on supporting workspaces which provide nearby computing power to the users devices and thus mediate between them and the clouds computing resources. Specifically, a workspace provides a set of middleware utilities designed to exploit local resources, and provide specific functions such as rendering of graphics, pre-fetching of data, and combining data from different servers. More generally, the workspace is designed to run any subset of activities that cannot be run on a user's device due to computation speed or storage size, and cannot be run on a cloud server due to network latency. Ultimately, the goal is to produce a set of middleware utilities that when run in the workspace with highly-interactive, computation/data intensive applications will result in better user-perceived performance. We are exploring this system architecture constructively, by adapting applications that benefit from this architecture and discovering how best to suit their needs. We have already adapted VNC (Virtual Network Computing, which allows local interaction with remote computations) to run under a similar architecture, and as a result increased video performance in high network latency conditions by an order of magnitude. We are currently working on adapting Google Earth to run under this system architecture, with the goal of the user being able to intuitively navigate through renderings of Ancient Rome in video glasses, without being hampered by any bulky equipment.","2160-2891","978-1-4244-5861-5","10.1109/CMCVR.2010.5560606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5560606","","Servers;Computer architecture;Google;Earth;Rendering (computer graphics);Three dimensional displays;Games","augmented reality;Internet;middleware;software architecture;ubiquitous computing","resource-based architecture;augmented reality applications;cloud-based computing architecture;proximal workspace architecture;lightweight devices;video glasses;earphones;wrist displays;body sensors;computation and-data-intensive programs;ubiquitous access;middleware utilities;VNC;virtual network computing;Google Earth","","7","","19","","2 Sep 2010","","","IEEE","IEEE Conferences"
"A Situation Visualization System Based on 2D&3D Electronic Sand Table","Q. Li; H. Liu; Z. Wu","CSSC System Engineering Research Institute, Beijing, China; CSSC System Engineering Research Institute, Beijing, China; CSSC System Engineering Research Institute, Beijing, China","2018 IEEE 3rd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)","16 Dec 2018","2018","","","2057","2060","The situation visualization had acted an important prop of judging the situation and determining the decision, in order to improve the ability of scene show and Human-Computer Interaction (HCI), a situation visualization system based on 2D&3D electronic sand table was proposed. Firstly, focusing on the linkage mode, the 2D&3D electronic sand table was designed with the three-tier structure. Then the general architecture of the situation visualization system was built, the basic flow was defined. Finally, software-hardware platform of the situation visualization was applied for the multi-commander consultation and decision-making. The result shows the application value of the system could be effective and significant.","2381-0947","978-1-5386-4509-3","10.1109/IAEAC.2018.8577668","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8577668","situation visualization;2D&3D;electronic sand table;HCI;multi-commander consultation","Three-dimensional displays;Two dimensional displays;Human computer interaction;Tools;Couplings;Databases;Data visualization","data visualisation;human computer interaction;virtual reality","situation visualization system;3D electronic sand table;2D electronic sand table;human-computer interaction;multi-commander consultation;software-hardware platform;decision-making","","","","5","","16 Dec 2018","","","IEEE","IEEE Conferences"
"Bayesian-Optimized Impedance Control of an Aerial Robot for Safe Physical Interaction with the Environment","A. Khattab; R. Rashad; J. B. C. Engelen; S. Stramigioli","Robotics and Mechatronics group, University of Twente, Enschede, The Netherlands; Robotics and Mechatronics group, University of Twente, Enschede, The Netherlands; Robotics and Mechatronics group, University of Twente, Enschede, The Netherlands; Robotics and Mechatronics group, ITMO University, Saint Petersburg, Russia","2019 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)","26 Sep 2019","2019","","","172","179","Impedance control is a widely used interaction-control technique for aerial and ground robots. To achieve consistent performance during impedance control tasks, an a-priori knowledge of the environment parameters is needed to adjust the controller's impedance parameters accordingly. Concentrating on tasks requiring constant impedance parameters throughout operation, a model-free learning framework is proposed to autonomously find the suitable parameters values. The framework relies on Bayesian optimization and episodic reward calculation requiring the drone to repeatedly perform a predetermined task in the environment actively searching in the impedance parameters space. The sample-efficiency and safety of learning were improved by adding two novel modifications to standard Bayesian optimization. The proposed technique was validated in a high fidelity simulation environment. The results show that the proposed framework is able to automatically find suitable impedance parameters values in different situations given the same initial knowledge and that the learned parameters values can be generalized to similar interaction tasks.","2475-8426","978-1-7281-0778-3","10.1109/SSRR.2019.8848967","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848967","","Impedance;Task analysis;Bayes methods;Optimization;Unmanned aerial vehicles;Robot sensing systems","aerospace robotics;Bayes methods;control engineering computing;human-robot interaction;learning (artificial intelligence);mobile robots;optimisation","aerial ground robots;model-free learning framework;Bayesian-optimized impedance control;safe physical interaction;interaction-control technique","","","","15","","26 Sep 2019","","","IEEE","IEEE Conferences"
"MIME: A Mixed-Space Collaborative System with Three Immersion Levels and Multiple Users","I. García-Pereira; J. Gimeno; M. Pérez; C. Portalés; S. Casas","Department of Computer Science, University of Valencia; Department of Computer Science, University of Valencia; Department of Computer Science, University of Valencia; Department of Computer Science, University of Valencia; Department of Computer Science, University of Valencia","2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","179","183","Shared spaces for remote collaboration are nowadays possible by considering a variety of users, devices, immersion systems, interaction capabilities, navigation paradigms, etc. There is a substantial amount of research done in this line, proposing different solutions. However, still a more general solution that considers the heterogeneity of the involved actors/items is lacking. In this paper, we present MIME, a mixed-space tri-collaborative system. Differently from other mixed-space systems, MIME considers three different types of users (in different locations) according to the level of immersion in the system, who can interact simultaneously - what we call a tri-collaboration. For the three types, we provide a solution to navigate, point at objects/locations and make annotations, while users are able to see a virtual representation of the rest of users. Additionally, the total number of users that can simultaneously interact with the system is only restricted by the available hardware, i.e., various users of the same type can be simultaneously connected to the system. We have conducted a preliminary study at the laboratory level, showing that MIME is a promising tool that can be used in many real cases for different purposes.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699172","Augmented Reality;Virtual Reality;shared spaces;mixed-space;remote collaboration;K.5.1 [Multimedia Information Systems]: Artificial, augmented, and virtual realities","Augmented reality","groupware;virtual reality","virtual representation;mixed-space tri-collaborative system;interaction capabilities;immersion systems;remote collaboration;MIME","","3","","15","","29 Apr 2019","","","IEEE","IEEE Conferences"
"A Study on User Interaction with Multi-Window Screen Support Framework for Multitasking Operations on Smartphones","Ginny; C. Kumar; K. Naik","Department of Computer Science and Engineering, Indian Institute of Technology (ISM), Dhanbad, Jharkhand, India; Department of Computer Science and Engineering, Indian Institute of Technology (ISM), Dhanbad, Jharkhand, India; Department of Electrical and Computer Engineering, University of Waterloo, Ontario, Canada","2017 14th IEEE India Council International Conference (INDICON)","11 Oct 2018","2017","","","1","6","Advancement in Smartphone technologies has added one more feather to its cap by introducing multi-window screen support. This latest addition has been introduced in Android Nougat (7.0) which supports concurrent display of more than one application. The multi-tasking feature developed for Android Nougat (7.0) has been partially adopted by the previous versions of the Android through some root accessibility adjustments. This paper presents a detailed analysis of the user interaction with multi-window framework through user-interaction information extracted from different mobile devices. Multinomial regression analysis has been applied on the collected user interaction dataset to estimate the relationship between key factors and generalize the user trend towards the multi-window framework applicability.","2325-9418","978-1-5386-4318-1","10.1109/INDICON.2017.8487718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8487718","Multi-window Framework;Multitasking;Multinomial Logistic Regression","Smart phones;Multitasking;Microsoft Windows;Logistics;Fitting;Regression analysis","Android (operating system);human computer interaction;mobile computing;multiprogramming;regression analysis;smart phones;user interfaces","multiwindow framework applicability;multiwindow screen support framework;multitasking operations;smartphones;Android Nougat;concurrent display;multitasking feature;root accessibility adjustments;user-interaction information;multinomial regression analysis;smartphone technologies;mobile devices","","","","9","","11 Oct 2018","","","IEEE","IEEE Conferences"
"Prophet: A Parallel Instruction-Oriented Many-Core Simulator","W. Zhang; X. Ji; Y. Lu; H. Wang; H. Chen; P. Yew","Software SchoolShanghai Key Laboratory of Data Science; Software SchoolShanghai Key Laboratory of Data Science; Shanghai Key Laboratory of Data ScienceSchool of Computer Science; Software SchoolShanghai Key Laboratory of Data Science; Institute of Parallel and Distributed Systems, Shanghai Jiaotong University, Shanghai, China; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN","IEEE Transactions on Parallel and Distributed Systems","8 Sep 2017","2017","28","10","2939","2952","Most existing computer architecture simulators are cycle oriented, i.e., they are driven cycle by cycle. However, frequent switches among simulation contexts, excessive buffer accesses and tightly coupled manner often make such an architecture simulator slow, difficult to parallelize and hard to scale to large-scale many-core systems. In this paper, we propose Prophet, a parallel instruction-oriented simulation framework for many-cores. Prophet adopts a general instruction-oriented model to simulate processor cores, in which a simulator is built from the perspective of each simulated instruction impacting a small number of relevant processor components, as opposed to that of a large number of processor components executing many instructions in each cycle as in the cycle-oriented approach. Prophet determines the execution cycle of a simulated instruction based on the states of the relevant components impacted by the instruction, and update the components states after the execution of the instruction. Prophet also adopts a speculative model to decouple private resources from the shared resources (e.g., shared cache), which avoids unnecessary interactions between them and only pays a penalty upon a rare mis-speculation. We have designed and implemented a prototype of Prophet that supports both user-level and full-system simulation. Experimental results show Prophet can scale up to simulate thousands of simulated cores (4,096 cores in the current implementation) with good performance and small accuracy loss. It achieves average simulation speeds of about 98 and 235 MIPS (millions of simulated instructions per second) for full-system and user-level simulation, respectively, with only 3 percent IPC error rate and negligible deviation in cache simulation results. When run on a many-core platform (i.e., Intel Xeon Phi), it achieved an average simulation speed of about 413 MIPS.","1558-2183","","10.1109/TPDS.2017.2700307","National Key Research and Development Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7917344","Instruction-oriented;parallel;manycore;simulation;architecture-simulation","Computational modeling;Timing;Data models;Pipelines;Registers;Clocks","digital simulation;multiprocessing systems;parallel processing","Prophet;many-core simulator;large-scale many-core systems;parallel instruction-oriented simulation;general instruction-oriented model","","2","","31","Traditional","2 May 2017","","","IEEE","IEEE Journals"
"Modeling individual behaviors in crowd simulation","A. Braun; S. R. Musse; L. P. L. de Oliveira; B. E. J. Bodmann","Masters in Appl. Comput., Univ. of Vale do Rio dos Sinos, Sao Leopoldo, Brazil; Masters in Appl. Comput., Univ. of Vale do Rio dos Sinos, Sao Leopoldo, Brazil; Masters in Appl. Comput., Univ. of Vale do Rio dos Sinos, Sao Leopoldo, Brazil; Masters in Appl. Comput., Univ. of Vale do Rio dos Sinos, Sao Leopoldo, Brazil","Proceedings 11th IEEE International Workshop on Program Comprehension","21 May 2003","2003","","","143","148","This paper presents a model for studying the impact of individual agent characteristics in emergent groups, based on the evacuation efficiency as a result of local interactions. We used the physically based model of crowd simulation proposed by Helbing et al. (2000) and generalized it in order to deal with different individualities for agent and group behaviors. In addition, we present a framework to visualize the virtual agents and discuss the obtained results. A variety of simulations with different parameter sets shows significant impact on the evacuation scenario.","1087-4844","0-7695-1934-2","10.1109/CASA.2003.1199317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1199317","","Computational modeling;Visualization;Birds;Animation;Humans;History;Motion control;Psychology;Application software;Resource management","simulation;software agents;data visualisation;virtual reality","individual behavior modeling;crowd simulation;individual agents;emergent groups;evacuation efficiency;local interactions;physically based model;virtual agent visualization","","67","","12","","21 May 2003","","","IEEE","IEEE Conferences"
"CTLSS-an advanced electromagnetic simulation tool for designing high-power microwave sources","S. J. Cooke; A. Mondelli; B. Levush; T. M. Antonsen; D. P. Chernin; T. H. McClure; D. R. Whaley; M. Basten","Adv. Technol. Group, SAIC, McLean, VA, USA; NA; NA; NA; NA; NA; NA; NA","IEEE Transactions on Plasma Science","6 Aug 2002","2000","28","3","841","866","Simulation-based-design (SBD) techniques to achieve ""first-pass design success"" depend on the development of fast, accurate, realistic models that can handle material properties, geometry, and appropriate boundary conditions. This paper describes a new three-dimensional (3-D) electromagnetic and large-signal simulation tool. Cold-Test and Large-Signal Simulator (CTLSS), which has been developed as part of an SBD tool suite for vacuum electron devices. Computational electromagnetic codes are essential for applying the SBD methodology to the design of vacuum electron devices and components. CTLSS offers the unique advantage that its computational electromagnetics model is linked intimately with a large-signal simulation tool for computing the electron-wave interaction in the radiating structure. Currently, this link has been implemented for helix traveling-wave tubes (TWTs) only, using the CHRISTINE code as the large-signal model, but a new, general, large-signal model is under development and is described in this paper. The electromagnetic simulation engine in CTLSS has been designed and implemented as a volumetric frequency-domain model that can handle both resonant eigenvalue problems, using the Jacobi-Davidson algorithm, and nonresonant driven-frequency problems, using the quasi-minimal residual (QMR) technique to invert the non-Hermitian matrices that often occur in real problems. The features and advantages of this code relative to other models and results from the code for several classes of microwave devices are presented.","1939-9375","","10.1109/27.887737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=887737","","Computational modeling;Solid modeling;Electron devices;Computational electromagnetics;Electromagnetic modeling;Jacobian matrices;Material properties;Geometry;Boundary conditions;Design methodology","simulation;digital simulation;design aids;microwave devices;vacuum tubes","3-D electromagnetic simulation tool;high-power microwave sources;simulation-based-design techniques;first-pass design success;material properties;three-dimensional electromagnetic simulation tool;cold-test and large-signal simulator;tool suite;electromagnetic codes;vacuum electron devices;electronic device components;computational electromagnetics model;large-signal simulation tool;electron-wave interaction;radiating structure;helix traveling-wave tubes;CHRISTINE code;large-signal model;electromagnetic simulation engine;volumetric frequency-domain model;resonant eigenvalue problems;Jacobi-Davidson algorithm;nonresonant driven-frequency problems;quasi-minimal residual technique;nonHermitian matrices;matrix inversion;microwave devices","","35","1","47","","6 Aug 2002","","","IEEE","IEEE Journals"
"Modelling and simulation in global system engineering education","J. LeFevre","LAIL, CNRS, Villeneuve d'Ascq, France","1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation","6 Aug 2002","1997","3","","2045","2049 vol.3","Systems engineering must now cover the interaction of engineering and industrial systems with management, finance, socio-economic issues and environmental interactions (a discipline which we call ""global systems engineering""). Modelling and simulation are important tools for educating students to the design and analysis of these systems. The paper presents briefly our work to develop the methods and tools needed to integrate modelling and simulation of the class of systems described above in computer-aided packages including extensive, target-directed, multi-media help and educational support. A special emphasis is placed on a new modelling method generalising Forrester system dynamics and using some ideas from bond graphs. Due to its intuitive character, this method allows us to put modelling in the hands not only of modellers but also of end-users: domain specialists, teachers and students.","1062-922X","0-7803-4053-1","10.1109/ICSMC.1997.635164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=635164","","Systems engineering education;Systems engineering and theory;Computational modeling;Environmental management;Financial management;Engineering management;Finance;Analytical models;Computer simulation;Packaging","systems engineering;engineering education;bond graphs;socio-economic effects;computer aided instruction","global system engineering education;industrial systems;management;finance;socio-economic issues;environmental interactions;modelling;simulation;students;computer-aided packages;target-directed multi-media help;educational support;Forrester system dynamics;bond graphs","","","","","","6 Aug 2002","","","IEEE","IEEE Conferences"
