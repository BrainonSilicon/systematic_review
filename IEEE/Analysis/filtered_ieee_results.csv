Document Title,Authors,Author Affiliations,Publication Title,Date Added To Xplore,Publication Year,Volume,Issue,Start Page,End Page,Abstract,ISSN,ISBNs,DOI,Funding Information,PDF Link,Author Keywords,IEEE Terms,INSPEC Controlled Terms,INSPEC Non-Controlled Terms,Mesh_Terms,Article Citation Count,Patent Citation Count,Reference Count,License,Online Date,Issue Date,Meeting Date,Publisher,Document Identifier
A methodology for eliciting expert knowledge in virtual engineering environments,J. Ritchie; J. Simmons; R. Dewar; I. Carpenter,"Dept. of Mech. & Chem. Eng., Heriot-Watt Univ., Edinburgh, UK; NA; NA; NA",PICMET '99: Portland International Conference on Management of Engineering and Technology. Proceedings Vol-1: Book of Summaries (IEEE Cat. No.99CH36310),6-Aug-02,1999,1,,202 vol.1,,"Summary form only given. This research was initiated and applied in an area of engineering where tacit knowledge predominates; that of manual assembly planning. In this domain the evaluation and formalization of tacit knowledge is very difficult. Assembly planning is generally undertaken by planning 'experts' who produce plans after studying design data in whatever form. Research at Heriot-Watt University has shown that immersive virtual reality (VR) offers significant potential for the interactive planning of mechanical assemblies. Using this system for gathering assembly intent, a knowledge elicitation methodology was developed in which expert assembly planners' activities were logged while building a virtual assembly. This involved four main stages in its application: definition of the salient component attributes (repertory grid analysis); evaluation of attributes for given components (manual evaluation); recording expert assembly usage data (nonintrusive VR data logging); and generating rules relating the components to specific assembly methods (induction). This paper demonstrates how this novel nonintrusive knowledge acquisition methodology can be applied using immersive virtual environments; implying that, as globalizes technology becomes available, this may be a route to the formalization of company know-how.",,1-890843-02-4,10.1109/PICMET.1999.808115,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=808115,,Knowledge engineering;Virtual reality;Assembly systems;Knowledge based systems;Design engineering;Chemical engineering;Informatics;Expert systems;Heart;Buildings,knowledge acquisition;assembly planning;virtual reality;interactive systems,expert knowledge elicitation;virtual engineering environments;knowledge based systems;manual assembly planning;Heriot-Watt University;immersive virtual reality;interactive planning;mechanical assemblies;virtual assembly;repertory grid analysis;manual evaluation;nonintrusive VR data logging;nonintrusive knowledge acquisition methodology,,,,,,6-Aug-02,,,IEEE,IEEE Conferences
A Haptic Interface with Motor/Brake System for Colonoscopy Simulation,E. Samur; L. Flaction; U. Spaelter; H. Bleuler; D. Hellier; S. Ourselin,"Laboratory of Robotic Systems, Ecole Polytechnique F√©d√©rale de Lausanne (EPFL), Switzerland; Laboratory of Robotic Systems, Ecole Polytechnique F√©d√©rale de Lausanne (EPFL), Switzerland; Laboratory of Robotic Systems, Ecole Polytechnique F√©d√©rale de Lausanne (EPFL), Switzerland; Laboratory of Robotic Systems, Ecole Polytechnique F√©d√©rale de Lausanne (EPFL), Switzerland; BioMedIA Lab, CSIRO E-Health Research Centre, Brisbane, Australia, david.hellier@csiro.au; BioMedIA Lab, CSIRO E-Health Research Centre, Brisbane, Australia",2008 Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems,31-Mar-08,2008,,,477,478,"Training for colonoscopy, which is the examination and treatment of the colon, is often performed on real patients once the physician has passed the novice level. This increases the risk of colon injury to the patient and lengthens the procedure time. Since a decade ago, there has been research on virtual reality surgery simulators with haptic feedback. The main goal is to provide an alternative to traditional training methods on animals, cadavers or real patients. Haptic feedback is a key feature for every surgery simulator for the training of hand-eye coordination. In this paper, a compact and portable haptic interface is presented for the colonoscopy. The haptic interface provides position data acquisition and force feedback in linear and rotational directions with combined electrical motors and passive brakes to cover a large range of forces. The motorized drives are used for active force feedback and friction compensation and the brakes are used for high force rendering without slipping. This novel design allows decoupled motion in both directions.",2324-7355,978-1-4244-2005-6,10.1109/HAPTICS.2008.4479998,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4479998,B.0 [Hardware]: General¬øSurgery Simulators;I.6.3 [Computing Methodologies]: Simulation and Modeling¬øApplications,Haptic interfaces;Colonoscopy;Force feedback;Colon;Surgery;Medical treatment;Injuries;Virtual reality;Animals;Cadaver,DC motors;digital simulation;force feedback;haptic interfaces;patient treatment;virtual reality,haptic interface;colonoscopy simulation;colon treatment;brake system;electrical motor system;virtual reality surgery simulator;haptic force feedback;data acquisition;friction compensation;force rendering;hand-eye coordination training,,11,2,9,,31-Mar-08,,,IEEE,IEEE Conferences
The impact of motion in virtual environments on memorization performance,P. H√§fner; C. Vinke; V. H√§fner; J. Ovtcharova; W. Schotte,"Institute for Information, Management in Engineering, Karlsruhe Institute of Technology, Zirkel 2, 76131, Germany; Institute for Information, Management in Engineering, Karlsruhe Institute of Technology, Zirkel 2, 76131, Germany; Institute for Information, Management in Engineering, Karlsruhe Institute of Technology, Zirkel 2, 76131, Germany; Institute for Information, Management in Engineering, Karlsruhe Institute of Technology, Zirkel 2, 76131, Germany; High Performance Computing Center Stuttgart, University of Stuttgart, Nobelstr. 19, 70569, Germany",2013 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA),3-Oct-13,2013,,,104,109,"Virtual environments are more and more used for educational and training purposes. In order to design virtual environments for these applications in particular, it is very important to get a deep understanding of the relevant design features supporting the user's process of learning and comprehension. Relevance and implementation of these features as well as the benefits of virtual learning environments over traditional educational approaches in general are rarely explored. Focusing on modes of interaction in this work, we examined the effect of different motion types on the knowledge acquisition of users in various virtual environments. For our study we chose a simple memorization task as approximation of low cognitive knowledge acquirement. We hypothesized motion types and immersion levels influence memorization performance in virtual environments. The memorization task was conducted in two virtual environments with different levels of immersion: A high-immersive Cave Automatic Virtual Environment (CAVE) and a low-immersive desktop virtual environment. Two motion types in virtual environments were explored: Physical and virtual walking. In the CAVE physical walking was implemented by using motion capturing and virtual walking was realized using a joystick-like input device. The results indicate neither motion types nor immersion levels in virtual environments affect memorization performance significantly.",2377-9322,978-1-4673-4703-7,10.1109/CIVEMSA.2013.6617404,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6617404,cognition;human computer interaction;learning;memory;motion;virtual environment;virtual reality,Virtual environments;Navigation;Legged locomotion;Tutorials;Stereo vision;Educational institutions,computer aided instruction;human computer interaction;human factors;interactive devices;virtual reality,training;education;CAVE physical walking;virtual walking;low-immersive desktop virtual environment;high-immersive CAVE automatic virtual environment;hypothesized motion types;cognitive knowledge acquirement;user knowledge acquisition;virtual learning environments;user process;virtual environment design;training purposes;memorization performance,,4,,12,,3-Oct-13,,,IEEE,IEEE Conferences
Remote machinery maintenance system with the use of virtual reality,M. Bellamine; N. Abe; K. Tanaka; H. Taki,"Fac. of Comput. Sci. & Eng., Kyushu Inst. of Technol., Fukuoka, Japan; Fac. of Comput. Sci. & Eng., Kyushu Inst. of Technol., Fukuoka, Japan; Fac. of Comput. Sci. & Eng., Kyushu Inst. of Technol., Fukuoka, Japan; NA",Proceedings. First International Symposium on 3D Data Processing Visualization and Transmission,7-Nov-02,2002,,,38,43,"The use of robots for fault diagnosis and maintenance operations is being more widely used. Robot control is generally done by teleoperation, which still has many weak points. To solve these problems, we use virtual reality techniques. We conceive a system for collecting vibration data using remote robot control by a virtual designed model. With our model we can manipulate both the machine to be checked, and the robot. In our 3D model the data collection points are very well known. This will assure precision in data collection. Our system assure good remote maintenance and fault diagnosis not only in dangerous places, but also in ordinary cases.",,0-7695-1521-4,10.1109/TDPVT.2002.1024036,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1024036,,Machinery;Virtual reality;Fault diagnosis;Robot sensing systems;Robot control;Inspection;Orbital robotics;Acoustic noise;Force measurement;Data visualization,telerobotics;maintenance engineering;virtual reality;engineering graphics;data acquisition;vibration measurement;sensors;manipulators,remote machinery maintenance system;virtual reality;fault diagnosis;teleoperation;vibration data collection;3D model;data collection,,10,,4,,7-Nov-02,,,IEEE,IEEE Conferences
Design and development of wetland evaluation system based on remote sensing and 3D visualization,Jing Lingling; Zhu Lin; Gong Huili; Pan Yun; Du Lufei,"College of Resource Environment and Tourism, Capital Normal University, Beijing, China; College of Resource Environment and Tourism, Capital Normal University, Beijing, China; College of Resource Environment and Tourism, Capital Normal University, Beijing, China; Information Acquisition and Application Key, Laboratory of Education Ministry, Capital Normal University, Beijing, China; Information Acquisition and Application Key, Laboratory of Education Ministry, Capital Normal University, Beijing, China",2010 International Conference on Computer Application and System Modeling (ICCASM 2010),4-Nov-10,2010,2,,V2-170,V2-173,"To meet the demands of the regional wetland evaluation, a wetland evaluation system (WES) was developed, which integrated digital image processing, economic value evaluation model of wetland functions and 3D visualization. This paper chose CASM ImageInfo as one part of WES for processing the multiple source images. Based on the wetland database management system, a graphical modeling tool was developed which supplied many wetland value calculation functions in form of a flowchart and made wetland evaluation process semi-automatic. Besides, Jx-4 (a digital photogrammetric system) was chosen as the data preparation module in the WES. Based on the DEM data derived from Jx-4. 3D visualization of regional wetlands was realized by the VR (Virtual Reality) technology. The VR technology was integrated to simulate the circumstance of the wetland and the wetland dynamic processes under different hydrologic conditions in 3D space. This system was an effective and fully digital processing platform for the researchers to evaluate regional wetland services and to obtain the general circumstance and the change of the wetland. This system provided advanced scientific management and effective decision-making information for wetland resources.",2161-9077,978-1-4244-7237-6,10.1109/ICCASM.2010.5618994,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5618994,remote sensing technology;evaluation model of wetland services;GIS;3D visualization;framework of WES,Visualization,data visualisation;database management systems;geophysical image processing;hydrological techniques;remote sensing;virtual reality,wetland evaluation system;remote sensing;3D visualization;digital image processing;economic value evaluation model;wetland function;CASM imagelnfo;multiple source image;database management system;graphical modeling tool;wetland value calculation function;DEM data;virtual reality;wetland dynamic process;hydrologic condition;3D space;scientific management;decision making information;wetland resource,,3,,6,,4-Nov-10,,,IEEE,IEEE Conferences
Time-Variant Visual Attention in 360-Degree Video Playback,H. Huang; J. Chen; H. Xue; Y. Huang; T. Zhao,"College of Physics and Information Engineering, Fuzhou University, Fuzhou, China; College of Physics and Information Engineering, Fuzhou University, Fuzhou, China; College of Physics and Information Engineering, Fuzhou University, Fuzhou, China; College of Physics and Information Engineering, Fuzhou University, Fuzhou, China; College of Physics and Information Engineering, Fuzhou University, Fuzhou, China","2018 IEEE International Symposium on Haptic, Audio and Visual Environments and Games (HAVE)",29-Nov-18,2018,,,1,5,"The user visual attention has been playing an imperative role in visual Quality of Experience (QoE) modeling. In recent years, researchers have developed numerous visual attention models for images and videos. However, existing studies on visual attention generally perform on spatial domain (i.e. pictures) without consideration on time-variant user attention. Besides, the user attention on immersive video playback has not been well investigated in Virtual Reality (VR) environment. In this paper, we design subjective experiments to acquire the user attention during 360-degree video playback, in order to characterize the visual attention changes on time axis. We compare and model the temporal attentions in two scenarios: 360-degree video and conventional 2D video display. It is observed in video display, the user attention needs a short period (~ 30 seconds) to concentrate to a relatively stable level. Within this period, the user attention to 360-degree video is significantly lower than that to traditional 2D videos, which shows that the users are relatively difficult to adapt to VR display. Therefore, short videos less than 30 seconds, especially short 360-degree videos, are not preferable in subjective video quality assessment, although they have been tested in some scenarios. We hope this conclusion would conduce to QoE modeling during video display of VR environment.",,978-1-5386-5838-3,10.1109/HAVE.2018.8547419,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8547419,Virtual Reality (VR);360-degree video;visual attention;Quality of Experience (QoE);visual quality,Visualization;Two dimensional displays;Quality of experience;Resists;Solid modeling;Video recording;Quality assessment,data visualisation;quality of experience;video cameras;video signal processing;video streaming;virtual reality,time-variant visual attention;360-degree video playback;user visual attention;time-variant user attention;immersive video playback;visual attention changes;temporal attentions;video display;short videos;subjective video quality assessment;visual quality;visual attention models;quality of experience modeling;VR environment;QoE modeling;virtual reality environment,,1,,17,,29-Nov-18,,,IEEE,IEEE Conferences
Virtual reality for post-stroke shoulder-arm motor rehabilitation: Training system & assessment method,Shih-Ching Yeh; Si-Huei Lee; Jia-Chi Wang; Shuya Chen; Yu-Tsung Chen; Yi-Yung Yang; Huang-Ren Chen; Yen-Po Hung,"Department of Computer Science and Information Engineering National Central University, China; Taipei Veterans General Hospital, Taiwan; Taipei Veterans General Hospital, Taiwan; Department of Physical Therapy, China Medical University, China; Department of Computer Science and Information Engineering National Central University, China; Taipei Veterans General Hospital, Taiwan; Department of Computer Science and Information Engineering National Central University, China; Department of Computer Science and Information Engineering National Central University, China","2012 IEEE 14th International Conference on e-Health Networking, Applications and Services (Healthcom)",13-Dec-12,2012,,,190,195,"Stroke is one of the major diseases around the world. The brain injury caused by stroke will derive sustaining neurological disorder of different forms, which in turn will lead to all kinds of limb and body exercise hindrance and will cause significant challenge to the life of the patient, that is, the quality of life of the patient is going to be strictly affected. Along with the development and popularity of technology, scholars in the medical care and rehabilitation fields are trying to integrate all kinds of new technologies to perform the development of new rehabilitation training system. This research aims at rehabilitation items of upper limbs, which include the reciprocating stretching of upper limb, reaching of the upper arm, bi-lateral coordination and balance of the body. In association with interactive technology, game technology, sensor technology and stereo image technology, virtual reality physical-based training task is developed, and initial pilot test is done on patient with stroke, meanwhile, multi-dimensional experimental results are acquired, which include clinical test assessment, task performance, historical data of exercise track and psychological emotional data. The research objectives are to verify the functionality of the system, to verify the effectiveness of the system on rehabilitation, to develop new assessment method and to investigate topics related to human machine interaction. The experimental results have verified the functionality of this rehabilitation training task in all aspects. Through the exercise analysis of the historical data of exercise track and the statistical analysis of task performance of the past therapy sessions, this system can acquire successfully reliable and valuable information to be used for future verification of medical therapeutic effectiveness and the development of new type of clinical assessment method. In the mean time, according to the measured psychological emotional data as perceived subjectively, this system indeed can urge the patient to engage continuously rehabilitation therapeutic session that is based on this training system and enjoy it, besides, the authors are very confident on the possibly generated rehabilitation effect of these two training tasks.",,978-1-4577-2040-6,10.1109/HealthCom.2012.6379398,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6379398,,Training;Games;Virtual reality;Psychology;Solid modeling;Extremities;Medical treatment,computer games;diseases;medical disorders;medical image processing;patient rehabilitation;stereo image processing;virtual reality,post-stroke shoulder-arm motor rehabilitation;brain injury;neurological disorder;quality of life;medical care;rehabilitation training system;interactive technology;game technology;sensor technology;stereo image technology;virtual reality physical-based training task;human machine interaction;clinical assessment method,,2,,14,,13-Dec-12,,,IEEE,IEEE Conferences
Training Simulations for Crime Risk Assessment,M. Kavakli,"Leader, Interactive Systems and Virtual Reality Research Group, Department of Computing, Macquarie University, Sydney, Australia, NSW 2109. phone: 61 2 9850 9572; fax: 61 2 9850 9551; e-mail: manolya@ics.mq.edu.au",2006 7th International Conference on Information Technology Based Higher Education and Training,2-Apr-07,2006,,,203,210,"The purpose of this paper is to review training simulations for crime risk assessment and to discuss the system architecture of a training simulation (RiskMan). Computer aided training systems offer a flexible and cost-effective method for learning new skills. The satisfactory management of risk situations involves risk identification, the development of risk handling strategies and plans and the conduct and monitoring of those plans. Recognising the importance of tacit knowledge, scenario-based training has gained importance in recent years. For example, USA General Accounting Office (GAO) released a report on Homeland security titled Risk Management approach can guide preparedness efforts. This report provides a list of risk assessment measurements for contingency plan development and a matrix for risk-based scenario development. In this paper, integrating traditional scenario-based training with desktop VR systems using game engineering, we investigate how a virtual reality training system, which draws on research in the areas of computer games, knowledge acquisition, agent technology and natural language processing, can provide a safe learning experience to assist acquisition of the necessary tacit knowledge. The aim of RiskMan is to train police officers to handle high-risk situations. RiskMan is an ARC Discovery project carried out by the Department of Computing in Macquarie University. RiskMan has been developed using a very-high level scripting language of a game engine, Unreal Tournament 2004. It is composed of modules such as a Scenario-based Expert System, a Narrative Engine, a Game Engine, and a CAD package. RiskMan uses socket connections to feed information between the Narrative Engine and Sim Master to Unreal Tournament Game Engine (UT2004)",,1-4244-0405-3,10.1109/ITHET.2006.339765,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4141628,Games;Training;Simulation;Risk Analysis,Risk management;Management training;Engines;Computational modeling;Virtual reality;Computerized monitoring;Terrorism;Knowledge engineering;Systems engineering and theory;Knowledge acquisition,computer based training;computer games;expert systems;knowledge acquisition;natural language processing;police;risk analysis;software agents;virtual reality,training simulation;crime risk assessment;RiskMan;computer aided training system;skills learning;risk identification;risk handling;scenario-based training;contingency plan development;game engineering;virtual reality training system;computer games;knowledge acquisition;agent technology;natural language processing;police officer training;scenario-based expert system;narrative engine;risk analysis,,4,,30,,2-Apr-07,,,IEEE,IEEE Conferences
Integration between virtual-reality and video-based systems to deliver cognitive tele-rehabilitation; three case studies,S. Harel; R. Kizony; H. Kfir; Y. Feldman; M. Shani,"Gertner Institute for Epidemiology and Health Policy Research,Tel Hashomer,Israel; Sheba Medical Center,Center of Advanced Technologies in Rehabilitation,Israel; Sheba Medical Center,Telerehabilitation,Tel Hashomer,Israel; Gertner Institute for Epidemiology and Health Policy Research,Tel Hashomer,Israel; Gertner Institute for Epidemiology and Health Policy Research,Tel Hashomer,Israel",2019 International Conference on Virtual Rehabilitation (ICVR),13-Feb-20,2019,,,1,2,"The purpose of this paper is to describe implementation of VR-based and video-based cognitive telerehabilitation, as a part of a large clinical telerehabilitation service. Three clients in the chronic phase after an Acquired Brain Injury received cognitive tele-rehabilitation with a 3D sensor-based platform (VR-based system) and a video-based system. The therapy was provided on-line, once or twice a week. Each client set at least two functional goals using the Canadian Occupational Performance Measure. Improvement of at least one goal was seen in all clients. It seems that the use of the VR-based system together with the video-based system is feasible and may enhance adherence to treatment and generalization to daily activities.",2331-9569,978-1-7281-1285-5,10.1109/ICVR46560.2019.8994638,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994638,cognitive strategies;telerehabilitation;metacognitive;acquired brain injury,,brain;cognition;injuries;medical computing;neurophysiology;patient rehabilitation;patient treatment;telemedicine;virtual reality,Canadian Occupational Performance Measure;VR-based cognitive telerehabilitation;video-based cognitive telerehabilitation;video-based system;VR-based system;3D sensor-based platform;acquired brain injury;clinical telerehabilitation service;virtual-reality,,,,7,,13-Feb-20,,,IEEE,IEEE Conferences
Development of a haptic bilateral interface for arm self-rehabilitation,C. Morito; T. Shimono; N. Motoi; Y. Fujimoto; T. Tsuji; Y. Hasegawa; K. Abe; Y. Sakurai; S. Ishii,"Department of Electrical and Computer Engineering, Yokohama National University, 79-5 Tokiwadai, Hodogaya, 240-8501, JAPAN; Department of Electrical and Computer Engineering, Yokohama National University, 79-5 Tokiwadai, Hodogaya, 240-8501, JAPAN; Department of Electrical and Computer Engineering, Yokohama National University, 79-5 Tokiwadai, Hodogaya, 240-8501, JAPAN; Department of Electrical and Computer Engineering, Yokohama National University, 79-5 Tokiwadai, Hodogaya, 240-8501, JAPAN; Graduate School of Science and Engineering, Saitama University, 255 Shimo-ohkubo, Sakura, 338-8520, JAPAN; Rehabilitation Unit, Ushioda General Hospital, 1-6-20 Yakou, Tsurumi, Yokohama, 230-0001, JAPAN; Rehabilitation Unit, Ushioda General Hospital, 1-6-20 Yakou, Tsurumi, Yokohama, 230-0001, JAPAN; Faculty of Health and Social Work, Kanagawa University of Human Services, 1-10-1 Heisei, Yokosuka, 238-0013, JAPAN; Faculty of Health and Social Work, Kanagawa University of Human Services, 1-10-1 Heisei, Yokosuka, 238-0013, JAPAN",2013 IEEE/ASME International Conference on Advanced Intelligent Mechatronics,22-Aug-13,2013,,,804,809,"This paper presents a newly-developed haptic interface for arm self-rehabilitation based on bilateral control. The purpose of this research is the improvement of the physical function of patients' arm with hemiplegia. In order to acquire enough motion range for the rehabilitation, the X-Y tables with two degrees-of-freedom are utilized as the haptic system. The developed interface realizes the rehabilitation environment on the basis of the integration of the bilateral control system for haptic transmission between arms and the virtual reality for visual guidance. This integration can provide the self-rehabilitation suitable for the patients with hemiplegia. In this paper, the results of bilateral control in the presented haptic system and the results of basic evaluation for the physicality of the human arm in the reaching task are presented. From these experimental results, the utility of the developed interface is verified.",2159-6255,978-1-4673-5320-5,10.1109/AIM.2013.6584192,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6584192,,Force;Haptic interfaces;Virtual reality;Trajectory;Acceleration;Visualization,haptic interfaces;motion control;patient rehabilitation;virtual reality,haptic bilateral interface development;arm self rehabilitation;patient arm physical function;hemiplegia;degree of freedom;haptic system;bilateral control system integration;haptic transmission;virtual reality;visual guidance,,13,,14,,22-Aug-13,,,IEEE,IEEE Conferences
Crossing Streets: a K-12 virtual reality application for understanding knowledge acquisition,F. R. Rusch; D. S. Millar; R. E. Cimera; D. L. Shelden; U. Thakkar; D. A. Chapman; Y. H. Khan; D. D. Moore; J. S. LeBoy,"Transition Res. Lab., Illinois Univ., Champaign, IL, USA; NA; NA; NA; NA; NA; NA; NA; NA",Proceedings of IEEE 1997 Annual International Symposium on Virtual Reality,6-Aug-02,1997,,,211,,"Transportation-related skills have been identified by parents as a critical area in which to teach children and youths to be more independent. Crossing Streets, the authors' initial effort to investigate skill acquisition and generalization in a virtual reality environment, attempts to teach children, including those with disabilities, a safe way to cross a street.",1087-8270,0-8186-7843-7,10.1109/VRAIS.1997.583074,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=583074,,Virtual reality;Knowledge acquisition;Educational institutions;Recruitment;Collaboration;Virtual environment;Computer applications;Navigation;Application software;Software performance,virtual reality;safety;handicapped aids;computer aided instruction;road traffic,K-12 virtual reality application;Crossing Streets;transportation-related skills;children;youths;skill acquisition;knowledge acquisition;virtual reality environment;disabled children;teaching,,,,2,,6-Aug-02,,,IEEE,IEEE Conferences
Knowledge Spaces in VR: Intuitive Interfacing with a Multiperspective Hypermedia Environment,P. Gerjets; M. Lachmair; M. V. Butz; J. Lohmann,Leibniz-Institut f√ºr Wissensmedien; Leibniz-Institut f√ºr Wissensmedien; University of T√ºbingen; University of T√ºbingen,2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),30-Aug-18,2018,,,555,556,"Virtual reality technologies, along with motion based input devices allow for the design of innovative interfaces between learners and digital knowledge resources. These interfaces might facilitate knowledge work in educational and scientific contexts. Compared to 2D interfaces, immersive 3D environments provide greater flexibility regarding the interface design, however, so far no general, theory-driven and validated design principles are available. Seeing that complex learning environments can foster the development of various cognitive abilities, like multiperspective reasoning skills (MPRS), such design principles are highly desirable. Using multiperspective hypermedia environments (MHEs) as a testbed, the presented project aims to identify and evaluate design principles, derived from cognitive science. We will create and study interactive, immersive 3D-interface to MHEs using virtual reality technology. To evaluate the developed system, we will contrast the acquisition of MPRS in 2D and 3D learning environments. We expect that the developed design principles will be directly applicable for enhancing the accessibility of other knowledge environments.",,978-1-5386-3365-6,10.1109/VR.2018.8446137,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446137,"VR;Hypermedia Environment;HCI;Interaction Design;H.5.1 [Multimedia Information Systems]: Artificial, augmented and virtual realities;H.5.2 [User Interfaces]: Theory and Methods",Conferences;Virtual reality;Three-dimensional displays;User interfaces,cognition;computer aided instruction;hypermedia;interactive systems;virtual reality,knowledge spaces;intuitive interfacing;multiperspective hypermedia environment;virtual reality technology;motion based input devices;innovative interfaces;digital knowledge resources;knowledge work;educational contexts;scientific contexts;immersive 3D environments;interface design;general theory-driven;complex learning environments;cognitive abilities;multiperspective reasoning skills;MPRS;MHEs;3D learning environments;developed design principles;knowledge environments;VR,,1,,15,,30-Aug-18,,,IEEE,IEEE Conferences
Research Study Design for Teaching and Testing Fire Safety Skills with AR and VR Games,K. Tarkkanen; A. Lehto; D. Oliva; B. Somerkoski; T. Haavisto; M. Luimula,"ICT, Turku University of Applied Sciences,Turku,Finland; RDI Services, Turku University of Applied Sciences,Turku,Finland; ICT, Turku University of Applied Sciences,Turku,Finland; University of Turku,Department of Teacher Education,Turku,Finland; ICT, Turku University of Applied Sciences,Turku,Finland; ICT, Turku University of Applied Sciences,Turku,Finland",2020 11th IEEE International Conference on Cognitive Infocommunications (CogInfoCom),2-Nov-20,2020,,,167,172,"Virtual and augmented reality (VR & AR) games can provide innovative methods for teaching and learning important skills relating to fire safety. However, in an emergency context, testing the acquired knowledge and skills, i.e. verifying the learning, can be challenging. In this paper, we ask how the interplay between AR and VR could support learning verification. We describe two standalone games of both types, which interchangeably teach fire safety skills to children and verify their learning results. In particular, we describe the planned learning paths and research study designs for verification studies within and between these games to answer the above question. By operationalizing the two cases, the paper ends in proposing more generalized study design for AR and VR research in a fire safety context.",2380-7350,978-1-7281-8213-1,10.1109/CogInfoCom50765.2020.9237831,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237831,virtual reality;augmented reality;fire safety;serious games;research design,Conferences;Education;Games;Data collection;Augmented reality;Fire safety;Testing,augmented reality;computer aided instruction;computer games;emergency management;teaching,emergency context;learning verification;standalone games;augmented reality games;innovative methods;learning paths planning;fire safety skills teaching;fire safety skills testing;virtual reality games;AR games;VR games,,,,20,,2-Nov-20,,,IEEE,IEEE Conferences
Generalized approach for modeling minimally invasive surgery as a stochastic process using a discrete Markov model,J. Rosen; J. D. Brown; L. Chang; M. N. Sinanan; B. Hannaford,"Dept. of Electr. Eng., Univ. of Washington, WA, USA; NA; NA; NA; NA",IEEE Transactions on Biomedical Engineering,21-Feb-06,2006,53,3,399,413,Minimally invasive surgery (MIS) involves a multidimensional series of tasks requiring a synthesis between visual information and the kinematics and dynamics of the surgical tools. Analysis of these sources of information is a key step in defining objective criteria for characterizing surgical performance. The Blue DRAGON is a new system for acquiring the kinematics and the dynamics of two endoscopic tools synchronized with the endoscopic view of the surgical scene. Modeling the process of MIS using a finite state model [Markov model (MM)] reveals the internal structure of the surgical task and is utilized as one of the key steps in objectively assessing surgical performance. The experimental protocol includes tying an intracorporeal knot in a MIS setup performed on an animal model (pig) by 30 surgeons at different levels of training including expert surgeons. An objective learning curve was defined based on measuring quantitative statistical distance (similarity) between MM of experts and MM of residents at different levels of training. The objective learning curve was similar to that of the subjective performance analysis. The MM proved to be a powerful and compact mathematical model for decomposing a complex task such as laparoscopic suturing. Systems like surgical robots or virtual reality simulators in which the kinematics and the dynamics of the surgical tool are inherently measured may benefit from incorporation of the proposed methodology.,1558-2531,,10.1109/TBME.2005.869771,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1597490,Dynamics;haptics;human machine interface;kinematics;manipulation;Markov model;minimally invasive;robotics;simulation;soft tissue;surgery;surgical skill assessment;surgical tool;vector quantization,Minimally invasive surgery;Stochastic processes;Kinematics;Performance analysis;Multidimensional systems;Information analysis;Information resources;Layout;Animal structures;Protocols,surgery;Markov processes;endoscopes;medical robotics;virtual reality;robot kinematics,minimally invasive surgery;stochastic process;discrete Markov model;visual information;surgical tool kinematics;surgical tool dynamics;Blue DRAGON;endoscopic tools;finite state model;objective learning curve;subjective performance analysis;laparoscopic suturing;surgical robots;virtual reality simulators,"Computer Simulation;Endoscopes;Endoscopy;Expert Systems;Humans;Man-Machine Systems;Markov Chains;Models, Biological;Models, Statistical;Robotics;Robotics;Stochastic Processes;Surgery, Computer-Assisted;Surgery, Computer-Assisted;Surgical Procedures, Minimally Invasive;Surgical Procedures, Minimally Invasive;Task Performance and Analysis;User-Computer Interface",160,3,47,,21-Feb-06,,,IEEE,IEEE Journals
Constraint-Based Soft Tissue Simulation for Virtual Surgical Training,W. Tang; T. R. Wan,"School of Computing, University of Teesside, Middlesbrough, U.K.; School of Informatics, University of Bradford, Bradford, U.K.",IEEE Transactions on Biomedical Engineering,15-Oct-14,2014,61,11,2698,2706,"Most of surgical simulators employ a linear elastic model to simulate soft tissue material properties due to its computational efficiency and the simplicity. However, soft tissues often have elaborate nonlinear material characteristics. Most prominently, soft tissues are soft and compliant to small strains, but after initial deformations they are very resistant to further deformations even under large forces. Such material characteristic is referred as the nonlinear material incompliant which is computationally expensive and numerically difficult to simulate. This paper presents a constraint-based finite-element algorithm to simulate the nonlinear incompliant tissue materials efficiently for interactive simulation applications such as virtual surgery. Firstly, the proposed algorithm models the material stiffness behavior of soft tissues with a set of 3-D strain limit constraints on deformation strain tensors. By enforcing a large number of geometric constraints to achieve the material stiffness, the algorithm reduces the task of solving stiff equations of motion with a general numerical solver to iteratively resolving a set of constraints with a nonlinear Gauss-Seidel iterative process. Secondly, as a Gauss-Seidel method processes constraints individually, in order to speed up the global convergence of the large constrained system, a multiresolution hierarchy structure is also used to accelerate the computation significantly, making interactive simulations possible at a high level of details. Finally, this paper also presents a simple-to-build data acquisition system to validate simulation results with ex vivo tissue measurements. An interactive virtual reality-based simulation system is also demonstrated.",1558-2531,,10.1109/TBME.2014.2326009,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6820761,Nonlinear soft tissue simulation and modeling;robotic-assisted surgery;virtual surgical training,Strain;Biological tissues;Materials;Computational modeling;Solid modeling;Biological system modeling;Force,biomechanics;biomedical education;deformation;surgery;virtual reality,constraint-based soft tissue simulation;virtual surgical training;linear elastic model;soft tissue material properties;computational efficiency;nonlinear material characteristics;small strains;deformations;nonlinear material incompliant;interactive simulation;deformation strain tensors;strain limit constraints;geometric constraints;Gauss-Seidel iterative,"Abdomen;Algorithms;Animals;Computer Simulation;Liver;Magnetic Resonance Imaging;Models, Biological;Reproducibility of Results;Robotic Surgical Procedures;Swine;User-Computer Interface",16,,25,,23-May-14,,,IEEE,IEEE Journals
Immersive Virtual Reality for the Assessment and Training of Spatial Memory: Feasibility in Individuals with Brain Injury,J. Belger; S. Krohn; C. Finke; J. Tromp; F. Klotzsche; A. Villringer; M. Gaebler; P. Chojecki; E. Quinque; A. Th√∂ne-Otto,"University Hospital Leipzig,Clinic for Cognitive Neurology,Leipzig,Germany; Charit√©-Universit√§tsmedizin Berlin,Department of Neurology,Berlin,Germany; Charit√©-Universit√§tsmedizin Berlin,Department of Neurology,Berlin,Germany; Max Planck Institute for Human Cognitive and Brain Sciences,Leipzig,Germany; Max Planck Institute for Human Cognitive and Brain Sciences,Leipzig,Germany; Max Planck Institute for Human Cognitive and Brain Sciences,Leipzig,Germany; Max Planck Institute for Human Cognitive and Brain Sciences,Leipzig,Germany; Fraunhofer Institute for Telecommunications,Immersive Media and Communication Group,Berlin,Germany; University Hospital Leipzig,Clinic for Cognitive Neurology,Leipzig,Germany; University Hospital Leipzig,Clinic for Cognitive Neurology,Leipzig,Germany",2019 International Conference on Virtual Rehabilitation (ICVR),13-Feb-20,2019,,,1,2,"Immersive Virtual Reality (VR) shows promise for cognitive diagnostics and rehabilitation as it can present individuals with cognitive impairment with realistic, life-like environments, and allows to precisely record behavioral performance to infer indicators of cognitive processes. The aims of our study were to (1) determine the feasibility in using immersive VR in individuals with acquired brain injury, and detect limits in its applicability, and (2) estimate the extent to which the immersion, sense of presence, usability and general motivational aspects, and side effects affect users' experience. To that end, a novel VR task, the immersive Virtual Memory Task (imVMT), was developed and applied to measure the spatial memory. Preliminary data will be discussed with a focus on feasibility.",2331-9569,978-1-7281-1285-5,10.1109/ICVR46560.2019.8994342,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994342,virtual reality;neuropsychological diagnostic;spatial memory;feasibility,,brain;cognition;medical computing;neurophysiology;patient rehabilitation;virtual reality,cognitive processes;immersive VR;brain injury;spatial memory;immersive virtual reality;cognitive diagnostics;rehabilitation;cognitive impairment;behavioral performance;immersive virtual memory task;Immersive Virtual Reality,,,,9,,13-Feb-20,,,IEEE,IEEE Conferences
The development of virtual reality driving simulator for rehabilitation,H. B. Ahn; J. H. Ku; B. H. Cho; H. Kim; H. J. Jo; J. M. Lee; I. Y. Kim; S. I. Kim,"Biomed. Eng., Hanyang Univ., Seoul, South Korea; Biomed. Eng., Hanyang Univ., Seoul, South Korea; Biomed. Eng., Hanyang Univ., Seoul, South Korea; Biomed. Eng., Hanyang Univ., Seoul, South Korea; Biomed. Eng., Hanyang Univ., Seoul, South Korea; Biomed. Eng., Hanyang Univ., Seoul, South Korea; Biomed. Eng., Hanyang Univ., Seoul, South Korea; Biomed. Eng., Hanyang Univ., Seoul, South Korea",2001 Conference Proceedings of the 23rd Annual International Conference of the IEEE Engineering in Medicine and Biology Society,7-Nov-02,2001,4,,3780,3783 vol.4,"As the number of automobiles is increasing, a automobile is a general means of transportation. Therefore the driving ability became an important part in normal life. But accidents or diseases cause a reduction of some people's driving ability. When they try to acquire a driver's licence, ""on-road test"" may be very dangerous and difficult. So therapists have tried to assess and enhance handicapped peoples driving ability in the virtual environment safely. The goal of this study is to make a virtual reality driving simulator in order to check and enhance the subjects' driving ability. The driving simulator includes a real car that we remodelled for handicapped and connecter with a personal computer (PC) for more immersion. Also it includes a module to analyze the subject's driving ability variable.",1094-687X,0-7803-7211-5,10.1109/IEMBS.2001.1019661,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1019661,,Virtual reality;Automobiles;Computational modeling;Transportation;Accidents;Diseases;Licenses;Testing;Virtual environment;Computer simulation,digital simulation;patient rehabilitation;handicapped aids;microcomputer applications;automobiles;virtual reality,virtual reality driving simulator development;subject's driving ability variable analysis;handicapped peoples driving ability enhancement;personal computer;real car;driver's licence;safety;on-road test,,1,,4,,7-Nov-02,,,IEEE,IEEE Conferences
Simulating the experience of home environments,K. Ponto; R. Tredinnick; G. Casper,"University of Wisconsin - Madison, Wisconsin Institute for Discovery, 53715, USA; University of Wisconsin - Madison, Wisconsin Institute for Discovery, 53715, USA; University of Wisconsin - Madison, Wisconsin Institute for Discovery, 53715, USA",2017 International Conference on Virtual Rehabilitation (ICVR),14-Aug-17,2017,,,1,9,"Growing evidence indicates that transitioning patients are often unprepared for the self-management role they must assume when they return home. Over the past twenty five years, LiDAR scanning has emerged as a fascinating technology that allows for the rapid acquisition of three dimensional data of real world environments while new virtual reality (VR) technology allows users to experience simulated environments. However, combining these two technologies can be difficult as previous approaches to interactively rendering large point clouds have generally created a trade-off between interactivity and quality. For instance, many techniques used in commercially available software have utilized methods to sub-sample data during interaction, only showing a high-quality render when the viewpoint is kept static. Unfortunately, for displays in which viewpoints are rarely static, such as virtual reality systems, these methods are not useful. This paper presents a novel approach to the problem of quality-interactivity trade-off through a progressive feedback-driven rendering algorithm. This technique uses reprojections of past views to accelerate the reconstruction of the current view and can be used to extend existing point cloud viewing algorithms. The presented method is tested against previous methods, demonstrating marked improvements in both rendering quality and interactivity. This algorithm and rendering application could serve as a tool to enable virtual rehabilitation within 3D models of one's own home from a remote location.",2331-9569,978-1-5090-3053-8,10.1109/ICVR.2017.8007521,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007521,,Rendering (computer graphics);Three-dimensional displays;Laser radar;Graphics processing units;Virtual reality;Hardware;Solid modeling,data acquisition;medical computing;virtual reality,home environments;self-management role;LiDAR scanning;three dimensional data acquisition;virtual reality;high-quality render;progressive feedback-driven rendering algorithm;virtual rehabilitation;3D models;cloud viewing algorithms,,,,34,,14-Aug-17,,,IEEE,IEEE Conferences
NASA Telexploration Project demo,J. Norris; S. Davidoff,NASA Jet Propulsion Laboratory; NASA Jet Propulsion Laboratory,2014 IEEE Virtual Reality (VR),24-Apr-14,2014,,,183,184,"NASA's Telexploration Project seeks to make us better explorers by building immersive environments that feel like we are really there. The Mission Operations Innovation Office and its Operations Laboratory at the NASA Jet Propulsion Laboratory (JPL) founded the Telexploration Project, and is researching how immersive visualization and natural human-robot interaction can enable mission scientists, engineers, and the general public to interact with NASA spacecraft and alien environments in a more effective way. These efforts have been accelerated through partnerships with many different companies, especially in the video game industry. These demos will exhibit some of the progress made at NASA and its commercial partnerships by allowing attendees to experience Mars data acquired from NASA spacecraft in a head mounted display using several rendering and interaction techniques.",2375-5334,978-1-4799-2871-2,10.1109/VR.2014.6802112,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802112,virtual reality;space exploration;robotics,NASA;Mars;Laboratories;Propulsion;Robots;Three-dimensional displays;Space vehicles,astronomy computing;data visualisation;helmet mounted displays;human-robot interaction;Mars;rendering (computer graphics);virtual reality,NASA Telexploration Project demo;immersive environment;Mission Operations Innovation Office;Operations Laboratory;NASA Jet Propulsion Laboratory;NASA JPL;immersive visualization;natural human-robot interaction;mission science;mission engineering;NASA spacecraft;alien environment;Mars data;head mounted display;rendering technique;interaction technique,,3,,,,24-Apr-14,,,IEEE,IEEE Conferences
Decoding Subjective Emotional Arousal during a Naturalistic VR Experience from EEG Using LSTMs,S. M. Hofmann; F. Klotzsche; A. Mariola; V. V. Nikulin; A. Villringer; M. Gaebler,"Amsterdam Brain & Cognition, Univ. of Amsterdam, Amsterdam, Netherlands; Berlin Sch. of Mind & Brain, Humboldt Univ. zu Berlin, Berlin, Germany; Sussex Neurosci., Univ. of Sussex, Brighton, UK; Neurology, MPI Hum. Cog. & Brain Sci., Leipzig, Germany; Neurology, MPI Hum. Cog. & Brain Sci., Leipzig, Germany; Neurology, MPI Hum. Cog. & Brain Sci., Leipzig, Germany",2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),17-Jan-19,2018,,,128,131,"Emotional arousal (EA) denotes a heightened state of activation that has both subjective and physiological aspects. The neurophysiology of subjective EA, among other mind-brain-body phenomena, can best be tested when subjects are stimulated in a natural fashion. Immersive virtual reality (VR) enables naturalistic experimental stimulation and thus promises to increase the ecological validity of research findings i.e., how well they generalize to real-life settings. In this study, 45 participants experienced virtual rollercoaster rides while their brain activity was recorded using electroencephalography (EEG). A Long Short-Term Memory (LSTM) recurrent neural network (RNN) was then trained on the alpha-frequency (8-12 Hz) component of the EEG signal (input) and the retrospectively acquired continuous reports of subjective EA (target). With the LSTM-based model, subjective EA could be predicted significantly above chance level. This demonstrates a novel EEG-based decoding approach for subjective states of experience in naturalistic research designs using VR.",,978-1-5386-9269-1,10.1109/AIVR.2018.00026,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613645,subjective experience;neural decoding;emotional arousal;continuous time series;naturalistic research designs,Brain modeling;Electroencephalography;Feature extraction;Decoding;Biological system modeling;Predictive models;Time series analysis,electroencephalography;medical signal processing;neurophysiology;recurrent neural nets;virtual reality,naturalistic VR experience;subjective aspects;physiological aspects;LSTM;neurophysiology;electroencephalography;alpha-frequency component;EEG signal;EEG-based decoding approach;subjective emotional arousal;naturalistic research designs;Long Short-Term Memory recurrent neural network;brain activity;virtual rollercoaster rides;ecological validity;naturalistic experimental stimulation;immersive virtual reality;natural fashion;mind-brain-body phenomena;subjective EA;frequency 8.0 Hz to 12.0 Hz,,,,28,,17-Jan-19,,,IEEE,IEEE Conferences
Metrics for the Evaluation of Tracking Systems for Virtual Environments,E. Luckett; T. Key; N. Newsome; J. A. Jones,University of Mississippi; Rust College; Clemson University; University of Mississippi,2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,1711,1716,"In this paper, we present three generalizable metrics by which tracking systems for virtual environments can be evaluated. These metrics include positional accuracy, rotational accuracy, and tracking resolution. Additionally, we present methods for acquiring these measurements using components commonly available at hardware and hobby shops. The methods are tested using a consumer-grade virtual reality system but are widely generalizable to most tracking systems, both professional-and consumer-grade.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8798374,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798374,Human-centered computing;Interaction paradigms;Virtual reality,Resists;Position measurement;Measurement by laser beam;Three-dimensional displays;Testing;Surface emitting lasers,virtual reality,consumer-grade virtual reality system;tracking systems;virtual environments;positional accuracy;rotational accuracy;tracking resolution,,2,,11,,15-Aug-19,,,IEEE,IEEE Conferences
Haptic devices synchronization into a software simulator,G. Ion-Eugen; R. Ionut-Cristian; B. N. George,"Department of Computers and Information Technology, University of Craiova, Romania; Department Mechatronics and Robotics, University of Craiova, Romania; Department Mechatronics and Robotics, University of Craiova, Romania",2017 18th International Carpathian Control Conference (ICCC),7-Jul-17,2017,,,440,445,"In this paper is presented the design and developing process of a software simulator that allows both a pre-surgical planning and training future physician about anatomy and liver damage. For this it was made a design three-dimensional (3D) liver and was added properties of soft tissues in order to have a simulator surgery as realistic as to provide a complete answer and complex palpation by devices Geomagic Touch X and Phantom Omni. It highlighted the acute need for such simulator in medicine in general and surgery in particular, and its advantages over traditional methods of learning. Emphasis was placed on the use of virtual reality and haptic feedback to improve the realism of the simulator. The final goal was the synchronization between two or more haptic device using events to acquire more feedback information in the real time. Experiments conducted using different obj flies representing normal liver, hepatic liver, cirrhosis liver and cystic liver demonstrated the reliability and the robustness of the proposed method. The next step will involve the usage of Augmented Reality and Virtual Reality to provide training to physicians and healthcare staff.",,978-1-5090-4862-5,10.1109/CarpathianCC.2017.7970440,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7970440,haptic device;software simulator;force feedback;behavior model;algorithms;haptic rendering;collision detection,,augmented reality;biomedical education;computer based training;digital simulation;force feedback;haptic interfaces;health care;liver;medicine;personnel;realistic images;surgery;synchronisation,haptic device synchronization;software simulator;pre-surgical planning;physician training;anatomy;liver damage;three-dimensional liver design;3D liver design;soft tissues;realistic surgery simulator;complex palpation;Geomagic Touch X;Phantom Omni;medicine;virtual reality;haptic feedback;feedback information;hepatic liver;cirrhosis liver;cystic liver;reliability;augmented reality;healthcare staff,,,,10,,7-Jul-17,,,IEEE,IEEE Conferences
Assessing Knowledge Retention of an Immersive Serious Game vs. a Traditional Education Method in Aviation Safety,L. Chittaro; F. Buttussi,"Department of Mathematics and Computer Science, Human-Computer Interaction Lab, Italy; Department of Mathematics and Computer Science, Human-Computer Interaction Lab, Italy",IEEE Transactions on Visualization and Computer Graphics,23-Mar-15,2015,21,4,529,538,"Thanks to the increasing availability of consumer head-mounted displays, educational applications of immersive VR could now reach to the general public, especially if they include gaming elements (immersive serious games). Safety education of citizens could be a particularly promising domain for immersive serious games, because people tend not to pay attention to and benefit from current safety materials. In this paper, we propose an HMD-based immersive game for educating passengers about aviation safety that allows players to experience a serious aircraft emergency with the goal of surviving it. We compare the proposed approach to a traditional aviation safety education method (the safety card) used by airlines. Unlike most studies of VR for safety knowledge acquisition, we do not focus only on assessing learning immediately after the experience but we extend our attention to knowledge retention over a longer time span. This is a fundamental requirement, because people need to retain safety procedures in order to apply them when faced with danger. A knowledge test administered before, immediately after and one week after the experimental condition showed that the immersive serious game was superior to the safety card. Moreover, subjective as well as physiological measurements employed in the study showed that the immersive serious game was more engaging and fear-arousing than the safety card, a factor that can contribute to explain the obtained superior retention, as we discuss in the paper.",1941-0506,,10.1109/TVCG.2015.2391853,Federal Aviation Administration (FAA); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7014255,Immersive VR;serious games;user evaluation;knowledge retention;physiological measurements;aviation safety;Immersive VR;serious games;user evaluation;knowledge retention;physiological measurements;aviation safety,Games;Safety;Aircraft;Education;Materials;Avatars;Engines,avionics;computer aided instruction;computer games;helmet mounted displays;virtual reality,knowledge retention;consumer head-mounted displays;educational applications;immersive VR;gaming elements;immersive serious games;safety materials;HMD-based immersive game;aircraft emergency;aviation safety education method;airlines;safety knowledge acquisition;safety procedures;knowledge test;safety card;physiological measurements;superior retention,"Accidents, Aviation;Aviation;Computer Graphics;Humans;User-Computer Interface;Video Games",99,,59,,19-Jan-15,,,IEEE,IEEE Journals
Interactive Motion Recovery of Chinese Kung-Fu for Computer Games,H. Yi,"Wuhan Polytech., Wuhan, China",2013 International Conference on Computer Sciences and Applications,19-Jun-14,2013,,,402,405,"As a kind of Chinese culture, Chinese Kung-fu has been very popular in movies and TV programs and attracted the interest of people all over the world. The paper address the problem to recover Chinese Kung-fu from video sequence for further use in computer games. Human motion capture for animation and VR has reached a level of capturing real motion data from people using various visual and non-visual sensors. However, most of the available systems require special devices and environment, or even attach extra things onto an actor. To realize a personal system, this paper developed a general software to acquire arbitrary motion from a video sequence. A general 3D articulate human model with changeable size, color and surface shape is prepared. This model is then driven either automatically or manually to match with the moving body in the consecutive image frames. This matching starts from key frames that contain key poses. A specific orientation interpolation is used to get the motion status in in-between frames and finally a smooth motion is obtained. This approach is suitable for personal use to meet wide needs of human motion acquisition.",,978-0-7695-5125-8,10.1109/CSA.2013.101,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6835628,Video Sequences;Human motion capture;Chinese Kung-fu;Computer Games;Key Frames,Interpolation;Solid modeling;Video sequences;Biological system modeling;Quaternions;Computers;Three-dimensional displays,computer games;image motion analysis;image sequences;solid modelling;video signal processing,interactive motion recovery;Chinese Kung Fu;computer games;Chinese culture;video sequence;human motion capture;animation;VR;virtual reality;visual sensors;nonvisual sensors;general 3D articulate human model;image frames;smooth motion;human motion acquisition,,,,6,,19-Jun-14,,,IEEE,IEEE Conferences
Regional Anaesthesia Simulator and Assistant (RASimAs): Medical Image Processing Supporting Anaesthesiologists in Training and Performance of Local Blocks,T. M. Deserno; J. E. E. De Oliveira; O. Grottke,"Uniklinik, Dept. of Med. Inf., RWTH Aachen, Aachen, Germany; Uniklinik, Dept. of Med. Inf., RWTH Aachen, Aachen, Germany; Uniklinik, Dept. of Anaesthesiology, RWTH Aachen, Aachen, Germany",2015 IEEE 28th International Symposium on Computer-Based Medical Systems,27-Jul-15,2015,,,348,351,"In worldwide health systems, regional anaesthesia (RA) is not applied as frequent as it should be and benefits to patient's cure and cost savings are wasted. The Regional Anaesthesia Simulator and Assistant (RASimAs) project combines image processing, physiological models, and virtual reality to support ultrasound-guided and electrical nerve stimulation-guided RA. The simulator component maps patient-specific data to general models and composes virtual reality environments using a haptic device coupled with the needle. The assistant component provides enhanced feedback mapping online-acquired ultrasound data. Regarding image processing, RASimAs aims at acquiring subject data for model development and composing a library of segmentation and registration algorithms to provide localized, patient-specific, material properties within anatomical context. Subject posing and extrapolation of body regions without patient-specific data are central challenges.",2372-9198,978-1-4673-6775-2,10.1109/CBMS.2015.61,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7167514,regional anaesthesia simulator;regional anaesthesia assistant;anatomical model,Solid modeling;Anesthesia;Data models;Training;Biomedical imaging;Computational modeling;Magnetic resonance imaging,bioelectric phenomena;biomedical ultrasonics;extrapolation;haptic interfaces;image registration;image segmentation;medical image processing;needles;physiological models;surgery;virtual reality,RASimAs;medical image processing;anaesthesiologists;local block training;local block performance;worldwide health systems;patient cure;Regional Anaesthesia Simulator and Assistant project;physiological models;ultrasound-guided RA;electrical nerve stimulation-guided RA;simulator component maps;patient-specific data;general models;virtual reality environments;haptic device;needle;assistant component;enhanced feedback mapping online;ultrasound data;subject data;model development;segmentation algorithms;body regions;extrapolation;anatomical context;material properties;patient-specific properties;localized properties;registration algorithms,,5,,10,,27-Jul-15,,,IEEE,IEEE Conferences
General-purpose telepresence with head-worn optical see-through displays and projector-based lighting,A. Maimone; X. Yang; N. Dierk; A. State; M. Dou; H. Fuchs,University of North Carolina at Chapel Hill; Shanghai Jiao Tong University; University of North Carolina at Chapel Hill; University of North Carolina at Chapel Hill; University of North Carolina at Chapel Hill; University of North Carolina at Chapel Hill,2013 IEEE Virtual Reality (VR),9-Sep-13,2013,,,23,26,In this paper we propose a general-purpose telepresence system design that can be adapted to a wide range of scenarios and present a framework for a proof-of-concept prototype. The prototype system allows users to see remote participants and their surroundings merged into the local environment through the use of an optical see-through head-worn display. Real-time 3D acquisition and head tracking allows the remote imagery to be seen from the correct point of view and with proper occlusion. A projector-based lighting control system permits the remote imagery to appear bright and opaque even in a lit room. Immersion can be adjusted across the VR continuum. Our approach relies only on commodity hardware; we also experiment with wider field of view custom displays.,2375-5334,978-1-4673-4796-9,10.1109/VR.2013.6549352,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549352,teleconferencing;augmented reality;virtual reality,Three-dimensional displays;Optical imaging;Optical sensors;Lighting control;Prototypes;Adaptive optics;Geometry,data acquisition;helmet mounted displays;lighting control;object tracking;optical projectors;virtual reality,head-worn optical see-through displays;projector-based lighting;general-purpose telepresence system design;proof-of-concept prototype;optical see-through head-worn display;real-time 3D acquisition;head tracking;remote imagery;projector-based lighting control system;VR continuum;field-of-view custom displays;commodity hardware,,29,7,11,,9-Sep-13,,,IEEE,IEEE Conferences
"Research on the integration of data warehouse, virtual reality and geographical information system in water resources management",X. Luo; Y. Xu; F. Zhou,"School of Geographic and Oceanographic Sciences, Nanjing University, Nanjing, China; School of Geographic and Oceanographic Sciences, Nanjing University, Nanjing, China; School of Geographic and Oceanographic Sciences, Nanjing University, Nanjing, China",Proceedings 2011 IEEE International Conference on Spatial Data Mining and Geographical Knowledge Services,1-Aug-11,2011,,,497,500,"As the development of geographical information system (GIS), water resources information systems have been applied in water conservancy management increasingly. However, there are still some problems. Along with the improvement of hydrological telemetering systems, more and more data could be acquired. The inconsistencies in data, as well as bulk information processing would intensify the pressure of clients noticeably. Besides, water resources information systems are usually not intuitionistic enough, and it is difficult for users to recognize underlying surface features comprehensively. This paper explored the integration of data warehouse (DW), virtual reality (VR) and GIS in water resources information system to solve the problems mentioned above, while Yinzhou District, located in Ningbo, Eastern China, was selected as the research area to develop the system. Firstly, DW was built in this system to integrate hydrological data from ultra-short wave (USW) telemetering system with those from general packet radio service (GPRS) telemetering system, providing the system with desirable data without massive calculation in clients. Secondly, remote sensing image was utilized as the base map of the system, which was also used for three-dimensional animations generation so that watershed characteristics could be demonstrated more intuitively. Finally, with the help of GIS, water resources information system was developed which could meet diverse practical requirements of water conservancy management.",,978-1-4244-8351-8,10.1109/ICSDM.2011.5969095,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5969095,Water resources information system;data warehouse;virtual reality;geographical information system;integration,Water resources;Geographic Information Systems;Water conservation;Databases;Animation;Data warehouses,computer animation;data warehouses;environmental management;geographic information systems;geophysics computing;hydrology;remote sensing;telemetry;virtual reality;water resources,data warehouse;virtual reality;geographical information system;water resources management;GIS;water resources information system;water conservancy management;hydrological telemetering system;Yinzhou District;hydrological data;ultra-short wave telemetering system;USW telemetering system;general packet radio service;GPRS telemetering system;remote sensing image;three-dimensional animation,,1,,18,,1-Aug-11,,,IEEE,IEEE Conferences
Video game experience and basic robotic skills,A. Tanaka; R. Smith; C. Hughes,"The Nicholson Center, Florida Hospital, Celebration, US; The Nicholson Center, Florida Hospital, Celebration, US; Department of Computer Science, The University of Central Florida, Orlando, US",2016 IEEE International Conference on Serious Games and Applications for Health (SeGAH),10-Oct-16,2016,,,1,6,"Virtual reality simulators have emerged as valuable tools for standardized and objective robotic surgery skill training and assessments. In recent years the idea of using video game technology in surgical education for laparoscopy has also been explored, however few have attempted to make a connection between video game experience and robotic surgical skills. Thus, the current study aims to examine the performance of video gamers in a virtual reality robotic surgery simulator. Furthermore, the video gamers' performance was compared to that of medical students, expert robotic surgeons, and ‚Äúlaypeople.‚Äù The purpose of this study is to demonstrate that video gamers acquire perceptual and psychomotor skills through video game play, similar to those used by robotic surgeons. Subjects completed a demographic questionnaire and performed three computer-based perceptual tests: a Flanker compatibility task, a subsidizing task, and a Multiple Object Tracking test. Participants then performed two warm-up exercises and eight trials of two core exercises on a robotic surgery simulator. After completing all trials, participants completed a post-questionnaire regarding their experience with the system. Expert video gamers (n=40), medical students (n=24), laypeople (n=42) and expert robotic surgeons (n=16) were recruited. Medical students and gamers were significantly faster than experts in the Flanker Task. The experts were significantly slower than the all other groups in the subsidizing task. Experts scored significantly higher, were significantly more efficient, and were significantly faster than laypeople, medical students, and gamers in the first trial of Ring & Rail 1 and Suture Sponge. In trial eight of the simulation exercises, the experts performed significantly better than most groups in all of the metrics. Contrary to prior literature in laparoscopy, this study was unable to validate enhanced abilities of video gamers in a robotic surgery simulator. This study does further demonstrate that the transfer of skills developed through video game play is relevant to the surgical technique. This may be due to the differences of the systems and how the users interact within them. In a society where video games have become an integral past time, it is important to determine the role that video games play in the perceptual and psychomotor development of users. These findings can be generalized to domains outside of medicine that utilize robotic and computer-controlled systems, speaking to the scope of the gamers' abilities and pointing to the capacity within these systems.",,978-1-5090-2210-6,10.1109/SeGAH.2016.7586262,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586262,,Surgery;Robots;Measurement;Games;Training;Rails;Cameras,biomedical education;computer aided instruction;computer games;educational robots;human-robot interaction;medical computing;medical robotics;surgery;virtual reality,video game experience;basic robotic skills;virtual reality robotic surgery simulator;standardized robotic surgery skill training;objective robotic surgery skill training;standardized robotic surgery skill assessment;objective robotic surgery skill assessment;surgical education;laparoscopy;video game technology;perceptual skill acquisition;psychomotor skill acquisition;computer-based perceptual tests;flanker compatibility task;subsidizing task;multiple object tracking test;computer-controlled systems,,1,,17,,10-Oct-16,,,IEEE,IEEE Conferences
An introduction to panospheric imaging,S. L. Bogner,"Defence Res. Establ. Suffield, Medicine Hat, Alta., Canada","1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century",6-Aug-02,1995,4,,3099,3106 vol.4,"A general imaging technology which is able to capture and present substantially spherical fields of view has been developed, and a new discipline known as panospheric imaging (PI) has been recognised. PI is a technology which allows a substantially spherical field-of-view to be captured, digitally processed, and presented to an observer in the form of a fully immersive spherical perspective image, in both still and full motion video formats. This technology greatly simplifies the process of acquiring and presenting panoramic and immersive still images, and offers for the first time a practical technology for true panoramic and panospheric full motion video. PI has become feasible because of a number of separate advances, including the development of appropriate optics, the emergence of a general digital image remapping capability able to correct even severely distorted images, and the availability of wide angle virtual reality (VR) headsets with head orientation sensing, which provide an appropriate device for viewing such images.",,0-7803-2559-1,10.1109/ICSMC.1995.538258,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=538258,,Optical distortion;Optical imaging;Optical sensors;Optical signal processing;Optical devices;Virtual reality;Digital images;Head;Humans;HDTV,image processing;virtual reality,panospheric imaging;fully immersive spherical perspective image;full motion video;optics;digital image remapping capability;wide-angle virtual reality headsets,,8,13,12,,6-Aug-02,,,IEEE,IEEE Conferences
Interactive Web-based animations for teaching and learning,M. Syrjakow; J. Berdux; H. Szczerbicka,"Inst. of Comput. Design & Fault Tolerance, Karlsruhe Univ., Germany; NA; NA",2000 Winter Simulation Conference Proceedings (Cat. No.00CH37165),6-Aug-02,2000,2,,1651,1659 vol.2,"Web based study resources can be viewed as a basic requirement in order to remain a competitive player on a more and more globalised educational market. For that reason, it is getting increasingly important for universities to supplement offered lectures with additional Web based learning material. The authors focus on interactive multimedia elements like computer animations and simulations, which can be used by students for individual experimentation. Such supplementary material represents a motivating but also a very effective chance to deepen and to increase the knowledge acquired in the lecture. The paper gives some general guidelines for building interactive Web based animations. Beyond that, two of our developed animations are presented in detail. The first animation visualizes the search processes of some common direct global and local optimization strategies. In the second animation an artificial ecosystem is simulated, where several autonomous agents have to perform a number of different actions in order to survive. Our animations are realized as Java applets, which have the advantage that they can be executed within Web browsers anywhere in the world at any time and without having to install anything.",,0-7803-6579-8,10.1109/WSC.2000.899152,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=899152,,Animation;Education;Educational institutions;Computational modeling;Computer simulation;Guidelines;Visualization;Ecosystems;Autonomous agents;Java,courseware;teaching;computer animation;multimedia computing;digital simulation;information resources;Java;interactive systems,interactive Web based animations;teaching;learning;Web based study resources;competitive player;globalised educational market;universities;Web based learning material;interactive multimedia elements;computer animations;individual experimentation;supplementary material;search processes;local optimization strategies;artificial ecosystem;autonomous agents;Java applets;Web browsers,,5,,13,,6-Aug-02,,,IEEE,IEEE Conferences
Poster: Say it to see it: A speech based immersive model retrieval system,R. Tredinnick; K. Ponto,"University of Wisconsin - Madison, USA; University of Wisconsin - Madison, USA",2013 IEEE Symposium on 3D User Interfaces (3DUI),5-Sep-13,2013,,,181,182,"Virtual spaces have proven to be a valuable means to visualize and inspect 3D environments. Unfortunately, adding objects to 3D scenes while inside of an immersive environment is often difficult as the means used to acquire models from repositories are built for standard computer interfaces and are generally not available during a users session. We develop a novel interface for the insertion of models into a virtual scene through the use of voice, 3D visuals, and a 3D input device. Our interface seamlessly communicates with external model repositories (Trimble 3D Warehouse) enabling models to be acquired and inserted in the scene during a user's virtual session. We see the benefits of our pipeline and interface in the fields of design, architecture, and simulation.",,978-1-4673-6098-2,10.1109/3DUI.2013.6550238,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6550238,,Solid modeling;Three-dimensional displays;Load modeling;Speech;Pipelines;Graphical user interfaces;Adaptation models,multimedia systems;solid modelling;speech-based user interfaces;virtual reality,speech based immersive model retrieval system;virtual spaces;3D visuals;3D input device;Trimble 3D Warehouse,,,,9,,5-Sep-13,,,IEEE,IEEE Conferences
Real time visualization of 3D variable in time object based on cloud of points data gathered by coloured structure light projection system,P. Garbat; M. Wegiel; M. Kujawinska,"Inst. of Micromechanics & Photonics, Warsaw Univ. of Technol., Poland; Inst. of Micromechanics & Photonics, Warsaw Univ. of Technol., Poland; Inst. of Micromechanics & Photonics, Warsaw Univ. of Technol., Poland","Proceedings. 2nd International Symposium on 3D Data Processing, Visualization and Transmission, 2004. 3DPVT 2004.",20-Sep-04,2004,,,623,630,"The problem of virtual view creation has received increasing attention in recent years. Major current approaches are based on modified stereo vision systems. Recently the structure light measurement system based on digital light projection supported by special data coding and processing allow to rapid 3D shape acquisition. Application of this technology to record 3D data has increased significantly the accuracy of reconstructed shape and simplified data manipulation process. In the paper the general concept of virtual reality system supported by data gathered by means of structure light projection is presented. The methodology of conversion of cloud of measurement points (x,y,z,R,G,B) into virtual reality environment is described. It is supported by implementation of a virtual camera concept, as the mean for interactive object visualization. The methodology of real time 3D object visualization based on its coding by means of specially formed contours and their B-spline approximation is presented. The applicability of the methodology has been shown on numerically generated data which simulate performance of the measurement system. The total processing path was successfully tested.",,0-7695-2223-8,10.1109/TDPVT.2004.1335297,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1335297,,Real time systems;Data visualization;Clouds;Data processing,data visualisation;solid modelling;image colour analysis;virtual reality;stereo image processing;image reconstruction;cameras;edge detection;splines (mathematics);approximation theory,real time visualization;light projection system;stereo vision system;data coding;3D shape acquisition;virtual reality;interactive object visualization;B-spline approximation,,1,,15,,20-Sep-04,,,IEEE,IEEE Conferences
Virtual and remote robotic laboratory: comparative experimental evaluation,C. S. Tzafestas; N. Palaiologou; M. Alifragis,"Sch. of Electr. & Comput. Eng., Athens Univ., Zographou, Greece; NA; NA",IEEE Transactions on Education,7-Aug-06,2006,49,3,360,369,"This paper describes the development and experimental evaluation of an e-laboratory platform in the field of robotics. The system in its current configuration is designed to enable distance training of students in real scenarios of robot manipulator programming. From a technological perspective, the research work presented in this paper is directed towards the adaptation of concepts and techniques developed in the field of telerobotics and virtual reality, and their integration in such e-laboratory settings. This paper focuses particularly on the educational impact of such systems. The goal is to assess the performance of e-laboratory scenarios in terms of the efficacy of training provided to students. The results of a pilot experimental study are presented, providing a comparative evaluation for three training modalities: real, remote, and virtual training on robot manipulator programming. The experiments were conducted according to an evaluation protocol specially designed for the considered target training task, using scoring charts to obtain quantitative performance measures and assess the performance of the student groups participating in the course. Training, as a dynamic process, is approached according to a classical three dimensional model, and performance scores are accordingly assessed in these dimensions (namely: low-level versus mid and high-level skills and understanding). The obtained results reveal certain differences between the three groups, particularly as related to the low-level skill training score, giving some insight about the training `dimensions' that are expected to be mostly affected by the absence of physical (or realistic virtual) presence in a real hands-on experimentation. Statistical analysis indicates, however, that, despite these apparent differences, such e-laboratory modules can be integrated quite effectively in practical scenarios, creating virtual training environments that can provide adequate learning elements, as related particularly to mid and high-level skill acquisition. Further work and large-scale studies are still needed, though, in order to explore the extent to which such a general conclusion is valid in different training settings, and to form the basis of a more theoretical evaluation for a comprehensive understanding of the pedagogical differences between real, virtual, and remote learning/training methodologies and experiences",1557-9638,,10.1109/TE.2006.879255,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1668280,Distance training;evaluation methodology;remote laboratory;telerobotics;virtual robotic laboratory,Manipulators;Telerobotics;Virtual reality;Control engineering education;Statistics;Student experiments,computer based training;control engineering education;distance learning;educational courses;manipulators;statistical analysis;student experiments;telerobotics;virtual reality,virtual robotic laboratory;remote robotic laboratory;e-laboratory;distance training;robot manipulator programming;telerobotics;virtual reality;scoring charts;statistical analysis;virtual training environments;high-level skill acquisition,,103,,24,,7-Aug-06,,,IEEE,IEEE Journals
The signature of drifting sensitivity and centre-of-rotation in SPM analysis of multi-head gammacamera brain SPECT and a method of correction,L. Barnden,"Department of Nuclear Medicine, The Queen Elizabeth Hospital, Adelaide, SA, 5011 Australia",2007 IEEE Nuclear Science Symposium Conference Record,22-Jan-08,2007,6,,4433,4435,"In the course of an SPM brain SPECT analysis, significant differences were detected between 2 groups of normal controls acquired on the same 3-head gamma camera but 3 years apart. A distinctive asymmetry was evident in the distribution of focal differences in the SPM maps. The source of this asymmetry was investigated by simulating calibration errors in the projections from one camera head of 30 scans of a 90 scan normal database, reconstructing them and using SPM to detect differences between the modified 30 and the remaining 60 scans. Two different calibration errors were simulated: either an increase by 10% in count levels to simulate differential sensitivity, or an offset of 1 pixel (3.5 mm) in X or Y to simulate an incorrect centre of rotation (COR). Error simulations were performed for both 3-head and 2-head cameras. The affect of a simulated 10% increase in sensitivity in head 3 of 3 most closely resembled the observed SPM difference image and we concluded that a drift in sensitivity had caused the observed SPM differences. In general, simulated sensitivity changes in one head caused an asymmetry in the SPM map centred on the mid acquisition angle for that head for both 3-head and 2-head systems. The blurring caused by the simulation of a 1 pixel COR error in 1 head did not translate into significant SPM differences between the two populations. Although an asymmetric clinical SPM result may be valid, it should be regarded with suspicion and the beta difference image computed to check whether the asymmetry is aligned with a single camera head. After applying an inverse correction derived from the SPM beta images to the affected normal controls, a repeat SPM analysis showed no significant difference. This method may be suitable for correction and subsequent use of databases from different cameras and institutions.",1082-3654,978-1-4244-0922-8,10.1109/NSSMIC.2007.4437095,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4437095,SPECT;SPM;artifact;sensitivity;center-ofrotation;drift,Scanning probe microscopy;Head;Cameras;Calibration;Gamma ray detection;Gamma ray detectors;Brain modeling;Databases;Image reconstruction;Computational modeling,brain;calibration;error analysis;gamma-ray apparatus;single photon emission computed tomography;statistical analysis,transient drift sensitivity;multihead gamma camera brain SPECT analysis;SPM analysis;calibration errors;error simulations;centre-of-rotation error;inverse correction method;statistical parametric mapping;normal controls,,1,,5,,22-Jan-08,,,IEEE,IEEE Conferences
Resting state functional connectivity and task-related effective connectivity changes after upper extremity rehabilitation: a pilot study,S. Saleh; S. V. Adamovich; E. Tunik,"New Jersey Institute of Technology, Newark, 07102 USA; New Jersey Institute of Technology, Newark, 07102 USA; School of Health Related Professions and the school of Biomedical Sciences at the University of Medicine and Dentistry, Newark, 07107, USA",2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society,10-Nov-12,2012,,,4559,4562,"In this study we investigated the effect of 2 weeks of robot-aided virtual reality therapy for the paretic upper limb in stroke patients on changes in brain activation. Brain activation was acquired during the resting state and during visually-guided hand movement. fMRI analysis focused on characterizing functional connectivity with ipsilesional primary motor cortex (iM1) at rest and during execution of paretic hand movement. Two subjects who sustained a stroke more than 6 months ago participated. Before and after the training period, motor function was evaluated (Wolf Motor Function Test [WMFT], Jebsen Test of Hand Function [JTHF]). After the training period, clinical outcomes (WMFT and JTHF) improved in both subjects. The resting state functional connectivity (rsFC) maps and task-related functional connectivity with iM1 showed different magnitudes of activation, however, the general directionality of the pattern (increases versus decreases) was similar. Specifically, both the rsFC and the task-related functional connectivity between iM1 and contralesional primary motor cortex (cM1) decreased after the therapy for the first subject and increased for the second subject. Our preliminary data suggest that resting state functional connectivity may be a useful measure of brain reorganization, particularly for subjects with limited volitional control of the paretic limb.",1558-4615,978-1-4577-1787-1,10.1109/EMBC.2012.6346981,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6346981,stroke;fMRI connectivity;brain reorganization;hand rehabilitation,Training;Kinematics;Medical treatment;Lesions;Robots;Magnetic resonance imaging;Correlation,biomedical MRI;medical disorders;medical robotics;neurophysiology;patient rehabilitation;virtual reality,resting state functional connectivity;task related effective connectivity change;upper extremity rehabilitation;robot aided virtual reality therapy;paretic upper limb;stroke patients;brain activation;visually guided hand movement;fMRI analysis;ipsilesional primary motor cortex;paretic hand movement;Wolf Motor Function Test;Jebsen Test of Hand Function;task related functional connectivity,Aged;Brain Mapping;Connectome;Humans;Magnetic Resonance Imaging;Male;Middle Aged;Motor Cortex;Movement;Neuronal Plasticity;Paresis;Paresis;Paresis;Pilot Projects;Psychomotor Performance;Recovery of Function;Rest;Treatment Outcome;Upper Extremity,3,,20,,10-Nov-12,,,IEEE,IEEE Conferences
Developing a Semantic-Driven Hybrid Segmentation Method for Point Clouds of 3D Shapes,X. Yang; X. Han; Q. Li; L. He; M. Pang; C. Jia,"School of Data Science and Technology, North University of China, Taiyuan, China; School of Data Science and Technology, North University of China, Taiyuan, China; Department of Computer Science, University of Hull, Hull, U.K.; Department of Computer Science, University of Warwick, Coventry, U.K.; School of Data Science and Technology, North University of China, Taiyuan, China; School of Data Science and Technology, North University of China, Taiyuan, China",IEEE Access,6-Mar-20,2020,8,,40861,40880,"With the rapid development of point cloud processing technologies and the availability of a wide range of 3D capturing devices, a geometric object from the real world can be directly represented digitally as a dense and fine point cloud. Decomposing a 3D shape represented in point cloud into meaningful parts has very important practical implications in the fields of computer graphics, virtual reality and mixed reality. In this paper, a semantic-driven automated hybrid segmentation method is proposed for 3D point cloud shapes. Our method consists of three stages: semantic clustering, variational merging, and region remerging. In the first stage, a new feature of point cloud, called Local Concave-Convex Histogram, is introduced to first extract saddle regions complying with the semantic boundary feature. All other types of regions are then aggregated according to this extracted feature. This stage often leads to multiple over-segmentation convex regions, which are then remerged by a variational method established based on the narrow-band theory. Finally, in order to recombine the regions with the approximate shapes, order relation is introduced to improve the weighting forms in calculating the conventional Shape Diameter Function. We have conducted extensive experiments with the Princeton Dataset. The results show that the proposed algorithm outperforms the state-of-the-art algorithms in this area. We have also applied the proposed algorithm to process the point cloud data acquired directly from the real 3D objects. It achieves excellent results too. These results demonstrate that the method proposed in this paper is effective and universal.",2169-3536,,10.1109/ACCESS.2020.2976847,National Natural Science Foundation of China; Shanxi Provincial Key Research and Development Project; Natural Science Foundation of Shanxi Province; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9016225,Semantic-driven;local concave-convex histogram;variational method;shape diameter function,Three-dimensional displays;Shape;Clustering algorithms;Image segmentation;Feature extraction;Semantics;Surface reconstruction,computer graphics;feature extraction;image segmentation;solid modelling;virtual reality,semantic-driven hybrid segmentation method;3D shapes;3D capturing devices;dense point cloud;fine point cloud;semantic-driven automated hybrid segmentation method;over-segmentation convex regions;point cloud data,,3,,58,CCBY,27-Feb-20,,,IEEE,IEEE Journals
A Fuzzy System Constructed by Rule Generation and Iterative Linear SVR for Antecedent and Consequent Parameter Optimization,C. Juang; C. Hsieh,"Department of Electrical Engineering , National Chung-Hsing University, Taichung, Taiwan; Department of Electrical Engineering , Hsiuping University of Science and Technology, Taichung, Taiwan",IEEE Transactions on Fuzzy Systems,3-Apr-12,2012,20,2,372,384,"This paper proposes a new fuzzy regression model, i.e., the fuzzy system constructed by rule generation and iterative linear support vector regression (FS-RGLSVR) for structural risk minimization. The FS-RGLSVR is composed of Takagi-Sugeno (TS)-type fuzzy if-then rules. These rules are automatically constructed by a self-splitting rule generation algorithm that introduces the self-splitting technique to the k-means clustering algorithm. This new algorithm regards a cluster as a fuzzy rule, where no preassignment of the cluster (rule) number is necessary. The cost function for parameter learning is defined based on structural risk instead of empirical risk minimization in order to achieve generalizability. Tuning all of the free parameters in the FS-RGLSVR using linear support vector regression (SVR) is proposed to minimize the cost function. Each of the consequent and antecedent part parameters is expressed as a linear combination coefficient in a transformed input space so that the linear SVR is applicable. This paper introduces iterative linear SVR to tune antecedent and consequent parameters. This paper demonstrates the capabilities of FS-RGLSVR by two simulated and four practical regression examples. Comparisons with fuzzy systems with different types of learning algorithms verify the performance of the FS-RGLSVR.",1941-0034,,10.1109/TFUZZ.2011.2174997,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6070980,Fuzzy modeling;fuzzy neural networks (FNNs);neural fuzzy systems (NFSs);series prediction;support vector regression (SVR);support vectors (SVs),Cost function;Clustering algorithms;Support vector machines;Fuzzy systems;Training;Artificial neural networks;Input variables,fuzzy set theory;fuzzy systems;iterative methods;knowledge acquisition;learning (artificial intelligence);minimisation;pattern clustering;regression analysis;support vector machines,iterative linear SVR;antecedent parameter optimization;consequent parameter optimization;fuzzy regression model;iterative linear support vector regression;FS-RGLSVR;structural risk minimization;Takagi-Sugeno-type fuzzy if-then rules;TS-type fuzzy if-then rules;self-splitting rule generation algorithm;self-splitting technique;k-means clustering algorithm;fuzzy rule;cost function;parameter learning;empirical risk minimization;generalizability;free parameters;linear combination coefficient;antecedent parameters;consequent parameters;practical regression examples;fuzzy systems;learning algorithms,,38,,40,,7-Nov-11,,,IEEE,IEEE Journals
Residual MLP Network for Mental Fatigue Classification in Mining Workers from Brain Data,A. C. Q. Siravenha; M. N. F. Reis; I. Cordeiro; R. A. Tourinho; B. D. Gomes; S. R. Carvalho,Vale Institute of Technology; Federal University of Para; Vale Institute of Technology; Vale S/A; Federal University of Para; Vale Institute of Technology,2019 8th Brazilian Conference on Intelligent Systems (BRACIS),5-Dec-19,2019,,,407,412,"At the mining industry, human safety and productivity are both desirable in the logistics pipeline. Since the operation of heavy machines requires continued vigilance and mental activity, fatigue caused by long hours of work and constant effort generally occurs in this environment. In general, mental fatigue is related to a loss of efficiency, leading to a decrease in productivity and inducing critical errors, which can provoke equipment breakups or accidents with human victims. At this high cognitive workload environment, there is a need for the development of robust monitoring techniques aiming to predict mental fatigue before workers' movement responses become slower, more variable, and more error-prone. In this work, we introduce a residual multilayer perceptron (MLP) network (ResMLPNet) and assess its performance in the challenging problem of mental fatigue classification from cognitive electrophysiology data, acquired during Virtual Reality (VR) training sessions mimicking a real operation faced by excavator workers at the mining industry. In a three-step training strategy, the ResMLPNet achieved slightly better classification accuracies compared to its plain MLP architecture.",2643-6264,978-1-7281-4253-1,10.1109/BRACIS.2019.00078,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8923986,Residual multilayer perceptron network;Classification;mental fatigue;EEG time series,Fatigue;Electroencephalography;Electrodes;Training;Task analysis;Databases;Benchmark testing,brain;cognition;electroencephalography;ergonomics;fatigue;medical signal processing;mining industry;multilayer perceptrons;neurophysiology;occupational stress;pattern classification;virtual reality,mining workers;brain data;mining industry;human safety;logistics pipeline;mental activity;human victims;residual multilayer perceptron network;mental fatigue classification;cognitive electrophysiology data;residual MLP network,,,,15,,5-Dec-19,,,IEEE,IEEE Conferences
2-D and 3-D Reconstruction Algorithms in the Fourier Domain for Plane-Wave Imaging in Nondestructive Testing,L. Merabet; S. Robert; C. Prada,"Department of Imaging and Simulation for Nondestructive Testing, CEA-LIST, Gif-sur-Yvette, France; Department of Imaging and Simulation for Nondestructive Testing, CEA-LIST, Gif-sur-Yvette, France; Institut Langevin, ESPCI Paris, CNRS, PSL Research University, Paris, France","IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control",28-Mar-19,2019,66,4,772,788,"Time-domain plane-wave imaging (PWI) has recently emerged in medical imaging and is now taking to nondestructive testing (NDT) due to its ability to provide images of good resolution and contrast with only a few steered plane waves. Insonifying a medium with plane waves is a particularly interesting approach in 3-D imaging with matrix arrays because it allows to tremendously reduce the volume of data to be stored and processed as well as the acquisition time. However, even if the data volume is reduced with plane wave emissions, the image reconstruction in the time domain with a delay-and-sum algorithm is not sufficient to achieve low computation times in 3-D due to the number of voxels. Other reconstruction algorithms take place in the wavenumber-frequency (f-k) domain and have been shown to accelerate computation times in seismic imaging and in synthetic aperture radar. In this paper, we start from time-domain PWI in 2-D and compare it to two algorithms in the f-k domain, coming from the Stolt migration in seismic imaging and the Lu theory of limited diffraction beams in medical imaging. We then extend them to immersion testing configurations where a linear array is facing a plane water-steel interface. Finally, the reconstruction algorithms are generalized to 3-D imaging with matrix arrays. A comparison dwelling on image quality and algorithmic complexities is provided, as well as a theoretical analysis of the image amplitudes and the limits of each method. We show that the reconstruction schemes in the f-k domain improve the lateral resolution and offer a theoretical and numerical computation gain of up to 36 in 3-D imaging in a realistic NDT configuration.",1525-8955,,10.1109/TUFFC.2019.2895995,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8629307,2-D and 3-D imaging;nondestructive testing (NDT);transducer arrays;ultrasounds;wavenumber‚Äìfrequency (f-k) migration,Three-dimensional displays;Two dimensional displays;Acoustics;Time-domain analysis;Biomedical imaging;Frequency control,biomedical ultrasonics;image reconstruction;image resolution;medical image processing;radar imaging;synthetic aperture radar;time-domain analysis;ultrasonic imaging,Fourier domain;nondestructive testing;time-domain plane-wave imaging;medical imaging;steered plane waves;matrix arrays;plane wave emissions;image reconstruction;seismic imaging;time-domain PWI;plane water-steel interface;image quality;image amplitudes;3D imaging,"Algorithms;Equipment Design;Fourier Analysis;Imaging, Three-Dimensional;Transducers;Ultrasonography",2,,38,,29-Jan-19,,,IEEE,IEEE Journals
Fast and robust progressive stereo reconstruction by symmetry guided fusion,H. Zhang; S. Negahdaripour,"Dept. of Electr. & Comput. Eng., Miami Univ., Coral Gables, FL, USA; Dept. of Electr. & Comput. Eng., Miami Univ., Coral Gables, FL, USA",Europe Oceans 2005,3-Oct-05,2005,1,,551,556 Vol. 1,"Acquiring photorealistic 3D computer models of objects has been a very active research area with most important applications in Virtual Reality and Multimedia systems. This paper deals with a generalization of dense stereo reconstruction, which forms the basis for incremental fusing of stereo sequences to construct a 3-D model of underwater natural objects. The approach is fast and robust. Initialized with a set of robust feature matches over the left and right images, efficient left-to-right and right-to-left stereo matching are carried out by match propagation [Q. Chen, G. Medioni, 1999]. Symmetry relation between the two stereo matchings is utilized to guide robust fusion. Where a large difference exists between the two dense stereo reconstructions, it is most probable that at least one estimate is erroneous, thus is rejected. Conversely, small differences are expected because of the discrete nature of the disparity values. When fused these two estimates, better results are expected. Experimental results demonstrate the efficacy of the proposed approach.",,0-7803-9103-9,10.1109/OCEANSE.2005.1511774,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1511774,,Robustness;Stereo vision;Stereo image processing;Brightness;Image reconstruction;Application software;Computer vision;Cameras;Motion estimation;Layout,stereo image processing;image reconstruction;virtual reality;multimedia systems;seafloor phenomena;geophysics computing,dense stereo reconstruction;symmetry guided fusion;photorealistic 3D computer models;active research area;Virtual Reality and Multimedia systems;incremental fusing;stereo sequences fusing;underwater natural objects;left-to-right stereo matching;right-to-left stereo matching;match propagation,,5,1,45,,3-Oct-05,,,IEEE,IEEE Conferences
Coordinating attention and cooperation in multi-user virtual reality narratives,C. Brown; G. Bhutra; M. Suhail; Q. Xu; E. D. Ragan,"Texas A&M University, United States of America; Texas A&M University, United States of America; Texas A&M University, United States of America; Texas A&M University, United States of America; Texas A&M University, United States of America",2017 IEEE Virtual Reality (VR),6-Apr-17,2017,,,377,378,"Limited research has been performed attempting to handle multiuser storytelling environments in virtual reality. As such, a number of questions about handling story progression and maintaining user presence in a multi-user virtual environment have yet to be answered. We created a multi-user virtual reality story experience in which we intend to study a set of guided camera techniques and a set of gaze distractor techniques to determine how best to attract disparate users to the same story. Additionally, we describe our preliminary work and plans to study the effectiveness of these techniques, their effect on user presence, and generally how multiple users feel their actions affect the outcome of a story.",2375-5334,978-1-5090-6647-6,10.1109/VR.2017.7892334,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892334,"H.5.1 [Information interfaces and presentation]: Multimedia Information Systems ‚Äî Artificial, augmented, and virtual realities",Virtual environments;Cameras;Collaboration;Multimedia communication;Electronic mail;Face,user interfaces;virtual reality,user attention;user cooperation;multiuser virtual reality narratives;multiuser storytelling environments;story progression;user presence;guided camera techniques;gaze distractor techniques;multiuser virtual reality story experience,,5,,11,,6-Apr-17,,,IEEE,IEEE Conferences
Architecture of Human-controlled Arm Manipulator Operator Training System,M. V. Nosikov,"Miass branch of South Ural State University (National Research University), Miass, Russian Federation",2018 Global Smart Industry Conference (GloSIC),9-Dec-18,2018,,,1,6,"Industrial robots of different kinematic structures and functionality are widely used nowadays in different areas of industry and most of them function autonomously with a pre-programmed set of actions or typical trajectories. Some special purpose mobile and stationary robots are human-controlled and in most cases require qualified operator skills. This article describes general approaches and practical aspects of the operator training and qualification system for arm-based special purpose manipulators. The set of training system functions include: general manipulator control (basic motion) and grasping actions, manipulator operations in restricted working areas, operator actions using virtual reality helms and multi-monitor visualization, etc. The hardware and software architecture of training system should allow for an effective training process and teamwork of trainee and instructor to reach good results. The paper proposes a ROS-based software part of the training system with a description of inter-process communication messages, data formats, integration with a database and the following analysis of trainee action.",,978-1-5386-7386-7,10.1109/GloSIC.2018.8570118,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8570118,trainig system;manipulator;software architecture;database,Manipulators;Training;Control systems;Service robots;Robot sensing systems;Visualization,control engineering computing;industrial manipulators;manipulator kinematics;mobile robots;multi-robot systems;training;user interfaces;virtual reality,industrial robots;functionality;pre-programmed set;stationary robots;operator skills;general approaches;qualification system;arm-based special purpose manipulators;training system functions;general manipulator control;basic motion;grasping actions;manipulator operations;restricted working areas;operator actions;software architecture;effective training process;trainee action;human-controlled arm manipulator operator training system;kinematic structures,,,,24,,9-Dec-18,,,IEEE,IEEE Conferences
xR-EgoPose: Egocentric 3D Human Pose From an HMD Camera,D. Tome; P. Peluse; L. Agapito; H. Badino,UCL; Facebook; University College London; Facebook,2019 IEEE/CVF International Conference on Computer Vision (ICCV),27-Feb-20,2019,,,7727,7737,"We present a new solution to egocentric 3D body pose estimation from monocular images captured from a downward looking fish-eye camera installed on the rim of a head mounted virtual reality device. This unusual viewpoint, just 2 cm away from the user's face, leads to images with unique visual appearance, characterized by severe self-occlusions and strong perspective distortions that result in a drastic difference in resolution between lower and upper body. Our contribution is two-fold. Firstly, we propose a new encoder-decoder architecture with a novel dual branch decoder designed specifically to account for the varying uncertainty in the 2D joint locations. Our quantitative evaluation, both on synthetic and real-world datasets, shows that our strategy leads to substantial improvements in accuracy over state of the art egocentric pose estimation approaches. Our second contribution is a new large-scale photorealistic synthetic dataset - xR-EgoPose - offering 383K frames of high quality renderings ofpeople with a diversity of skin tones, body shapes, clothing, in a variety of backgrounds and lighting conditions, performing a range of actions. Our experiments show that the high variability in our new synthetic training corpus leads to good generalization to real world footage and to state of the art results on real world datasets with ground truth. Moreover, an evaluation on the Human3.6M benchmark shows that the performance of our method is on par with top performing approaches on the more classic problem of 3D human pose from a third person viewpoint.",2380-7504,978-1-7281-4803-8,10.1109/ICCV.2019.00782,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010983,,Three-dimensional displays;Cameras;Pose estimation;Two dimensional displays;Training;Resists;Uncertainty,cameras;helmet mounted displays;image capture;image motion analysis;image sensors;pose estimation;realistic images;rendering (computer graphics);solid modelling;video signal processing;virtual reality,xR-EgoPose;HMD camera;monocular images;fish-eye camera;unique visual appearance;encoder-decoder architecture;2D joint locations;large-scale photorealistic synthetic dataset;high quality renderings;head mounted virtual reality device;dual branch decoder design;egocentric 3D human body pose estimation,,3,,61,,27-Feb-20,,,IEEE,IEEE Conferences
Danger from the Deep: A Gap Affordance Study in Augmented Reality,H. Wu; H. Adams; G. Pointon; J. Stefanucci; S. Creem-Regehr; B. Bodenheimer,"Vanderbilt University, USA; Vanderbilt University, USA; University of Utah, USA; University of Utah, USA; University of Utah, USA; Vanderbilt University, USA",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,1775,1779,"It is an open question as to whether people perceive and act in augmented reality environments in the same way that they do in real environments. The current work investigated participants' judgments of whether or not they could act on an obstacle portrayed with augmented reality. Specifically, we presented gaps of varying widths and depths to participants in augmented reality using the Microsoft HoloLens. We asked users to indicate whether or not they believed that they could step across the virtual gaps given their widths and depths. Averaging across changes in width and depth, users generally underestimated their abilities to cross gaps. However, this underestimation was significantly greater when the gaps were deep. Thus, our findings suggest that users in augmented reality respond with more conservative judgments when presented with risky stimuli-a response that mimics real world behavior. Their altered reactions to deeper gaps may provide early evidence for augmented reality's capacity to evoke a sense of realism or immersion and its use in evaluating perception and action.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8797965,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797965,Augmented reality;Affordances;Perception;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism‚ÄîVirtual Reality;J.4 [Computer Applications]: Social and Behavioral Sciences‚ÄîPsychology,Augmented reality;Visualization;Atmospheric measurements;Particle measurements;Length measurement,augmented reality;interactive devices,gap affordance study;augmented reality environments;virtual gaps;Microsoft HoloLens,,3,,29,,15-Aug-19,,,IEEE,IEEE Conferences
Intuitive control of a multi-robot-system by means of projective virtual reality,E. Freund; J. Rossmann,"Inst. of Robotics Res., Dortmund Univ., Germany; NA",1996 IEEE/SICE/RSJ International Conference on Multisensor Fusion and Integration for Intelligent Systems (Cat. No.96TH8242),6-Aug-02,1996,,,273,280,"Experiences in controlling a multi-robot-system which is capable of performing different experiment handling and service tasks in a space laboratory environment, showed that the realization of a man machine interface based on modern virtual reality (VR) techniques is a promising approach for a new command and supervision interface that is intuitively operable. The general aim of the development described here was to provide the general framework for ""projective virtual reality"" which allows to ""project"" actions that are carried out by users in the virtual world into the real world with the help of robots. This framework is based on a new approach which relies on the ""task deduction"" capabilities of the virtual-reality-system and the task planning component of the multi-robot-control.",,0-7803-3700-X,10.1109/MFI.1996.572188,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=572188,,Virtual reality;Intelligent robots;Orbital robotics;Control systems;User interfaces;Man machine systems;Virtual environment;Data gloves;Intelligent systems;Controllability,telerobotics;virtual reality;man-machine systems;graphical user interfaces,multiple robot system;projective virtual reality;space laboratory;man machine interface;supervision interface;command interface;task planning;robot control;workcell modelling,,2,,10,,6-Aug-02,,,IEEE,IEEE Conferences
How to control a multi-robot system by means of projective virtual reality,E. Freund; J. Rossmann,"Inst. of Robotics Res., Dortmund Univ., Germany; NA",1997 8th International Conference on Advanced Robotics. Proceedings. ICAR'97,6-Aug-02,1997,,,759,764,"Smart man machine interfaces turn out to be a key technology for robot applications in industrial environments as well as in future scenarios for robot applications in space for internal and external servicing. For either field, the use of virtual reality techniques showed a great potential. At the IRF a virtual reality system was developed and implemented during the last two years which allows the intuitive control of a multi-robot system. The general aim of the development was to provide the general framework for projective virtual reality which allows to project actions that are carried out by users in the virtual world into the real world with the help of robots.",,0-7803-4160-0,10.1109/ICAR.1997.620267,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=620267,,Control systems;Multirobot systems;Virtual reality;Space technology;Service robots;Intelligent robots;Orbital robotics;Man machine systems;Aerospace industry;Electrical equipment industry,virtual reality;user interfaces;telerobotics;aerospace control;intelligent control;manipulators;industrial robots;Internet,multi-robot system;projective virtual reality;smart man machine interfaces;industrial environments;space;servicing;intuitive control,,6,,6,,6-Aug-02,,,IEEE,IEEE Conferences
Eye tracking for locomotion prediction in redirected walking,M. Zank; A. Kunz,Innovation Center Virtual Reality - IWF - ETH Zurich; Innovation Center Virtual Reality - IWF - ETH Zurich,2016 IEEE Symposium on 3D User Interfaces (3DUI),28-Apr-16,2016,,,49,58,"Model predictive control was shown to be a powerful tool for Redirected Walking when used to plan and select future redirection techniques. However, to use it effectively, a good prediction of the user's future actions is crucial. Traditionally, this prediction is made based on the user's position or current direction of movement. In the area of cognitive sciences however, it was shown that a person's gaze can also be highly indicative of his intention in both selection and navigation tasks. In this paper, this effect is used the first time to predict a user's locomotion target during goal-directed locomotion in an immersive virtual environment. After discussing the general implications and challenges of using eye tracking for prediction in a locomotion context, we propose a prediction method for a user's intended locomotion target. This approach is then compared with position based approaches in terms of prediction time and accuracy based on data gathered in an experiment. The results show that, in certain situations, eye tracking allows an earlier prediction compared approaches currently used for redirected walking. However, other recently published prediction methods that are based on the user's position perform almost as well as the eye tracking based approaches presented in this paper.",,978-1-5090-0842-1,10.1109/3DUI.2016.7460030,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7460030,Tracking;locomotion;eye tracking;prediction;redirected walking;virtual reality,Legged locomotion;Gaze tracking;Virtual environments;Context;Navigation;Predictive control,ergonomics;virtual reality,eye tracking;locomotion prediction;redirected walking;model predictive control;redirection techniques;user action prediction;cognitive sciences;user intention;user selection task;user navigation task;position based approach,,7,,31,,28-Apr-16,,,IEEE,IEEE Conferences
Towards Immersive Learning in Object-Oriented Paradigm: A Preliminary Study,F. Fernandes; C. Werner,IF Sudeste MG; COPPE/UFRJ,2019 21st Symposium on Virtual and Augmented Reality (SVR),5-Dec-19,2019,,,59,68,"Object-Oriented Paradigm Teaching is mandatory in the curriculum of the courses of the Computing area. Students are taught fundamental concepts about this paradigm, such as class, object, encapsulation, polymorphism, generalization and composition. One of the major challenges of Software Engineering is to teach complex and abstract concepts in a short time, with examples or simple projects done in academic environments. Virtual Reality has demonstrated advantages applied to Education, providing immersive experiences and new ways of visualization and interaction. However, this technology has not been extensively explored in Software Engineering. In this sense, this paper aims to present a disruptive method of teaching and learning support on fundamentals in object orientation paradigm based on Immersive Learning, called OO Game VR. In addition, an initial heuristic evaluation was performed with 6 subjects in order to identify usability problems. Despite problems found related to support learning, navigation and orientation, the natural expression of action and clear entry and exit points, the subjects were able to perform all the tasks, showing indications that the application has the potential to support teaching of OOP teaching through Immersive Learning. In future works, the usability problems will be fixed and specific methods will be applied for measuring influence immersion on learning outcomes.",,978-1-7281-5434-3,10.1109/SVR.2019.00026,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8921030,immersive learning;object-oriented paradigm;software engineering education;virtual reality,Education;Games;Software engineering;Usability;Avatars;Monitoring,computer aided instruction;computer science education;educational courses;human factors;object-oriented methods;object-oriented programming;software engineering;teaching;virtual reality,complex concepts;abstract concepts;immersive experiences;learning support;object orientation paradigm;usability problems;navigation;OOP teaching;influence immersion;learning outcomes;Immersive Learning;Software Engineering;fundamental concepts;Object-Oriented Paradigm Teaching,,,,22,,5-Dec-19,,,IEEE,IEEE Conferences
Mitigating Incorrect Perception of Distance in Virtual Reality through Personalized Rendering Manipulation,A. Peer; K. Ponto,"Virtual Environments, Wisconsin Institute for Discovery, University of Wisconsin-Madison, USA; Virtual Environments, Wisconsin Institute for Discovery, University of Wisconsin-Madison, USA",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,244,250,"Viewers of virtual reality appear to have an incorrect sense of space when performing blind directed-action tasks, such as blind walking or blind throwing. It has been shown that various manipulations can influence this incorrect sense of space, and that the degree of misperception varies by person. It follows that one could measure the degree of misperception an individual experiences and generate some manipulation to correct for it, though it is not clear that correct behavior in a specific blind directed action task leads to correct behavior in all tasks in general. In this work, we evaluate the effectiveness of correcting perceived distance in virtual reality by first measuring individual perceived distance through blind throwing, then manipulating sense of space using a vertex shader to make things appear more or less distant, to a degree personalized to the individual's perceived distance. Two variants of the manipulation are explored. The effects of these personalized manipulations are first evaluated when performing the same blind throwing task used to calibrate the manipulation. Then, in order to observe the effects of the manipulation on dissimilar tasks, participants perform two perceptual matching tasks which allow full visual feedback as objects, or the participants themselves, move through space.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8797911,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797911,I.3.7 [Computing Methodologies]: Graphics Utilities‚ÄîVirtual reality,Task analysis;Virtual environments;Measurement uncertainty;Atmospheric measurements;Particle measurements;Rendering (computer graphics),rendering (computer graphics);virtual reality,performing blind directed-action tasks;specific blind directed action task;perceived distance;virtual reality;personalized manipulations;blind throwing task;dissimilar tasks;perceptual matching tasks;personalized rendering manipulation,,,,19,,15-Aug-19,,,IEEE,IEEE Conferences
VPARK - a Windows NT software platform for a virtual networked amusement park,H. Seo; C. Joslin; U. Berner; N. Magnenat-Thalmann; M. Jovovic; J. Esmerado; D. Thalmann; I. Palmer,"MIRALab., Geneva Univ., Switzerland; NA; NA; NA; NA; NA; NA; NA",Proceedings Computer Graphics International 2000,6-Aug-02,2000,,,309,315,"Presents the VPARK (Virtual Park) system, which includes a networked virtual environment (NVE) system called W-VLNET and an ""attraction building system"" that is able to create and modify the attractions used in the NVE. Both systems have been developed in the Windows NT environment. The paper outlines the techniques for communication, scene management, facial and body animation, and general user interaction modules. The use of VRML97 and MPEG-4 SHNC is overviewed for the purpose of outlining the compatability of the system with other similar virtual reality systems. The software provides realistic virtual actors as well as sets of high-level actions that are applicable to them in real-time. Related issues on obtaining actor models and animating them in real time are presented. The creation process of an attraction incorporates assembling animation units through a timeline. Using this software, the users are able to bring their own scenario-based applications into a shared virtual environment.",,0-7695-0643-7,10.1109/CGI.2000.852347,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=852347,,Virtual environment;Humans;Animation;Computer graphics;Layout;Virtual reality;Real time systems;Windows;MPEG 4 Standard;Assembly,entertainment;virtual reality;computer animation;groupware;graphical user interfaces;network operating systems,VPARK;Virtual Park;Microsoft Windows NT software platform;virtual networked amusement park;networked virtual environment system;W-VLNET;attraction building system;communication techniques;scene management;facial animation;body animation;user interaction modules;VRML97;MPEG-4 SHNC;compatability;virtual reality system;realistic virtual actors;high-level actions;real-time actor model animation;animation unit assembly;timeline;scenario-based applications;shared virtual environment;virtual humans,,3,1,22,,6-Aug-02,,,IEEE,IEEE Conferences
Learning an Action-Conditional Model for Haptic Texture Generation,N. Heravi; W. Yuan; A. M. Okamura; J. Bohg,"Stanford University,Department of Mechanical Engineering; Carnegie Mellon University,Robotics Institute; Stanford University,Department of Mechanical Engineering; Stanford University,Department of Computer Science",2020 IEEE International Conference on Robotics and Automation (ICRA),15-Sep-20,2020,,,11088,11095,"Rich haptic sensory feedback in response to user interactions is desirable for an effective, immersive virtual reality or teleoperation system. However, this feedback depends on material properties and user interactions in a complex, non-linear manner. Therefore, it is challenging to model the mapping from material and user interactions to haptic feedback in a way that generalizes over many variations of the user's input. Current methodologies are typically conditioned on user interactions, but require a separate model for each material. In this paper, we present a learned action-conditional model that uses data from a vision-based tactile sensor (GelSight) and user's action as input. This model predicts an induced acceleration that could be used to provide haptic vibration feedback to a user. We trained our proposed model on a publicly available dataset (Penn Haptic Texture Toolkit) that we augmented with GelSight measurements of the different materials. We show that a unified model over all materials outperforms previous methods and generalizes to new actions and new instances of the material categories in the dataset.",2577-087X,978-1-7281-7395-5,10.1109/ICRA40945.2020.9197447,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197447,,Haptic interfaces;Autoregressive processes;Force;Acceleration;Predictive models;Solid modeling;Discrete Fourier transforms,feedback;haptic interfaces;human-robot interaction;image texture;learning (artificial intelligence);mobile robots;robot vision;tactile sensors;telerobotics;virtual reality,Haptic Texture generation;haptic sensory feedback;user interactions;immersive virtual reality;material properties;haptic vibration feedback;Penn Haptic Texture Toolkit;action-conditional model learning;GelSight measurements;teleoperation system;autonomous robot;GelSight image texture,,,,33,,15-Sep-20,,,IEEE,IEEE Conferences
Locomotive Recalibration and Prism Adaptation of Children and Teens in Immersive Virtual Environments,H. Adams; G. Narasimham; J. Rieser; S. Creem-Regehr; J. Stefanucci; B. Bodenheimer,Dept. of Electrical Engineering and Computer ScienceVanderbilt University; Vanderbilt Institute for Digital Learning; Dept. of Psychology and Human DevelopmentVanderbilt University; Department of PsychologyUniversity of Utah; Department of PsychologyUniversity of Utah; Dept. of Electrical Engineering and Computer ScienceVanderbilt University,IEEE Transactions on Visualization and Computer Graphics,13-Mar-18,2018,24,4,1408,1417,"As virtual reality expands in popularity, an increasingly diverse audience is gaining exposure to immersive virtual environments (IVEs). A significant body of research has demonstrated how perception and action work in such environments, but most of this work has been done studying adults. Less is known about how physical and cognitive development affect perception and action in IVEs, particularly as applied to preteen and teenage children. Accordingly, in the current study we assess how preteens (children aged 8-12 years) and teenagers (children aged 15-18 years) respond to mismatches between their motor behavior and the visual information presented by an IVE. Over two experiments, we evaluate how these individuals recalibrate their actions across functionally distinct systems of movement. The first experiment analyzed forward walking recalibration after exposure to an IVE with either increased or decreased visual flow. Visual flow during normal bipedal locomotion was manipulated to be either twice or half as fast as the physical gait. The second experiment leveraged a prism throwing adaptation paradigm to test the effect of recalibration on throwing movement. In the first experiment, our results show no differences across age groups, although subjects generally experienced a post-exposure effect of shortened distance estimation after experiencing visually faster flow and longer distance estimation after experiencing visually slower flow. In the second experiment, subjects generally showed the typical prism adaptation behavior of a throwing after-effect error. The error lasted longer for preteens than older children. Our results have implications for the design of virtual systems with children as a target audience.",1941-0506,,10.1109/TVCG.2018.2794072,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8267487,Virtual environments;perceptual-motor recalibration;perception;children,Legged locomotion;Visualization;Virtual environments;Biomechanics;Calibration;Electronic mail,gait analysis;virtual reality;visual perception,teenage children;visual information;normal bipedal locomotion;physical gait;adaptation paradigm;throwing movement;post-exposure effect;visually faster flow;visually slower flow;throwing after-effect error;virtual systems;locomotive recalibration;immersive virtual environments;action work;physical development;cognitive development;visual flow;virtual reality;prism adaptation behavior;time 8 year to 12 year;time 15 year to 18 year,"Adaptation, Physiological;Adolescent;Child;Female;Humans;Male;Perception;Psychomotor Performance;User-Computer Interface;Virtual Reality;Walking",,,81,Traditional,23-Jan-18,,,IEEE,IEEE Journals
A taxonomy and comparison of haptic actions for disassembly tasks,A. Bloomfield; Yu Deng; J. Wampler; P. Rondot; D. Harth; M. McManus; N. Badler,"Center for Human Modeling & Simulation, Pennsylvania Univ., PA, USA; Center for Human Modeling & Simulation, Pennsylvania Univ., PA, USA; NA; NA; NA; NA; NA","IEEE Virtual Reality, 2003. Proceedings.",2-Apr-03,2003,,,225,231,"The usefulness of modern day haptics equipment for virtual simulations of actual maintenance actions is examined. In an effort to categorize which areas haptic simulations may be useful, we have developed a taxonomy for haptic actions. This classification has two major dimensions: the general type of action performed and the type of force or torque required. Building upon this taxonomy, we selected three representative tasks from the taxonomy to evaluate in a virtual reality simulation. We conducted a series of human subject experiments to compare user performance and preference on a disassembly task with and without haptic feedback using CyberGlove, Phantom, and SpaceMouse interfaces. Analysis of the simulation runs shows Phantom users learned to accomplish the simulated actions significantly more quickly than did users of the CyberGlove or the SpaceMouse. Moreover, a lack of differences in the post-experiment questionnaire suggests that haptics research should include a measure of actual performance speed or accuracy rather than relying solely on subjective reports of a device's ease of use.",1087-8270,0-7695-1882-6,10.1109/VR.2003.1191143,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1191143,,Taxonomy;Haptic interfaces;Data gloves;Imaging phantoms;Analytical models;Torque;Virtual reality;Humans;Feedback;Velocity measurement,haptic interfaces;virtual reality;digital simulation;assembling,haptic actions;disassembly tasks;haptic simulations;virtual reality simulation;human subject experiments;user performance;disassembly task;haptic feedback;CyberGlove;Phantom;SpaceMouse interfaces;simulation runs;simulated actions;haptics research,,17,,14,,2-Apr-03,,,IEEE,IEEE Conferences
A gesture based interaction technique for a planning tool for construction and design,M. Rauterberg; M. Bichsel; M. Meier; M. Fjeld,"Inst. of Hygiene & Appl. Physiol., Swiss Federal Inst. of Technol., Zurich, Switzerland; NA; NA; NA",Proceedings 6th IEEE International Workshop on Robot and Human Communication. RO-MAN'97 SENDAI,6-Aug-02,1997,,,212,217,"In this article we present a method that goes beyond the established approaches of human-computer interaction. We first bring a serious critique of traditional interface types, showing their major drawbacks and limitations. Promising alternatives are offered by virtual (or immersive) reality (VR) and by augmented reality (AR). The AR design strategy enables humans to behave in a nearly natural way. Natural interaction means human actions in the real world with other humans and/or with real world objects. Guided by the basic constraints of natural interaction, we derive a set of recommendations for the next generation of user interfaces: the natural user interface (NUI). Our approach to NUIs is discussed in the form of a general framework followed by a prototype. The prototype tool builds on video-based interaction and supports construction and plant layout. A first empirical evaluation is briefly presented.",,0-7803-4076-0,10.1109/ROMAN.1997.646984,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=646984,,Virtual reality;Humans;User interfaces;Prototypes;Mice;Computer displays;Command languages;Feedback;Physiology;Design methodology,user interfaces;man-machine systems;virtual reality;interactive systems,gesture based interaction;human-computer interaction;virtual reality;augmented reality;natural user interface;video-based interaction,,10,3,20,,6-Aug-02,,,IEEE,IEEE Conferences
A virtual reality-based multiplayer game using fine-grained localization,T. D. Schepper; B. Braem; S. Latre,"Department of Mathematics and Computer Science, University of Antwerp - iMinds, Belgium; Department of Mathematics and Computer Science, University of Antwerp - iMinds, Belgium; Department of Mathematics and Computer Science, University of Antwerp - iMinds, Belgium",2015 Global Information Infrastructure and Networking Symposium (GIIS),10-Dec-15,2015,,,1,6,"The popularity and availability of Head Mounted Displays (HMDs) has known an increase over the past few years. In general those devices need to be connected to a computer to function properly. Moreover, applications that project images on such an HMD respond typically only to user inputs like mouse and keyboard actions and head movement. In this paper we go a step further by proposing a framework in which the movements of a person are translated into actions in a virtual world. This allows a user to walk around freely while wearing an HMD, increasing the reality of the virtual experience. We will focus in detail on the challenges related to the localization of the user and discuss different options like existing wireless localization technologies, Bluetooth Low Energy (BLE) and an object recognition algorithm. The latter is used in the final solution. Furthermore, we present an experimental and mobile setup to use an HMD in a portable manner. Our solution is demonstrated through a multiplayer game, in which two players compete against each other to capture a flag.",,978-1-4673-7707-2,10.1109/GIIS.2015.7347176,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7347176,Virtual Reality;Multiplayer Game;Oculus Rift;Wireless Localization;Object Tracking,Wireless communication;Cameras;Mobile communication;Histograms;Games;Head;Computers,Bluetooth;computer games;helmet mounted displays;mobile computing;object recognition;portable computers;virtual reality,virtual reality-based multiplayer game;fine-grained localization;head mounted displays;HMD;project images;keyboard actions;mouse actions;head movement;virtual world;virtual experience;wireless localization technologies;Bluetooth Low Energy;BLE;object recognition algorithm;multiplayer game,,3,,23,,10-Dec-15,,,IEEE,IEEE Conferences
Simulation exploration through immersive parallel planes,N. Brunhart-Lupo; B. W. Bush; K. Gruchalla; S. Smith,National Renewable Energy Laboratory; National Renewable Energy Laboratory; National Renewable Energy Laboratory; Los Alamos Visualization Associates,2016 Workshop on Immersive Analytics (IA),25-May-17,2016,,,19,24,"We present a visualization-driven simulation system that tightly couples systems dynamics simulations with an immersive virtual environment to allow analysts to rapidly develop and test hypotheses in a high-dimensional parameter space. To accomplish this, we generalize the two-dimensional parallel-coordinates statistical graphic as an immersive ""parallel-planes"" visualization for multivariate time series emitted by simulations running in parallel with the visualization. In contrast to traditional parallel coordinate's mapping the multivariate dimensions onto coordinate axes represented by a series of parallel lines, we map pairs of the multivariate dimensions onto a series of parallel rectangles. As in the case of parallel coordinates, each individual observation in the dataset is mapped to a polyline whose vertices coincide with its coordinate values. Regions of the rectangles can be ""brushed"" to highlight and select observations of interest: a ""slider"" control allows the user to filter the observations by their time coordinate. In an immersive virtual environment, users interact with the parallel planes using a joystick that can select regions on the planes, manipulate selection, and filter time. The brushing and selection actions are used to both explore existing data as well as to launch additional simulations corresponding to the visually selected portions of the input parameter space. As soon as the new simulations complete, their resulting observations are displayed in the virtual environment. This tight feedback loop between simulation and immersive analytics accelerates users' realization of insights about the simulation and its output.",,978-1-5090-0834-6,10.1109/IMMERSIVE.2016.7932377,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7932377,I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Virtual reality,Computational modeling;Analytical models;Visualization;Data visualization;Virtual environments;Mathematical model,interactive devices;virtual reality,visualization-driven simulation system;tightly-coupled system dynamic simulation;immersive virtual environment;high-dimensional parameter space;two-dimensional parallel-coordinates statistical graphic;immersive parallel-plane visualization;multivariate time series;multivariate dimensions;coordinate axes;parallel rectangles;parallel coordinates;polyline vertices;coordinate values;slider control;joystick;brushing action;selection action;input parameter space;tight feedback loop;immersive analytics,,3,1,25,,25-May-17,,,IEEE,IEEE Conferences
The temporal limits of agency for reaching movements in augmented virtuality,G. Bernal; P. Maes; O. A. Kannape,"MIT Media Lab, Massachusetts Institute of Technology, Cambridge, USA; MIT Media Lab, Massachusetts Institute of Technology, Cambridge, USA; School of Psychology, University of Central Lancashire, Preston, UK","2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",9-Feb-17,2016,,,2896,2899,"The sense of agency (SoA) describes the feeling of being the author and in control of one's movements. It is closely linked to automated aspects of sensorimotor control and understood to depend on one's ability to monitor the details of one's movements. As such SoA has been argued to be a critical component of self-awareness in general and contribute to presence in virtual reality environments in particular. A common approach to investigating SoA is to ask participants to perform goal-directed movements and introducing spatial or temporal visuomotor mismatches in the feedback. Feedback movements are traditionally either switched with someone else's movements using a 2D video-feed or modified by providing abstracted feedback about one's actions on a computer screen. The aim of the current study was to quantify conscious monitoring and the SoA for ecologically valid, three dimensional feedback of the participants' actual limb and movements. This was achieved by displaying an Infra-Red (IR) feed of the participants' upper limbs in an augmented virtuality environment (AVE) using a head-mounted display (HMD). Movements could be fed back in real-time (46ms system delay) or with an experimental delay of up to 570ms. As hypothesized, participant's SoA decreased with increasing temporal visuomotor mismatches (p<;.001), replicating previous findings and extending them to AVEs. In-line with this literature, we report temporal limits of 222¬±60ms (50% psychometric threshold) in N=28 participants. Our results demonstrate the validity of the experimental platform by replicating studies in SoA both qualitatively and quantitatively. We discuss our findings in relation to the use of virtual and mixed reality in research and implications for neurorehabilitation therapies.",,978-1-5090-1897-0,10.1109/SMC.2016.7844679,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7844679,augmented virtuality;sense of agency;presence;sensory integration;movement feedback;motion capture,Delays;Visualization;Feeds;Real-time systems;Training;Conferences;Cybernetics,augmented reality;helmet mounted displays;human computer interaction,temporal agency limits;SoA;sense of agency;infrared feed;IR feed;augmented virtuality environment;head-mounted display;temporal visuomotor mismatches;mixed reality;HMD;AVE,,1,,19,,9-Feb-17,,,IEEE,IEEE Conferences
Natural Interaction to Support Teaching Activities in Health,D. Dos Santos Ferreira; L. S. Machado,"Lab. de Tecnol. para o Ensino Virtual e Estatistica (LabTEVE), Univ. Fed. da Paraiba (UFPB), Jo√£o Pessoa, Brazil; Lab. de Tecnol. para o Ensino Virtual e Estatistica (LabTEVE), Univ. Fed. da Paraiba (UFPB), Jo√£o Pessoa, Brazil",2014 XVI Symposium on Virtual and Augmented Reality,2-Oct-14,2014,,,254,257,"In the field of human-computer interaction, Natural Interaction methods has been gaining importance because they provide communication between user and machine through an easy and intuitive way, by interpreting the natural actions of persons. In the development of Virtual Reality systems for health, there is a need to produce forms of interaction that are similar to the commonly performed by people in daily activities. Because of its intuitive features, the Natural Interaction can perform an important role in this scenario. It is important to emphasize that some natural behaviors can be of cultural origin, creating the need to identify the specific features target audience in interaction with applications that provide natural interfaces. The general goal of paper is to discuss a set of techniques for Natural Interaction by gestures for use in tracking systems by optical devices to support professors in health teaching activities.",,978-1-4799-4261-9,10.1109/SVR.2014.18,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913100,Natural Interaction;Virtual Reality;Optical Tracking;Health Education,Three-dimensional displays;Mice;Education;Visualization;Augmented reality;Cultural differences,biomedical education;computer aided instruction;health care;human computer interaction;medical computing;teaching;virtual reality,human-computer interaction;natural interaction methods;virtual reality systems;daily activities;natural interfaces;tracking systems;optical devices;health teaching activities,,,,8,,2-Oct-14,,,IEEE,IEEE Conferences
Batmen Forever: Unified Virtual Hand Metaphor for Consumer VR Setups,A. Montes Rodrigues; M. Nagamura; L. G. Freire da Costa; M. K. Zuffo,Interdisciplinary Center in Interactive Technologies - Polytechnic School - University of S√£o Paulo; Interdisciplinary Center in Interactive Technologies - Polytechnic School - University of S√£o Paulo; Interdisciplinary Center in Interactive Technologies - Polytechnic School - University of S√£o Paulo; Interdisciplinary Center in Interactive Technologies - Polytechnic School - University of S√£o Paulo,2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),30-Aug-18,2018,,,854,855,"In this work, we present a hand-based natural interaction that allows performing fundamental actions such as moving or controlling objects and climbing ladders. The setup was restricted to available consumer VR technology, aiming to advance towards a practical unified framework for 3D interaction. The strategy was syncing the closest natural movement allowed by the device with primary task actions, either directly or indirectly, creating hypernatural UIs. The prototype allowed successful completion of the three challenges proposed by the 2018 3DUI Contest, as validated by a preliminary user study with participants from the target audience and also from the general public.",,978-1-5386-3365-6,10.1109/VR.2018.8446277,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446277,I.3.6 [Computer Graphics]: Methodology and Techniques - Interaction Techniques,Three-dimensional displays;User interfaces;Conferences;Virtual reality;Industrial engineering,human computer interaction;user interfaces;virtual reality,unified virtual hand metaphor;consumer VR setups;hand-based natural interaction;primary task actions;hypernatural UIs;ladder climbing;consumer VR technology,,1,,4,,30-Aug-18,,,IEEE,IEEE Conferences
Virtual physics for virtual reality,P. Willis,"Dept. of Comput. Sci., Bath Univ., UK","Proceedings Theory and Practice of Computer Graphics, 2004.",19-Jul-04,2004,,,42,49,"We consider the problem of giving virtual reality objects physical behaviour. We wish to do this in a way, which allows users to construct new objects from simpler ones and have the correct composite behaviour emerge. Our approach uses a graph structure to model, dynamically, the way one object can influence another. It uses a lightweight message system to cause actions between objects. It has routines to encode each kind of general physical behaviour. Any given object can have multiple independent behaviours and these behaviours can be extended to give a richer range of outcomes. These outcomes arise from the creative use to which the objects are put by the user, rather than from predetermined actions built-in when the VE was designed. In addition, we replace hierarchical geometry modelling with a much flatter structure. We explain the approach, describe the implementation, suggest enhancements and offer a range of tests, which demonstrate the concepts in action",,0-7695-2137-1,10.1109/TPCG.2004.1314451,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1314451,,Physics;Virtual reality;Computer science;Message systems;Geometry;Solid modeling;Testing;Mechanical factors;Application software;Software systems,mechanics;solid modelling;virtual reality,virtual physics;virtual reality;object construction;graph structure;lightweight message system;solid modelling,,2,,7,,19-Jul-04,,,IEEE,IEEE Conferences
SceneCam: Improving Multi-camera Remote Collaboration using Augmented Reality,T. A. Rasmussen; W. Huang,"Aarhus University, Denmark; University of Technology Sydney",2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),9-Jan-20,2019,,,28,33,"Systems for remote collaboration on physical tasks generally use AR/VR technologies to create a shared visual space for collaborators to perform tasks together. The shared space often comes from a single camera view. Prior research has not reported on the benefits of using multiple cameras for remote collaboration. On the contrary, there seems to be some usability issues, which must be addressed, when designing remote collaboration systems that use multiple cameras to capture different areas and perspectives of a task space. To be usable, a multi-camera remote collaboration system must indicate to the local user which camera the remote user is looking at and vice versa, the system must make it fast and easy for the remote user to obtain the right camera view for a given collaborative task. We present SceneCam, an AR prototype with which we explore different techniques for improving the usability of multi-camera remote collaboration by making camera selection easier and faster. Specifically, SceneCam implements two camera selection techniques. The first technique nudges the remote user to manually select an optimal camera view of the local user's actions. The second technique automatically selects an optimal camera view of the local user and shows it to the remote user. Additionally, SceneCam implements two focus-in-context views (exocentric and egocentric views) that provide the remote user with a spatial overview of the local user's whereabouts in relation to the multiple task space areas and direct visual access to the camera views of said areas. Camera selection techniques (manual point-and-click, nudging, automatic), and focus-in-context views (no focus-in-context view, exocentric, egocentric) make up the two dimensions in a design space for multi-camera remote collaboration. We describe how SceneCam spans this design space. Lastly, as part of future work we discuss some hypotheses regarding the effects of the proposed camera selection techniques, focus-in-context views and combinations hereof on the usability of multi-camera remote collaboration.",,978-1-7281-4765-9,10.1109/ISMAR-Adjunct.2019.00023,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951899,Remote collaboration;Augmented Reality;Multiple cameras;Usability,Cameras;Task analysis;Collaboration;Two dimensional displays;Visualization;Usability;Three-dimensional displays,augmented reality;cameras;data visualisation;groupware,SceneCam;single camera view;multiple cameras;multicamera remote collaboration system;camera selection techniques;optimal camera view;focus-in-context view;multiple task space areas;multicamera remote collaboration;augmented reality;AR/VR technologies;exocentric view;egocentric view,,,,16,,9-Jan-20,,,IEEE,IEEE Conferences
A hybrid fuzzy logic/constraint satisfaction problem approach to automatic decision making in simulation game models,S. Braathen; O. J. Sendstad,"Norwegian Defence Res. Establ., Kjeller, Norway; Norwegian Defence Res. Establ., Kjeller, Norway","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",19-Jul-04,2004,34,4,1786,1797,"Possible techniques for representing automatic decision-making behavior approximating human experts in complex simulation model experiments are of interest. Here, fuzzy logic (FL) and constraint satisfaction problem (CSP) methods are applied in a hybrid design of automatic decision making in simulation game models. The decision processes of a military headquarters are used as a model for the FL/CSP decision agents choice of variables and rulebases. The hybrid decision agent design is applied in two different types of simulation games to test the general applicability of the design. The first application is a two-sided zero-sum sequential resource allocation game with imperfect information interpreted as an air campaign game. The second example is a network flow stochastic board game designed to capture important aspects of land manoeuvre operations. The proposed design is shown to perform well also in this complex game with a very large (billionsize) action set. Training of the automatic FL/CSP decision agents against selected performance measures is also shown and results are presented together with directions for future research.",1941-0492,,10.1109/TSMCB.2004.828591,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1315761,,Fuzzy logic;Decision making;Game theory;Uncertainty;Humans;Testing;Stochastic processes;Resource management;Machine learning;Character generation,game theory;military computing;decision making;fuzzy logic;constraint theory;learning (artificial intelligence);knowledge based systems;digital simulation,automatic decision-making;hybrid fuzzy logic;hybrid constraint satisfaction problem;simulation game model;decision agent;sequential resource allocation game;air campaign game;network flow stochastic board game;machine learning,"Algorithms;Artificial Intelligence;Computer Simulation;Decision Support Techniques;Fuzzy Logic;Game Theory;Numerical Analysis, Computer-Assisted",10,,24,,19-Jul-04,,,IEEE,IEEE Journals
Computer-enhanced route and survey spatial knowledge assessment in clinical neuropsychology,F. Morganti; A. Gaggioli; L. Strambi; M. L. Rusconi; G. Riva,"Appl. Technol. for Neuro-Psychol. Lab, Ist. Auxologico Italiano, Milan; Appl. Technol. for Neuro-Psychol. Lab, Ist. Auxologico Italiano, Milan; Appl. Technol. for Neuro-Psychol. Lab, Ist. Auxologico Italiano, Milan; NA; NA",2006 International Workshop on Virtual Rehabilitation,9-Oct-06,2006,,,110,115,"In the field of clinical neuropsychology, topographical disorientation represents one of the main consequences of brain injury. Different methodological approaches and different tools have been used in the assessment of brain-injured patient's navigational abilities. These procedures include auto-evaluation questionnaires, evaluation of general cognitive level, mental rotation tasks or specifically suited visual-spatial tasks. All these methodologies have shown a moderate correlation between the results of these kinds of evaluation and the navigational ability impairment observed in everyday contexts. Meanwhile, the evaluation of patient's spatial orientation out of laboratory setting appears to be an unprofitable opportunity for clinicians. Thus the problem in designing an effective assessment tool is still open. A promising approach could be to integrate classical evaluation tools with computer-based interactive ones, such as virtual reality. According to this framework, we propose a combination of classical and virtual reality-based assessment, in which perceptive, memory and attentional functions (that combined each other are considered the hub for spatial orientation ability) will be evaluated with standardized neuropsychological tests and a more situated computer-based tools will allow the assessment of spatial orientation during the interaction with complex environments. Strictly linked with ""paper and pencil"" spatial disorientation neuropsychological evaluation, we propose two 3D virtual reality tools based on Wisc-R Maze subtest and road map test, customized to match interactive evaluation requirements. The first will provide the possibility to evaluate human ability of finding the best route to achieve a target goal while immersed in an empty environment. The second can be used to evaluate the ability in creating relationships between various points of the environment and in inferring, through the reasoning process, high-level spatial organization knowledge. By providing the possibility to track user's spatial behaviours, a virtual reality-based evaluation allows an effective and objective record of all the experimental variables. It also avoids the intervention of the experimenter, which may interfere with the actions of the agent-explorer. The main hypothesis of our research is that the integration of virtual reality-based tools with traditional evaluation methods will improve the evaluation of topographical disorientation in brain-injured patients",2331-9569,1-4244-0280-8,10.1109/IWVR.2006.1707537,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1707537,,Humans;Virtual reality;Navigation;Brain injuries;Dementia;Lesions;Laboratories;Space exploration;Vehicles;Patient monitoring,brain;medical diagnostic computing;navigation;patient diagnosis;psychology;virtual reality,computer-enhanced route knowledge assessment;spatial knowledge assessment;clinical neuropsychology;topographical disorientation;brain injury;patient navigational abilities;cognitive level evaluation;mental rotation;visual-spatial tasks;navigational ability impairment;spatial orientation;3D virtual reality tools;Wisc-R Maze subtest;road map test;interactive evaluation;spatial behaviour,,1,,40,,9-Oct-06,,,IEEE,IEEE Conferences
Feature Extraction of Human Motion Video Based on Virtual Reality Technology,M. Zhou,"School of Philosophy, Heilongjiang University, Harbin, China",IEEE Access,2-Sep-20,2020,8,,155563,155575,"In virtual reality scenes, the premise of moving target recognition in video is accurate target segmentation and extraction of target low-level features. In order to distinguish moving targets, it is not enough to use the underlying features. Further extraction of structural features that reflect the target structure can improve the recognition and tracking of moving targets. In order to ensure the stability of the feature areas extracted from the three-channel most stable extremum region, this article proposes an improved algorithm of the three-channel most stable extremum region to improve the three-channel most stable extremum region. The algorithm can adaptively select the filters of each channel to filter the feature regions extracted from the three most stable extreme value regions. An action cycle is generally 30~50 frames, so it is faster and more advantageous to directly use the first 50 frames of video for processing. In this article, two feature representation methods of variance gait energy graph algorithm and image splitting algorithm are proposed. The variance energy graph algorithm significantly improves the recognition rate; image splitting enhances the robustness of behavior classification. This article proposes a feature representation algorithm of ‚Äúdistance from contour line to center line‚Äù to improve the recognition rate. By analyzing the feature extraction methods of principal component analysis, Fisher linear discriminant analysis and maximum divergence difference discriminant analysis, the main component discriminant analysis of row maximum divergence discriminant column and the two-dimensional two-dimensional maximum divergence discriminant analysis of row and column are proposed. This further enhances the ability to classify behaviors.",2169-3536,,10.1109/ACCESS.2020.3019233,Project of Inner Mongolia University for Nationalities: The Experimental Research on the Introduction of Healthy Physical Fitness Into Calisthenics Teaching; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9177108,Human motion video;feature extraction;improved three-channel most stable extreme value area;virtual reality,Feature extraction;Virtual reality;Face recognition;Face;Trajectory;Target tracking;Filtering algorithms,feature extraction;graph theory;image classification;image representation;image segmentation;principal component analysis;virtual reality,variance energy graph algorithm;image splitting algorithm;variance gait energy graph algorithm;stable extreme value regions;feature regions;stable extremum region;feature areas;target tracking;target structure;structural features;underlying features;moving targets;target low-level features;accurate target segmentation;target recognition;virtual reality scenes;virtual reality technology;human motion video;feature extraction methods;feature representation algorithm;recognition rate,,,,32,CCBY,25-Aug-20,,,IEEE,IEEE Journals
EEG-based Control of a 3D Game Using 14-channel Emotiv Epoc+,T. N. Malete; K. Moruti; T. S. Thapelo; R. S. Jamisola,"Botswana International University of Science and Technology,Simulation, Machine Learning, Robotics and Technopreneurship Laboratory (SMaRT Lab) Department of Mechanical, Energy and Industrial Engineering,Palapye,Botswana; Botswana International University of Science and Technology,Simulation, Machine Learning, Robotics and Technopreneurship Laboratory (SMaRT Lab) Department of Mechanical, Energy and Industrial Engineering,Palapye,Botswana; Botswana International University of Science and Technology,Simulation, Machine Learning, Robotics and Technopreneurship Laboratory (SMaRT Lab) Department of Mechanical, Energy and Industrial Engineering,Palapye,Botswana; Botswana International University of Science and Technology,Simulation, Machine Learning, Robotics and Technopreneurship Laboratory (SMaRT Lab) Department of Mechanical, Energy and Industrial Engineering,Palapye,Botswana","2019 IEEE International Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM)",19-May-20,2019,,,463,468,"This work focuses on the use of brain signals to interpret the neurophysiological signals as a direct communication pathway to an external device. The main objective is to build a simple development platform based on a commercially available 14-channel electroencephalography (EEG)-based brain-computer interface (BCI) to control a 3D game. The proposed method consists on harvesting, recording and processing of EEG data from an Emotiv Epoc+ headset. Support vector machine (SVM), linear neural network (NN) and decision trees (DT) are used to build machine learning models and are compared based on statistical measures. The models are trained on two control states: forward and backward, in order to control the character in the game. In the first stage of modeling, each user is built using its own unique model based on the data gathered during user training. Then a more general model is developed to allow plug and play interactions with many users, without the need for retraining. The proposed classifiers are able to sufficiently model brain control for a single user with acceptable errors for the motor action training dataset, but fail to generalize to datasets with multiple users. Feature extraction improves learning of the models like neural network, but decreases the number of learning samples which calls for more datasets to generalize results for multiple users. The 3D game used for control is built on Unity 5 game engine. The traditional navigation controls in the game are mapped to the machine learning model predictions, while the internal Gyroscope is used for panning and rotation.",2326-8239,978-1-7281-3458-1,10.1109/CIS-RAM47153.2019.9095807,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9095807,Electroencephalography;brain-computer interface;support vector machine;linear neural network;decision trees,Games;Electroencephalography;Three-dimensional displays;Brain modeling;Feature extraction;Machine learning;Headphones,brain-computer interfaces;electroencephalography;feature extraction;medical signal processing;neural nets;neurophysiology;signal classification;support vector machines,14-channel electroencephalography-based brain-computer interface;Emotiv Epoc+ headset;decision trees;machine learning models;brain control;motor action training dataset;linear neural network;Unity 5 game engine;machine learning model predictions;brain signals;neurophysiological signals;direct communication pathway;14-channel Emotiv Epoc+;SVM;support vector machine;3D game;feature extraction,,,,22,,19-May-20,,,IEEE,IEEE Conferences
Effects of Image Size and Structural Complexity on Time and Precision of Hand Movements in Head Mounted Virtual Reality,A. U. Batmaz; M. de Mathelin; B. Dresp-Langley,"University of Strasbourg CNRS, ICube Laboratory, UMR 7357 Strasbourg, France; University of Strasbourg CNRS, ICube Laboratory, UMR 7357 Strasbourg, France; University of Strasbourg CNRS, ICube Laboratory, UMR 7357 Strasbourg, France",2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),30-Aug-18,2018,,,167,174,"The effective design of virtual reality (VR) simulators requires a deeper understanding of VR mediated human actions such as hand movements, with specifically tailored experiments testing how different design parameters affect performance. The present experiment investigates the time and precision of hand (index finger) movements under varying conditions of structural complexity and image size in VR without tactile feed-back from object to hand/finger. 18 right-handed subjects followed a complex and a simple physiological structure of small, medium and large size in VR, with the index finger of one of their two hands, from right to left, and from left to right. The results show that subjects performed best with small-size-simple structures and large-size-complex structures in VR. Movement execution was generally faster and more precise on simple structures. Performance was less precise when the dominant hand was used to follow the complex structures and small object size in VR. It is concluded that both size and structural complexity critically influence task execution in VR when no tactile feed-back from object to finger is generated. Individual learning curves should be monitored from the beginning of the training as suggested by the individual speed-precision analyses.",,978-1-5386-3365-6,10.1109/VR.2018.8446217,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446217,Computing methodologies-Computer Graphics-Graphic systems and interfaces-Virtual reality;Human-centered computing-Human computer interaction (HCI)-Interaction paradigms-Virtual reality;Human-centered computing-Human computer interaction (HCI)-Interaction devices;Human-centered computing-Interaction design;Software and its engineering-Software organization and properties-Virtual worlds software-Virtual worlds training simulations,Indexes;Complexity theory;Three-dimensional displays;Head;Software;Image color analysis;Virtual reality,biomechanics;feedback;helmet mounted displays;image processing;physiological models;virtual reality,structural complexity;image size;hand movements;virtual reality simulators;VR mediated human actions;index finger;tactile feedback;physiological structure;complex structures;speed-precision analyses;head mounted virtual reality;learning curves,,2,,41,,30-Aug-18,,,IEEE,IEEE Conferences
Virtual Eye: A sensor based mobile viewer to aid collaborative decision making in virtual environments,W. Ranaweera; R. Wickramarachchi; S. Jabbar; M. Weerasinghe; N. Gunathilake; C. Keppitiyagama; D. Sandaruwan; P. Samarasinghe,"School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka",International Conference on Advances in ICT for Emerging Regions (ICTer2012),31-Jan-13,2012,,,56,61,"Current virtual simulation techniques often include multi-user interactivity in virtual environments that can be controlled in real time. Such simulation techniques are mostly employed in virtual military training sessions and in real time gaming experiences, where users have to make more strategic decisions by analyzing the information they receive, in response to the actions of the other users in the same virtual environment. Generally, in the real world, collaborative decision making takes place when a team of people work together to control the behaviour of a single object which cannot be handled alone by an individual. A ship with its crew can be held as an example. When applying this scenario into virtually simulated environments, multiple users have to involve in representing a single object in the virtual world. These users need to obtain sufficient information about the activities in the environment that will contribute to the collaborative decision making process. Out of many sources, visual information is the most reliable source the users tend to depend on. The use of traditional static displays to obtain visual information limits the capability of providing a rich set of information about the 3D environment. Head Mounted Displays address these limitations while introducing several new problems. On the otherhand, our work is focused on exploring how smart devices can be employed by a collaboratively working team of users to obtain visual information to the level beyond which a static display provides, thus aiding the process of decision making. To serve the above purpose, we propose a solution, ‚ÄúVirtual Eye‚Äù, which uses a smart mobile device with the ability to view the visual output of the virtual world and the ability to control that view according to user's orientation changes and movements with the use of its inbuilt sensors.",,978-1-4673-5530-8,10.1109/ICTer.2012.6422831,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6422831,Virtual reality;collaborative decision making;mobile;sensors;streaming,Educational institutions;Mobile communication;Visualization;Servers;Communication channels;Optical reflection;Optical sensors,computer games;decision making;digital simulation;mobile computing;sensors;virtual reality,virtual eye;sensor based mobile viewer;aid collaborative decision making;virtual environments;virtual simulation techniques;multiuser interactivity;virtual military training sessions;virtual world;collaborative decision making process;visual information;head mounted displays;static display,,1,,13,,31-Jan-13,,,IEEE,IEEE Conferences
Interconection of virtual environments with mechatronic systems,L. -C. Bazavan; H. Roibu; F. Besnea Petcu; S. Irinel Cismaru; B. N. George,"University of Craiova,Faculty of Control, Computers and Electronics,Mechatronics and Robotics Department,Craiova,Romania; University of Craiova,Faculty of Control, Computers and Electronics,Mechatronics and Robotics Department,Craiova,Romania; University of Craiova,Faculty of Control, Computers and Electronics,Mechatronics and Robotics Department,Craiova,Romania; University of Craiova,Faculty of Control, Computers and Electronics,Mechatronics and Robotics Department,Craiova,Romania; University of Craiova,Faculty of Control, Computers and Electronics,Mechatronics and Robotics Department,Craiova,Romania","2020 24th International Conference on System Theory, Control and Computing (ICSTCC)",23-Nov-20,2020,,,654,659,"The development of both hardware and software technology in recent years has led to the creation of complex virtual environments and boosted the desire of both users and developers to make them as immersive as possible. To achieve this immersion, virtual reality applications must interact with physical systems, that generally consist of command and control electronics, actuators and a sensory system. This paper presents a series of experiments performed by the authors in order to determine three major steps in the process of interaction between hardware systems and software emulating virtual environments: transpose the events from Unity virtual environment into signals necessary to control a physical system, transmission of the signals generated by the sensory system and, interpretation and conversion of those signals into events for the virtual reality application. Because interconnection involves both receiving and transmitting signals, the authors propose a two-way control interface implemented on different development boards. At the same time, the experiments aimed to observe the response of the physical systems and to determine an algorithm for correlating the action of the physical system, with a proportionality factor of one to one, related to the events that occurred in the virtual reality.",2372-1618,978-1-7281-9809-5,10.1109/ICSTCC50638.2020.9259668,European Social Fund; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9259668,Virtual environment;Unity;Control;Communication,Hardware;Games;Virtual environments;Software;Microcontrollers;Three-dimensional displays;Mechatronics,control engineering computing;mechatronics;signal processing;user interfaces;virtual reality,complex virtual environments;virtual reality application;command and control electronics;sensory system;hardware systems;Unity virtual environment;mechatronic systems;actuators;physical system control;signal transmission;two-way control interface,,,,9,,23-Nov-20,,,IEEE,IEEE Conferences
Energy-based hybrid excitation control for synchronous generators,W. Qiao; Q. Hui,"Department of Electrical Engineering, University of Nebraska-Lincoln, 68588-511 USA; Department of Mechanical Engineering, Texas Tech University, Lubbock, 79409-1021, USA",IEEE PES General Meeting,30-Sep-10,2010,,,1,6,"This paper presents an energy-based hybrid control, which replaces the traditional automatic voltage regulator (AVR) for excitation control of a synchronous generator connected to an infinite power system. The proposed controller is based on energy representation of the power system by using a port-controlled Hamiltonian form. The controller uses a hierarchical hybrid architecture characterized by continuous-time dynamics at the lower level of the hierarchy and logical decision-making units at the higher level of the hierarchy. The lower-level units, i.e., the subcontrollers, are each designed for a power system operating mode and directly interact with the power system to be controlled; while the higher-level decision-making units perform logical checks that identify system mode of operation and activates the corresponding lower-level unit; the activated lower-level unit then executes continuous control actions for the power system. Consequently, the controller can adapt to different power system operating modes. Simulation studies are carried out to show the effectiveness of the proposed controller for excitation control of the synchronous generator.",1944-9925,978-1-4244-6551-4,10.1109/PES.2010.5589516,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5589516,Energy-based hybrid control;excitation control;port-controlled Hamiltonian form;synchronous generator,Power system dynamics;Synchronous generators;Power system stability;Hybrid power systems;Transient analysis,decision making;machine control;power system control;synchronous generators;voltage regulators,energy-based hybrid excitation control;automatic voltage regulator;synchronous generator;energy representation;port controlled Hamiltonian form;hierarchical hybrid architecture;continuous time dynamics;logical decision making;power system operating mode;higher level decision making units;continuous control actions;power system control,,,,35,,30-Sep-10,,,IEEE,IEEE Conferences
Intelligent Objects to Facilitate Human Participation in Virtual Institutions,I. Rodriguez; A. Puig; M. Esteva; C. Sierra; A. Bogdanovych; S. Simoff,"Appl. Math. Dept., Univ. of Barcelona, Barcelona; Appl. Math. Dept., Univ. of Barcelona, Barcelona; Artificial Intell. Res. Inst., Barcelona; Artificial Intell. Res. Inst., Barcelona; Sch. of Comput. & Math., Univ. of Western Sydney, Sydney, NSW; Sch. of Comput. & Math., Univ. of Western Sydney, Sydney, NSW",2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology,6-Jan-09,2008,1,,196,199,"Our research combines electronic institutions and 3D virtual worlds for the construction of virtual institutions which are virtual worlds with normative regulation of interactions. That is, a virtual world where participants actions have to comply with predefined institutional rules. In this context, the actions a participant may perform depend on the institutional rules and the current execution state. We propose to include iObjects, intelligent objects, as entities having both visualization properties and decision mechanisms in the virtual institution. They are a new key element to improve users participation in virtual institutions. We situate them in a middleware infrastructure in order to be independent of 3D virtual world platform and to provide a general solution in which participants could be connected from different immersive environment platforms.",,978-0-7695-3496-1,10.1109/WIIAT.2008.320,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740448,virtual environments;normative multiagent systems;virtual institutions;intelligent objects,Humans;Intelligent agent;Visualization;Artificial intelligence;Avatars;Mathematics;Software agents;Multiagent systems;Mechanical factors;Middleware,data visualisation;human computer interaction;middleware;multi-agent systems;virtual reality,intelligent objects;human participation;virtual institutions;electronic institutions;3D virtual worlds;iObjects;visualization property;middleware infrastructure,,2,,11,,6-Jan-09,,,IEEE,IEEE Conferences
Interaction-Oriented Service Entity Placement in Edge Computing,Y. Liang; J. Ge; S. Zhang; J. Wu; L. Pan; T. Zhang; B. Luo,"State Key Lab. for Novel Software Technology, Software Institute, Nanjing University, Nanjing, China; State Key Lab. for Novel Software Technology, Software Institute, Nanjing University, Nanjing, China; Department of Computer Science and Technology, State Key Lab. for Novel Software Technology, Nanjing University, Nanjing, China; Center for Networked Computing, Temple University, Philadelphia, PA, USA; State Key Lab. for Novel Software Technology, Software Institute, Nanjing University, Nanjing, China; State Key Lab. for Novel Software Technology, Software Institute, Nanjing University, Nanjing, China; State Key Lab. for Novel Software Technology, Software Institute, Nanjing University, Nanjing, China",IEEE Transactions on Mobile Computing,3-Feb-21,2021,20,3,1064,1075,"Distributed Interactive Applications (DIAs) such as virtual reality and multiplayer online game usually require fast processing of tremendous data and timely exchange of delay-sensitive action data and metadata. This makes traditional mobile-based or cloud-based solutions no longer effective. Thanks to edge computing, DIA Service Providers (DSPs) can rent resources from Edge Infrastructure Providers (EIPs) to place service entities that store user states and run computation-intensive tasks. One fundamental problem for a DSP is to decide where to place service entities to achieve low-delay pairwise interactions between DIA users, under the constraint that the total placement cost is no more than a specified budget threshold. In this article, we formally model the service entity placement problem and prove that it is NP-complete by a polynomial reduction from the set cover problem. We present GPA, an efficient algorithm for service entity placement, and theoretically analyze its performance. We evaluated GPA with both real-world data trace-driven simulations, and observed that GPA performs close to the optimal algorithm and generally outperforms the baseline algorithm. We also output a curve showing the trade-off between the weighted average interaction delay and the budget threshold, so that a DSP can choose the right balance.",1558-0660,,10.1109/TMC.2019.2952097,National Key R&D Program of China; NSFC; Natural Science Foundation of Jiangsu Province; CCF-Tencent Open Fund; Collaborative Innovation Center of Novel Software Technology and Industrialization; Open Foundation of State key Laboratory of Networking and Switching Technology; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894371,Edge computing;distributed interactive applications;interaction delay;service entity placement,Servers;Delays;Edge computing;Mobile computing;Cloud computing;Games;Task analysis,cloud computing;computational complexity;computer games;optimisation;virtual reality,edge computing;distributed interactive applications;DIA;virtual reality;delay-sensitive action data;metadata;edge infrastructure providers;service entities;computation-intensive tasks;low-delay pairwise interactions;total placement cost;specified budget threshold;service entity placement problem;set cover problem;GPA;real-world data trace-driven simulations;weighted average interaction delay;interaction-oriented service entity placement;mobile-based cloud-based solutions;DIA service providers,,2,,33,IEEE,8-Nov-19,,,IEEE,IEEE Journals
Real-time multi-objective hand posture/gesture recognition by using distance classifiers and finite state machine for virtual mouse operations,A. Aksa√ß; O. √ñzt√ºrk; T. √ñzyer,"Computer Engineering Department, TOBB University of Economics & Technology, Ankara, Turkey; Computer Engineering Department, TOBB University of Economics & Technology, Ankara, Turkey; Computer Engineering Department, TOBB University of Economics & Technology, Ankara, Turkey",2011 7th International Conference on Electrical and Electronics Engineering (ELECO),26-Jan-12,2011,,,II-457,II-461,"Cameras that are connected to computers record sequence of digital images of human hand in order to interpret human posture/gesture. Human hand posture/gesture recognition has been utilized for providing virtual reality mechanism and it is still an ongoing research in human-computer interaction (HCI) community. Virtual reality can be operated on a particular program but it will be more effective if the entire system can be controlled for the sake of generality. Another direction is the applicability of virtual reality in real time. In this paper, we have developed a virtual mouse system that can recognize the pre-defined mouse movements in real time regardless of the context. Our real time hand recognition system is three fold. 1) skin detection, 2) feature extraction and 3) recognition. For recognition, various features with their own objectives are constructed from hand postures and compared according to the similarity measures and the best-matched posture is used as a mouse action to control the cursor of the computer.",,978-6-0501-0090-7,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6140225,,Thumb;Mice;Pattern recognition;Feature extraction;Skin;Image color analysis,feature extraction;finite state machines;gesture recognition;human computer interaction;image classification;image sequences;object detection;virtual reality,hand posture recognition;gesture recognition;distance classifier;finite state machine;virtual mouse operation;human computer interaction;virtual reality mechanism;skin detection;feature extraction;digital image sequence;best-matched posture,,,,23,,26-Jan-12,,,IEEE,IEEE Conferences
"Integral Line-of-Sight Guidance and Control of Underactuated Marine Vehicles: Theory, Simulations, and Experiments",W. Caharija; K. Y. Pettersen; M. Bibuli; P. Calado; E. Zereik; J. Braga; J. T. Gravdahl; A. J. S√∏rensen; M. Milovanoviƒá; G. Bruzzone,"Centre for Autonomous Marine Operations and Systems, Norwegian University of Science and Technology, Trondheim, Norway; Centre for Autonomous Marine Operations and Systems, Norwegian University of Science and Technology, Trondheim, Norway; Institute of Intelligent Systems for Automation‚ÄìNational Research Council of Italy, Genoa, Italy; Laborat√≥rio de Sistemas e Tecnologia Subaqu√°tica, University of Porto, Porto, Portugal; Institute of Intelligent Systems for Automation‚ÄìNational Research Council of Italy, Genoa, Italy; Laborat√≥rio de Sistemas e Tecnologia Subaqu√°tica, University of Porto, Porto, Portugal; Department of Engineering Cybernetics, Norwegian University of Science and Technology, Trondheim, Norway; Centre for Autonomous Marine Operations and Systems, Norwegian University of Science and Technology, Trondheim, Norway; Rolls-Royce Marine AS, Bergen, Norway; Institute of Intelligent Systems for Automation‚ÄìNational Research Council of Italy, Genoa, Italy",IEEE Transactions on Control Systems Technology,4-Aug-16,2016,24,5,1623,1642,"This paper presents an extensive analysis of the integral line-of-sight (ILOS) guidance method for path-following tasks of underactuated marine vehicles, operating on and below the sea surface. It is shown that due to the embedded integral action, the guidance law makes the vessels follow straight lines by compensating for the drift effect of environmental disturbances, such as currents, wind, and waves. The ILOS guidance is first applied to a 2-D model of surface vessels that includes the underactauted sway dynamics of the vehicle as well as disturbances in the form of constant irrotational ocean currents and constant dynamic, attitude dependent, and forces. The actuated dynamics are not considered at this point. A Lyapunov closed-loop analysis yields explicit bounds on the guidance law gains to guarantee uniform global asymptotic stability (UGAS) and uniform local exponential stability (ULES). The complete kinematic and dynamic closed-loop system of the 3-D ILOS guidance law is analyzed in the following and hence extending the analysis to underactuated autonomous underwater vehicles (AUVs) for the 3-D straight-line path-following applications in the presence of constant irrotational ocean currents. The actuated surge, pitch, and yaw dynamics are included in the analysis where the closed-loop system forms a cascade, and the properties of UGAS and ULES are shown. The 3-D ILOS control system is a generalization of the 2-D ILOS guidance. Finally, results from simulations and experiments are presented to validate and illustrate the theoretical results, where the 2-D ILOS guidance is applied to the cooperative autonomous robotics towing system vehicle and light AUV.",1558-0865,,10.1109/TCST.2015.2504838,Research Council of Norway through the Centres of Excellence Funding Scheme; Strategic University Program; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422058,Cooperative autonomous robotics towing system (CART);unmanned semisubmersible vehicle (USSV);experiments;light autonomous underwater vehicle (LAUV);line-of-sight (LOS) guidance;nonlinear control;path following;underactuated vessels,Vehicle dynamics;Dynamics;Stability analysis;Sea surface;Vehicles;Underwater vehicles,asymptotic stability;attitude control;autonomous underwater vehicles;closed loop systems;Lyapunov methods;mobile robots;motion control;multi-robot systems;path planning;robot dynamics;robot kinematics;vehicle dynamics,integral line-of-sight guidance method;underactuated marine vehicles;3D straight-line path-following applications;3D ILOS guidance law;drift effect compensation;environmental disturbances;ILOS guidance method;2D surface vessel model;constant irrotational ocean currents;constant dynamic;attitude dependent;Lyapunov closed-loop analysis;uniform global asymptotic stability;UGAS;uniform local exponential stability;ULES;kinematic closed-loop system;dynamic closed-loop system;underactuated autonomous underwater vehicles;AUV;actuated surge dynamics;actuated pitch dynamics;actuated yaw dynamics;cooperative autonomous robotics,,115,,62,,29-Feb-16,,,IEEE,IEEE Journals
Tracking Operator Intent in Tactical Operations,M. F. Schneider; M. E. Miller; J. M. McGuirl,"Air Force Institute of Technology,Department of Systems Engineering and Management,Dayton,USA; Air Force Institute of Technology,Department of Systems Engineering and Management,Dayton,USA; LLC,Senior Scientist Centauri,Beavercreek,USA","2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",14-Dec-20,2020,,,3214,3220,"Effective teams coordinate their actions to achieve shared goals. In Human-Agent teams, the Artificial Intelligent Agents (AIAs) struggle to coordinate effectively due to a lack of understanding of their human teammate's intent. This places a burden on the human teammate to extensively communicate explicitly what goals they are pursuing and how they are pursuing them. To improve the AIAs ability to coordinate, we have proposed Operationalized Intent as a means to explicitly model how an operator qualitatively desires a task to be performed. In this paper, we report the results of a study to track operator intent through a tactical scenario. The focus of this paper is on the dynamics of intent and it's cohesiveness across operators. The study employed an immersive, advanced research, remotely piloted aircraft (RPA) simulator to study intent in a synthetic task environment. Using operational pilots and sensor operators in realistic scenarios we were able to elicit their intent under naturalistic conditions in the midst of challenging tactical situations to study the real-time dynamics. Analysis indicates that the method models intent which is dynamically responsive to changes in the situation and the data are suitably cohesive across operators to generalize to an operator role. When the intent data is coupled to situated data from the simulator it provides a labeled data source for future AIAs to estimate intent in real-time.",2577-1655,978-1-7281-8526-2,10.1109/SMC42975.2020.9283017,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283017,Human-Machine Cooperation and Systems;Mental Models;Augmented Cognition,Conferences;Real-time systems;Data models;Intelligent agents;Task analysis;Man-machine systems;Cybernetics,human computer interaction;military computing;software agents,operator intent;tactical operations;human-agent teams;artificial intelligent agents;AIA;operationalized intent;tactical scenario;remotely piloted aircraft simulator;operational pilots;sensor operators;tactical situations;RPA simulator,,,,14,,14-Dec-20,,,IEEE,IEEE Conferences
Virtual reality as a complex interactive system: a multidimensional model of person artificial partner co-relations,A. Libin,"Dept. of Psychol., Georgetown Univ., Rockville, MD, USA",Proceedings Seventh International Conference on Virtual Systems and Multimedia,6-Aug-02,2001,,,652,657,"The operational definition of virtual reality as a complex interactive system (CIS) represents it as a configuration of exchanges between a person and a digital world mediated by the artificial, partner. The adequate model for understanding the essence of CIS includes, in addition to three 'traditional' dimensions (physical-per-se, mental, and virtual), a fourth dimension defined as individual self-determination and formed by one's needs, preferences, profile of imagination, identities, and individual experiences. The analysis of 'person-artificial agent' interactions in the context of a complex systems approach is associated with the implementation of such interaction effects as compensation, optimization, adequacy, and effectiveness. Virtual entertainment can be viewed not only as a part of modern popular culture but also as a tool for constructive activities. The latter, employed by certain groups of users, can not only enhance their life as an enjoyment but also as training tool for sensory-motor, cognitive and emotional improvement, and their well-being in general.",,0-7695-1402-2,10.1109/VSMM.2001.969724,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=969724,,Virtual reality;Interactive systems;Multidimensional systems;Computational Intelligence Society;Humans;Visual perception;Cultural differences;Search engines;Psychology;Aging,virtual reality;man-machine systems;software agents;computer games;interactive systems,complex interactive system;virtual reality;artificial agent;individual preferences;man machine interactions;computer game,,4,,30,,6-Aug-02,,,IEEE,IEEE Conferences
Panel-human performance in virtual environments,J. Hodgins,"Georgia Inst. of Technol., Atlanta, GA, USA",Proceedings of IEEE 1997 Annual International Symposium on Virtual Reality,6-Aug-02,1997,,,78,,The panel embraces a number of pertinent design issues in this rapidly advancing technologic area. The issues to be discussed include: telepresence I/O device design issues to include haptic design issues for telesurgery; cybersickness issues and perceptual inputs; general HF design issues and lessons learned in VR; perceptual motor requirements and behavioral goals/ID of optimal display media and system object manipulation paradigms; VR issues in medical systems; VR tool development and perceptual considerations; and immersive object manipulation methods.,1087-8270,0-8186-7843-7,10.1109/VRAIS.1997.584400,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=584400,,Virtual reality;Haptic interfaces;Hafnium;Displays,virtual reality;human factors;interactive devices;social aspects of automation;medical computing;telecontrol,human performance;virtual environments;pertinent design issues;telepresence I/O device design issues;haptic design issues;telesurgery;cybersickness issues;perceptual inputs;general HF design issues;perceptual motor requirements;behavioral goals/ID;optimal display media;system object manipulation paradigms;VR issues;medical systems;VR tool development;perceptual considerations;immersive object manipulation methods,,,,,,6-Aug-02,,,IEEE,IEEE Conferences
Evaluating Multiple Levels of an Interaction Fidelity Continuum on Performance and Learning in Near-Field Training Simulations,A. Bhargava; J. W. Bertrand; A. K. Gramopadhye; K. C. Madathil; S. V. Babu,Clemson University; Clemson University; Clemson University; Clemson University; Clemson University,IEEE Transactions on Visualization and Computer Graphics,13-Mar-18,2018,24,4,1418,1427,"With costs of head-mounted displays (HMDs) and tracking technology decreasing rapidly, various virtual reality applications are being widely adopted for education and training. Hardware advancements have enabled replication of real-world interactions in virtual environments to a large extent, paving the way for commercial grade applications that provide a safe and risk-free training environment at a fraction of the cost. But this also mandates the need to develop more intrinsic interaction techniques and to empirically evaluate them in a more comprehensive manner. Although there exists a body of previous research that examines the benefits of selected levels of interaction fidelity on performance, few studies have investigated the constituent components of fidelity in a Interaction Fidelity Continuum (IFC) with several system instances and their respective effects on performance and learning in the context of a real-world skills training application. Our work describes a large between-subjects investigation conducted over several years that utilizes bimanual interaction metaphors at six discrete levels of interaction fidelity to teach basic precision metrology concepts in a near-field spatial interaction task in VR. A combined analysis performed on the data compares and contrasts the six different conditions and their overall effects on performance and learning outcomes, eliciting patterns in the results between the discrete application points on the IFC. With respect to some performance variables, results indicate that simpler restrictive interaction metaphors and highest fidelity metaphors perform better than medium fidelity interaction metaphors. In light of these results, a set of general guidelines are created for developers of spatial interaction metaphors in immersive virtual environments for precise fine-motor skills training simulations.",1941-0506,,10.1109/TVCG.2018.2794639,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260967,Bimanual Interaction;Interaction Fidelity;Empirical Evaluation;Educational Virtual Reality,Training;Aerospace electronics;Solid modeling;Metrology;Mice;Virtual environments,computer based training;helmet mounted displays;virtual reality,Interaction Fidelity Continuum;near-field training simulations;virtual reality applications;education;real-world interactions;safe risk-free training environment;intrinsic interaction techniques;near-field spatial interaction task;learning outcomes;discrete application points;performance variables;medium fidelity interaction metaphors;spatial interaction metaphors;immersive virtual environments;fine-motor skills training simulations;bimanual interaction metaphors;restrictive interaction metaphors;head-mounted displays;tracking technology,Adolescent;Adult;Cognition;Female;High Fidelity Simulation Training;Humans;Male;Surveys and Questionnaires;Task Performance and Analysis;User-Computer Interface;Virtual Reality;Young Adult,1,,33,Traditional,17-Jan-18,,,IEEE,IEEE Journals
Tracking target motion under combined visual and kinesthetic disturbances,L. Masia; V. Squeri; M. Casadio; P. Morasso; V. Sanguineti; G. Sandini,"IIT, Genoa, Italy; IIT, Genoa, Italy; IIT, Genoa, Italy; DIST, University of Genoa, Italy; DIST, University of Genoa, Italy; IIT, Genoa, Italy",2009 IEEE International Conference on Rehabilitation Robotics,21-Aug-09,2009,,,688,693,"This study addresses a major problem in the design of HCI (human-computer interface) systems: how to avoid or reduce the long learning/adaptation process and the corresponding attentional load of the underlying hand-eye coordination task that frequently affects HCI systems. In particular, we considered a tracking task to a visual target whose frame of reference is rotated with respect to a body-fixed frame in a time-varying manner. We investigated it by means of a wrist robot coupled with a virtual reality system: kinesthetic and visual disturbances were applied during a tracking task, in a unimodal and bimodal manner, and we observed the performance. Tracking involved two degrees of freedom and the kinesthetic disturbance was applied by the robot through the third degree of freedom. Visual disturbance was provided by rotating the visual feedback. The results suggest that the combination of a suitable proprioceptive feedback with the kinematic redundancy of the HCI system might be a rather general principle for improving the efficiency of HCI systems.",1945-7901,978-1-4244-3788-7,10.1109/ICORR.2009.5209541,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5209541,wrist robot;visual and proprioceptive disturbance;visuo-manual tracking;virtual reality,Target tracking;Human computer interaction;Robot kinematics;Motor drives;Mice;Wrist;Virtual reality;Feedback;Brushes;Minimally invasive surgery,robots;user interfaces;virtual reality,tracking target motion;visual disturbances;kinesthetic disturbances;human-computer interface;hand-eye coordination task;wrist robot;virtual reality system;proprioceptive feedback,,,,14,,21-Aug-09,,,IEEE,IEEE Conferences
An Exoskeleton Type 4-DOF Force Feedback Device Using Magnetorheological Fluid Clutches and Artificial Muscles,Y. Onozuka; R. Suzuki; Y. Yamada; T. Nakamura; C. University,"Faculty of Science and Engineering, Department of Precision Mechanics, Chuo University, 1-13-27 Kasuga, Bunkyo-ku, Tokyo, 112-8551, Japan; Faculty of Science and Engineering, Department of Precision Mechanics, Chuo University, 1-13-27 Kasuga, Bunkyo-ku, Tokyo, 112-8551, Japan; Faculty of Science and Engineering, Department of Precision Mechanics, Chuo University, 1-13-27 Kasuga, Bunkyo-ku, Tokyo, 112-8551, Japan; Faculty of Science and Engineering, Department of Precision Mechanics, Chuo University, 1-13-27 Kasuga, Bunkyo-ku, Tokyo, 112-8551, Japan; Faculty of Science and Engineering, Department of Precision Mechanics, Chuo University, 1-13-27 Kasuga, Bunkyo-ku, Tokyo, 112-8551, Japan",2018 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),2-Sep-18,2018,,,869,874,"Recently, virtual reality (VR) technology has been developed using a head mounted displays (HMD). Users can recognize virtual objects easily in a VR space. However, users cannot obtain haptic perception, such as operating actual objects. There are force feedback devices that can render its perception. General devices are desktop types which restrict the range of motion (ROM) of operators, whereas exoskeleton types achieve ROM like a human. Many force feedback devices using motors and decelerators lead to a loss of backdrivability and can harm the operator by active force. Therefore, we developed an exoskeleton type four degrees of freedom (DOF) force feedback device for the upper limb with magnetorheological fluid clutches and artificial muscles that are backdrivable and safe actuators; we confirmed that the proposed device can render an elastic force.",2159-6255,978-1-5386-1854-7,10.1109/AIM.2018.8452696,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8452696,,Muscles;Force;Force feedback;Torque;Wires;Elasticity;Rendering (computer graphics),clutches;electroactive polymer actuators;force feedback;magnetorheology;pneumatic actuators;virtual reality;wearable robots,virtual reality technology;head mounted displays;upper limb;pneumatic artificial muscles;virtual objects;exoskeleton type 4-DOF force feedback device;elastic force;artificial muscles;magnetorheological fluid clutches;exoskeleton types,,2,,13,,2-Sep-18,,,IEEE,IEEE Conferences
Shoulder flexion rehabilitation in patients with monoparesia using an exergame,J. B. Castano; J. D. Hoyos Escobar; J. E. Munoz Cardona; J. F. Lopez Herrera,"Human Computer Interaction Group, Programa Ciencias del Deporte y la Recreaci√≥n, Universidad Tecnol√≥gica de Pereira Pereira, Colombia; Human Computer Interaction Group Programa Ciencias del Deporte y la Recreaci√≥n, Universidad Tecnol√≥gica de Pereira Pereira, Colombia; Human Computer Interaction Group Maestr√≠a en Ingenier√≠a El√©ctrica Pereira, Colombia; Programa Ciencias del Deporte y la Recreaci√≥n, Universidad Tecnol√≥gica de Pereira Pereira, Colombia",2014 IEEE 3nd International Conference on Serious Games and Applications for Health (SeGAH),26-Mar-15,2014,,,1,5,"Purpose - Pyramidal syndrome is a neuromotor disorder that affects quality of life of 1 out of 12,000 people around the world and most people in their middle- old age. Conventional methods are used generally for the rehabilitation of this disorder and studies are currently trying to rehabilitate patients through interaction with serious video games focused on health. This study proposes a combination of the two methods to find improvements in the flexion angle of shoulder affected by upper motor neurone lesion in patients of the ‚ÄúClinica de Dolor del Eje Cafetero‚Äù. Methodology - 6 patients (3 patients with sequels of stroke, 1 patient with sequels of TBI and 2 patients with sequels of cerebral palsy) were taken into consideration. All patients suffered monoparesia in upper limb. Each patient had 7 sessions of rehabilitation. Each session of rehabilitation lasted for 30 minutes of assisted therapy and another 30 minutes with therapies of VR, where the movements of flexion of the shoulder affected through the Kinect sensor were recorded while the patient interacted with the video game. A biomechanical analysis with the Bio-Cirac software developed to load data from MoCap and show angle graphs was performed. Results - the patient who achieved the best results showed 21.0 % of improvement in the angle of flexion of the affected shoulder and improvement in muscular endurance and control of their affected limb. Conclusion - VR and serious video games specifically designed for particular pathologies are potentially useful technologies that can be combined with conventional methods to improve the angle of amplitude of flexion of the shoulder affected in patients with sequels of upper motor neurone lesion. In addition VR offers immersive experiences favorable for dissipation of pain, fatigue, setting goals and enjoyment of the activity.",,978-1-4799-4823-9,10.1109/SeGAH.2014.7067072,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7067072,pyramidal syndrome;Kinect;Rehabilitation;Exergame;Serious Game,Games;Medical treatment;Lesions;Neurons;Virtual reality;Pain;Muscles,biomechanics;interactive devices;medical computing;medical disorders;patient rehabilitation;serious games (computing);virtual reality,shoulder flexion rehabilitation;patient rehabilitation;monoparesia;exergame;serious video game;pyramidal syndrome;neuromotor disorder;Kinect sensor;biomechanical analysis;Bio-Cirac software;VR;virtual reality,,1,,19,,26-Mar-15,,,IEEE,IEEE Conferences
A new approach to quantify elbow position sense using an exoskeleton and a virtual reality display,A. Deblock-Bellamy; C. S. Batcho; C. Mercier; A. K. Blanchette,"CIRRIS, Universite Laval, Quebec city, Canada; CIRRIS, Universite Laval, Quebec city, Canada; CIRRIS, Universite Laval, Quebec city, Canada; CIRRIS, Universite Laval, Quebec city, Canada",2017 International Conference on Virtual Rehabilitation (ICVR),14-Aug-17,2017,,,1,2,"Most of the proprioception assessments commonly used are not adapted for individuals who present multiple impairments after a stroke. Indeed, these assessments require certain motor or cognitive functions that are generally affected after a stroke. We have therefore developed a protocol, combining a robotic device and a virtual reality display, that enables the assessment of position sense without requiring active movement in the evaluated arm, involving the opposite arm or relying on working memory. As a preliminary step of validation, elbow joint position sense of healthy young adults was quantified and test-retest reliability was studied. Results show that this protocol can quantify elbow position sense of healthy young adults (mean detection threshold: around 7 degrees), with a fair to good test-retest reliability.",2331-9569,978-1-5090-3053-8,10.1109/ICVR.2017.8007518,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007518,Proprioception;assessment;reliability;robotics;virtual reality;upper limb,Reliability;Elbow;Exoskeletons;Protocols;Robot sensing systems;Virtual reality,medical robotics;patient rehabilitation;virtual reality,elbow position;exoskeleton;virtual reality display;proprioception assessments;cognitive functions;robotic device;working memory,,,,8,,14-Aug-17,,,IEEE,IEEE Conferences
Experience with head-mounted virtual reality (HMD-VR) predicts transfer of HMD-VR motor skills,J. M. Juliano; D. Saldana; A. Schmiesing; S. Liew,"University of Southern California (USC),Neuroscience Graduate Program,Los Angeles,CA,USA; University of Southern California,Chan Division of Occupational,Los Angeles,CA,USA; University of Southern California,Chan Division of Occupational,Los Angeles,CA,USA; University of Southern California,Chan Division of Occupational,Los Angeles,CA,USA",2019 International Conference on Virtual Rehabilitation (ICVR),13-Feb-20,2019,,,1,2,"Immersive, head-mounted virtual reality (HMD-VR) has the potential to be a useful tool for motor rehabilitation. However, when developing tools for rehabilitation, it is essential to design interventions that will be most effective for generalizing to the real world. Therefore, it is important to understand what factors facilitate transfer from HMD-VR to non-HMD-VR environments. Here we used a well-established test of skilled motor learning, the Sequential Visual Isometric Pinch Task (SVIPT), to train healthy individuals in an HMD-VR environment. We examined whether learned motor skills transferred to a more conventional (non-HMD-VR) environment and what factors facilitated transfer. Our results suggest that on average, learned motor skills from this task transfer from an immersive virtual environment to a conventional environment; however, some individuals did not transfer the learned motor skills. We then examined individual differences between those that did show transfer and those that did not. We found that individuals who had previous exposure to HMD-VR were more likely to transfer their learned motor skills than those who did not. Individual differences in previous exposure to HMD-VR environments prior to training may serve as a predictor to whether learned motor skills will transfer out of HMD-VR.",2331-9569,978-1-7281-1285-5,10.1109/ICVR46560.2019.8994345,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994345,head-mounted virtual reality;skilled motor learning;transfer,,biomechanics;helmet mounted displays;learning (artificial intelligence);patient rehabilitation;virtual reality,HMD-VR environment;learned motor skills;head-mounted virtual reality;HMD-VR motor skills;motor rehabilitation;nonHMD-VR environments;skilled motor learning;immersive virtual environment,,,,9,,13-Feb-20,,,IEEE,IEEE Conferences
Pinch simulation with haptic feedback for stroke rehabilitation: A pilot study,P. Chiu; S. Lee; S. Yeh,"School of Information Science and Technology, Fudan University, Shanghai, China; Department of Physical Medicine and Rehabilitation, Taipei Veterans General Hospital, Taipei, Taiwan; School of Information Technology, Fudan University, Shanghai, China",2017 2nd International Conference on Information Technology (INCIT),15-Jan-18,2017,,,1,6,"Stroke is a leading cause of long-term disability, and virtual reality (VR)-based stroke rehabilitation has been shown to be effective for increasing the motivation and functional performance of stroke patients. Although many patients regain most reach and grasp capabilities in their upper extremity function, recovery of the pinch skill remains incomplete for the majority of patients. In this study, an innovative VR-based pinch skill training and strengthening system using haptics simulation was developed for the long-term recovery of upper extremity motor function post stroke. Two subject tests were conducted. The first was a healthy subject test conducted with 30 participants to verify the system design and functionality, specifically emphasizing difficulty levels and behavior phases. The second was a pilot test conducted on two stroke patients to examine the feasibility and therapeutic effects of the proposed system. Upon completion of the pilot test, the results of clinical assessment showed that both participants were improved. Using synchronized kinematic and kinetic data, the participants' behavior time-history was reconstructed for behavior interpretation and motor activity analysis. Finally, user acceptance of the technology was high, indicating that the participants intended to continue using the proposed system for rehabilitation.",,978-1-5386-1431-0,10.1109/INCIT.2017.8257885,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8257885,haptics;pinch;stroke;upper extremity;virtual reality (VR) therapy;rehabilitation,Force;Thumb;Haptic interfaces;Training;Information technology,biomechanics;haptic interfaces;medical computing;medical disorders;patient rehabilitation;virtual reality,innovative VR-based pinch skill training;haptics simulation;stroke patients;virtual reality;stroke rehabilitation;haptic feedback;pinch simulation;motor activity analysis,,1,,18,,15-Jan-18,,,IEEE,IEEE Conferences
Visuo-motor tracking with coordinated wrist movements under different combinations of visual and kinesthetic disturbances,L. Masia; V. Squeri; M. Casadio; P. Morasso; V. Sanguineti; G. Sandini,"Robotics Brain and Cognitive Sciences, Italian Institute of Technology, Genoa, Italy; Robotics Brain and Cognitive Sciences, Italian Institute of Technology, Genoa, Italy; Department of Informatics, Systems and Telecommunications, University of Genoa, Italy; Department of Informatics, Systems and Telecommunications, University of Genoa, Italy; Robotics Brain and Cognitive Sciences, Italian Institute of Technology, Genoa, Italy; Robotics Brain and Cognitive Sciences, Italian Institute of Technology, Genoa, Italy",2009 2nd Conference on Human System Interactions,23-Jun-09,2009,,,715,718,"This study addresses a major problem in the design of HCI (human-computer interface) systems: how to avoid or reduce the long learning/adaptation process and the corresponding attentional load of the underlying hand-eye coordination task that frequently affects HCI systems. In particular, we considered a 2D tracking task with two degrees of freedom of the wrist to a visual target whose frame of reference was rotated with respect to a body-fixed frame in a time varying manner. We investigated it by means of a wrist robot coupled with a virtual reality system. The experimental protocol consisted of applying kinesthetic and visual disturbances in a unimodal or bimodal manner and observing the tracking performance. The kinesthetic disturbance was provided by passively rotating the forearm of the subjects by the third degree of freedom of the wrist robot, while the visual disturbance was provided by rotating the visual scene. The results suggest that the combination of a suitable proprioceptive feedback with the kinematic redundancy of the HCI system might be a rather general principle for improving the efficiency of HCI systems.",2158-2254,978-1-4244-3959-1,10.1109/HSI.2009.5091065,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5091065,wrist robot;visuo-proprioceptive disturbance;tracking;virtual reality,Tracking;Wrist;Robot kinematics;Human computer interaction;Motor drives;Mice;Virtual reality;Brushes;Cognitive robotics;Informatics,control engineering computing;human computer interaction;robots;virtual reality,visuomotor tracking;coordinated wrist movements;visual-kinesthetic disturbances;human-computer interface;learning-adaptation process;hand-eye coordination task;virtual reality system;kinematic redundancy,,1,,12,,23-Jun-09,,,IEEE,IEEE Conferences
A Kinect-Based System for Stroke Rehabilitation,S. Yeh; S. Lee; R. Chan; S. Chen,"Computer Science and Information Engineering National Central University Taipei, Taiwan; Taipei Veterans General Hospital Taipei, Taiwan; Taipei Veterans General Hospital Taipei, Taiwan; Physical Therapy China Medical University, Taiwan Taipei, Taiwan",2019 Twelfth International Conference on Ubi-Media Computing (Ubi-Media),30-Mar-20,2019,,,192,198,"Virtual reality (VR)-based stroke rehabilitation has been shown to be effective in increasing motivation and functional performance in stroke patients. The new motion-sensing technology, Kinect, is cost effective and does not require the patient to wear sensors on the body, which increases freedom of movement. The objective of this study was to use Kinect technology to develop a VR stroke rehabilitation system with unilateral and bilateral tasks for recovering the function of the upper extremity. This study tested the feasibility, therapeutic effectiveness, and user acceptance of this technology. Two participants with various levels of motor severity received 30-minute stroke rehabilitation 3 times per week over 8 weeks (a total 24 training sessions). The Wolf Motor Function Test (WMFT), Test √âvaluant la performance des Membres sup√©rieurs des Personnes √Çg√©es (TEMPA), and Fugl-Meyer Assessment of Physical Performance (FMA) were used to collect data before and after rehabilitation, and during a follow-up to detect the changes of functional performance. Questionnaires of user acceptance of the technology were administered. On completion of the rehabilitation program, using the proposed Kinect-based VR training system, WMFT, TEMPA, and FMA results increased for both participants. The technology acceptance questionnaires indicated that participants had strong intentions to continue using the proposed system for rehabilitation. We developed the first Kinect-based stroke rehabilitation for the upper extremity, and demonstrated its feasibility and effectiveness in improving upper extremity function after a stroke. A large-scale study should be conducted to test the effectiveness of the proposed system for stroke rehabilitation.",,978-1-7281-2820-7,10.1109/Ubi-Media.2019.00045,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9049601,"Stroke, upper extremity, effectiveness, virtual-reality therapy",Task analysis;Stroke (medical condition);Extremities;Three-dimensional displays;Training;Medical treatment;Atmospheric measurements,image motion analysis;medical disorders;medical image processing;patient rehabilitation;virtual reality,physical performance;rehabilitation program;Kinect-based VR training system;Kinect-based stroke rehabilitation;upper extremity function;Kinect-based system;virtual reality-based stroke rehabilitation;stroke patients;motion-sensing technology;Kinect technology;VR stroke rehabilitation system;bilateral tasks;motor severity;stroke rehabilitation;Wolf Motor Function Test;Test Evaluant la performance des Membres superieurs des Personnes Agees;time 8.0 week,,,,16,,30-Mar-20,,,IEEE,IEEE Conferences
Evaluating A VR-based Box and Blocks Test for Automatic Assessment of Manual Dexterity: A Preliminary Study in Parkinson‚Äôs Disease,E. D. O√±a; A. Cuesta-Gomez; J. A. Garcia; W. Raffe; P. S√°nchez-Herrera; R. Cano-de-la-Cuerda; A. Jard√≥n,"Department of Systems Engineering and Automation, University Carlos III of Madrid, Legan√©s, Madrid, Spain; Faculty of Health Sciences, Rey Juan Carlos University, Alcorc√≥n, Madrid, Spain; UTS Games Studio, University of Technology Sydney, Sydney, NSW, Australia; UTS Games Studio, University of Technology Sydney, Sydney, NSW, Australia; Faculty of Health Sciences, Rey Juan Carlos University, Alcorc√≥n, Madrid, Spain; Faculty of Health Sciences, Rey Juan Carlos University, Alcorc√≥n, Madrid, Spain; Department of Systems Engineering and Automation, University Carlos III of Madrid, Legan√©s, Madrid, Spain",2019 IEEE 7th International Conference on Serious Games and Applications for Health (SeGAH),28-Oct-19,2019,,,1,6,"Opportunities of using Virtual Reality (VR) technology for the automation of clinical procedures in general, and for the assessment of motor function in particular, have not been fully explored in Parkinson' disease (PD). For that purpose, a game-like version of the Box and Blocks Test (BBT) for automatic assessment of hand motor function in VR was built. This system uses the Leap Motion Controller (LMC) for hand tracking and the Oculus Rift for a fully immersive experience. In this paper, we focus on evaluating the capabilities of our VR-BBT to reliably measure the manual dexterity in a sample of PD patients. For this study, a group of nine individuals in mild to moderate stage of PD were recruited. Participants were asked to perform both the physical BBT and the VR-BBT systems. Correlation analysis of collected data was carried out comparing the BBT and VR-BBT assessments. The test-retest reliability was also explored for the scores gathered with the virtual tool. Statistical analysis proved that the performance data collected by the game-like system correlated with the validated measures of the physical BBT, with a strong test-retest reliability. This fact suggests that the virtual version of the BBT could be used as a valid and reliable indicator for health improvements.",2573-3060,978-1-7281-0300-6,10.1109/SeGAH.2019.8882472,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8882472,automatic;assessment;manual dexterity;Parkinson‚Äôs disease;neurological rehabilitation;virtual reality,Reliability;Manuals;Sensors;Tools;Parkinson's disease;Automation,diseases;medical computing;reliability;statistical analysis;virtual reality,VR-based Box;Blocks Test;automatic assessment;manual dexterity;Parkinson's disease;Virtual Reality technology;clinical procedures;Parkinson disease;game-like version;hand motor function;Leap Motion Controller;hand tracking;Oculus Rift;fully immersive experience;PD patients;physical BBT;VR-BBT systems;correlation analysis;VR-BBT assessments;virtual tool;performance data;strong test-retest reliability;virtual version,,,,18,,28-Oct-19,,,IEEE,IEEE Conferences
Neurocognitive Assessment in Virtual Reality Through Behavioral Response Analysis,H. Oagaz; B. Schoun; M. Pooji; M. -H. Choi,"Department of Computer Science and Comcast Media and Technology Center, University of Colorado Denver, Denver, CO, USA; Department of Computer Science and Comcast Media and Technology Center, University of Colorado Denver, Denver, CO, USA; Department of 3D Graphics and Animation, University of Colorado Denver, Denver, CO, USA; Department of Computer Science and Comcast Media and Technology Center, University of Colorado Denver, Denver, CO, USA",IEEE Journal of Biomedical and Health Informatics,4-Sep-19,2019,23,5,1899,1910,"The ability to detect and diagnose neurocognitive disorders at the earliest possible moment is key to a better prognosis for the patient. Two of the earliest indicators of potential neurocognitive problems are motor and visual dysfunction. Motor disorders and problems in visual cognition can be seen in many neurocognitive disorders, resulting in abnormal physical reactions to visual stimuli. Analyzing physical behaviors when presented with such stimuli can provide insights into the visual perception and motor abilities of an individual, yet there is currently no unbiased, objective, general-purpose tool that analyzes attention and motor behavior to assess neurocognitive function. We propose a novel method of neurocognitive function assessment that tests the patient's cognition using virtual reality with eye tracking and motion analysis. By placing the patient in a controlled virtual environment and analyzing their movements, we can evoke certain physical responses from subjects for neurocognitive assessment. We have developed a prototype system that places the subject in a virtual baseball field and captures their full body motion as they try to catch baseballs. This scenario tests the subject's ability to determine the landing time and position of the ball, as well as the test subject's balance, motor skills, attention, and memory. Preliminary tests with 20 healthy normal individuals demonstrate the ability of this tool to assess the test subject's balance, memory, attention, and reaction to visual stimuli. This platform has a twofold contribution: it is used to assess several neurocognitive constructs that affect visual and motor capability neutrally and objectively based on controlled stimuli, and it enables objective comparison between different neurocognitive disorders research in this field.",2168-2208,,10.1109/JBHI.2018.2881455,Comcast Media and Technology Center; CU Denver ORS; Department of Education GAANN Fellowship; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8536376,Behavioral analysis;motor skills;neurocognitive assessment;virtual reality;visual cognition,Visualization;Tools;Sports;Tracking;Task analysis;Three-dimensional displays;Virtual reality,brain;cognition;gaze tracking;medical computing;medical disorders;neurophysiology;virtual reality;visual perception,neurocognitive function assessment;virtual reality;eye tracking;motion analysis;controlled virtual environment;physical responses;virtual baseball field;visual stimuli;motor capability;behavioral response analysis;visual dysfunction;motor disorders;visual cognition;visual perception;motor behavior;physical behaviors;neurocognitive problems,Adult;Aged;Cognition;Female;Humans;Male;Middle Aged;Neuropsychological Tests;Psychomotor Performance;Virtual Reality;Young Adult,1,,58,Traditional,15-Nov-18,,,IEEE,IEEE Journals
An innovative augmented reality educational framework with gamification to assist the learning process of children with intellectual disabilities,R. Colpani; M. R. Petrucelli Homem,"Department of Science Computer, Federal University of S√£o Carlos - UFSCar, Sorocaba, Brazil; Department of Science Computer, Federal University of S√£o Carlos - UFSCar, S√£o Carlos, Brazil","2015 6th International Conference on Information, Intelligence, Systems and Applications (IISA)",21-Jan-16,2015,,,1,6,"Currently, several studies are making use of multimedia systems, and Virtual Reality (VR) technology has been applied to people with special needs. However, its main limitations are the need for qualified human resources and the high costs. On the other hand, Augmented Reality (AR) technology has been increasing and it has become more and more popular because of its specificities. However, most studies involving these technologies are focused on the treatment of people with motor disabilities. Thus, this paper presents a proposal of an AR framework with gamification to assist the learning process of children with intellectual disabilities in general. Finally, the study will present some ways on how teachers might work some concepts and cognitive skills on children with intellectual disabilities with the aid of the framework.",,978-1-4673-9311-9,10.1109/IISA.2015.7387964,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7387964,Augmented Reality;Gamification;Intellectual Disability,Games;Animals;Computers;Software;Augmented reality;Education;Three-dimensional displays,augmented reality;computer aided instruction;computer games;handicapped aids;multimedia systems,innovative augmented reality educational framework;gamification;learning process;children;intellectual disabilities;multimedia systems;VR technology,,7,,18,,21-Jan-16,,,IEEE,IEEE Conferences
Developing and Validating Virtual Reality Tool for the Evaluation of Cognitive and Physical Performance During Simulated lengthy field March,S. K. Naor; R. Yanovich; Y. Bahat; M. Plotnik; I. Ketko; A. Gottlieb; O. Ben-Gal; Y. Heled,"Sheba Medical Center,The Center of Advanced Technologies in Rehabilitation,Tel Hashomer,Israel; Israel Defense Forces Medical Corps,Heller Institute of Medical Research,Tel Hashomer,Israel; Sheba Medical Center,The Center of Advanced Technologies in Rehabilitation,Tel Hashomer,Israel; Sheba Medical Center,The Center of Advanced Technologies in Rehabilitation,Tel Hashomer,Israel; Israel Defense Forces Medical Corps,Heller Institute of Medical Research,Tel Hashomer,Israel; Sheba Medical Center,The Center of Advanced Technologies in Rehabilitation,Tel Hashomer,Israel; Sheba Medical Center,The Center of Advanced Technologies in Rehabilitation,Tel Hashomer,Israel; Tel Aviv,Heller Institute of Medical Research,Tel Hashomer,Israel",2019 International Conference on Virtual Rehabilitation (ICVR),13-Feb-20,2019,,,1,7,"Athletes, soldiers, and rescue personnel are often required to perform intensive and prolonged physically demanding activities while remaining cognitively focused. The combined effect of physical and cognitive tasks is of great interest, as both efforts share central nervous system reserves. Amid a larger study that is aimed to create an ecologically validated virtual reality (VR) - based experimental protocol to explore the effect of high-load physical and cognitive efforts on young individuals, the present report focuses on comparing new cognitive tasks presented in the context of simulated military missions with physical load to already established cognitive testing battery. Twelve young participants performed a 10 Km loaded march on a treadmill in VR settings with or without additional cognitive tasks (VR-COG). Each experimental day, subjects underwent pre-and post-evaluation, in which cognitive (trail making test - the color trail test CTT version, and SYNWIN battery for multitasking evaluation) and physical tests (time to exhaustion test - TTE) were conducted. In general, strong or moderate correlations were found between VR-COG performances and the cognitive tests. The VR-COG tasks, together with CTT components, were able to successfully predict the effect of the combined physical and cognitive load on the multitasking performance. Multitasking was evaluated by the SYNWIN score. We believe that our protocol allows optimal conditions for measurement of the effect of high-load physical and cognitive efforts for an extended period of time, thus contributing to the motor-cognitive interaction model knowledge base. It is apparent that virtual environments are ideal set ups for studying military activities, as they enable the participants to experience a particular situation within a controlled area.",2331-9569,978-1-7281-1285-5,10.1109/ICVR46560.2019.8994473,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994473,virtual reality;ecologic environments;cognitive load;SYNWIN;CTT;Arm forces;military,Task analysis;Protocols;Visualization;Legged locomotion;Virtual reality;Navigation;Batteries,cognition;human factors;neurophysiology;psychology;virtual reality,virtual reality tool;physical performance;simulated lengthy field march;rescue personnel;central nervous system reserves;ecologically validated virtual reality;experimental protocol;young individuals;simulated military missions;physical load;cognitive testing battery;young participants;10 Km loaded march;VR settings;additional cognitive tasks;post-evaluation;trail making test;color trail test CTT version;multitasking evaluation;exhaustion test - TTE;VR-COG performances;cognitive tests;VR-COG tasks;multitasking performance;motor-cognitive interaction model knowledge base;virtual environments,,,,27,,13-Feb-20,,,IEEE,IEEE Conferences
Experimental evaluation of a haptic interface for endoscopic simulation,E. Samur; L. Flaction; H. Bleuler,"Laboratory of Robotic Systems, Ecole Polytechnique F√©d√©rale de Lausanne (EPFL), Switzerland; Laboratory of Robotic Systems, Ecole Polytechnique F√©d√©rale de Lausanne (EPFL), Switzerland; Laboratory of Robotic Systems, Ecole Polytechnique F√©d√©rale de Lausanne (EPFL), Switzerland",2011 IEEE World Haptics Conference,11-Jul-11,2011,,,545,549,"The main goal of virtual reality based surgery simulators with haptic feedback is to provide an alternative to traditional training methods on animals, cadavers or real patients. Haptic feedback is a key feature for every surgery simulator for the training of hand-eye coordination. To address the need for higher fidelity and complexity in an endoscopic simulator, we have designed a new haptic interface, instrumented a clinical endoscope and integrated it with a software simulation for colonoscopy. The proposed haptic interface provides high translational force and rotational torque with combined electrical motors and passive brakes. This paper presents the evaluation of the haptic interface. Experimental analyzes are performed for characterization and performance evaluation. A model-based feed-forward control is implemented and the results show that the control successfully compensates for the device dynamics and nonlinearities such as Coulomb and viscous friction.",,978-1-4577-0298-3,10.1109/WHC.2011.5945544,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5945544,,Haptic interfaces;Force;Colonoscopy;Solid modeling;Friction;Endoscopes;Performance evaluation,endoscopes;haptic interfaces;medical computing;surgery;virtual reality,haptic interface;endoscopic simulation;virtual reality based surgery simulator;haptic feedback;model-based feedforward control;Coulomb friction;viscous friction,,5,2,26,,11-Jul-11,,,IEEE,IEEE Conferences
Whitewater Slalom Pseudo Experience Device using 3-DOF Motion Base and VR Goggles,S. Yoshikawa; K. Takishima; T. Tomihira; Y. Sato; A. Homma; A. Yamashita; K. Matsubayashi,"Dept. of Comput. Sci., Nat. Inst. of Tech., Hachioji, Japan; Dept. of Comput. Sci., Nat. Inst. of Tech., Hachioji, Japan; Dept. of Comput. Sci., Nat. Inst. of Tech., Hachioji, Japan; Dept. of Mech. Eng., Nat. Inst. of Tech., Hachioji, Japan; Dept. of Comput. Sci., Nat. Inst. of Tech., Hachioji, Japan; Dept. of Comput. Sci., Nat. Inst. of Tech., Hachioji, Japan; Dept. of Comput. Sci., Nat. Inst. of Tech., Hachioji, Japan",2017 Conference on Technologies and Applications of Artificial Intelligence (TAAI),10-May-18,2017,,,76,79,"We generally visit a stadium, watch TV programs, or view online broadcasts to enjoy watching sports. However, the position of the seat or camera for broadcast in the stadium is generally fixed, and the motion of players cannot be experienced. A sports-watching system, called ""Synchro-athlete,"" is developed in our study, with a 3 DOF motion base and a virtual reality (VR) goggle. The motion base is driven by electric motors and is small and lightweight. Synchro-athlete provides 360¬∞ video, sound, and motion, which gives the viewer the impression of being a player. The control of the 3-DOF motion base and the application to canoe slalom are described in this paper.",2376-6824,978-1-5386-4203-0,10.1109/TAAI.2017.46,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356912,Sports-watching system;motion base;virtual reality;canoe,Acceleration;Actuators;Streaming media;Computer science;Motion pictures;Eye protection;Real-time systems,human factors;sport;virtual reality,whitewater slalom pseudoexperience device;VR goggles;watch TV programs;sports-watching system;3 DOF motion base;virtual reality goggle;synchro-athlete,,,,9,,10-May-18,,,IEEE,IEEE Conferences
Enactive Approach to Assess Perceived Speed Error during Walking and Running in Virtual Reality,T. Perrin; H. A. Kerherv√©; C. Faure; A. Sorel; B. Bideau; R. Kulpa,"Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France; Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France; Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France; Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France; Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France; Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,622,629,"The recent development of virtual reality (VR) devices such as head mounted displays (HMDs) increases opportunities for applications at the confluence of physical activity and gaming. Recently, the fields of sport and fitness have turned to VR, including for locomotor activities, to enhance motor and energetic resources, as well as motivation and adherence. For example, VR can provide visual feedbacks during treadmill running, thereby reducing monotony and increasing the feeling of movement and engagement with the activity. However, the relevance of using VR tools during locomotion depends on the ability of these systems to provide natural immersive feelings, specifically a coherent perception of speed. The objective of this study is to estimate the error between actual and perceived locomotor speed in VE using an enactive approach, i.e. allowing an active control of the environment. Sixteen healthy individuals participated in the experiment, which consisted in walking and running on a motorized treadmill at speeds ranging from 3 to 11 km/h with 0.5 km/h increments, in a randomized order while wearing a HMD device (HTC Vive) displaying a virtual racetrack. Participants were instructed to match VE speed with what they perceived was their ac-tuallocomotion speed (LS), using a handheld Vive controller. They were able to modify the optic flow speed (OFS) with a 0.02 km/h increment/decrement accuracy. An optic flow multiplier (OFM) was computed based on the error between OFS and LS. It represents the gain that exists between the visually perceived speed and the real locomotion speed experienced by participants for each trial. For all conditions, the average of OFM was 1.00¬±.25 to best match LS. This finding is at odds with previous works reporting an underestimation of speed perception in VR. It could be explained by the use of an enactive approach allowing an active and accurate matching of visually and proprioceptively perceived speeds by participants. But above all, our study showed that the perception of speed in VR is strongly individual, with some participants always overestimating and others constantly underestimating. Therefore, a general OFM should not be used to correct speed in VE to ensure congruence in speed perception, and we propose the use of individual models as recommendations for setting up locomotion-based VR applications.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8798209,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798209,Virtual reality;speed perception assessment;running in virtual environment;enaction;physical activity in VR,Legged locomotion;Adaptive optics;Resists;Optical feedback;Virtual environments;Visualization,gait analysis;helmet mounted displays;human factors;mechanoception;virtual reality,speed perception;visually perceived speeds;proprioceptively perceived speeds;locomotion-based VR applications;virtual reality devices;physical activity;locomotor activities;visual feedbacks;VR tools;natural immersive feelings;actual perceived locomotor speed;motorized treadmill;HMD device;virtual racetrack;VE speed;handheld Vive controller;optic flow speed;optic flow multiplier;visually perceived speed;locomotion speed;perceived speed error;velocity 0.5 km/h;velocity 0.02 km/h;velocity 3.0 km/h to 11.0 km/h,,,,35,,15-Aug-19,,,IEEE,IEEE Conferences
A Haptic Virtual Borescope for Visual Engine Inspection Training,D. Vembar; A. T. Duchowski; S. Sadasivan; A. K. Gramopadhye,"School of Computing, Clemson University, Clemson, SC 29634; School of Computing, Clemson University, Clemson, SC 29634, e-mail: duchowski@acm.org; Industrial Engineering, Clemson University, Clemson, SC 29634; Industrial Engineering, Clemson University, Clemson, SC 29634",2008 IEEE Symposium on 3D User Interfaces,31-Mar-08,2008,,,19,26,"A haptic virtual borescope is developed for the purpose of aircraft engine inspection training, similar in spirit to borescope trainers intended for use in gas turbine maintenance training schools. Such devices consist of engine section mockups for use with a real borescope. Our approach instead simulates engine sections in virtual reality, replacing the need for physical mockups. We model the engine casing as a ""black box"" where a simulated borescope tip is inserted (in practice a real borescope is used to provide tactile veridicality of the probe's braided sheath but the camera at its tip is not used). The probe's translational movement is mapped to the virtual camera's. The graphical engine representation can conceivably generalize to any engine section that can be modeled graphically. Since the interior chamber of the ""black box"" casing is empty, the critical component of our simulator is correct borescope tip navigation as well as force feedback response based on a mathematical model of collision detection of the tip in the computer generated environment. Haptic response is thought to be a key component of the simulator as it provides non-visual tactile awareness of the borescope tip within the engine under inspection and, more importantly, its contact with engine surfaces. Our contribution is two-fold. First, we design a novel motor-powered clamp that provides collision response to collision of the camera detected in virtual space. Second, we attempt to isolate the effect of the system's tactile response and provide empirical evaluation of its utility. In line with previous results, our empirical analysis reveals a trend toward a benefit in performance (speed), but suggests that the provision of haptic feedback, while preferred over a solely visual interface, may be perceived as extraneous in a visually-dominated discrimination task.",,978-1-4244-2047-6,10.1109/3DUI.2008.4476586,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4476586,I.3.6 [Computer Graphics]: Methodology and Techniques¬øErgonomics;J.4 [Computer Applications]: Social and Behavioral Sciences¬øPsychology,Haptic interfaces;Engines;Inspection;Cameras;Computational modeling;Aircraft propulsion;Turbines;Educational institutions;Virtual reality;Computer simulation,aerospace engineering;computer based training;engines;force feedback;graphical user interfaces;haptic interfaces;mechanical engineering computing;virtual reality,haptic virtual borescope;visual engine inspection training;aircraft engine inspection training;virtual reality;graphical engine representation;black box casing;borescope tip navigation;force feedback response;collision detection;computer generated environment,,1,1,19,,31-Mar-08,,,IEEE,IEEE Conferences
Artificial Behavioral System By Sensor-Motor Mapping Strategy For Multi-Objective Robot Tasks,E. Daglarli; H. Temeltas,"Istanbul Technical University, Turkey; Istanbul Technical University, Turkey",Third International Conference on Natural Computation (ICNC 2007),5-Nov-07,2007,2,,139,143,"In this study, behavioral system based robot control architecture is built up for a four-wheel driven and four-wheel steered mobile robot. Behavioral system is determined as evolutionary neural-fuzzy inference system for behavior generation and self-learning processes in the general robot control architecture. The kinematics and dynamic model of the mobile robot with non-holonomic constraints is used as present structure which is modeled in previous studies. The posture and speed of the robot and the configurations, speeds and torques of the wheels can be observed from the simulation plant and virtual reality viewer. The behaviors are investigated regarding their gains, fuzzy inference structures, real-time applicability and their coordination.",2157-9563,978-0-7695-2875-5,10.1109/ICNC.2007.268,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4344332,Robot behavior;SOM Neural networks;Relational fuzzy logic;Diploid genetic programming;Autonomous robotics.,Robot sensing systems;Mobile robots;Robot kinematics;Laboratories;Robot control;Control systems;Orbital robotics;Sensor systems;Fuzzy logic;Intelligent robots,control engineering computing;evolutionary computation;fuzzy neural nets;inference mechanisms;mobile robots;multi-robot systems;robot dynamics;robot kinematics;virtual reality,artificial behavioral system;sensor-motor mapping strategy;multiobjective robot tasks;robot control architecture;four-wheel steered mobile robot;evolutionary neural-fuzzy inference system;behavior generation;self-learning processes;robot kinematics;robot dynamics;nonholonomic constraints;virtual reality viewer;fuzzy inference structures,,,,7,,5-Nov-07,,,IEEE,IEEE Conferences
Information Constrained Control Analysis of Eye Gaze Distribution Under Workload,R. M. Hecht; A. B. Hillel; A. Telpaz; O. Tsimhoni; N. Tishby,"Rachel and Selim Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem, Israel; Department of Industrial Engineering and Management, Ben-Gurion University of the Negev‚ÄîFaculty of Engineering Sciences, Beersheba, Israel; Advanced Technical Center Israel, General Motors, Herzliya, Israel; General Motors Technical Center, Warren, MI, USA; Rachel and Selim Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem, Israel",IEEE Transactions on Human-Machine Systems,4-Dec-19,2019,49,6,474,484,"We describe a novel model of human eye gaze behavior under workload, derived from the basic principle of information constrained control. The model assumes two distributions over the visual field: A saliency distribution, which is nongoal oriented, and a reward task-related distribution. The eye gaze behavior is determined by the tradeoff between these two distributions, where the goal is to preserve the task-related constraints, while remaining as close as possible to the saliency distribution representing a comfort zone. Based on minimum Kullback-Liebler divergence principles, the model gives rise to a family of gaze distributions controlled by a single tradeoff parameter. The model was evaluated experimentally in a driving simulator that consisted of an immersive environment with clear tasks and accurate monitoring capabilities. The findings confirm the theoretical predictions with respect to the low rank manifold and order relations in the data. We show that the model can be used to visualize the unknown reward function associated with a task, and predict human workload based on gaze pattern.",2168-2305,,10.1109/THMS.2019.2930996,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8821410,Eye gazing distribution;information constrained control (ICC),Gaze tracking;Visual systems;Computational modeling;Task analysis;Visualization;Position measurement,control engineering computing;data visualisation;distributed control;human computer interaction;statistical distributions,Kullback-Liebler divergence principles;human eye gaze behavior;visual field;information constrained control,,,,43,IEEE,30-Aug-19,,,IEEE,IEEE Journals
Advanced human-system interfaces for telerobotics using virtual reality and telepresence technologies,R. J. Stone,"United Kingdom Adv. Robotics Res. Centre, Salford, UK",Fifth International Conference on Advanced Robotics 'Robots in Unstructured Environments,6-Aug-02,1991,,,168,173 vol.1,"Historically, human-system interfaces have not, in general, received the human factors attention they deserve. One approach to overcoming the problems of poor human-system interface designs is to exploit the human's natural information processing and motor control skills in order to enhance situational awareness and minimise mental and physical workload. This paper describes the early stages and results of a UK Project which addresses the design of 'natural' or 'intuitive' interfaces by combining telepresence and virtual reality technologies.<>",,0-7803-0078-5,10.1109/ICAR.1991.240658,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=240658,,Telerobotics;Virtual reality;Human factors;Service robots;Mobile robots;Robot sensing systems;Teleoperators;Man machine systems;Master-slave;Space technology,human factors;man-machine systems;robots;telecontrol;user interfaces;virtual reality,man-machine systems;robotics;telerobotics;virtual reality;telepresence;human-system interfaces;human factors;situational awareness,,15,1,24,,6-Aug-02,,,IEEE,IEEE Conferences
Design expanded BCI with improved efficiency for VR-embedded neurorehabilitation systems,F. Parivash; L. Amuzadeh; A. Fallahi,"School of Mechanical and Mechatronics Engineering, Shahrood University of Technology, Shahrood, Iran; Department of Biomedical Engineering, Hamedan University of Technology, Hamedan, Iran; Department of Biomedical Engineering, Hamedan University of Technology, Hamedan, Iran",2017 Artificial Intelligence and Signal Processing Conference (AISP),26-Mar-18,2017,,,230,235,"A general brain computer interface (BCI) usually consists of three main units known as preprocessing unit, feature selection unit and classification unit. In this paper, an EEG-based BCI with expanded structure is introduced that provides opportunity to improve efficiency of virtual reality (VR) embedded neurorehabilitation systems. The proposed BCI has to detect three different neuro-stimulations during specified motor imagery tasks and generate proper virtual neuro-stimulations for the avatar to do the task in the VR world. In the proposed BCI, discrete wavelet transformation (DWT) and multilayer perceptron (MLP) neural network are applied for preprocessing and classification, respectively; and an expounder is added to eliminate misclassifications which lead to wrong virtual neuro-stimulations. Offline EEG signals are applied to examine the proposed BCI and results are demonstrated.",,978-1-5386-2585-9,10.1109/AISP.2017.8324087,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8324087,brain computer interface(BCI);EEG motor imagery signals;virtual reality;neuro-rehabilitation,Task analysis;Electroencephalography;Band-pass filters;Brain-computer interfaces;Visualization;Feature extraction,brain-computer interfaces;discrete wavelet transforms;electroencephalography;feature extraction;medical signal processing;multilayer perceptrons;neurophysiology;patient rehabilitation;signal classification;virtual reality,virtual neurostimulations;expanded BCI;multilayer perceptron neural network;offline EEG signals;general brain computer interface;preprocessing classification;VR world;specified motor imagery tasks;virtual reality embedded neurorehabilitation systems;expanded structure;classification unit;feature selection unit;preprocessing unit,,,,16,,26-Mar-18,,,IEEE,IEEE Conferences
Investigating Human Performance in a Virtual Reality Haptic Simulator as Influenced by Fidelity and System Latency,D. B. Kaber; Y. Li; M. Clamann; Y. Lee,"Edward P. Fitts Department of Industrial and Systems Engineering, North Carolina State University, Raleigh, NC, USA; Edward P. Fitts Department of Industrial and Systems Engineering, North Carolina State University , Raleigh, NC, USA; Edward P. Fitts Department of Industrial and Systems Engineering, North Carolina State University, Raleigh, NC, USA; Edward P. Fitts Department of Industrial and Systems Engineering, North Carolina State University , Raleigh, NC, USA","IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans",12-Oct-12,2012,42,6,1562,1566,"The objective of this study was to demonstrate the utility of an established model of human motor behavior for assessing the fidelity of a virtual reality (VR) and haptic-based simulation for fine motor task performance. This study was also to serve as a basis for formulating general performance-based simulator-design guidelines toward balancing perceived realism with simulator limitations, such as latency resulting from graphic and haptic renderings. A low-fidelity surgical simulator was developed as an example VR for study, and user performance was tested in a simplified tissue-cutting task using a virtual scalpel. The observed aspect of the simulation included a discrete-movement task under different system-lag conditions and settings of task difficulty. Results revealed user performance in the VR to conform with Fitts' law of motor behavior and for performance to degrade with increasing task difficulty and system time lag. In general, the findings of this work support predictions on human performance under various simulator-design conditions using an established model of motor-control behavior and formulation of human-performance-based simulator-design principles.",1558-2426,,10.1109/TSMCA.2012.2201466,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6330028,Haptic interfaces;medical simulation;modeling;virtual reality,Virtual reality;Haptic interfaces;Modeling;Surgery;Mathematical model,haptic interfaces;medical computing;rendering (computer graphics);virtual reality,human performance;virtual reality;haptic simulator;fidelity;system latency;human motor behavior;haptic-based simulation;graphic renderings;haptic renderings,,26,,24,,12-Oct-12,,,IEEE,IEEE Journals
VR Motor Cues: Inducing user movements in virtual rehabilitation systems.,S. A. Perez; J. Gil-Gomez; M. Alcaniz; J. Lozano,"Computer Science and Systems Engineering Dept., University of Zaragoza, Teruel, Espa√±a; Inst. Bioingenier√≠a y Tecnolog√≠a Orientada al Ser Humano, Universidad Polit√©cnica de Valencia, Espa√±a; Inst. Bioingenier√≠a y Tecnolog√≠a Orientada al Ser Humano, Universidad Polit√©cnica de Valencia, Espa√±a; Inst. Bioingenier√≠a y Tecnolog√≠a Orientada al Ser Humano, Universidad Polit√©cnica de Valencia, Espa√±a",2009 Virtual Rehabilitation International Conference,24-Jul-09,2009,,,199,199,"Generally, the tracking system is one of the main restrictions in a virtual rehabilitation system because of its cost and / or complex setup. Here we introduce the concept of Virtual Reality Motor Cues (VR Motor Cues). VR Motor Cues include those mechanisms designed with the specific purpose of inducing the user to realize a specific motor activity. An effective VR Motor Cue can guarantee, in a high percentage of cases, the realization of specific user movements, thereby avoiding the need to integrate a tracking system to ensure these movements are carried out. Following this concept, this contribution proposes two initial classifications of VR Motor Cues.",2331-9569,978-1-4244-4188-4,10.1109/ICVR.2009.5174237,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5174237,Virtual motor rehabilitation;VR Motor Cues,Virtual reality;Tracking;Virtual environment;Protocols;Costs;Haptic interfaces;Avatars;Gas insulated transmission lines;Computer science;Systems engineering and theory,medical computing;patient rehabilitation;virtual reality,VR Motor Cue;virtual rehabilitation system;Virtual Reality Motor Cue,,,,1,,24-Jul-09,,,IEEE,IEEE Conferences
A novel ultrasonic motor with a built-in clutch mechanism for a force-feed-back actuator,M. Aovagi; T. Tomikawa; T. Takano,"Muroran Inst. of Technol., Japan; NA; NA","IEEE Ultrasonics Symposium, 2004",18-Apr-05,2004,3,,2239,2242 Vol.3,"A force-feed-back actuator used for a haptic virtual reality system requires a rapid reactive force generation in order to present the realistic touch of surface roughness and hardness on a virtual object. In general, an ultrasonic motor (USM) has a quick response; however, a torque free condition that gives no feeling to a user does not exist on a USM. One solution of this problem is to have a static clutch mechanism within a USM. A novel ultrasonic motor equipped with a clutch mechanism is proposed and examined.",1051-0117,0-7803-8412-1,10.1109/ULTSYM.2004.1418285,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1418285,,Actuators;Haptic interfaces;Elasticity;Force control;Virtual reality;Rough surfaces;Surface roughness;Torque;Circuits;Friction,ultrasonic motors;clutches;actuators;haptic interfaces;tactile sensors;piezoelectric actuators;virtual reality,ultrasonic motor;built-in clutch mechanism;force-feedback actuator;haptic virtual reality system;reactive force generation;surface roughness;surface hardness;static clutch mechanism;multilayer piezoelectric actuator,,,,3,,18-Apr-05,,,IEEE,IEEE Conferences
Evaluation of multimodal feedback effects on the time-course of motor learning in multimodal VR platform for rowing training,K. Maria; A. Filippeschi; E. Ruffaldi; Y. Shorr; D. Gopher,"Department of Occupational Therapy, University of Haifa, Haifa, Israel; Scuola Superiore Sant'Anna TECIP, Pisa, Italy; Scuola Superiore Sant'Anna TECIP, Pisa, Italy; William Davidson Faculty of Industrial Engineering and Management, Technion, Israel Institute of Technology, Haifa, Israel; William Davidson Faculty of Industrial Engineering and Management, Technion, Israel Institute of Technology, Haifa, Israel",2015 International Conference on Virtual Rehabilitation (ICVR),17-Dec-15,2015,,,158,159,"This study focused on the benefits of feedback augmentation for multi-session training of a complex motor-cognitive skill of indoor rowing in virtual environment. Specifically, we compared the effectiveness of augmented information feedback provided per training trial either visually, haptically or visual-haptically to the non-augmented condition, where no on-line feedback on task performance was afforded during training sessions. Surprisingly, the non-augmented training group was in general as successful in the long-term learning of a rowing skill as the augmented groups and according to some measures even superior to them. Our results also highlight important differences in the course of learning and skill representation upon different feedback conditions provided during training and may provide useful insights to the optimization for both sport and rehabilitation training protocols in VR.",2331-9569,978-1-4799-8984-3,10.1109/ICVR.2015.7358628,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358628,indoor rowing;long-term training;augmented feedback;visual feedback;haptic feedback;motor learning;skill acquisition;VR,,augmented reality;cognition;gait analysis;medical computing;patient rehabilitation;sport,multimodal feedback effects;motor learning time-course;multimodal VR platform;rowing training;feedback augmentation;multisession training;complex motor-cognitive skill;indoor rowing;virtual environment;augmented information feedback;nonaugmented condition;online feedback;task performance;training sessions;nonaugmented training group;long-term learning;rowing skill;skill representation;sport;rehabilitation training protocols,,1,,6,,17-Dec-15,,,IEEE,IEEE Conferences
Implementation Study of Parachute Training Simulator,C. Duran Aygun; H. Gozde; M. Dursun; M. M. Aygun; M. C. Taplamacioglu,University of Gazi; National Defense University; University of Gazi; TOBB University of Economics and Technology; University of Gazi,2019 6th International Conference on Electrical and Electronics Engineering (ICEEE),12-Aug-19,2019,,,307,311,"Parachute training simulator is a powerful simulation tool that gives training starting from the position of free fall to jumpers with scenarios and graphics very close to reality and can perform this education close to reality. Parachute simulator is a cost-effective solution for paratroopers to enhance training, planning, practicing skills and mission readiness in a short notice and safe environment. Parachute training simulator designed parachute training with 3D virtual images are an effective addition to mastering all the necessary parachute dynamics and control by providing a real jump to the staff. The system provides real-time practicing the crucial skills under a wide range of weather conditions, wind and emergency situations while improving mission readiness and performance by using virtual reality with high resolution visual database. Parachute simulator training starts with free fall motion. After the parachute is turned on by the user, it is aimed to be controlled by the parachute control rivers (ripcord) to land at the specified point. A parachute simulator training system generally includes parachute training unit, visual system, instructor console, environmental voice and intercom are the basic units. In this study, the example design procedure is explained for a parachute simulator.",,978-1-7281-3910-4,10.1109/ICEEE2019.2019.00066,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8792509,parachute simulator;control applications;man machine interactions;precision motion control,Training;Solid modeling;Virtual reality;Brushless motors;Atmospheric modeling;Actuators;Real-time systems,aerodynamics;aerospace computing;aerospace testing;computer based training;design engineering;parachutes;virtual reality,mission readiness;necessary parachute dynamics;parachute control rivers;parachute simulator training system;parachute training unit;3D virtual images;weather conditions;high resolution visual database;ripcord;instructor console;environmental voice;intercom,,,,9,,12-Aug-19,,,IEEE,IEEE Conferences
The changes of improvement-related motor kinetics after virtual reality based rehabilitation,C. Chen; S. Lee; W. Wang; H. Chen; J. Liu; Y. Huang; M. Su,"Department of Biomedical Sciences and Engineering, National Central University, No.300, Jhongda Rd., Jhongli City, Taoyuan County 32001, Taiwan (R.O.C.); Department of Physical Medicine and Rehabilitation, Taipei Veterans General Hospital, Taiwan; Department of Computer Science and Information Engineering, National Central University, No.300, Jhongda Rd., Jhongli City, Taoyuan County 32001, Taiwan (R.O.C.); Department of Computer Science and Information Engineering, National Central University, No.300, Jhongda Rd., Jhongli City, Taoyuan County 32001, Taiwan (R.O.C.); Department of Physical Medicine and Rehabilitation, Taipei Veterans General Hospital, Taiwan; Department of Physical Medicine and Rehabilitation, Taipei Veterans General Hospital, Taiwan; Department of Computer Science and Information Engineering, National Central University, No.300, Jhongda Rd., Jhongli City, Taoyuan County 32001, Taiwan (R.O.C.)",2017 International Conference on Applied System Innovation (ICASI),24-Jul-17,2017,,,683,685,"Stroke is a major cause of adult disability and up to two thirds of stroke survivors have left with motor deficits of the affected upper limb (UL). Rehabilitation is the main therapeutic approach for reducing poststroke functional deficits but significant variability exists between patients regarding rehabilitation efficacy. Because the recovery mechanisms induced by rehabilitation are not fully understood, it is still not clear which treatment approaches and techniques are most beneficial. Virtual reality (VR) is a computer-based environment that provides the users an immersive experience of a synthetic world and allows a systemic testing of human functions under the simulated environment of controllable parameters. A large body of evidence has demonstrated the efficacy of VR based rehabilitation for improving the upper limb functional recovery. However, the question which components in the VR game are most valuable for promoting the recovery has not been examined. This study aims to identify the motion kinetics extracted from the VR based rehabilitation that are significantly correlated with the functional improvement. Twenty-one stroke patients were recruited and received 1 hour rehabilitation with the intensity of 3 times per week over 8 weeks, in total 24 training sessions, using a home-made VR program. All patients underwent the evaluation of their function before and after rehabilitation by Fugl-Meyer assessment (FMA). The parameters of human kinetics, such as speed/max speed, velocity and trajectory during VR-based rehabilitation were recorded digitally and the changes of the kinetics after finishing 24 training sessions were then correlated with the post-rehabilitation changes of FMA. The statistic result showed that the increase of efficiency, speed stability and straightness of trajectory leads to a better functional improvement, in addition to the increase of palm strength. In conclusion, the changes of the improvement-related motor kinetics could serve as guidance when designing the individualized treatment strategy.",,978-1-5090-4897-7,10.1109/ICASI.2017.7988517,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7988517,virtual reality (VR) based rehabilitation;Kinematic Features;individualized treatment,Kinetic theory;Virtual reality;Games;Training;Trajectory;Extremities;Conferences,medical computing;patient treatment;virtual reality,improvement related motor kinetics;virtual reality;rehabilitation;stroke;adult disability;stroke survivors;motor deficits;upper limb;UL;therapeutic approach;post stroke functional;recovery mechanisms;computer based environment;synthetic world;human functions;simulated environment;controllable parameters;upper limb functional recovery;VR game;motion kinetics extraction;Fugl-Meyer assessment;FMA;human kinetics;individualized treatment strategy,,1,,17,,24-Jul-17,,,IEEE,IEEE Conferences
EMG Feature Extractions for Upper-Limb Functional Movement During Rehabilitation,M. S. Hazam Majid; W. Khairunizam; A. B. Shahriman; I. Zunaidi; B. N. Sahyudi; M. R. Zuradzman,"AiCOS Research Lab, School of Mechatronic, Universiti Malaysia Perlis, Perlis, Malaysia; AiCOS Research Lab, School of Mechatronic, Universiti Malaysia Perlis, Perlis, Malaysia; AiCOS Research Lab, School of Mechatronic, Universiti Malaysia Perlis, Perlis, Malaysia; Technopreneur at UniMAP Sdn. Bhd., Perlis, 01000, Malaysia; AiCOS Research Lab, School of Mechatronic, Universiti Malaysia Perlis, Perlis, Malaysia; AiCOS Research Lab, School of Mechatronic, Universiti Malaysia Perlis, Perlis, Malaysia",2018 International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS),29-Nov-18,2018,3,,314,320,"Rehabilitation is important treatment for post stroke patient to regain their muscle strength and motor coordination as well as to retrain their nervous system. Electromyography (EMG) has been used by researcher to enhance conventional rehabilitation method as a tool to monitor muscle electrical activity however EMG signal is very stochastic in nature and contains some noise. Special technique is yet to be researched in processing EMG signal to make it useful and effective both to researcher and to patient in general. Feature extraction is among the signal processing technique involved and the best method for specific EMG study needs to be applied. In this works, nine feature extractions techniques are applied to EMG signals recorder from subjects performing upper limb rehabilitation activity based on suggested movement sequence pattern. Three healthy subjects perform the experiment with three trials each and EMG data were recorded from their bicep and deltoid muscle. The applied features for every trials of each subject were analyzed statistically using student T-Test their significant of p-value. The results were then totaled up and compared between the nine features applied and Auto Regressive coefficient (AR) present the best result and consistent with each subjects' data. This feature will be used later in our future research work of Upper-limb Virtual Reality Rehabilitation.",2189-8723,978-1-5386-7516-8,10.1109/ICIIBMS.2018.8549932,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8549932,Electromyography;Arm Rehabilitation;Feature extraction,Electromyography;Muscles;Feature extraction;Task analysis;Training;Electrodes,biomechanics;electromyography;feature extraction;medical computing;medical robotics;medical signal processing;neurophysiology;patient rehabilitation;virtual reality,EMG feature extractions;important treatment;post stroke patient;muscle strength;motor coordination;nervous system;conventional rehabilitation method;muscle electrical activity;special technique;processing EMG signal;feature extraction;signal processing technique;specific EMG study;feature extractions techniques;EMG signals recorder;upper limb rehabilitation activity;suggested movement sequence pattern;healthy subjects;EMG data;bicep;deltoid muscle;future research work;upper-limb virtual reality rehabilitation;upper-limb functional movement,,1,,22,,29-Nov-18,,,IEEE,IEEE Conferences
Virtual reality based training to resolve visio-motor conflicts in surgical environments,M. Vankipuram; K. Kahol; A. Ashby; J. Hamilton; J. Ferrara; M. Smith,"Human Machine Symbiosis Lab, Department of Biomedical Informatics, Arizona State University, Phoenix 85004 USA; Human Machine Symbiosis Lab, Department of Biomedical Informatics, Arizona State University, Phoenix 85004 USA; Human Machine Symbiosis Lab, Department of Biomedical Informatics, Arizona State University, Phoenix 85004 USA; Phoenix Integrated Surgical Residency Program, Banner Good Samaritan Medical Center, AZ 850016 USA; Phoenix Integrated Surgical Residency Program, Banner Good Samaritan Medical Center, AZ 850016 USA; Simulation and Training Center (SimET Center), Banner Good Samaritan Medical Center, Phoenix AZ 850016 USA",2008 IEEE International Workshop on Haptic Audio visual Environments and Games,21-Nov-08,2008,,,7,12,"An issue that complicates movement training, specifically in minimally invasive surgery, is that often there is no one to one correlation between the visual feedback provided on a screen and the movement required to perform the given task. This paper presents a simulator that specifically addresses the intermodal conflict between motor actuation and visual feedback. We developed a virtual reality visio-haptic simulator to assist surgical residents in training to resolve visio-motor conflict. The developed simulator offers individuals the flexibility to train in various scenarios with different levels of visio-motor conflicts. The levels of conflict were simulated by creating a linear functional relation between movement in the real environment and the virtual environment. The haptic rendering was consistent with the visual feedback. Experiments were conducted with expert pediatric surgeons and general surgery residents. Baseline data on performance in conditions of visio-motor conflict were assimilated from expert surgeons. Residents were divided into experimental group that was exposed to visio-motor conflict and the control group which wasnpsilat exposed to visio-motor conflict training. When the performance was compared on a standard surgical suturing task, the residents with inter-modal conflict training performed better than the control group suggesting the construct validity of the training and that visio-motor training can accelerate learning.",,978-1-4244-2668-3,10.1109/HAVE.2008.4685290,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4685290,Virtual Reality;Medical Simulation;Haptic User Interfaces;Surgical Simulation,Virtual reality;Minimally invasive surgery;Feedback;Humans;Cameras;Haptic interfaces;Medical simulation;Ergonomics;Biological system modeling;Patient monitoring,computer based training;haptic interfaces;medical computing;rendering (computer graphics);surgery;virtual reality,virtual reality based training;visio-motor conflicts;surgical environments;minimally invasive surgery;visual feedback;linear functional relation;haptic rendering;visio-motor training,,3,,10,,21-Nov-08,,,IEEE,IEEE Conferences
An unilateral master-slave hand system with a force-controlled slave hand,H. Hashimoto; H. Ogawa; T. Umeda; M. Obama; K. Tatsuno,"Keihin Product Oper., Toshiba Corp., Yokohama, Japan; NA; NA; NA; NA",Proceedings of 1995 IEEE International Conference on Robotics and Automation,6-Aug-02,1995,1,,956,961 vol.1,"We have developed a new unilateral master-slave hand system. The master system consists of a master arm which has a 3-DOF parallel link mechanism and a 3-DOF wrist mechanism, and a dataglove that is usually used for a virtual reality system. The slave system has a 6-DOF arm and a 16-DOF four-fingered hand. In general, a slave system is controlled by position with reference to a master system position. In this system, when an operator makes the slave system work on a complicated task, he must look at the slave carefully and let his arm and hand manipulate discretely. In the new master-slave system, each finger of the slave hand has a fingertip tactile sensor, and it is controlled by position and force. When an operator has knowledge of a task and handling objects and sets the slave fingertip stiffness, the operation can be performed easily by handling the master arm and hand to a rough position.",1050-4729,0-7803-1965-6,10.1109/ROBOT.1995.525406,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=525406,,Master-slave;Fingers;Control systems;Force control;DC motors;Tactile sensors;Force sensors;Wrist;Data gloves;Virtual reality,telerobotics;man-machine systems;virtual reality;force control;position control;tactile sensors;manipulators,unilateral master-slave hand system;force-controlled slave hand;master arm;3-DOF parallel link mechanism;3-DOF wrist mechanism;dataglove;virtual reality;6-DOF arm;16-DOF four-fingered hand;position control;tactile sensor;force control;fingertip stiffness,,10,5,8,,6-Aug-02,,,IEEE,IEEE Conferences
Force reflection distribution of haptic devices,M. Hossny; A. Bhatti; S. Nahavandi; R. Tilove,"Centre for Intelligent Systems Research (CISR), Deakin University, Australia; Centre for Intelligent Systems Research (CISR), Deakin University, Australia; Centre for Intelligent Systems Research (CISR), Deakin University, Australia; GM Global Research and Development, General Motors, USA",2014 8th International Conference on Signal Processing and Communication Systems (ICSPCS),26-Jan-15,2014,,,1,9,"Haptically enabled virtual reality systems facilitate rapid and low cost testing for process design, training practices and ergonomic analysis in many manufacturing industries, particularly automotive and aerospace. In this work we design a validation framework to validate the dynamic forces displayed by haptic display devices using a robot arm equipped with a force sensor. The validation framework is completely autonomous to ensure unbiased characterization. Measured force magnitude and the direction of the sensed force vector are the main criteria used in this work.",,978-1-4799-5255-7,10.1109/ICSPCS.2014.7021102,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7021102,Haptics Interface;Force Validation,Force;Haptic interfaces;Vectors;Force sensors;Robot kinematics;Robot sensing systems,force sensors;haptic interfaces;manipulators;virtual reality,force reflection distribution;virtual reality systems;dynamic forces;haptic display devices;force sensor;robot arm,,,,15,,26-Jan-15,,,IEEE,IEEE Conferences
The training strategy in brain-computer interface,B. Xia; W. Yang; D. Xiao; C. Wang,"College of Electronics and Information Engineering, Tongji University, Shanghai, China; Department of Electronic Engineering, Shanghai Maritime University, China; Department of Electronic Engineering, Shanghai Maritime University, China; Department of Electronic Engineering, Shanghai Maritime University, China",2010 Sixth International Conference on Natural Computation,23-Sep-10,2010,4,,2190,2193,"In this paper, we discuss the different train strategies for brain-computer interface. In general, it will take a long time to train subjects for motor imagery based BCI. There are many biofeedback methods to train subject. To compare the efficiency of different training strategies, we train the subjects by using two type training models: virtual reality and progress bar. The progress bar based training strategy show good result in our experiments.",2157-9563,978-1-4244-5961-2,10.1109/ICNC.2010.5583993,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5583993,motor imagery;progress bar;virtual-reality,Electroencephalography;Training;Accuracy;Support vector machines;Virtual reality;Signal processing;Feature extraction,brain-computer interfaces;virtual reality,training strategy;brain-computer interface;motor imagery;biofeedback methods;virtual reality;progress bar based training strategy,,2,,6,,23-Sep-10,,,IEEE,IEEE Conferences
A General Framework of Brain-Computer Interface with Visualization and Virtual Reality Feedback,G. Sun; K. Li; X. Li; B. Zhang; S. Yuan; G. Wu,"Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai, China; Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai, China; Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai, China; Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai, China; Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai, China; Sch. of Comput. Eng. & Sci., Shanghai Univ., Shanghai, China","2009 Eighth IEEE International Conference on Dependable, Autonomic and Secure Computing",15-Jan-10,2009,,,418,423,"The concept of brain-computer interface (BCI) has emerged over the last three decades as a promising alternative to the existing interface methods. However the BCI framework generally spoken only emphasizes on the aspects of BCI signal processing, lacking of the function of visualization and virtual reality (VR) feedback. This paper designs a general and extendable framework which has the ability of offline, online analysis, visualization, and VR feedback. For the researchers, they can use it to analyze the online EEG signals, and observe the dynamic brain information of subjects. Meanwhile, the researchers can also do the offline analysis. For subjects, VR technology can provide a more secure and realistic environment for training and tuning neutrally controlled interfaces to real-world devices, such as wheelchairs. At last, the methods and algorithms used in the framework are also described.",,978-1-4244-5421-1,10.1109/DASC.2009.72,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5380420,Brain-Computer Interface (BCI);EEG;Motor imagery;Real-time;Visualization;Virtual Reality,Brain computer interfaces;Visualization;Virtual reality;Feedback;Signal processing;Information analysis;Signal analysis;Electroencephalography;Wheelchairs;Signal processing algorithms,brain-computer interfaces;data visualisation;electroencephalography;medical signal processing;virtual reality,brain-computer interface;virtual reality feedback;visualization function;BCI signal processing;online EEG signals;VR technology,,4,,14,,15-Jan-10,,,IEEE,IEEE Conferences
Position-Based Control of Under-Constrained Haptics: A System for the Dexmo Glove,S. Friston; E. Griffith; D. Swapp; A. Marshall; A. Steed,"Department of Computer Science, University College London, London, U.K.; Department of Electrical Engineering and Electronics, University of Liverpool, Liverpool, U.K.; Department of Computer Science, University College London, London, U.K.; Department of Electrical Engineering and Electronics, University of Liverpool, Liverpool, U.K.; Department of Computer Science, University College London, London, U.K.",IEEE Robotics and Automation Letters,24-Jul-19,2019,4,4,3497,3504,"The Dexmo glove is a haptic exoskeleton that provides kinesthetic feedback in virtual reality. Unlike many other gloves based on string-pulleys, the Dexmo uses a free-hinged link-bar to transfer forces from a crank to the fingertips. It also uses an admittance-based controller parameterized by position, as opposed to an impedance-based controller parameterized by force. When setting the controller's target position, developers must use its native angular coordinate system. The Dexmo has a number of uninstrumented degrees of freedom. Mature forward models can reliably predict the hand pose, even with these unknowns. When it comes to computing angular controller parameters from a target pose in Cartesian space however, things become more difficult. Complex models that provide attractive visuals from a small number of sensors can be non-trivial or even impossible to invert. In this letter, we suggest side-stepping this issue. We sample the forward model in order to build a lookup table. This is embedded in three-dimensional space as a curve, on which traditional queries against world geometry can be performed. Controller parameters are stored as attributes of the sample points. To compute the driver parameters for a target position, the application constrains the position to the geometry, and interpolates them. This technique is generalizable, stable, simple, and fast. We validate our approach by implementing it in Unity 2017.3 and integrating it with a Dexmo glove.",2377-3766,,10.1109/LRA.2019.2927940,Engineering and Physical Sciences Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758944,Data gloves;force feedback;virtual reality;robot control,Haptic interfaces;Exoskeletons;Robots;Admittance;Computational modeling;Couplings;DC motors,data gloves;feedback;haptic interfaces;position control;virtual reality,position-based control;under-constrained haptics;Dexmo glove;haptic exoskeleton;free-hinged link-bar;admittance-based controller;impedance-based controller;native angular coordinate system;angular controller parameters;Unity 2017.3;kinesthetic feedback;virtual reality,,1,,45,CCBY,10-Jul-19,,,IEEE,IEEE Journals
Mechanisms of neural reorganization in chronic stroke subjects after virtual reality training,S. Saleh; H. Bagce; Q. Qiu; G. Fluet; A. Merians; S. Adamovich; E. Tunik,"New Jersey Institute of Technology Newark, NJ 07102 USA; School of Health Related Professions and the school of Biomedical Sciences at the University of Medicine and Dentistry, Newark, 07107; New Jersey Institute of Technology Newark, NJ 07102 USA; School of Health Related Professions at the University of Medicine and Dentistry, Newark, 07107; School of Health Related Professions at the University of Medicine and Dentistry, Newark, 07107; New Jersey Institute of Technology Newark, NJ 07102 USA; School of Health Related Professions and the school of Biomedical Sciences at the University of Medicine and Dentistry, Newark, 07107",2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society,1-Dec-11,2011,,,8118,8121,"This study investigates patterns of brain reorganization in chronic stroke subjects after two weeks of robot-assisted arm and hand training in virtual reality (VR). Four subjects were studied with event-related fMRI while doing simple paretic hand finger movements before (double baseline) and after training. Bilateral hand movements were recorded and used to provide real-time feedback to subjects during scanning to eliminate performance confounds on fMRI results. The kinematic parameters of each movement were also used in the general linear model with the BOLD signal to investigate training-induced changes in neuromotor coupling. Univariate analysis showed an increase in BOLD signal in the ipsilesional hemisphere in two subjects and a decrease in activity in the other two subjects. Seed voxel based functional connectivity analysis revealed an increase in connectivity between ipsilesional motor cortex and bilateral sensorimotor cortex during finger movements in all four subjects. Hemispheric laterality index values showed a tendency to decrease reflecting a reduction in the over-dominance of the contralesional hemisphere. The study is novel in terms of 1) tracking finger movement during a motor task in the scanner, 2) monitoring motor performance during the experiment and 3) giving online visual feedback of subjects' movement. This pilot study introduces a novel approach to study neural plasticity by combining measures of regional intensity, interregional interactions (using functional connectivity analysis and hemispheric laterality index), and modulation in the strength of neuromotor coupling.",1558-4615,978-1-4577-1589-1,10.1109/IEMBS.2011.6092002,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6092002,,Training;Robot sensing systems;Thumb;Angular velocity;Kinematics;Couplings,biomechanics;biomedical MRI;brain;diseases;medical image processing;medical robotics;neurophysiology;virtual reality,neural reorganization;chronic stroke;virtual reality training;brain reorganization;robot-assisted arm;hand training;event-related fMRI;paretic hand finger movements;bilateral hand movements;real-time feedback;BOLD signal;univariate analysis;functional connectivity analysis;ipsilesional motor cortex;bilateral sensorimotor cortex;tracking finger movement;online visual feedback;neural plasticity;hemispheric laterality index;neuromotor coupling,Aged;Chronic Disease;Female;Functional Laterality;Humans;Male;Middle Aged;Nerve Net;Nervous System;Oxygen;Robotics;Stroke;Stroke;Task Performance and Analysis;User-Computer Interface,9,,20,,1-Dec-11,,,IEEE,IEEE Conferences
Vibrotactile letter reading using a low-resolution tactor array,Y. Yanagida; M. Kakita; R. W. Lindeman; Y. Kume; N. Tetsutani,"Media Inf. Sci. Labs., ATR, Kyoto, Japan; Media Inf. Sci. Labs., ATR, Kyoto, Japan; Media Inf. Sci. Labs., ATR, Kyoto, Japan; Media Inf. Sci. Labs., ATR, Kyoto, Japan; Media Inf. Sci. Labs., ATR, Kyoto, Japan","12th International Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, 2004. HAPTICS '04. Proceedings.",19-Apr-04,2004,,,400,406,"Vibrotactile displays have been studied for several decades in the context of sensory substitution. Recently, a number of vibrotactile displays have been developed to extend sensory modalities in virtual reality. Some of these target the whole body as the stimulation region, but existing systems are only designed for discrete stimulation points at specific parts of the body. However, since human tactile sensation has more resolution, a higher density might be required in factor alignment in order to realize general-purpose vibrotactile displays. One problem with this approach is that it might result in an impractically high number of required tactors. Our current focus is to explore ways of simplifying the system while maintaining an acceptable level of expressive ability. As a first step, we chose a well-studied task: tactile letter reading. We examined the possibility of distinguishing alphanumeric letters by using only a 3-by-3 array of vibrating motors on the back of a chair. The tactors are driven sequentially in the same sequence as if someone were tracing the letter on the chair's back. The results showed 87% successful letter recognition in some cases, which was close to the results in previous research with much larger arrays.",,0-7695-2112-6,10.1109/HAPTIC.2004.1287227,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1287227,,Computer displays;Virtual reality;Humans;Virtual environment;Haptic interfaces;Information science;Laboratories;Computer science;Knowledge engineering;Elbow,haptic interfaces;virtual reality;character recognition;touch (physiological),vibrotactile letter reading;tactor array;vibrotactile displays;sensory substitution;virtual reality;letter recognition;human tactile sensation,,37,,21,,19-Apr-04,,,IEEE,IEEE Conferences
The perceived orientation in people with and without Alzheimer's,D. Zen; A. Byagowi; M. Garcia; D. Kelly; B. Lithgow; Z. Moussavi,"Faculty of Medicine at Federal University of Espirito Santo, Brazil; Electrical and Computer Engineering Department, University of Manitoba; Biomedical Engineering Program, University of Manitoba; Department of Psychology and Biomedical Engineering Program, University of Manitoba; Alfred Hospital, Monash University, Australia, and Biomedical Engineering Program of University of Manitoba; Biomedical Engineering Program of the University of Manitoba, Winnipeg, Manitoba",2013 6th International IEEE/EMBS Conference on Neural Engineering (NER),2-Jan-14,2013,,,460,463,"Accurate spatial perception is important for the successful performance of any motor task. Research suggests that this capability declines significantly in patients with Alzheimer's disease. Using a virtual reality navigational test, this study investigates the orientation ability. In particular, we hypothesize the ability to orient using egocentric information declines significantly with Alzheimer's even at early stages, whereas general orientation abilities maybe preserved through the use of allocentric orientation strategies in mild Alzheimer's patients. The study subjects were 11 cognitively healthy and 8 patients with mild to moderate Alzheimer's. The results are congruent with our hypothesis, and encourage further investigation in a larger population.",1948-3554,978-1-4673-1969-0,10.1109/NER.2013.6695971,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6695971,,Alzheimer's disease;Floors;Educational institutions;Solid modeling;Virtual reality;Windows,cognition;diseases;virtual reality;visual perception,perceived orientation;Alzheimer's disease;accurate spatial perception;motor task;virtual reality navigational test;orientation ability;egocentric information;allocentric orientation,,,,17,,2-Jan-14,,,IEEE,IEEE Conferences
[Title page i - Volume 1],,,2012 International Conference on Computer Science and Electronics Engineering,23-Apr-12,2012,1,,i,i,The following topics are dealt with: environmental cost internalization effect analysis; pricing decision theory; international carbon emission trading; device description technology; proportional-derivative controller; chaotic financial system; rolling bearing fault diagnosis; multichannel MAC protocol; 802.11-based wireless mesh networks; Uyghur broadcast news continues speech sensitive-word spotting system; viscoelastic ray tracing simulation; underground cavity stability; spacecraft attitude control; inertia matrix generalized mixed vector variational-like inequalities; stub tooth involute gears; expression recognition; BP neural network; file access security; CFD numerical simulation; exhaust gas flow pattern; hot galvanizing bath; grading steel ball; wear discrete element method; orbit determination; space-based optical observations; Adaboost blob tracking; parallel switching power supply module system; multisource heterogeneous data integration; DSP-based SVPWM vector control system; asynchronous motor scanned document image segmentation; Voronoi diagram; aircraft object recognition model; adaptive threshold Canny edge detection algorithm; data synchronization; open service-aware mobile network API; OAuth based authentication; Open Telco API; online fresh supermarket logistics delivery information system; image encryption algorithm; fast 1-DDCT algorithm; parallel computing; safety education system; virtual reality technology; water quality; aeronautical component repair business optimization; high-speed BiCMOS fully differential operational amplifier; cloud computing; enterprise information system; software development cost; Java multithread technology; wireless sensor network; NC remote video monitoring; military communication network; e-government affair system; particle swarm optimized wavelet neural network; face recognition; grass stem biomechanics; RFID system; Internet of Things; gyroscope test instrument rotating floor DSP control system; and AC synchronous generators.,,978-0-7695-4647-6,10.1109/ICCSEE.2012.81,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6187941,,,access protocols;aircraft maintenance;application program interfaces;asynchronous generators;attitude control;authorisation;backpropagation;biomechanics;cloud computing;computational fluid dynamics;computational geometry;data integration;decision theory;environmental economics;face recognition;fault diagnosis;file organisation;finite element analysis;galvanising;gears;government data processing;image coding;information systems;military communication;neural nets;parallel processing;particle swarm optimisation;pricing;radiofrequency identification;ray tracing;rolling bearings;signal processing;space vehicles;speech recognition;test equipment;three-term control;video surveillance;virtual reality;water quality;wear;wireless mesh networks;wireless sensor networks,environmental cost internalization effect analysis;pricing decision theory;international carbon emission trading;device description technology;proportional-derivative controller;chaotic financial system;rolling bearing fault diagnosis;multichannel MAC protocol;802.11-based wireless mesh networks;Uyghur broadcast news continues speech sensitive-word spotting system;viscoelastic ray tracing simulation;underground cavity stability;spacecraft attitude control;inertia matrix;generalized mixed vector variational-like inequalities;stub tooth involute gears;expression recognition;BP neural network;file access security;CFD numerical simulation;exhaust gas flow pattern;hot galvanizing bath;grading steel ball wear;discrete element method;orbit determination;space-based optical observations;Adaboost blob tracking;parallel switching power supply module system;multisource heterogeneous data integration;DSP-based SVPWM vector control system;asynchronous motor;scanned document image segmentation;Voronoi diagram;aircraft object recognition model;adaptive threshold Canny edge detection algorithm;data synchronization;open service-aware mobile network API;OAuth based authentication;Open Telco API;online fresh supermarket logistics delivery information system;image encryption algorithm;fast 1-DDCT algorithm;parallel computing;safety education system;virtual reality technology;water quality;aeronautical component repair business optimization;high-speed BiCMOS fully differential operational amplifier;cloud computing;enterprise information system;software development cost;Java multithread technology;wireless sensor network;NC remote video monitoring;military communication network;e-government affair system;particle swarm optimized wavelet neural network;face recognition;grass stem biomechanics;RFID system;Internet of Things;gyroscope test instrument rotating floor DSP control system;AC synchronous generators,,,,,,23-Apr-12,,,IEEE,IEEE Conferences
Wearable tactile device using mechanical and electrical stimulation for fingertip interaction with virtual world,V. Yem; H. Kajimoto,"The University of Electro-Communications, Tokyo, Japan; The University of Electro-Communications, Tokyo, Japan",2017 IEEE Virtual Reality (VR),6-Apr-17,2017,,,99,104,"We developed ‚ÄúFinger Glove for Augmented Reality‚Äù (FinGAR), which combines electrical and mechanical stimulation to selectively stimulate skin sensory mechanoreceptors and provide tactile feedback of virtual objects. A DC motor provides high-frequency vibration and shear deformation to the whole finger, and an array of electrodes provide pressure and low-frequency vibration with high spatial resolution. FinGAR devices are attached to the thumb, index finger and middle finger. It is lightweight, simple in mechanism, easy to wear, and does not disturb the natural movements of the hand. All of these attributes are necessary for a general-purpose virtual reality system. User study was conducted to evaluate its ability to reproduce sensations of four tactile dimensions: macro roughness, friction, fine roughness and hardness. Result indicated that skin deformation and cathodic stimulation affect macro roughness and hardness, whereas high-frequency vibration and anodic stimulation affect friction and fine roughness.",2375-5334,978-1-5090-6647-6,10.1109/VR.2017.7892236,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892236,FinGAR;mechanical stimulation;electrical stimulation;virtual touch,Vibrations;Thumb;Skin;Electrodes;DC motors;Electrical stimulation,augmented reality;data gloves;DC motors;haptic interfaces;shear deformation;vibrations,wearable tactile device;electrical stimulation;mechanical stimulation;virtual world;fingertip interaction;finger glove for augmented reality;skin sensory mechanoreceptors;tactile feedback;virtual objects;DC motor;high-frequency vibration;shear deformation;electrode array;low-frequency vibration;high spatial resolution;FinGAR devices;general-purpose virtual reality system;tactile dimensions;macro roughness;friction;fine roughness;hardness;anodic stimulation,,33,,34,,6-Apr-17,,,IEEE,IEEE Conferences
Elucidating Factors that can Facilitate Veridical Spatial Perception in Immersive Virtual Environments,W. B. Thompson; J. E. Swan; D. Proffitt; J. K. Kearney; V. Interrante; W. B. Thompson; J. E. Swan; D. Proffitt; J. K. Kearney; V. Interrante,"NA; NA; NA; NA; Minnesota Univ., MN; NA; NA; NA; NA; Minnesota Univ., MN",2007 IEEE Virtual Reality Conference,23-Apr-07,2007,,,11,18,"Enabling veridical spatial perception in immersive virtual environments (IVEs) is an important yet elusive goal, as even the factors implicated in the often-reported phenomenon of apparent distance compression in HMD-based IVEs have yet to be satisfactorily elucidated. In recent experiments (Interrante et al., 2006), we have found that participants appear less prone to significantly underestimate egocentric distances in HMD-based IVEs, relative to in the real world, in the special case that they unambiguously know, through first-hand observation, that the presented virtual environment is a high fidelity 3D model of their concurrently occupied real environment. We had hypothesized that this increased veridicality might be due to participants having a stronger sensation of 'presence' in the IVE under these conditions of co-location, which state of mind leads them to act on their visual input in the IVE similarly as they would in the real world (the presence hypothesis). However, alternative hypotheses are also possible. Primary among these is the visual calibration hypothesis: participants could be relying on metric information gleaned from their exposure to the real environment to calibrate their judgments of sizes and distances in the matched virtual environment. It is important to disambiguate between the presence and visual calibration hypotheses because they suggest different directions for efforts to facilitate veridical distance perception in general (non-co-located) IVEs. In this paper, we present the results of an experiment that seeks novel insight into this question. Using a mixed within- and between-subjects design, we compare participants' relative ability to accurately estimate egocentric distances in three different virtual environment models: one that is an identical match to the occupied real environment; one in which each of the walls in our virtual room model has been surreptitiously moved ~10% inward towards the center of the room; and one in which each of the walls has been surreptitiously moved ~10% outwards from the center of the room. If the visual calibration hypothesis holds, then we should expect to see a degradation in the accuracy of peoples' distance judgments in the surreptitiously modified models, manifested as an underestimation of distances when the IVE is actually larger than the real room and as an overestimation of distances when the IVE is smaller. However, what we found is that distances were significantly underestimated in the virtual environment relative to in the real world in each of the surreptitiously modified room environments, while remaining reasonably accurate (consistent with our previous findings) in the case of the faithfully size-matched room environment. In a post-test survey, participants in each of the three room size conditions reported equivalent subjective levels of presence and did not indicate any overt awareness of the room size manipulation",2375-5334,1-4244-0905-5,10.1109/VR.2007.352458,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4161000,egocentric distance perception;immersive virtual environments,Virtual environment;Calibration;Computer graphics;Displays;Computer science;Computer architecture;Degradation;Chromium;Virtual reality;USA Councils,augmented reality;computer graphics;visual perception,spatial perception;immersive virtual environments;human perception;3D spatial relationships;augmented reality;optical-motor information;ocular-motor information,,19,,13,,23-Apr-07,,,IEEE,IEEE Conferences
Development of a virtual environment based training system for ROV pilots,B. Fletcher; S. Harris,"Imetrix Inc., Cataumet, MA, USA; NA",OCEANS 96 MTS/IEEE Conference Proceedings. The Coastal Ocean - Prospects for the 21st Century,6-Aug-02,1996,1,,65,71 vol.1,"Availability of trained pilots is key to many military and commercial remotely operated vehicle (ROV) missions. Due to the expense and logistics involved with operating actual systems, training and practice is: often difficult to obtain in other than an ""on the job"" fashion. To remedy this situation, a virtual environment (VE) based system is being developed for the training of ROV piloting skills. Analysis of typical missions such as mine countermeasures and search/salvage yielded a set of general skills to be taught including manoeuvring, situational awareness, sensor data integration, and mission operations. Use of VE technology permits the creation of an enriched learning environment including simulation of a wide range of operational environments, vehicle configurations, learning aids, rind mission scenarios. The prototype training system is a VE-based Intelligent Tutor which implements various training aids and interventions to promote the development of both the sensorimotor and cognitive skills related to basic manoeuvring tasks and situational awareness. Once implemented, the training effectiveness of this prototype will be studied by analyzing pilot performance on an actual ROV.",,0-7803-3519-8,10.1109/OCEANS.1996.572546,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=572546,,Virtual environment;Remotely operated vehicles;Intelligent sensors;Management training;Prototypes;Remote sensing;Humans;Logistics;On the job training;Performance analysis,mobile robots;computer based training;computer aided instruction;virtual reality;intelligent tutoring systems,virtual environment based training;ROV pilots;remotely operated vehicle;trained pilots;virtual environment;ROV piloting skills;mine countermeasures;search/salvage;cognitive skills;training aids;Intelligent Tutor;manoeuvring tasks;situational awareness,,2,,,,6-Aug-02,,,IEEE,IEEE Conferences
Inducing Compensatory Changes in Gait Similar to External Perturbations Using an Immersive Head Mounted Display,L. Riem; J. Van Dehy; T. Onushko; S. Beardsley,"Marquette University, Department of Biomedical Engineering, Milwaukee, Wisconsin; Marquette University, Department of Biomedical Engineering, Milwaukee, Wisconsin; Marquette University, Department of Biomedical Engineering, Milwaukee, Wisconsin; Marquette University, Department of Biomedical Engineering, Milwaukee, Wisconsin",2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),30-Aug-18,2018,,,128,135,"Understanding the sensorimotor control mechanisms that mediate gait compensation during environmental perturbation is a crucial step in developing tailored rehabilitative therapies to restore ambulation in patient populations. Current methods to evaluate the effects of environmental perturbations involve costly systems that physically perturb patients to elicit a compensatory response. Studies have shown that visual feedback alone can elicit dramatic changes in gait; however, the impact of fully immersive visual feedback is not well studied. Here we examined whether a low cost immersive virtual reality (VR) system can elicit perturbation responses similar to a physical disruption. We examined the responses of 11 subjects as they walked through a VR environment consisting of a bridge spanning a lake. While subjects walked on a treadmill mounted to a 6 degree-of-freedom motion base, pseudorandom roll perturbations (3, 6, 11 deg.) were applied visually to the bridge with (VP trials) and without (V trials) the corresponding physical displacement of the motion base. Significant differences were found between normal (unperturbed) walking and normal walking in the VR environment (p<;.05) for average step length, width, and Margin of Stability (MoS). Significant differences were also observed between unperturbed and perturbed walking in the VR environment (p<;0.05 for VP and V trials). While the subjects' responses to visual perturbations were generally lower than to combined visual and physical perturbations, the differences were not statistically significant (p>.05). The results demonstrate that visual perturbations provided in an immersive virtual environment can induce compensatory changes in gait during treadmill walking that are consistent with a physical perturbation. The application of environmental perturbations in VR systems could provide a cost-effective approach for gait rehabilitation in patient populations.",,978-1-5386-3365-6,10.1109/VR.2018.8446432,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446432,Virtual Reality;Head Mounted Display;Visualization.: H.5.1 [Multimedia Information Systems]: Artificial;augmented;and virtual realities,Perturbation methods;Visualization;Legged locomotion;Virtual environments;Bridges;Sociology;Statistics,biomechanics;gait analysis;helmet mounted displays;patient rehabilitation;patient treatment;virtual reality,external perturbations;immersive head mounted display;sensorimotor control mechanisms;mediate gait compensation;environmental perturbation;patient populations;perturbation responses;physical disruption;VR environment;pseudorandom roll perturbations;unperturbed walking;physical perturbations;immersive virtual environment;treadmill walking;physical perturbation;VR systems;gait rehabilitation;immersive virtual reality system;physical displacement;visual perturbations;gait compensatory changes;immersive visual feedback;6 degree-of-freedom motion base perturbations;VP trials,,1,,30,,30-Aug-18,,,IEEE,IEEE Conferences
VIVR: Presence of Immersive Interaction for Visual Impairment Virtual Reality,J. Kim,"Division of Computer Engineering, Hansung University, Seoul, South Korea",IEEE Access,6-Nov-20,2020,8,,196151,196159,"The immersive virtual reality (VR) to provide a realistic walking experience for the visually impaired is proposed in this study. To achieve this, a novel immersive interaction using a walking aid, i.e., a white cane, is designed. The key structure of the proposed interaction consists of a walking process that enables users with visual impairments to process the ground recognition and inference processes realistically by connecting the white cane to the VR controller. Additionally, a decision-making model using deep learning is proposed to design interactions that can be applied to real-life situations instead of being limited to virtual environment experiences. A learning model is designed that can accurately and efficiently process sensing of braille block, which is an important process in the walking of visually impaired people using a white cane assistance tool. The goal is to implement a white cane walking system that can be used in the real world in addition to a virtual environment. Finally, a survey is conducted to confirm that the proposed immersive interaction provides a walking experience with high presence in virtual reality when compared with the real-world experience. The applicability of the proposed deep-learning-based decision-making model in the real world is verified by its high accuracy in recognition of braille block.",2169-3536,,10.1109/ACCESS.2020.3034363,Hansung University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9241733,Immersive virtual reality;presence;immersive interaction;visual impairment;deep learning,Legged locomotion;Visualization;Haptic interfaces;Solid modeling;Virtual environments;Deep learning,decision making;gait analysis;handicapped aids;learning (artificial intelligence);neural nets;virtual reality,realistic walking experience;immersive interaction;walking aid;walking process;ground recognition;inference processes;VR controller;decision-making;deep learning;virtual environment experiences;braille block;visually impaired people;white cane assistance tool;white cane walking system;real-world experience;visual impairment virtual reality;immersive virtual reality;VIVR,,,,34,CCBY,28-Oct-20,,,IEEE,IEEE Journals
Polyvalent display framework to control virtual navigations by 6DOF tracking,P. Bourdot; D. Touraine,"Lab. d'Informatique pour la Mecanique et les Sci. de l'Ingenieur, CNRS, Orsay, France; NA",Proceedings IEEE Virtual Reality 2002,7-Aug-02,2002,,,277,278,"Many applications using Virtual Reality (VR) require free hand navigation control. This forbids the use of devices such as Joystick, 3D mouse, ... That is generally because hand-based gesture interaction must be dedicated to specific tasks: sculpting or grasping the objects, which compose a virtual scene. With this aim, we present a polyvalent display approach, which allows the system to determine the desired focus and the moving intention of the user for virtual navigations. After we point out the limits of the classical solutions used to control virtual navigations, we describe the conceptual and mathematical implementation of our approach. Some of our considerations depend on physiological and ergonomic constraints. We conclude on the first applications of our fully head tracking navigation controller.",1087-8270,0-7695-1492-8,10.1109/VR.2002.996537,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=996537,,Displays;Virtual reality;Layout;Aircraft navigation;Mice;Equations;Grasping;Taxonomy;Virtual environment;Keyboards,virtual reality;navigation;tracking,Virtual Reality;free hand navigation control;gesture interaction;polyvalent display;virtual scene;head tracking;virtual environments,,8,,8,,7-Aug-02,,,IEEE,IEEE Conferences
Development of Eye-Gaze Interface System and Its Application to Virtual Reality Controller,H. F. Putra; K. Ogata,"Graduate School of Science and Technology (GSST), Kumamoto University, Kumamoto, Japan; Graduate School of Science and Technology (GSST), Kumamoto University, Kumamoto, Japan","2018 International Conference on Computer Engineering, Network and Intelligent Multimedia (CENIM)",13-May-19,2018,,,208,213,"Eye-gaze tracking systems are a type of human-machine interface application. These systems have been widely applied in many fields, such as medical, interface systems, and studies on human behavior. In this study, an eye-gaze tracking system is designed to control the view of a virtual reality application. As is generally known, gyroscopes and game controllers are popular devices to control the view of virtual reality applications. To control the view of a virtual reality application, we measure the vertical and horizontal movements of the eye-gaze. Using ring-shaped pattern matching, we find the position of the iris and estimate the direction of the eye-gaze. The vertical and horizontal movement of the eye-gaze are transformed into the rotation of virtual reality camera view in the x and y axes, respectively. The ease of use of the system was evaluated in terms of the distance traveled by the user and the time taken to complete the task.",,978-1-5386-7509-0,10.1109/CENIM.2018.8710926,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8710926,eye-gaze;tracking;interface;virtual reality,Virtual reality;Cameras;Iris;Image color analysis;Games;Pattern matching;Lenses,cameras;computer vision;eye;gaze tracking;human computer interaction;user interfaces;virtual reality,horizontal movement;vertical movement;virtual reality camera view;eye-gaze interface system;virtual reality controller;eye-gaze tracking system;human-machine interface application;interface systems;virtual reality application;game controllers,,1,,10,,13-May-19,,,IEEE,IEEE Conferences
Genesys: A Virtual Reality scene builder,J. D. O. De Leon; R. P. Tavas; R. A. Aranzanso; R. O. Atienza,"Ubiquitous Computing Laboratory, Electrical and Electronics Engineering Institute, University of the Philippines Diliman, Quezon City, Philippines; Ubiquitous Computing Laboratory, Electrical and Electronics Engineering Institute, University of the Philippines Diliman, Quezon City, Philippines; Ubiquitous Computing Laboratory, Electrical and Electronics Engineering Institute, University of the Philippines Diliman, Quezon City, Philippines; Ubiquitous Computing Laboratory, Electrical and Electronics Engineering Institute, University of the Philippines Diliman, Quezon City, Philippines",2016 IEEE Region 10 Conference (TENCON),9-Feb-17,2016,,,3708,3711,"Virtual Reality (VR) is a computer technology which simulates real world environments and a user's interactions within it. Current trends in VR, however, are focused on the gaming industry with limited work on VR creation tools. Thus, we propose a VR application that allows users to create 3-dimensional scenes in virtual reality named Genesys. Scenes created are viewed with the use of VR head mounted displays which provide the user with a more immersive work environment compared to traditional 2D monitors. Interactions within this workspace are done through motion controllers that allow users to manipulate with objects and spawn more from an online repository. Scenes created can be shared to the Genesys community of artists, creators and users through an online website. This feature widens the project's applications in education, business, and entertainment as a world builder and presentation tool. To measure the effectiveness of the application, a scene composition test was conducted at the end of the experiment. The results showed that Genesys is generally easy to use for people with limited experience in VR. However, improvements can still be made on the object manipulation controls such as rotation and scaling.",2159-3450,978-1-5090-2597-8,10.1109/TENCON.2016.7848751,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7848751,,Virtual reality;Games;Three-dimensional displays;Engines;Industries;Google;Software,helmet mounted displays;human computer interaction;user interfaces;virtual reality,Genesys;virtual reality scene builder;computer technology;VR creation tools;user interactions;gaming industry;three-dimensional scenes;VR head mounted displays;immersive work environment;motion controllers;online Web site;scene composition test;object manipulation controls,,1,,17,,9-Feb-17,,,IEEE,IEEE Conferences
Continuous automatic calibration for optical see-through displays,K. R. Moser; Y. Itoh; J. E. Swan,Mississippi State University; Technical University of Munich; Mississippi State University,2015 IEEE Virtual Reality (VR),27-Aug-15,2015,,,241,242,"The current advent of consumer level optical see-through (OST) head-mounted displays (HMD's) has greatly broadened the accessibility of Augmented Reality (AR) to not only researchers but also the general public as well. This increased user base heightens the need for robust automatic calibration mechanisms suited for nontechnical users. We are developing a fully automated calibration system for two stereo OST HMD's, a consumer level and prototype model, based on the recently introduced interaction free display calibration (INDICA) method. Our current efforts are also focused on the development of an evaluation process to assess the performance of the system during use by non-expert subjects.",2375-5334,978-1-4799-1727-3,10.1109/VR.2015.7223385,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223385,Calibration;OST HMD;Augmented Reality,Calibration;Cameras;Hardware;Augmented reality;Robustness;Prototypes;Head,augmented reality;helmet mounted displays,continuous automatic calibration system;consumer level optical see-through head-mounted displays;augmented reality;robust automatic calibration mechanisms;interaction free display calibration method;INDICA method,,1,,6,,27-Aug-15,,,IEEE,IEEE Conferences
"A Physiology-Based QoE Comparison of Interactive Augmented Reality, Virtual Reality and Tablet-Based Applications",C. Keighrey; R. Flynn; S. Murray; N. Murray,"Athlone Institute of Technology, Athlone, Ireland; Athlone Institute of Technology, Athlone, Ireland; Health Service Executive, Primary Care Centre, Longford, Ireland; Athlone Institute of Technology, Athlone, Ireland",IEEE Transactions on Multimedia,17-Dec-20,2021,23,,333,341,"The availability of affordable head-mounted display technology has facilitated new, potentially more immersive, interactive multimedia experiences. These technologies were traditionally focused on entertainment; however, academia and industry are now exploring applications in other domains such as health, learning and training. Key to the success of these new multimedia experiences is the understanding of a user's perceived quality of experience (QoE). Subjective user ratings have been the primary mechanism to capture insights into a user's experience. Such ratings have generally been captured post experience and reflected using a mean opinion score (MOS). However, user perception is multifactorial and subjective ratings alone do not express the true measure of an experience. As a result, recent efforts to capture QoE have included exploring the use of implicit metrics (e.g., physiological measures). This article presents the results of an experimental QoE evaluation and comparison of immersive applications delivered across three multimedia platforms. The platforms compared were augmented reality, tablet and virtual reality. The QoE methodology employed considered explicit (post-test questionnaire) and implicit (heart rate and electrodermal activity) assessment methods. The results indicate comparatively higher levels of QoE for users of the augmented reality and tablet platforms.",1941-0077,,10.1109/TMM.2020.2982046,Irish Research Council - Government of Ireland Postgraduate Scholarship; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9042281,Quality of experience;augmented reality;virtual reality;physiological;speech language pathology;aphasia,Quality of experience;Semantics;Multimedia systems;Augmented reality;Biomedical monitoring,augmented reality;helmet mounted displays;human computer interaction;mobile computing;multimedia systems;quality of experience;user interfaces,user experience;perceived quality of experience;tablet based applications;physiology based QoE comparison;physiological measures;mean opinion score;interactive multimedia experiences;immersive multimedia experiences;head mounted display;virtual reality;interactive augmented reality,,7,,35,IEEE,19-Mar-20,,,IEEE,IEEE Journals
A novel menu interaction method using head-mounted display for smartphone-based virtual reality,C. Sheng; L. Jiang; B. Tang; X. Tang,"College of Electronic Science and Engineering, NUDT, Changsha 410073, China; College of Electronic Science and Engineering, NUDT, Changsha 410073, China; College of Electronic Science and Engineering, NUDT, Changsha 410073, China; College of Electronic Science and Engineering, NUDT, Changsha 410073, China",2017 Progress In Electromagnetics Research Symposium - Spring (PIERS),18-Jan-18,2017,,,2384,2388,"The menu interaction design method for smartphone-based VR is currently one of the most popular research domains. The existing menu interaction method can be generally divided into two categories: the interaction devices based method and ray selection based method. However, both of them have some inevitable defects, which lead to bad user experience. In this paper, a novel interaction method is proposed, combining the advantages of the ray selection technology and HMD technology. And a smartphone-based VR application demonstration named ‚ÄúTarget Arena‚Äù is developed. In addition, the user experience is evaluated by conducting a survey on several aspects of the demonstration system such as portability, controllability, comfort degree, and overall user experience. Experimental results show that the menu interaction method proposed in the paper performs better than other existing methods.",,978-1-5090-6269-0,10.1109/PIERS.2017.8262151,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8262151,,Resists;Games;Virtual environments;Head;Smart phones;Electromagnetics;Springs,helmet mounted displays;interactive devices;smart phones;user interfaces;virtual reality,head-mounted display;smartphone-based virtual reality;menu interaction design method;existing menu interaction method;interaction devices;ray selection based method;ray selection technology;smartphone-based VR application demonstration,,,,4,,18-Jan-18,,,IEEE,IEEE Conferences
Towards a linguistically motivated model for selection in virtual reality,T. Pfeiffer,"A.I. Group, Faculty of Technology, Bielefeld University",2012 IEEE Virtual Reality Workshops (VRW),12-Apr-12,2012,,,89,90,"Swiftness and robustness of natural communication is tied to the redundancy and complementarity found in our multimodal communication. Swiftness and robustness of human-computer interaction (HCI) is also a key to the success of a virtual reality (VR) environment. The interpretation of multimodal interaction signals has therefore been considered a high goal in VR research, e.g. following the visions of Bolt's put-that-there in 1980 [1]. It is our impression that research on user interfaces for VR systems has been focused primarily on finding and evaluating technical solutions and thus followed a technology-oriented approach to HCI. In this article, we argue to complement this by a human-oriented approach based on the observation of human-human interaction. The aim is to find models of human-human interaction that can be used to create user interfaces that feel natural. As the field of Linguistics is dedicated to the observation and modeling of human-human communication, it could be worthwhile to approach natural user interfaces from a linguistic perspective. We expect at least two benefits from following this approach. First, the human-oriented approach substantiates our understanding of natural human interactions. Second, it brings about a new perspective by taking the interaction capabilities of a human addressee into account, which are not often explicitly considered or compared with that of the system. As a consequence of following both approaches to create user interfaces, we expect more general models of human interaction to emerge.",2375-5334,978-1-4673-1246-2,10.1109/VR.2012.6180896,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180896,H.5.2 [Information Interfaces and Presentation]: User Interfaces ‚Äî Natural Language;I.3.6 [Computer Graphics]: Methodology and Techniques ‚Äî Interaction Techniques;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems ‚Äî Artificial;Augmented and Virtual Realities,Pragmatics;Humans;Virtual reality;Human computer interaction;Solid modeling;Context,human computer interaction;user interfaces;virtual reality,linguistically motivated model;virtual reality environment;natural communication;multimodal communication;human-computer interaction;HCI;multimodal interaction signals;VR research;Bolt put-that-there;technology-oriented approach;human-oriented approach;human-human interaction;human-human communication;natural user interfaces;human addressee,,1,,13,,12-Apr-12,,,IEEE,IEEE Conferences
Research and Application of Access Control Technique in 3D Virtual Reality System OpenSim,Y. Wei; Y. Lu; X. Hu; B. Sun,"Coll. of Inf. Sci. & Technol., Beijing Normal Univ., Beijing, China; Coll. of Inf. Sci. & Technol., Beijing Normal Univ., Beijing, China; Coll. of Inf. Sci. & Technol., Beijing Normal Univ., Beijing, China; Coll. of Inf. Sci. & Technol., Beijing Normal Univ., Beijing, China",2013 Sixth International Symposium on Computational Intelligence and Design,24-Apr-14,2013,2,,65,68,"Access control in 3-D virtual reality systems is a wide and still growing topic. A good access control model is a premise for data security, and makes the whole system play its functions reliably. We compare access control techniques in 3D system OpenSim with that of other virtual reality systems. By using a general extended scheme, we analyze the model and the rule of access control in OpenSim. In this scheme, we provide a method of expanding network services for special proposes. Meanwhile, it verifies the feasibility of developing OpenSim's services on the basis of data security.",,978-0-7695-5079-4,10.1109/ISCID.2013.130,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6804829,Access Control;Capability;Virtual Reality;OpenSim,Access control;Servers;Virtual reality;Three-dimensional displays;Animation;Solid modeling,authorisation;human computer interaction;public domain software;virtual reality,access control technique;3D virtual reality system;OpenSim;data security;system functions;general extended scheme;network service expansion,,,,13,,24-Apr-14,,,IEEE,IEEE Conferences
Brain Activity in Virtual Reality: Assessing Signal Quality of High-Resolution EEG While Using Head-Mounted Displays,S. Hertweck; D. Weber; H. Alwanni; F. Unruh; M. Fischbach; M. E. Latoschik; T. Ball,"Translational Neurotechnology Lab, University Medical Center Freiburg; Translational Neurotechnology Lab, University Medical Center Freiburg; Translational Neurotechnology Lab, University Medical Center Freiburg; Human-Computer Interaction Lab, University of Wuerzburg; Human-Computer Interaction Lab, University of Wuerzburg; Human-Computer Interaction Lab, University of Wuerzburg; Translational Neurotechnology Lab, University Medical Center Freiburg",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,970,971,"Biometric measures such as the electroencephalogram (EEG) promise to become viable alternatives to subjective questionnaire ratings for the evaluation of psychophysical effects associated with Virtual Reality (VR) systems, as they provide objective and continuous measurements without breaking the exposure. The extent to which the EEG signal can be disturbed by the presence of VR systems, however, has been barely investigated. This study outlines how to evaluate the compatibility of a given EEG-VR setup on the example of two commercial head-mounted displays (HMDs), the Oculus Rift and the HTC Vive Pro. We use a novel experimental protocol to compare the spectral composition between conditions with and without an HMD present during an eyes-open vs. eyes-closed task. We found general artifacts at the line hum of 50 Hz, and additional HMD refresh rate artifacts (90 Hz) for the Oculus rift exclusively. Frequency components typically most interesting to non-invasive EEG research and applications , however, remained largely unaffected. We observed similar topographies of visually-induced modulation of alpha band power for both HMD conditions in all subjects. Hence, the study introduces a necessary validation test for HMDs in combination with EEG and further promotes EEG as a potential biometric measurement method for psychophysical effects in VR systems.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8798369,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798369,,Electroencephalography;Frequency measurement;Resists;Electrodes;Virtual reality;Task analysis;Physiology,electroencephalography;helmet mounted displays;medical signal processing;neurophysiology;virtual reality,signal quality;addHMD refresh rate artifacts;biometric measurement method;EEG-VR setup;head-mounted displays;HTC Vive Pro;Oculus Rift;EEG signal;Virtual Reality systems;electroencephalogram;high-resolution EEG;brain activity;spectral composition;frequency 50.0 Hz;frequency 90.0 Hz,,1,,9,,15-Aug-19,,,IEEE,IEEE Conferences
Using relative head and hand-target features to predict intention in 3D moving-target selection,J. S. Casallas; J. H. Oliver; J. W. Kelly; F. Merienne; S. Garbaya,"Iowa State University Arts et Metiers ParisTech; Virtual Reality Applications Center, Iowa State University; Department of Psychology, Iowa State University; Institut Image Arts et M√©tiers ParisTech; Institut Image Arts et M√©tiers ParisTech",2014 IEEE Virtual Reality (VR),24-Apr-14,2014,,,51,56,"Selection of moving targets is a common, yet complex task in human-computer interaction (HCI) and virtual reality (VR). Predicting user intention may be beneficial to address the challenges inherent in interaction techniques for moving-target selection. This article extends previous models by integrating relative head-target and hand-target features to predict intended moving targets. The features are calculated in a time window ending at roughly two-thirds of the total target selection time and evaluated using decision trees. With two targets, this model is able to predict user choice with up to ~ 72% accuracy on general moving-target selection tasks and up to ~ 78% by also including task-related target properties.",2375-5334,978-1-4799-2871-2,10.1109/VR.2014.6802050,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802050,"H.5.2 [Information interfaces and presentation]: User Interfaces ‚Äî Interaction Styles, Theory and methods;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism ‚Äî Virtual Reality;I.5.4 [Pattern Recognition]: Applications",Accuracy;Predictive models;Decision trees;Three-dimensional displays;Solid modeling;Virtual reality;Human computer interaction,decision trees;human computer interaction;virtual reality,3D moving-target selection;human-computer interaction;HCI;virtual reality;VR;user intention prediction;decision trees;user choice prediction;task-related target properties;relative hand-target features;relative head-target features,,,,42,,24-Apr-14,,,IEEE,IEEE Conferences
Ginput: a tool for fast hi-fi prototyping of gestural interactions in virtual reality,J. R. Fonseca; J. Abreu; L. Figueredo; J. G. Neto; V. Teichrieb; J. P. Quintino; F. Q. B. da Silva; A. L. M. Santos; H. Pinho,"Universidade Federal de,Voxar Labs / CIn,Pernambuco; Universidade Federal de,Voxar Labs / CIn,Pernambuco; Universidade Federal de,Voxar Labs / CIn,Pernambuco; Universidade Federal de,Voxar Labs / CIn,Pernambuco; Universidade Federal de,Voxar Labs / CIn,Pernambuco; Universide Federal de,Projeto CIn-Samsung,Pernambuco; CIn / Universidade Federal de,Pernambuco; CIn / Universidade Federal de,Pernambuco; Desenvolvimento para a Inform√°tica,Samsung Instituto de",2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),16-Dec-20,2020,,,63,64,"Gestural interfaces in virtual reality (VR) expand the design space for user interaction, allowing spatial metaphors with the environment and more natural and immersive experiences. Typically, machine learning approaches recognize gestures with models that rely on a large number of samples for the training phase, which is an obstacle for rapidly prototyping gestural interactions. In this paper, we propose a solution designed for hi-fi prototyping of gestures within a virtual reality environment through a high-level Domain-Specific Language (DSL), as a subset of the natural language. The proposed DSL allows non-programmer users to intuitively describe a broad domain of poses and connect them for compound gestures. Our DSL was designed to be general enough for multiple input classes, such as body tracking, hand tracking, head movement, motion controllers, and buttons. We tested our solution for wands with VR designers and developers. Results showed that the tool gives non-programmers the ability to prototype gestures with ease and refine its recognition within a few minutes.",,978-1-7281-7675-8,10.1109/ISMAR-Adjunct51615.2020.00030,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288432,Human-centered computing;Visualization;Visualization techniques;Treemaps; Human-centered computing;Visualization;Visualization design and evaluation methods,Training;Solid modeling;Tracking;Natural languages;Tools;DSL;Task analysis,gesture recognition;high level languages;human computer interaction;learning (artificial intelligence);motion control;object tracking;software prototyping;virtual reality,gestural interfaces;design space;user interaction;spatial metaphors;immersive experiences;machine learning;virtual reality environment;high-level domain-specific language;DSL;natural language;nonprogrammer users;compound gestures;prototype gestures;fast hi-fi prototyping;natural experience;gesture recognition;gestural interaction rapid prototyping;body tracking;hand tracking;head movement;motion controllers;buttons;Ginput,,,,7,,16-Dec-20,,,IEEE,IEEE Conferences
Progressive feedback point cloud rendering for virtual reality display,R. Tredinnick; M. Broecker; K. Ponto,Wisconsin Institute for Discovery - University of Wisconsin-Madison; Wisconsin Institute for Discovery - University of Wisconsin-Madison; Wisconsin Institute for Discovery - University of Wisconsin-Madison,2016 IEEE Virtual Reality (VR),7-Jul-16,2016,,,301,302,"Previous approaches to rendering large point clouds on immersive displays have generally created a trade-off between interactivity and quality. While these approaches have been quite successful for desktop environments when interaction is limited, virtual reality systems are continuously interactive, which forces users to suffer through either low frame rates or low image quality. This paper presents a novel approach to this problem through a progressive feedback-driven rendering algorithm. This algorithm uses reprojections of past views to accelerate the reconstruction of the current view. The presented method is tested against previous methods, showing improvements in both rendering quality and interactivity.",2375-5334,978-1-5090-0836-0,10.1109/VR.2016.7504773,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504773,Point-based graphics;virtual reality;3D scanning,Rendering (computer graphics);Three-dimensional displays;Graphics processing units;Measurement;Virtual reality;Feedback loop;Geometry,rendering (computer graphics);virtual reality,progressive feedback point cloud rendering;virtual reality display;immersive displays;interactivity;desktop environments;virtual reality systems;progressive feedback-driven rendering algorithm,,6,,3,,7-Jul-16,,,IEEE,IEEE Conferences
Work-in-Progress‚ÄîA Generalizable Virtual Reality Training and Intelligent Tutor for Additive Manufacturing,M. Mogessie; S. D. Wolf; M. Barbosa; N. Jones; B. M. McLaren,"Carnegie Mellon University,Human-Computer Interaction Institute,Pittsburgh,PA,United States; Carnegie Mellon University,NextManufacturing Center,Pittsburgh,PA,United States; Carnegie Mellon University,Human-Computer Interaction Institute,Pittsburgh,PA,United States; Carnegie Mellon University,NextManufacturing Center,Pittsburgh,PA,United States; Carnegie Mellon University,Human-Computer Interaction Institute,Pittsburgh,PA,United States",2020 6th International Conference of the Immersive Learning Research Network (iLRN),4-Aug-20,2020,,,355,358,"There is currently significant demand for training in how to use metals additive manufacturing (AM) machines. Such training is important not only for the technicians who run and maintain the machines, but also for engineers and strategic decision makers who need to support AM part fabrication. Furthermore, there are a variety of AM machines, each with different details to be learned and potential hazards to overcome, and it is difficult to train more than a handful of users at one time. To address these challenges, a prototype training system has been developed, the AM Training Tutor, which uses interactive virtual reality (VR) to train users on a specific AM machine - the EOS M290. To make the training technology more widely available and expand its use across a variety of different AM machines, efforts are underway to develop a modularized and generic version of the AM Training Tutor that can be customized with relatively little effort to train users to operate other AM machines. This work-in-progress paper details the progress to-date, challenges and proposed solutions with the aim to demonstrate how standalone VR-based training systems can be redesigned for relatively easy repurposing and generalization.",,978-1-7348995-0-4,10.23919/iLRN47897.2020.9155119,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155119,generalized VR;VR-based training;workforce training;cognitive tutor;advanced manufacturing;additive manufacturing;3D printing,Training;Tutorials;Three-dimensional printing;Three-dimensional displays;Solid modeling;Earth Observing System,computer based training;decision making;human computer interaction;intelligent tutoring systems;interactive systems;production engineering computing;rapid prototyping (industrial);virtual reality,intelligent tutor;strategic decision makers;AM machines;prototype training system;AM Training Tutor;interactive virtual reality;specific AM machine;training technology;standalone VR-based training systems;generalizable virtual reality training;metals additive manufacturing machines;EOS M290,,,,17,,4-Aug-20,,,IEEE,IEEE Conferences
Redirected Walking in Irregularly Shaped Physical Environments with Dynamic Obstacles,H. Chen; S. Chen; E. S. Rosenberg,"USC Institute for Creative Technologies, Los Angeles, CA; USC Institute for Creative Technologies, Los Angeles, CA; USC Institute for Creative Technologies, Los Angeles, CA",2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),30-Aug-18,2018,,,523,524,"Redirected walking (RDW) is a virtual reality (VR) locomotion technique that enables the exploration of a large virtual environment (VE) within a small physical space via real walking. Thus far, the physical environment has generally been assumed to be rectangular, static, and free of obstacles. However, it is unlikely that real-world locations that may be used for VR fulfill these constraints. In addition, accounting for dynamic obstacles such as people helps increase user safety when the view of the physical world is occluded by a head-mounted display. In this work, we present the design and initial implementation of a RDW planning algorithm that can redirect the user in an irregularly shaped physical environment with dynamically moving obstacles. This represents an important step towards the use of RDW in more dynamic, real-world environments.",,978-1-5386-3365-6,10.1109/VR.2018.8446563,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446563,H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems-Artificial;augmented;and virtual realities;I.3.6 [Computer Graphics]: Methodology and Techniques-Interaction techniques;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Virtual reality,Heuristic algorithms;Legged locomotion;Planning;Prediction algorithms;Safety;Virtual environments,collision avoidance;helmet mounted displays;user interfaces;virtual reality,irregularly shaped physical environment;real-world environments;dynamic obstacles;redirected walking;virtual reality locomotion technique;virtual environment;physical space;physical world;RDW planning algorithm;user safety;head-mounted display,,2,,4,,30-Aug-18,,,IEEE,IEEE Conferences
Enhancing the Stiffness Perception of Tangible Objects in Mixed Reality Using Wearable Haptics,X. de Tinguy; C. Pacchierotti; M. Marchal; A. L√©cuyer,"Inria CNRS IRISA, Univ Rennes INSA, Rennes, France; Inria CNRS IRISA, Univ Rennes INSA, Rennes, France; Inria CNRS IRISA, Univ Rennes INSA, Rennes, France; Inria CNRS IRISA, Univ Rennes INSA, Rennes, France",2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),30-Aug-18,2018,,,81,90,"This paper studies the combination of tangible objects and wearable haptics for improving the display of stiffness sensations in virtual environments. Tangible objects enable to feel the general shape of objects, but they are often passive or unable to simulate several varying mechanical properties. Wearable haptic devices are portable and unobtrusive interfaces able to generate varying tactile sensations, but they often fail at providing convincing stiff contacts and distributed shape sensations. We propose to combine these two approaches in virtual and augmented reality (VR/AR), becoming able of arbitrarily augmenting the perceived stiffness of real/tangible objects by providing timely tactile stimuli at the fingers. We developed a proof-of-concept enabling to simulate varying elasticity/stiffness sensations when interacting with tangible objects by using wearable tactile modules at the fingertips. We carried out a user study showing that wearable haptic stimulation can well alter the perceived stiffness of real objects, even when the tactile stimuli are not delivered at the contact point. We illustrated our approach both in VR and AR, within several use cases and different tangible settings, such as when touching surfaces, pressing buttons and pistons, or holding an object. Taken together, our results pave the way for novel haptic sensations in VR/AR by better exploiting the multiple ways of providing simple, unobtrusive, and low-cost haptic displays.",,978-1-5386-3365-6,10.1109/VR.2018.8446280,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446280,Human-centered computing-Human computer interaction-Interaction devices-Haptic devices,Haptic interfaces;Skin;Shape;Belts;Virtual environments;Mechanical factors;Augmented reality,augmented reality;elasticity;haptic interfaces,virtual reality;augmented reality;elasticity sensations;stiff contacts;mixed reality;distributed shape sensations;tactile sensations;wearable haptic devices;stiffness perception;low-cost haptic displays;wearable haptic stimulation;wearable tactile modules,,5,,32,,30-Aug-18,,,IEEE,IEEE Conferences
Web Assisted Online Children's Rural Intelligent Travel Framework based on Virtual Cloud Computing and VR,J. Zhang,"Chongqing University of Education,School of Tourism Service and Management,Chongqing,China,400065",2020 Fourth International Conference on Computing Methodologies and Communication (ICCMC),23-Apr-20,2020,,,395,398,"Web assisted online Children's rural intelligent travel framework based on virtual cloud computing and VR is designed in this manuscript. Virtual reality technology refers to the computer, sensor technology, artificial intelligence, multimedia and some other technologies combined to generate general human-computer interaction technology. Based on this technology, this paper proposes the novel rural intelligent travel framework. The green mountains and rivers in the countryside make urban residents yearn endlessly. The data mining, VR and the intelligent system are combined for the systematic design. The experimental results have proven the effectiveness.",,978-1-7281-4889-2,10.1109/ICCMC48092.2020.ICCMC-00074,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9076490,Web system;rural intelligent;virtual computing;cloud computing;VR technology,,cloud computing;data mining;human computer interaction;town and country planning;travel industry;virtual reality,virtual cloud computing;virtual reality technology;artificial intelligence;human-computer interaction technology;Web assisted online children rural intelligent travel framework;data mining;intelligent system;VR technology,,,,21,,23-Apr-20,,,IEEE,IEEE Conferences
Visual Data Mining by Virtual Reality for Protein-Protein Interaction Networks,N. Aouaa; R. Gherbi; A. Meziane; H. Hadjar; I. Setitra,"CERIST, Research Centre For Scientific And Technical Information, Algiers, Algeria, Universit√© Abderrahmane Mira B√©jaia - Rue Targa Ouzemour B√©jaia, Algeria; Paris-Sud XI University, Orsay, France; CERIST, Research Centre For Scientific And Technical Information, Algiers, Algeria; CERIST, Research Centre For Scientific And Technical Information, Algiers, Algeria; CERIST, Research Centre For Scientific And Technical Information, Algiers, Algeria",2018 IEEE/ACS 15th International Conference on Computer Systems and Applications (AICCSA),17-Jan-19,2018,,,1,8,"Currently, visualization techniques in the genetic field require a very important modeling phase in terms of resources. 2D based projections of traditional visualization techniques are rarely adapted to manage and process such huge mass of information. To overcome such limitation, we propose to use a new graph modeling technique. This, when used in conjunction with virtual reality technology, allows biologists to have a wide visibility and fluent exploration through several points of view and user interaction, thus enabling what we can call visual data mining of big scientific data. The general principle of our approach is to build a biological network model in the form of a graph with a spatial representation adapted to the visualization of biological networks in a virtual environment. The results show that the improvement of the node distribution algorithm allows a better and more intuitive visualization, compared to the equivalent two-dimensional visualization.",2161-5330,978-1-5386-9120-5,10.1109/AICCSA.2018.8612849,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8612849,virtual reality;visual data mining;big scientific data;protein interaction networks;user interaction,Proteins;Data visualization;Solid modeling;Virtual reality;Visualization;Biological system modeling,biology computing;data mining;data visualisation;distributed algorithms;graph theory;network theory (graphs);proteins;virtual reality,node distribution algorithm;two-dimensional visualization;virtual environment;biological network model;big scientific data;user interaction;virtual reality technology;graph modeling technique;2D based projections;genetic field;protein-protein interaction networks;visual data mining,,1,,21,,17-Jan-19,,,IEEE,IEEE Conferences
BlenderVR: Open-source framework for interactive and immersive VR,B. F. G. Katz; D. Q. Felinto; D. Touraine; D. Poirier-Quinot; P. Bourdot,"LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France; LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France; LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France; LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France; LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France",2015 IEEE Virtual Reality (VR),27-Aug-15,2015,,,203,204,"BlenderVR is an open-source project framework for interactive and immersive applications based on an extension of the Blender Game Engine to Virtual Reality applications. BlenderVR is a generalization of the BlenderCAVE project, accounting for alternate platforms (e.g., HMD, video-walls). The goal is to provide a flexible and easy to use framework for the creation of VR applications for various platforms, making use of the existing power of the BGE's graphics rendering and physics engine. Compatible with 3 major Operating Systems, BlenderVR has been developed by VR researchers with support from the Blender Community. BlenderVR currently handles multi-screen/multi-user tracked stereoscopic rendering through efficient low-level master/slave synchronization process with multimodal interactions via OSC and VRPN protocols.",2375-5334,978-1-4799-1727-3,10.1109/VR.2015.7223366,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223366,"H.5.1 [Multimedia Information Systems]: Artificial, augmented, and virtual realities;I.3.2 [Graphics Systems]: Distributed/network graphics",Rendering (computer graphics);Synchronization;Virtual reality;Engines;Games;Navigation,protocols;public domain software;rendering (computer graphics);synchronisation;virtual reality,BlenderVR;virtual reality;open-source framework;interactive application;immersive application;Blender game engine;graphics rendering;physics engine;synchronization process;OSC protocol;VRPN protocol,,5,,8,,27-Aug-15,,,IEEE,IEEE Conferences
[DC] Case-studies of Contemporary Presence Theory: Towards More Objective and Reliable Measures of Presence,J. Schirm,"Sheffield Hallam University, Reutlingen University",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,1363,1364,"A large body of literature is concerned with models of presence-the sensory illusion of being part of a virtual scene-but there is still no general agreement on how to measure it in an objective and reliable way. When it comes to virtual reality, presence is often considered as one of the main factors contributing to quality of experience, yet existing methods either rely on subjective assessments of users or on specifics of the virtual environment they are applied in, making it difficult for experimental procedures to be generalized. This paper presents ideas for research into promising measures of presence, based on first experiments with novel behavioral measures inside a rich environment which users can feel present in more naturally.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8798203,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798203,Human-centered computing;Human computer interaction (HCI);HCI design and evaluation methods;User studies;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality,Atmospheric measurements;Particle measurements;Virtual environments;Games;Real-time systems;Reliability,behavioural sciences;virtual reality,contemporary presence theory;objective measures;reliable measures;general agreement;virtual reality;quality of experience;virtual environment;behavioral measures;sensory illusion;virtual scene,,,,12,,15-Aug-19,,,IEEE,IEEE Conferences
Simulator sickness in immersive virtual environment,C. Jinjakam; K. Hamamoto,"Graduate School of Science and Technology, Course of Science and Technology, Tokai University, Tokyo, JAPAN; Department of Information Media Technology, School of Information and Telecommunication Engineering, Tokai University, Tokyo, JAPAN",The 5th 2012 Biomedical Engineering International Conference,21-Feb-13,2012,,,1,4,"The simulator sickness in immersive virtual environment was studied for future questionnaire improvement. The top four sickness scores are general discomfort, eyestrain, difficulty concentrating, and fatigue. These experimental results suggest future questionnaire for immersive virtual environment to concentrate on problems about eyes and seeing. Furthermore, the least four simulator sickness are burping, increase salivation, sweating, and stomach awareness. These sickness symptoms might be reduced to shorten future simulator sickness questionnaire.",,978-1-4673-4892-8,10.1109/BMEiCon.2012.6465465,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6465465,Virtual reality;immersive virtual environment;simulator sickness;simulator sickness questionnaire,Virtual environments;Fatigue;Stomach;Educational institutions;Focusing;Electronic mail,digital simulation;human computer interaction;human factors;medical computing;virtual reality,simulator sickness;immersive virtual environment;sickness scores;general discomfort;eyestrain;concentration difficulty;fatigue;burping;salivation;sweating;stomach awareness;sickness symptoms;virtual reality,,3,,9,,21-Feb-13,,,IEEE,IEEE Conferences
Annotation-Based Development of Explorable Immersive VR/AR Environments,J. Floty≈Ñski; A. Nowak,"Pozna≈Ñ University of Economics and Business,61-875 Pozna≈Ñ,Poland; Pozna≈Ñ University of Economics and Business,61-875 Pozna≈Ñ,Poland",2019 International Conference on 3D Immersion (IC3D),30-Jan-20,2019,,,1,9,"Virtual and augmented reality environments consist of objects that typically interact with other objects and users, leading to evolution of 3D objects and scenes over time. In multiple VR/AR applications in different domains, interactions and temporal properties of 3D content may be represented using general or domain knowledge, which makes them comprehensible to average users or domain experts without an expertise in IT. Logging interactions and their results can be especially useful in VR/AR environments that are intended to monitor and gain knowledge about the system behavior as well as users' behavior and preferences. However, the available approaches to development of VR/AR environments do not enable logging interactions in an explorable way. The main contribution of this paper is a method of developing explorable VR/AR environments on the basis of existing environments developed using well established tools, such as game engines and imperative programming languages. In the approach, interactions can be represented with general or domain knowledge. The method is discussed in the context of an immersive car showroom, which enables acquisition of knowledge about customers' interests and preferences for marketing and merchandising purposes.",2379-1780,978-1-7281-5189-2,10.1109/IC3D48390.2019.8975907,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8975907,annotations;exploration;interaction;virtual reality;augmented reality;semantics;ontologies,,augmented reality,logging interactions;domain knowledge;annotation-based development;temporal properties;domain experts;system behavior;virtual reality environments;augmented reality environments;VR/AR applications;immersive VR/AR environments,,,,35,,30-Jan-20,,,IEEE,IEEE Conferences
Exploring Virtual Environments by Visually Impaired Using a Mixed Reality Cane Without Visual Feedback,L. Zhang; K. Wu; B. Yang; H. Tang; Z. Zhu,"The City University of New York,Borough of Manhattan Community College,New York,NY,USA; The City University of New York,Borough of Manhattan Community College,New York,NY,USA; The City University of New York,Borough of Manhattan Community College,New York,NY,USA; The City University of New York,Borough of Manhattan Community College,New York,NY,USA; The City University of New York,The City College Visual Computing Lab,New York,NY,USA",2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),16-Dec-20,2020,,,51,56,"Though virtual reality (VR) has been advanced to certain levels of maturity in recent years, the general public, especially the population of the blind and visually impaired (BVI), still cannot enjoy the benefit provided by VR. Current VR accessibility applications have been developed either on expensive head-mounted displays or with extra accessories and mechanisms, which are either not accessible or inconvenient for BVI individuals. In this paper, we present a mobile VR app that enables BVI users to access a virtual environment on an iPhone in order to build their skills of perception and recognition of the virtual environment and the virtual objects in the environment. The app uses the iPhone on a selfie stick to simulate a long cane in VR, and applies Augmented Reality (AR) techniques to track the iPhone's real-time poses in an empty space of the real world, which is then synchronized to the long cane in the VR environment. Due to the use of mixed reality (the integration of VR & AR), we call it the Mixed Reality cane (MR Cane), which provides BVI users auditory and vibrotactile feedback whenever the virtual cane comes in contact with objects in VR. Thus, the MR Cane allows BVI individuals to interact with the virtual objects and identify approximate sizes and locations of the objects in the virtual environment. We performed preliminary user studies with blind-folded participants to investigate the effectiveness of the proposed mobile approach and the results indicate that the proposed MR Cane could be effective to help BVI individuals in understanding the interaction with virtual objects and exploring 3D virtual environments. The MR Cane concept can be extended to new applications of navigation, training and entertainment for BVI individuals without more significant efforts.",,978-1-7281-7675-8,10.1109/ISMAR-Adjunct51615.2020.00028,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288373,Virtual Reality;Mixed Reality;Visually Impaired;Spatial Exploration,Training;Visualization;Navigation;Virtual environments;Tools;Space exploration;Augmented reality,augmented reality;handicapped aids;haptic interfaces;helmet mounted displays;mobile computing,3D virtual environment;blind and visually impaired;virtual reality;BVI;mobile VR app;virtual objects;augmented reality;VR environment;mixed reality cane;VR accessibility applications;MR cane;head-mounted displays;vibrotactile feedback;auditory feedback,,,,24,,16-Dec-20,,,IEEE,IEEE Conferences
[DC] Self-Adaptive Technologies for Immersive Trainings,J. Heyse,"Ghent University - imec, IDLab",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,1381,1382,"Online learning is the preferred option for professional training, e.g. Industry 4.0 or e-health, because it is more cost efficient than on-site organisation of realistic training sessions. However, current online learning technologies are limited in terms of personalisation, interactivity and immersiveness that are required by applications such as surgery and pilot training. Virtual Reality (VR) technologies have the potential to overcome these limitations. However, due to its early stage of research, VR requires significant improvements to fully unlock its potential. The focus of this PhD is to tackle research challenges to enable VR for online training in three dimensions: (1) dynamic adaptation of the training content for personalised trainings, by incorporating prior knowledge and context data into self-learning algorithms; (2) mapping of sensor data onto what happens in the VR environment, by focusing on motion prediction techniques that use past movements of the users, and (3) investigating immersive environments with intuitive interactions, by gaining a better understanding of human motion in order to improve interaction. The designed improvements will be characterised though a prototype VR training platform for multiple use cases. This work will not only advance the state of the art on VR training, but also on online e-learning applications in general.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8798207,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798207,Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality;Applied computing;Life and medical sciences;Health informatics,Training;Virtual reality;Tracking;Resists;Haptic interfaces;Surgery;Prototypes,computer based training;sensors;virtual reality,online training;training content;personalised trainings;context data;self-learning algorithms;sensor data;VR environment;motion prediction techniques;immersive environments;intuitive interactions;prototype VR training platform;online e-learning applications;immersive trainings;on-site organisation;immersiveness;surgery;pilot training;training sessions;online learning technologies;self-adaptive technologies;virtual reality technologies,,,,6,,15-Aug-19,,,IEEE,IEEE Conferences
Logging Interactions in Explorable Immersive VR/AR Applications,J. Floty≈Ñski; P. Soboci≈Ñski,"Pozna≈Ñ University of Economics and Business, 61-875 Pozna≈Ñ, Poland; Pozna≈Ñ University of Economics and Business, 61-875 Pozna≈Ñ, Poland",2018 International Conference on 3D Immersion (IC3D),7-Mar-19,2018,,,1,8,"3D content of immersive virtual and augmented reality applications typically consists of objects that can interact with users and other objects. Interactions may be followed by changes of objects' properties, including their geometry, structure and appearance as well as high-level, domain-specific semantics. Logging interactions and temporal 3D content properties in a uniform, explorable way can be useful in various domains that involve multiple collaborating users and interacting objects, and can benefit from analysis of the users' and objects' behavior, e.g., in design, training, education, e-commerce, marketing and merchandising. However, the available approaches do not enable creation of explorable immersive VR/AR applications with regards to interactions and temporal 3D content properties. The main contribution of this paper is an approach to generating explorable interaction logs in immersive applications. The logs are ontologies compliant with the semantic web. Hence, the approach may be used with general or domain knowledge in a way intelligible to average users or domain specialists without expertise in IT. The approach is discussed in the context of a heterogeneous immersive environment, which combines diverse VR presentation and interaction devices to enable collaboration of multiple users within urban design.",2379-1780,978-1-5386-7590-8,10.1109/IC3D.2018.8657830,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8657830,3D content exploration;interaction;semantic web;urban design;Unity,Three-dimensional displays;Ontologies;Semantics;Solid modeling;Urban areas;Tools;Semantic Web,augmented reality;groupware;ontologies (artificial intelligence);semantic Web,logging interactions;immersive virtual reality applications;augmented reality applications;domain-specific semantics;temporal 3D content properties;multiple collaborating users;interacting objects;e-commerce;explorable interaction logs;immersive applications;general domain knowledge;domain specialists;heterogeneous immersive environment;interaction devices;explorable immersive VR-AR applications,,,,20,,7-Mar-19,,,IEEE,IEEE Conferences
"Augmented reality @ Siemens: ""The Workflow Designer Project"" & ""Augmented reality PDA""",A. Raczynski; C. Reimann; P. Gussmann; C. Matysczok; A. Grow; W. Rosenbach,NA; NA; NA; NA; NA; NA,"The First IEEE International Workshop Agumented Reality Toolkit,",6-Jan-03,2002,,,2 pp.,,"In this paper we describe two AR projects at Siemens: ""The Workflow Designer Project"" and ""AR-PDA - A Personal Digital Assistant for VR/AR Content"". The Workflow Designer makes use of pattern recognition and tracking to augment real-time video with 3D models, allowing a remote expert to guide a worker through a complicated workflow step-by-step. The general idea of the AR-PDA project to the development of applications for new mobile devices like 3/sup rd/ generation mobile telephones, organizer or PDA for the consumer market. In this context augmented reality is used to support efficiently final users during their daily tasks and especially in service situations. The AR-PDA enhances real camera images by virtual objects (3D-animations, 2D-graphics or text) and allows personalized user interactions with the augmented scene.",,0-7803-7680-3,10.1109/ART.2002.1106974,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1106974,,Augmented reality;Layout;Pattern recognition;Wireless networks;Video compression;Image coding;Prototypes;Animation;Displays;Personal digital assistants,3G mobile communication;augmented reality;workflow management software;notebook computers;pattern recognition;real-time systems;computer animation,augmented reality;Siemens;The Workflow Designer Project;Augmented reality PDA;A Personal Digital Assistant for VR/AR Content;AR-PDA;pattern recognition;pattern tracking;real-time video;3D models;3rd generation mobile telephones;virtual objects;3D animations;2D graphics;text;personalized user interactions;augmented scene,,,3,3,,6-Jan-03,,,IEEE,IEEE Conferences
Visualisation of a simple beam under a load in virtual environment,S. Jankovic; L. Jankovic; A. H. C. Chan; G. H. Little,"Sch. of Civil Eng., Birmingham Univ., UK; NA; NA; NA",Proceedings Fifth International Conference on Information Visualisation,7-Aug-02,2001,,,589,591,"Visualisation is generally considered to be a problem in structural design. Being an iterative process, structural design is time consuming for engineers, and results are difficult for clients to visualize. Current numerical methods have slow dynamic visualisation capability, which is usually separate from the calculation phase. The paper investigates whether an analogue virtual reality (VR) model of a structure can integrate calculation and visual representation. Early results of this research show that it is possible to have analogue virtual reality models of structures capable of real time user interaction. The paper shows how the user can interact with a VR analogue model of a simple beam, move a concentrated load along the length of the beam, change the value of the force, and visualise deflection of the beam using the analytical solution of the problem.",,0-7695-1195-3,10.1109/IV.2001.942115,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=942115,,Visualization;Virtual environment;Virtual reality;Solid modeling;Steel;Civil engineering;Postal services;Process design;Design engineering;Geometry,virtual reality;data visualisation;structural engineering computing;real-time systems,simple beam visualisation;load;virtual environment;structural design;iterative process;engineers;numerical methods;slow dynamic visualisation capability;calculation phase;analogue virtual reality model;visual representation;real time user interaction;VR analogue model;concentrated load;beam deflection;analytical solution,,,,5,,7-Aug-02,,,IEEE,IEEE Conferences
Multi-Window 3D Interaction for Collaborative Virtual Reality,A. Kunert; T. Weissker; B. Froehlich; A. Kulik,"Virtual Reality and Visualization Research Group, Bauhaus-Universit√§t Weimar, Weimar, Germany; Virtual Reality and Visualization Research Group, Bauhaus-Universit√§t Weimar, Weimar, Germany; Virtual Reality and Visualization Research Group, Bauhaus-Universit√§t Weimar, Weimar, Germany; Virtual Reality and Visualization Research Group, Bauhaus-Universit√§t Weimar, Weimar, Germany",IEEE Transactions on Visualization and Computer Graphics,30-Sep-20,2020,26,11,3271,3284,"We present a novel collaborative virtual reality system that offers multiple immersive 3D views at large 3D scenes. The physical setup consists of two synchronized multi-user 3D displays: a tabletop and a large vertical projection screen. These displays afford different presentations of the shared 3D scene. The wall display lends itself to the egocentric exploration at 1:1 scale, while the tabletop affords an allocentric overview. Additionally, handheld 3D portals facilitate the personal exploration of the scene, the comparison of views, and the exchange with others. Our developments enable seamless 3D interaction across these independent 3D views. This requires the simultaneous representation of user input in the different viewing contexts. However, the resulting interactions cannot be executed independently. The application must coordinate the interactions and resolve potential ambiguities to provide plausible effects. We analyze and document the challenges of seamless 3D interaction across multiple independent viewing windows, propose a high-level software design to realize the necessary functionality, and apply the design to a set of interaction tools. Our setup was tested in a formal user study, which revealed general advantages of collaborative 3D data exploration with multiple views in terms of user preference, comfort, and task performance.",1941-0506,,10.1109/TVCG.2019.2914677,European Unions Horizon 2020 Framework Programme for Research and Innovation; German Federal Ministry of Education and Research; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8705329,Collaborative virtual environment;multi-display setups;3D interaction techniques;input disambiguation,Three-dimensional displays;Collaboration;Windows;Microsoft Windows;Navigation;Virtual environments;Two dimensional displays,data visualisation;groupware;interactive systems;three-dimensional displays;virtual reality,novel collaborative virtual reality system;multiple immersive 3D views;synchronized multiuser 3D;vertical projection screen;wall display;egocentric exploration;tabletop affords;personal exploration;seamless 3D interaction;independent 3D views;multiple independent viewing windows;interaction tools;collaborative 3D data exploration;multiwindow 3D interaction;3D portals,,9,,52,IEEE,3-May-19,,,IEEE,IEEE Journals
VR Sickness Prediction for Navigation in Immersive Virtual Environments using a Deep Long Short Term Memory Model,Y. Wang; J. -R. Chardonnet; F. Merienne,"Arts et Metiers, LISPEN EA7515, HESAM, UBFC, Institut Image; Arts et Metiers, LISPEN EA7515, HESAM, UBFC, Institut Image; Arts et Metiers, LISPEN EA7515, HESAM, UBFC, Institut Image",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,1874,1881,"This paper proposes a new objective metric of visually induced motion sickness (VIMS) in the context of navigation in virtual environments (VEs). Similar to motion sickness in physical environments, VIMS can induce many physiological symptoms such as general discomfort, nausea, disorientation, vomiting, dizziness and fatigue. To improve user satisfaction with VR applications, it is of great significance to develop objective metrics for VIMS that can analyze and estimate the level of VR sickness when a user is exposed to VEs. One of the well-known objective metrics is the postural instability. In this paper, we trained a LSTM model for each participant using a normal-state postural signal captured before the exposure, and if the postural sway signal from post-exposure was sufficiently different from the pre-exposure signal, the model would fail at encoding and decoding the signal properly; the jump in the reconstruction error was called loss and was proposed as the proposed objective measure of simulator sickness. The effectiveness of the proposed metric was analyzed and compared with subjective assessment methods based on the simulator sickness questionnaire (SSQ) in a VR environment, achieving a Pearson correlation coefficient of. 89. Finally, we showed that the proposed method had the potential to be deployed within a closed-loop system and get real-time performance to predict VR sickness, opening new insights to develop user-centered and customized VR applications based on physiological feedback.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8798213,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798213,Human-centered computing;Virtual reality;Walkthrough evaluations;User interface design;Interaction devices;Computing methodologies;Machine learning;Machine learning approaches;Neural networks,Navigation;Virtual environments;Physiology;Real-time systems;Three-dimensional displays;Logic gates;Deep learning,closed loop systems;human factors;physiology;recurrent neural nets;virtual reality,VR sickness prediction;navigation;immersive virtual environments;deep long short term memory model;visually induced motion sickness;VIMS;VEs;physical environments;physiological symptoms;general discomfort;dizziness;fatigue;user satisfaction;VR applications;postural instability;LSTM model;normal-state postural signal;postural sway signal;post-exposure;pre-exposure signal;objective measure;simulator sickness questionnaire;VR environment;user-centered VR applications,,1,,34,,15-Aug-19,,,IEEE,IEEE Conferences
Visualizing Ecological Data in Virtual Reality,J. Huang; M. S. Lucash; R. M. Scheller; A. Klippel,"Pennsylvania State University, ChoroPhronesis; Portland State University; North Carolina State University; Pennsylvania State University, ChoroPhronesis",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,1311,1312,"Visualizing complex scientific data and models in 2D can be challenging. The result can be hard to interpret and understand for the general audience, and the model accuracy hard to evaluate even for the experts. To address these problems, we created a workflow that translates data of an ecological model, LANDIS-II, into a high-fidelity 3D model in virtual reality (VR). We combined ecological modeling, analytical modeling, procedural modeling, and VR, to allow users to experience a forest in northern Wisconsin (WI), United States, under two climate scenarios. Users can explore and interact with the forest under different climate scenarios, explore the impacts of climate change on different tree species, and retrieve information from a 3D tree database. The VR application can be used as an educational tool for the general public, and as a model checking tool by researchers.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8797771,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797771,Visualization;Scientific visualization;Geographic visualization;Virtual reality;Human computer interaction;Human centered computing;Interaction paradigms;Software and its engineering;Software organization and properties;Virtual worlds software;Virtual worlds training simulations;Physical sciences and engineering;Earth and atmospheric sciences;Environmental sciences;Visualization application domains,Forestry;Data visualization;Solid modeling;Biological system modeling;Three-dimensional displays;Data models,data visualisation;ecology;environmental science computing;formal verification;vegetation;virtual reality,virtual reality;ecological model;high-fidelity 3D model;VR;ecological modeling;analytical modeling;procedural modeling;forest;model checking tool;climate scenarios;ecological data visualization;LANDIS-II;climate change;tree species,,1,,10,,15-Aug-19,,,IEEE,IEEE Conferences
Opportunities for Virtual and Mixed Reality Knowledge Demonstration,R. Horst; R. D√∂rner,RheinMain University of Applied Sciences; RheinMain University of Applied Sciences,2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),29-Apr-19,2018,,,381,385,"Universities are more and more expected to disseminate research findings to the general public and specific stakeholders especially in the economy (‚Äúthird mission‚Äù). Since this third mission also affects third party research funding within recent decades, j scientists do need to be able to service both educational and marketing related purposes within their presentations. Moreover, scientists need to address heterogenous audiences. To meet such demanding requirements, Virtual Reality (VR) and Mixed Reality (MR) technology could serve as a valuable medium. In this position paper, we explore opportunities concerning VR and MR for what we refer to as `Knowledge Demonstration' (KD), based on a state of the art literature analysis. Furthermore, we propose aspects to consider when planning virtually augmented KD systems.",,978-1-5386-7592-2,10.1109/ISMAR-Adjunct.2018.00110,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699173,Human-centered computing‚ÄîInteraction paradigms‚ÄîMixed / augmented reality;Human-centered computing‚ÄîInteraction paradigms‚ÄîVirtual reality;Applied computing‚ÄîEducation‚ÄîComputer-assisted instruction;Applied computing‚ÄîOperations research‚ÄîMarketing,Education;Collaboration;Augmented reality;Face;Tools;Videos,educational institutions;technical presentation;virtual reality,universities;virtually augmented KD systems;virtual reality technology;marketing related purposes;educational related purposes;mixed reality knowledge demonstration;mixed reality technology,,,,59,,29-Apr-19,,,IEEE,IEEE Conferences
Towards understanding scene transition techniques in immersive 360 movies and cinematic experiences,K. R. Moghadam; E. D. Ragan,"Texas A&M University, United States; Texas A&M University, United States",2017 IEEE Virtual Reality (VR),6-Apr-17,2017,,,375,376,"Many researchers have studied methods of effective travel in virtual environments, but little work has considered scene transitions, which may be important for virtual reality experiences like immersive 360 degree movies. In this research, we designed and evaluated three different scene transition techniques in two environments, conducted a pilot study, and collected metrics related to sickness, spatial orientation, and preference. Our preliminary results indicate that faster techniques are generally preferred by gamers and more gradual transitions are preferred by participants with less experience with 3D gaming and virtual reality.",2375-5334,978-1-5090-6647-6,10.1109/VR.2017.7892333,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892333,"H.5.1 [Information interfaces and presentation]: Multimedia Information Systems ‚Äî Artificial, augmented, and virtual realities",Interpolation;Teleportation;Motion pictures;Three-dimensional displays;Virtual environments;Google,human computer interaction;virtual reality,cinematic experiences;virtual reality;immersive 360 degree movies;scene transition techniques,,8,,3,,6-Apr-17,,,IEEE,IEEE Conferences
Hand-based interactions in Virtual Reality: No better feeling than the real thing!,D. Panzoli; P. Royeres; M. Fedou,"IRIT UMR 5505, Toulouse, F-31400, France; INU Jean-Francois Champollion, Albi, France; INU Jean-Francois Champollion, Albi, France",2019 11th International Conference on Virtual Worlds and Games for Serious Applications (VS-Games),14-Oct-19,2019,,,1,2,"Manipulating tools or crafting objects using one's bare hands is a recurring activity in many immersive training applications. Yet, high technical challenge and costly haptic hardware confine such tasks to surgery training and specialised simulators of the like, while more general immersive applications settle for less natural experiences using standard game controllers and/or relying on more abstract interactions. We designed a low-cost prototype were a physical object is used to provide a natural haptic feedback to a barehanded virtual manipulation task, hypothesising that nothing better than a real object would provide an accurate feeling of touch and control. With VR and AR high-end technologies now reaching out to broad audiences, we wondered if it was yet possible to design a compelling experience using only consumer market products and APIs. In this paper we demonstrate indeed that these technologies are mature enough to build a working prototype, but we failed to reach a level of quality suitable for more widespread usage.",2474-0489,978-1-7281-4540-2,10.1109/VS-Games.2019.8864546,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8864546,Mixed Reality;Hand-based interaction;haptic feedback;object recognition,Haptic interfaces;Cameras;Virtual environments;Training;Hardware;Task analysis,haptic interfaces;virtual reality,hand-based interactions;virtual reality;manipulating tools;crafting objects;bare hands;immersive training applications;haptic hardware;surgery training;general immersive applications;natural experiences;standard game controllers;abstract interactions;low-cost prototype;physical object;natural haptic feedback;barehanded virtual manipulation task;high-end technologies;consumer market products;augmented reality;API,,,,6,,14-Oct-19,,,IEEE,IEEE Conferences
Empowering Young Job Seekers with Virtual Reality,E. Prasolova-F√∏rland; M. Fominykh; O. I. Ekelund,"IMTEL, Norwegian University of Science and Technology, Trondheim, Norway; IMTEL, Norwegian University of Science and Technology, Trondheim, Norway; IMTEL, Norwegian University of Science and Technology, Trondheim, Norway",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,295,302,"This paper presents the results of the Virtual Internship project that aims to help young job seekers get insights of different workplaces via immersive and interactive experiences. We designed a concept of `Immersive Job Taste' that provides a rich presentation of occupations with elements of workplace training, targeting a specific group of young job seekers, including high-school students and unemployed. We developed several scenarios and applied different virtual and augmented reality concepts to build prototypes for different types of devices. The intermediary and the final versions of the prototypes were evaluated by several groups of primary users and experts, including over 70 young job seekers and high school students and over 45 various professionals and experts. The data were collected using questionnaires and interviews. The results indicate a generally very positive attitude towards the concept of immersive job taste, although with significant differences between job seekers and experts. The prototype developed for room-scale virtual reality with controllers was generally evaluated better than those including cardboard with 360 videos or with animated 3D graphics and augmented reality glasses. In the paper, we discuss several aspects, such as the potential of immersive technologies for career guidance, fighting youth unemployment by better informing the young job seekers, and various practical and technology considerations.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8798179,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798179,Virtual Reality;Career guidance;unemployment,Task analysis;Employment;Interviews;Fish;Training;Three-dimensional displays;Videos,augmented reality;computer based training;human computer interaction;unemployment,room-scale virtual reality;immersive job taste;high-school students;augmented reality;empowering young job seekers;virtual internship project;workplace training;career guidance;youth unemployment,,,,16,,15-Aug-19,,,IEEE,IEEE Conferences
Estimating the motion-to-photon latency in head mounted displays,J. Zhao; R. S. Allison; M. Vinnikov; S. Jennings,"Department of Electrical Engineering and Computer Science, York University, Canada; Department of Electrical Engineering and Computer Science, York University, Canada; Flight Research Laboratory, National Research Council, Canada; Flight Research Laboratory, National Research Council, Canada",2017 IEEE Virtual Reality (VR),6-Apr-17,2017,,,313,314,"We present a method for estimating the Motion-to-Photon (End-to-End) latency of head mounted displays (HMDs). The specific HMD evaluated in our study was the Oculus Rift DK2, but the procedure is general. We mounted the HMD on a pendulum to introduce damped sinusoidal motion to the HMD during the pendulum swing. The latency was estimated by calculating the phase shift between the captured signals of the physical motion of the HMD and a motion-dependent gradient stimulus rendered on the display. We used the proposed method to estimate both rotational and translational Motion-to-Photon latencies of the Oculus Rift DK2.",2375-5334,978-1-5090-6647-6,10.1109/VR.2017.7892302,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892302,Motion-to-Photon Latency;End-to-End Latency;Head-Mounted Displays,Resists;Potentiometers;Photodiodes;Virtual reality;Cameras;Estimation;Frequency-domain analysis,helmet mounted displays;human computer interaction;virtual reality,head mounted displays;HMD;Oculus Rift DK2;pendulum;damped sinusoidal motion;phase shift;motion-dependent gradient stimulus;translational motion-to-photon latencies;rotational motion-to-photon latencies;virtual reality,,18,,6,,6-Apr-17,,,IEEE,IEEE Conferences
A Structure to Integrate Natural Interaction into VR Systems for Education in Health,D. d. S. Ferreira; L. S. Machado,"NA; Lab. de Tecnol. para o Ensino Virtual e Estatistica (LabTEVE), Univ. Fed. da Paraiba (UFPB), Joao Pessoa, Brazil",2013 XV Symposium on Virtual and Augmented Reality,7-Nov-13,2013,,,208,211,"The use of virtual reality (VR) systems for education can improve the learning process in health, providing more motivation and realism to users. In general, specific devices are used to increase immersion and, in general, demand an adaptation period. Natural Interaction (NI) can provide an intuitive way to interact in VR systems since it can improve and make the communication between users and the system easier. The present work investigated NI techniques provided by VR frameworks for health. As a result, was designed a structure to integrate NI techniques into a framework.",,978-0-7695-5001-5,10.1109/SVR.2013.18,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6655781,Natural Interaction;Virtual Reality;Optical Tracking;Health Education,Visualization;Education;Virtual reality;Three-dimensional displays;Mice;Nickel;Multimedia communication,biomedical education;computer aided instruction;health care;human computer interaction;medical computing;virtual reality,VR frameworks;NI techniques;user communication;natural Interaction;adaptation period;user realism;user motivation;learning process;health education;VR systems;virtual reality,,,,21,,7-Nov-13,,,IEEE,IEEE Conferences
Jedi ForceExtension: Telekinesis as a Virtual Reality interaction metaphor,R. M. S. Clifford; N. M. B. Tuanquin; R. W. Lindeman,"HIT Lab NZ, University of Canterbury, New Zealand; HIT Lab NZ, University of Canterbury, New Zealand; HIT Lab NZ, University of Canterbury, New Zealand",2017 IEEE Symposium on 3D User Interfaces (3DUI),6-Apr-17,2017,,,239,240,"Virtual Reality (VR) enables us to freely operate in a space that is unconstrained by physical laws and limitations. To take advantage of this aspect, we have developed a technique for pseudo-telekinetic object manipulation in VR using slight downward tilt of the head to simulate Jedi concentration. This telekinetic ability draws inspiration from The Force abilities exhibited in the Star Wars universe, and is particularly well suited to VR because it provides the ability to interact with and manipulate objects at a distance. We implemented force translate, force rotate, force push and force pull behaviours as examples of the general concept of force extension. We conducted exploratory user testing to assess telekinesis as a suitable interaction metaphor. Subject performance and feedback varied between participants but were generally encouraging.",,978-1-5090-6716-9,10.1109/3DUI.2017.7893360,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7893360,Virtual Reality;3D interaction;3D Selection;object displacement,Three-dimensional displays;Force;Two dimensional displays;User interfaces;Virtual environments;Laser transitions,virtual reality,virtual reality interaction metaphor;pseudotelekinetic object manipulation;VR;Jedi concentration;Star Wars universe;force translate behaviours;force rotate behaviours;force push behaviours;force pull behaviours;force extension,,2,,5,,6-Apr-17,,,IEEE,IEEE Conferences
Simple augmented reality system for 3D ultrasonic image by see-through HMD and single camera and marker combination,S. Tano; K. Suzuki; K. Miki; N. Watanabe; M. Iwata; T. Hashiyama; J. Ichino; K. Nakayama,"University of Electro-Communications, Chofu-shi, Tokyo, 182-8585 JAPAN; University of Electro-Communications, Chofu-shi, Tokyo, 182-8585 JAPAN; Showa General Hospital, Kodaira-shi, Tokyo, 187-8510 JAPAN; University of Electro-Communications, Chofu-shi, Tokyo, 182-8585 JAPAN; Tokyo Metropolitan College of Industrial Technology, Shinagawa-ku, 140-0011, JAPAN; University of Electro-Communications, Chofu-shi, Tokyo, 182-8585 JAPAN; University of Electro-Communications, Chofu-shi, Tokyo, 182-8585 JAPAN; University of Electro-Communications, Chofu-shi, Tokyo, 182-8585 JAPAN",Proceedings of 2012 IEEE-EMBS International Conference on Biomedical and Health Informatics,7-Jun-12,2012,,,464,467,"Thanks to the rapid progress of ICT, significant progress has been made in both the ‚Äúgeneration‚Äù and ‚Äúdisplay‚Äù of the advanced medical information. However, serious problems still remain in both the ‚Äúgeneration‚Äù and ‚Äúdisplay‚Äù. Therefore, we propose a simple augmented reality system that can display an ultrasonic image of exactly the same plane in the body of the patient that a doctor is looking at. The key idea is to utilize the fact that an ultrasonic probe moves inside the doctor's field of view and within the accessible range of the arm in order to simplify the augmented reality system. The prototype has been developed using only a see-through HMD and single camera and marker combination. Three simple interaction methods compensate for the limitations in 3D position sensing. We worked with a medical doctor to test the prototype system and found it to be effective.",2168-2208,978-1-4577-2177-9,10.1109/BHI.2012.6211617,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6211617,,,augmented reality;biomedical ultrasonics;cameras;helmet mounted displays;medical image processing;medical information systems,augmented reality system;3D ultrasonic image;see-through HMD;ICT;medical information display;medical information generation;ultrasonic probe;interaction methods;3D position sensing;medical doctor;single camera-marker combination;information and communication technology;head mounted display,,2,,12,,7-Jun-12,,,IEEE,IEEE Conferences
Relief Mapping on facade of Sino Portuguese Architecture in Virtual Reality,K. Kalarat,"Multimedia Technology and Animation, Walailak University, Nakhonsithammarat, Thailand",2014 Fourth International Conference on Digital Information and Communication Technology and its Applications (DICTAP),29-May-14,2014,,,333,336,"Virtual Reality (VR) is an artificial environment created for presented for users to interact to virtual world and to be experienced in the way that users believe and accept it such a real environment. The environment is created to be three dimensional world using computer technology which is called Virtual Environment (VE). Virtual Environment makes user experiences immersion and realize to be inside and the part of the virtual world. Therefore, Virtual Environment is very important factor for making user immersive effectively, user must be able to explore what appears in the virtual environment and be able to interact by changing perspectives seamlessly. Generally, Virtual Environment (VE) should be made to be reality as much as possible by using high resolution of 3D model to increase more information and detail to the model in the environment. However, high resolution model, high polygon, really needs high performance computing to calculate rendering process to support user's interaction in real-time. For this paper, we focus on implementing Relief Mapping technique to reduce the polygonal bas-relief built in 3D world which is applied to VR of Sino Portuguese Architecture due to the facade of buildings consist of many bas-relief pattern via game engine, Unity3D, for real-time rendering and VR walkthrough. The result of this uses a single polygon/1 bas-relief and the quality of visualization after rendering process is compatible to the conventional process.",,978-1-4799-3724-0,10.1109/DICTAP.2014.6821706,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6821706,Virtual Reality (VR);Virtual Environment (VE);immersion;Facade;Bas-relief;Relief Mapping;Unity3D,Solid modeling;Three-dimensional displays;Real-time systems;Computer architecture;Virtual environments;Rendering (computer graphics),data visualisation;parallel processing;real-time systems;rendering (computer graphics);solid modelling;user interfaces;virtual reality,facade;Sino Portuguese architecture;virtual reality;artificial environment;computer technology;virtual environment;3D model;high resolution model;high performance computing;rendering process;user interaction;relief mapping technique;polygonal bas-relief;bas-relief pattern;game engine;Unity3D;real-time rendering;VR walkthrough;visualization,,,,15,,29-May-14,,,IEEE,IEEE Conferences
Interaction Patterns of Spatial Navigation in VR Workspaces,A. sud√°r; √Å. B. Csap√≥,"Sz√©chenyi Istv√°n University,Multidisciplinary Doctoral School of Engineering Sciences,Hungary; Sz√©chenyi Istv√°n University,Multidisciplinary Doctoral School of Engineering Sciences,Hungary",2019 10th IEEE International Conference on Cognitive Infocommunications (CogInfoCom),11-May-20,2019,,,615,618,"During the discovery of any new environment - be it real or virtual - the first step is usually that of exploration. The goal exploration in this context is to find the location that provides the most informative, or otherwise useful viewpoint in the space. Depending on the complexity of the space and the task at hand, this can be a difficult challenge. Nevertheless, the finding of useful viewpoints can be facilitated, at least in virtual reality, by changing the layout of the space, as well as by changing other visual features to lower the cognitive load of navigation. In this paper, we present a set of experiments using the MaxWhere desktop virtual environment which suggest that besides the arrangement of a space, its key points of discovery can also influence the time it takes to accomplish a task. This conclusion is supported both by data on key points of navigation and on the activation mode that was utilized on the various smartboards laid out in 3D space. In this research, we hope to show how specific nodes can be found, based on a data-oriented approach, which can lead users to focus on the most important information and obtain the best overview of any virtual space in general.",2380-7350,978-1-7281-4793-2,10.1109/CogInfoCom47531.2019.9089998,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9089998,virtual reality;MaxWhere;spatial cognition;spatial preferences;spatial navigation,Navigation;Task analysis;Virtual environments;Three-dimensional displays;Cognition;Atmospheric measurements,virtual reality,virtual reality;visual features;MaxWhere desktop virtual environment;activation mode;data-oriented approach;virtual space;interaction patterns;spatial navigation;VR workspaces;goal exploration;informative viewpoint,,6,,25,,11-May-20,,,IEEE,IEEE Conferences
Real-time VR Simulation of Laparoscopic Cholecystectomy based on Parallel Position-based Dynamics in GPU,J. Pan; L. Zhang; P. Yu; Y. Shen; H. Wang; H. Hao; H. Qin,"Beihang University Peng Cheng Lab,State Key Lab of VR Tech & Syst; Beihang University,State Key Lab of VR Tech & Syst; Beihang University,State Key Lab of VR Tech & Syst; Beijing Normal University,Faculty of Education; Beijing Aerospace General Hospital; Beihang University,Peng Cheng Lab; Stony Brook University,Department of Computer Science",2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),11-May-20,2020,,,548,556,"In recent years, virtual reality (VR) based training has greatly changed surgeons learning mode. It can simulate the surgery from the visual, auditory, and tactile aspects. VR medical simulator can greatly reduce the risk of the real patient and the cost of hospitals. Laparoscopic cholecystectomy is one of the typical representatives in minimal invasive surgery (MIS). Due to the large incidence of cholecystectomy, the application of its VR-based simulation is vital and necessary for the residents' surgical training. In this paper, we present a VR simulation framework based on position-based dynamics (PBD) for cholecystectomy. To further accelerate the deformation of organs, PBD constraints are solved in parallel by a graph coloring algorithm. We introduce a bio-thermal conduction model to improve the realism of the fat tissue electrocautery. Finally, we design a hybrid multi-model connection method to handle the interaction and simulation of the liver-gallbladder separation. This simulation system has been applied to laparoscopic cholecystectomy training in several hospitals. From the experimental results, users can operate in real-time with high stability and fidelity. The simulator is also evaluated by a number of digestive surgeons through preliminary studies. They believed that the system can offer great help to the improvement of surgical skills.",2642-5254,978-1-7281-5608-8,10.1109/VR46266.2020.00076,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9089572,Human-centered computing‚ÄîHuman computer interaction‚ÄîInteractive systems and tools‚ÄîUser interface programming;Computer systems organization‚ÄîReal-time systems‚ÄîReal- time system architecture,Surgery;Biological system modeling;Strain;Biological tissues;Image color analysis;Deformable models;Solid modeling,biological tissues;computer based training;graphics processing units;liver;medical computing;surgery;virtual reality,minimal invasive surgery;VR-based simulation;PBD constraints;graph coloring algorithm;hybrid multimodel connection method;laparoscopic cholecystectomy;parallel position-based dynamics;virtual reality based training;visual aspects;tactile aspects;VR medical simulator;GPU;auditory aspects;biothermal conduction model;fat tissue electrocautery;liver-gallbladder separation,,,,30,,11-May-20,,,IEEE,IEEE Conferences
The Library: A Non-Intrusive Gaze Directed Virtual Reality Animation,K. A. Yu,NA,2019 IEEE 2nd Workshop on Animation in Virtual and Augmented Environments (ANIVAE),2-Apr-20,2019,,,1,4,"In recent years, Cinematic Virtual Reality (CVR) has emerged as a unique form of VR storytelling. While narrative strategies for this new medium are still being explored, one often discussed issue is in guiding the viewer to look where the filmmaker intended. Conventional cinematic techniques such as sound and visual cues have been adopted to direct the viewer's attention. However, this dispersed viewer's attention might suggest an unexplored territory for storytelling in VR and immersive media in general. My current creative practice-led research explores how dispersed viewer's attention could be used to navigate a branching and spatial narrative structure. The Library is a work in progress, an animated VR experience that reimagines Jorge Luis Borges' Library of Babel. The story progresses according to how the viewer's gaze reacts to the narrative events that are organised both temporally and spatially, all the while without the viewer being aware of the gaze interaction mechanism. This paper presents some of the strategies that have emerged in the production of the creative work, which could lead to further explorations of a non-intrusive gaze directed interactive immersive cinema.",,978-1-7281-3229-7,10.1109/ANIVAE47543.2019.9050930,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9050930,Cinematic Virtual Reality;Animation;Computer Graphics,,computer animation;data visualisation;human computer interaction;humanities;interactive systems;virtual reality,cinematic virtual reality;VR storytelling;narrative strategies;sound cues;visual cues;dispersed viewer;branching;spatial narrative structure;animated VR experience;narrative events;gaze interaction mechanism;cinematic techniques;nonintrusive gaze directed virtual reality,,,,9,,2-Apr-20,,,IEEE,IEEE Conferences
Muscleblazer: Force-Feedback Suit for Immersive Experience,Y. Kishishita; S. Das; A. V. Ramirez; C. Thakur; R. Tadayon; Y. Kurita,"Hiroshima University; Hiroshima University; Hiroshima University; Hiroshima University; Arizona State University, CuBiC; Hiroshima University, JST PRESTO",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,1813,1818,"The increasing use of virtual reality (VR) and augmented reality (AR) systems has opened the possibility of providing immersive experiences to the general population around the world. However, most of the existing systems do not provide highly effective force-feedback experiences to the user. To provide such augmented systems in combination with force-feedback, novel ideas must be introduced that can be easily integrated with the existing VR and AR technologies. This work proposes a first-person VR game integrated with a soft exoskeleton that enhances the quality of interaction between the subject and the virtual environment (VE) through an additional force-feedback element. The effect of introducing the force-feedback element on the user is analyzed by using biosensors and questionnaire feedback. The biosensors are used to measure the level of anxiety induced in the subject during interaction with the virtual environment. Conditions in which this interaction occurs with and without force-feedback are compared. The questionnaire analyzes the perceived change in emotions of users as a result of the introduction of the force-feedback element. This game can be played by most individuals, regardless of age and physical fitness.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8797962,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797962,Virtual reality;Force-feedback;Pneumatic actuators;Wearable technology;Biosensors;Galvanic skin response (GSR),Games;Virtual environments;Muscles;Valves;Solenoids;Force;Biosensors,augmented reality;biosensors;force feedback;haptic interfaces;human factors,force-feedback suit;immersive experience;highly effective force-feedback experiences;augmented systems;first-person VR game;virtual environment;additional force-feedback element;questionnaire feedback;virtual reality;augmented reality systems;AR systems;soft exoskeleton;biosensors,,1,,12,,15-Aug-19,,,IEEE,IEEE Conferences
3rd Virtual and Augmented Reality for Good (VAR4Good) Workshop,A. Dey; M. Billinghurst; G. Welch; E. Rojas-Mu√±oz,NA; NA; NA; NA,2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),29-Apr-19,2018,,,364,364,"Virtual Reality (VR) and Augmented Reality (AR) are becoming mainstream. With the research and technological advances, it is now possible to use these technologies in almost all domains and places. This provides a bigger opportunity to create applications that intend to impact society in greater ways than beyond just entertainment. Today the world is facing different challenges including healthcare, environment, and education. Now is the time to explore how VR/AR might be used to solve widespread societal challenges. The third Virtual and Augmented Reality for Good (VAR4Good) workshop will bring together researchers, developers, and industry partners in presenting and promoting research that intends to solve real-world problems using VR/AR. The workshop will provide a platform to grow a research community that discusses challenges and opportunities to create Virtual and Augmented Reality for Good. We invite application and position papers (2-4 pages, excluding references), that address the way that VR/AR technologies can solve real-world problems in various application domains including, but not limited to, health, the environment, education, sports, the arts, and applications in support of special needs such as assistive, adaptive, and rehabilitative applications. Our focus and preference will be on applications that are beyond general uses of VR/AR. Please see full CFP on our website.",,978-1-5386-7592-2,10.1109/ISMAR-Adjunct.2018.00105,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699256,,Augmented reality;Conferences;Australia;Education;Entertainment industry;Medical services,augmented reality;human computer interaction;technology management,VAR4Good;technological advances;Virtual and Augmented Reality for Good workshop;VR/AR technologies,,,,,,29-Apr-19,,,IEEE,IEEE Conferences
Interacting with Distant Objects in Augmented Reality,M. Whitlock; E. Harnner; J. R. Brubaker; S. Kane; D. A. Szafir,University of Colorado Boulder; University of Colorado Boulder; University of Colorado Boulder; University of Colorado Boulder; University of Colorado Boulder,2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),30-Aug-18,2018,,,41,48,"Augmented reality (AR) applications can leverage the full space of an environment to create immersive experiences. However, most empirical studies of interaction in AR focus on interactions with objects close to the user, generally within arms reach. As objects move farther away, the efficacy and usability of different interaction modalities may change. This work explores AR interactions at a distance, measuring how applications may support fluid, efficient, and intuitive interactive experiences in room-scale augmented reality. We conducted an empirical study (N = 20) to measure trade-offs between three interaction modalities-multimodal voice, embodied freehand gesture, and handhelds devices-for selecting, rotating, and translating objects at distances ranging from 8 to 16 feet (2.4m-4.9m). Though participants performed comparably with embodied freehand gestures and handheld remotes, they perceived embodied gestures as significantly more efficient and usable than device-mediated interactions. Our findings offer considerations for designing efficient and intuitive interactions in room-scale AR applications.",,978-1-5386-3365-6,10.1109/VR.2018.8446381,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446381,Human-centered computing-Interaction design-Interaction design process and methods-User interface design,Task analysis;Usability;Visualization;Pervasive computing;Augmented reality;Electronic mail,augmented reality;gesture recognition;user interfaces,distant objects;augmented reality;immersive experiences;AR interactions;fluid experiences;intuitive interactive experiences;room-scale;empirical study;interaction modalities-multimodal voice;embodied freehand gesture;handhelds devices-for selecting;device-mediated interactions;efficient interactions;intuitive interactions;interaction modalities;room-scale AR applications,,2,,44,,30-Aug-18,,,IEEE,IEEE Conferences
Interactive Modeling of Trees using VR Devices,Z. Liu; C. Shen; Z. Li; T. Weng; O. Deussen; Z. Cheng; D. Wang,"Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",2019 International Conference on Virtual Reality and Visualization (ICVRV),6-Oct-20,2019,,,69,75,"Conventional interactive 3D tree modeling systems are generally based on 2D input devices, and it's not convenient to generate desired 3D tree shape from 2D inputs due to the complexity of 3D tree structures. In this paper, we present a system for modeling trees interactively using a 3D gesture-based VR platform. The system contains a head-mounted display (HMD) and a 6-DOF motion controller for interaction. We propose an improved procedural modeling method to generate trees faster for VR platform. Using the 6-DOF motion controller, users can manipulate tree structures by a set of 3D interactive operations, including geometric editing using 3D gestures, sketching, brushing and silhouette-guided growth. Our interactions are more flexible and convenient than using traditional 2D input devices, e.g., we allow the user to simultaneously rotate and translate parts of a tree using a 3D gesture.",2375-141X,978-1-7281-4752-9,10.1109/ICVRV47840.2019.00020,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9212896,Human-centered computing-Human computer interaction (HCI)-Interaction paradigms-Virtual reality;Computing methodologies-Computer graphics-Shape modeling,Three-dimensional displays;Vegetation;Solid modeling;Two dimensional displays;Computational modeling;Input devices;Skeleton,geometry;gesture recognition;helmet mounted displays;interactive systems;solid modelling;virtual reality,interactive modeling;VR devices;tree structures;3D gesture-based VR platform;head-mounted display;3D interactive operations;2D input devices;interactive 3D tree modeling systems;geometric editing,,,,25,,6-Oct-20,,,IEEE,IEEE Conferences
Haptically enabled interactive virtual reality prototype for general assembly,A. Bhatti; Yong Bing Khoo; D. Creighton; J. Anticev; S. Nahavandi; Mingwei Zhou,"Deakin University, Australia; CSIRO, Australia; Deakin University, Australia; CSIRO, Australia; Deakin University, Australia; CSIRO, Australia",2008 World Automation Congress,9-Dec-08,2008,,,1,6,"Desktop computers based virtual training systems are attracting paramount attention from manufacturing industries due to their potential advantages over the conventional training practices. Significant cost savings can be realized due to the shorter training-scenarios development times and reuse of existing engineering models. In addition, by using computer based virtual reality (VR) training systems, the time span from the product design to commercial production can be shortened due to non-reliance on hardware parts. Within the aforementioned conceptual framework, a haptically enabled interactive and immersive virtual reality (HIIVR) system is presented. Unlike existing VR systems, the presented idea tries to imitate real physical training scenarios by providing comprehensive user interaction, constrained within the physical limitations of the real world imposed by the haptics devices within the virtual environment. As a result, in contrast to the existing VR systems, capable of providing knowledge generally about assembly sequences only, the proposed system helps in procedural learning and procedural skill development as well, due to its high physically interactive nature.",2154-4824,978-1-889335-38-4,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4699035,Haptics;virtual assembly;interactive and immersive,Virtual reality;Virtual prototyping;Assembly;Industrial training;Computer aided manufacturing;Manufacturing industries;Costs;Design engineering;Product design;Production systems,assembling;computer based training;haptic interfaces;industrial training;production engineering computing;virtual reality,haptically enabled interactive virtual reality prototype;general assembly;manufacturing industries;computer-based virtual reality training systems;immersive virtual reality,,,,9,,9-Dec-08,,,IEEE,IEEE Conferences
A Gas Turbine Virtual Reality Application Migration to Mixed Reality: Development Experience,H. Sulaiman; A. M. Yusof; N. Ibrahim; R. A. Latif,"Universiti Tenaga Nasional,Department of Informatics,Malaysia; Universiti Tenaga Nasional,Department of Informatics,Malaysia; Universiti Tenaga Nasional,Institute of Informatics and Computing in Energy,Malaysia; Universiti Tenaga Nasional,Department of Informatics,Malaysia",2020 IEEE Graphics and Multimedia (GAME),15-Jan-21,2020,,,19,24,"This paper discusses several technical issues and difficulties faced while converting a Gas Turbine Virtual Reality (VR) application to a Mixed Reality (MR) application. Direct conversion from a VR to MR is feasible. However, it is found that several techniques or methods employed in VR are ineffective in MR. This is due to the Head Mounted Device used in the MR application allows users to see the real world while visualising computer-generated image, whereby the same function is not applicable in VR. Among the functions in VR which are not compatible with MR are teleporting and interaction. These issues were discovered during a prototype testing of the MR system. Based on the observation, it is found that in an MR system, the view inside HMD is overcrowded when a virtual background is visible along with the actual background. In addition to that, in an MR system, users prefer to physically walk towards the virtual object rather than teleporting using a controller. The discussion is not only highlighting the problem faced but also the solutions. In general, the objective of this paper is to share the technical issues experienced during the development process. It is expected that this knowledge can be helpful to future researchers or developers.",,978-1-7281-9244-4,10.1109/GAME50158.2020.9315123,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9315123,Virtual Reality (VR);Mixed Reality (MR);teleportation;interaction,Virtual reality;Turbines;Three-dimensional displays;Real-time systems;Solids;Navigation;Mixed reality,data visualisation;gas turbines;helmet mounted displays;mechanical engineering computing;mobile computing;virtual reality;wearable computers,mixed reality application;head mounted device;virtual background;gas turbine virtual reality application;computer generated image visualisation;VR device;mobile devices,,,,10,,15-Jan-21,,,IEEE,IEEE Conferences
The design and implementation of the multi-screen interaction service architecture for the Real-Time streaming media,X. Xie; Z. Yu; K. Wang,"The Shandong Provincial Engineering Center of Health Informatics, Qingdao University, Qingdao, China; The Shandong Provincial Engineering Center of Health Informatics, Qingdao University, Qingdao, China; The Shandong Provincial Engineering Center of Health Informatics, Qingdao University, Qingdao, China",2013 Ninth International Conference on Natural Computation (ICNC),19-May-14,2013,,,1600,1604,"With the development of the Networks Convergence in China, the multi-screen interaction has been nearer and nearer to us. In order to build a unified service platform which supports the multi-screen interaction, A general application architecture is proposed for the Real-Time streaming media, which supports various platform and terminal. By employing virtual reality, MPEG-4 CODEC, interprocess communication technology and Real-Time streaming media transmission protocol, the Real-Time streaming media system is implemented, which verified the feasibility of the application architecture for multi-screen interaction service.",2157-9563,978-1-4673-4714-3,10.1109/ICNC.2013.6818237,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6818237,Real-Time;Streaming Media;Multi-Screen Interaction;Virtual-Reality;Encoding,Streaming media;Servers;Real-time systems;Protocols;Games;Transform coding;Virtual reality,computerised instrumentation;media streaming;virtual reality,multiscreen interaction service architecture;networks convergence;China;unified service platform;virtual reality;MPEG-4 CODEC;interprocess communication technology;real-time streaming media transmission protocol;real-time streaming media system,,,,12,,19-May-14,,,IEEE,IEEE Conferences
Getting around in google cardboard ‚Äì exploring navigation preferences with low-cost mobile VR,W. Powell; V. Powell; P. Brown; M. Cook; J. Uddin,University of Portsmouth; University of Portsmouth; University of Portsmouth; University of Portsmouth; University of Portsmouth,2016 IEEE 2nd Workshop on Everyday Virtual Reality (WEVR),23-Feb-17,2016,,,5,8,"In recent years there has been a paradigm shift in the uptake and use of Virtual Reality (VR). Advances in graphics rendering, and the introduction of low-cost VR headsets has brought VR into the reach of ordinary consumers. Google Cardboard VR viewers cost just a few dollars and work with most smart phones, enabling mobile VR to truly enter the domain of the everyday. However, these headsets are currently generally used for passive entertainment or viewing 360 degree media, and are not ideally suited to active exploration of a virtual space. In this paper we present our preliminary evaluation of three approaches to travel and navigation.",,978-1-5090-0840-7,10.1109/WEVR.2016.7859536,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7859536,Interaction;travel techniques;HMD;mobile VR;Google Cardboard;navigation,Navigation;Headphones;Switches;Google;Bluetooth;Mobile communication,mobile computing;rendering (computer graphics);virtual reality,Google cardboard;navigation preferences;low-cost mobile VR;virtual reality;graphics rendering;low-cost VR headsets;smart phones;360 degree media,,9,,14,,23-Feb-17,,,IEEE,IEEE Conferences
The Transreality Interaction Platform: Enabling Interaction across Physical and Virtual Reality,K. A. Martin; J. J. Laviola,"Dept. of Comput. Sci., Univ. of Central Florida, Orlando, FL, USA; Dept. of Comput. Sci., Univ. of Central Florida, Orlando, FL, USA","2016 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)",4-May-17,2016,,,177,186,"The convergence of the Internet of Things (IoT) and interactive systems will enable future interactive environments which transcend physical and virtual reality. Embedded Things provide sensors and actuators to virtualize the physical environment, while Interactive Things extend the virtualized environment with modalities for human interaction, ranging from tangible and wearable interfaces to immersive virtual and augmented reality interfaces. We introduce the Transreality Interaction Platform (TrIP) to enable service ecosystems which situate virtual objects alongside virtualized physical objects and allow for novel ad-hoc interactions between humans, virtual, and physical objects in a transreality environment. TrIP provides a generalized middleware platform addressing the unique challenges that arise in complex transreality systems which have yet to be fully explored in current IoT or HCI research. We describe the system architecture, data model, and query language for the platform and present a proof-of-concept implementation. We evaluate the performance of the implementation and demonstrate its use integrating embedded and interactive things for seamless interaction across physical and virtual realities.",,978-1-5090-5880-8,10.1109/iThings-GreenCom-CPSCom-SmartData.2016.54,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7917082,Internet of Things;Interactive Things;Transreality;Interactive Systems;Augmented Reality;Virtual Reality;Tangible User Interface,Solid modeling;Virtual reality;Human computer interaction;Ecosystems;Databases;Sensor systems and applications,interactive systems;Internet of Things;middleware;virtual reality,transreality interaction platform;virtual reality;Internet of Things;IoT;interactive systems;interactive environments;embedded things;actuators;physical environment;interactive things;human interaction;wearable interfaces;tangible interfaces;service ecosystems;virtual objects;generalized middleware platform,,4,,50,,4-May-17,,,IEEE,IEEE Conferences
Validation of the MR Simulation Approach for Evaluating the Effects of Immersion on Visual Analysis of Volume Data,B. Laha; D. A. Bowman; J. D. Schiffbauer,"Center for Human-Computer Interaction and the Department of Computer Science, Virginia Tech; Center for Human-Computer Interaction and the Department of Computer Science, Virginia Tech; Department of Geological Sciences, University of Missouri, Columbia, MO",IEEE Transactions on Visualization and Computer Graphics,13-Mar-13,2013,19,4,529,538,"In our research agenda to study the effects of immersion (level of fidelity) on various tasks in virtual reality (VR) systems, we have found that the most generalizable findings come not from direct comparisons of different technologies, but from controlled simulations of those technologies. We call this the mixed reality (MR) simulation approach. However, the validity of MR simulation, especially when different simulator platforms are used, can be questioned. In this paper, we report the results of an experiment examining the effects of field of regard (FOR) and head tracking on the analysis of volume visualized micro-CT datasets, and compare them with those from a previous study. The original study used a CAVE-like display as the MR simulator platform, while the present study used a high-end head-mounted display (HMD). Out of the 24 combinations of system characteristics and tasks tested on the two platforms, we found that the results produced by the two different MR simulators were similar in 20 cases. However, only one of the significant effects found in the original experiment for quantitative tasks was reproduced in the present study. Our observations provide evidence both for and against the validity of MR simulation, and give insight into the differences caused by different MR simulator platforms. The present experiment also examined new conditions not present in the original study, and produced new significant results, which confirm and extend previous existing knowledge on the effects of FOR and head tracking. We provide design guidelines for choosing display systems that can improve the effectiveness of volume visualization applications.",1941-0506,,10.1109/TVCG.2013.43,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479179,MR simulator;immersion;micro-CT;volume visualization;virtual reality;3D visualization;HMD;virtual environments.,Virtual reality;Visualization;Mice;Solid modeling;Head;Training;Computational modeling,data analysis;data visualisation;digital simulation;helmet mounted displays;virtual reality,MR simulation approach;immersion effects;visual volume data analysis;virtual reality systems;VR;mixed reality simulation approach;field of regard;FOR;head tracking;volume visualized microCT datasets;CAVE-like display;MR simulator platform;high-end head-mounted display;HMD;display systems;volume visualization applications,"Adolescent;Adult;Computer Graphics;Cues;Equipment Design;Equipment Failure Analysis;Female;Humans;Imaging, Three-Dimensional;Imaging, Three-Dimensional;Male;Task Performance and Analysis;Tomography, X-Ray Computed;User-Computer Interface;Visual Perception;Young Adult",15,,31,,13-Mar-13,,,IEEE,IEEE Journals
Design and Implementation of the Interactive Virtual Reality Touring System - A Case Study of Shulin Ji'an Temple in Taiwan,J. -H. Lo; M. -J. You,"Fo-Guang University,Department of Applied Informatics,Yilan,Taiwan,26247; Fo-Guang University,Department of Applied Informatics,Yilan,Taiwan,26247",202020 3rd IEEE International Conference on Knowledge Innovation and Invention (ICKII),18-Jan-21,2020,,,115,117,"Most current tour guiding methods for Taiwanese temples employ graphic webpage frameworks combined with captioned pictures for introduction. This type of tour guiding lacks interactive presence. In addition, the audience may not be able to focus on browsing webpages or learn essential information from the introduction. This study adopted the Delphi method to evaluate the current developed system. This system was aimed at designing VR-based interaction that differs from conventional tour guiding methods to aid users in viewing the display space from their viewpoints. Users can not only control camera view angles but also select the paths and guiding information as if they were walking in the temple. The analysis results revealed that in general, the users perceived Web VR tour guiding as convenient and easy to use. The display and content of the tour guiding system presented clear information to the users, aiding them in gaining further understanding of the introduced item. Finally, the study results can serve as a reference for design research on VR applications in tour guiding.",,978-1-7281-9333-5,10.1109/ICKII50300.2020.9318862,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9318862,A-Frame;Delphi method;Questionnaire for User Interface Satisfaction (QUIS);Virtual Reality (VR),Internet;Technological innovation;Social networking (online);Graphics;Statistical analysis;Cultural differences;Usability,interactive systems;Internet;virtual reality,interactive virtual reality touring system;Taiwanese temples;graphic webpage frameworks;captioned pictures;interactive presence;webpages;Delphi method;VR-based interaction;conventional tour;camera view angles;guiding information;Web VR tour;tour guiding system;design research;Shulin Ji'an Temple,,,,8,,18-Jan-21,,,IEEE,IEEE Conferences
VR Dodge-ball: Application of Real-time Gesture Detection from Wearables to ExerGaming,S. Ishii; M. Luimula; A. Yokokubo; G. Lopez,"Aoyama Gakuin University 5-10-1 Fuchinobe,Chuo-ku, Sagamihara-shi, Kanagawa,Japan; Turku University of Applied Sciences Joukahaisenkatu 3C,Turku,Finland,20520; Aoyama Gakuin University 5-10-1 Fuchinobe,Chuo-ku, Sagamihara-shi, Kanagawa,Japan; Aoyama Gakuin University 5-10-1 Fuchinobe,Chuo-ku, Sagamihara-shi, Kanagawa,Japan",2020 11th IEEE International Conference on Cognitive Infocommunications (CogInfoCom),2-Nov-20,2020,,,81,82,"Wearable technologies are applied to various areas nowadays, including health care and physical training. In previous work, we developed ExerSense, an algorithm to segment, classify, and count different predefined motions in real-time using correlation of acceleration. Using ExerSense, we developed a Virtual Reality (VR) Dodge-ball game. A watch-like wearable device is mounted to the right wrist and connected wireless to a head-mounted display (HMD). ExerSense enables to recognize real-time ball throwing gesture. Dodging opponent's ball in 3-Dimensional virtual space is detected using the sensors embedded in the HMD. We found that wearable devices have an advantage for virtual exergames against the camera-based approaches: there is no space and place limitation. Additionally, the study shows that exergames could be implemented with only general usage devices.",2380-7350,978-1-7281-8213-1,10.1109/CogInfoCom50765.2020.9237824,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237824,,Wrist;Wireless communication;Wireless sensor networks;Wearable computers;Resists;Virtual reality;Real-time systems,computer games;gesture recognition;helmet mounted displays;human computer interaction;mobile computing;motion sensors;pattern classification;real-time systems;sensor fusion;virtual reality;wearable computers,health care;physical training;ExerSense;motion segmentation;head mounted display;wearable devices;virtual exergames;3-dimensional virtual space;virtual reality dodge ball game;real time gesture detection;VR Dodge ball;motion classification;gesture recognition;embedded sensors,,,,8,,2-Nov-20,,,IEEE,IEEE Conferences
Underwater integral photography,N. Maki; K. Yanaka,Kanagawa Institute of Technology; Kanagawa Institute of Technology,2015 IEEE Virtual Reality (VR),27-Aug-15,2015,,,343,344,"A novel integral photography (IP) system in which the amount of popping out is more than three times larger than usual is demonstrated in this study. If autostereoscopic display is introduced into virtual reality, IP is an ideal candidate because not only the horizontal but also the vertical parallax can be obtained. However, the amount of popping out obtained by IP is generally far less than that obtained by head-mounted display because the ray density decreases when the viewer is distant from the fly's eye lens. Although a solution is to extend the focal length of the fly's eye lens, this lens is difficult to manufacture. We address this problem by simply immersing the fly's eye lens into water to extend the effective focal length.",2375-5334,978-1-4799-1727-3,10.1109/VR.2015.7223436,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223436,3D display;autostereoscopic display;integral photography,Lenses;IP networks;Photography;Virtual reality;Three-dimensional displays;Rendering (computer graphics);Human computer interaction,digital photography;geophysics computing;human computer interaction;oceanographic techniques;three-dimensional displays;virtual reality,underwater integral photography system;IP system;virtual reality;autostereoscopic display;vertical parallax;head-mounted display;fly eye lens;focal length;ray density,,1,,4,,27-Aug-15,,,IEEE,IEEE Conferences
Latency and User Performance in Virtual Environments and Augmented Reality,S. R. Ellis,"NASA Ames Res. Center, Moffett Field, CA, USA",2009 13th IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications,28-Dec-09,2009,,,69,69,"System rendering latency has been recognized by senior researchers, such as Professor Fredrick Brooks of UNC (Turing Award 1999), as a major factor limiting the realism and utility of head-referenced display systems. Latency has been shown to reduce the user's sense of immersion within a virtual environment, to disturb user interaction with virtual objects, and to contribute to motion sickness during some simulation tasks. Latency, however, is not just an issue for external display systems since finite nerve conduction rates and variation in transduction times in the human body's sensors also pose problems for latency management within the nervous system. Some of the phenomena arising from the brain's handling of sensory asynchrony due to latency will be discussed as a prelude to consideration of the effects of latency in interactive displays. The causes and consequences of the erroneous movement that appears in displays due to latency will be illustrated with examples of the user performance impact provided by several experiments. These experiments will review the generality of user sensitivity to latency when users judge either object or environment stability. Hardware and signal processing countermeasures will also be discussed. In particular the tuning of a simple extrapolative predictive filter not using a dynamic movement model will be presented. Results show that it is possible to adjust this filter so that the appearance of some latencies may be hidden without the introduction of perceptual artifacts such as overshoot. Several examples of the effects of user performance will be illustrated by three-dimensional tracking and tracing tasks executed in virtual environments. These experiments demonstrate classic phenomena known from work on manual control and show the need for very responsive systems if they are intended to support precise manipulation. The practical benefits of removing interfering latencies from interactive systems will be emphasized with some classic final examples from surgical telerobotics and human-computer interaction.",1550-6525,978-0-7695-3868-6,10.1109/DS-RT.2009.44,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5361782,,Delay;Virtual environment;Augmented reality;Displays;Filters;Limiting;Brain modeling;Humans;Sensor phenomena and characterization;Sensor systems,augmented reality;interactive systems,user performance;virtual environments;augmented reality;system rendering latency;motion sickness;nervous system;sensory asynchrony;extrapolative predictive filter;interactive systems,,,,,,28-Dec-09,,,IEEE,IEEE Conferences
The role of latency in the validity of AR simulation,C. Lee; S. Bonebrake; D. A. Bowman; T. H√∂llerer,"University of California, Santa Barbara; University of California, Santa Barbara; Virginia Tech; University of California, Santa Barbara",2010 IEEE Virtual Reality Conference (VR),8-Apr-10,2010,,,11,18,"It is extremely challenging to run controlled studies comparing multiple Augmented Reality (AR) systems. We use an AR simulation approach, in which a Virtual Reality (VR) system is used to simulate multiple AR systems. To investigate the validity of this approach, in our first experiment we carefully replicated a well-known study by Ellis et al. using our simulator, obtaining comparable results. We include a discussion on general issues we encountered with replicating a prior study. In our second experiment further exploring the validity of AR simulation, we investigated the effects of simulator latency on the results from experiments conducted in an AR simulator. We found simulator latency to have a significant effect on 3D tracing, however there was no interaction between simulator latency and artificial latency. Based on the results from these two experiments, we conclude that simulator latency is not inconsequential in determining task performance. Simulating visual registration is not sufficient to simulate the overall perception of registration errors in an AR system. We also need to keep simulator latency at a minimum. We discuss the impact of these results on the use of the AR simulation approach.",2375-5334,978-1-4244-6238-4,10.1109/VR.2010.5444820,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444820,I.3.7 [Three-Dimensional Graphics and Realism]: Virtual Reality-AR Simulation;I.3.6 [Methodology and Techniques]: Device independence-Replication,Delay;Virtual reality;Computational modeling;Hardware;Graphics;Augmented reality;Computer displays;Degradation;Software performance;Jitter,augmented reality;simulation,multiple augmented reality simulation;virtual reality;simulator latency;3D tracing;artificial latency;registration errors,,26,,14,,8-Apr-10,,,IEEE,IEEE Conferences
Robot Competition to Evaluate Guidance Skill for General Users in VR Environment,T. Inamura; Y. Mizuchi,"The Graduate University for Advanced Studies, National Institute of Informatics SOKENDAI, Tokyo, Japan; National Institute of Informatics, Tokyo, Japan",2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI),25-Mar-19,2019,,,552,553,"Robot competition such as RoboCup@Home is one of the most effective ways to evaluate the performance of human-robot interaction; however, it takes a lot of costs for real robot maintenance and the practice of evaluation sessions. We have proposed a simulation software to evaluate human-robot interaction in daily life environment based on immersive virtual reality. In this paper, we design a task named `human navigation' in which the evaluation requires a subjective impression by the users. Through a substantiative experiment, we confirmed that the proposed task and system reduced the cost for the practice of the competition.",2167-2148,978-1-5386-8555-6,10.1109/HRI.2019.8673218,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8673218,Natural Language Generation;Guidance;Robot Competition,Robots;Task analysis;Human-robot interaction;Software;Solid modeling;Navigation;Natural languages,control engineering computing;human-robot interaction;robot programming;virtual reality,robot competition;general users;VR environment;RoboCup@Home;human-robot interaction;robot maintenance;human navigation;guidance skill evaluation;software simulation,,,,3,,25-Mar-19,,,IEEE,IEEE Conferences
Development and Analysis of Simulation Virtual Online Guiding Resources based on VR Technology,C. Hu; C. Li,"Guangzhou College of Technology and Business,Guangzhou,China,510850; Guangzhou College of Technology and Business,Guangzhou,China,510850",2020 3rd International Conference on Intelligent Sustainable Systems (ICISS),18-Jan-21,2020,,,29,33,"Development and the analysis of simulation virtual online guiding resources based on VR technology is conducted in this paper. MR can easily complete human body modeling, as if it has a perspective eye, directly hitting the anatomical structure of the human body, and can interact with holographic images in real time through gestures, voice, peripherals, etc., and is in the theoretical study and practical exercise of general education both have positive and broad application prospects. In this research work, the face recognition, data mining and intelligent interaction models are combined to construct the efficient system. The experiment results have reflected the high accuracy and the core robustness. This proves the efficiency of the proposed model.",,978-1-7281-7089-3,10.1109/ICISS49785.2020.9316109,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9316109,Virtual Reality;Data Simulation;Data Mining;Online Guiding;Resource Mining,Face recognition;Solid modeling;Feature extraction;Training;Biological system modeling;Real-time systems;Face detection,data mining;face recognition;solid modelling;virtual reality,face recognition;intelligent interaction models;data mining;holographic images;anatomical structure;perspective eye;human body modeling;VR technology;simulation virtual online guiding resources,,,,19,,18-Jan-21,,,IEEE,IEEE Conferences
You Shall Not Pass: Non-Intrusive Feedback for Virtual Walls in VR Environments with Room-Scale Mapping,M. Boldt; M. Bonfert; I. Lehne; M. Cahnbley; K. Korschinq; L. Bikas; S. Finke; M. Hanci; V. Kraft; B. Liu; T. Nguyen; A. Panova; R. Singh; A. Steenbergen; R. Malaka; J. Smeddinck,"University of the Arts Bremen, Germany; University of Bremen, Germany; University of Bremen, Germany; University of Bremen, Germany; Univ. of Bremen, Bremen, Germany; University of Bremen, Germany; University of Bremen, Germany; University of Bremen, Germany; University of Bremen, Germany; University of Bremen, Germany; University of Bremen, Germany; University of Bremen, Germany; University of Bremen, Germany; University of Bremen, Germany; University of Bremen, Germany; University of Bremen, Germany",2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),30-Aug-18,2018,,,143,150,"Room-scale mapping facilitates natural locomotion in virtual reality (VR), but it creates a problem when encountering virtual walls. In traditional video games, player avatars can simply be prevented from moving through walls. This is not possible in VR with room-scale mapping due to the lack of physical boundaries. Game design is either limited by avoiding walls, or the players might ignore them, which endangers the immersion and the overall game experience. To prevent players from walking through walls, we propose a combination of auditory, visual, and vibrotactile feedback for wall collisions. This solution can be implemented with standard game engine features, does not require any additional hardware or sensors, and is independent of game concept and narrative. A between-group study with 46 participants showed that a large majority of players without the feedback did pass through virtual walls, while 87% of the participants with the feedback refrained from walking through walls. The study found no notable differences in game experience.",,978-1-5386-3365-6,10.1109/VR.2018.8446177,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446177,Virtual reality;virtual walls;tactile feedback;haptic feedback;visual feedback;auditory feedback;locomotion;game design;K.8.0 [Personal Computing]: General - games;H.5.2 [Information interfaces and presentation]: User Interfaces. - Interaction styles,Games;Legged locomotion;Visualization;Hardware;Haptic interfaces;Resists;Vibrations,avatars;computer games;virtual reality,game concept;narrative;players;virtual walls;game experience;nonintrusive feedback;VR environments;virtual reality;traditional video games;player avatars;game design;avoiding walls;wall collisions;standard game engine features;room-scale mapping;natural locomotion,,,,29,,30-Aug-18,,,IEEE,IEEE Conferences
Corrective feedback for depth perception in CAVE-like systems,A. K. T. Ng; L. K. Y. Chan; H. Y. K. Lau,"The University of Hong Kong, Hong Kong, China; The University of Hong Kong, Hong Kong, China; The University of Hong Kong, Hong Kong, China",2017 IEEE Virtual Reality (VR),6-Apr-17,2017,,,293,294,"The perceived distance estimation in an immersive virtual reality system is generally underestimated to the actual distance. Approaches had been found to provide users with better dimensional perception. One method used in head-mounted displays is to interact by walking with visual feedback, but it is not suitable for a CAVE-like system, like imseCAVE, with confined spaces for walking. A verbal corrective feedback mechanism is proposed. The result shows that estimation accuracy generally improves after eight feedback trials although some estimations become overestimated. One possible explanation is the need of more verbal feedback trials. Further research on top-down approach for improvement in depth perception is suggested.",2375-5334,978-1-5090-6647-6,10.1109/VR.2017.7892292,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892292,Distance estimation;error correction;training from feedback;CAVE-like systems;imseCAVE,Estimation;Training;Legged locomotion;Virtual environments;Three-dimensional displays;Visualization,helmet mounted displays;human computer interaction;virtual reality,depth perception;CAVE-like systems;perceived distance estimation;immersive virtual reality system;dimensional perception;head-mounted displays;visual feedback;imseCAVE;verbal corrective feedback;cave automatic virtual environment,,2,,7,,6-Apr-17,,,IEEE,IEEE Conferences
"Interactive, immersive visualization for indoor environments: use of augmented reality, human-computer interaction and building simulation",A. Malkawi; R. Srinivasan; B. Jackson; Yun Yi; Kin Chan; S. Angelov,"Dept. of Archit., Pennsylvania Univ., Philadelphia, PA, USA; Dept. of Archit., Pennsylvania Univ., Philadelphia, PA, USA; NA; NA; NA; NA","Proceedings. Eighth International Conference on Information Visualisation, 2004. IV 2004.",9-Aug-04,2004,,,833,838,"We present an interactive gesture recognition-based, immersive augmented reality system visualizing computational fluid dynamics (CFD) datasets of indoor environments. CFD simulation is used to predict the indoor environments and assess their response to specific internal and external conditions. To enable efficient visualization of CFD datasets in actual-space, an augmented reality system was integrated with a CFD simulation engine. To facilitate efficient data manipulation of the simulated post-processed CFD data and to increase the user-control of the immersive environment, a new intuitive method of human-computer interaction (HCI) has been incorporated. A gesture recognition system was integrated with the augmented reality-CFD structure to transform hand-postural data into a general description of hand-shape, through forward kinematics and computation of hand segment positions and their joint angles. This enabled real-time interactions between users and simulated CFD results in actual-space.",1093-9547,0-7695-2177-0,10.1109/IV.2004.1320237,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1320237,,Indoor environments;Augmented reality;Data visualization;Computational fluid dynamics;Buildings;Computational modeling;Human computer interaction;Computer simulation;Virtual reality;Pipelines,human computer interaction;data visualisation;digital simulation;gesture recognition;augmented reality;computational fluid dynamics;real-time systems,interactive immersive visualization;augmented reality;human-computer interaction;building simulation;interactive gesture recognition;computational fluid dynamics simulation;computational fluid dynamics visualization;hand-postural data transformation;hand segment positions;real-time interactions,,4,,26,,9-Aug-04,,,IEEE,IEEE Conferences
wavEMS: Improving Signal Variation Freedom of Electrical Muscle Stimulation,M. Kono; J. Rekimoto,"The University of Tokyo; The University of Tokyo, Sony Computer Science Laboratories, Inc.",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,1529,1532,"There has been a long history in electrical muscle stimulation (EMS), which has been used for medical and interaction purposes. Human-computer interaction (HCI) researchers are now working on various applications, including virtual reality (VR), notification, and learning. For the electric signals applied to the human body, various types of waveforms have been considered and tested. In typical applications, pulses with short duration are applied, however, many perspectives are required to be considered. In addition to the duration and polarity of the pulse/waves, the wave shapes can also be an essential factor to consider. A problem of conventional EMS toolkits and systems are that they have a limitation to the variety of signals that it can produce. For example, some may be limited to monophonic pulses. Furthermore, they are usually limited to rectangular pulses and a limited range of frequencies, and other waveforms cannot be produced. These kinds of limitations make us challenging to consider variations of EMS signals in HCI research and applications. The purpose of ‚ÄúwavEMS‚Äù is to encourage testing of a variety of waveforms for EMS, which can be manipulated through audio output. We believe that this can help improve HCI applications, and to open up new application areas.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8798102,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798102,Human-centered computing;Human computer interaction (HCI);Interaction devices;Haptic devices;General and reference;Document types;General literature,Energy management;Human computer interaction;Medical services;Muscles;Safety;History,electromyography;human computer interaction;medical signal processing;virtual reality,EMS signals;wavEMS;HCI applications;electrical muscle stimulation;medical interaction purposes;virtual reality;electric signals;human body;wave shapes;monophonic pulses;rectangular pulses;human computer interaction researchers;signal variation freedom;EMS toolkits;VR;waves polarity,,,,34,,15-Aug-19,,,IEEE,IEEE Conferences
Robust optical see-through head-mounted display calibration: Taking anisotropic nature of user interaction errors into account,E. Azimi; L. Qian; P. Kazanzides; N. Navab,"Johns Hopkins Univ., USA; Johns Hopkins Univ., USA; Johns Hopkins Univ., USA; Johns Hopkins Univ., USA, TU M√ºnchen, Germany",2017 IEEE Virtual Reality (VR),6-Apr-17,2017,,,219,220,"Uncertainty in measurement of point correspondences negatively affects the accuracy and precision in the calibration of head-mounted displays (HMD). In general, the distribution of alignment errors for optical see-through calibration are not isotropic, and one can estimate its distribution based on interaction requirements of a given calibration process and the user's measurable head motion and hand-eye coordination characteristics. Current calibration methods, however, mostly utilize the Direct Linear Transformation (DLT) method which minimizes Euclidean distances for HMD projection matrix estimation, disregarding the anisotropicity in the alignment errors. We utilize the error covariance in order to take the anisotropic nature of error distribution into account. The main hypothesis of this study is that using Mahalonobis distance within the nonlinear optimization can improve the accuracy of the HMD calibration. The simulation results indicate that our new method outperforms the standard DLT method both in accuracy and precision, and is more robust against user alignment errors. To the best of our knowledge, this is the first time that anisotropic noise has been accommodated in the optical see-through HMD calibration.",2375-5334,978-1-5090-6647-6,10.1109/VR.2017.7892255,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892255,augmented reality;HMD;calibration;error propagation;Mahalonobis distance,Calibration;Resists;Robustness;Adaptive optics;Nonlinear optics;Standards;Uncertainty,augmented reality;calibration;helmet mounted displays;matrix algebra;nonlinear programming;user interfaces,robust optical see-through head-mounted display calibration;user interaction errors;augmented reality;point correspondence measurement;alignment error distribution;user measurable head motion;hand-eye coordination characteristics;direct linear transformation method;Euclidean distances;HMD projection matrix estimation;alignment error anisotropicity;error covariance;Mahalonobis distance;nonlinear optimization;standard DLT method;anisotropic noise,,5,,4,,6-Apr-17,,,IEEE,IEEE Conferences
Identifying Accessibility Conditions for Children with Multiple Disabilities: A Virtual Reality Wheelchair Simulator,N. Rodriguez,L1RMM - University of Montpellier - CNRS,2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),29-Apr-19,2018,,,370,372,"Training is one of the main domain applications of Virtual Reality (VR). Simulation and visual realism provide training situations very close to practice with real systems while reducing cost and with greater safety. Furthermore, VR offers the possibility of change time or space scales, visualize from different perspectives, experience inaccessible real environments, all under the user's control, without risks, at her own pace. This allows to develop skills and to have confidence to work thereafter in real conditions with real equipment. Interaction technologies are now more widely available and affordable. But generally devices are conceived for ‚Äústandard‚Äù people leaving behind people with impairments and further accentuating the digital gap. In this paper, we present our work in the development of an accessible wheelchair simulator designed to allow children with multiple disabilities to familiarize themselves with the wheelchair, and practitioners to better understand children capabilities.",,978-1-5386-7592-2,10.1109/ISMAR-Adjunct.2018.00107,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699276,"virtual reality;simulator;disability;multiple disabilities;wheelchair;learning;augmented and alternative communication;interaction devices;I.3.1 [Computer Graphics]: Hardware Architecture ‚Äî Input devices;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism ‚Äì Virtual reality;H.5.1 [Information Interfaces And Presentation]: Multimedia Information Systems ‚Äî Artificial, augmented, and virtual realities;H.5.2 [Information Interfaces And Presentation]: User Interfaces ‚Äî Input devices and strategies",Wheelchairs;Virtual reality;Tools;Solid modeling;Visualization;Games;Adaptation models,computer based training;computer simulation;handicapped aids;virtual reality;wheelchairs,accessibility conditions;VR;visual realism;interaction technologies;accessible wheelchair simulator;virtual reality wheelchair simulator;children with multiple disabilities,,,,12,,29-Apr-19,,,IEEE,IEEE Conferences
A Non-Stationary Office Desk Substitution for Desk-Based and HMD-Projected Virtual Reality,D. Zielasko; B. Weyers; T. W. Kuhlen,"Visual Computing Institute, RWTH Aachen University, JARA-HPC, Aachen, Germany; University of Trier, Germany; Visual Computing Institute, RWTH Aachen University, JARA-HPC, Aachen, Germany",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,1884,1889,"The ongoing migration of HMDs to the consumer market also allows the integration of immersive environments into analysis workflows that are often bound to an (office) desk. However, a critical factor when considering VR solutions for professional applications is the prevention of cybersickness. In the given scenario the user is usually seated and the surrounding real world environment is very dominant, where the most dominant part is maybe the desk itself. Including this desk in the virtual environment could serve as a resting frame and thus reduce cybersickness next to a lot of further possibilities. In this work, we evaluate the feasibility of a substitution like this in the context of a visual data analysis task involving travel, and measure the impact on cybersickness as well as the general task performance and presence. In the conducted user study ( n=52), surprisingly, and partially in contradiction to existing work, we found no significant differences for those core measures between the control condition without a virtual table and the condition containing a virtual table. However, the results also support the inclusion of a virtual table in desk-based use cases.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8797837,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797837,Human-centered concepts [Human computer interaction (HCI)]: Interaction paradigms‚ÄîVirtual reality;Human-centered concepts [Human computer interaction (HCI)]: Visualization‚ÄîEmpirical studies in visualization,Task analysis;Data analysis;Virtual environments;Data visualization;Visualization;Three-dimensional displays,data analysis;helmet mounted displays;user interfaces;virtual reality,nonstationary office desk substitution;HMD-projected virtual reality;consumer market;VR solutions;professional applications;cybersickness;virtual environment;visual data analysis task;virtual table;desk-based use cases,,1,,32,,15-Aug-19,,,IEEE,IEEE Conferences
Multiuser Interaction with Hybrid VR and AR for Cultural Heritage Objects,Y. Li; E. Ch‚Äông; S. Cai; S. See,"International Doctoral Innovation Centre & NVIDIA Joint-Lab on Mixed Reality, University of Nottingham, Ningbo, China; NVIDIA Joint-Lab on Mixed Reality, University of Nottingham, Ningbo, China; Faculty of Humanities and Social Sciences & & NVIDIA Joint-Lab on Mixed Reality, University of Nottingham, Ningbo, China; NVIDIA AI Technology Centre, NVIDIA, Singapore",2018 3rd Digital Heritage International Congress (DigitalHERITAGE) held jointly with 2018 24th International Conference on Virtual Systems & Multimedia (VSMM 2018),26-Aug-19,2018,,,1,8,"This research investigates the factors and ways in which users initiate conversations and engage in interactions in a hybrid virtual environment using a combination of Virtual Reality (VR) and Augmented Reality (AR) devices. The research was done in the `spirit of the ancient Silk Road' where trade brought in exchange of ideas, cultural influence and cross-border communications. The notion of a 21st century Silk Road is necessarily digital, over the Internet and based around 3D cultural heritage objects. Digi-Capital's Report forecasts the revenue of AR and VR to be US$150b by 2020. We projected that VR and AR will become pervasive, much like the Social Web and the universal ubiquity of mobile devices such as smartphones and wearables. Here, we conducted a user study exploring users' acceptance of the use of hybrid VR and AR for cultural heritage, and investigated the social nature of multiple co-located user interaction. We adapted the UTAUT questionnaire in our experiment and found that social influence has positive effects on performance expectancy and effort expectancy, which generate positive effects on user behavioural intention. This study pioneers the future design and use of hybrid VR and AR technology in cultural heritage specifically, and in other application areas generally by highlighting the significant role that social influence plays in enhancing users' behavioural intention facilitated by different immersive devices.",,978-1-7281-0292-4,10.1109/DigitalHeritage.2018.8810126,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8810126,Virtual reality;augmented reality;hybrid VR AR;technology acceptance;interaction design;social interaction;cultural heritage;heritage objects,Cultural differences;Virtual environments;Roads;Global communication;Augmented reality;History,augmented reality;cultural aspects;history;human computer interaction;Internet;mobile computing;user interfaces,hybrid virtual environment;cross-border communications;mobile devices;user behavioural intention;multiuser interaction;social Web;immersive devices;hybrid VR;hybrid AR;virtual reality;augmented reality devices;3D cultural heritage objects;digi-capital's report;smartphones;multiple co-located user interaction;UTAUT questionnaire,,,,25,,26-Aug-19,,,IEEE,IEEE Conferences
Latency Measurement in Head-Mounted Virtual Environments,J. A. Jones; E. Luckett; T. Key; N. Newsome,University of Mississippi; University of Mississippi; Rust College; Clemson University,2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,1000,1001,"In this paper, we discuss a generalizable method to measure end-to-end latency. This is the length of time that elapses between when a real-world movement occurs and when the pixels within a head-mounted display are updated to reflect this movement. The method described here utilizes components commonly available at electronics and hobby shops. We demonstrate this measurement method using an HTC Vive and discuss the influence of its low-persistence display on latency measurement.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8798361,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798361,Human-centered computing;Interaction paradigms;Virtual reality;Visualization;Visualization design and evaluation methods,Photodiodes;Resists;Oscilloscopes;Liquid crystal displays;Virtual environments;Cameras,helmet mounted displays;virtual reality,real-world movement;head-mounted display;latency measurement;head-mounted virtual environments;generalizable method;HTC Vive,,2,,3,,15-Aug-19,,,IEEE,IEEE Conferences
Three Haptic Shape-Feedback Controllers for Virtual Reality,M. Sinclair; E. Ofek; C. Holz; I. Choi; E. Whitmire; E. Strasnick; H. Benko,"Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA",2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),30-Aug-18,2018,,,777,778,"We present three new novel haptic controllers that render shape force feedback during interaction. 1) CLAW is a multi-purpose controller that renders tactile forces for common hand interactions, such as grasping, touching, and triggering grasped objects. 2) Haptic Revolver is a general-purpose handheld VR controller that renders touch contact with virtual surfaces, motion shear along a surface, textures, and shapes using interchangeable wheels. 3) Haptic Links haptic render shape feedback between two controllers using variable-stiffness locking mechanisms to provide force feedback for grasping and interacting with two-handed objects such as wind instruments, steering wheels, handle bars, or bow and arrow.",,978-1-5386-3365-6,10.1109/VR.2018.8446399,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446399,Haptics;Virtual Reality;Controller;#K.6.1 [Management of Computing and Information Systems];Project and People Management;Life Cycle;K.7.m [The Computing Profession];Miscellaneous-Ethics,Conferences;Virtual reality;Three-dimensional displays;User interfaces,force feedback;haptic interfaces;rendering (computer graphics);virtual reality,virtual reality;multipurpose controller;common hand interactions;grasped objects;general-purpose handheld VR controller;virtual surfaces;shape feedback;two-handed objects;tactile force;haptic shape-feedback controllers;shape force feedback;Haptic Revolver;CLAW controller;rendering,,1,,9,,30-Aug-18,,,IEEE,IEEE Conferences
Improving human interactions in complex product development,O. Waller; F. Isnard; G. Dodds,"Dept. of Electr. & Electron. Eng., Queen's Univ., Belfast, UK; NA; NA",IEE Colloquium on Virtual Reality Personal Mobile and Practical Applications,6-Aug-02,1998,,,1-Jun,7-Jun,"It is possible, using virtual reality (VR), to create virtual prototypes which can be fully tested with respect to electrical, mechanical, aesthetic and ergonomic properties while the product is still in the design stage. Current VR software packages do not yet offer an idea solution to the problem of creating realistic virtual prototypes. This problem is especially true for large industrial products such as in the aerospace industry. These large products would especially benefit from virtual prototyping in areas such as maintenance, assembly and training. It is important to minimise the preparation and evaluation time in these short production runs and individually specified products. Three areas are examined: data reduction, economic conversion costs and real time implementation methods are discussed. These include task based reduction and more general compression methods. The use of human factors with intelligent responsive manikins is outlined along with a range of desirable features. Real environments require complex interactions and open systems with user specified code and debugging. The state of some VR systems are described and it is shown how research in these areas can overcome the current limitations of industrial virtual reality packages. The work is based on experience with large models, multiple VR packages and manikin interactions.",,,10.1049/ic:19980753,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=744430,,,virtual reality,human interactions;complex product development;virtual reality;virtual prototypes;electrical properties;mechanical properties;aesthetic properties;ergonomic properties;design stage;software packages;virtual prototyping;maintenance;assembly;training;data reduction;economic conversion costs;real time implementation methods;task based reduction;compression methods;human factors;intelligent responsive manikins;open systems;complex interactions;user specified code;debugging;industrial virtual reality packages;large models,,2,,,,6-Aug-02,,,IET,IET Conferences
Virtual-reality based visualization of cardiac arrhythmias on mobile devices,J. Greiner; T. Oesterlein; G. Lenis; O. D√∂ssel,"Institute of Biomedical Engineering, Karlsruhe Institute of Technology, Germany; Institute of Biomedical Engineering, Karlsruhe Institute of Technology, Germany; Institute of Biomedical Engineering, Karlsruhe Institute of Technology, Germany; Institute of Biomedical Engineering, Karlsruhe Institute of Technology, Germany",2016 Computing in Cardiology Conference (CinC),2-Mar-17,2016,,,1081,1084,"Computer simulations and imaging of human physiology and anatomy are effectively used for diagnostics and medical treatments and are thus a focus of scientific research. Suitable representation of data is a critical aspect to achieve best results. Therefore, we developed an interactive visualization scheme especially for the representation of cardiac arrhythmias based on a conventional mobile device and virtual reality (VR) goggles (Google Cardboard and Samsung Gear VR) in combination with a game engine. The aim of this paper is to raise awareness for this new technique, evaluate its potential and propose a general workflow for such a visualization environment. The use of a conventional mobile device in combination with VR goggles creates a portable and low-cost system, equipped with enough processing power and pixel density for many types of applications. The user can interact with the data through head movement or a secondary controller As current game engines support a wide range of additional input methods and controllers, the interaction method can be customized to fit the target audience. To evaluate this method, we conducted a survey with eight typical phenomena from the field of cardiac arrhythmias. The participants were asked to rate different performance aspects on a scale from one (very bad) to five (very good). All participants (N=27) rated the performance as fluent (median=5). Furthermore, most participants (70%) ranked the overall impression as very good (median=5). On the long run, the system can be used for education and presentations as well as improved planning and guidance of medical procedures.",2325-887X,978-1-5090-0895-7,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7868934,,Data visualization;Engines;Mobile handsets;Games;Computational modeling;Eye protection;Solid modeling,biomechanics;cardiology;computer games;medical disorders;medical image processing;mobile handsets;virtual reality,virtual reality-based visualization;cardiac arrhythmias;mobile devices;human physiology;anatomy;diagnostics;medical treatments;data representation;interactive visualization scheme;mobile device;VR goggles;Google Cardboard VR;Samsung Gear VR;game engine;pixel density;processing power;head movement;secondary controller,,,,9,,2-Mar-17,,,IEEE,IEEE Conferences
Scenario management in Web-based simulation,A. F. Seila; J. A. Miller,"Dept. of MIS, Georgia Univ., Athens, GA, USA; NA",WSC'99. 1999 Winter Simulation Conference Proceedings. 'Simulation - A Bridge to the Future' (Cat. No.99CH37038),6-Aug-02,1999,2,,1430,1437 vol.2,"Internet communications in general and the World-Wide Web specifically are revolutionizing the computer industry. Today, the Web is full of important documents and clever applets. Java applets and servlets are beginning to appear that provide useful and even mission critical applications. From the perspective of simulation, a future Web will be full of simulation models and large amounts of simulation-generated data. Many of the models will include two or three dimensional animation as well as virtual reality. Others will allow human interaction with simulation models to control or influence their execution no matter where the user is located in the world. Analysis of data from Web-based simulations involves greater degrees of freedom than traditional simulations. The number of simulation models available and the amount of simulation data are likely to be much greater. In order to assure the quality of data, the execution of models under a variety of scenarios should be well managed. Since the user community will also be larger, quality assurance should be delegated to agents responsible for defining scenarios and executing models. A major element of simulation analysis is the analysis of output data, which manages the execution of simulation models, in order to obtain statistical data of acceptable quality. Such data may be used to predict the performance of a single system, or to compare the performance of two or more alternative system designs using a single or multiple performance measures.",,0-7803-5780-9,10.1109/WSC.1999.816876,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=816876,,Computational modeling;Analytical models;Data analysis;Quality management;Internet;Computer industry;Java;Mission critical systems;Application software;Animation,Internet;Java;object-oriented programming;distributed programming;virtual reality;information resources;digital simulation,scenario management;Web-based simulation;Internet communications;World-Wide Web;Java applets;servlets;mission critical applications;animation;virtual reality;human interaction;simulation models;Web-based simulations;statistical data;multiple performance measures,,1,,12,,6-Aug-02,,,IEEE,IEEE Conferences
Virtual reality-based assessment and treatment interventions for the combat-injured service member,C. A. R√°bago; A. L. Pruziner; E. R. Esposito,"DoD-VA Extremity Trauma and Amputation Center of Excellence, and Center for the Intrepid, Brooke Army Medical Center, Fort Sam Houston, TX USA; DoD-VA Extremity Trauma and Amputation Center of Excellence, and Department of Rehabilitation, Walter Reed National Military Medical Center, Bethesda, MD USA; DoD-VA Extremity Trauma and Amputation Center of Excellence, and Center for the Intrepid, Brooke Army Medical Center, Fort Sam Houston, TX USA",2015 International Conference on Virtual Rehabilitation (ICVR),17-Dec-15,2015,,,3,3,"Summary form only given. This presentation will highlight clinical cases and empirical results from virtual reality (VR)-based rehabilitation programs at two military medical facilities. These programs utilize VR environments to detect and treat functional deficits often difficult to address with standard clinical methods. Injured service members seen at these facilities are often young and highly fit at the time of their injuries. Their injuries include single and multiple limb traumas such as amputation, burns, and limb salvage. Despite the severity of these injuries and associated co-morbidities, these individuals commonly set rehabilitation goals that include a return to competitive sports and/or military duty. Deficits described by these individuals, that can limit the achievement of these goals, can be difficult to detect and quantify with conventional clinical measures. Novel VR-based assessments, developed by our clinical research team, have helped identify functional deficits across multiple domains using ecologically-valid tasks. Further, VR-based treatment applications have been designed to address these deficits and progress patients toward their goals. In general, we have found that service members following traumatic brain injury, amputation, and severe limb trauma demonstrate significant increases in function with VR therapies. These VR interventions are based on well-established therapeutic techniques and can be used to promote functional interactions with challenging environments while maintaining full safeties and controls.",2331-9569,978-1-4799-8984-3,10.1109/ICVR.2015.7358631,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358631,,Extremities;Virtual reality;Standards;Brain injuries;Medical treatment;Safety,injuries;patient rehabilitation;virtual reality,virtual reality-based assessment;treatment intervention;combat-injured service member;virtual reality-based rehabilitation program;military medical facility;virtual reality environment;multiple limb trauma;amputation;limb salvage;competitive sport;military duty;traumatic brain injury;virtual reality therapY,,,,,,17-Dec-15,,,IEEE,IEEE Conferences
Virtual reality interfaces and population-specific models to mitigate public speaking anxiety,M. Yadav; M. N. Sakib; K. Feng; T. Chaspari; A. Behzadan,"HUBBS Lab, Texas A&M university College,Station,TX,USA; CIBER Lab, Texas A&M university College,Station,TX,USA; HUBBS Lab, Texas A&M university College,Station,TX,USA; HUBBS Lab, Texas A&M university College,Station,TX,USA; CIBER Lab, Texas A&M university College,Station,TX,USA",2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII),9-Dec-19,2019,,,1,7,"Public speaking is key to effectively exchanging ideas, persuading others, and making a tangible impact. Yet, public speaking anxiety (PSA) ranks as a top social phobia among many people. This paper leverages bio-behavioural indices captured from wearable devices and virtual reality (VR) interfaces to quantify PSA. The significance of individual-specific factors, such as general trait anxiety and personality, as well as contextual factors, such as age, gender, highest education, and native language, in moderating the association between bio-behavioral indices and PSA is further examined through group-based machine learning models. Results highlight the importance of including such factors for detecting PSA with the proposed group-based PSA models yielding Spearman's correlation of 0.55(p <; 0.05) between the actual and predicted state-based anxiety scores. This work further analyzes whether systematic exposure to public speaking tasks in the VR environment can help alleviate PSA. Results indicate that systematic exposure to public speaking in VR can alleviate PSA in terms of both self-reported (p <; 0.05) and physiological (p <; 0.05) indices. Findings of this study will enable researchers to better understand antedecedents and causes of PSA contributing to behavioral interventions using VR.",2156-8111,978-1-7281-3888-6,10.1109/ACII.2019.8925509,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8925509,public speaking anxiety;virtual reality;physiological signals;speech;wearable devices;group-based clustering,Public speaking;Physiology;Temperature measurement;Biological system modeling;Context modeling;Electrocardiography;Virtual reality,behavioural sciences computing;learning (artificial intelligence);medical computing;patient treatment;psychology;public speaking;virtual reality,public speaking anxiety;VR environment;trait anxiety;contextual factors;bio-behavioral indices;group-based machine learning models;group-based PSA models;public speaking tasks;virtual reality interfaces;population-specific models;bio-behavioural indices;wearable devices;state-based anxiety scores,,1,,46,,9-Dec-19,,,IEEE,IEEE Conferences
Immersive authoring of tangible augmented reality applications,G. A. Lee; C. Nelles; M. Billinghurst; G. J. Kim,"Virtual Reality Lab., Pohang Univ. of Sci. & Technol., South Korea; NA; NA; NA",Third IEEE and ACM International Symposium on Mixed and Augmented Reality,24-Jan-05,2004,,,172,181,"In this paper, we suggest a new approach for authoring tangible augmented reality applications, called 'immersive authoring.' The approach allows the user to carry out the authoring tasks within the AR application being built, so that the development and testing of the application can be done concurrently throughout the development process. We describe the functionalities and the interaction design for the proposed authoring system that are specifically targeted for intuitive specification of scenes and various object behaviors. Several cases of applications developed using the authoring system are presented. A small pilot user study was conducted to compare the proposed method to a non-immersive approach, and the results have shown that the users generally found it easier and faster to carry out authoring tasks in the immersive environment.",,0-7695-2191-6,10.1109/ISMAR.2004.34,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1383054,,Augmented reality;Authoring systems;Programming profession;Virtual reality;Testing;Layout;Application software;Software libraries;Humans;Educational programs,augmented reality;authoring systems,immersive authoring;tangible augmented reality;authoring tasks;AR application;interaction design;authoring system;immersive environment,,64,6,21,,24-Jan-05,,,IEEE,IEEE Conferences
Multi-agent Modeling of Biological Data Based on Virtual Reality,I. Hamdi; G. Querrec; I. R. Farah; M. B. Ahmed,"Laboratoire RIADI, l'Ecole Nationale des Sciences de l'Informatique, Campus Universitaire de la Manouba, 2010 Manouba, Tunisie. Fax: (+216)71600449, Tel: (+216)71600444, Ines.hamdi@riadi.rnu.tn; Equipe d'EBV, CER V (Centre Europeen de Realite Virtuelle)25 rue Claude Chappe BP 38 F-29280 PLOUZANE, France.; Laboratoire RIADI, l'Ecole Nationale des Sciences de l'Informatique,Campus Universitaire de la Manouba, 2010 Manouba, Tunisie.; Laboratoire RIADI, l'Ecole Nationale des Sciences de l'Informatique,Campus Universitaire de la Manouba, 2010 Manouba, Tunisie.",2006 2nd International Conference on Information & Communication Technologies,16-Oct-06,2006,2,,3046,3051,"Many applications related to various fields indeed require the use of temporal data referred in time. Unfortunately, the practical application of such systems is not achieved without difficulties. Complications of a technical but so conceptual nature generally appear. The spatial and temporal data present fundamental problems with the DBMS, not only because of the considerable size and the constant growth of these data, but also because of the complexity of the geometrical and topological relations between these data. From this, the spatio-temporal modeling represents many difficulties. The main goal of our work is to solve this problem in the biological domain and particularly the spatio-temporal modeling and visualisation of molecular and functional network. In order to do that, we propose a system based on multiagent system with the virtual reality allowing the user to interact with the three-dimensional image objects. As a computer-generated representation of a three-dimensional environment, virtual reality enables the user to view and manipulate the contents of an environment. Virtual reality is often referred to as the technology that gives a user the experience of being immersed in a computer-generated virtual world. Although virtual reality is a very useful application for examining and understanding complex data sets. In this paper, we started by the state of the art of the existing systems for modeling the biological data and their interactions (molecular and functional), then we described the multiagent architecture of the spatio-temporal modeling of molecular and functional interactions based on virtual reality techniques",,0-7803-9521-2,10.1109/ICTTA.2006.1684902,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1684902,,Biological system modeling;Virtual reality;Biology computing;Genetics;Computer networks;Computational modeling;Cells (biology);Computer simulation;Spatiotemporal phenomena;Bioinformatics,biology computing;computer graphics;multi-agent systems;virtual reality,multiagent system modeling;biological data modeling;virtual reality;spatio-temporal modeling;molecular network visualisation;functional network visualisation;three-dimensional image object;computer-generated virtual world;multiagent architecture;molecular interaction;functional interaction,,,,6,,16-Oct-06,,,IEEE,IEEE Conferences
Virtual Hands for Risk Prevention Integration in Human-Computer Interactions,M. Pouliquen; A. Bernard; J. Marsot,"IRCCyN - Ecole Centrale de Nantes, 1 rue de la No√´, BP 92101, 44321 Nantes Cedex 3, France; IRCCyN - Ecole Centrale de Nantes, 1 rue de la No√´, BP 92101, 44321 Nantes Cedex 3, France; INRS - Institut National de Recherche et de S√©curit√©, avenue de Bourgogne, BP 27, 54501 Vandoeuvre Cedex, France","2006 IEEE Symposium on Virtual Environments, Human-Computer Interfaces and Measurement Systems",30-Nov-06,2006,,,142,147,"The development of virtual reality offers new possibilities to better simulate and understand the human/system interactions. The current challenge is to take into account the human being in order to generalize the use of ergonomics in the design stage. We propose to improve the simulation of the interactions between man and machine by estimating the risk level of the working situation. After reviewing the previous work, we present our virtual physically-based hands which are coupled with a virtual press-brake by using a motion capture system. Thus, the operator can interact in real-time with the virtual environment. By integrating a dynamic risk index, we can also estimate the degree of hazard of the current working situation",1944-9410,1-4244-0242-5,10.1109/VECIMS.2006.250809,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4016682,Human-computer interactions;Virtual reality;Motion Capture;Risk prevention;Physically-based simulation,Virtual reality;Humans;Grasping;Virtual environment;Finite element methods;Anthropometry;Ergonomics;Hazards;Skeleton;Tendons,human computer interaction;virtual reality,virtual hands;risk prevention integration;human-computer interactions;virtual reality;ergonomics;virtual physically-based hands;virtual press-brake;motion capture system;dynamic risk index,,1,,22,,30-Nov-06,,,IEEE,IEEE Conferences
"VR and Empathy: The Bad, the Good, and the Paradoxical",M. Moroz; K. Krol,"University of Nevada, Reno; University of Cambridge",2018 IEEE Workshop on Augmented and Virtual Realities for Good (VAR4Good),16-Dec-18,2018,,,1,4,"Virtual reality (VR) is cited as offering the ultimate empathy machine [31]. This theory makes sense intuitively since VR enables a user to step in to another's shoes and experience the world as they do. We define this specific class of mental state as `emotional empathy' [49].The ability of VR to evoke emotional empathy is widely lauded as a good thing [18], [35], [43]. In this paper we invite labels such as `Luddites' and `technophobes' as we question the soundness of such claims. We instead offer warnings regarding employing VR is this manner and urge caution. Rather than dismiss the usefulness of VR in this realm we offer alternative implementation techniques in order to evoke more positive results in users.VR offers much utility for psychologists, psychiatrists, and neu-roscientists due to the ability it affords to alter cognition. While promoting the medium in general, we offer warnings regarding potential short and long term neurological impacts. We encourage increased research focus on the underlying neural mechanisms that underpin VR's successful multisensory hijack.",,978-1-5386-5977-9,10.1109/VAR4GOOD.2018.8576883,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576883,"Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality;Applied computing;Law, social and behavioral sciences;Psychology",Virtual reality;Psychology;Pain;Brain modeling;Solid modeling;Functional magnetic resonance imaging;Dairy products,cognition;neurophysiology;psychology;virtual reality,ultimate empathy machine;emotional empathy;VR;neural mechanisms;cognition;multisensory hijack;psychiatrists;psychologists;virtual reality,,1,,53,,16-Dec-18,,,IEEE,IEEE Conferences
Key requirements for CAVE simulations,S. M. Preddy; R. E. Nance,"Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA; Dept. of Comput. Sci., Virginia Polytech. Inst. & State Univ., Blacksburg, VA, USA",Proceedings of the Winter Simulation Conference,29-Jan-03,2002,1,,127,135 vol.1,"Virtual reality offers a new frontier for human interaction with simulation models. A virtual environment, such as that created with a CAVE, imposes either real-time or quasi-real-time performance on the simulation model. Beyond that general requirement, what others can be identified for simulation programs that drive a virtual reality or virtual environment interface? Based on experience with the Virginia Tech CAVE augmented by a literature search, we propose three key requirements for successful CAVE-based simulations: (1) portability among CAVE-specific input/output devices, (2) effective and efficient interprocess communication, and (3) overcoming the limitations associated with input/output device interaction. Each requirement is described in some detail to both explain and justify its inclusion. Limitations and near- and intermediate-term research needs are identified.",,0-7803-7614-5,10.1109/WSC.2002.1172876,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1172876,,Virtual environment;Humans;Computational modeling;Virtual reality;Buildings;Computer science;Professional communication;Education;Writing;Input variables,digital simulation;virtual reality;application program interfaces,CAVE simulations;virtual reality;human interaction;simulation models;real-time performance;quasi-real-time performance;virtual environment interface;Virginia Tech CAVE;CAVE-specific input/output devices;interprocess communication,,4,,18,,29-Jan-03,,,IEEE,IEEE Conferences
Evaluating Embodied Navigation in Virtual Reality Environments,J. DeYoung; J. Berry; S. Riggs; J. Wesson; L. C. Wertz,"Yale University, Center for Collaborative Arts and Media, New Haven CT, USA; Yale University, Center for Collaborative Arts and Media, New Haven CT, USA; Sunchaser Entertainment, New York, NY; USA; Yale University, Center for Collaborative Arts and Media, New Haven CT, USA; Yale University, Center for Collaborative Arts and Media, New Haven CT, USA","2018 IEEE Games, Entertainment, Media Conference (GEM)",1-Nov-18,2018,,,1,9,"Virtual reality has become more accessible and affordable to the general public in recent years, introducing the exciting potential of this technology to new audiences. However, the mechanisms of navigating within a virtual environment have primarily been constrained to handheld input devices akin to gaming controllers. For people unfamiliar with traditional gaming input devices, VR navigation devices are not intuitively mapped to real-world modes of locomotion and can be frustrating and disorienting. Designers have largely focused on utility (the ability to efficiently accomplish a task) to the detriment of usability (ease of use). The industry lacks an intuitive, universal method of navigation that can be easily learned by novice participants. Dr. Jakob Nielsen identified five factors that impact usability in human-computer interactions (HCI): learnability, efficiency, memorability, errors, and satisfaction. Previous research in virtual environment locomotion incorporated teaching time periods where the researchers explained the control devices to participants. We believe that this neglected one of the key usability factors in human-computer interactions: learnability, or the ability and ease to accomplish a task the first time a user encounters it. Our research focuses on comparing existing modes of navigation (game controller based) with a mode of controller-less fully embodied navigation between two demographics based on Nielsen's usability factors. Existing research has demonstrated little noticeable learnability difference between modes of rotation and lean-based navigation, and joystick navigation in VR [1]; however, similar study demonstrates that partially embodied leaning mechanics can positively affect sensory perception in VR [2]. While previous Studies in controller-less VR navigation methods have demonstrated an inclination toward subject motion sickness when controllers are removed [3], other research has yielded positive qualitative results (sans motion sickness) when partially embodied alternative controller systems are used [4]. Additional research into partially embodied alternative controller systems has, in fact, indicated a preference toward existing modes of controller-based joystick navigation in VR subjects [5]; however, when partially embodied leaning mechanics are combined with another mode of sensory perception, like foot haptics, self-motion perception (vection) is enhanced [6]. In this study, we test a fully embodied mode of navigation to evaluate whether a fully engaged body experiences more positive usability results according to HCI measures. We test our results within communities of self-identified gamers and non-gamers, evaluating navigation modes designed for joystick control pads, trigger-based teleportation, and controller-less embodied navigation. Our research inquires whether embodied navigation enhances usability in accordance with Nielsen's usability factors, specifically enabling easier access and engagement for inexperienced subj e ct s, compared with controller-based modes of navigation.",,978-1-5386-6304-2,10.1109/GEM.2018.8516499,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516499,,Navigation;Hardware;Games;Media;Usability;Virtual environments,computer games;human computer interaction;interactive devices;navigation;teaching;user interfaces;virtual reality,virtual reality environments;gaming controllers;VR navigation devices;real-world modes;human-computer interactions;virtual environment locomotion incorporated teaching time periods;control devices;key usability factors;game controller;Nielsen's usability factors;partially embodied leaning mechanics;controller-less VR navigation methods;controller-based joystick navigation;fully embodied mode;joystick control pads;controller-based modes;navigation modes;alternative controller systems;gaming input devices,,1,,6,,1-Nov-18,,,IEEE,IEEE Conferences
A Tactile Sensation Assisted VR Catheterization Training System for Operator‚Äôs Cognitive Skills Enhancement,Y. Wang; F. Yang; Y. Li; T. Yang; C. Ren; Z. Shi,"School of Electrical Engineering and Information, Southwest Petroleum University, Chengdu, China; School of Electrical Engineering and Information, Southwest Petroleum University, Chengdu, China; School of Electrical Engineering and Information, Southwest Petroleum University, Chengdu, China; General Hospital of Western Theater Command, Chengdu, China; School of Electrical Engineering and Information, Southwest Petroleum University, Chengdu, China; School of Electrical Engineering and Information, Southwest Petroleum University, Chengdu, China",IEEE Access,31-Mar-20,2020,8,,57180,57191,"In the clinical vascular interventional surgery, experienced surgeons usually rely on visual feedback to reason tool-tissue interaction, because haptic forces are easily contaminated by frictions between the catheter and the introducer sheath, which brings difficulty in collision force perceptions. Thus, cognitive skills are highly demanded for novice surgeons to thoroughly interpret the relative positions between tool and tissue in images and make appropriate decisions about further catheter motions in case of collisions. In this paper, an operator's cognitive skills training system has been introduced, which exploits the tactile sensation to reinforce the visualized spatial positions between catheter tip and vascular wall in the VR simulator. In cooperation with the collision alert module (CAM) in the VR simulator, the newly developed catheter manipulator can provide tactile sensations for novices when catheter tip is threaded beyond safety boundary, so that the VR exhibited tool-tissue interaction can be deliberately intensified. For demonstrating such tactile sensations adequate to strengthen visions, the system model has been established to facilitate the analysis in the perspective of operator's kinesthetic perception. A series of experiments have been conducted at last and the results reveal that the catheter manipulator can not only realize the accurate catheter motions but also provide the enough tactile sensations for novices. Moreover, statistical data prove that subjects under cognitive trainings have developed the ability to interpret the relative spatial positions between catheter tip and vascular wall. Such findings support that the operator's cognitive skills can be enhanced by the tactile reinforcement of VR visualized tool-tissue interaction.",2169-3536,,10.1109/ACCESS.2020.2982219,National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9043517,Catheterization training system;cognitive skills;tactile sensation;VR simulator;collision detection,Catheters;Training;Surgery;Haptic interfaces;Force;Manipulators,catheters;cognition;haptic interfaces;manipulators;medical computing;medical robotics;surgery;touch (physiological);virtual reality,statistical data;operator kinesthetic perception;operator cognitive skill training system;operator cognitive skill enhancement;VR visualized tool-tissue interaction;tactile reinforcement;relative spatial positions;cognitive trainings;catheter motions;system model;catheter manipulator;collision alert module;VR simulator;vascular wall;catheter tip;visualized spatial positions;novice surgeons;collision force perceptions;introducer sheath;haptic forces;visual feedback;experienced surgeons;clinical vascular interventional surgery;tactile sensation assisted VR catheterization training system,,,,32,CCBY,20-Mar-20,,,IEEE,IEEE Journals
GestAR: Real Time Gesture Interaction for AR with Egocentric View,S. Hegde; R. Perla; R. Hebbalaguppe; E. Hassan,"Smart Machines R&D Group, TCS Res., New Delhi, India; Smart Machines R&D Group, TCS Res., New Delhi, India; Smart Machines R&D Group, TCS Res., New Delhi, India; Smart Machines R&D Group, TCS Res., New Delhi, India",2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct),2-Feb-17,2016,,,262,267,"The existing, sophisticated AR gadgets1 in the market today are mostly exorbitantly priced. This limits their usage for the upcoming academic research institutes and also their reach to the mass market in general. Among the most popular and frugal head mounts, Google Cardboard (GC) and Wearality2 are video-see-through devices that can provide immersible AR and VR experiences with a smartphone. Stereo-rendering of camera feed and overlaid information on smartphone helps us experience AR with GC. These frugal devices have limited user-input capability, allowing user interactions with GC such as head tilting, magnetic trigger and conductive lever. Our paper proposes a reliable and intuitive gesture based interaction technique for these frugal devices. The hand gesture recognition employs the Gaussian Mixture Models (GMM) based on human skin pixels and tracks segmented foreground using optical flow to detect hand swipe direction for triggering a relevant event. Realtime performance is achieved by implementing the hand gesture recognition module on a smartphone and thus reducing the latency. We augment real-time hand gestures as new GC's interface with its evaluation done in terms of subjective metrics and with the available user interactions in GC.",,978-1-5090-3740-7,10.1109/ISMAR-Adjunct.2016.0090,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836511,H.5.1 [Information Interfaces and Presentation]: Artificial;Augmented;and Virtual Realities‚Äî; H.5.2 [Information Interfaces and Presentation]: User Interfaces‚ÄîInteraction Styles I.4.8 [Computing Methodologies]: Image Processing and Computer V,Gesture recognition;Feature extraction;Cameras;Magnetic resonance imaging;Inspection;Google;Adaptive optics,augmented reality;Gaussian processes;gesture recognition;image segmentation;image sequences;mixture models;rendering (computer graphics);stereo image processing;tracking,subjective metrics;GC interface;hand gesture recognition module;hand swipe direction detection;optical flow;segmented foreground tracking;human skin pixels;GMM;Gaussian mixture models;intuitive gesture based interaction;user interactions;smartphone helps;stereo-rendering;VR experiences;video-see-through devices;Wearality2;Google Cardboard;head mounts;AR gadgets;egocentric view;augmented reality;real time gesture interaction;GestAR,,7,,36,,2-Feb-17,,,IEEE,IEEE Conferences
An intelligent and modular sensing system for Augmented Reality application,M. F. Alam; S. Katsikas; S. Hadjiefthymiades,"Pervasive Computing Research, Dept. of Informatics and Telecommunications, National Kapodistrain University of Athens, Greece; Research and Development Electronics, Informatics and Telecommunications, Prisma Electronics SA, Athens, Greece; Pervasive Computing Research, Dept. of Informatics and Telecommunications, National Kapodistrian University of Athens, Greece",2015 9th International Conference on Sensing Technology (ICST),24-Mar-16,2015,,,850,855,"The scientific objective of this paper is to describe an innovative architecture of modular form in sensing and supervision system. In our study, a maintenance work at ATLAS detector in Large Hadron Collider at European Organization for Nuclear Research (CERN), Geneva, Switzerland has been considered. The research challenges lie in the development of real-time data-transmission, instantaneous analysis of data coming from different inputs, local intelligences in low power embedded system, interaction with augmented reality in multiple on-site users, complex interfaces, and portability. The proposed architecture is allocated with modular form. The prototype of this modular device is named a PSS (Personnel Supervision System) module. The hardware of the modular system includes with many sensor modules, cameras, IMU (Inertial Measurement Unit) sensors, processors, Wi-Fi module, laser, LED light plus its associated software. The mobile PSS module is responsible for local data processing for various sensors, image processing, 3D pose estimation, audio data acquisition, visualization and wireless interfaced devices. The advantage of modular concept is that it can work independently or together. The Head Mounted Display (HMD) includes HW and SW to communicate the augmented reality content to the user and to display visual information on a worker's field of view (FOV). The module serves as a supervision post, providing sensor data, video and audio stream to the supervisor. It stores data and provide the means for the supervisor to easily communicate and instruct the worker. It decides, selects and serves the AR (Augmented) content on multiple PTUs, automatically or with minor supervisor intervention. The development of this system to be compatible with a wearable use in a highly challenging environment presents an excellent opportunity to integrate today's leading technical knowledge in a product which can become accessible to industry and general public. This study is a part of the EDUSAFE project, a Marie Curie ITN project focusing on research into the use of Virtual and Augmented Reality (VR/AR) during planned and emergency maintenance in extreme environments.",2156-8073,978-1-4799-6314-0,10.1109/ICSensT.2015.7438515,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7438515,Modular system;Sensors;Augmented Reality;Supervision,Temperature sensors;Program processors;Pins;Augmented reality;Cameras,augmented reality;helmet mounted displays;intelligent sensors,intelligent sensing system;modular sensing system;augmented reality application;head mounted display;personnel supervision system module,,,,26,,24-Mar-16,,,IEEE,IEEE Conferences
VREdu: A Framework for Interactive Immersive Lectures using Virtual Reality,M. Misbhauddin,"Information Systems Department, College of Computer Sciences and Information Technology, King Faisal University, Al-Ahsa, Saudi Arabia",2018 21st Saudi Computer Society National Computer Conference (NCC),30-Dec-18,2018,,,1,6,"In the current education system, we expect the comprehension level of all the students in a classroom to be same. However, this is not the case. There are many factors that may affect the comprehension of lectures in the classroom including class size, visibility of the whiteboard, student's level of concentration, student's level of comprehension to name a few. Our main aim is to find a better way to offer the best education experience for students using the latest innovative solutions in technology. During our survey of Virtual Reality (VR) applications, we identified several readily available applications most of which were related to either medical education, tourism or other domains of sciences. None of the applications were available for general education where a complete classroom is transported into virtual reality. In this paper, we developed a VR framework that enhances the learning experience of students who face difficulties in the classroom. Moreover, we developed a complete prototype system to validate the framework. The proposed framework makes learning immersive, interactive and narrative offering enhanced motivation to students. The prototype system setup involves setting up a camera in the classroom to capture the whiteboard. Visuals from the whiteboard augmented with the course material (lecture slides) are compiled together to create a virtual space for the students. Students can interact with the virtual classroom by a provided set of tools in the virtual space. The VR application is developed using Unity 3D Engine and interaction is implemented using a handheld Bluetooth device.",,978-1-5386-4110-1,10.1109/NCG.2018.8593095,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593095,Virtual reality in education;Classroom VR;3D Engine,Education;Virtual reality;Aerospace electronics;Prototypes;Engines;Streaming media;Visualization,computer aided instruction;educational courses;interactive systems;virtual reality,interactive immersive lectures;education experience;general education;VR framework;learning experience;course material;virtual space;virtual classroom;VR application;education system;virtual reality applications,,1,,20,,30-Dec-18,,,IEEE,IEEE Conferences
A control-system architecture for robots used to simulate dynamic force and moment interaction between humans and virtual objects,C. L. Clover,"MechDyne Corp., Marshalltown, IA, USA","IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)",6-Aug-02,1999,29,4,481,493,"Haptic or kinesthetic feedback is essential in many important virtual reality and telepresence applications. Previous research focuses on simulating static forces such as those encountered when interacting with a stiff object such as a wall. Past studies usually employ custom-made devices that are not readily available to other researchers. Consequently, many of the results found in the haptic feedback literature cannot be replicated independently. With experimental results, the paper demonstrates that ""off the shelf,"" general purpose robotics equipment can be incorporated into an effective haptic/kinesthetic feedback system. Such a system can accommodate a wide variety of virtual reality applications including training and telerobotics. An admittance control scheme is utilized, which enables the simulation of dynamic force and moment interaction as well as contact with stiff objects. The paper shows that the mechanical deficiencies (e.g., friction, inertia, and backlash) often associated with general purpose manipulators can be overcome with a suitable control system architecture.",1558-2442,,10.1109/5326.798763,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=798763,,Robot control;Haptic interfaces;Feedback;Virtual reality;Telerobotics;Admittance;Force control;Friction;Manipulator dynamics;Control systems,haptic interfaces;virtual reality;telerobotics;force feedback;digital simulation;human factors;robot programming;bibliographies,robot control system architecture;dynamic force simulation;moment interaction;human/virtual object interaction;kinesthetic feedback;virtual reality;telepresence applications;off the shelf general purpose robotics equipment;haptic/kinesthetic feedback system;telerobotics;admittance control scheme;stiff objects;mechanical deficiencies;general purpose manipulators,,9,,51,,6-Aug-02,,,IEEE,IEEE Journals
"Connecting User Experience to Learning in an Evaluation of an Immersive, Interactive, Multimodal Augmented Reality Virtual Diorama in a Natural History Museum & the Importance of Story",M. C. R. Harrington,"University of Central Florida,Games and Interactive Media,Orlando,Florida,USA",2020 6th International Conference of the Immersive Learning Research Network (iLRN),4-Aug-20,2020,,,70,78,"Reported are the findings of user experience and learning outcomes from a July 2019 study of an immersive, interactive, multimodal augmented reality (AR) application, used in the context of a museum. The AR Perpetual Garden App is unique in creating an immersive multisensory experience of data. It allowed scientifically na√Øve visitors to walk into a virtual diorama constructed as a data visualization of a springtime woodland understory and interact with multimodal information directly through their senses. The user interface comprised of two different AR data visualization scenarios reinforced with data based ambient bioacoustics, an audio story of the curator's narrative, and interactive access to plant facts. While actual learning and dwell times were the same between the AR app and the control condition, the AR experience received higher ratings on perceived learning. The AR interface design features of ""Story"" and ""Plant Info"" showed significant correlations with actual learning outcomes, while ""Ease of Use"" and ""3D Plants"" showed significant correlations with perceived learning. As such, designers and developers of AR apps can generalize these findings to inform future designs.",,978-1-7348995-0-4,10.23919/iLRN47897.2020.9155202,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155202,augmented reality;bioacoustics;data visualization;immersive;information fidelity;informal learning;interactive;multimodal;museums;narrative;photorealistic;place illusion;presence;virtual dioramas;virtual reality,Data visualization;Virtual reality;Forestry;History;Biomedical acoustics;Three-dimensional displays;Games,augmented reality;bioacoustics;computer aided instruction;data visualisation;history;human computer interaction;learning (artificial intelligence);museums;user interfaces;virtual reality,"user experience;natural history museum;July 2019 study;immersive, interactive, multimodal augmented reality application;AR Perpetual Garden App;immersive multisensory experience;scientifically na√Øve visitors;virtual diorama;data visualization;springtime woodland understory;multimodal information;user interface;audio story;interactive access;AR app;AR experience;perceived learning;actual learning outcomes",,,,29,,4-Aug-20,,,IEEE,IEEE Conferences
Evaluating Mixed and Augmented Reality: A Systematic Literature Review (2009-2019),L. Merino; M. Schwarzl; M. Kraus; M. Sedlmair; D. Schmalstieg; D. Weiskopf,University of Stuttgart; University of Stuttgart; University of Konstanz; University of Stuttgart; Graz University of Technology; University of Stuttgart,2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),14-Dec-20,2020,,,438,451,"We present a systematic review of 45S papers that report on evaluations in mixed and augmented reality (MR/AR) published in ISMAR, CHI, IEEE VR, and UIST over a span of 11 years (2009-2019). Our goal is to provide guidance for future evaluations of MR/AR approaches. To this end, we characterize publications by paper type (e.g., technique, design study), research topic (e.g., tracking, rendering), evaluation scenario (e.g., algorithm performance, user performance), cognitive aspects (e.g., perception, emotion), and the context in which evaluations were conducted (e.g., lab vs. in-thewild). We found a strong coupling of types, topics, and scenarios. We observe two groups: (a) technology-centric performance evaluations of algorithms that focus on improving tracking, displays, reconstruction, rendering, and calibration, and (b) human-centric studies that analyze implications of applications and design, human factors on perception, usability, decision making, emotion, and attention. Amongst the 458 papers, we identified 248 user studies that involved 5,761 participants in total, of whom only 1,619 were identified as female. We identified 43 data collection methods used to analyze 10 cognitive aspects. We found nine objective methods, and eight methods that support qualitative analysis. A majority (216/248) of user studies are conducted in a laboratory setting. Often (138/248), such studies involve participants in a static way. However, we also found a fair number (30/248) of in-the-wild studies that involve participants in a mobile fashion. We consider this paper to be relevant to academia and industry alike in presenting the state-of-the-art and guiding the steps to designing, conducting, and analyzing results of evaluations in MR/AR.",1554-7868,978-1-7281-8508-8,10.1109/ISMAR50242.2020.00069,Deutsche Forschungsgemeinschaft; Deutsche Forschungsgemeinschaft; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284762,Mixed and Augmented Reality;Evaluation;Systematic Literature Review;I.3.7 [Computing Methodologies];Three-Dimensional Graphics and Realism;A.1 [General Literature];Computer Graphics;Introductory and Survey,Systematics;Benchmark testing;User interfaces;Rendering (computer graphics);Calibration;Usability;Augmented reality,augmented reality;cognition;decision making;human computer interaction;human factors;Internet;user interfaces,augmented reality;systematic literature review;IEEE VR;future evaluations;evaluation scenario;user performance;technology-centric performance evaluations;human-centric studies;user studies;data collection methods;cognitive aspects;in-the-wild studies,,,,123,,14-Dec-20,,,IEEE,IEEE Conferences
Natural interaction in VR environments for Cultural Heritage and its impact inside museums: The Etruscanning project,E. Pietroni; C. Ray; C. Rufa; D. Pletinckx; I. Van Kampen,"CNR Institute of Technologies Applied to Cultural Heritage, Rome, Italy; Allard Pierson Museum - University of Amsterdam, Amsterdam, Holland; E.V.O. CA s.r.l., Rome, Italy; Visual Dimension, Ename, Belgium; Soprintendenza Etruria Meridionale, Formello, Italy",2012 18th International Conference on Virtual Systems and Multimedia,3-Dec-12,2012,,,339,346,"A basic limit of most Virtual Reality (VR) applications reproducing cultural sites developed by the scientific community is that they often fail to fire up the attention and the involvement of the public. Starting from our experience in this domain, we would like to discuss some of the fundamental concepts about the potentiality of virtual ecosystems and to propose new natural interaction interfaces in VR environments based on body movements. The system we will describe has been derived from the new generation of games, but for the first time, it has been applied to VR environments dedicated to Cultural Heritage (CH) and experimented with inside museums. Interesting research focused on the definition of a new grammar of gestures is in progress, allowing more and more complexity, but with natural interchanges and connections between real and virtual worlds. An important development in this field has been realized in the framework of the Etruscanning project, a European project (Culture 2007) whose aim is to explore the possibilities of new visualization techniques, in order to re-create and restore the original context of the Etruscan graves. In this paper, we will discuss the methodological approach and the VR application dedicated to Regolini Galassi tomb, in the Sorbo necropolis in Cerveteri. Finally, we will present the results of the evaluation of the VR installation presented inside the museums, derived from public feedback. This observation lasted several months and gave us the opportunity to adjust the grammar of gestures and the general infrastructure of the application in order to define and implement the most efficient solution for people.",,978-1-4673-2563-9,10.1109/VSMM.2012.6365943,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365943,virtual reality;communication;natural interaction;embodiment;learning;museum;public evaluation,Cultural differences;Global communication;Solid modeling;Visualization;Engines;Real-time systems;Floors,data visualisation;history;museums;virtual reality,VR environments;virtual reality;cultural heritage;museums;Etruscanning project;scientific community;virtual ecosystems;natural interaction interfaces;body movements;European project;Regolini Galassi tomb;Sorbo necropolis;Cerveteri;visualization techniques,,14,,18,,3-Dec-12,,,IEEE,IEEE Conferences
Comparing Four Approaches to Generalized Redirected Walking: Simulation and Live User Data,E. Hodgson; E. Bachmann,"Smale Interactive Visualization Center at Miami University, Ohio; Computer Science and Software Engineering and Director of the HIVE at Miami University, Ohio",IEEE Transactions on Visualization and Computer Graphics,13-Mar-13,2013,19,4,634,643,"Redirected walking algorithms imperceptibly rotate a virtual scene and scale movements to guide users of immersive virtual environment systems away from tracking area boundaries. These distortions ideally permit users to explore large and potentially unbounded virtual worlds while walking naturally through a physically limited space. Estimates of the physical space required to perform effective redirected walking have been based largely on the ability of humans to perceive the distortions introduced by redirected walking and have not examined the impact the overall steering strategy used. This work compares four generalized redirected walking algorithms, including Steer-to-Center, Steer-to-Orbit, Steer-to-Multiple-Targets and Steer-to-Multiple+Center. Two experiments are presented based on simulated navigation as well as live-user navigation carried out in a large immersive virtual environment facility. Simulations were conducted with both synthetic paths and previously-logged user data. Primary comparison metrics include mean and maximum distances from the tracking area center for each algorithm, number of wall contacts, and mean rates of redirection. Results indicated that Steer-to-Center out-performed all other algorithms relative to these metrics. Steer-to-Orbit also performed well in some circumstances.",1941-0506,,10.1109/TVCG.2013.28,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479192,Redirected walking;virtual environments;navigation;human computer interaction;live users;simulation.,Legged locomotion;Orbits;Navigation;Algorithm design and analysis;Space vehicles;Visualization;Tracking,human computer interaction;navigation;virtual reality,live user data;virtual scene;scale movement;immersive virtual environment system;tracking area boundary;virtual world;physical space;steering strategy;generalized redirected walking algorithm;Steer-to-Center;Steer-to-Orbit;Steer-to-Multiple-Targets;Steer-to-Multiple+Center;live-user navigation;large immersive virtual environment facility;synthetic path;tracking area center;wall contact,"Algorithms;Biofeedback, Psychology;Computer Graphics;Cues;Humans;Imaging, Three-Dimensional;User-Computer Interface;Visual Perception;Walking",34,,20,,13-Mar-13,,,IEEE,IEEE Journals
Virtual cooperating manipulator control for haptic interaction with NURBS surfaces,G. R. Luecke; J. C. Edwards; B. E. Miller,"Iowa State Univ., Ames, IA, USA; NA; NA",Proceedings of International Conference on Robotics and Automation,6-Aug-02,1997,1,,112,117 vol.1,"Virtual manipulators are a new concept in the area of force feedback for virtual reality. This control approach does not make use of any specialized haptic display hardware but instead is formulated for implementation with any general industrial robot that allows six degree of freedom motion. Using this approach many commonly available manipulators can be used as an interface device to a virtual environment. This work extends the virtual manipulator concept, to allow haptic interaction with more complex virtual objects. The time varying virtual manipulator developed here constrains the end effector of a robot to trace along a NURBS surface. This virtual mechanism provides interaction forces consistent with the sensation of contacting the surface. These interaction forces can be coupled with a graphical display to provide a more complete feeling of immersion.",,0-7803-3612-7,10.1109/ROBOT.1997.620024,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=620024,,Haptic interfaces;Manipulators;Displays;Force feedback;Virtual reality;Motion control;Hardware;Industrial control;Service robots;Virtual environment,virtual reality;manipulators;feedback;Jacobian matrices;graphical user interfaces,virtual cooperating manipulator control;haptic interaction;NURBS surfaces;force feedback;virtual reality;general industrial robot;six degree of freedom motion;virtual environment;time varying virtual manipulator;end effector;virtual mechanism;interaction forces;graphical display,,3,2,15,,6-Aug-02,,,IEEE,IEEE Conferences
Waving Real Hand Gestures Recorded by Wearable Motion Sensors to a Virtual Car and Driver in a Mixed-Reality Parking Game,D. Bannach; O. Amft; K. S. Kunze; E. A. Heinz; G. Troster; P. Lukowicz,"Embedded Systems Lab, University of Passau, Passau. david.bannach@uni-passau.de; Wearable Computing Lab, ETH Z√ºrich, Z√ºrich. amft@ife.ee.ethz.ch; Embedded Systems Lab, University of Passau, Passau. kai.kunze@uni-passau.de; Computer Systems and Networks (CSN), UMIT, Hall in Tyrol. ernst.heinz@umit.at; Wearable Computing Lab, ETH Z√ºrich, Z√ºrich. troester@ife.ee.ethz.ch; Embedded Systems Lab, University of Passau, Passau; Computer Systems and Networks (CSN), UMIT, Hall in Tyrol. paul.lukowicz@uni-passau.de, paul.lukowicz@umit.at",2007 IEEE Symposium on Computational Intelligence and Games,4-Jun-07,2007,,,32,39,"We envision to add context awareness and ambient intelligence to edutainment and computer gaming applications in general. This requires mixed-reality setups and ever-higher levels of immersive human-computer interaction. Here, we focus on the automatic recognition of natural human hand gestures recorded by inexpensive, wearable motion sensors. To study the feasibility of our approach, we chose an educational parking game with 3D graphics that employs motion sensors and hand gestures as its sole game controls. Our implementation prototype is based on Java-3D for the graphics display and on our own CRN Toolbox for sensor integration. It shows very promising results in practice regarding game appeal, player satisfaction, extensibility, ease of interfacing to the sensors, and - last but not least - sufficient accuracy of the real-time gesture recognition to allow for smooth game control. An initial quantitative performance evaluation confirms these notions and provides further support for our setup",2325-4289,1-4244-0709-5,10.1109/CIG.2007.368076,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4219021,Game Control;Gesture Recognition;Immersive Human-Computer Interaction;Java-3D;Mixed Reality;Motion Sensors;Wearable Computing,Wearable sensors;Virtual reality;Intelligent sensors;Context awareness;Ambient intelligence;Computer applications;Pervasive computing;Application software;Humans;Computer graphics,computer games;gesture recognition;human computer interaction;image motion analysis;image sensors;Java;virtual reality;wearable computers,real hand gestures;wearable motion sensors;virtual car;virtual driver;mixed-reality parking game;context awareness;ambient intelligence;edutainment;computer gaming;human-computer interaction;natural human hand gesture recognition;educational parking game;3D graphics;Java-3D;graphics display;CRN Toolbox;sensor integration;game control;wearable computing,,29,,21,,4-Jun-07,,,IEEE,IEEE Conferences
A Controlled Experiment on Spatial Orientation in VR-Based Software Cities,M. R√ºdel; J. Ganser; R. Koschke,"Univ. of Bremen, Bremen, Germany; Univ. of Bremen, Bremen, Germany; Univ. of Bremen, Bremen, Germany",2018 IEEE Working Conference on Software Visualization (VISSOFT),11-Nov-18,2018,,,21,31,"Multiple authors have proposed a city metaphor for visualizing software. While early approaches have used three-dimensional rendering on standard two-dimensional displays, recently researchers have started to use head-mounted displays to visualize software cities in immersive virtual reality systems (IVRS). For IVRS of a higher order it is claimed that they offer a higher degree of engagement and immersion as well as more intuitive interaction. On the other hand, spatial orientation may be a challenge in IVRS as already reported by studies on the use of IVRS in domains outside of software engineering such as gaming, education, training, and mechanical engineering or maintenance tasks. This might be even more true for the city metaphor for visualizing software. Software is immaterial and, hence, has no natural appearance. Only a limited number of abstract aspects of software are mapped onto visual representations so that software cities generally lack the details of the real world, such as the rich variety of objects or fine textures, which are often used as clues for orientation in the real world. In this paper, we report on an experiment in which we compare navigation in a particular kind of software city (EvoStreets) in two variants of IVRS. One with head-mounted display and hand controllers versus a 3D desktop visualization on a standard display with keyboard and mouse interaction involving 20 participants.",,978-1-5386-8292-0,10.1109/VISSOFT.2018.00011,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8530128,Visualization;Software City;Orientation;Experiment;Software Engineering;Virtual Reality,Software;Visualization;Urban areas;Navigation;Measurement;Task analysis;Three-dimensional displays,helmet mounted displays;program visualisation;virtual reality,software city;IVRS;head-mounted display;3D desktop visualization;standard display;spatial orientation;VR-based software cities;city metaphor;two-dimensional displays;immersive virtual reality systems;software engineering;mechanical engineering;visual representations;software visualization;EvoStreets;hand controllers,,3,,45,,11-Nov-18,,,IEEE,IEEE Conferences
Inverse Kinematics and Temporal Convolutional Networks for Sequential Pose Analysis in VR,D. C. Jeong; J. J. Xu; L. C. Miller,"Santa Clara University,Department of Communication,Santa Clara,USA; University of Southern California,Annenberg School for Communication,Los Angeles,USA; University of Southern California,Annenberg School for Communication,Los Angeles,USA",2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),15-Jan-21,2020,,,274,281,"Drawing from a recent call to advance generalizability and causal inference in psychological science using contextually representative research designs [1], we introduce a conceptual framework that integrates techniques in machine perception of poses with VR-driven inverse kinematic character animation, leveraging the Unity game engine to mediate between the human user and the machine learner. This Computational Virtual Reality (C-VR) system contains the following components: a) Human motion capture (VR), b) Human to avatar character animation (inverse kinematics), c) character animation recordings (virtual cameras), d) avatar pose detection (OpenPose), d) avatar pose classification (SVM), and e) sequential avatar moving pose analyses (TCN). By leveraging the precision in representation afforded in virtual environments and agents and the precision in perception afforded in computer vision and machine learning in a unified system, we may take steps towards understanding a wider range of human complexity.",,978-1-7281-7463-1,10.1109/AIVR50618.2020.00056,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319069,avatars;neural networks;computer vision,Kinematics;Psychology;Avatars;Pose estimation;Computer vision;Animation;Skeleton,avatars;computer animation;computer games;computer vision;convolutional neural nets;human computer interaction;learning (artificial intelligence);pose estimation;psychology;solid modelling;virtual reality,human complexity;sequential pose analysis;causal inference;psychological science;contextually representative research designs;machine perception;VR-driven inverse kinematic character animation;Unity game engine;human user;machine learner;C-VR;human motion capture;avatar character animation;inverse kinematics;virtual cameras;virtual environments;computer vision;machine learning;computational virtual reality system,,,,81,,15-Jan-21,,,IEEE,IEEE Conferences
Analysis on the current condition of virtual reality and computer graphics and the applications on the digital media interaction,P. Wu,"Shenyang Aerospace University, Liaoning province, Shenyang city, 110136, China",2016 International Conference on Inventive Computation Technologies (ICICT),19-Jan-17,2016,1,,1,6,"In this paper, we conduct analysis on the current condition of virtual reality and the computer graphics and the applications on the digital media interaction. We proposed the systematic review of the digital media interaction modes with the theoretical analysis of the virtual reality and computer graphics. Multimedia gateway is a separate control of the entire media interaction center core components, has the media docking and adaptation, multimedia intelligent routing, configuration and management, and other functions and at the center of the centralized control of all media interaction, the configuration and management of multimedia intelligent routing. With this basis, we integrate the 3D reconstruction methodology to propose the new perspective of the digital media interaction paradigm. The man-machine interface design principles should include the basic principles of general interface design, analysis and man-machine interface specification and the type of interface requirements. Our review summarizes the characteristics of the method well and in the future, the VR integration with the multimedia system and optimized re-construction method and image representation algorithms will be considered.",,978-1-5090-1285-5,10.1109/INVENTIVE.2016.7823249,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823249,Virtual Reality;Computer Graphics;Digital Media Interaction;Current Condition;Image Processing,Multimedia communication;Media;Three-dimensional displays;Solid modeling;Streaming media;Computers;Computer graphics,image reconstruction;image representation;man-machine systems;multimedia systems;user interfaces;virtual reality,virtual reality;computer graphics;digital media interaction center core components;media docking;media adaptation;multimedia intelligent routing;multimedia gateway;multimedia configuration;multimedia management;centralized control;3D reconstruction;man-machine interface specification;interface requirements;man-machine interface design principles;VR integration;optimized reconstruction;image representation,,,,47,,19-Jan-17,,,IEEE,IEEE Conferences
The Alps at your fingertips: virtual reality and geoinformation systems,R. Pajarola; T. Ohler; P. Stucki; K. Szabo; P. Widmayer,"Dept. of Comput. Sci., Eidgenossische Tech. Hochschule, Zurich, Switzerland; NA; NA; NA; NA",Proceedings 14th International Conference on Data Engineering,6-Aug-02,1998,,,550,557,"Advocates a desktop virtual reality (VR) interface to a geographic information system (GIS). The navigational capability to explore large topographic scenes is a powerful metaphor and a natural way of interacting with a GIS. VR systems succeed in providing visual realism and real-time navigation and interaction, but fail to cope with very large amounts of data and to provide the general functionality of information systems. We suggest a way to overcome these problems. We describe a prototype system, called ViRGIS (Virtual Reality GIS), that integrates two system platforms: a client that runs the VR component interacts via a (local or wide area) network with a server that runs an object-oriented database containing geographic data. For the purpose of accessing data efficiently, we describe how to integrate a geometric index into the database, and how to perform the operations that are requested in a real-time trip through the virtual world.",1063-6382,0-8186-8289-2,10.1109/ICDE.1998.655818,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=655818,,Virtual reality;Geographic Information Systems;Navigation;Object oriented databases;Spatial databases;Layout;Real time systems;Information systems;Virtual prototyping;Network servers,virtual reality,desktop virtual reality interface;geographic information system;navigational capability;large topographic scenes;visual realism;real-time navigation;real-time interaction;functionality;prototype system;ViRGIS;client-server system;local area network;wide area network;object-oriented database;data access;geometric index,,4,4,17,,6-Aug-02,,,IEEE,IEEE Conferences
Estimating Gaze Depth Using Multi-Layer Perceptron,Y. Lee; C. Shin; A. Plopski; Y. Itoh; T. Piumsomboon; A. Dey; G. Lee; S. Kim; M. Billinghurst,"Empathic Comput. Lab., Univ. of South Australia, Adelaide, SA, Australia; VR/AR Res. Center, KETI, South Korea; Interactive Media Design Lab., NAIST, Japan; Interactive Media Lab., Keio Univ., Yokohama, Japan; Empathic Comput. Lab., Univ. of South Australia, Adelaide, SA, Australia; Empathic Comput. Lab., Univ. of South Australia, Adelaide, SA, Australia; Empathic Comput. Lab., Univ. of South Australia, Adelaide, SA, Australia; Empathic Comput. Lab., Univ. of South Australia, Adelaide, SA, Australia; Empathic Comput. Lab., Univ. of South Australia, Adelaide, SA, Australia",2017 International Symposium on Ubiquitous Virtual Reality (ISUVR),24-Jul-17,2017,,,26,29,"In this paper we describe a new method for determining gaze depth in a head mounted eye-tracker. Eye-trackers are being incorporated into head mounted displays (HMDs), and eye-gaze is being used for interaction in Virtual and Augmented Reality. For some interaction methods, it is important to accurately measure the x-and y-direction of the eye-gaze and especially the focal depth information. Generally, eye tracking technology has a high accuracy in x-and y-directions, but not in depth. We used a binocular gaze tracker with two eye cameras, and the gaze vector was input to an MLP neural network for training and estimation. For the performance evaluation, data was obtained from 13 people gazing at fixed points at distances from 1m to 5m. The gaze classification into fixed distances produced an average classification error of nearly 10%, and an average error distance of 0.42m. This is sufficient for some Augmented Reality applications, but more research is needed to provide an estimate of a user's gaze moving in continuous space.",,978-1-5386-3091-4,10.1109/ISUVR.2017.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7988648,Eye-gaze;3D gaze;Machine Learning;Augmented Reality;Head-mounted display,Three-dimensional displays;Meters;Cameras;Training;Error analysis;Resists;Calibration,augmented reality;cameras;gaze tracking;helmet mounted displays;image classification;learning (artificial intelligence);multilayer perceptrons,gaze depth;head mounted eye-tracker;head mounted displays;virtual reality;augmented reality;focal depth information;eye tracking technology;binocular gaze tracker;eye cameras;gaze vector;MLP neural network;training;performance evaluation;gaze classification;fixed distances;fixed points;average classification error;gaze depth estimation;multilayer perceptron,,4,,23,,24-Jul-17,,,IEEE,IEEE Conferences
Application and Realization of VR Technology in Interior Design,R. wang,"Zhejiang Tongji Vocational College of Science and Technology, Hangzhou, China",2019 12th International Conference on Intelligent Computation Technology and Automation (ICICTA),2-Mar-20,2019,,,182,186,"This paper introduces the development of virtual reality technology at home and abroad, and introduces the basic knowledge of virtual reality. The model of indoor environment is built by VRML, and the roaming technology of virtual scene is also introduced. The reason why VRML is used to establish indoor mode is that Web technology is used in the implementation part of this paper. Finally, based on virtual scene modeling, the establishment of virtual indoor environment is completed, which combines the virtual reality interior design technology with the popular Internet technology. The experiments show that the improved technology-based virtual scene space multi-dimensional display effect is good and expansibility is strong; the online virtual indoor scene designed can be realized with users. The interaction enables users to roam the virtual indoor system according to their own wishes, generally meeting the expected requirements.",,978-1-7281-4284-5,10.1109/ICICTA49267.2019.00046,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9017034,VR;3ds MAX;interior design;VRML,Erbium;Automation,indoor environment;Internet;virtual reality,Web technology;virtual scene modeling;virtual indoor environment;virtual reality interior design technology;popular Internet technology;improved technology-based virtual scene space multidimensional display effect;online virtual indoor scene;virtual indoor system;VR technology;virtual reality technology;VRML;roaming technology;indoor mode,,,,9,,2-Mar-20,,,IEEE,IEEE Conferences
Virtual reality for electrons in vacuum devices,A. J. Sangster,"Dept. of Electr. & Electron. Eng., Heriot-Watt Univ., Edinburgh, UK",IEE Colloquium on Real World Visualisation - Virtual World - Virtual Reality,6-Aug-02,1991,,,1-Jul,3-Jul,"Vacuum tube oscillators and amplifiers at microwave frequencies have presented a considerable challenge to CAD design engineers, since successful computer modelling of such devices can lead to considerable savings in their development costs. In principle, the vacuum tube is potentially capable of very precise mathematical simulation (virtual reality) if three basic conditions prevail. These are: (1) the devices are perfectly evacuated; (2) electrodes and waveguiding structures are perfectly conducting; and (3) electrons can be viewed as 'particles'. The compilation of a computer simulation package for electron beam tubes requires the solution of two distinct field problems. Firstly, a finite difference, or finite element, representation of the Laplace of Poisson equation in the collector or gun regions of the device is required together with the observance of Lorentz forces on the electrons if magnetic focussing fields are present. Secondly, gain or oscillation in a microwave tube occurs in the beam/circuit interaction region. The 'circuit' is generally a slow-wave structure which supports a guided electromagnetic wave. The field solution for such circuits involves the numerical evaluation of the Helmholtz equation together with appropriate boundary conditions. One of the main tasks in the computer simulation of such structures entails the development of algorithms which can flexibly accommodate a wide variety of geometrical shapes.<>",,,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=263724,,,digital simulation;electronic engineering computing;engineering graphics;finite element analysis;vacuum tubes,vacuum tube oscillators;vacuum tube amplifiers;finite difference representation;finite element representation;Laplace equation;electron gas;vacuum devices;microwave frequencies;CAD;computer modelling;virtual reality;electrodes;waveguiding structures;computer simulation package;electron beam tubes;Poisson equation;collector;Lorentz forces;magnetic focussing fields;gain;beam/circuit interaction region;slow-wave structure;Helmholtz equation;boundary conditions;computer simulation;geometrical shapes,,,,,,6-Aug-02,,,IET,IET Conferences
Multi-agent based architecture for virtual reality intelligent simulation system of vehicles,Y. Yu; A. El Kamel; G. Gong,"LAGIS, CNRS UMR 8129, Ecole Centrale de Lille, Villeneuve d'Ascq Cedex, France; LAGIS, CNRS UMR 8129, Ecole Centrale de Lille, Villeneuve d'Ascq Cedex, France; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China","2013 10th IEEE INTERNATIONAL CONFERENCE ON NETWORKING, SENSING AND CONTROL (ICNSC)",27-Jun-13,2013,,,597,602,"Most existed researches on traffic simulation with virtual reality are mainly concentrated on the visualization or the real-time simulation to create immersion experiences in virtual world, but little attention has been paid on system modeling and formal specification of traffic simulation. Based on multi-agent technology, Virtual Reality Intelligent Simulation System of Vehicles (VR-ISSV) is proposed to investigate the modeling method of vehicles simulation system, with the advantages of reusability, scalability and flexibility. Firstly, the framework modeling is introduced to depict the general intelligent simulation system. Then, intelligent vehicle agent and environment agent are presented for the simulation of interactions among the vehicles, the traffic situation and the environment. Finally, the application results of the proposed system are realized.",,978-1-4673-5200-0,10.1109/ICNSC.2013.6548806,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6548806,,Solid modeling;Vehicles;Intelligent vehicles;Artificial intelligence;Three-dimensional displays;Virtual reality;Visualization,automated highways;digital simulation;multi-agent systems;road traffic;road vehicles;software reusability;traffic engineering computing;virtual reality,multiagent based architecture;Virtual Reality Intelligent Simulation System of Vehicles;vehicles simulation system modeling method;software reusability;VR-ISSV scalability;VR-ISSV flexibility;intelligent simulation system;intelligent vehicle agent;environment agent,,2,,17,,27-Jun-13,,,IEEE,IEEE Conferences
CyPhone-experimenting mobile real-time telepresence,P. Pulli; T. Pyssysalo; J. -. Metsavainio; O. Komulainen,"Oulu Univ., Finland; NA; NA; NA",Proceeding. 10th EUROMICRO Workshop on Real-Time Systems (Cat. No.98EX168),6-Aug-02,1998,,,10,17,"Advances in multimedia, virtual reality, and immersive environments have expanded human computer interaction beyond text and vision to include touch, gestures, voice and 3D sound. Although there exist well developed single modalities for communication, we do not really understand the general problem of designing integrated multimodal systems. Recent advances in mobile communication based on picocellular technologies allow the transmission of high bandwidth data over personal surrounding networks. We analyse the sources of real time constraints in telepresence and augmented reality applications. We offer an approach to adding aspects of mobility and augmented reality to real time mobile telepresence, discuss the technology and potential future product concept vision, the CyPhone, and depict the general architecture and integration framework briefly. Finally, a survey of relevant telecooperation services are introduced.",1068-3070,0-8186-8503-4,10.1109/EMWRTS.1998.684927,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=684927,,Virtual reality;Telecommunication computing;Mobile communication;Embedded computing;Augmented reality;Computer displays;Electronic mail;Telecommunication services;Pervasive computing;Ubiquitous computing,virtual reality;multimedia systems;mobile communication;user interfaces;interactive systems;real-time systems;telephony,CyPhone;mobile real time telepresence;multimedia;virtual reality;immersive environments;human computer interaction;integrated multimodal systems;mobile communication;picocellular technologies;high bandwidth data transmission;personal surrounding networks;real time constraints;augmented reality applications;real time mobile telepresence;future product concept vision;integration framework;telecooperation services,,1,1,21,,6-Aug-02,,,IEEE,IEEE Conferences
Explore Voice and Foot-based Interaction Techniques to Navigate 2D Radiological Images in the Virtual Reality Operation Theatre,A. Zaman; A. Roy; K. Fatema; N. J. Farin; T. Doring; R. Malaka,"University of Bremen,Digital Media Lab,Bremen,Germany; Stamford University Bangladesh,Department of Computer Science and Engineering,Dhaka,Bangladesh; Stamford University Bangladesh,Department of Computer Science and Engineering,Dhaka,Bangladesh; Stamford University Bangladesh,Department of Computer Science and Engineering,Dhaka,Bangladesh; TZI, University of Bremen,Digital Media Lab,Bremen,Germany; TZI, University of Bremen,Digital Media Lab,Bremen,Germany",2019 22nd International Conference on Computer and Information Technology (ICCIT),19-Mar-20,2019,,,1,7,"During surgery, the surgeons often need to interact with the 2D radiological images. Due to sterility, surgeons are unable to interact with the system and depend on duty assistant. However, communication with the substitute might be complicated and error-prone if the operators and the surgeons do not have an equal level of communication skills which might interrupt the workflow. To get rid of the dependency on substitute operator, two hands-free modalities i.e. voice and foot- based interactions have been analyzed and investigated for the surgeon to interact with 2D images. To feel like a real Operation Theatre, the Virtual Reality environment has been designed, where the hands-free modalities are deployed. 16 participants had evaluated the interaction systems. To analysis, the system usability, the qualitative and quantitative studies have been considered. Our finding indicates that both systems reached general usability rating. Wherein the observation indicated that, the voice command system is comfortable to use whereas foot- based interaction is more efficient. Nevertheless, for the short and longer interaction foot-based interaction is preferable than a voice command, however, for short interaction, voice command is more acceptable.",,978-1-7281-5842-6,10.1109/ICCIT48885.2019.9038175,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9038175,Foot gesture;Voice Command;Virtual Reality;Human-Computer Interaction,,interactive systems;medical image processing;radiology;speech processing;surgery;virtual reality,system usability;voice command system;foot-based interaction techniques;error-prone;communication skills;hands-free modalities;surgeon;voice-based interaction systems;virtual reality operation theatre;2D radiological images,,,,28,,19-Mar-20,,,IEEE,IEEE Conferences
Toward a model-based approach to the specification of virtual reality environments,D. Fogli; P. Mussio; A. Celentano; F. Pittarello,"Dipt. di Elettronica per l'Automazione, Universita degli Studi di Brescia, Italy; Dipt. di Elettronica per l'Automazione, Universita degli Studi di Brescia, Italy; NA; NA","Fourth International Symposium on Multimedia Software Engineering, 2002. Proceedings.",25-Feb-03,2002,,,148,155,"An approach to the specification of a virtual reality (VR) interactive environment is presented, which merges and generalizes two recently proposed methods: the PCL characteristic pattern approach to WIMP system design and the interaction locus approach to interactive navigation in 3D virtual spaces. Merging the two points of view allows refinement of the model of interaction of a user with a virtual environment and leads to the definition of ""real"" and ""virtual"" characteristic patterns, which the discussion shows to be important for the designer to properly undertake the design of complex virtual reality systems.",,0-7695-1857-5,10.1109/MMSE.2002.1181607,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1181607,,Virtual reality;Computer interfaces;Layout;Human computer interaction;Navigation;Merging;Virtual environment;Proposals;Laboratories;Process design,virtual reality;user interfaces;formal specification,virtual reality interactive environment;specification;PCL characteristic pattern approach;WIMP system design;interaction locus approach;interactive navigation;3D virtual spaces;user interaction model;virtual characteristic pattern;real characteristic pattern,,2,,19,,25-Feb-03,,,IEEE,IEEE Conferences
Distributed simulation and virtual reality visualization of multi-robot distributed receding horizon control systems,Yan Zhao; Liang Bai; B. W. Gordon,"Control and Information Systems (CIS) Laboratory, Department of Mechanical and Industrial Engineering, Concordia University, Montreal, Quebec, H3G IM8, Canada; Control and Information Systems (CIS) Laboratory, Department of Mechanical and Industrial Engineering, Concordia University, Montreal, Quebec, H3G IM8, Canada; Control and Information Systems (CIS) Laboratory, Department of Mechanical and Industrial Engineering, Concordia University, Montreal, Quebec, H3G IM8, Canada",2007 IEEE International Conference on Robotics and Biomimetics (ROBIO),16-May-08,2007,,,1290,1295,"This paper presents a new framework and experimental setup for distributed simulation and virtual reality visualization of multi-robot receding horizon control (RHC) systems. A distributed RHC algorithm for formation control of multi-robot systems is implemented on multiple computers using a UDP/IP network and synchronization functions for real-time implementation. An object oriented virtual reality (VR) environment is also developed which can be interfaced with the distributed simulation. Several types of VR ground and air vehicles can be simulated and combined with the distributed RHC system for verification of the controller in an unstructured VR environment. Furthermore, a 6 degree of freedom motion platform is integrated with the system to allow pilot vehicle interaction studies. Together this work provides a general and useful tool for development and testing of multi-robot distributed RHC control systems.",,978-1-4244-1761-2,10.1109/ROBIO.2007.4522350,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4522350,Real-time distributed RHC;Virtual Reality;Formation Control;6-DOF platform,Virtual reality;Visualization;Control system synthesis;Distributed control;Computational modeling;Object oriented modeling;Control systems;Multirobot systems;Computer networks;Distributed computing,control engineering computing;data visualisation;distributed control;multi-robot systems;predictive control;synchronisation;virtual reality,distributed simulation;virtual reality visualization;multirobot distributed receding horizon control systems;multirobot receding horizon control systems;formation control;UDP/IP network;synchronization functions;real-time implementation;object oriented virtual reality environment,,3,,26,,16-May-08,,,IEEE,IEEE Conferences
Virtual experiments for introduction of computing: Using virtual reality technology,F. Li; D. Li; J. Zheng; S. Zhao,"School of Computer Science and Technology, Beijing Institute of Technology, Beijing 100081, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing 100081, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing 100081, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing 100081, China",2015 IEEE Frontiers in Education Conference (FIE),7-Dec-15,2015,,,1,5,"Introduction to Computing is a public course for the first-year non-major undergraduate students, aiming at training students for the abilities in computer science and technology with computational thinking. However, as new computer technologies emerge continuously and rapidly, it is required for this course to accommodate more and more knowledge. Therefore the teaching contents are growing enormously, which makes it very difficult to cover all of them in limited hours, and therefore sets an obstacle in understanding computing principles and building up a clear and general picture of computing, especially for non-major students. As computer science and technology are becoming more and more essential for various disciplines and majors, it is urgent for the education community to find out an effective and propagable way to solve this problem. In this regard, we employ virtual reality technology to the experiment teaching of this course, and have developed 18 virtual experiments to support the whole teaching process. For example, Turing machine is a basic model for computer science and technology. However, since it is not a real machine, it is not easy for the students to imagine the working process of Turing machine and understand the related concepts. Another example, the execution of an instruction is very important to understand the principles of computer organization. However, as the information flow is invisible, it is difficult and time-consuming for the teachers to explain how an instruction is executed inside a computer. Therefore, 3D modeling and animation techniques are used to demonstrate the invisible micro-structure of computers, and human-machine interaction and visualization techniques are used to present the internal process of information evolution, thus constructing a complete virtual experiment system of this course, including demonstration experiments, verification experiments and interaction experiments. Our virtual experiments have applied software copyrights and served more than 12,000 students from five universities of China since 2013. The evaluation demonstrates that the virtual experiments have produced excellent results in both teaching effectiveness and learning efficiency, relieved the conflicts between limited hours and vast knowledge, and helped students understand and build up the knowledge of computing.",,978-1-4799-8454-1,10.1109/FIE.2015.7344376,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7344376,virtual experiments;Introduction to Computing;virtual reality,Computers;Random access memory;Education;Turing machines;Computational modeling;Computer science;Animation,computer aided instruction;computer animation;computer science education;solid modelling;student experiments;training;Turing machines;virtual reality,virtual experiments;virtual reality technology;introduction to computing;public course;student training;computer science;computational thinking;teaching contents;Turing machine;computer organization;3D modeling;animation;human-machine interaction;demonstration experiments;verification experiments;interaction experiments;software copyrights;teaching effectiveness;learning efficiency,,5,,10,,7-Dec-15,,,IEEE,IEEE Conferences
An innovative virtual reality system for mild cognitive impairment: Diagnosis and evaluation,S. Yeh; Y. Chen; C. Tsai; A. Rizzo,"Computer Science and Information Engineering Dept., National Central University, Taiwan; Computer Science and Information Engineering Dept., National Central University, Taiwan; Taipei Veterans General Hospital, Taiwan; Institute for Creative Technologies, University of Southern California, USA",2012 IEEE-EMBS Conference on Biomedical Engineering and Sciences,15-Apr-13,2012,,,23,27,"In advanced countries throughout the world, the population of Alzheimer's Disease(AD) patients has been gradually increasing with the aging of the society. As a result, it has become an important research topic how to diagnose AD early and give necessary treatment and training to AD patients, especially those with mild cognitive impairment(MCI), whose executive functions such as response inhibition, cognitive flexibility, attention switching and planning may display evident disorder and impairment. Unlike traditional paper tests and subjective assessments by the patient's relatives, this study adopts virtual reality(VR) technology to develop a novel diagnosis & assessment system, which uses head mounted display(HMD), game technology and sensors to generate an interactive and panoramic scenario-a virtual convenience store-for assessment of executive functions and memory. A variety of tasks of multi-layered difficulty-level hierarchy, such as memorizing a shopping list, looking for certain goods, and checking out, has been designed for customized and adaptive assessment, training, and treatment of MD. In the meantime, the study also records test-takers' performance data (including path and central-vision movement) in the process of all tasks for the development of a novel diagnosis & assessment method. Moreover, test-takers' technology acceptance is measured for assessing the elderly's subjective perception of new technology and discussing the topic of human-machine interaction. In the study, tests on 2 healthy adults have been completed, the system's functionality has been preliminarily verified, and test-takers' subjective perception of the system has been investigated.",,978-1-4673-1666-8,10.1109/IECBES.2012.6498023,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6498023,virtual realit;mild cognitive impairment;Alzheimer's Disease;executive function,,computer games;diseases;helmet mounted displays;patient diagnosis;patient treatment;sensors;virtual reality,innovative virtual reality system;mild cognitive impairment;Alzheimer disease patient;AD diagnosis;AD patient treatment;AD patient training;MCI;response inhibition;cognitive flexibility;attention switching;planning;VR;head mounted display;HMD;game technology;sensors;virtual convenience store;multilayered difficulty-level hierarchy;test-taker performance data;path movement;central-vision movement;test-taker technology acceptance;elderly subjective perception;human-machine interaction;system functionality;test-taker subjective perception,,7,,7,,15-Apr-13,,,IEEE,IEEE Conferences
Automatic generation of world in miniatures for realistic architectural immersive virtual environments,A. Bonsch; S. Freitag; T. W. Kuhlen,"Visual Computing Institute, RWTH Aachen University, JARA - High Performance Computing; Visual Computing Institute, RWTH Aachen University, JARA - High Performance Computing; Visual Computing Institute, RWTH Aachen University, JARA - High Performance Computing",2016 IEEE Virtual Reality (VR),7-Jul-16,2016,,,155,156,"Orientation and wayfinding in architectural Immersive Virtual Environments (IVEs) are non-trivial, accompanying tasks which generally support the users' main task. World in Miniatures (WIMs) - essentially 3D maps containing a scene replica - are an established approach to gain survey knowledge about the virtual world, as well as information about the user's relation to it. However, for large-scale, information-rich scenes, scaling and occlusion issues result in diminishing returns. Since there typically is a lack of standardized information regarding scene decompositions, presenting the inside of self-contained scene extracts is challenging. Therefore, we present an automatic WIM generation workflow for arbitrary, realistic in- and outdoor IVEs in order to support users with meaningfully selected and scaled extracts of the IVE as well as corresponding context information. Additionally, a 3D user interface is provided to manually manipulate the represented extract.",2375-5334,978-1-5090-0836-0,10.1109/VR.2016.7504700,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504700,I.3.6 [Computer Graphics]: Methodology and Techniques ‚Äî Interaction Techniques,Three-dimensional displays;Context;Data mining;Solid modeling;Buildings;Runtime;Geometry,graphical user interfaces;virtual reality,3D user interface;indoor IVE;outdoor IVE;automatic WIM generation workflow;self-contained scene extraction;scene decompositions;large-scale scenes;information-rich scenes;3D maps;automatic world in miniature generation;realistic architectural immersive virtual environments,,3,,5,,7-Jul-16,,,IEEE,IEEE Conferences
"Altering the Stiffness, Friction, and Shape Perception of Tangible Objects in Virtual Reality Using Wearable Haptics",S. V. Salazar; C. Pacchierotti; X. de Tinguy; A. Maciel; M. Marchal,"University Rennes, CNRS, Inria, IRISA, Rennes, France; University Rennes, CNRS, Inria, IRISA, Rennes, France; University Rennes, INSA, IRISA, Inria, CNRS, Rennes, France; Federal University of Rio Grande do Sul, Porto Alegre, Brazil; University Rennes, INSA, IRISA, Inria, CNRS, Rennes, France",IEEE Transactions on Haptics,11-Mar-20,2020,13,1,167,174,"Tangible objects are used in virtual reality (VR) and augmented reality (AR) to enhance haptic information on the general shape of virtual objects. However, they are often passive or unable to simulate rich varying mechanical properties. This article studies the effect of combining simple passive tangible objects and wearable haptics for improving the display of varying stiffness, friction, and shape sensations in these environments. By providing timely cutaneous stimuli through a wearable finger device, we can make an object feel softer or more slippery than it really is, and we can also create the illusion of encountering virtual bumps and holes. We evaluate the proposed approach carrying out three experiments with human subjects. Results confirm that we can increase the compliance of a tangible object by varying the pressure applied through a wearable device. We are also able to simulate the presence of bumps and holes by providing timely pressure and skin stretch sensations. Altering the friction of a tangible surface showed recognition rates above the chance level, albeit lower than those registered in the other experiments. Finally, we show the potential of our techniques in an immersive medical palpation use case in VR. These results pave the way for novel and promising haptic interactions in VR, better exploiting the multiple ways of providing simple, unobtrusive, and inexpensive haptic displays.",2329-4051,,10.1109/TOH.2020.2967389,European Union's Horizon 2020 Research and Innovation Programme; Fapergs-Brazil PqG 2017 Project; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8961106,Haptic interfaces;tactile feedback;human computer interaction.,Haptic interfaces;Shape;Pistons;Skin;Friction;End effectors;Force,augmented reality;haptic interfaces;human computer interaction;image resolution;medical image processing;skin,wearable finger device;wearable device;VR;haptic interactions;virtual reality;augmented reality;haptic information;virtual objects;mechanical properties;tangible object friction;tangible object stiffness;tangible object shape perception;immersive medical palpation,"Adult;Biomechanical Phenomena;Equipment Design;Feedback, Sensory;Female;Friction;Humans;Male;Surface Properties;Touch Perception;Virtual Reality;Wearable Electronic Devices;Young Adult",1,,29,IEEE,16-Jan-20,,,IEEE,IEEE Journals
An In-Depth Exploration of the Effect of 2D/3D Views and Controller Types on First Person Shooter Games in Virtual Reality,D. Monteiro; H. -N. Liang; J. Wang; H. Chen; N. Baghaei,Xi‚Äôan Jiaotong-Liverpool University; Xi‚Äôan Jiaotong-Liverpool University; Xi‚Äôan Jiaotong-Liverpool University; Xi‚Äôan Jiaotong-Liverpool University; Massey University,2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),14-Dec-20,2020,,,713,724,"The amount of interest in Virtual Reality (VR) research has significantly increased over the past few years, both in academia and industry. The release of commercial VR Head-Mounted Displays (HMDs) has been a major contributing factor. However, there is still much to be learned, especially how views and input techniques, as well as their interaction, affect the VR experience. There is little work done on First-Person Shooter (FPS) games in VR, and those few studies have focused on a single aspect of VR FPS. They either focused on the view, e.g., comparing VR to a typical 2D display or on the controller types. To the best of our knowledge, there are no studies investigating variations of 2D/3D views in HMDs, controller types, and their interactions. As such, it is challenging to distinguish findings related to the controller type from those related to the view. If a study does not control for the input method and finds that 2D displays lead to higher performance than VR, we cannot generalize the results because of the confounding variables. To understand their interaction, we propose to analyze in more depth, whether it is the view (2D vs. 3D) or the way it is controlled that gives the platforms their respective advantages. To study the effects of the 2D/3D views, we created a 2D visual technique, PlaneFrame, that was applied inside the VR headset. Our results show that the controller type can have a significant positive impact on performance, immersion, and simulator sickness when associated with a 2D view. They further our understanding of the interactions that controllers and views have and demonstrate that comparisons are highly dependent on how both factors go together. Further, through a series of three experiments, we developed a technique that can lead to a substantial performance, a good level of immersion, and can minimize the level of simulator sickness.",1554-7868,978-1-7281-8508-8,10.1109/ISMAR50242.2020.00102,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284718,Virtual Reality;2D/3D Views;Controller types;First Person Shooter;Gaming;Head-Mounted Displays,Performance evaluation;Visualization;Three-dimensional displays;Two dimensional displays;Keyboards;Games;Turning,computer games;data visualisation;helmet mounted displays;virtual reality,virtual reality;input techniques;VR experience;VR FPS;typical 2D display;controller type;2D visual technique;VR headset;first person shooter games;commercial VR head-mounted displays;2D-3D views;PlaneFrame,,,,54,,14-Dec-20,,,IEEE,IEEE Conferences
Seated Immersive Exergaming for Fall Prevention of Older Adults,S. Rings; F. Steinicke; T. Picker; C. Prasuhn,Universit√§at Hamburg; Universit√§at Hamburg; Hochschule D√ºsseldorf; Universit√§at Hamburg,2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),11-May-20,2020,,,289,290,"Virtual reality (VR) exergames provide a unique opportunity for developing safe and effective therapies for older adults at assisted living facilities. This group of people has an increased risk of falls, which can lead to severe injuries and increase the risk of falls even further. An early detailed individualized assessment and treatment intervention for older adults with preexisting conditions is recommend, but the workload for physicians is high and training is often perceived as boring because exercises generally do not change that often. In this paper we introduce a seated VR exergame for fall prevention of older adults. The game has been designed and developed together with clinical experts and therapists to provide adequate fall prevention exercises, which can be implemented in patients daily schedules and administered through a VR exergame. Movements that control the exergame match the motions suggested by our partner physicians and improve balance by shifting the players center of mass.",,978-1-7281-6532-5,10.1109/VRW50115.2020.00063,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9090601,Human-centered computing;Human-computer interaction (HCI);Interaction Paradigms;virtual reality,Training;Cameras;Medical treatment;Assisted living;Task analysis;Torso,biomechanics;biomedical equipment;computer games;diseases;geriatrics;patient care;patient diagnosis;patient treatment;virtual reality,safe therapies;assisted living facilities;treatment intervention;seated VR exergame;fall prevention exercises,,,,10,,11-May-20,,,IEEE,IEEE Conferences
Immersive and non-immersive virtual reality system to learn relative motion concepts,M. Kozhevnikov; J. Gurlitt,"Department of Engineering, Norfolk State University, VA USA; Department of Educational Science, University of Freiburg, Germany",2013 3rd Interdisciplinary Engineering Design Education Conference,10-Jun-13,2013,,,168,172,"The focus of the current study is to understand the strength and limits of immersive virtual environments as a new media for learning and teaching relative motion concepts. Our results show that while training in both Immersive Virtual Environment (IVE) and Desktop (non-immersive) Virtual Environment (DVE) resulted in a significant improvement on relative motion problem solving test in general, the IVE group performed significantly better than the DVE group on solving two-dimensional relative motion problems after training in the simulations. This result supports our hypothesis that egocentric encoding of the scene in IVE (where the learner constitutes a part of a scene being immersed in it) as compared to allocentric encoding on a computer screen in DVI (where the earner is looking on the scene from ‚Äúoutside‚Äù) is beneficial for studying two-dimensional problems.",,978-1-4673-5112-6,10.1109/IEDEC.2013.6526781,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6526781,Virtual Environment;Educational Technology;Immersivity;Relative Motion,Computational modeling;Solid modeling;Switches;Abstracts;Reliability;Real-time systems;Virtual reality,computer aided instruction;human computer interaction;teaching;user interfaces;virtual reality,immersive virtual reality system;non immersive virtual reality system;relative motion concept learning;relative motion concept teaching;desktop virtual environment;IVE;DVE;motion problem solving test;educational technology,,2,,14,,10-Jun-13,,,IEEE,IEEE Conferences
An Interaction Tool for Immersive Environments Using Mobile Devices,D. P. d. S. Medeiros; F. G. d. Carvalho; A. B. Raposo; I. H. F. d. Santos,"Tecgraf - Comput. Graphics Group PUC-Rio (Pontificia Univ. Catolica do Rio de Janeiro), Rio de Janeiro, Brazil; Tecgraf - Comput. Graphics Group PUC-Rio (Pontificia Univ. Catolica do Rio de Janeiro), Rio de Janeiro, Brazil; Tecgraf - Comput. Graphics Group PUC-Rio (Pontificia Univ. Catolica do Rio de Janeiro), Rio de Janeiro, Brazil; Petrobras, CENPES, Rio de Janeiro, Brazil",2013 XV Symposium on Virtual and Augmented Reality,7-Nov-13,2013,,,90,96,"Interaction in engineering virtual environments differs by the necessity of the high precision level needed for the execution of specifics tasks for this kind of environment. Generally this kind of task uses specific interaction devices with 4 or more DOF. Current applications involving 3D interaction use interaction devices for object modelling or for the implementation of navigation, selection and manipulation tecniques in a virtual environment. A related problem is the necessity of controlling tasks that are naturally non-immersive, such as symbolic input (e.g., text, photos). Another problem is the large learning curve to handle such non-conventional devices. The addition of sensors and the popularization of smartphones and tablets, allowed the use of such devices in virtual engineering environments. Thes devices, besides their popularity and sensors, differs by the possibility of including additional information and performing naturally non-immersive tasks. This work presents a 3D interaction tablet-based tool, which allows the aggregation of all major 3D interaction topics, such as navigation, selection, manipulation, system control and symbolic input.",,978-0-7695-5001-5,10.1109/SVR.2013.32,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6655766,3D Interaction;virtual reality;mobile devices;virtual environments,Three-dimensional displays;Smart phones;Solid modeling;Virtual environments;Navigation;Sensors,mobile computing;notebook computers;smart phones;task analysis;virtual reality,interaction tool;immersive environment;mobile devices;task execution;interaction device;object modelling;navigation;selection technique;manipulation technique;virtual environment;task control;symbolic input;smartphones;virtual engineering environment;naturally nonimmersive task;3D interaction tablet-based tool;system control,,2,,22,,7-Nov-13,,,IEEE,IEEE Conferences
Instrument-Tissue Segment Interaction Using Finite Element Modeling,A. Alsaraira; I. Brown; R. McColl; F. Lim,"Monash University Centre for Biomedical Engineering, Department of Electrical and Computer Systems Engineering, PO BOX 72, Monash University, 3800, Australia. Phone: +61 3 9905 1821; fax: +61 3 9905 3454; e-mail: Amer.Alsaraira@eng.monash.edu.au; Assoc. Prof., Member, IEEE, Monash University Centre for Biomedical Engineering, Department of Electrical and Computer Systems Engineering, PO BOX 72, Monash University, 3800, Australia; Monash University Centre for Biomedical Engineering, Department of Electrical and Computer Systems Engineering, PO BOX 72, Monash University, 3800, Australia; Monash University Centre for Biomedical Engineering, Department of Electrical and Computer Systems Engineering, PO BOX 72, Monash University, 3800, Australia",2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,22-Oct-07,2007,,,2760,2763,A virtual reality based laparoscopic surgery simulator is an important training option for laparoscopic surgeons. It has significant advantages over other training methods. Instruments-anatomy interactions are one of the main features of these simulators. In this paper we present the deformation of the uterine tube using three dimensional finite element methods with finite element software. The work examines the feasibility of incorporating the finite element (FE) model within the visual graphic model to achieve high degree of realism of instrument-tissue interactions.,1558-4615,978-1-4244-0787-3,10.1109/IEMBS.2007.4352900,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4352900,,Instruments;Finite element methods;Solid modeling;Deformable models;Computational modeling;Laparoscopes;Minimally invasive surgery;Humans;Biological system modeling;Computational geometry,biological organs;biological tissues;biomechanics;biomedical education;computer based training;computer graphics;deformation;finite element analysis;medical computing;physiological models;surgery;virtual reality,instrument-tissue segment interaction model;three dimensional finite element modeling;virtual reality;laparoscopic surgery simulator;laparoscopic surgery training;uterine tube deformation;finite element software;visual graphic model,"Computer-Assisted Instruction;Elasticity;Finite Element Analysis;General Surgery;Laparoscopy;Models, Anatomic;Robotics;Software",1,,14,,22-Oct-07,,,IEEE,IEEE Conferences
Tangi: Tangible Proxies For Embodied Object Exploration And Manipulation In Virtual Reality,M. Feick; S. Bateman; A. Tang; A. Miede; N. Marquardt,"University College London,London,UK; University of New Brunswick,Fredericton,Canada; University of Toronto,Toronto,Canada; htw saar,Saarbruecken,Germany; University College London,London,UK",2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),14-Dec-20,2020,,,195,206,"Exploring and manipulating complex virtual objects is challenging due to limitations of conventional controllers and free-hand interaction techniques. We present the TanGi toolkit which enables novices to rapidly build physical proxy objects using Composable Shape Primitives. TanGi also provides Manipulators allowing users to build objects including movable parts, making them suitable for rich object exploration and manipulation in VR. With a set of different use cases and applications we show the capabilities of the TanGi toolkit and evaluate its use. In a study with 16 participants, we demonstrate that novices can quickly build physical proxy objects using the Composable Shape Primitives and explore how different levels of object embodiment affect virtual object exploration. In a second study with 12 participants we evaluate TanGi's Manipulators and investigate the effectiveness of embodied interaction. Findings from this study show that TanGi's proxies outperform traditional controllers and were generally favored by participants.",1554-7868,978-1-7281-8508-8,10.1109/ISMAR50242.2020.00042,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284771,Virtual Reality;Tangible Interfaces;VR Object Exploration and Manipulation;Tangible Proxy Objects,Shape;Manipulators;Augmented reality,manipulators;virtual reality,complex virtual objects;free-hand interaction techniques;TanGi toolkit;physical proxy objects;object exploration;object embodiment;manipulators;virtual reality;composable shape primitives,,,,66,,14-Dec-20,,,IEEE,IEEE Conferences
Gesture3DFramework: A Generic Gesture-Based Interaction Middleware Applied to 3D Environments,D. Passos Costa; P. N. M. Sampaio; V. F. Martins,"Computing and Systems Graduate Program Salvador University (UNIFACS) Salvador, Bahia, Brazil; Computing and Systems Graduate Program Salvador University (UNIFACS) Salvador, Bahia, Brazil; School of Computing and Informatics Marckenzie Presbiterian University S√£o Paulo, S√£o Paulo, Brazil",2018 XLIV Latin American Computer Conference (CLEI),5-Aug-19,2018,,,590,598,"The technological advances provide the development and wide adoption of different kinds of humanmachine interfaces, which leads to the creation of new applications such as those based on multimedia and virtual reality (3D). In particular, the proposal of interaction metaphors applied to 3D environments which aim at replicating real world concepts into the virtual environment, facilitates user's interaction. The utilization of gestural interaction metaphors within a 3D environment can turn the user experience more familiar and concrete, making the training curb smaller. However, in order to apply interaction metaphors it is necessary their classification and generalization, so that they can be widely deployed in different applications. This paper introduces the development of a generic and customizable solution for the mediation of user gestural interaction (selection, manipulation and navigation) with heterogeneous rendering engines for virtual reality environments. This solution, called Gesture3DFramework, allows the users context and gesture-metaphors configuration to be easily customized so that it can be adaptable to multiple 3D virtual environments. With Gesture3DFramework, the final user (and developer) will be provided with a higher level of abstraction when it comes to the development of interactive virtual reality applications, since once the configuration directives have been described, the system will adapt itself to the specific interaction routines of the applied rendering engine.",,978-1-7281-0437-9,10.1109/CLEI.2018.00076,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8786315,Virtual Reality;Gesture Interaction;Selection;Manipulation;Navigation;Immersion;3D environment,Three-dimensional displays;Casting;Navigation;Middleware;Virtual environments;Rendering (computer graphics),gesture recognition;graphical user interfaces;human computer interaction;middleware;rendering (computer graphics);virtual reality,generic gesture-based interaction middleware;user experience;user gestural interaction;multiple 3D virtual environments;interactive virtual reality applications;Gesture3DFramework;rendering engine;interaction routines,,,,,,5-Aug-19,,,IEEE,IEEE Conferences
"London calling: GIS, VR, and the Victorian period",R. F. Chevez; T. L. Milbank,NA; NA,Proceedings Seventh International Conference on Virtual Systems and Multimedia,6-Aug-02,2001,,,335,344,"The Bolles Collection of Tufts University represents a comprehensive and integrated collection of sources on the history and topography of Victorian London. Texts, images, maps, and three-dimensional reconstructions are all interconnected forming a body of material that transcends the limits of print publication and exploits the flexibility of the electronic medium. The Perseus Digital Library has incorporated geographic information system and virtual reality technologies in a set of tools intended to help readers synthesize and visualize the numerous temporal and spatial interconnections between Bolles Collection materials. The tools, which are applicable to any large assemblage of related documents, also help readers grasp the complex temporal-spatial interactions that shape historical materials in general.",,0-7695-1402-2,10.1109/VSMM.2001.969688,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=969688,,Geographic Information Systems;Virtual reality;Software libraries;Visualization;Books;Surfaces;Assembly;History;Image reconstruction;Shape,cartography;virtual reality;solid modelling;history;geographic information systems;interactive systems,Bolles Collection;Tufts University;Perseus Digital Library;geographic information system;virtual reality;London;3D image reconstructions;temporal-spatial interactions,,1,,3,,6-Aug-02,,,IEEE,IEEE Conferences
Gesture recognition for virtual reality applications using data gloves and neural networks,J. Weissmann; R. Salomon,"Dept. of Comput. Sci., Zurich Univ., Switzerland; NA",IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339),6-Aug-02,1999,3,,2043,2046 vol.3,"Explores the use of hand gestures as a means of human-computer interactions for virtual reality applications. For the application, specific hand gestures, such as ""fist"", ""index finger"" and ""victory sign"", have been defined. Most existing approaches use various camera-based recognition systems, which are rather costly and very sensitive to environmental changes. In contrast, this paper explores a data glove as the input device, which provides 18 measurement values for the angles of different finger joints. The paper compares the performance of different neural network models, such as backpropagation and radial-basis functions, which are used by the recognition system to recognize the actual gesture. Some network models achieve a recognition rate (training as well a generalization) of up to 100% over a number of test subjects. Due to its good performance, this recognition system is the first step towards virtual reality applications in which program execution is controlled by a sign language.",1098-7576,0-7803-5529-6,10.1109/IJCNN.1999.832699,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=832699,,Virtual reality;Data gloves;Neural networks;Application software;Fingers;Wrist;Mice;Image recognition;Computer science;Testing,gesture recognition;virtual reality;data gloves;backpropagation;radial basis function networks,neural networks;hand gestures;human-computer interactions;fist;index finger;victory sign;radial-basis functions;sign language,,28,1,8,,6-Aug-02,,,IEEE,IEEE Conferences
Faster Multibeam Sonar Data Cleaning: Evaluation of Editing 3D Point Clouds using Immersive VR,A. H. Stevens; T. Butkiewicz,"Center for Coastal and Ocean Mapping, University of New Hampshire,Durham,New Hampshire,USA; Center for Coastal and Ocean Mapping, University of New Hampshire,Durham,New Hampshire,USA",OCEANS 2019 MTS/IEEE SEATTLE,20-Jan-20,2019,,,1,10,"Remote sensing technologies routinely generate point cloud datasets with billions of points. While automatic data cleaning algorithms exist, safety-critical applications (such as waterway surveys) still require that data be processed and verified by a human. This presents a significant bottleneck in the pipeline from surveys into navigational maps. The recent proliferation of low-cost, high-quality virtual reality systems presents an opportunity to explore how these technologies might be integrated into the point cloud data processing pipeline. Prior research has shown that stereoscopic viewing, head-tracked perspective, and bimanual interactions can lead to faster 3D task completion times and lower errors compared to traditional monoscopic, mouse-and-keyboard desktop systems. In this paper, we present a human factors study that compares 3D point cloud editing performance between a traditional interface and type types of immersive virtual reality interfaces. Our results showed that for complex datasets, the immersive interfaces generally led to faster task completion times than when using the desktop interface. Participants also reported a strong subjective preference for the immersive interface.",0197-7385,978-0-578-57618-3,10.23919/OCEANS40490.2019.8962793,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8962793,virtual reality;point clouds;editing;annotation,,data handling;graphical user interfaces;human factors;remote sensing;sonar imaging;stereo image processing;virtual reality,navigational maps;high-quality virtual reality systems;point cloud data processing pipeline;head-tracked perspective;human factors;3D point cloud editing performance;immersive virtual reality interfaces;complex datasets;immersive VR;remote sensing technologies;point cloud datasets;automatic data cleaning algorithms;safety-critical applications;waterway surveys;multibeam sonar data cleaning;3D task completion times;stereoscopic viewing;bimanual interactions,,,,55,,20-Jan-20,,,IEEE,IEEE Conferences
An intestinal surgery simulator: real-time collision processing and visualization,L. Raghupathi; L. Grisoni; F. Faure; D. Marchal; M. -. Cani; C. Chaillou,"GRAVIR/IMAG Lab., Montbonnet, France; NA; NA; NA; NA; NA",IEEE Transactions on Visualization and Computer Graphics,13-Sep-04,2004,10,6,708,718,"This research work is aimed toward the development of a VR-based trainer for colon cancer removal. It enables the surgeons to interactively view and manipulate the concerned virtual organs as during a real surgery. First, we present a method for animating the small intestine and the mesentery (the tissue that connects it to the main vessels) in real-time, thus enabling user interaction through virtual surgical tools during the simulation. We present a stochastic approach for fast collision detection in highly deformable, self-colliding objects. A simple and efficient response to collisions is also introduced in order to reduce the overall animation complexity. Second, we describe a new method based on generalized cylinders for fast rendering of the intestine. An efficient curvature detection method, along with an adaptive sampling algorithm, is presented. This approach, while providing improved tessellation without the classical self-intersection problem, also allows for high-performance rendering thanks to the new 3D skinning feature available in recent GPUs. The rendering algorithm is also designed to ensure a guaranteed frame rate. Finally, we present the quantitative results of the simulations and describe the qualitative feedback obtained from the surgeons.",1941-0506,,10.1109/TVCG.2004.36,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1333668,Index Terms- Virtual reality;physically-based modeling;animation;curve and surface representation.,Intestines;Visualization;Oncological surgery;Animation;Colon;Cancer;Stochastic processes;Object detection;Sampling methods;Algorithm design and analysis,data visualisation;virtual reality;cancer;surgery;computer animation;rendering (computer graphics);medical image processing;user interfaces;simulation;computational geometry;sampling methods,intestinal surgery simulator;real-time collision processing;real-time visualization;VR-based trainer;colon cancer removal;virtual organ;user interaction;virtual surgical tool;stochastic approach;self-colliding object;animation complexity;self-intersection problem;3D skinning feature;virtual reality;physically-based model,"Algorithms;Biomedical Engineering;Colonic Neoplasms;Computer Graphics;Computer Simulation;Computer Systems;Computer-Assisted Instruction;Digestive System Surgical Procedures;Digestive System Surgical Procedures;Humans;Intestine, Small;Intestine, Small;Models, Anatomic;User-Computer Interface",34,3,41,,13-Sep-04,,,IEEE,IEEE Journals
Distance-based modeling and manipulation techniques using ultrasonic gloves,T. N. Hoang; B. H. Thomas,"Wearable Computer Lab - University of South Australia, Australia; Wearable Computer Lab - University of South Australia, Australia",2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),7-Jan-13,2012,,,287,288,"We present a set of distance-based interaction techniques for modeling and manipulation, enabled by a new input device called the ultrasonic gloves. The ultrasonic gloves are built upon the original design of the pinch glove device for virtual reality systems with a tilt sensor and a pair of ultrasonic transducers in the palms of the gloves. The transducers are distance-ranging sensors that allow the user to specify a range of distances by natural gestures such as facing the palms towards each other or towards other surfaces. The user is able to create virtual models of physical objects by specifying their dimensions with hand gestures. We combine the reported distance with the tilt orientation data to construct virtual models. We also map the distance data to create a set of affine transformation techniques, including relative and fixed scaling, translation, and rotation. Our techniques can be generalized to different sensor technologies.",,978-1-4673-4662-7,10.1109/ISMAR.2012.6402577,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402577,ultrasonic gloves;distance-based techniques;modeling;manipulation,Acoustics;Solid modeling;Ultrasonic variables measurement;Thumb;Ultrasonic transducers;Augmented reality,augmented reality;data gloves;sensors;solid modelling;user interfaces,distance-based modeling technique;distance-based manipulation technique;ultrasonic gloves;distance-based interaction technique;pinch glove device;virtual reality system;tilt sensor;ultrasonic transducer;distance-ranging sensor;virtual model;hand gesture;tilt orientation data;affine transformation technique;relative scaling technique;fixed scaling technique;translation technique;rotation technique;sensor technology,,4,,7,,7-Jan-13,,,IEEE,IEEE Conferences
Easy Extrinsic Calibration of VR System and Multi-camera Based Marker-Less Motion Capture System,K. Takahashi; D. Mikami; M. Isogawa; S. Sun; Y. Kusachi,NTT; NTT; NTT; NTT; NTT,2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),9-Jan-20,2019,,,83,88,"This paper proposes a novel easy extrinsic calibration algorithm for an off-the-shelf VR system and a multi-camera based marker-less motion capture system. To realize interactions between 3D user motions and virtual objects reconstructed from multi-view videos in a common 3D space, the extrinsic calibration of the VR system and the multiple cameras must be conducted beforehand. This calibration, which involves estimating the pose and position of each coordinate system, is a key technology for handling 3D information in a system with various type of input sources. In general, extrinsic calibration is carried out by identifying and utilizing some common 3D points. However, since most of off-the-shelf VR systems do not include any imaging device, it is difficult to apply conventional automatic calibration approaches as there are no common points shared with the cameras. Against this problem, this paper introduces an easy calibration algorithm by generating corresponding points from the trajectories of the user's motion with VR devices and 3D human pose reconstructed from multi-view videos. Our study provides the following two contributions; (1) our method does not need to introduce additional devices, such as a chessboard and (2) our method does not need manual processes as the extrinsic parameters are automatically estimated. We demonstrate the performance of the proposed method in a practical scenario.",,978-1-7281-4765-9,10.1109/ISMAR-Adjunct.2019.00036,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951990,calibration;motion;multi view,,cameras;image capture;image motion analysis;image reconstruction;pose estimation;stereo image processing;video signal processing;virtual reality,VR devices;multiview videos;extrinsic calibration algorithm;off-the-shelf VR system;3D user motions;common 3D space;multiple cameras;common 3D points;automatic calibration approaches;multicamera based markerless motion capture system;virtual objects reconstruction;3D human pose reconstruction,,,,18,,9-Jan-20,,,IEEE,IEEE Conferences
An evaluation of two simple methods for representing heaviness in immersive virtual environments,J. Hummel; J. Dodiya; R. Wolff; A. Gerndt; T. Kuhlen,"Simulation and Software Technology, German Aerospace Center (DLR), Germany; Simulation and Software Technology, German Aerospace Center (DLR), Germany; Simulation and Software Technology, German Aerospace Center (DLR), Germany; Simulation and Software Technology, German Aerospace Center (DLR), Germany; Virtual Reality Group, RWTH Aachen University, Germany",2013 IEEE Symposium on 3D User Interfaces (3DUI),5-Sep-13,2013,,,87,94,"Weight perception in virtual environments generally can be achieved with haptic devices. However, most of these are hard to integrate in an immersive virtual environment (IVE) due to their technical complexity and the restriction of a user's movement within the IVE. We describe two simple methods using only a wireless light-weight finger-tracking device in combination with a physics simulated hand model to create a feeling of heaviness of virtual objects when interacting with them in an IVE. The first method maps the varying distance between tracked fingers and the thumb to the grasping force required for lifting a virtual object with a given weight. The second method maps the detected intensity of finger pinch during grasping gestures to the lifting force. In an experiment described in this paper we investigated the potential of the proposed methods for the discrimination of heaviness of virtual objects by finding the just noticeable difference (JND) to calculate the Weber fraction. Furthermore, the workload that users experienced using these methods was measured to gain more insight into their usefulness as interaction technique. At a hit ratio of 0.75, the determined Weber fraction using the finger distance based method was 16.25% and using the pinch based method was 15.48%, which corresponds to values found in related work. There was no significant effect of method on the difference threshold measured and the workload experienced, however the user preference was higher for the pinch based method. The results demonstrate the capability of the proposed methods for the perception of heaviness in IVEs and therefore represent a simple alternative to haptics based methods.",,978-1-4673-6098-2,10.1109/3DUI.2013.6550202,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6550202,,Force;Grasping;Thumb;Skin;Software,gesture recognition;haptic interfaces;virtual reality,heaviness representation;immersive virtual environments;IVE;weight perception;technical complexity;wireless light-weight finger-tracking device;physics simulated hand model;finger pinch intensity detection;grasping gestures;heaviness discrimination;just noticeable difference;JND;determined Weber fraction;finger distance based method;haptics based methods,,6,,27,,5-Sep-13,,,IEEE,IEEE Conferences
Architectural approach to interoperability between multi-agent systems and 3D virtual worlds,H. B. Bar√≥n; R. G. Crespo; O. S. Martinez,"Facultad de Ingenier√≠a, Universidad Cat√≥lica de Colombia, Bogot√°, Colombia; Escuela de Ingenier√≠a y Arquitectura, Universidad Pontificia de Salamanca, Madrid, Spain; Facultad de Ingenier√≠a, Universidad Carlos III Madrid, Spain",2013 8th Computing Colombian Conference (8CCC),21-Oct-13,2013,,,1,6,"The three-dimensional interfaces are approaching to virtual reality, because allowing to create simulation scenarios in which man interacts to likeness of the real live, however, a rich graphical environment and natural interaction itself neither warrants effective learning, it need a monitoring, evaluation and feedback. Therefore, We propose the integration of three-dimensional environments with multi agents system, it is looking customize the learning process to the individual needs of students, organize and distribute content efficiently and support student reflection on their learning. Different studies have made specific implementations of agents through markup languages, however the proposed model, looks for general purpose implementations. Our architectural model integrates the behaviors of multi-agent systems and virtual 3D World. Validation was performed through an implementation that integrates Java Agent Development Framework developed by Telecom Italia Lab and OpenSimulator.",,978-1-4799-1056-4,10.1109/ColombianCC.2013.6637528,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6637528,intelligent Agents;3D Virtual Worlds;Architectural Approach;Interoperability,Three-dimensional displays;Second Life;Solid modeling;Software;Unified modeling language;ISO standards;Servers,computer aided instruction;human computer interaction;Java;multi-agent systems;open systems;software architecture;virtual reality,interoperability;multiagent systems;3D virtual worlds;three-dimensional interfaces;virtual reality;simulation scenarios;graphical environment;natural interaction;learning process customization;individual student needs;content distribution;content organization;markup languages;general purpose implementations;architectural model;Java agent development framework;Telecom Italia Lab;OpenSimulator,,,,22,,21-Oct-13,,,IEEE,IEEE Conferences
Construction of virtual world using dynamics modules and interaction modules,T. Yoshikawa; H. Ueda,"Dept. of Mech. Eng., Kyoto Univ., Japan; Dept. of Mech. Eng., Kyoto Univ., Japan",Proceedings of IEEE International Conference on Robotics and Automation,6-Aug-02,1996,3,,2358,2364 vol.3,"Recently force-feedback has been recognized to be important for virtual reality systems, and many studies have been done in this field. Although we have proposed several methods for displaying the operating feel of a virtual object by considering its dynamics, we have not dealt with cases of multiple objects or operators. In more advanced applications of haptic virtual reality, however, multiple operators and multiple objects will generally exist in the virtual world. In this paper, we propose a systematic method of constructing a virtual world by combining the dynamics modules and interaction modules, the former denoting elements of the virtual world (virtual objects or operators) and the latter denoting interactions between them. Since this method makes it possible to regard those elements as equal, we can construct a flexible and extendable virtual world to which we can easily add new elements or remove some of its elements. An experimental result using a prototype force display system shows the validity of the proposed method.",1050-4729,0-7803-2988-0,10.1109/ROBOT.1996.506516,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506516,,Modular construction;Virtual reality;Haptic interfaces;Virtual prototyping;Auditory displays;Interference;Collaboration;Manipulator dynamics,virtual reality;dynamics;feedback;interactive systems;telerobotics,virtual world;dynamics modules;interaction modules;force-feedback;dynamics;haptic virtual reality;force display system,,14,40,8,,6-Aug-02,,,IEEE,IEEE Conferences
The empty museum. Multi-user interaction in an immersive and physically walkable VR space,L. Hernandez; J. Taibo; A. Seoane; R. Lopez; R. Lopez,"Eng., Archit. & Urban Design Visualisation Group, Univ. da Coruna, Spain; Eng., Archit. & Urban Design Visualisation Group, Univ. da Coruna, Spain; Eng., Archit. & Urban Design Visualisation Group, Univ. da Coruna, Spain; Eng., Archit. & Urban Design Visualisation Group, Univ. da Coruna, Spain; Eng., Archit. & Urban Design Visualisation Group, Univ. da Coruna, Spain",Proceedings. 2003 International Conference on Cyberworlds,8-Jan-04,2003,,,446,452,"Until quite recently, virtual reality systems consisted of fixed devices which enabled the user to feel immersed in a spot of the virtual space by means of the adequate hardware. The recent emergence of wireless systems for motion capture, together with the increase in graphic power of laptops, and the generalisation of wireless networks has allowed the appearance of the first systems in which at last the user is able to walk physically within a given space framed in the real one, and containing the objects and elements of the virtual space. Some examples of this hybrid space have already been accomplished worldwide. However, beyond the technical problems with the development of these systems, we must bear in mind the types of contents to be shown, making the most of the possibilities offered by the fact that the user him/herself is the pointer in this kind of virtual reality, while the space itself is the interface. The authors have recently developed a system similar to the ones described. This is a totally immersive, walkable and wireless system called the Empty Museum. The paper outlines its enlargement with the purpose of making it simultaneously usable by several persons. Besides, an example of content is provided which has been specifically designed in order to be experienced in multi-user mode with this equipment: the Virtual Art Gallery.",,0-7695-1922-9,10.1109/CYBER.2003.1253488,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1253488,,Virtual reality;Head;Hardware;Displays;Design engineering;Visualization;Irrigation;Graphics;Portable computers;Wireless networks,virtual reality;art;wireless LAN,multi-user interaction;VR space;virtual reality;wireless system;wireless network;virtual art gallery,,2,,12,,8-Jan-04,,,IEEE,IEEE Conferences
A comparison between measured and modelled head-related transfer functions for an enhancement of real-time 3D audio processing for virtual reality environments,A. S. Suarez; J. Tissieres; L. S. Vieira; R. Hunter-McHardy; S. K. Sernavski; S. Serafin,Aalborg University Copenhagen; Aalborg University Copenhagen; Aalborg University Copenhagen; Aalborg University Copenhagen; Aalborg University Copenhagen; Aalborg University Copenhagen,2017 IEEE 3rd VR Workshop on Sonic Interactions for Virtual Environments (SIVE),17-Apr-17,2017,,,1,9,"Sound in Virtual Reality (VR) has been explored in a variety of algorithms which try to enhance the illusion of presence, improving sound localization and spatialization in the virtual environment. As new systems are developed, different models are applied. There is still the need to evaluate and understand the main advantages of each of these approaches. In this study, a performance comparison of two methods for real-time 3D binaural sound tested preferences and quality of presence for headphones in a VR experience. Both the mathematical based HRTF and the convolution based measured HRTF from the MIT KEMAR show a general similarity in the participants sense of localization, depth and presence. Nevertheless, the tests also indicate a preference in elevation perception for the convolution-based measured HRTF. Further experiments with new tools, techniques, contexts, and guidelines are therefore required to highlight the importance and differences between these two methods and other implementations.",,978-1-5386-0459-5,10.1109/SIVE.2017.7901609,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7901609,,Ear;Three-dimensional displays;Convolution;Computational modeling;Databases;Mathematical model;Azimuth,audio signal processing;real-time systems;virtual reality,real-time 3D audio processing enhancement;virtual reality environments;sound localization;sound spatialization;binaural sound tested preferences;quality of presence;headphones;VR experience;mathematical based HRTF;MIT KEMAR;convolution,,2,2,11,,17-Apr-17,,,IEEE,IEEE Conferences
Navigation Power of MaxWhere: a Unique Solution,B. Berki,"Sz√©chenyi Istv√°n University, Doctoral School of Multidisciplinary Engineering Sciences,Gy√∂r,Hungary",2020 11th IEEE International Conference on Cognitive Infocommunications (CogInfoCom),2-Nov-20,2020,,,509,514,"Precise and accurate navigation is an elementary expectation in desktop virtual realities. In this paper, the navigation method of MaxWhere VR is presented, furthermore, it is analyzed in terms of interaction fidelity and controller mapping. The MaxWhere VR platform offers different navigational operations, that are optimized for an external mouse with a scroll wheel. Besides moving forward and backward, rotating the camera view and lifting, another navigation type is available, the spherical orbit. This navigational operation is known from engineering software, and its role is to look around a selected object and observe it from each side. This function can be useful in educational and exhibition spaces where 3D models are located. These navigational operations are considered low-fidelity interactions, compared to human motions, although with the directionally mapped general control devices, such as a mouse, high perceived naturalness can be achieved that can relate to a higher sense of spatial presence.",2380-7350,978-1-7281-8213-1,10.1109/CogInfoCom50765.2020.9237904,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237904,virtual reality;navigation;spherical orbit;MaxWhere,Three-dimensional displays;Navigation;Wheels;Virtual reality;Orbits;Mice;Software,mouse controllers (computers);solid modelling;virtual reality,elementary expectation;desktop virtual realities;interaction fidelity;controller mapping;MaxWhere VR platform;navigational operations;external mouse;scroll wheel;camera view;lifting;navigation type;navigational operation;low-fidelity interactions;3D models,,,,36,,2-Nov-20,,,IEEE,IEEE Conferences
Withindows: A Framework for Transitional Desktop and Immersive User Interfaces,A. Hill; A. Johnson,"University of Illinois at Chicago, e-mail: ahill@evl.uic.edu; University of Illinois at Chicago, e-mail: ajohnson@uic.edu",2008 IEEE Symposium on 3D User Interfaces,31-Mar-08,2008,,,3,10,"The uniqueness of 3D interaction is often used to justify levels of user fatigue that are significantly higher than those of desktop systems. Object manipulation and symbolic manipulation techniques based strictly on first person perspective are also generally less efficient than their desktop counterparts. Instead of considering the two environments as distinct, we have focused on the idea that desktop applications will likely need to transition smoothly into full immersion through intermediate states. The Withindows framework uses image-plane selection and through- the-lens techniques in an attempt to smooth the movement of both traditional and immersive applications across transitional states such as desktop stereo and multi-display setups. We propose using a virtual cursor in the dominant eye and a reinforcing cursor in the non-dominant eye to avoid ambiguity problems that have discouraged the use of image-plane selection in stereo. We show how image-plane selection resolves non-linear control-display relationships inherent in some approaches to desktop stereo. When combined with through-the-lens techniques, image-plane selection allows immersive viewpoint management and 2&‚Äå#xBD;D object manipulation techniques analogous to those on the desktop. This approach resolves global search and scaling problems inherent in prior through-the-lens implementations. We describe extensions for 6 DOF input devices that do not supersede the default interaction method. We developed a single-authored virtual world builder as a proof of concept application of our framework. Our evaluations found alternate perspectives useful but our implementation of viewing windows proved fatiguing to some users.",,978-1-4244-2047-6,10.1109/3DUI.2008.4476584,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4476584,"Through the Lens;Image Plane;Virtual Reality;Augmented Reality;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Artificial, augmented, and virtual realities;I.3.6 [Computer Graphics]: Methodology and Techniques - Interaction Techniques",User interfaces;Fatigue;Virtual reality;Augmented reality;Aerospace simulation;Industrial training;Space technology;Displays;Image resolution;Application software,user interfaces;virtual reality,immersive user interface;desktop user interface;symbolic manipulation;object manipulation;stereo image plane selection;virtual cursor;Withindows framework;virtual reality,,1,2,32,,31-Mar-08,,,IEEE,IEEE Conferences
Haptic interactions with under-actuated robots using virtual mechanisms,G. R. Luecke; J. A. Beckman,"Iowa State University, Department of Mechanical Engineering, Ames, USA; Graduate Assistant at Iowa State University, USA",2008 IEEE International Conference on Robotics and Automation,13-Jun-08,2008,,,2878,2883,"Haptic interactions with computer generated simulations has become almost routine in Virtual Reality (VR) applications. While general interaction requires six degrees of freedom, some haptic devices are designed with fewer degrees of freedom, and so have problems representing general haptic contact. In this work, we present a new approach to the control of a general haptic device, and extend this approach to compensate for missing forces in under-actuated haptic devices. We present an experimental implementation using one of the most popular devices, the PHANTOMreg, and show experimental results for a simple case of haptic interaction.",1050-4729,978-1-4244-1646-2,10.1109/ROBOT.2008.4543646,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4543646,,Haptic interfaces;Robots;Force feedback;Probes;Virtual environment;Virtual reality;Imaging phantoms;Manipulators;Robotics and automation;Actuators,control engineering computing;haptic interfaces;manipulators;virtual reality,haptic interaction;computer generated simulation;under-actuated robot;virtual reality;haptic device,,2,,6,,13-Jun-08,,,IEEE,IEEE Conferences
Physiological Measurement for Emotion Recognition in Virtual Reality,L. B. Hinkle; K. K. Roudposhti; V. Metsis,"Texas State University; Lahijan Branch, Islamic Azad University; Texas State University",2019 2nd International Conference on Data Intelligence and Security (ICDIS),3-Oct-19,2019,,,136,143,"In this work, various non-invasive sensors are used to collect physiological data during subject interaction with virtual reality environments. The collected data are used to recognize the subjects' emotional response to stimuli. The shortcomings and challenges faced during the data collection and labeling process are discussed, and solutions are proposed. A machine learning approach is adopted for emotion classification. Our experiments show that feature extraction is a crucial step in the classification process. A collection of general purpose features that can be extracted from a variety of physiological biosignals is proposed. Our experimental results show that the proposed feature set achieves better emotion classification accuracy compared to traditional domain-specific features used in previous studies.",,978-1-7281-2080-5,10.1109/ICDIS.2019.00028,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8855312,"Physiological measurement, emotion recognition, virtual reality, feature extraction, feature selection.",Sensors;Electrodes;Virtual reality;Feature extraction;Biomedical monitoring;Data collection;Physiology,data analysis;emotion recognition;feature extraction;human computer interaction;learning (artificial intelligence);medical signal processing;neurophysiology;sensor fusion;signal classification;virtual reality,machine learning;emotion classification;user interaction;data collection;virtual reality environments;physiological data;noninvasive sensors;emotion recognition;physiological measurement;physiological biosignals;feature extraction,,1,,24,,3-Oct-19,,,IEEE,IEEE Conferences
Applicability of Immersive Analytics in Mixed Reality: Usability Study,B. Hoppenstedt; T. Probst; M. Reichert; W. Schlee; K. Kammerer; M. Spiliopoulou; J. Schobel; M. Winter; A. Felnhofer; O. D. Kothgassner; R. Pryss,"Institute of Databases and Information Systems, University of Ulm, Ulm, Germany; Department for Psychotherapy and Biopsychosocial Health, Danube University Krems, Krems an der Donau, Austria; Institute of Databases and Information Systems, University of Ulm, Ulm, Germany; Department of Psychiatry and Psychotherapy, University of Regensburg, Regensburg, Germany; Institute of Databases and Information Systems, University of Ulm, Ulm, Germany; Faculty of Computer Science, Otto von Guericke University Magdeburg, Magdeburg, Germany; Institute of Databases and Information Systems, University of Ulm, Ulm, Germany; Institute of Databases and Information Systems, University of Ulm, Ulm, Germany; Department of Pediatrics and Adolescent Medicine, Medical University of Vienna, Vienna, Austria; Department of Child and Adolescent Psychiatry, Medical University of Vienna, Vienna, Austria; Institute of Databases and Information Systems, University of Ulm, Ulm, Germany",IEEE Access,12-Jun-19,2019,7,,71921,71932,"Nowadays, visual analytics is mainly performed by programming approaches and viewing the results on a desktop monitor. However, due to the capabilities of smart glasses, new user interactions and representation possibilities become possible. This refers especially to 3D visualizations in the medical field, as well as, the industry domain, as valuable depth information can be related to the complex real-world structures and related data, which is also denoted as immersive analytics. However, the applicability of immersive analytics and its drawbacks, especially in the context of mixed reality, are quite unexplored. In order to validate the feasibility of immersive analytics for the aforementioned purposes, we designed and conducted a usability study with 60 participants. More specifically, we evaluated the effects of spatial sounds, performance changes from one analytics task to another, expert status, and compared an immersive analytics approach (i.e., a mixed-reality application) with a desktop-based solution. Participants had to solve several data analytics tasks (outlier's detection and cluster recognition) with the developed mixed-reality application. Thereby, the performance measures regarding time, errors, and movement patterns were evaluated. The separation into groups (low performer vs. high performer) was performed using a mental rotation pretest. When solving analytic tasks in mixed reality, participants changed their movement patterns in the mixed reality setting significantly, while the use of spatial sounds reduced the handling time significantly, but did not affect the movement patterns. Furthermore, the usage of mixed reality for cluster recognition is significantly faster than the desktop-based solution (i.e., a 2D approach). Moreover, the results obtained with self-developed questionnaires indicate 1) that wearing smart glasses are perceived as a potential stressor and 2) that the utilization of sounds is perceived very differently by the participants. Altogether, industry and researchers should consider immersive analytics as a suitable alternative compared to the traditional approaches.",2169-3536,,10.1109/ACCESS.2019.2919162,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8723024,Immersive analytics;mixed reality;spatial sounds;visual analytics;hololens,Task analysis;Virtual reality;Three-dimensional displays;Atmospheric measurements;Particle measurements;Two dimensional displays;Smart glasses,computer displays;data analysis;data visualisation;pattern clustering;user interfaces;virtual reality,visual analytics;desktop-based solution;immersive analytics;mixed-reality;data analytics;desktop monitor;user interactions;3D visualizations;medical field;cluster recognition,,1,,38,,27-May-19,,,IEEE,IEEE Journals
AliciaVR: Exploration of scientific articles in an immersive virtual environment with natural user interfaces,R. Linares; J. Herrera; L. Alfaro,"UNSA, National University of Saint Agustin, Arequipa, Peru; UNSA, National University of Saint Agustin, Arequipa, Peru; UNSA, National University of Saint Agustin, Arequipa, Peru",2016 IEEE Ecuador Technical Chapters Meeting (ETCM),24-Nov-16,2016,,,1,6,"Researchers share their results through articles that are published and indexed in scientific databases, which are useful to consult in future research. Generally, the user interface of these databases are traditional, restrict user interaction and limit their field of view. In this paper a new interface model is proposed, based on virtual reality and natural language processing, which together provide a excellent user experience and better use of human capabilities, such as intuition and spatial cognition. In this research they are used the devices Oculus Rif and Leap Motion hardware. The case study is the exploration of scientific articles using Alicia, which is the scientific database of Peru. The motivation for this research is to contribute with better tools to optimize the tasks of literature review and facilitate the work of researchers.",,978-1-5090-1629-7,10.1109/ETCM.2016.7750829,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7750829,Virtual reality;human interaction computer;natural user interfaces;information retrieval;leap motion;oculus rift,Virtual environments;User interfaces;Three-dimensional displays;Two dimensional displays;Databases;Software,database management systems;natural language interfaces;natural language processing;scientific information systems;virtual reality,AliciaVR;scientific article exploration;immersive virtual environment;natural user interfaces;virtual reality;natural language processing;Oculus Rif;Leap Motion hardware;scientific database;Peru;literature review,,1,,19,,24-Nov-16,,,IEEE,IEEE Conferences
Go-in-Circles: A Directed Walking Algorithm for VR Navigation Based on One-Step-Ahead Strategy,M. Qi; G. Liu; J. Cui,"School of Information Science and Engineering, Shandong Normal University, Jinan, China; School of Information Science and Engineering, Shandong Normal University, Jinan, China; School of Information Science and Engineering, Shandong Normal University, Jinan, China",IEEE Access,17-Mar-20,2020,8,,49028,49037,"In virtual reality (VR), how to map large-scale virtual spaces to small tracking area is a challenging problem. In this paper, we propose a novel steering algorithm for the redirected walking (RDW) technique to steer users away from the boundaries of the tracking area while reducing perceptible discrepancies. Inspired by the motion illusion that when a person is blindfolded, she goes in circles while thinking she is walking in a straight and infinitely long path, we map the path composed of straight-line segments in virtual space to a path composed of arcs in real space, and use one-step-ahead strategy and a buffer zone to reduce the number of user-boundary collisions. To verify the effectiveness of our algorithm, we conduct two experiments based on simulated in large-scale virtual spaces with a relatively small tracking area. The results indicate that our algorithm can effectively reduce collisions and perceptual distortion, and show the potential to address the challenge of simultaneously redirecting more than one user.",2169-3536,,10.1109/ACCESS.2020.2977363,National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9019652,Virtual Reality;Redirected Walking;Navigation,Navigation;Skeleton;Legged locomotion;Space exploration;Space vehicles;Tracking;Distortion,human computer interaction;virtual reality,directed walking algorithm;VR navigation;one-step-ahead strategy;virtual reality;tracking area;novel steering algorithm;redirected walking technique;perceptible discrepancies;motion illusion;straight path;infinitely long path;straight-line segments;virtual space;user-boundary collisions;go-in-circles;large-scale virtual spaces,,,,30,CCBY,2-Mar-20,,,IEEE,IEEE Journals
Scrutinizing pseudo haptic feedback of surface roughness in virtual environments,G. Hannig; B. Deml,"Institut f√ºr Arbeitswissenschaft, Universit√§t der Bundeswehr M√ºnchen, Werner-Heisenberg-Weg 39, 85577 Neubiberg, Germany; Institut f√ºr Arbeitswissenschaft, Universit√§t der Bundeswehr M√ºnchen, Werner-Heisenberg-Weg 39, 85577 Neubiberg, Germany","2008 IEEE Conference on Virtual Environments, Human-Computer Interfaces and Measurement Systems",8-Aug-08,2008,,,1,4,"Operators in virtual environments have to mostly rely on visual feedback when exploring virtual scenes and objects. If no additional haptic actuators are available then information about surface roughness will not be communicable and thus the degree of immersion will suffer. To compensate for this shortcome the usage of pseudo haptic feedback (Control/ Display ratio = visual cues encoding haptic object properties) is discussed and two psychophysical experiments are conducted. The first experiment deals with the perceptual scaling of different Control/ Display ratios while the second experiment examines the way, how human subjects assign suitable Control/ Display ratios to different real surfaces. It turns out that human operators can reliably perceive differences in Control/ Display ratios and a psychophysic function is established. The allocation of specific Control/ Display values to real materials does not give any generalizable results; only a global trend is observable.",1944-9410,978-1-4244-1927-2,10.1109/VECIMS.2008.4592742,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4592742,Pseudo haptic feedback;Control-Display ratio;psychophysical scaling;surface roughness;multi modal feedback;virtual environment;human-machine interface;Blender,Haptic interfaces;Surface roughness;Rough surfaces;Materials;Virtual environment;Visualization;Tracking,haptic interfaces;human computer interaction;surface roughness;virtual reality,pseudohaptic feedback;surface roughness;virtual environment;visual feedback;virtual scenes;virtual objects;haptic actuators;psychophysical experiment,,1,,6,,8-Aug-08,,,IEEE,IEEE Conferences
Virtual frog dissection for anatomical learning,T. Yamada; B. Tsagaan; H. Nakatani,"Department of Computer Science, Shizuoka University, Hamamatsu 432-8011, Japan; Department of Computer Science, Shizuoka University, Hamamatsu 432-8011, Japan; Department of Computer Science, Shizuoka University, Hamamatsu 432-8011, Japan",The First Asian Conference on Pattern Recognition,12-Mar-12,2011,,,135,138,"Frog dissection practice used to be a student's laboratory work in Japanese elementary schools. It was an effective approach for learning animal's anatomy. However this practice has been stopped due to animal protection issues and implemental cost. In this study, we aimed to simulate interactive dissecting practice in the virtual space. The presented virtual frog dissection system consists of virtual reality software in conjunction with head-mounted stereoscopic crystal glasses and a haptic device that allows users to touch and manipulate virtual objects. The developed system was evaluated by examining learning ability of students. Participants were divided in four groups of different learning styles, took a written test on the same questions and their resultant scores were compared. Two findings were obtained from this evaluation exam. First, students who have experienced virtual frog dissection were more correct on the appearance related questions, while students who have used paper materials were more concrete on the function-related questions in general. This general tendency may be conducted in accordance with their habitual learning style. Second, in the aspect of convenience and preparing time of each learning style, students who have used conventional paper materials demonstrated more balanced learning than did students of virtual paper materials. These findings suggest that our virtual frog dissection system can show potential benefits in the structural anatomical learning of students; and in contrast, a habitual learning style is likely to produce better outcomes if the new technique provides only the same amount of information.",0730-6512,978-1-4577-0121-4,10.1109/ACPR.2011.6166690,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6166690,virtual frog dissection;virtual reality;3D vision;haptic device;multi-modal interaction,Materials;Three dimensional displays;Solid modeling;Haptic interfaces;Biological systems;Virtual reality;Educational institutions,biological organs;biology computing;computer aided instruction;haptic interfaces;stereo image processing;student experiments;virtual reality,student laboratory work;Japanese elementary school;animal anatomy learning;animal protection issues;interactive dissecting practice;virtual space;virtual frog dissection system;virtual reality software;head-mounted stereoscopic crystal glass;haptic device;virtual object touching;virtual object manipulation;student learning ability;habitual learning style;virtual paper material;structural anatomical learning,,,,13,,12-Mar-12,,,IEEE,IEEE Conferences
Towards a social virtual reality learning environment in high fidelity,C. Zizza; A. Starr; D. Hudson; S. S. Nuguri; P. Calyam; Z. He,Grinnell College; Pomona College; Truman State University; University of Missouri; University of Missouri; University of Missouri,2018 15th IEEE Annual Consumer Communications & Networking Conference (CCNC),19-Mar-18,2018,,,1,4,"Virtual Learning Environments (VLEs) are spaces designed to educate students remotely via online platforms. Although traditional VLEs such as iSocial have shown promise in educating students, they offer limited immersion that diminishes learning effectiveness. This paper outlines a virtual reality learning environment (VRLE) over a high-speed network, which promotes educational effectiveness and efficiency via our creation of flexible content and infrastructure which meet established VLE standards with improved immersion. This paper further describes our implementation of multiple learning modules developed in High Fidelity, a ‚Äúsocial VR‚Äù platform. Our experiment results show that the VR mode of content delivery better stimulates the generalization of lessons to the real world than non-VR lessons and provides improved immersion when compared to an equivalent desktop version.",2331-9860,978-1-5386-4790-5,10.1109/CCNC.2018.8319187,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319187,Virtual Reality;Virtual Learning Environment;High Fidelity;Multi-user Network Application,Avatars;Games;Servers;Web pages;Education;Cloud computing,computer aided instruction;human computer interaction;virtual reality,multiple learning modules;social VR platform;social virtual reality learning environment;online platforms;high-speed network;educational effectiveness;VRLE;VLE standards,,4,,11,,19-Mar-18,,,IEEE,IEEE Conferences
Scalable context-aware development infrastructure for interactive systems in smart environments,T. Eichler; S. Draheim; C. Grecos; Q. Wang; K. von Luck,"Department of Computer Science, Hamburg University of Applied Sciences, Hamburg, Germany; Department of Computer Science, Hamburg University of Applied Sciences, Hamburg, Germany; Department of Computer Science, Central Washington University, Ellensburg, WA, USA; School of Engineering & Computing, University of the West of Scotland, Paisley, UK; Department of Computer Science, Hamburg University of Applied Sciences, Hamburg, Germany","2017 IEEE 13th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)",23-Nov-17,2017,,,147,150,"Context-aware systems for smart environments can be very complex and demanding for developers especially in distributed computing and communication environments. We propose a new development infrastructure, that targets this challenge by improving the general system's scalability and traceability. The infrastructure has been developed for and tested in two research labs for smart environments and human computer interaction. First measurements show that the platform has high scalability and low message latency that is perfectly suitable for interactive projects and virtual reality experiments.",,978-1-5386-3839-2,10.1109/WiMOB.2017.8115848,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115848,context awareness;scalability;middleware;multi-agent systems;smart environments,Middleware;Runtime environment;Sensors;Monitoring;Scalability;Libraries,human computer interaction;ubiquitous computing;virtual reality,scalable context-aware development infrastructure;interactive systems;smart environments;context-aware systems;distributed computing;communication environments;human computer interaction;general system scalability;general system traceability;interactive projects;virtual reality experiments,,,,9,,23-Nov-17,,,IEEE,IEEE Conferences
Virtual Reality for Pain Management in Cancer: A Comprehensive Review,M. Pittara; M. Matsangidou; K. Stylianides; N. Petkov; C. S. Pattichis,"Bernoulli Institute for Mathematics, Computer Science and Artificial Intelligent, University of Groningen, CP Groningen, The Netherlands; Research Centre on Interactive Media, Smart Systems and Emerging Technologies RISE, Nicosia, Cyprus; Cyprus Association of Cancer Patients and Friends, PASYKAF, Nicosia, Cyprus; Bernoulli Institute for Mathematics, Computer Science and Artificial Intelligent, University of Groningen, CP Groningen, The Netherlands; Research Centre on Interactive Media, Smart Systems and Emerging Technologies RISE, Nicosia, Cyprus",IEEE Access,24-Dec-20,2020,8,,225475,225489,"Virtual Reality is a computer-simulated 3-Dimensional technology in which the user interacts via different senses: visual, auditory, tactile, and/or olfactory. In the past decades, it has been argued that Virtual Reality as a technique could be applied in the clinical environment to successfully manage pain. This article provides a systematic review of research on Virtual Reality and pain management for patients who are suffering from cancer. More specifically, this article focuses on all types of Virtual Reality technologies (Non-Immersive, Semi-Immersive, Fully-Immersive) which has been developed and released to manage the pain which evokes from the treatment of cancer. An exhaustive search identified 23 relevant studies from 2010 to 2020. Overall, the identified studies indicated that Virtual Reality can improve the experience of pain for patients who are suffering from cancer. It was also found that, if Virtual Reality is appropriately designed, the pain which is arising from cancer treatments can be reduced. Even though some positive outcomes have been reported, overall, the results are inconclusive and studies that examine specifically the treatment of pain in cancer patients are limited. Further research needs to be conducted, to articulate clearly, under what circumstances Virtual Reality is an effective tool for cancer patients, and under what factors Virtual Reality can be the solution to the pain patients are experiencing.",2169-3536,,10.1109/ACCESS.2020.3044233,"European Union‚Äôs Horizon 2020 Research and Innovation Programme; Government of the Republic of Cyprus through the Directorate-General for European Programmes, Coordination, and Development; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9291419,Virtual reality;cancer;pain;interactive devices,Cancer;Pain;Virtual reality;Libraries;Breast;Lung;Licenses,cancer;cultural aspects;medical computing;reviews;virtual reality,pain management;cancer patients;virtual reality technologies;computer-simulated 3-dimensional technology;user interaction;tactile senses;olfactory senses;visual senses;auditory senses;clinical environment;fully-immersive technologies;non-immersive technologies;semi-immersive technologies;cancer treatment,,,,66,CCBYNCND,11-Dec-20,,,IEEE,IEEE Journals
Anno 2010-remembering our future. Challenges and frontiers of visualization for Human-Media Technology as the kernel for Human-Centered Computing,J. L. Encarnacao,"Fraunhofer Inst. of Comput. Graphics, Tech. Univ. of Darmstadt, Germany",XII Brazilian Symposium on Computer Graphics and Image Processing (Cat. No.PR00481),6-Aug-02,1999,,,3,,"Summary form only given. Human-Media-Technology is one of the ""technology's top 10 challenges and opportunities"" for the year 2010. The subject hereby is: ""humans live, science finds out how technology conforms."" The goal is to develop environments that allow users to cooperate in the most efficient and natural way. Human-centered systems will have to incorporate people as an explicit design component. The article addresses the main goals in developing such systems based on their general characteristics and the corresponding enabling technologies: visualization; virtual and augmented reality; and multimedia. Examples from applications and case studies support the clarification of ideas and goals. So far, the human-centered interfaces to accommodate human perception and human response capabilities and limitations have been presented and discussed. These interfaces allow us to integrate the desired amount of immersion and cooperation (CSCW). Based on this, some ""hands-on"" live demos are shown to discuss the state of the art of these technologies, like Virtual Tables (responsive workbenches), special I/O technologies, etc. Some of these demos are stand-alone demos; others show the potential of telecommunication for collaboration by connecting the floor with other locations to demonstrate CSCW based visual tele-applications. A brief survey is given on the most important research and application challenges, with the objective of having technology conforming to users and not vice versa.",,0-7695-0481-7,10.1109/SIBGRA.1999.805591,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=805591,,Kernel;Human computer interaction;Computer graphics;Technology forecasting;Data visualization;Augmented reality;Multimedia systems;Videos;Collaborative work;Joining processes,technological forecasting;user centred design;user interfaces;virtual reality;multimedia systems;groupware;data visualisation,visualization;Human-Media Technology;Human-Centered Computing;2010;explicit design component;enabling technologies;augmented reality;virtual reality;multimedia;case studies;human-centered interfaces;human perception;human response capabilities;Virtual Tables;responsive workbenchs;special I/O technologies;CSCW based visual tele-applications,,,,,,6-Aug-02,,,IEEE,IEEE Conferences
A distributed collaborative simulation environment for orthopedic surgical training,J. Cecil; A. Gupta; P. Ramanathan; M. Pirela-Cruz,"Center for Cyber Physical Systems, Computer Science, Oklahoma State University, Stillwater, Ok 74078; Center for Cyber Physical Systems, Computer Science, Oklahoma State University, Stillwater, OK 74078; Electrical and Computer Engineering, University of Wisconsin-Madison; Orthopedic Surgery, Paul Foster School of Medicine, TTHSC, El Paso, TX",2017 Annual IEEE International Systems Conference (SysCon),29-May-17,2017,,,1,8,"The use of Virtual Reality (VR) simulators has increased rapidly in the field of medical surgery for training purposes. In this paper, the design and development of a Virtual Surgical Environment (VSE) for training residents in an orthopaedic surgical process called Less Invasive Stabilization System (LISS) surgery is discussed; LISS plating surgery is a process used to address fractures of the femur bone. The development of such virtual environments for educational and training purposes will accelerate and supplement existing training approaches enabling medical residents to be better prepared to serve the surgical needs of the general public. One of the important aspects of the VSE is that it is a network based simulator. Our approach explores the potential of emerging Next Generation Internet frameworks and technologies to support such distributed interaction contexts. A discussion of the validation activities is also presented, which highlights the effectiveness of the VSE for teaching medical residents and students.",2472-9647,978-1-5090-4623-2,10.1109/SYSCON.2017.7934721,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7934721,virtual reality;orthopaedic simulator;LISS plating,Surgery;Training;Solid modeling;Haptic interfaces;Plating;Software,biomedical education;groupware;medical computing;orthopaedics;surgery;virtual reality,distributed collaborative simulation environment;orthopedic surgical training;virtual reality;VR simulators;medical surgery;virtual surgical environment;VSE;orthopaedic surgical process;less invasive stabilization system;LISS plating surgery;fractures;femur bone;virtual environments;medical residents;surgical needs;next generation Internet frameworks;distributed interaction contexts;students,,7,,40,,29-May-17,,,IEEE,IEEE Conferences
Towards a taxonomy of virtual reality user interfaces,M. K. D. Coomans; H. J. P. Timmermans,"Fac. of Archit., Building & Planning, Eindhoven Univ. of Technol., Netherlands; NA",Proceedings. 1997 IEEE Conference on Information Visualization (Cat. No.97TB100165),6-Aug-02,1997,,,279,284,"Virtual reality based user interfaces (VRUIs) are expected to bring about a revolution in computing. VR can potentially communicate large amounts of data in an easily understandable format. VR looks very promising, but it is still a very new interface technology for which very little application oriented knowledge is available. As a basis for such a future VRUI design theory, a taxonomy of VRUIs is required. A general model of human computer communication is formulated. This model constitutes a frame for the integration of partial taxonomies of human computer interaction that are found in the literature. The whole model constitutes a general user interface taxonomy. The field of VRUIs is described and delimited with respect to this taxonomy.",1093-9547,0-8186-8076-8,10.1109/IV.1997.626531,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=626531,,Taxonomy;Virtual reality;User interfaces;Computer interfaces;Visualization;Computer architecture;Buildings;Technology planning;Postal services;Humans,graphical user interfaces;virtual reality;interactive systems;human factors,virtual reality user interfaces;VRUIs;VR;understandable format;interface technology;application oriented knowledge;future VRUI design theory;human computer communication;partial taxonomies;human computer interaction;general user interface taxonomy,,12,3,9,,6-Aug-02,,,IEEE,IEEE Conferences
Balancing Algorithm and Active Shutter Improved ROV Monitoring and Control Platform Using Mobile Phone,Z. Tao; J. Qiao; L. Jiang; L. Han,"School of Information Science and Engineering, Harbin Institute of Technology,Weihai,China; Weihai Beiyang Optoelectronic Info-Tech Co., Ltd,Weihai,China; Weihai Oceanic Fishery Monitoring and Hazard Mitigation Center,Weihai,China; School of Information Science and Engineering, Harbin Institute of Technology,Weihai,China",2020 IEEE 6th International Conference on Computer and Communications (ICCC),12-Feb-21,2020,,,2340,2344,"In this paper, we propose a novel and convenient Remote Operated Vehicle (ROV) monitoring and control platform based on Virtual Reality (VR) system and virtual rocker control system. In general, conventional monitoring and control platforms for ROV is bulky and lack of real-world interaction. To overcome these problems, we design a portable monitor and control platform that offers 3D visualization and control interface based on mobile phone. Besides, to improve the immersion perception of mobile phone VR platform, an algorithm based on Kalman filter is proposed to improve the accuracy of controlling data. Active shutter technology is also applied to enhance the image resolution in VR visualization.",,978-1-7281-8635-1,10.1109/ICCC51575.2020.9344986,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9344986,VR;monitoring and control platform;ROV;mobile phone;virtual rocker;Kalman filter;active shutter,Three-dimensional displays;Data visualization;Virtual reality;Resists;Mobile handsets;Kalman filters;Monitoring,data visualisation;image resolution;Kalman filters;remotely operated vehicles;underwater vehicles;virtual reality,active shutter technology;mobile phone VR platform;control interface;portable monitor;control platforms;conventional monitoring;virtual rocker control system;Virtual Reality system;control platform;active shutter improved ROV monitoring;balancing algorithm,,,,18,,12-Feb-21,,,IEEE,IEEE Conferences
Virtual cooperating manipulators as a virtual reality haptic interface,G. R. Luecke; J. C. Edwards,"Dept. of Mech. Eng., Iowa State Univ., Ames, IA, USA; NA",Proceedings Third Annual Symposium on Human Interaction with Complex Systems. HICS'96,6-Aug-02,1996,,,133,140,"One central element in the focus on research into human-machine interfaces is the capability to interact physically with the computer model. The sense of touch and feel is vital for realistic manipulation and control of virtual objects. The research described here is the development and implementation of a new dynamic control strategy using a standard six-degree-of-freedom robot manipulator as a force interface to virtual reality systems. The haptic element of VR interfacing is currently the subject of abundant research, some addressing the stability and control of interactive systems but with much of the focus on the development of new hardware systems to support stable interaction between humans and VR graphics displays. However, general six-degree-of-freedom manipulators are well understood today and are known to have the capability for generating the general force and motion constraints necessary for the design interaction described in the story. This approach to haptic feedback capability is based on the concept of describing a virtual manipulator model that mimics the motion constraints imposed by a virtual surface. This virtual manipulator is conceptually linked to an actual manipulator to form a closed kinematic chain system. The closed chain system equations are used to define a set of constraints that control the actual robot manipulator so as to allow motion only in the free directions of the virtual manipulator. These free directions are also the free motion directions allowed by the virtual surfaces one tremendous advantage of the approach is that the control algorithm is formulated using local error feedback schemes at the robot level providing effective, stable, and simple control of the robotic hardware. Using the proposed control scheme will allow any six-degree-of-freedom manipulator to be used as a haptic interface device.",,0-8186-7493-8,10.1109/HUICS.1996.549503,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=549503,,Virtual reality;Haptic interfaces;Control systems;Motion control;Manipulator dynamics;Hardware;Feedback;Robot control;Man machine systems;Computer interfaces,virtual reality,virtual cooperating manipulators;virtual reality haptic interface;human-machine interfaces;virtual objects;standard six-degree-of-freedom robot manipulator;hardware systems;haptic feedback capability;local error feedback schemes,,5,1,19,,6-Aug-02,,,IEEE,IEEE Conferences
Design and Implementation of the Radioactive Aerosol's Concentration Measurement System Based on Virtual Training,H. Wei-hua; H. Chang-qiang; D. Da-li,"Eng. Inst., Air Force Eng. Univ., Xi'an, China; Eng. Inst., Air Force Eng. Univ., Xi'an, China; Eng. Inst., Air Force Eng. Univ., Xi'an, China",2011 International Conference on Business Computing and Global Informatization,25-Aug-11,2011,,,509,511,"A Virtual Training System of radioactive aerosol 's concentration measurement is constructed based on Virtual Reality. Firstly, 3-d geometric models about radioactive aerosol's outer environment, detector, intelligent scaler and air sampling pump etc. are constructed, the general radioactive law based on face radioactive source is presented. These models are driving in general program platform using human computer interaction technology. Furthermore, there are several functions about database sharing, fault diagnosis, examining evaluation and on-time help which realize the whole system virtual training. Program show this training system avoids ""nuclear fear"" psychology and improves staff's training effect.",2378-895X,978-1-4577-0788-9,10.1109/BCGIn.2011.134,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6003961,Virtual Training;Radioactivity;Aerosol;Radiation Field component,Training;Atmospheric modeling;Aerosols;Nuclear measurements;Solid modeling;Instruments;Face,aerosols;computer aided instruction;human computer interaction;nuclear engineering computing;virtual reality,radioactive aerosol concentration measurement system;virtual training;virtual reality;3D geometric model;general program platform;human computer interaction technology;database sharing;fault diagnosis;nuclear fear psychology,,,,5,,25-Aug-11,,,IEEE,IEEE Conferences
Immersive Gastronomic Experience with Distributed Reality,P. Perez; E. Gonzalez-Sosa; R. Kachach; J. Ruiz; I. Benito; F. Pereira; A. Villegas,Nokia Bell Labs; Nokia Bell Labs; Nokia Bell Labs; Nokia Bell Labs; Nokia Bell Labs; Nokia Bell Labs; Nokia Bell Labs,2019 IEEE 5th Workshop on Everyday Virtual Reality (WEVR),22-Aug-19,2019,,,1,6,"We have developed an immersive gastronomic experience as a proof of concept of Distributed Reality, a type of Augmented Virtuality which combines a reality transmitted from a remote place, using 360¬∞ video, with a local reality, using video see-through. In order to reach fully immersive experience, local objects of interest such as hands and local food are segmented using red chrominance keying. Only those segmented objects are merged with the remote reality, enabling this way to increase self-presence and to allow user interaction. More concretely, the gastronomic experience consists of tasting small pieces of food, while being immersed in a remote place designed to pair with the food, thus creating an innovative concept with potential impact in hospitality and tourism industries. An evaluation performed with 66 users shows that it provides good levels of immersion, local interactivity, and general user satisfaction. The application achieves real time performance and has been developed for a smartphone mounted on a consumer headset, thus being easy to deploy and to reuse in other use cases.",,978-1-7281-4050-6,10.1109/WEVR.2019.8809591,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809591,Human-centered computing;Human computer interaction (HCI);Interaction paradigms,Cameras;Streaming media;Virtual reality;Distortion;Real-time systems;Resists;Image segmentation,augmented reality;computer graphics;image colour analysis;image segmentation;interactive devices;smart phones,immersive gastronomic experience;distributed reality;fully immersive experience;local food;red chrominance keying;segmented objects;remote reality;local interactivity;augmented virtuality;user interaction;smart phone;consumer headset,,7,,26,,22-Aug-19,,,IEEE,IEEE Conferences
Design of Cyber-Human Frameworks for Immersive Learning,A. Gupta; J. Cecil; O. Tapia; M. Sweet-Darter,"Oklahoma State University,Center for Cyber-Physical Systems,Stillwater,USA; Oklahoma State University,Co-Director, Center for Cyber-Physical Systems,Stillwater,USA; Oklahoma State University,Center for Cyber-Physical Systems,Stillwater,USA; Director, Anselm Center, Edmond,Oklahoma,USA","2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",28-Nov-19,2019,,,1563,1568,"This paper focuses on the creation of information centric Cyber-Human Learning Frameworks involving Virtual Reality based mediums. A generalized framework is proposed, which is adapted for two educational domains: one to support education and training of residents in orthopedic surgery and the other focusing on science learning for children with autism. Users, experts and technology based mediums play a key role in the design of such a Cyber-Human framework. Virtual Reality based immersive and haptic mediums were two of the technologies explored in the implementation of the framework for these learning domains. The proposed framework emphasizes the importance of Information-Centric Systems Engineering (ICSE) principles which emphasizes a user centric approach along with formalizing understanding of target subjects or processes for which the learning environments are being created.",2577-1655,978-1-7281-4569-3,10.1109/SMC.2019.8914205,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8914205,Virtual Reality;Human-Computer Interaction;Virtual Learning,Haptic interfaces;Surgery;Human computer interaction;Training;Solid modeling,biomedical education;computer aided instruction;handicapped aids;medical computing;surgery;virtual reality,immersive learning;generalized framework;educational domains;science learning;technology based mediums;immersive mediums;haptic mediums;information-centric systems engineering principles;user centric approach;learning environments;cyber-human framework;virtual reality based mediums;information centric cyber-human learning frameworks,,,,48,,28-Nov-19,,,IEEE,IEEE Conferences
Teaching of assembly motion by demonstration-artificial constrained motion primitives and its implementation using virtual polyhedron,H. Onda,"Electrotech. Lab., MITI, Tsukuba, Japan","Smc 2000 conference proceedings. 2000 ieee international conference on systems, man and cybernetics. 'cybernetics evolving to systems, humans, organizations, and their complex interactions' (cat. no.0",6-Aug-02,2000,2,,949,954 vol.2,"Teaching by demonstration is a method to generate a robot program that makes a robot do the same task as the task which a human operator demonstrates. The author developed a teaching by demonstration in VR system which automatically generates a robot program to work in the real world after a task is demonstrated by an operator in the virtual world. This system deals with a task of controlling contact states between bodies like the assembly task. When one body is not in contact with another, not only contact states but also other new states which can specify more general arrangement of the bodies are necessary in order to make the robot more skilful. The author introduced a virtual smallface (VSF) and an artificial constrained motion primitive (ACMP) for this purpose. A virtual polyhedron for constrained motion (VPCM) is newly introduced in order to implement more general ACMPs. An operator more easily and generally defines new states of the task by using VSFs and VPCMs, since VSFs are used to define intuitively new states of a task and since (virtual) contact states between VPCMs are also used as the new states.",1062-922X,0-7803-6583-6,10.1109/ICSMC.2000.885972,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=885972,,Education;Robotics and automation;Educational robots;Robotic assembly;Control systems;Humans;Automatic control;Assembly systems;Virtual reality;Robot kinematics,assembling;industrial robots;virtual reality,assembly motion teaching;artificial constrained motion primitives;virtual polyhedron;teaching by demonstration;robot program;human operator;virtual reality;virtual smallface;contact states,,,,10,,6-Aug-02,,,IEEE,IEEE Conferences
VEC3D: a 3-D virtual English classroom for second language learning,Yong-Yuan Lin; Ya-Chun Shih; Mau-Tsuen Yang,"Media Lab., Nat. Dong Hwa Univ., Shoufeng, Taiwan; NA; NA",Fifth IEEE International Conference on Advanced Learning Technologies (ICALT'05),19-Sep-05,2005,,,906,908,"The traditional e-learning systems are generally less attractive to students due to their lack of 3D immersion and real voice interaction. The technology of virtual reality can be exploited to compensate these weaknesses. We propose a realistic and interactive virtual English classroom entitled VEC3D by integrating vivid 3D graphics and real-time voice communication. The goal of VEC3D aims to help undergraduate students develop the overall English communicative competence in listening, speaking, reading and writing.",2161-377X,0-7695-2338-2,10.1109/ICALT.2005.302,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1508852,,Natural languages;Virtual reality;Writing;Avatars;Educational institutions;Space technology;Education;Electronic learning;Graphics;Appropriate technology,computer aided instruction;linguistics;natural language interfaces;virtual reality;solid modelling;voice communication;real-time systems,VEC3D;3D virtual English classroom;second language learning;e-learning systems;3D immersion;voice interaction;virtual reality;interactive virtual English classroom;3D graphics;real-time voice communication;undergraduate students;English communicative competence;listening;speaking;reading;writing,,,,6,,19-Sep-05,,,IEEE,IEEE Conferences
Pattern recognition as a key technology for the next generation of user interfaces,M. Rauterberg; P. Steiger,"Swiss Federal Inst. of Technol., Zurich, Switzerland; NA","1996 IEEE International Conference on Systems, Man and Cybernetics. Information Intelligence and Systems (Cat. No.96CH35929)",6-Aug-02,1996,4,,2805,2810 vol.4,"It is time to go beyond the established approaches in human-computer interaction. After a serious critic of command language, menu selection, and desktop interfaces we discuss the two known approaches to overcome the obstacles and limitations: virtual reality (VR), and augmented reality (AR). Both design strategies are diametrically opposed: VR enriches the virtual world with real humans, while AR augments the real world with intelligent features. Only with the AR design strategy humans are able to behave as much as possible in a natural way: behavior of humans in the real world with other humans and/or real world objects. Our interest in human centred design let us follow this idea. Based on the fundamental constraints of natural way of interacting we derive a set of recommendations for the next generation of user interfaces: the natural user interface (NUI). The concept of NUI is discussed in forms of general framework and several NUI-like applications. Finally, we describe the interdisciplinary research topics that must be taken into consideration for a well-designed NUI in the near future.",1062-922X,0-7803-3280-6,10.1109/ICSMC.1996.561385,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=561385,,Pattern recognition;User interfaces;Humans;Virtual reality;Mice;Computer displays;Augmented reality;Application software;Computer graphics;Workstations,human factors;user interfaces;interactive systems;virtual reality;technological forecasting;pattern recognition;computer vision,pattern recognition;natural user interfaces;human-computer interaction;command language;menu selection;desktop interfaces;virtual reality;augmented reality,,6,,51,,6-Aug-02,,,IEEE,IEEE Conferences
Accessibility of Immersive Serious Games for Persons with Cognitive Disabilities,P. Guitton; H. Sauz√©on; P. Cinquin,University of Bordeaux; University of Bordeaux; University of Bordeaux,2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),9-Jan-20,2019,,,443,447,"E-learning systems are still not very accessible for persons with disabilities, particularly those with cognitive impairments. It's well known that the training deficit is one of the cause of lower employment rates. In the past, we have addressed this issue by working on the accessibility of MOOCs. We have developed Aiana, a MOOC player with accessibility features based on the fragmentation of information streams and enabling user interface self-configuration. We are starting a new research program focused on the accessibility of immersive Serious Games for persons with cognitive impairments by first transposing some of Aiana's design principles. We believe that immersive Serious Games can provide effective assistance to learning for PWDs and we want to demonstrate this rigorously through large field studies. More generally, we wonder about the questions raised by the accessibility of Mixed Reality tools in immersive e-learning systems.",,978-1-7281-4765-9,10.1109/ISMAR-Adjunct.2019.00051,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951894,accessibility;e-learning;serious-games;immersion,Augmented reality,cognition;computer based training;educational courses;handicapped aids;human computer interaction;serious games (computing);virtual reality,immersive serious games;cognitive impairments;training deficit;employment rates;MOOC player;immersive e-learning systems;Aiana design principles;user interface self-configuration;person with cognitive disabilities;information stream fragmentation;PWDs;mixed reality tools,,,,31,,9-Jan-20,,,IEEE,IEEE Conferences
Stable haptic interaction with virtual environments,R. J. Adams; B. Hannaford,"Dept. of Electr. Eng., Washington Univ., Seattle, WA, USA; NA",IEEE Transactions on Robotics and Automation,6-Aug-02,1999,15,3,465,474,"This paper addresses fundamental stability and performance issues associated with haptic interaction. It generalizes and extends the concept of a virtual coupling network, an artificial link between the haptic display and a virtual world, to include both the impedance and admittance models of haptic interaction. A benchmark example exposes an important duality between these two cases. Linear circuit theory is used to develop necessary and sufficient conditions for the stability of a haptic simulation, assuming the human operator and virtual environment are passive. These equations lead to an explicit design procedure for virtual coupling networks which give maximum performance while guaranteeing stability. By decoupling the haptic display control problem from the design of virtual environments, the use of a virtual coupling network frees the developer of haptic-enabled virtual reality models from issues of mechanical stability.",2374-958X,,10.1109/70.768179,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=768179,,Haptic interfaces;Virtual environment;Coupling circuits;Displays;Circuit stability;Impedance;Admittance;Linear circuits;Sufficient conditions;Circuit simulation,virtual reality;force feedback;haptic interfaces;absolute stability;mechanical stability,haptic interface;virtual environments;absolute stability;virtual coupling network;impedance control;admittance models;linear circuit theory;haptic display;virtual reality;force feedback,,432,6,29,,6-Aug-02,,,IEEE,IEEE Journals
Study of Multimodal Interfaces and the Improvements on Teleoperation,E. Triantafyllidis; C. Mcgreavy; J. Gu; Z. Li,"School of Informatics, The University of Edinburgh, Edinburgh, U.K.; School of Informatics, The University of Edinburgh, Edinburgh, U.K.; School of Informatics, The University of Edinburgh, Edinburgh, U.K.; School of Informatics, The University of Edinburgh, Edinburgh, U.K.",IEEE Access,5-May-20,2020,8,,78213,78227,"Research in multimodal interfaces aims to provide immersive solutions and to increase overall human performance. A promising direction is to combine auditory, visual and haptic interaction between the user and the simulated environment. However, no extensive comparison exists to show how combining audiovisuohaptic interfaces would affect human perception and by extent reflected on task performance. Our paper explores this idea and presents a thorough, full-factorial comparison of how all combinations of audio, visual and haptic interfaces affect performance during manipulation. We evaluated how each combination affects the performance in a study (N=25 ) consisting of manipulation tasks with various difficulties. The overall performance was assessed using both subjective measures, by assessing cognitive workload and system usability, and objective measurements, by incorporating time and spatial accuracy-based metrics. The results showed that regardless of task complexity, the combination of stereoscopic-vision with the virtual reality headset increased performance across all measurements by 40%, compared to monocular-vision from a generic display monitor. Besides, using haptic feedback improved outcomes by 10% and auditory feedback accounted for approximately 5% improvement.",2169-3536,,10.1109/ACCESS.2020.2990080,EPSRC Future AI and Robotics for Space; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9076603,Audiovisuohaptic;auditory feedback;haptic feedback;immersive manipulation;immersive teleoperation;multimodal interaction;multimodal interface;virtual reality,Task analysis;Visualization;Haptic interfaces;Robot sensing systems;Robot kinematics;Virtual reality,computer displays;control engineering computing;haptic interfaces;manipulators;stereo image processing;telerobotics;virtual reality,multimodal interfaces;immersive solutions;human performance;auditory interaction;visual interaction;haptic interaction;simulated environment;extensive comparison;audiovisuohaptic interfaces;human perception;task performance;full-factorial comparison;audio interfaces;visual interfaces;haptic interfaces;manipulation tasks;subjective measures;cognitive workload;system usability;objective measurements;spatial accuracy-based metrics;task complexity;haptic feedback improved outcomes,,,,68,CCBY,23-Apr-20,,,IEEE,IEEE Journals
A coupling library for the force dimension haptic devices and the 20-sim modelling and simulation environment,F. Sanfilippo; P. B. T. Weustink; K. Y. Pettersen,"Department of Maritime Technology and Operations, Aalesund University College, Postboks 1517, 6025 Aalesund, Norway; Controllab Products B.V. Hengelosestraat, 500, 7521 AN Enschede, Netherlands; Department of Engineering, Cybernetics, Norwegian University of Science and Technology, 7491 Trondheim, Norway",IECON 2015 - 41st Annual Conference of the IEEE Industrial Electronics Society,28-Jan-16,2015,,,168,173,"A haptic feedback device is a device that establishes a kinaesthetic link between a human operator and a computer-generated environment. This paper addresses the bidirectional coupling between a commercial off-the-shelf (COTS) haptic feedback device and a general-purpose modelling and simulation environment. In particular, an open-source library is developed to couple the Force Dimension omega.7 haptic device with the 20-sim modelling and simulation environment. The presented coupling interface is also compatible with all the different haptic devices produced by Force Dimension. The proposed integrated haptic interface makes it possible to track the user's motion, detect collisions between the user-controlled probe and virtual objects, compute reaction forces in response to motion or contacts and exert an intuitive force feedback on the user. A real-time one-to-one correspondence between reality and virtual reality can be transparently created. This allows for a variety of possible applications. Stability issues, performance issues, design and virtual prototyping challenges can be addressed and investigated for research purposes. In addition, design and virtual prototyping are also of interest to industry. Realistic training environments can be developed for the user considering different possible operations and stressing the importance of usability and user experience. Experiments based on using haptics technology in the field of education can also be easily performed. To demonstrate the potential of the proposed coupling, a case study is presented. Related simulations and experimental results are carried out.",,978-1-4799-1762-4,10.1109/IECON.2015.7392094,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7392094,Haptics;Human-computer interaction;Simulation,Haptic interfaces;Solid modeling;Libraries;Couplings;Force;Computational modeling;Programming,force feedback;haptic interfaces;human computer interaction;motion estimation;public domain software;virtual reality,haptics technology;realistic training environments;virtual prototyping;virtual reality;real-time one-to-one correspondence;virtual objects;user-controlled probe;collision detection;user motion detection;integrated haptic interface;force dimension;coupling interface;haptic feedback devices;simulation environment;20-sim modelling;force dimension haptic devices;coupling library,,4,,13,,28-Jan-16,,,IEEE,IEEE Conferences
High performance explicit force control for finger interaction haptic interface,S. Marcheschi; F. Salsedo; M. Fontana; F. Tarri; O. Portillo-Rodriguez; M. Bergamasco,"PERCRO Scuola Superiore Sant'Anna, Italy; PERCRO Scuola Superiore Sant'Anna, Italy; PERCRO Scuola Superiore Sant'Anna, Italy; PERCRO Scuola Superiore Sant'Anna, Italy; PERCRO Scuola Superiore Sant'Anna, Italy; PERCRO Scuola Superiore Sant'Anna, Italy",Second Joint EuroHaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems (WHC'07),2-Apr-07,2007,,,464,469,"The requirements for a high performance haptic interface (HI) can arise from demanding VR applications such as the marketing on line of novel textiles or garments. Aiming at the improvement of the performance of the device, the integration of an explicit force control (i.e. a control making use of force measurement) on a HI, originally conceived for open loop control, may prove to be very challenging from the system stability point of view. This paper proposes a methodology for the dimensioning of a motion based explicit force control on the basis of the dynamic parameters of the plant (HI + human). The methodology highlights how the design solutions generally adopted for His intended for open loop force control can hinder the stability of the system when integrated with a closed loop force control",,0-7695-2738-8,10.1109/WHC.2007.69,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4145218,,Force control;Fingers;Haptic interfaces;Open loop systems;Stability;Virtual reality;Textiles;Clothing;Control systems;Force measurement,force control;haptic interfaces;open loop systems;stability;virtual reality,force control;finger interaction haptic interface;open loop control;system stability,,9,,14,,2-Apr-07,,,IEEE,IEEE Conferences
Helping Robots Learn: A Human-Robot Master-Apprentice Model Using Demonstrations via Virtual Reality Teleoperation,J. DelPreto; J. I. Lipton; L. Sanneman; A. J. Fay; C. Fourie; C. Choi; D. Rus,"MIT Distributed Robotics Lab,Cambridge,MA,02139; MIT Distributed Robotics Lab,Cambridge,MA,02139; MIT Interactive Robotics Group,Cambridge,MA,02139; MIT Distributed Robotics Lab,Cambridge,MA,02139; MIT Interactive Robotics Group,Cambridge,MA,02139; MIT Distributed Robotics Lab,Cambridge,MA,02139; MIT Distributed Robotics Lab,Cambridge,MA,02139",2020 IEEE International Conference on Robotics and Automation (ICRA),15-Sep-20,2020,,,10226,10233,"As artificial intelligence becomes an increasingly prevalent method of enhancing robotic capabilities, it is important to consider effective ways to train these learning pipelines and to leverage human expertise. Working towards these goals, a master-apprentice model is presented and is evaluated during a grasping task for effectiveness and human perception. The apprenticeship model augments self-supervised learning with learning by demonstration, efficiently using the human's time and expertise while facilitating future scalability to supervision of multiple robots; the human provides demonstrations via virtual reality when the robot cannot complete the task autonomously. Experimental results indicate that the robot learns a grasping task with the apprenticeship model faster than with a solely self-supervised approach and with fewer human interventions than a solely demonstration-based approach; 100% grasping success is obtained after 150 grasps with 19 demonstrations. Preliminary user studies evaluating workload, usability, and effectiveness of the system yield promising results for system scalability and deployability. They also suggest a tendency for users to overestimate the robot's skill and to generalize its capabilities, especially as learning improves.",2577-087X,978-1-7281-7395-5,10.1109/ICRA40945.2020.9196754,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9196754,,Robots;Grasping;Task analysis;Three-dimensional displays;Solid modeling;Virtual reality;Pipelines,control engineering computing;human-robot interaction;learning (artificial intelligence);multi-robot systems;robot programming;telerobotics;virtual reality,grasping task;human perception;human-robot master-apprentice model;virtual reality teleoperation;artificial intelligence;self-supervised learning,,1,,50,,15-Sep-20,,,IEEE,IEEE Conferences
Teleplanning by human demonstration for VR-based teleoperation of a mobile robotic assistant,C. S. Tzafestas,"Inst. of Informatics & Telecommun., Nat. Center for Sci. Res. ""Demokritos"", Athens, Greece",Proceedings 10th IEEE International Workshop on Robot and Human Interactive Communication. ROMAN 2001 (Cat. No.01TH8591),6-Aug-02,2001,,,462,467,"Focuses on the integration of local path planning techniques in a multimodal teleoperation interface, for the efficient remote control of a mobile robotic assistant. The main principle underlying this scheme is related to finding new ways to establish an efficient human-robot cooperation framework, where humans and robots take charge of the parts of the tasks that they can perform more efficiently. For the teleoperation of a mobile robotic platform, a simple application of this general principle could be to commit the human operator in performing the necessary global planning operations, which are more demanding in terms of complex reasoning and required ""intelligence"", while other more local tasks such as collision avoidance and trajectory optimization are dedicated to the telerobotic system. We propose an implementation of this principle within a mobile robot teleoperation interface integrating virtual reality techniques and Web standards. The paper describes the multimodal interface and the design principles followed, as well as the integration of a local path planning method. This scheme, called ""computer-assisted teleplanning by human demonstration"", aims at providing active assistance to the human operator, enabling him to indicate in a natural way the desired global motion plan, for a more efficient teleoperation of a mobile robotic assistant.",,0-7803-7222-0,10.1109/ROMAN.2001.981947,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=981947,,Mobile robots;Human robot interaction;Telerobotics;Path planning;Collision avoidance;Trajectory;Robot sensing systems;Virtual reality;Informatics;Telecommunication control,mobile robots;collision avoidance;telerobotics;virtual reality,teleplanning;human demonstration;VR-based teleoperation;mobile robotic assistant;local path planning techniques;efficient human-robot cooperation framework;complex reasoning;collision avoidance;trajectory optimization;virtual reality techniques;Web standards;local path planning method;wavefront expansion;trajectory modification technique;multimodal teleoperation interface,,6,,15,,6-Aug-02,,,IEEE,IEEE Conferences
NaviBoard and NaviChair: Limited Translation Combined with Full Rotation for Efficient Virtual Locomotion,T. Nguyen-Vo; B. E. Riecke; W. Stuerzlinger; D. -M. Pham; E. Kruijff,"School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC, Canada; School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC, Canada; School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC, Canada; School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC, Canada; Institute of Visual Computing, Bonn-Rhein-Sieg University of Applied Sciences, Sankt Augustin, Germany",IEEE Transactions on Visualization and Computer Graphics,24-Nov-20,2021,27,1,165,177,"Walking has always been considered as the gold standard for navigation in Virtual Reality research. Though full rotation is no longer a technical challenge, physical translation is still restricted through limited tracked areas. While rotational information has been shown to be important, the benefit of the translational component is still unclear with mixed results in previous work. To address this gap, we conducted a mixed-method experiment to compare four levels of translational cues and control: none (using the trackpad of the HTC Vive controller to translate), upper-body leaning (sitting on a ‚ÄúNaviChair‚Äù, leaning the upper-body to locomote), whole-body leaning/stepping (standing on a platform called NaviBoard, leaning the whole body or stepping one foot off the center to navigate), and full translation (physically walking). Results showed that translational cues and control had significant effects on various measures including task performance, task load, and simulator sickness. While participants performed significantly worse when they used a controller with no embodied translational cues, there was no significant difference between the NaviChair, NaviBoard, and actual walking. These results suggest that translational body-based motion cues and control from a low-cost leaning/stepping interface might provide enough sensory information for supporting spatial updating, spatial awareness, and efficient locomotion in VR, although future work will need to investigate how these results might or might not generalize to other tasks and scenarios.",1941-0506,,10.1109/TVCG.2019.2935730,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809840,Adaptive control;cognitive informatics;human computer interaction;human factors;user interface;virtual reality,Legged locomotion;Task analysis;Navigation;Resists;Wheelchairs;Virtual reality;Input devices,virtual reality,physical translation;rotational information;translational component;mixed-method experiment;HTC Vive controller;NaviChair;NaviBoard;task performance;embodied translational cues;walking;translational body-based motion cues;virtual locomotion;gold standard;navigation;virtual reality;upper-body leaning;whole-body leaning;whole-body stepping;task load;simulator sickness;low-cost leaning interface;low-cost stepping interface;sensory information;spatial updating;spatial awareness,,,,50,IEEE,22-Aug-19,,,IEEE,IEEE Journals
Folkways in Wonderland: A Cyberworld Laboratory for Ethnomusicology,R. Ranaweera; M. Frishkopf; M. Cohen,"Spatial Media Group, Univ. of Aizu, Aizu-Wakamatsu, Japan; Dept. of Music, Univ. of Alberta, Edmonton, AB, Canada; Spatial Media Group, Univ. of Aizu, Aizu-Wakamatsu, Japan",2011 International Conference on Cyberworlds,17-Nov-11,2011,,,106,112,"In this paper we describe a musical cyber world - a collaborative, immersive virtual environment for browsing musical databases - together with an experimental design launching a new sub discipline: the ethnomusicology of controlled musical cyberspaces. Research in ethnomusicology, the ethnographic study of music in its socio-cultural environment, has typically been conducted through qualitative fieldwork in uncontrolled, real-world settings. Recently, ethnomusicologists have begun to attend to the study of virtual environments, including pre-existing cyber worlds (such as video games). However, in this paper, we adopt an unprecedented approach by designing a custom musical cyber world to serve as a virtual laboratory for the ethnographic study of music. By constructing an immersive cyber world suitable for ethno musicological fieldwork, we aim for much greater control than has heretofore been possible in ethno musicological research, leading to results that may suggest better ways of designing musical cyber worlds for research, discovery, learning, entertainment, and e-commerce, as well as contributing towards our general understanding of the role of music in human interaction and community-formation. Such controlled research can usefully supplement traditional ethnography in the real world.",,978-1-4577-1453-5,10.1109/CW.2011.33,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6079353,Ethnomusicology;ethnography;fieldwork;cyberworlds;world music;collaborative virtual environment;groupware;Wonderland;spatial music;immersive environment;hypermedia,Avatars;Servers;Computer architecture;Three dimensional displays;Microprocessors;Virtual environments;Collaboration,cultural aspects;design of experiments;groupware;music;virtual reality,cyberworld laboratory;ethnomusicology;musical cyber world;collaborative virtual environment;immersive virtual environment;musical database browsing;experimental design;socio-cultural environment;ethnographic study;entertainment;e-commerce;human interaction;community-formation,,1,,17,,17-Nov-11,,,IEEE,IEEE Conferences
A Stable and Real-Time Nonlinear Elastic Approach to Simulating Guidewire and Catheter Insertions Based on Cosserat Rod,W. Tang; T. R. Wan; D. A. Gould; T. How; N. W. John,"School of Computing, the University of Teesside, Middlesbrough, U.K.; Bradford University, Bradford, U.K.; Royal Liverpool University Hospital, Liverpool, U.K.; Liverpool University, Liverpool, U.K.; Bangor University , Bangor, U.K.",IEEE Transactions on Biomedical Engineering,12-Jul-12,2012,59,8,2211,2218,"Interventional Radiology procedures (e.g., angioplasty, embolization, stent graft placement) provide minimally invasive therapy to treat a wide range of conditions. These procedures involve the use of flexible tipped guidewires to advance diagnostic or therapeutic catheters into a patient's vascular or visceral anatomy. This paper presents a real-time physically based hybrid modeling approach to simulating guidewire insertions. The long, slender body of the guidewire shaft is simulated using nonlinear elastic Cosserat rods, and the shorter flexible tip composed of a straight, curved, or angled design is modeled using a more efficient generalized bending model. Therefore, the proposed approach efficiently computes intrinsic dynamic behaviors of guidewire interactions within vascular structures. The efficacy of the proposed method is demonstrated using detailed numerical simulations inside 3-D blood vessel structures derived from preprocedural volumetric data. A validation study compares positions of four physical guidewires deployed within a vascular phantom, with the co-ordinates of the corresponding simulated guidewires within a virtual model of the phantom. An optimization algorithm is also implemented to further improve the accuracy of the simulation. The presented simulation model is suitable for interactive virtual reality-based training and for treatment planning.",1558-2531,,10.1109/TBME.2012.2199319,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6200309,Cosserat theory of elastic rod;guidewire insertion;minimally invasive interventions;physically based simulation,Computational modeling;Solid modeling;Materials;Friction;Shafts;Accuracy;Real time systems,catheters;phantoms;radiology;surgery;virtual reality,stable nonlinear elastic approach;real time nonlinear elastic approach;guidewire simulation;catheter insertion simulation;Cosserat rod;interventional radiology;angioplasty;embolization;stent graft placement;minimally invasive therapy;vascular anatomy;visceral anatomy;vascular phantom;interactive virtual reality based training;treatment planning,"Algorithms;Aorta, Abdominal;Aortic Aneurysm, Abdominal;Catheterization;Catheterization;Computer Simulation;Humans;Image Processing, Computer-Assisted;Models, Cardiovascular;Nonlinear Dynamics;Phantoms, Imaging;Reproducibility of Results",51,,26,,15-May-12,,,IEEE,IEEE Journals
Virtual 3D Simulation of Fault Diagnosis and its Realization in the Electrical System of Certain Equipment,Z. Liu; S. An; Y. Wang; X. Wang,"Dept. of Electron. Eng., Ordnance Eng. Coll., Shijiazhuang, China; Dept. of Electron. Eng., Ordnance Eng. Coll., Shijiazhuang, China; Dept. of Electron. Eng., Ordnance Eng. Coll., Shijiazhuang, China; NA","2012 Second International Conference on Instrumentation, Measurement, Computer, Communication and Control",4-Feb-13,2012,,,1338,1341,"Focusing on the problems existing in conventional maintenance training ways and means which can't adapt to the needs of equipment development, a set of desktop interactive in the electrical system of certain equipment by means of virtual reality techniques was developed. Aimed at the complicated structures and relationships within electrical maintenance, the general functional module of virtual maintenance system was established, the 3 dimension (3D) model nodes of electrical system were rebuilt, and the research on key techniques relevant to maintenance simulation interaction was carried out. The system is in practice proved to be a new way and mean for complicated electrical maintenance training.",,978-1-4673-5034-1,10.1109/IMCCC.2012.315,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6429151,fault diagnosis;virtual maintenance;modal node,Maintenance engineering;Circuit faults;Assembly;Training;Testing;Solid modeling;Instruments,fault diagnosis;geometry;maintenance engineering;power apparatus;power engineering computing;virtual reality,3D geometry model;3 dimension model;electrical maintenance;virtual reality technique;desktop interactive;maintenance training way;certain equipment;electrical system;fault diagnosis;virtual 3D simulation,,,,6,,4-Feb-13,,,IEEE,IEEE Conferences
Decoding 2D kinematics of human arm for body machine interfaces,T. Gulrez; M. Kavakli-Thorne; A. Tognetti,"Virtual and Simulations of Reality Research Lab, Department of Computing, Faculty of Science, Macquarie University, NSW 2109 Australia; Virtual and Simulations of Reality Research Lab, Department of Computing, Faculty of Science, Macquarie University, NSW 2109 Australia; Department of Bioengineering, Interdepartmental Research Center E. Piaggio, Faculty of Engineering, University of Pisa, Italy",2013 IEEE 8th Conference on Industrial Electronics and Applications (ICIEA),25-Jul-13,2013,,,719,722,"Body-machine interface provides stroke and spinal cord injured patients a mean to participate in their activities of daily livings (ADLs). In this paper, electrophysiological signals from the human upper limb are used as a control interface between the user and a virtual robotic wheelchair. There is a general perception that these body signals contain an insufficient level of information for decoding or reconstructing kinematics of multi-joint limb activity. In this paper we present the results obtained in our virtual reality laboratory at Macquarie University, showing that non-invasive upper limb signals from high density wearable sensing shirt can be utilized to continuously decode the kinematics of 2D arm movements. Our results also show that body signals contain an information about the neural representation of movement. Moreover, they provide an alternative way for developing non-invasive body-machine interfaces, which have diverse clinical applications and access to these signals may provide understanding of functional brain states at various stages of development and aging.",2158-2297,978-1-4673-6322-8,10.1109/ICIEA.2013.6566461,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6566461,,Wheelchairs;Robot sensing systems;Mobile robots;Kinematics;Decoding,bioelectric potentials;biomechanics;brain;handicapped aids;human-robot interaction;injuries;kinematics;mechanoception;medical computing;medical disorders;medical robotics;mobile robots;neural nets;neurophysiology;user interfaces;virtual reality;wheelchairs,2D kinematics decoding;stroke;spinal cord injured patient;activities of daily living;ADL;electrophysiological signal;human upper limb;control interface;virtual robotic wheelchair;general perception;body signal;kinematics reconstruction;multijoint limb activity;virtual reality laboratory;noninvasive upper limb signal;high density wearable sensing shirt;2D arm movement kinematics;movement neural representation;noninvasive body-machine interface;functional brain states,,,,12,,25-Jul-13,,,IEEE,IEEE Conferences
Immersive Representation of Objects in Virtual Reality Environment Implementing Impicit Properties,A. Bachvarov; S. Maleshkov; D. Chotrov; J. Katicic,"FDIBA, Tech. Univ. of Sofia, Sofia, Bulgaria; FDIBA, Tech. Univ. of Sofia, Sofia, Bulgaria; FDIBA, Tech. Univ. of Sofia, Sofia, Bulgaria; Inst. for Inf. Manage. in Eng., Karlsruhe Inst. of Technol. (KIT), Karlsruhe, Germany",2011 Developments in E-systems Engineering,13-Feb-12,2011,,,587,592,"In this work we propose a new concept of so called implicit (or ""hidden"") properties implemented in material object models. These are some features of the material object model that cannot be perceived by the observer through his/her senses (i.e. magnetization, radiation, humidity). Exploration of such features requires additional means and techniques that expand the perception range of the observer's different sensory channels. Traditional approaches use only a few of the explicit properties of objects models (mainly its geometric, structural and topological characteristics) for their building. We believe that the supplement of implicit properties, the selection of an appropriate combination of stimuli for separate sensory channels, their effective presentation to the observer and the ability for their modification directly in the virtual world will turn this situation in a way that may lead to a disruption in the generally accepted practices for different research fields, thus allowing for the virtual reality to unfold its full potential as a significant engineering design tool. Respectively, this will considerably enhance and intensify the information perception of the observer during object exploration in the virtual environment. Here, a brief introduction in the Virtual Reality and its engineering application is presented. The concepts about the material objects and their properties, as well as systems and norms for standardized properties sets and classes, have been surveyed. The developed Aura-Dowsing interaction technique as a part of ongoing complex research on the possibility for implementation of the implicit properties concept is presented and discussed.",,978-1-4577-2186-1,10.1109/DeSE.2011.80,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6150058,implicit properties;material objects;virtual reality;multisensorial presentation,Materials;Virtual environments;Solid modeling;Visualization;Observers;Color,computer graphics;image representation;virtual reality,object representation;virtual reality environment;material object model;sensory channel;virtual world;engineering design tool;information perception;object exploration;standardized properties sets;Aura-Dowsing interaction technique,,2,3,8,,13-Feb-12,,,IEEE,IEEE Conferences
Augmented Reality Go: Extending Traditional Game Play with Interactive Self-Learning Support,T. Iwata; T. Yamabe; T. Nakajima,"Dept. of Comput. Sci. & Eng., Waseda Univ., Tokyo, Japan; Dept. of Comput. Sci. & Eng., Waseda Univ., Tokyo, Japan; Dept. of Comput. Sci. & Eng., Waseda Univ., Tokyo, Japan",2011 IEEE 17th International Conference on Embedded and Real-Time Computing Systems and Applications,29-Sep-11,2011,1,,105,114,"The augmented reality (AR)-based learning support has several advantages over virtual reality or PC applications. AR enables to maintain the physical interaction that an activity originally offers, thus the skills and knowledge acquired in an augmented learning process can be intuitively applied to practice use. Whereas lots of AR-based self-learning support systems have been developed in previous studies, it has not been sufficiently evaluated how it influences a learner's mindset and the efficiency of training. In this paper, we investigate the user experience brought by AR technologies in a self-learning process. We chose the game of Go as a study program, and developed the Augmented Reality Go (ARGo) system to compare the AR and conventional PC-based learning assistance. We found that the physical interaction with the original game apparatus enhanced the subjects' intrinsic motivation towards self-learning. Moreover, the original look-and-feel induced deeper concentration and higher elaboration on problem solving. Design issues are also discussed to generalize the concept of AR self-learning support towards broader application domains.",2325-1301,978-1-4577-1118-3,10.1109/RTCSA.2011.43,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6029834,,Games;Visualization;User interfaces;Guidelines;Augmented reality;Sensors;Training,augmented reality;game theory;interactive systems;problem solving;unsupervised learning,augmented reality;game play;interactive self learning support;learning support;virtual reality;augmented learning process;AR-based self learning support system;PC-based learning assistance;look-and-feel induced deeper concentration;problem solving,,12,,19,,29-Sep-11,,,IEEE,IEEE Conferences
"An architecture for virtual reality, audio, video, text, and document handling in applications supporting multi-person interactions",S. Pekkola; M. Robinson; J. Korhonen; S. Hujala; T. Toivonen; M. -. O. Saarinen,"Dept. of Comput. Sci. & Inf. Syst., Jyvaskyla Univ., Finland; NA; NA; NA; NA; NA",Proceedings of the 26th Euromicro Conference. EUROMICRO 2000. Informatics: Inventing the Future,6-Aug-02,2000,2,,150,157 vol.2,"There are limitations to Internet, networked PC, and mobile device document handling and communication services and applications. In general, these do not provide for awareness of, and communication with others while working on documents. Limiting services in this way runs contrary to major findings from CSCW: users move between media and devices promiscuously; combine applications and media in effective, but idiosyncratic ways; and need awareness of others and their activities for successful accomplishment of much work. This awareness, whether backgrounded or foregrounded, needs to be constantly available/present. The paper presents a scalable architecture for handling multiple media (VR, video, audio, text, and documents) and devices where awareness of others/activities can be almost universally provided. Important features are presentation level integration and choices between media. These support new approaches to collaborations involving arbitrary combinations of documents, people, media and access devices.",1089-6503,0-7695-0780-8,10.1109/EURMIC.2000.874412,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=874412,,Virtual reality;Document handling;Collaborative work;Computer architecture;Mobile communication;Application software;Computer science;Information systems;Web and internet services;Computer applications,multimedia systems;virtual reality;document handling;groupware;Internet,virtual reality;audio;video;text;document handling;multi-person interactions;Internet;networked PC;mobile device;CSCW;multimedia;computer supported cooperative work,,,2,39,,6-Aug-02,,,IEEE,IEEE Conferences
Walking with Virtual People: Evaluation of Locomotion Interfaces in Dynamic Environments,A. Olivier; J. Bruneau; R. Kulpa; J. Pettr√©,"INRIA Rennes, Rennes, France; INRIA Rennes, Rennes, France; INRIA Rennes, Rennes, France; INRIA Rennes, Rennes, France",IEEE Transactions on Visualization and Computer Graphics,25-May-18,2018,24,7,2251,2263,"Navigating in virtual environments requires using some locomotion interfaces, especially when the dimensions of the environment exceed the ones of the Virtual Reality system. Locomotion interfaces induce some biases both in the perception of the self-motion or in the formation of virtual locomotion trajectories. These biases have been mostly evaluated in the context of static environments, and studies need to be revisited in the new context of populated environments where users interact with virtual characters. We focus on a situation of collision avoidance between a real participant and a virtual character, and compared it to previous studies on real walkers. Our results show that, as in reality, the risk of future collision is accurately anticipated by participants, however with delay. We also show that collision avoidance trajectories formed in VR have common properties with real ones, with some quantitative differences in avoidance distances. More generally, our evaluation demonstrates that reliable results can be obtained for qualitative analysis of small scale interactions in VR. We discuss these results in the perspective of a VR platform for large scale interaction applications, such as in a crowd, for which real data are difficult to gather.",1941-0506,,10.1109/TVCG.2017.2714665,French National Research Agency ANR; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7946183,Locomotion;interaction;evaluation;experiment;collision avoidance;virtual reality,Trajectory;Legged locomotion;Collision avoidance;Context;Measurement;Virtual environments,collision avoidance;navigation;virtual reality,populated environments;virtual character;collision avoidance;virtual people;locomotion interfaces;dynamic environments;virtual environments;Virtual Reality system;virtual locomotion trajectories;static environments;VR platform,,13,,51,,12-Jun-17,,,IEEE,IEEE Journals
Immersive integration for virtual and human-centered environments,H. Fuchs,"North Carolina Univ., Chapel Hill, NC, USA",2005 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC'05),17-Oct-05,2005,,,13,,"Summary form only given. We envision future work and play environments that are more effectively human-centered with the user's computing interface being more closely integrated with the physical surroundings than today's conventional computer display screens and keyboards. We are working toward realizable versions of such environments, in which multiple video projectors and digital cameras enable every visible surface to be both measured in 3D and used for display. If the 3D surface positions are transmitted to a distant location, they may also enable distant collaborations to become more like working in adjacent offices connected by large windows. In one prototype, depth maps are calculated from streams of video images and the resulting 3D surface points are displayed to the user in head-tracked stereo. Another prototype allows direct ""painting"" onto movable objects - a dollhouse, for example. One long-term goal is advanced training for trauma surgeons by immersive replay of recorded procedures. More generally, we hope to demonstrate that the principal interface of a future computing environment need not be limited to a screen the size of one or two sheets of paper. Just as a useful physical environment is all around us, so too can the increasingly ubiquitous computing environment be all around us - becoming more effectively human-centered and integrated into our physical surroundings.",1943-6106,0-7695-2443-5,10.1109/VLHCC.2005.46,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1509481,,Computer displays;Computer interfaces;Prototypes;Physics computing;Keyboards;Digital cameras;Three dimensional displays;Large screen displays;Collaborative work;Streaming media,visual programming;solid modelling;virtual reality;human computer interaction;user centred design;user interfaces,immersive integration;virtual environments;human-centered environments;user interface;multiple video projectors;digital cameras;3D surface position;windows;video images;3D surface points;movable objects;ubiquitous computing,,,,,,17-Oct-05,,,IEEE,IEEE Conferences
The Effects of Two Game Interaction Modes on Cortical Activation in Subjects of Different Ages: A Functional Near-Infrared Spectroscopy Study,R. Ge; Z. Wang; X. Yuan; Q. Li; Y. Gao; H. Liu; Z. Fan; L. Bu,"School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore",IEEE Access,20-Jan-21,2021,9,,11405,11415,"Increasing age and various pathological factors lead to cognitive function decline among the elderly. The most serious cognitive dysfunctions among the elderly include mild cognitive impairment (MCI), Alzheimer's disease (AD), and vascular dementia (VAD). Cognitive training is an effective approach to mitigate the decline in cognitive function. Recent studies have confirmed that emerging training methods using new technologies, such as virtual reality (VR) and mobile phones, can be used effectively for cognitive training. This study used functional near-infrared spectroscopy (fNIRS) to compare the brain activation of young and elderly people during VR and mobile phone training when performing a cognitive training game. fNIRS has been shown to be an effective tool for monitoring cognitive decline. In the current study, the MMSE scale was used to measure cognitive performance and fNIRS was used to measure brain activation among 20 youth (mean age 25.33¬± 1.59 years) and 17 elderly people (mean age 63¬± 4.35 years). The results showed that the mobile phone game produced significant activation of the prefrontal lobe (PFC) and the VR game produced significant activation of the parietal lobe (MC). The average MMSE scale score of the elderly group was lower than that of the young group and was strongly correlated with PFC activation. This study confirms that elderly people have reduced cognitive function compared to young people. The results indicate that mobile phone games have a positive training effect on reducing cognitive decline, and that VR is a suitable means for cognitive function training among the elderly.",2169-3536,,10.1109/ACCESS.2021.3050210,Ministry of Education in China (MOE) Project of Humanities and Social Sciences; Shandong Social Science Planning Fund Program; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9317849,Virtual reality;functional near-infrared spectroscopy;cortical activation;game experience;cognitive decline,Games;Training;Senior citizens;Mobile handsets;Spectroscopy;Land mobile radio;Task analysis,biomedical optical imaging;brain;cognition;computer games;diseases;geriatrics;infrared spectroscopy;neurophysiology;virtual reality,game interaction modes;cortical activation;cognitive function decline;mild cognitive impairment;mobile phones;near-infrared spectroscopy;fNIRS;brain activation;mobile phone training;cognitive training game;cognitive decline;cognitive performance;mobile phone game;VR game;PFC activation;cognitive function training,,,,50,CCBY,8-Jan-21,,,IEEE,IEEE Journals
DTI-based Virtual Reality System for Neurosurgery,C. Lo; Y. Chao; K. Chou; W. Guo; J. Su; C. Lin,"Institute of Biomedical Engineering, Chung-Yuan Christian University. Dept. of BME, CYCU, 200, Chung Pei Rd., Chung Li, Taiwan 32023. e-mail: lgjbear@bclab.ym.edu.tw; Institute of Electrical Engineering, National Taiwan University. R304, EE II Building, Dept. of EE, NTU, No.1, Roosevelt Rd. Sec. 4, Taipei, Taiwan, 106. e-mail: catpin@me.ee.ntu.edu.tw; Institute of Biomedical Engineering, National Yang Ming University. e-mail: dargon@bclab.ym.edu.tw; Departments of Radiology, Taipei Veterans General Hospital. e-mail: wyguo@vghtpe.gov.tw; Institute of Biomedical Engineering, Chung-Yuan Christian University. Dept. of BME, CYCU, 200, Chung Pei Rd., Chung Li, Taiwan 32023. e-mail: jls@cycu.edu.tw; Institute of Neuroscience, National Yang-Ming University. phone: +886-2-28267338, email: cplin@ym.edu.tw",2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,22-Oct-07,2007,,,1326,1329,"The relationship between tumor mass and peritumoral structures including peritumoral edema is important for planning surgical trajectory and crucial for diagnosis, tumor excision, and post-surgical outcome. The recent development of diffusion tensor MRI has shown its feasibility in grading tumor, monitoring therapeutic effects, and post-surgery outcome. To visualize the tumor mass and the peritumoral structure, a 3D virtual reality environment was developed. Neural tractography and peritumoral anatomy were integrated in this interaction VR system. Using a 3D controller, suitable surgical trajectory can be defined by manipulating the tumor mass, peritumoral microstructure, and brain tissues before neurosurgery. Post-surgery evaluation showed that this system was useful to design pre-surgerical plan and optimize therapeutic outcome.",1558-4615,978-1-4244-0787-3,10.1109/IEMBS.2007.4352542,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4352542,,Virtual reality;Neurosurgery;Neoplasms;Surgery;Trajectory;Tensile stress;Magnetic resonance imaging;Visualization;Anatomy;Weight control,biodiffusion;biomedical MRI;brain;cancer;neurophysiology;surgery;tumours;virtual reality,DTI-based virtual reality system;neurosurgery;brain tumor mass;peritumoral structures;peritumoral edema;surgical trajectory planning;tumor excision;postsurgery evaluation;diffusion tensor MRI;therapeutic effects monitoring;3D virtual reality environment;neural tractography;peritumoral anatomy;3D controller;brain tissue microstructure;presurgerical plan design,"Computer Graphics;Diffusion Magnetic Resonance Imaging;Diffusion Magnetic Resonance Imaging;Equipment Design;Equipment Failure Analysis;Image Interpretation, Computer-Assisted;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Imaging, Three-Dimensional;Neurosurgical Procedures;Neurosurgical Procedures;Surgery, Computer-Assisted;Surgery, Computer-Assisted;User-Computer Interface",2,,10,,22-Oct-07,,,IEEE,IEEE Conferences
MIME: A Mixed-Space Collaborative System with Three Immersion Levels and Multiple Users,I. Garc√≠a-Pereira; J. Gimeno; M. P√©rez; C. Portal√©s; S. Casas,"Department of Computer Science, University of Valencia; Department of Computer Science, University of Valencia; Department of Computer Science, University of Valencia; Department of Computer Science, University of Valencia; Department of Computer Science, University of Valencia",2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),29-Apr-19,2018,,,179,183,"Shared spaces for remote collaboration are nowadays possible by considering a variety of users, devices, immersion systems, interaction capabilities, navigation paradigms, etc. There is a substantial amount of research done in this line, proposing different solutions. However, still a more general solution that considers the heterogeneity of the involved actors/items is lacking. In this paper, we present MIME, a mixed-space tri-collaborative system. Differently from other mixed-space systems, MIME considers three different types of users (in different locations) according to the level of immersion in the system, who can interact simultaneously - what we call a tri-collaboration. For the three types, we provide a solution to navigate, point at objects/locations and make annotations, while users are able to see a virtual representation of the rest of users. Additionally, the total number of users that can simultaneously interact with the system is only restricted by the available hardware, i.e., various users of the same type can be simultaneously connected to the system. We have conducted a preliminary study at the laboratory level, showing that MIME is a promising tool that can be used in many real cases for different purposes.",,978-1-5386-7592-2,10.1109/ISMAR-Adjunct.2018.00062,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699172,"Augmented Reality;Virtual Reality;shared spaces;mixed-space;remote collaboration;K.5.1 [Multimedia Information Systems]: Artificial, augmented, and virtual realities",Augmented reality,groupware;virtual reality,virtual representation;mixed-space tri-collaborative system;interaction capabilities;immersion systems;remote collaboration;MIME,,3,,15,,29-Apr-19,,,IEEE,IEEE Conferences
The versatility of the Wii controller in CS education,V. B. Petroviƒá; D. Ivetiƒá; Z. Konjoviƒá,"Faculty of Technical Sciences, Novi Sad, Serbia; Faculty of Technical Sciences, Novi Sad, Serbia; Faculty of Technical Sciences, Novi Sad, Serbia",2011 IEEE 9th International Symposium on Intelligent Systems and Informatics,3-Oct-11,2011,,,59,64,"This paper discusses the applicability of the Wii controller to CS (computer science) education. The controller can be used as an inexpensive sensor platform or as a human interface device. Its applicability is studied trough two examples: virtual reality and advanced human computer interaction on one side and artificial intelligence on the other. Both these examples showcase the flexibility of the Wii controller in particular and consumer electronics game accessories in general. It is also observed that despite the seemingly disparate nature of the example subjects chosen, project from both merged seamlessly. This illustrates that the Wii controller is very good at exploiting the deep synergy that exists between varying fields of CS study.",1949-0488,978-1-4577-1974-5,10.1109/SISY.2011.6034383,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6034383,,Tracking;Virtual reality;Neurons;Artificial intelligence;Artificial neural networks;Education;Hardware,artificial intelligence;computer games;computer science education;consumer electronics;human computer interaction;sensors;telecontrol;user interfaces;virtual reality,Wii controller;CS education;computer science education;human interface device;virtual reality;human computer interaction;artificial intelligence;consumer electronics game accessory,,3,,15,,3-Oct-11,,,IEEE,IEEE Conferences
A Low-Cost Multi-modal Auditory-Visual-Tactile Framework for Remote Touch,F. Sanfilippo; C. Pacchierotti,"University of Agder (UiA); CNRS, Univ Rennes, Inria, IRISA",2020 3rd International Conference on Information and Computer Technologies (ICICT),14-May-20,2020,,,213,218,"Haptic technology for human augmentation provides gains in ability for different applications, whether the aim is to enhance ""disabilities"" to ""abilities"", or ""abilities"" to ""super-abilities"". Commercially-available devices are generally expensive and tailored to specific applications and hardware. To give researchers a haptic feedback system that is economical, customisable, and fast to fabricate, our group developed a low-cost immersive haptic, audio, and visual experience built by using off-the-shelf (COTS) components. It is composed of a vibrotactile glove, a Leap Motion sensor, and an head-mounted display, integrated together to provide compelling immersive sensations. This paper proposes a higher technology readiness level (TRL) for the system to make it modular and reliable. To demonstrate its potential, we present two human subject studies in Virtual Reality. They evaluate the capability of the system in providing (i) guidance during simulated drone operations, and (ii) contact haptic feedback during virtual objects interaction. Results prove that the proposed haptic-enabled framework improves the performance and illusion of presence.",,978-1-7281-7283-5,10.1109/ICICT50521.2020.00040,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9092180,Haptics;Human-Computer Interaction;Multimodality,Haptic interfaces;Visualization;Actuators;Hardware;Software;Rendering (computer graphics);Force,data gloves;haptic interfaces;helmet mounted displays;virtual reality,low-cost multimodal auditory-visual-tactile framework;remote touch;haptic technology;human augmentation;super-abilities;commercially-available devices;haptic feedback system;visual experience;off-the-shelf components;vibrotactile glove;leap motion sensor;head-mounted display;compelling immersive sensations;higher technology readiness level;human subject studies;contact haptic feedback;COTS components;TRL;virtual reality,,,,24,,14-May-20,,,IEEE,IEEE Conferences
Whole-hand kinesthetic feedback and haptic perception in dextrous virtual manipulation,C. S. Tzafestas,"Lab. de Robotique de Paris, France","IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans",20-Jun-03,2003,33,1,100,113,"One of the key requirements for a Virtual Reality system is the multimodal, real-time interaction between the human operator and a computer simulated and animated environment. This paper investigates problems related particularly to the haptic interaction between the human operator and a virtual environment. The work presented here focuses on two issues: 1) the synthesis of whole-hand kinesthetic feedback, based on the application of forces (torques) on individual phalanges (joints) of the human hand, and 2) the experimental evaluation of this haptic feedback system, in terms of human haptic perception of virtual physical properties (such as the weight of a virtual manipulated object), using psychophysical methods. The proposed kinesthetic feedback methodology is based on the solution of a generalized force distribution problem for the human hand during virtual manipulation tasks. The solution is computationally efficient and has been experimentally implemented using an exoskeleton force-feedback glove. A series of experiments is reported concerning the perception of weight of manipulated virtual objects and the obtained results demonstrate the feasibility of the concept. Issues related to the use of sensory substitution techniques for the application of haptic feedback on the human hand are also discussed.",1558-2426,,10.1109/TSMCA.2003.812600,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1206459,,Haptic interfaces;Humans;Force feedback;Virtual reality;Real time systems;Computational modeling;Computer simulation;Animation;Virtual environment;Application software,virtual reality;haptic interfaces;dexterous manipulators,dextrous virtual manipulation;human operator;kinesthetic feedback;haptic feedback;human haptic perception;virtual physical properties;exoskeleton glove;grasping force distribution;psychophysics;virtual reality,,33,3,53,,20-Jun-03,,,IEEE,IEEE Journals
Research on the Realization of Substation Virtual Equipment Based on 3D Engine,Z. Qu; T. Jiang,"Sch. of Inf. Eng., Northeast Dianli Univ., Jilin, China; Sch. of Inf. Eng., Northeast Dianli Univ., Jilin, China",2009 International Forum on Computer Science-Technology and Applications,19-Jan-10,2009,2,,299,302,"According to training requirements that a substation virtual training scene needs substation virtual equipment with high actual sense and high interaction. This paper proposes a thought which is used to achieve substation virtual equipment by 3D engine, and then generalizes a method which contains geometrical characteristic, interactive characteristic and behavioral characteristic towards Virtual equipment achieved by 3D engine. This method uses modeling tool to construct the geometrical appearance of substation virtual equipment, takes the 3D engine VR technique as core to realize interactive characteristic and behavioral characteristic of the virtual equipment. Combining with substation the application characteristics of substation virtual equipment, the paper proposes an interactive algorithm suiting to virtual equipment to improve the interaction of virtual equipment.",,978-1-4244-5423-5,10.1109/IFCSTA.2009.195,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5384578,virtual reality;the 3D engine;substation;virtual equipment;object-oriented,Substations;Engines;Virtual reality;Object oriented modeling;Layout;Cities and towns;Solid modeling;Educational technology;Isolation technology;Switches,computational geometry;computer based training;engineering graphics;power engineering computing;power engineering education;solid modelling;substations;virtual reality,substation virtual equipment realization;3D engine;geometrical characteristic;interactive characteristic;behavioral characteristic;virtual training scene,,,,8,,19-Jan-10,,,IEEE,IEEE Conferences
New Magnetic Microactuator Design Based on PDMS Elastomer and MEMS Technologies for Tactile Display,J. Streque; A. Talbi; P. Pernod; V. Preobrazhensky,"Joint International Laboratory LEMAC: Institute of Electronics, Microelectronics and Nanotechnology (IEMN-UMR CNRS), Villeneuve d'Ascq; Joint International Laboratory LEMAC: Institute of Electronics, Microelectronics and Nanotechnology (IEMN-UMR CNRS), Villeneuve d'Ascq; Joint International Laboratory LEMAC: Institute of Electronics, Microelectronics and Nanotechnology (IEMN-UMR CNRS), Villeneuve d'Ascq; Joint International Laboratory LEMAC: Institute of Electronics, Microelectronics and Nanotechnology, Villeneuve d'Ascq and Wave Research Center of Prokhorov General Physics Institute, RAS",IEEE Transactions on Haptics,28-Jun-10,2010,3,2,88,97,"Highly efficient tactile display devices must fulfill technical requirements for tactile stimulation, all the while preserving the lightness and compactness needed for handheld operation. This paper focuses on the elaboration of highly integrated magnetic microactuators for tactile display devices. FEM simulation, conception, fabrication, and characterization of these microactuators are presented in this paper. The current demonstrator offers a 4 √ó 4 flexible microactuator array with a resolution of 2 mm. Each actuator is composed of a Poly (Dimethyl-Siloxane) (PDMS) elastomeric membrane, magnetically actuated by coil-magnet interaction. It represents a proof of concept for fully integrated MEMS tactile devices, with fair actuation forces provided for a power consumption up to 100 mW per microactuator. The prototypes are destined to provide both static and dynamic tactile sensations, with an optimized membrane geometry for actuation frequencies between DC and 350 Hz. On the basis of preliminary experiments, this display device can offer skin stimulations for various tactile stimuli for applications in the fields of Virtual Reality or Human-Computer Interaction (HCI). Moreover, the elastomeric material used in this device and its global compactness offer great advantages in matter of comfort of use and capabilities of integration in haptic devices.",2329-4051,,10.1109/TOH.2009.61,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5374397,Actuators;MEMS;micromagnetomechanical systems (MMMS);tactile display;magnetic actuation.,Micromagnetics;Micromechanical devices;Displays;Microactuators;Biomembranes;Fabrication;Actuators;Energy consumption;Virtual prototyping;Geometry,display devices;elastomers;electromagnetic actuators;haptic interfaces;human computer interaction;microactuators,magnetic microactuator design;PDMS elastomer;MEMS technologies;tactile display;tactile stimulation;handheld operation;FEM simulation;elastomeric membrane;coil magnet interaction;virtual reality;human computer interaction;HCI;elastomeric material,,44,2,27,,8-Jan-10,,,IEEE,IEEE Journals
A framework for interaction of distributed autonomous systems and human supervisors,H. J. W. Spoelder; D. M. Germans; L. Renambot; H. E. Bal; P. J. de Waal; F. C. A. Groen,"Dept. of Phys. & Astron., Vrije Univ., Amsterdam, Netherlands; NA; NA; NA; NA; NA",IMTC 2001. Proceedings of the 18th IEEE Instrumentation and Measurement Technology Conference. Rediscovering Measurement in the Age of Informatics (Cat. No.01CH 37188),7-Aug-02,2001,3,,1937,1941 vol.3,Autonomous systems are rapidly gaining importance in a large number of situations relevant to the general public. By their nature their need for external control is low but still necessary. In this paper we present a framework for interaction of distributed autonomous systems and human supervisors. This framework exploits progress made in a number of related areas and shows that they can be effectively combined into one single framework. To this end it combines an environment for computational steering with virtual reality techniques for visualization and WAP-based communication for ubiquitous intervention. Given the described setup for the technology the current version must be seen as a prototype that shows the feasibility of this approach.,1091-5281,0-7803-6646-8,10.1109/IMTC.2001.929538,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=929538,,Humans;Virtual reality;Internet;Extraterrestrial measurements;Anthropometry;Mobile handsets;Data visualization;IP networks;Physics;Astronomy,virtual reality;software agents;cooperative systems;virtual instrumentation;Internet telephony,distributed autonomous systems;human supervisors;interaction framework;external control;computational steering;virtual reality techniques;visualization;WAP-based communication;ubiquitous intervention;human in the loop;Internet-based systems;second-generation mobile phones;CAVE environment;Internet robots;virtual instrument;shared world,,,1,8,,7-Aug-02,,,IEEE,IEEE Conferences
Body-based interfaces,Changseok Cho; Huichul Yang; G. J. Kim; S. H. Han,"Imaging Media Res. Center, Korea Inst. of Sci. & Technol., South Korea; NA; NA; NA",Proceedings. Fourth IEEE International Conference on Multimodal Interfaces,22-Jan-03,2002,,,466,472,"This research explores different ways to use features of one's own body for interacting with computers. In the future, such ""body-based"" interfaces may be put into good use for wearable computing or virtual reality systems as part of a 3D multi-modal interface, freeing the user from holding interaction devices. We have identified four types of body-based interfaces: the Body-inspired-metaphor uses various parts of the body metaphorically for interaction; the Body-as-interaction-surface simply uses parts of the body as points of interaction; Mixed-mode mixes the former two; Object-mapping spatially maps the interaction object to the human body. These four body-based interfaces were applied to three different applications (and associated tasks) and were tested for their performance and utility. It was generally found that, while the body-inspired-metaphor produced the lowest error rate, it required a longer task completion time and caused more fatigue due to the longer hand moving distance. On the other hand, the body-as-interaction-surface was the fastest, but produced many more errors.",,0-7695-1834-6,10.1109/ICMI.2002.1167040,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1167040,,Wearable computers;Virtual reality;Humans;Guidelines;Computer science;Industrial engineering;Testing;Error analysis;Fatigue;Eyes,user interfaces;human factors;wearable computers;virtual reality,body-based interfaces;wearable computing;virtual reality;3D multi-modal interface;interaction devices;object-mapping;performance;error;interaction styles;task completion time,,1,1,9,,22-Jan-03,,,IEEE,IEEE Conferences
Learning 6-DOF Grasping Interaction via Deep Geometry-Aware 3D Representations,X. Yan; J. Hsu; M. Khansari; Y. Bai; A. Pathak; A. Gupta; J. Davidson; H. Lee,Universitv of Michigan during internship with Goozle Brain; Google; X Inc.; X Inc.; Google; Google; Google; Google,2018 IEEE International Conference on Robotics and Automation (ICRA),13-Sep-18,2018,,,3766,3773,"This paper focuses on the problem of learning 6- DOF grasping with a parallel jaw gripper in simulation. Our key idea is constraining and regularizing grasping interaction learning through 3D geometry prediction. We introduce a deep geometry-aware grasping network (DGGN) that decomposes the learning into two steps. First, we learn to build mental geometry-aware representation by reconstructing the scene (i.e., 3D occupancy grid) from RGBD input via generative 3D shape modeling. Second, we learn to predict grasping outcome with its internal geometry-aware representation. The learned outcome prediction model is used to sequentially propose grasping solutions via analysis-by-synthesis optimization. Our contributions are fourfold: (1) To best of our knowledge, we are presenting for the first time a method to learn a 6-DOF grasping net from RGBD input; (2) We build a grasping dataset from demonstrations in virtual reality with rich sensory and interaction annotations. This dataset includes 101 everyday objects spread across 7 categories, additionally, we propose a data augmentation strategy for effective learning; (3) We demonstrate that the learned geometry-aware representation leads to about 10% relative performance improvement over the baseline CNN on grasping objects from our dataset. (4) We further demonstrate that the model generalizes to novel viewpoints and object instances.",2577-087X,978-1-5386-3081-5,10.1109/ICRA.2018.8460609,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8460609,,Grasping;Three-dimensional displays;Shape;Geometry;Solid modeling;Two dimensional displays;Robots,convolution;dexterous manipulators;geometry;grippers;image reconstruction;image representation;intelligent robots;learning (artificial intelligence);optimisation;recurrent neural nets;virtual reality,outcome prediction model;3D shape modeling;DGGN;analysis-by-synthesis optimization;6-DOF grasping net;virtual reality;sensory annotations;data augmentation strategy;CNN;3D occupancy grid;mental geometry-aware representation;deep geometry-aware grasping network;3D geometry prediction;grasping interaction learning;parallel jaw gripper;RGBD input;internal geometry-aware representation,,15,,43,,13-Sep-18,,,IEEE,IEEE Conferences
A two-port framework for the design of unconditionally stable haptic interfaces,R. J. Adams; B. Hannaford,"Dept. of Electr. Eng., Washington Univ., Seattle, WA, USA; NA","Proceedings. 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems. Innovations in Theory, Practice and Applications (Cat. No.98CH36190)",6-Aug-02,1998,2,,1254,1259 vol.2,"A haptic interface is a kinesthetic link between a human operator and a virtual environment. This paper addresses stability and performance issues associated with haptic interaction. It generalizes and extends the concept of a virtual coupling network, an artificial connection between a haptic display and a virtual world, to include both the impedance and admittance models of haptic interaction. A benchmark example exposes an important duality between these two cases. Linear circuit theory is used to develop necessary and sufficient conditions for the stability of a haptic simulation, assuming the human operator and virtual environment are passive. These equations lead to an explicit design procedure for virtual coupling networks which give maximum performance while guaranteeing stability. By decoupling the haptic display control problem from the design of virtual environments, the use of a virtual coupling network frees the developer of haptic-enabled virtual reality models from issues of mechanical stability.",,0-7803-4465-0,10.1109/IROS.1998.727471,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=727471,,Haptic interfaces;Virtual environment;Humans;Coupling circuits;Displays;Circuit stability;Impedance;Admittance;Linear circuits;Sufficient conditions,virtual reality;haptic interfaces;two-port networks;stability,two-port framework;unconditionally stable haptic interface design;kinesthetic link;virtual environment;haptic interaction;virtual coupling network;haptic display;impedance model;admittance model;duality;linear circuit theory;necessary and sufficient conditions;human operator;virtual coupling networks;mechanical stability,,55,2,12,,6-Aug-02,,,IEEE,IEEE Conferences
Influence of visual information on bimanual haptic manipulation,S. Contu; C. Hughes; L. Masia,"School of Mechanical & Aerospace Engineering, Nanyang Technological University, Singapore; School of Mechanical & Aerospace Engineering, Nanyang Technological University, Singapore; School of Mechanical & Aerospace Engineering, Nanyang Technological University, Singapore",2015 IEEE International Conference on Rehabilitation Robotics (ICORR),1-Oct-15,2015,,,961,966,"The coordination of the upper limbs has been shown to be beneficial for post-stroke treatment. In virtual reality based rehabilitation, bimanual exercises can be performed by exploiting haptic rendering techniques that allow object manipulation with two haptic devices. Haptic interaction generally involves spherical end-effectors with invariant shapes. Furthermore, the position of the end-effectors can only be sensed haptically after object contact, which impacts the ability to determine the real position of the end effector and dynamically manipulate the object. The present study sought to examine whether additional visual information regarding the penetration of the wrists into the virtual object (i.e., the color and shape of the spheres changed according to the level of force exerted by the subject) leads to improved bimanual task performance in a virtual environment. To this end, six neurologically healthy participants performed an object manipulation task with haptic feedback (haptic condition) and with haptic feedback as well as additional visual cues (haptic+visual condition). Results demonstrated that interlimb coordination was enhanced during the haptic+visual condition. It is speculated that the presence of visual information provides a more natural way for individuals to exploit inter-limb coordination synergies, and may have useful implications for VR game development and post stroke rehabilitation protocols.",1945-7901,978-1-4799-1808-9,10.1109/ICORR.2015.7281328,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7281328,,Haptic interfaces;Visualization;Wrist;Force;Virtual environments;Hip;Robots,artificial limbs;end effectors;medical computing;medical robotics;patient rehabilitation;rendering (computer graphics);virtual reality,visual information;bimanual haptic manipulation;upper limb coordination;post-stroke treatment;virtual reality based rehabilitation;bimanual exercises;haptic rendering;haptic interaction;spherical end-effectors;virtual environment;post stroke rehabilitation protocols;VR game development;interlimb coordination synergies;haptic feedback;object manipulation task,,3,,26,,1-Oct-15,,,IEEE,IEEE Conferences
A framework for interaction of distributed autonomous systems and human supervisors,H. J. Spoelder; D. M. Germans; L. Renambot; H. E. Bal; P. J. de Waal; F. C. A. Groen,"Fac. of Sci., Vrije Univ., Amsterdam, Netherlands; Fac. of Sci., Vrije Univ., Amsterdam, Netherlands; Fac. of Sci., Vrije Univ., Amsterdam, Netherlands; Fac. of Sci., Vrije Univ., Amsterdam, Netherlands; NA; NA",IEEE Transactions on Instrumentation and Measurement,18-Apr-05,2002,51,4,798,803,"Semi-autonomous systems are rapidly gaining importance in a large number of situations relevant to the general public. By their nature, their need for external control is low but still necessary. In this paper, we present a framework for interaction of distributed autonomous systems and human supervisors. This framework exploits progress made in several related areas and shows that they can be effectively combined into one single framework. To this end, it combines an environment for computational steering with virtual reality techniques for visualization and WAP-based communication for ubiquitous intervention. Given the current state for the technology, the current version must be regarded as a proof of principle.",1557-9662,,10.1109/TIM.2002.803400,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1044749,,Humans;Wireless application protocol;Extraterrestrial measurements;Internet;Mobile handsets;Virtual reality;Anthropometry;Pervasive computing;Visualization;Safety,virtual reality;interactive systems;distributed processing;measurement systems;Internet;protocols,distributed autonomous systems;human supervisors;virtual reality;visualization;WAP-based communication;human in the loop;wireless application protocol;Internet-based systems;CAVE system;distributed measurements,,1,,8,,18-Apr-05,,,IEEE,IEEE Journals
Computer modeling of interaction of gas discharge plasma with solid dielectric barriers,Y. V. Serdyuk; S. M. Gubanski,"Chalmers Univ. of Technol., Gothenburg, Sweden; Chalmers Univ. of Technol., Gothenburg, Sweden",IEEE Transactions on Dielectrics and Electrical Insulation,26-Sep-05,2005,12,4,725,735,"A computer model describing charge transfer in a system consisting of two parallel-plate metallic electrodes covered with solid dielectric barriers immersed in gas medium is proposed. The material of the barriers is supposed to be a non-ideal insulator whose properties correspond to polyethylene and air is considered as a gas phase. The model is based on continuity equations for fluxes of charge carriers and accounts for their drift and diffusion and also for different sources of their generation and losses in different media. The continuity equations are coupled with Poisson's equation for computing electric fields affected by temporal and spatial variations of space charges in the system. Results of the computer simulations are obtained for the case when the applied field in the gas exceeds its breakdown threshold, i.e. charge transfer in the gas phase takes place in the form of an electrical discharge (electron avalanche and streamer). Evolution of generated discharge plasma is analyzed taking into account conditions on gas-solid interfaces and in the bulk of the solid dielectric barriers.",1558-4135,,10.1109/TDEI.2005.1511098,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1511098,,Solid modeling;Discharges;Poisson equations;Charge transfer;Plasma properties;Plasma materials processing;Concurrent computing;Electrodes;Dielectric materials;Dielectrics and electrical insulation,avalanche breakdown;discharges (electric);plasma-wall interactions;space charge;plasma;electrodes;polyethylene insulation;air insulation;Poisson equation;digital simulation;charge injection,gas discharge plasma;solid dielectric barrier;charge transfer;parallel-plate metallic electrode;nonideal insulator;polyethylene;continuity equation;charge carrier;drift;diffusion;Poissons equation;electric fields;spatial variation;temporal variations;space charge;computer simulation;breakdown threshold;electrical discharge;electron avalanche;streamer propagation;gas-solid interface;charge injection;charge transport,,35,,21,,26-Sep-05,,,IEEE,IEEE Journals
Framework for haptic interaction with virtual avatars,P. Evrard; F. Keith; J. Chardonnet; A. Kheddar,"AIST/CNRS Joint Japanese-French Robotics Laboratory, Tsukuba, Japan; AIST/CNRS Joint Japanese-French Robotics Laboratory, Tsukuba, Japan; AIST/CNRS Joint Japanese-French Robotics Laboratory, Tsukuba, Japan; AIST/CNRS Joint Japanese-French Robotics Laboratory, Tsukuba, Japan",RO-MAN 2008 - The 17th IEEE International Symposium on Robot and Human Interactive Communication,15-Aug-08,2008,,,15,20,"In this paper we present an integrative frame work centered on haptic interaction with virtual avatars. This framework is devised for general prototyping and collaborative scenario studies with haptic feedback. First we present the software architecture of the framework and give details on some of its components. Then we show how this framework can be used to derive in a short time a virtual reality simulation. In this simulation, a user directly interacts with a virtual avatar to collaboratively manipulate a virtual object, with haptic feedback and using fast dynamics computation and constraint based methods with friction.",1944-9437,978-1-4244-2212-8,10.1109/ROMAN.2008.4600636,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4600636,,Robots,avatars;feedback;haptic interfaces;software architecture,haptic interaction;virtual avatars;general prototyping;collaborative scenario;haptic feedback;software architecture;virtual reality simulation;virtual object,,8,,12,,15-Aug-08,,,IEEE,IEEE Conferences
Lessons from Digital Puppetry: Updating a Design Framework for a Perceptual User Interface,J. Ferguson,"Fac. of Sci. & Technol., Univ. of Westminster, London, UK","2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing",28-Dec-15,2015,,,1590,1595,"While digital puppeteering is largely used just to augment full body motion capture in digital production, its technology and traditional concepts could inform a more naturalized multi-modal human computer interaction than is currently used with the new perceptual systems such as Kinect. Emerging immersive social media networks with their fully live virtual or augmented environments and largely inexperienced users would benefit the most from this strategy. This paper intends to define digital puppeteering as it is currently understood, and summarize its broad shortcomings based on expert evaluation. Based on this evaluation it will suggest updates and experiments using current perceptual technology and concepts in cognitive processing for existing human computer interaction taxonomy. This updated framework may be more intuitive and suitable in developing extensions to an emerging perceptual user interface for the general public.",,978-1-5090-0154-5,10.1109/CIT/IUCC/DASC/PICOM.2015.239,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363285,digital puppeteering;perceptual user interface;motion capture;cognitive;multi-modal;immersive;social media,Software;Animation;Production;Sensors;Hardware;User interfaces;Motion segmentation,augmented reality;human computer interaction;image motion analysis;image sensors;social networking (online);user interfaces,digital puppetry;design framework;perceptual user interface;digital puppeteering;full body motion capture;digital production;naturalized multimodal human computer interaction;Kinect;immersive social media networks;fully live virtual environments;augmented environments;cognitive processing;human computer interaction taxonomy,,,,22,,28-Dec-15,,,IEEE,IEEE Conferences
Intuitive volume rendering on mobile devices,Y. Xin; H. Wong,"Faculty of Information Technology, Macau University of Science and Technology, China; Faculty of Information Technology, Macau University of Science and Technology, China","2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)",16-Feb-17,2016,,,696,701,"Nowadays, mobile devices, virtual reality and augment reality technologies are developing faster and faster. With a variety of equipments, people are no longer only using PC to handle tasks. Some traditional system frameworks are migrating to these new technology areas, and direct volume rendering is one of them. In this paper, we propose a real-time and intuitive volume data exploration framework on mobile devices. Our framework introduces a direct-touch transfer function design method that is able for the user to pick voxels directly on a volume rendered image. With one-pass shader, user interaction and volume rendering can be handled efficiently in real-time. The user only needs to learn a few related knowledge to explore a volume data and get its rendered image. As a result, the time cost of transfer function design for direct volume rendering is significantly reduced. Our framework is implemented with OpenGL ES 3.0 and GLSL shader. Experimental results show the advantages of our framework. Researchers, and even general users, can easily obtain volume rendered images of volume data.",,978-1-5090-3710-0,10.1109/CISP-BMEI.2016.7852799,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7852799,Direct volume rendering;mobile devices;transfer function design;volume data;direct touch;user interface design,Transfer functions;Rendering (computer graphics);Mobile handsets;Histograms;Image color analysis;Two dimensional displays,augmented reality;mobile computing;rendering (computer graphics);transfer functions,mobile devices;virtual reality;augment reality;real-time intuitive volume data exploration;intuitive volume rendering;direct-touch transfer function design;one-pass shader;user interaction;OpenGL ES 3.0;GLSL shader,,,,13,,16-Feb-17,,,IEEE,IEEE Conferences
A Novel Multimedia Interactive System for Public Show and Presentations,M. Gaudina; S. Schiappacasse; L. Lagomarsino; E. Bellanti; G. Vercelli,"Dept. of Inf., Bioeng., Robot., & Syst. Eng., Univ. of Genoa, Genoa, Italy; Dept. of Inf., Bioeng., Robot., & Syst. Eng., Univ. of Genoa, Genoa, Italy; Circle Garage Start-up Innovativa S.R.L., Genoa, Italy; Dept. of Inf., Bioeng., Robot., & Syst. Eng., Univ. of Genoa, Genoa, Italy; Dept. of Inf., Bioeng., Robot., & Syst. Eng., Univ. of Genoa, Genoa, Italy","2014 Eighth International Conference on Complex, Intelligent and Software Intensive Systems",2-Oct-14,2014,,,543,546,"Holographic interactivity is nowadays a promising research topic within HCI field, mainly due to recent technological improvements. Moreover, low-cost off-the shelf components are widely availables, with respect to the last century situation for traditional human-machine interaction paradigms. The way of displaying information and data communication are now much more robust and solid than in the past, allowing better user experiences (Ux) than before in terms of presence and immersion. The paper presents a novel interaction system based on holographic and multi-touch technologies well suited for shows and interactive talks. The performer/presenter operates behind a vertical touch enabled transparent holographic panel where multimedia contents are projected and directly manipulated. This type of communication is much more cogent and immersive than any other, since both the presenter and the public interact facing each other with the possibility of focusing their attention on the same interspersed interactive elements. Furthermore, the system relies on a web based cross-platform framework allowing both proximal and remote interaction and visualization on smartphones, tablets and internet enabled devices in general. Preliminary interviews have underlined the goodness of this new interaction paradigm suggesting that this could be a strong base of a much larger platform for many and different uses.",,978-1-4799-4325-8,10.1109/CISIS.2014.79,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6915571,,Three-dimensional displays;Software;Tactile sensors;Business;Multimedia communication;Internet,computer aided instruction;human computer interaction;Internet;multimedia systems;touch sensitive screens,multimedia interactive system;public show;public presentation;holographic interactivity;HCI field;human computer interface;user experience;multitouch technology;holographic technology;vertical touch enabled transparent holographic panel;multimedia contents;Web based cross-platform framework;proximal interaction;remote interaction,,1,,16,,2-Oct-14,,,IEEE,IEEE Conferences
UnityMol: interactive and ludic visual manipulation of coarse-grained RNA and other biomolecules,S. Doutreligne; C. Gageat; T. Cragnolini; A. Taly; S. Pasquali; P. Derreumaux; M. Baaden,"Lab. de Biochimie Theorique, CNRS UPR9080, Univ. Paris Diderot, Sorbonne Paris Cite, 13 rue Pierre et Marie Curie, 75005, Paris, France; Lab. de Biochimie Theorique, CNRS UPR9080, Univ. Paris Diderot, Sorbonne Paris Cite, 13 rue Pierre et Marie Curie, 75005, Paris, France; Lab. de Biochimie Theorique, CNRS UPR9080, Univ. Paris Diderot, Sorbonne Paris Cite, 13 rue Pierre et Marie Curie, 75005, Paris, France; Lab. de Biochimie Theorique, CNRS UPR9080, Univ. Paris Diderot, Sorbonne Paris Cite, 13 rue Pierre et Marie Curie, 75005, Paris, France; Lab. de Biochimie Theorique, CNRS UPR9080, Univ. Paris Diderot, Sorbonne Paris Cite, 13 rue Pierre et Marie Curie, 75005, Paris, France; Lab. de Biochimie Theorique, CNRS UPR9080, Univ. Paris Diderot, Sorbonne Paris Cite, 13 rue Pierre et Marie Curie, 75005, Paris, France; Lab. de Biochimie Theorique, CNRS UPR9080, Univ. Paris Diderot, Sorbonne Paris Cite, 13 rue Pierre et Marie Curie, 75005, Paris, France",2015 IEEE 1st International Workshop on Virtual and Augmented Reality for Molecular Science (VARMS@IEEEVR),9-Jul-15,2015,,,1,6,"We present a general software architecture to carry out interactive molecular simulations in a game engine environment. Our implementation is based on the UnityMol framework and the HireRNA physics engine. With UnityMol, we pursue the goal to create an interactive virtual laboratory enabling researchers in biology to visualize biomolecular systems, run simulations and interact with physical models and data. Similarly, UnityMol enables game designers to build scientifically accurate molecular scenarios. We discuss four case studies, from simulation setup via immersive experiments, force-induced unfolding of RNA to teaching and collaborative research applications. Visual effects enrich the dynamic and immersive aspects. We combine an appealing visual feedback with a set of analysis features to extract information about properties of the fascinating biomolecular systems under study. Access to various input devices enables a natural interaction with the simulation.",,978-1-4673-6926-8,10.1109/VARMS.2015.7151718,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7151718,I.6.6 [Simulation and Modeling]-Simulation Output Analysis;J.3 [Computer Applications]: Life and Medical Sciences-Biology and Genetics,Biological system modeling;Solid modeling;RNA;Computational modeling;Games;Engines;Force,data visualisation;interactive systems;molecular biophysics;RNA;software architecture;teaching,Ludic visual manipulation;interactive visual manipulation;coarse-grained RNA;software architecture;interactive molecular simulations;game engine environment;UnityMol framework;HireRNA physics engine;interactive virtual laboratory;biomolecular systems;physical models;game designers;collaborative research applications;visual effects;visual feedback;feature extraction;information extraction,,3,,14,,9-Jul-15,,,IEEE,IEEE Conferences
Eye-MMS: Miniature Multi-Scale Segmentation Network of Key Eye-Regions in Embedded Applications,F. Boutros; N. Damer; F. Kirchbuchner; A. Kuijper,"Fraunhofer Institute for Computer Graphics Research IGD, Germany and Technische Universit√§t Darmstadt, Germany; Fraunhofer Institute for Computer Graphics Research IGD, Germany and Technische Universit√§t Darmstadt, Germany; Fraunhofer Institute for Computer Graphics Research IGD, Germany and Technische Universit√§t Darmstadt, Germany; Fraunhofer Institute for Computer Graphics Research IGD, Germany and Technische Universit√§t Darmstadt, Germany",2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW),5-Mar-20,2019,,,3665,3670,"Segmentation of the iris or sclera is an essential processing block in ocular biometric systems. However, human-computer interaction, as in VR/AR applications, requires multiple region segmentation to enable smoother interaction and eye-tracking. Such application does not only demand highly accurate and generalizable segmentation, it requires such segmentation model to be appropriate for the limited computational power of embedded systems. This puts strict limits on the size of the deployed deep learning models. This work presents a miniature multi-scale segmentation network consisting of inter-connected convolutional modules. We present a baseline multi-scale segmentation network and modify it to reduce its parameters by more than 80 times, while reducing its accuracy by less than 3%, resulting in our Eye-MMS model containing only 80k parameters. This work is developed on the OpenEDS database and is conducted in preparation for the OpenEDS Semantic Segmentation Challenge.",2473-9944,978-1-7281-5023-9,10.1109/ICCVW.2019.00452,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022048,Semantic segmentation;Biometrics;Eye segmentation;Embedded biometrics,Image segmentation;Iris recognition;Databases;Solid modeling;Semantics;Image resolution;Computational modeling,augmented reality;biometrics (access control);embedded systems;eye;gaze tracking;human computer interaction;image segmentation;learning (artificial intelligence);neural nets,miniature multiscale segmentation network;eye regions;embedded applications;ocular biometric systems;human-computer interaction;multiple region segmentation;eye-tracking;embedded systems;deep learning;baseline multiscale segmentation network;Eye-MMS model;OpenEDS Semantic Segmentation Challenge;OpenEDS database;AR application;VR application,,8,,26,,5-Mar-20,,,IEEE,IEEE Conferences
"Origami, folding paper over the Web",N. Kishi; Y. Fujii,"Dept. of Math. & Comput. Sci., Tsuda Coll., Tokyo, Japan; NA",Proceedings. 3rd Asia Pacific Computer Human Interaction (Cat. No.98EX110),6-Aug-02,1998,,,337,342,"Origami, paperfolding, is a traditional Japanese art of folding paper into representation of 3-D figures. In general, it is quite difficult to learn origami from 2-D images such as diagrams and videos, because it requires inference of 3-D models from 2-D images. We are developing a system for folding origami over the Web, by designing a model of an origami folding process and by implementing a client-server system. Our system consists of three parts: the origami editor, origami server and origami browser. The origami editor enables the user to create and edit origami projects, which are sequences of origami states and folding methods. The origami server receives the input data from the editor and generates a VRML 2.0 data stream, which represents a transition between two origami states. The VRML 2.0 data stream is then displayed by the origami browser, or a VRML 2.0 browser, as a 3-D origami figure in motion.",,0-8186-8347-3,10.1109/APCHI.1998.704454,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=704454,,Videos;Books;Read only memory;Educational institutions;Art;Shape;Mathematics;Computer science;Client-server systems;Electrical capacitance tomography,computer animation;solid modelling;user interfaces;Internet;client-server systems;virtual reality,origami editor;paperfolding;Japanese art;3D figure representation;2D images;diagrams;World Wide Web;client-server system;origami server;origami browser;VRML;animation,,2,,4,,6-Aug-02,,,IEEE,IEEE Conferences
Rehabilitation Game Model for Personalised Exercise,D. Holmes; D. Charles; P. Morrow; S. McClean; S. McDonough,"Comput. Sci. Res. Inst., Univ. of Ulster, Newtownabbey, UK; Comput. Sci. Res. Inst., Univ. of Ulster, Newtownabbey, UK; Comput. Sci. Res. Inst., Univ. of Ulster, Newtownabbey, UK; Comput. Sci. Res. Inst., Univ. of Ulster, Newtownabbey, UK; Comput. Sci. Res. Inst., Univ. of Ulster, Newtownabbey, UK",2015 International Conference on Interactive Technologies and Games,8-Feb-16,2015,,,41,48,"Existing literature has shown that games and virtual reality can help motivate people thus keeping them engaged for longer. Nonetheless, in most approaches the design of games or virtual reality for rehabilitation purposes tend to apply a basic motivational approach that focuses on the general population of game players. Recent research shows that individuals can be motivated quite differently and so it may be important to consider each individual's motivational characteristics within the context of rehabilitation to ensure continued engagement. In this paper we present the Rehabilitation Game Model (RGM), which can be used as a basis for evaluating existing systems and for designing new interactive rehabilitation systems that are more personalised and engaging. Initial evaluation of existing rehabilitation games and comparison with commercial games using the RGM indicate a potential over emphasis on achievement based reward systems in rehabilitation game design compared to other reward systems.",,978-1-4673-7874-1,10.1109/iTAG.2015.11,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7399488,rehabilitation;game design;gamification;motivation;user types,Games;Ontologies;Psychology;Solid modeling;Virtual reality;Context;Systematics,computer games;health care;human computer interaction;patient rehabilitation;virtual reality,rehabilitation game model;personalised exercise;virtual reality;interactive rehabilitation systems;gamification;motivational characteristics,,4,,30,,8-Feb-16,,,IEEE,IEEE Conferences
"Which do you feel comfortable, interview by a real doctor or by a virtual doctor? A comparative study of responses to inquiries with various psychological intensities, for the development of the Hyper Hospital",A. Yoshida; Y. Hagita; K. Yamazaki; T. Yamaguchi,"Dept. of Inf. Technol., Kyoto Inst. of Technol., Japan; Dept. of Inf. Technol., Kyoto Inst. of Technol., Japan; NA; NA",Proceedings of 1993 2nd IEEE International Workshop on Robot and Human Communication,6-Aug-02,1993,,,370,374,"The ""Hyper Hospital"" is a novel medical care system which will be constructed on an electronic information network. The human interface of the Hyper Hospital based on the modern virtual reality technology is expected to maximally enhance patients' ability of healing illness by computer-supported online visual consultations. In order to investigate the effects and features of online visual consultations in the Hyper Hospital, we conducted an experiment to clarify the influence of electronic interviews on the talking behavior of interviewees in the similar context to real doctor-patient interactions. Four types of distant-confrontation interviews were presented to voluntary subjects and their verbal and nonverbal responses were analyzed from the human ethological viewpoints. In the media-mediated interviews both the latency and the duration of interviewees' utterances in answering questions increased compared with those of live face to face interviews. These results suggest that the interviewee became more verbose or talkative in the mediated interviews, but his psychological tension was generally augmented.<>",,0-7803-1407-7,10.1109/ROMAN.1993.367690,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=367690,,Hospitals;Humans;Psychology;Virtual reality;Information technology;Modems;Computer interfaces;Delay;Medical simulation;Medical services,medical computing;virtual reality;human factors;information networks,virtual doctor;psychological intensities;Hyper Hospital;electronic information network;virtual reality;computer-supported online visual consultations;verbosity;talkativeness;psychological tension,,1,,15,,6-Aug-02,,,IEEE,IEEE Conferences
Measurement system of Œ± Œ≤ surface radioactive contamination based on Virtual Training,Hui Weihua; Huang Changqiang; Ding Dali,"The Engineering Institute, Air Force Engineering University, Xi'an 710038, China; The Engineering Institute, Air Force Engineering University, Xi'an 710038, China; The Engineering Institute, Air Force Engineering University, Xi'an 710038, China",IEEE 2011 10th International Conference on Electronic Measurement & Instruments,10-Oct-11,2011,2,,90,93,"A Virtual Training System of Œ± Œ≤ surface radioactive contamination measurement is constructed based on Virtual Reality. Firstly, 3-d geometric models about radioactive environment, radioactive environment of surface device, Œ± Œ≤ detector, surface contamination instrument are constructed, the general radioactive law based on face radioactive source is presented. These models are driving in general program platform using human-computer interaction technology. Furthermore, there are several functions about database sharing, fault diagnosis, examining evaluation and on-time help which realize the whole system virtual training. Program show this training system avoid ‚Äúnuclear fear‚Äù psychology and improve staff's training effect.",,978-1-4244-8161-3,10.1109/ICEMI.2011.6037772,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6037772,virtual training;radioactivity;Œ± ray;Œ≤ ray;radiation field,Pollution measurement;Training;Surface contamination;Solid modeling;Instruments;Software,nuclear power stations;radioactivity measurement;surface contamination;virtual reality,measurement system;surface radioactive contamination;virtual training;virtual reality;3D geometric models;radioactive environment;surface contamination instrument;human-computer interaction technology;database sharing;fault diagnosis,,,,4,,10-Oct-11,,,IEEE,IEEE Conferences
Archeovirtual 2011: An evaluation approach to virtual museums,S. Pescarin; A. Pagano; M. Wallerg√•rd; W. Hupperetz; C. Ray,"Virtual Heritage Laboratory, CNR ITABC, Rome, Italy; University of Lugano, Switzerland; Lund University, Sweden; Allard Pierson Museum, University of Amsterdam Netherlands; Allard Pierson Museum, University of Amsterdam, Netherlands",2012 18th International Conference on Virtual Systems and Multimedia,3-Dec-12,2012,,,25,32,"November 2011 saw the opening of the exhibition ‚ÄúArcheovirtual‚Äù organized by CNR ITABC - Virtual Heritage Lab - and V-MusT Network of Excellence, in Paestum, Italy, under the general direction of BMTA1. The event, that was part of a wider European project focus on virtual museums, turned to be a great opportunity to show many different projects, applications and installations about Virtual Reality and Cultural Heritage. The four-days exhibition was an occasion to get in touch with the newest experiences with virtual reconstructions, 3D models, interactive environments, augmented reality and mobile solutions for cultural contents; at the same time, it was an opportunity for organizers to directly face the audience's impact towards projects. That because of the necessity to investigate more on social and behavioral aspects in order to positively affect the learning benefits of public. So doing, we could build in the future applications much more tailored on the final costumers, closer to their abilities and necessities. During the show four types of investigative tools were employed to evaluate the general visitor's behavior and the effectiveness of interfaces, to understand their expectations and experiences, and to obtain a reference grid of values to test if users' experience fit with organizers' ones. The first outcomes revealed that audience's impact toward interactive applications seems depending on the capability of technology to be ‚Äúinvisible‚Äù otherwise technology has to assure a wide range of possibilities in content accesses. In definitive, virtual museums need to have an always more integrated approach between cultural contents, interfaces and social and behavioral studies.",,978-1-4673-2563-9,10.1109/VSMM.2012.6365903,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365903,virtual museum;social and behavioral investigation;information interface;interaction;sensory immersion,Usability;Cultural differences;Face;Educational institutions;Europe;Interviews;User interfaces,history;interactive systems;museums;solid modelling;virtual reality,Archeovirtual 2011;virtual museums;CNR ITABC;Virtual Heritage Lab;European project;virtual reality;cultural heritage;virtual reconstructions;3D models;interactive environments;augmented reality;mobile solutions;cultural contents;reference grid;interactive applications,,14,,10,,3-Dec-12,,,IEEE,IEEE Conferences
A comprehensive case study of the impact of multicast routing protocols on mobile health care training systems,A. Zarrad; A. R. Mahlous,"Department of computer science and Information Systems Prince Sultan University Riyadh, Saudi Arabia; Department of computer science and Information Systems Prince Sultan University Riyadh, Saudi Arabia",The Third International Conference on e-Technologies and Networks for Development (ICeND2014),18-Dec-14,2014,,,70,74,"Nowadays, Health Care Training-based System (HCTS) is a vital component in the education and training of health care in 3D Virtual Environment (VE). The practice of HCTS continues to grow at rapid pace throughout all of the healthcare disciplines, however research in this field still in its early stage. Increasingly, decision makers and developer look forward to offer more sophisticated, much larger, and more complex HCTS to serve the desired outcome and improve the quality and safety of patient care. Due to the rapidly increasing usage of personal mobile devices and the need of executing HCTS applications in environments that have no previous network infrastructure available, Mobile Health Care Training-based System (MHCTS) is an expected future trend. In such systems, medical staff will share and collaborate in a 3D virtual environment through their mobile devices in an ad-hoc network (MANET) in order to accomplish specific missions' typically surgical emergency room. Users are organized into various groups (Radiologists, Maternity departments, and General surgery etc.), and need to be managed by a multicast scheme to save network bandwidth and offer immersive sense. MHCTS are sensitive to networking issues, since interactive 3D graphics requires additional load due to the use of mobile devices. Therefore, we need to emphasize on the importance and the improvement of multicast techniques for the effectiveness of MHCTS and the management of collaborative group interaction. Research so far has devoted little attention to the network communication protocols design of such systems which is crucial to preserve the sense of immersion for participating users. In this paper, we investigate the effect of multicast routing protocol in advancing the field of Health care Training-based System to the benefit of patient's safety, and health care professional. A comprehensive analysis about various ad-hoc multicast routing protocols is proposed. The selection key factors for the right protocol for MHCTS applications were safety and robustness. To the best of our knowledge, this work will be the first initiative involving systematic literature reviews to identify a research gate for the use of multicast protocol in health care simulation learning community.",,978-1-4799-3166-8,10.1109/ICeND.2014.6991355,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6991355,Ad-hoc;Multicast Protocol;Health care training system;3D Virtual Environment,Routing;Routing protocols;Medical services;Virtual environments;Peer-to-peer computing;Multicast protocols,biomedical communication;computer based training;mobile ad hoc networks;mobile computing;multicast protocols;routing protocols;virtual reality,multicast routing protocols;mobile health care training systems;MHCTS;3D virtual environment;VE;mobile ad-hoc network;MANET,,,,21,,18-Dec-14,,,IEEE,IEEE Conferences
Can Darwinian Virtual Objects Behave Well if Left Alone?,D. Harrison; E. Chng,"Sch. of Art & Design, Univ. of Wolverhampton, Wolverhampton, UK; NA",2012 International Conference on Cyberworlds,25-Oct-12,2012,,,290,295,"The artist and principal author has been creating art works in multimedia through the semantic association of ideas into concepts, as a means of exploring the efficacy of hypermedia for a conceptual art practice. This is particularly evident in the developments apparent in the ongoing 'Deconstructing Duchamp' project, where 'flocking' behaviours have been applied to Duchampian digitised items to observe the familial relations within, and key to his work, at play. Following this project, a second work 'Shift-Life' has proceeded to further develop the idea of allotting animal-like behaviours to electronic data items giving them the appearance of possessing a basic intelligence. By then observing their response to our physical interactions we can glean a clearer understanding, from their inter-relationships, of a complex conceptual framework. While Marcel Duchamp offered the art world one of the most complex and formative pieces of art ever, initiating the shift of values from aesthetics to idea, Charles Darwin developed the theory of evolution, the 'big' idea of survivability through adaptation. Shift-Life was created as part of the national Darwin 200 project for the international bicentenary in 2009. It is a complex system of virtual life-forms struggling to survive in an environment made volatile through human interaction. Central to this installation work is the artificial life ecosystem as a self-sustaining, self-reproducing equilibrium of creatures and plants living in it. The general behaviour of each organism was more sophisticated than for the Duchampian creatures in that they were equipped for survival strategies and the reproduction of progenies. An exposition of the Shift-Life program is therefore presented followed by reflection on both projects and future directions for this collaborative research where potential emergent behaviours are concerned.",,978-1-4673-2736-7,10.1109/CW.2012.49,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6337436,Duchamp;Darwin;associative media;behaviours;mixed-reality;artificial life;agent-based modelling,Art;Glass;Ecosystems;Organisms;Toxicology;Vegetation,art;multimedia computing;reliability;virtual reality,Darwinian virtual objects;multimedia;conceptual art practice;Deconstructing Duchamp project;Duchampian digitised items;familial relations;second work Shift-Life;animal-like behaviours;electronic data items;physical interactions;complex conceptual framework;formative pieces;complex pieces;survivability through adaptation;international bicentenary;complex system;virtual life-forms;human interaction;self-sustaining;artificial life ecosystem;Duchampian creatures;collaborative research;emergent behaviours,,,,9,,25-Oct-12,,,IEEE,IEEE Conferences
Communication Through Motion: Legibility of Multi-Robot Systems,B. Capelli; C. Secchi; L. Sabattini,"University of Modena and Reggio,Department of Sciences and Methods for Engineering (DISMI),Emilia,Italy; University of Modena and Reggio,Department of Sciences and Methods for Engineering (DISMI),Emilia,Italy; University of Modena and Reggio,Department of Sciences and Methods for Engineering (DISMI),Emilia,Italy",2019 International Symposium on Multi-Robot and Multi-Agent Systems (MRS),14-Nov-19,2019,,,126,132,"The interaction between a user and a multi-robot system in a shared environment is a relatively uncharted topic. But, as these types of systems will increase in the future years, an efficient way of communication is necessary. To this aim, it is interesting to discover if a multi-robot system can communicate its intentions exploiting only some motion-variables, which are characteristics of the motion of the robots. This study is about the legibility of a multi-robot system: in particular, we focus on the influence of these motion-variables on the legibility of more than one group of robots that move in a shared environment with the user. These motion-variables are: trajectory, dispersion and stiffness. They are generally used to define the motion of a group of mobile robots. Trajectory and dispersion were found relevant for the correctness of the communication between the user and the multi-robot system, while stiffness was found relevant for the rapidity of communication. The analysis of the influence of the motion-variables was carried out with an ANOVA (analysis of variance) based on a series of data coming from an experimental campaign conducted in a virtual reality set-up.",,978-1-7281-2876-4,10.1109/MRS.2019.8901100,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8901100,,Multi-robot systems;Mobile robots;Trajectory;Virtual reality;Complexity theory;Collision avoidance,control engineering computing;elasticity;mobile robots;motion control;multi-robot systems;statistical analysis;virtual reality,multirobot system;motion-variables;shared environment;mobile robots;stiffness;ANOVA;analysis of variance;virtual reality set-up,,1,,18,,14-Nov-19,,,IEEE,IEEE Conferences
On a non-web-based multimodal interactive documentary production,M. Song; S. A. Mokhov; P. Grogono; S. P. Mudur,"Concordia University, Montreal, Canada; Concordia University, Montreal, Canada; Concordia University, Montreal, Canada; Concordia University, Montreal, Canada",2014 International Conference on Virtual Systems & Multimedia (VSMM),29-Jun-15,2014,,,329,336,"The most common rendering of interactive documentary film is through the web-based medium, which is not ‚Äútangible‚Äù or as immersive as a different form could be. The earlier making of the ‚ÄúI Still Remember‚Äù documentary's memory floating bubbles interactive with audience's participation using ordinary OpenGL was the first non-web-based prototype. We describe a new HCI process and the design of an associated programmer framework for making a passive documentary interactive using currently available tools and preserving the aesthetic and emotional appeal. It is done in a local space as an artistic installation. In this context, we briefly review the proof-of-concept design and implementation of a multimodal interactive system, the Illimitable Space System (ISS). It was designed to supplement digital artists' work for various interactive scenarios and applications. Its design supports non-web-based interactive documentary creation with speech and gesture based interaction (via Kinect), music visualization and green screening for interactive dance visualization, among other things in real-time. The ISS framework provides a unified generalized architecture that supports a configurable setup of installations, as in public places described in earlier work. We also compare advantages and disadvantages of the ISS's based XNA/C# realization to that of the earlier OpenGL prototype for interactive documentary production.",,978-1-4799-7227-2,10.1109/VSMM.2014.7136675,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7136675,multimodal interaction;Kinect;interactive documentaries;XNA;OpenGL,Production;Keyboards,entertainment;human computer interaction;interactive systems;Internet;rendering (computer graphics),OpenGL prototype;unified generalized architecture;interactive dance visualization;green screening;music visualization;ISS;illimitable space system;multimodal interactive system;HCI process;nonWeb-based prototype;interactive documentary film;rendering;nonWeb-based multimodal interactive documentary production,,4,,41,,29-Jun-15,,,IEEE,IEEE Conferences
Enhanced frame rate for real-time eye tracking using circular hough transform,A. Al-Rahayfeh; M. Faezipour,"Department of Computer Science and Engineering University of Bridgeport, Bridgeport, CT 06604; Department of Computer Science and Engineering University of Bridgeport, Bridgeport, CT 06604","2013 IEEE Long Island Systems, Applications and Technology Conference (LISAT)",15-Aug-13,2013,,,1,6,"Eye-gaze detection and tracking has been widely investigated and presented as a way of unconventional human computer interaction. This area has provided convenience for many fields of practical applications, such as assistive systems and technology for people with severe disabilities, virtual reality, driver assistance and monitoring systems. Many methods for eye tracking have been introduced in literature. In this paper, a real-time eye tracking system is presented. To locate the iris of the eye in the captured video frames, the system uses the Circular Hough Transform which aims to recognize circular patterns in an image. Generally, the speed of eye motion is not as high as the used video frame rate of 30 Frames per Second (FPS) which is the frame rate used in general live video. In other words, the eye cannot move as fast as 30 motions per second. This led to proposing an enhancement to the eye tracking system being presented. This enhancement improved the CPU processing time requirements. The enhancement presented in this paper suggests that not all captured live video frames need to be processed for eye detection because the same eye movement will be captured on multiple subsequent video frames. Processing only a subset of frames will be enough to detect all eye movements in the video. The required CPU processing time is improved by selecting the minimum accepted video frame rate sufficient for accurately detecting all eye motions in a video. This was investigated for both the low and high speed eye movements. For low speed eye movements, the improvement in required CPU time was 1500%. For high speed eye movements, it was 750%. The improvement in CPU time is general and applies to different eye tracking algorithms when using the proposed enhancement. These improvements are a result of the elimination of the redundant video frames which are no longer processed in the procedure of eye detection.",,978-1-4673-6245-0,10.1109/LISAT.2013.6578214,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6578214,Eye tracking;eye motion speed;Real-time;Circular Hough Transform. frame rate,Transforms;Tracking;Real-time systems;Streaming media;Iris recognition;Human computer interaction;Image edge detection,eye;Hough transforms;human computer interaction;image enhancement;image motion analysis;iris recognition;object tracking;video signal processing,eye-gaze detection;eye-gaze tracking;human computer interaction;real-time eye tracking system;iris location;captured video frame rate;circular Hough transform;circular pattern recognition;eye motion speed;frame per second;FPS;CPU processing time requirements;eye movement;minimum accepted video frame rate selection;eye motion detection;redundant video frame elimination,,7,,16,,15-Aug-13,,,IEEE,IEEE Conferences
LazyNav: 3D ground navigation with non-critical body parts,E. Guy; P. Punpongsanon; D. Iwai; K. Sato; T. Boubekeur,"Telecom ParisTech - CNRS - Institut Mines-Telecom, France; Osaka University, Japan; Osaka University, Japan; Osaka University, Japan; Telecom ParisTech - CNRS - Institut Mines-Telecom, France",2015 IEEE Symposium on 3D User Interfaces (3DUI),25-Jun-15,2015,,,43,50,"With the growing interest in natural input devices and virtual reality, mid-air ground navigation is becoming a fundamental interaction for a large collection of application scenarios. While classical input devices (e.g., mouse/keyboard, gamepad, touchscreen) have their own ground navigation standards, natural input techniques still lack acknowledged mechanisms for travelling in a 3D scene. In particular, for most applications, navigation is not the primary interaction. Thus, the user should navigate in the scene while still being able to perform other interactions with her hands, and observe the displayed content by moving her eyes and locally rotating her head. Since most ground navigation scenarios require only two degrees of freedom to move forward or backward and rotate the view to the left or to the right, we propose LazyNav a mid-air ground navigation control model which lets the users hands, eyes or local head orientation completely free, making use of a single pair of the remaining tracked body elements to tailor the navigation. To this end, we design several navigation body motions and study their desired properties, such as being easy to discover, easy to control, socially acceptable, accurate and not tiring. We also develop several assumptions about motions design for ground navigation and evaluate them. Finally, we highlight general advices on mid-air ground navigation techniques.",,978-1-4673-6886-5,10.1109/3DUI.2015.7131725,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7131725,,Navigation;Hip;Knee;Three-dimensional displays;Tracking;Legged locomotion;Cameras,computer graphics;gesture recognition;human computer interaction,LazyNav;3D ground navigation;noncritical body parts;mid-air ground navigation control model,,22,,16,,25-Jun-15,,,IEEE,IEEE Conferences
Vernier: Accurate and Fast Acoustic Motion Tracking Using Mobile Devices,Y. Liu; J. Wang; Y. Zhang; L. Cheng; W. Wang; Z. Wang; W. Xu; Z. Li,"Michigan State University, East Lansing, MI, USA; School of Software and BNRist, Tsinghua University, Beijing, China; School of Software and BNRist, Tsinghua University, Beijing, China; School of Software and BNRist, Tsinghua University, Beijing, China; School of Software and BNRist, Tsinghua University, Beijing, China; School of Software and BNRist, Tsinghua University, Beijing, China; School of Software and BNRist, Tsinghua University, Beijing, China; City University of Hong Kong, Kowloon Tong, Hong Kong",IEEE Transactions on Mobile Computing,11-Jan-21,2021,20,2,754,764,"Acoustic motion tracking has been viewed as a promising user interaction technique in many scenarios such as Virtual Reality (VR), Smart Appliance, video gaming, etc. Existing acoustic motion tracking approaches, however, suffer from long window of accumulated signal and time-consuming signal processing. They are inherently difficult to achieve both high accuracy and low delay. In this paper, we present Vernier, an efficient and accurate acoustic tracking method based on commodity mobile devices. We design a new approach to efficiently and accurately derive phase change and thus moving distance. Vernier significantly reduces the tracking delay/overhead by removing the complicated frequency analysis and long window of signal accumulation, while keeping a high tracking accuracy. We implement Vernier on Android, and evaluate its performance with COTS mobile devices including Samsung Galaxy S7 and Sony L50t. Experimental results show that Vernier outperforms previous approaches with a tracking error less than 4 mm. The tracking speed achieves 3√ó improvement to the previous phase based approaches and 10√ó to Doppler Effect based approaches. Vernier is also validated in applications like controlling and drawing, and we believe it is generally applicable in many real applications.",1558-0660,,10.1109/TMC.2019.2945955,National Key R&D Program of China; National Natural Science Fund China for Excellent Young Scholars; NSFC key program; NSFC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861148,Acoustic signal;tracking;mobile phone,Tracking;Mobile handsets;Microsoft Windows;Acoustics;Delays;Doppler effect;Performance evaluation,acoustic signal detection;Doppler effect;mobile computing;object detection;tracking;virtual reality,Vernier;COTS mobile devices;tracking error;tracking speed;fast acoustic motion tracking;virtual reality;acoustic motion tracking approaches;time-consuming signal processing;commodity mobile devices;user interaction technique;Doppler effect based approach;Samsung Galaxy S7;Sony L50t;size 4.0 mm,,,,33,IEEE,7-Oct-19,,,IEEE,IEEE Journals
Stability of internet-based teleoperation systems using Bayesian predictions,J. Lee; S. Payandeh,"Experimental Robotics Laboratory, School of Engineering Science, Simon Fraser University, Burnaby, BC, Canada; Experimental Robotics Laboratory, School of Engineering Science, Simon Fraser University, Burnaby, BC, Canada",2011 IEEE World Haptics Conference,11-Jul-11,2011,,,499,504,"In this paper, we present a Bayesian prediction approach to improve stability of teleoperation systems over the Internet. Motion and force data flows in a teleoperation system are formulated in discrete time state-space models predicted by Bayesian filters, including the Kalman filter and particle filter. The particle filter, which is known as a robust tracking method in nonlinear and non-Gaussian environments, is used to compensate for the time-varying Internet delay. A stochastic analysis is presented to show stability improvement of a teleoperation system in the case when convergence of a Bayesian predictor is achieved and a generalized form of scattering transformation is used as a control scheme. Experiments are performed using a teleoperation system based on virtual reality. A haptic device is used as a human operator in conjunction with a mechanic-based virtual teleoperator by implementing the proposed Bayesian prediction method. Experimental results show that the proposed method improve stability of an overall teleoperation system in the presence of time-varying delay.",,978-1-4577-0298-3,10.1109/WHC.2011.5945536,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5945536,Teleoperation;haptic interface;time-varying delay;Internet;Bayesian;particle filter;Kalman filter;sequential Monte Carlo;scattering transformation,Force;Delay;Internet;Scattering;Particle filters;Bayesian methods;Stability analysis,Bayes methods;delays;discrete time filters;Gaussian processes;haptic interfaces;human-robot interaction;Internet;Kalman filters;particle filtering (numerical methods);predictive control;stability;state-space methods;telerobotics;time-varying filters;virtual reality,stability;Internet-Based teleoperation systems;Bayesian predictions;discrete time state-space models;Kalman filter;particle filter;nonGaussian environments;time-varying Internet delay;stochastic analysis;scattering transformation;virtual reality;haptic device;human operator;mechanic-based virtual teleoperator,,5,,25,,11-Jul-11,,,IEEE,IEEE Conferences
Evaluating an Immersive Space-Time Cube Geovisualization for Intuitive Trajectory Data Exploration,J. A. W. Filho; W. Stuerzlinger; L. Nedel,Federal University of Rio Grande do Sul; Simon Fraser University; Federal University of Rio Grande do Sul,IEEE Transactions on Visualization and Computer Graphics,25-Nov-19,2020,26,1,514,524,"A Space-Time Cube enables analysts to clearly observe spatio-temporal features in movement trajectory datasets in geovisualization. However, its general usability is impacted by a lack of depth cues, a reported steep learning curve, and the requirement for efficient 3D navigation. In this work, we investigate a Space-Time Cube in the Immersive Analytics domain. Based on a review of previous work and selecting an appropriate exploration metaphor, we built a prototype environment where the cube is coupled to a virtual representation of the analyst's real desk, and zooming and panning in space and time are intuitively controlled using mid-air gestures. We compared our immersive environment to a desktop-based implementation in a user study with 20 participants across 7 tasks of varying difficulty, which targeted different user interface features. To investigate how performance is affected in the presence of clutter, we explored two scenarios with different numbers of trajectories. While the quantitative performance was similar for the majority of tasks, large differences appear when we analyze the patterns of interaction and consider subjective metrics. The immersive version of the Space-Time Cube received higher usability scores, much higher user preference, and was rated to have a lower mental workload, without causing participants discomfort in 25-minute-long VR sessions.",1941-0506,,10.1109/TVCG.2019.2934415,Conselho Nacional de Desenvolvimento Cient√≠fico e Tecnol√≥gico; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854316,Space-time cube;Trajectory visualization;Immersive analytics,Task analysis;Trajectory;Three-dimensional displays;Data visualization;Clutter;Two dimensional displays;Visualization,data visualisation;human computer interaction;user interfaces;virtual reality,intuitive trajectory data exploration;spatiotemporal features;movement trajectory datasets;user interface features;immersive space-time cube geovisualization;immersive analytics domain;exploration metaphor;virtual representation,,4,,59,,1-Oct-19,,,IEEE,IEEE Journals
"Workflows and Challenges Involved in Creation of Realistic Immersive Virtual Museum, Heritage, and Tourism Experiences: A Comprehensive Reference for 3D Asset Capturing",H. Esmaeili; H. Thwaites; P. C. Woods,"Sch. of Arts, Sunway Univ., Malaysia; Sch. of Arts, Sunway Univ., Malaysia; Fac. of Creative Multimedia, Multimedia Univ., Cyberjaya, Malaysia",2017 13th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS),12-Apr-18,2017,,,465,472,"This study provides a technical review of the current state of immersive virtual museum, heritage, and tourism focusing on workflows and challenges involved in realistic asset creation. The workflow includes two parts i.e. virtualization of historic objects and creation of environment. However, in some instances the environment itself is a cultural heritage site e.g. an old castle that can be considered as historic object. Otherwise, the environment is just a conceptual virtual place (created using traditional 3D modeling methods) to mimic museum experience, embedding smaller historic objects, which are virtualized. Although tools and technologies such as photogrammetry, 3D scanning, or aerial 3D mapping have made the process of virtualization of historic/cultural objects considerably easier for basic users, challenges and limitations still remain as these automatic processes are not always accompanied by flawless outcomes. This study addresses some of those challenges and limitations faced during preparation of experimental immersive virtual museum for exhibition purposes. This covers various ranges of topics from lighting, texturing, and topology to limitations related to opacity, dark colors, and small details. This paper also provides a comprehensive overview of the technical details when it comes to preparation of virtual cultural heritage environments specifically for immersive experiences. Areas such as user interaction, navigation, space optimization, quality and viewing distance, access, purpose and objectives, degree of realism, etc. are covered in this review. The major processes illustrated in this study include photogrammetry, aerial 3D mapping, polygon modeling, 3D sculpting, 3D painting, UV Mapping, etc. The major software/tools used in this workflow include Agisoft Photoscan, Autodesk Remake, Pixologic ZBrush, xNormal, Autodesk 3ds Max, Unity, SteamVR, HTC Vive, including other relevant plugins and scripts. However, this study is not a step by step guide or a tutorial, but a reference for the currently available technologies to create immersive virtual museum, cultural heritage, and tourism aiming to distinguish the lines between different levels of processes involved. The objective is to provide a clear understanding of the challenges involved. Based on the literature review done prior to this study, a comprehensive academic reference (covering the mentioned areas) for digital heritage researchers is lacking (to date). The authors believe that due to the increasing availability and affordability of the current immersive virtual reality technologies for basic users this is a proper time for gathering major processes/challenges involved in creation of such environments and present them in form of a comprehensive reference. Although the main focus of this study is on digital heritage, the processes undertaken and explained can be generalized to be used by researchers in other fields where applicable.",,978-1-5386-4283-2,10.1109/SITIS.2017.82,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8334788,immersive virtual reality;virtual museum;cultural heritage;virtual tourism;photogrammetry;3d scan;aerial 3d mapping;3d visualization;HTC Vive;Oculus Rift;Unity,Three-dimensional displays;Solid modeling;Painting;Cultural differences;Cameras;Software;Virtualization,history;museums;photogrammetry;solid modelling;travel industry;virtual reality,realistic immersive virtual museum;tourism experiences;3d asset capturing;technical review;realistic asset creation;historic object;conceptual virtual place;traditional 3D modeling methods;museum experience;smaller historic objects;aerial 3D mapping;experimental immersive virtual museum;virtual cultural heritage environments;Autodesk 3;currently available technologies;comprehensive academic reference;digital heritage researchers;current immersive virtual reality technologies;cultural heritage site;historic-cultural objects,,3,,23,,12-Apr-18,,,IEEE,IEEE Conferences
Intent Inference of Human Hand Motion for Haptic Feedback Systems,M. Zhao; S. Dai,Beihang University; Beihang University,2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),27-Dec-19,2019,,,218,2185,"The haptic feedback system (HFS) in the virtual cockpit system (VCS) can definitely enhance the sense of immersion. Most HFSs in prior works sacrificed the native advantages of VCSs to achieve haptic interaction. This paper addresses the problem by proposing a novel framework for the HFS, which can predict the most likely interacting target of the human hand in advance. We introduce a HFS with a non-contact visual tracking sensor and a probability inference method based on Bayesian statistics, the features extracted by this HFS could be low-cost, high generality and flexibility. Simulations show that human intent inference can be computed in real-time and the results can meet the requirements of the HFM, which provides an important basis for haptic interactions in VCSs.",,978-1-7281-5604-0,10.1109/AIVR46125.2019.00046,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942346,intent inference;haptic feedback;virtual cockpit system;human computer interaction;Kalman filter,Hafnium;Haptic interfaces;Kalman filters;Bayes methods;Manipulators;Predictive models;Three-dimensional displays,aerospace computing;aircraft;Bayes methods;feature extraction;haptic interfaces;inference mechanisms,human hand motion;haptic feedback system;HFS;virtual cockpit system;VCSs;haptic interaction;noncontact visual tracking sensor;probability inference method;human intent inference;Bayesian statistics,,,,21,,27-Dec-19,,,IEEE,IEEE Conferences
Space walking [topological manifold visualization],A. J. Hanson; Hui Ma,"Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA; Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA",Proceedings Visualization '95,6-Aug-02,1995,,,126,133,"Proposes an interactive method for exploring topological spaces based on the natural local geometry of the space. Examples of spaces appropriate for this visualization approach occur in abundance in mathematical visualization, surface and volume visualization problems, and scientific applications such as general relativity. Our approach is based on using a controller to choose a direction in which to ""walk"" a manifold along a local geodesic path. The method automatically generates orientation changes that produce a maximal viewable region with each step of the walk. The proposed interaction framework has many natural properties to help the user develop a useful cognitive map of a space and is well-suited to haptic interfaces that may be incorporated into desktop virtual reality systems.",1070-2385,0-8186-7187-4,10.1109/VISUAL.1995.480804,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=480804,,Legged locomotion;Visualization;Space exploration;Haptic interfaces;Mice;Three dimensional displays;Two dimensional displays;Motion control;Computer science;Computational geometry,topology;virtual reality;interactive systems;data visualisation;path planning;computational geometry;differential geometry,topological manifold visualization;interactive method;local geometry;mathematical visualization;surface visualization;volume visualization;scientific applications;general relativity;controller;direction selection;local geodesic path;automatically generated orientation changes;maximal viewable region;interaction framework;cognitive map;haptic interfaces;desktop virtual reality systems,,6,,19,,6-Aug-02,,,IEEE,IEEE Conferences
A Sentiment Analysis Study on Recognition of Facial Expressions: Gauss and Canny Methods,A. Sevin√ß; B. Kaya; A. Ge√ßmez,"Fƒ±rat University,dept. Technology and Information Management,Elazƒ±ƒü,Turkey; Furat University,dept. Electronics and Automation,Elazig,Turkey; Firat University,dept. Electrical and Electronics Engineering,Elazig,Turkey",2020 International Conference on Decision Aid Sciences and Application (DASA),15-Jan-21,2020,,,1041,1046,"Human-computer interaction has been the focus of today's current researches. Human-computer interaction is accepted as a multidisciplinary field that takes place through interfaces. These interfaces can sometimes be software functions, or sometimes they can be interact provided with hardware components. Facial expressions give information about people's emotions play an important role in sentiment recognition. Today, facial expressions are used in many fields such as education, psychological studies, virtual reality, robotics, facial animation, health and law, and the need for analysis of facial expressions in many areas is increasing. In addition, the analysis of human facial expressions with computers is a remarkable research area, but it is considered a challenging problem. In this context, it is necessary to analyze facial expressions accurately and quickly by software. In this study, sentiment recognition from facial expressions (sad, happy, scared, confused) was performed using 50 different images obtained from various databases and internet sources. With digital image processing techniques, improved images can be obtained and feature extraction can be made. In this research, digital image processing functions and MATLAB programming language of MATLAB 2018 program, which provides advanced programming for scientific studies, were used. Image noise was removed with the Gauss filter, and edge detection operations were performed with the Canny method. Geometric ratios were used to eliminate errors. As a result of the study, it was determined that sentiment recognition procedures performed on images with similar facial expressions made incorrect sentiment classification. However, it has been observed that face recognition with MATLAB functions and MATLAB programming has generally produced successful results.",,978-1-7281-9677-0,10.1109/DASA51403.2020.9317234,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9317234,Face expression recognition;Sentiment analysis;Image processing;Gauss and Canny method,Face recognition;Sentiment analysis;Matlab;Image edge detection;Emotion recognition;Robots;Maximum likelihood detection,computer animation;edge detection;emotion recognition;face recognition;feature extraction;human computer interaction;image denoising;Matlab;sentiment analysis;virtual reality,sentiment analysis;human-computer interaction;sentiment recognition;law;human facial expressions;software functions;digital image processing;Matlab programming language;image noise;Gauss filter;edge detection;Canny method,,,,25,,15-Jan-21,,,IEEE,IEEE Conferences
Stereo imaging using a camera with stereoscopic adapter,Woontack Woo; Namgyu Kim; Y. Iwadate,"ATR MIC Labs., Kyoto, Japan; NA; NA","Smc 2000 conference proceedings. 2000 ieee international conference on systems, man and cybernetics. 'cybernetics evolving to systems, humans, organizations, and their complex interactions' (cat. no.0",6-Aug-02,2000,2,,1512,1517 vol.2,"The authors analyze the characteristics of the stereoscopic adapter, which is a cost-effective way to generate stereo video sequences with a camera. We also propose an efficient way to compensate for the inherent distortions. In general, stereo sequences can be captured using a pair of cameras but the resulting sequences tend to yield various well-known problems due to different characteristics of the pair of stereo cameras. Meanwhile, a camera with the stereoscopic adapter provides a natural way to capture and display stereoscopic video. It allows users to access all the functions built into the camera, e.g. zoom, auto-focus, auto-exposure, special effects, etc. The cost however is the reduced quality of the videos since the adapter allows capture of stereo video sequences in the field sequential format, i.e. left and right images in different scan lines, respectively. In addition, it generates size and color distortions due to the physical configuration of the mirror in the adapter. We analyze and compensate for such distortions to reduce possible errors in vision applications exploiting the stereo images. According to our preliminary study, the adapter with the proposed compensation scheme will pave the way for various low cost image based virtual reality applications at hand.",1062-922X,0-7803-6583-6,10.1109/ICSMC.2000.886069,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=886069,,Cameras;Video sequences;Three dimensional displays;Costs;Mirrors;Image analysis;Calibration;Layout;Microwave integrated circuits;Image sequence analysis,stereo image processing;video cameras;image sequences;video signal processing;virtual reality,stereo imaging;stereoscopic adapter;stereo video sequences;stereo sequences;stereo cameras;stereoscopic video;zoom;auto-focus;auto-exposure;special effects;field sequential format;scan lines;physical configuration;vision applications;compensation scheme;low cost image based virtual reality applications,,4,1,12,,6-Aug-02,,,IEEE,IEEE Conferences
K-HapticModelerTM: a haptic modeling scope and basic framework,Y. Seo; B. Lee; Y. Kim; J. Kim; J. Ryu,"Human-Machine-Computer Interface Lab, Gwangju Institute of Science and Technology, KOREA, E-mail: seoyw@gist.ac.kr; Human-Machine-Computer Interface Lab, Gwangju Institute of Science and Technology, KOREA, E-mail: bclee@gist.ac.kr; Human-Machine-Computer Interface Lab, Gwangju Institute of Science and Technology, KOREA, E-mail: kym@gist.ac.kr; Human-Machine-Computer Interface Lab, Gwangju Institute of Science and Technology, KOREA, E-mail: lowtar@gist.ac.kr; Human-Machine-Computer Interface Lab, Gwangju Institute of Science and Technology, KOREA, E-mail: ryu@gist.ac.kr","2007 IEEE International Workshop on Haptic, Audio and Visual Environments and Games",29-Oct-07,2007,,,136,141,"Haptics has been studied as a means of providing users with a natural and immersive tactile sensation in real, augmented, and virtual environments in the various areas. However, in spite of the considerable advantages offered by haptic technology, it is still relatively unfamiliar to the general public. One of reasons for this unfamiliarity is the lack of abundant haptic interaction contents, especially in areas that are very close to the general public. Even though there are a few modeling tools for creating haptic contents, addition of haptic data to graphic models or scenes is limited and many haptic modeling processes have to be done mostly manually, which is time consuming and is not intuitive. For this reason, a new, intuitive, comprehensive, and efficient haptic modeling system is needed. This paper tries to define haptic modeling processes and its scopes and proposes a basic framework for a haptic modeling system (K-HapticModelerTM) that can create and edit haptic contents easily and intuitively for any virtual objects or graphic scenes.",,978-1-4244-1570-0,10.1109/HAVE.2007.4371602,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4371602,haptics;haptic modeling;Haptic User Interface (HUI),Haptic interfaces;Layout;Solid modeling;Painting;Computer graphics;User interfaces;Material properties;Friction;Conferences;Virtual environment,haptic interfaces;virtual reality,K-haptic modeler;haptic modeling scope;immersive tactile sensation;virtual environments;abundant haptic interaction contents;graphic models;virtual objects,,2,1,17,,29-Oct-07,,,IEEE,IEEE Conferences
Exploring the use of virtual learning environments to support science learning in autistic students,J. Cecil; M. Sweet-Darter; A. Cecil-Xavier,"Computer Science, Center for Cyber Physical Systems (CCPS), Oklahoma, State University, Stillwater, USA; Applied Behavioral, Analysis-OK, Anselm Center, Edmond, USA; Stillwater High School and CCPS Soaring Eagle Research, Stillwater, Oklahoma",2017 IEEE Frontiers in Education Conference (FIE),14-Dec-17,2017,,,1,8,"Autism and Autism Spectrum Disorders (ASD) are general terms for a group of complex disorders of brain development. Autistic children exhibit certain characteristics in varying degrees including difficulties in verbal/non-verbal communication, social interaction and repetitive behaviors. This paper discusses the role of Virtual Learning Environments (VLEs) in helping autistic children learn science and engineering concepts. VLEs are a type cyber learning environments created using Virtual Reality technology; as part of a learning activities, a set of VLEs to teach autistic students concepts in related to the solar system, robotics and density has been developed; assessment results underscore the potential of such VLEs to support science and engineering learning.",,978-1-5090-5920-1,10.1109/FIE.2017.8190490,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8190490,Autism;Virtual Learning Environments;Cyber Learning,Autism;Robots;Virtual environments;Three-dimensional displays;Visualization;Haptic interfaces,brain;computer aided instruction;handicapped aids;medical disorders;teaching;virtual reality,virtual learning environments;science learning;complex disorders;brain development;autistic children;VLEs;Virtual Reality technology;learning activities;autistic students concepts;engineering learning;verbal communication;nonverbal communication,,3,,87,,14-Dec-17,,,IEEE,IEEE Conferences
Haptic Rendering of Virtual Hand Moving Objects,W. Yang; W. Chen,"Dept. of Mechanism & Autom., Zhejiang Sci-Tech Univ., Hangzhou, China; Dept. of Mechanism & Autom., Zhejiang Sci-Tech Univ., Hangzhou, China",2011 International Conference on Cyberworlds,17-Nov-11,2011,,,113,119,"The paper proposes a method of haptic rendering for virtual hand moving an object in virtual environments, which would not only improve the immersion and authenticity of the virtual reality system, but also help operators predict virtual objects' natural behavior and direct their interaction with virtual environments. By tracking the position of the grasped object, the posture change of the grasped object is detected. An algorithm is used to calculate the distribution of the external force imposed on the grasped object in arbitrary posture, and the static grasp force of the virtual hand is regenerated according to the physically-based general force model of virtual hand grasp. Based on the theories of kinematics and dynamics, the resultant force which causes the variation in motion of the grasped object can be obtained. Further, the grasp force of the virtual hand is regenerated by combining the posture change and the resultant force. The solution has been experimentally implemented using an exoskeleton force-feedback glove. A special series of experimental results show that the static grasp force rendering approach for the virtual hand moving an object is computationally efficient while retaining a well level of realism.",,978-1-4577-1453-5,10.1109/CW.2011.34,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6079354,haptic rendering;virtual hand;grasp force,Force;Thumb;Haptic interfaces;Mathematical model;Vectors;Rendering (computer graphics),data gloves;force feedback;gait analysis;interactive devices;rendering (computer graphics);virtual reality,haptic rendering;virtual hand moving object;virtual environments;virtual reality system;authenticity;virtual object natural behavior;grasped object;posture change;external force distribution;arbitrary posture;static grasp force;physically based general force model;exoskeleton force feedback glove;static grasp force rendering approach,,1,,22,,17-Nov-11,,,IEEE,IEEE Conferences
Vernier: Accurate and Fast Acoustic Motion Tracking Using Mobile Devices,Y. Zhang; J. Wang; W. Wang; Z. Wang; Y. Liu,"School of Software and TNList, Tsinghua University, China; School of Software and TNList, Tsinghua University, China; School of Software and TNList, Tsinghua University, China; School of Software and TNList, Tsinghua University, China; School of Software and TNList, Tsinghua University, China",IEEE INFOCOM 2018 - IEEE Conference on Computer Communications,11-Oct-18,2018,,,1709,1717,"Acoustic motion tracking has been viewed as a promising user interaction technique in many scenarios such as Virtual Reality (VR), Smart Appliance, video gaming, etc. Existing acoustic motion tracking approaches, however, suffer from long window of accumulated signal and time-consuming signal processing. Consequently, they are inherently difficult to achieve both high accuracy and low delay. We propose Vernier, an efficient and accurate acoustic tracking method on commodity mobile devices. In the heart of Vernier lies a novel method to efficiently and accurately derive phase change and thus moving distance. Vernier significantly reduces the tracking delay/overhead by removing the complicated frequency analysis and long window of signal accumulation, while keeping a high tracking accuracy. We implement Vernier on Android, and evaluate its performance on COTS mobile devices including Samsung Galaxy S7 and Sony L50t. Evaluation results show that Vernier outperforms previous approaches with a tracking error less than 4 mm. The tracking speed achieves 3√óimprovement to existing phase based approaches and 10√óto Doppler Effect based approaches. Vernier is also validated in applications like controlling and drawing, and we believe it is generally applicable in many real applications.",,978-1-5386-4128-6,10.1109/INFOCOM.2018.8486365,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8486365,,Mobile handsets;Tracking;Acoustics;Microsoft Windows;Delays;Doppler effect;Frequency modulation,acoustic signal detection;Doppler effect;mobile computing;user interfaces;virtual reality,Vernier;acoustic motion tracking approaches;time-consuming signal processing;commodity mobile devices;signal accumulation;high tracking accuracy;COTS mobile devices;tracking error;tracking speed;phase based approaches,,7,,25,,11-Oct-18,,,IEEE,IEEE Conferences
Oversketching and associated audio-based feedback channels for a virtual sketching application,A. Csapo; J. H. Israel; O. Belaifa,"3D Internet based Control and Communications Laboratory, Budapest Univ. of Technology and Economics, Hungary; Virtual Product Creation Division, Fraunhofer IPK, Berlin, Germany; Virtual Product Creation Division, Fraunhofer IPK, Berlin, Germany",2013 IEEE 4th International Conference on Cognitive Infocommunications (CogInfoCom),23-Jan-14,2013,,,509,514,"With the growing relevance of human interaction with infocommunications in general and augmented/virtual environments in particular, it is becoming increasingly important to provide users with a ‚Äúvirtual physics‚Äù capable of emulating the richness and subtle informativeness of multimodal feedback in the physical world. In this paper, we describe an extension to an existing immersive virtual sketching application which consists of an oversketching interaction mode, and a set of associated audio-based feedback signals. The implemented oversketching functionality allows users make incremental corrections to the drawing, helping them to emphasize certain aspects while deemphasizing others. The audio-based feedback signals, in turn, support a better understanding of the progress of oversketching, when the goal is to transition from curved to straight line segments, or vice versa.",,978-1-4799-1546-0,10.1109/CogInfoCom.2013.6719300,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719300,,Visualization;Semantics;Three-dimensional displays;Virtual environments;Shape;Conferences,problem solving;virtual reality,audio-based feedback channels;multimodal feedback;immersive virtual sketching application;oversketching interaction mode;oversketching functionality;straight line segments;curved line segments;problem solving,,7,,22,,23-Jan-14,,,IEEE,IEEE Conferences
A Software Platform for Governmental Virtual Institutions,C. J. A. d. Araujo; F. S. C. d. Corr√™a da Silva,"Lab. of Interactivity & Digital Entertainment Technol., Univ. of Sao Paulo, Sao Paulo, Brazil; Lab. of Interactivity & Digital Entertainment Technol., Univ. of Sao Paulo, Sao Paulo, Brazil",2011 Fourth International Conference on Ubi-Media Computing,18-Aug-11,2011,,,180,185,"Virtual Worlds constitute a highly popular media for general purpose social interaction, as well as for purpose oriented task execution and we believe that the adoption of this media is suitable for Electronic Government applications. It can increase the capillarity of public services, facilitate the access to (and execution of) government services and provide citizens with a natural and immersive experience. In the present work we present a Government Virtual Institution Model (GVI) for the provision of public services, that satisfies relevant issues such as: adaptability to different citizens education level, adaptability to heterogeneous government systems, alignment with government services requirements related to security, privacy, reliability and scalability, and government interoperability requirements. The government services and the information flow across the Government Virtual Institution are formally described using JamSession language. Also, the model of the GVI is described using the JamSession language and uses an architecture based on e-Ping, to deal with the conections to the governamental systems, and Embodied Conversational Agent (ECA) systems to interact with citizens.",,978-1-4577-1174-9,10.1109/U-MEDIA.2011.53,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5992067,Electronic Government;Virtual Worlds;Artificial Intelligence;Intelligent User Interfaces;Interoperability;Information Representation,Protocols;Knowledge based systems;Electronic government;Adaptation models;Security,open systems;public administration;software agents;user interfaces;virtual reality,governmental virtual institution;general purpose social interaction;purpose oriented task execution;electronic government services;public services;citizen education level;heterogeneous government system;government interoperability requirement;information flow;e-Ping;embodied conversational agent systems,,,,17,,18-Aug-11,,,IEEE,IEEE Conferences
Flexible Indoor Scene Synthesis via a Multi-object Particle Swarm Intelligence Optimization Algorithm and User Intentions,Y. Li; X. Wang; Z. Wu; S. Liu; M. Zhou,Beijing Normal University; Beijing Normal University; Beijing Normal University; Beijing Normal University; Beijing Normal University,2019 International Conference on Cyberworlds (CW),5-Dec-19,2019,,,29,36,"Flexible indoor scene synthesis is a popular topic in computer graphics and virtual reality research due to its wide-ranging applications in home design, games and automated robotics training. We propose a novel approach to automatic and flexible indoor scene synthesis using an energy-based method. We regard indoor scene synthesis as a multiple-object optimization problem with furniture location and orientation according to the user's intention, as a constraint on the energy of the optimization problem. Based on the relationship of objects, the embedded aesthetic criterion, the design criterion for proper placement and human movement in a scene, we design five energy functions, the overlap constraint, pairwise constraint, wall constraint, aisle constraint, angle constraint and penalty item, are proposed. We use a multi-object particle swarm intelligence optimization method with a Markov chain Monte Carlo algorithm to solve this optimization problem and obtain a Pareto-optimal solution. 3D gestures are used as the medium of interaction between the user and the system. Our method significantly enhances the existing weighted energy optimization method by allowing a joint optimization of various energy functions. The experiments confirm that all the energy functions can converge at the same time and that the proposed method obtains results superior to those of the weighted methods. The proposed method is general which can be used to obtain layouts for various kind of rooms with different furniture.",2642-3596,978-1-7281-2297-7,10.1109/CW.2019.00014,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918966,"Indoor scene synthesis, Automatic layout, Multiobject particle swarm intelligence, Pareto optimal, 3D gesture",Layout;Three-dimensional displays;Optimization;Particle swarm optimization;Solid modeling;Task analysis;Databases,furniture;Markov processes;Monte Carlo methods;Pareto optimisation;particle swarm optimisation;virtual reality,flexible indoor scene synthesis;multiobject particle swarm intelligence optimization algorithm;energy-based method;multiple-object optimization problem;energy functions;multiobject particle swarm intelligence optimization method;Pareto-optimal solution;weighted energy optimization method;user intentions;computer graphics;virtual reality;overlap constraint;pairwise constraint;wall constraint;aisle constraint;angle constraint;penalty item;Markov chain Monte Carlo algorithm;3D gestures;furniture location,,,,29,,5-Dec-19,,,IEEE,IEEE Conferences
Early Results of a Usability Evaluation of Two Digital Human Model -based Ergonomic Software Applying Eye-Tracking Methodology Comparison of the usability of ViveLab and Jack software,M. Babicsn√©-Horv√°th; K. Hercegfi,"Budapest University of Technology and Economics,Department of Ergonomics and Psychology,Budapest,Hungary; Budapest University of Technology and Economics,Department of Ergonomics and Psychology,Budapest,Hungary",2019 10th IEEE International Conference on Cognitive Infocommunications (CogInfoCom),11-May-20,2019,,,205,210,"Analysis software for ergonomics are more and more wide spread among researchers. There are various software for ergonomics available on the market, and it would be important to know which one to choose in various research tasks. Although data on the capabilities of the software can be found relatively easily, a comparison regarding their ease of use and the quality of their user interface cannot be found in the literature. In this article, the usability of two software were compared. A cloud based Hungarian software, ViveLab and the well-known Jack software was chosen. In addition to the traditional software usability testing technique based on screen and event recording and user camera, eye-tracking methodology was also applied. The goal of this research is to find out which software is more usable in different situations. The results were divisive and in some cases astonishing. We are not able to give a definite answer which software is easier to use. There were several cases when ViveLab was easier and almost as much cases when Jack. There are areas for improvement in both software. Our results can help researchers to choose software for their specific tasks. Furthermore, the results can give additional information on which user interface elements and concepts are worth to improve by developers of the ergonomic software, and, in some cases, may inspire developers of other 3D-based software in general.",2380-7350,978-1-7281-4793-2,10.1109/CogInfoCom47531.2019.9089993,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9089993,Usability testing;Eye-tracking;Human Factors and Ergonomics (HFE);Digital Human Model;Computer Aided Anthropometric Design (CAAD);Software for ergonomic risk assessment;ViveLab;Jack,Usability;Ergonomics;Task analysis;Solid modeling;Lifting equipment;Risk management,ergonomics;gaze tracking;human computer interaction;tracking;user interfaces,event recording;user camera;ViveLab;user interface elements;usability evaluation;digital human model;Jack software;analysis software;ergonomics;research tasks;Hungarian software;traditional software usability;eye-tracking methodology comparison;ergonomic software,,,,31,,11-May-20,,,IEEE,IEEE Conferences
"Virtual journey through the history of Fort Saint Jean, Marseille (VJ-FSJ Project) : Case Study: New Media exhibit at the Mus√©e des civilisations de L‚ÄôEurope et de la M√©diterran√©e (MuCEM)",F. Fischnaller,"Accademia Albertina di Belle Arti di Torino, Italy",2018 3rd Digital Heritage International Congress (DigitalHERITAGE) held jointly with 2018 24th International Conference on Virtual Systems & Multimedia (VSMM 2018),26-Aug-19,2018,,,1,8,"This paper presents insights about the design of a permanent digital heritage exhibit, Virtual Journey through the history of Fort Saint Jean (VJ-FSJ), based in the fort of the same name, a prominent historical and architectural site in Marseille, France. The VJ-FSJ project is a multi-disciplinary technology-based exhibit, combining mixed media display systems, holographic imaging, video mapping on 3D printed models, augmented audio-visual environments, and digital heritage narrative and storytelling embedded within physical and virtual architecture. The exhibit opened in 2018 at the Mus√©e des Civilisations de L'Europe et de la M√©diterran√©e (MuCEM) in Marseille. The design is one of the outcomes of an ongoing interdisciplinary research project entitled: New generation interaction in cultural heritage: immersive exhibitions within the field of art and architecture in museums (NGI-CH research). The paper begins by presenting a general overview of the research, project background, goals, aims, historical framework, and heritage context, and then moves on to address outcomes: case study (exhibit design), methodologies, technologies and design solutions, and closes with conclusions and lessons learned.",,978-1-7281-0292-4,10.1109/DigitalHeritage.2018.8810134,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8810134,DH Museum exhibitions;cultural heritage;digital narrative and storytelling for education in museums;3D printing;rapid prototyping and reproduction;video mapping;holographic techniques;mixed media installation;cross-disciplinary research and design practice,Cultural differences;Media;History;Three-dimensional displays;Solid modeling;Display systems;Art,exhibitions;history;museums;virtual reality,Fort Saint Jean;Marseille;VJ-FSJ project;MuCEM;permanent digital heritage exhibit;architectural site;multidisciplinary technology-based exhibit;mixed media display systems;3D printed models;augmented audio-visual environments;digital heritage narrative;storytelling;physical architecture;virtual architecture;cultural heritage;immersive exhibitions;exhibit design;historical site;virtual journey;New Media exhibit;Mus√©e des civilisations de L'Europe et de la M√©diterran√©e;holographic imaging;video mapping,,,,26,,26-Aug-19,,,IEEE,IEEE Conferences
Airborne navigation with onboard InfraRed Sensors,G. Colombi; A. Ondini; L. Fortunato; G. Balzarotti,"Skyward IPT - Selex Galileo, Viale Europa snc 20014 Nerviano (MI) - Italy; Skyward IPT - Selex Galileo, Viale Europa snc 20014 Nerviano (MI) - Italy; Skyward IPT - Selex Galileo, Viale Europa snc 20014 Nerviano (MI) - Italy; Skyward IPT - Selex Galileo, Viale Europa snc 20014 Nerviano (MI) - Italy",2012 13th International Workshop on Cellular Nanoscale Networks and their Applications,18-Oct-12,2012,,,1,6,"Infrared Sensors are widely used nowadays on Aircrafts (rotary and fixed wing) to help pilot's activities. The infrared information of the surrounding area are used mainly for two different purposes: Navigation and Search & Track-While-Scan. Navigation functions, commonly identified with the name of Imaging Modes, are devoted to aid pilots in conjunction with advanced human machine interfaces such as Head Up Display (HUD) and Helmet Mounted Display (HMD). The availability of IR images generated from airborne opto-electronics equipment can support the pilot during navigation in adverse weather conditions, providing important information about external threats (i.e. obstacles), otherwise not detectable by human eye. Search & Track-While-Scan, is a functionality related to surveillance. It includes combination of automatic detection and tracking functions within a wide search volume. These features are typically executed in automatic way and generate the position of possible threats present in the flight path. In general Search & Track-While-Scan outputs are not displayed together with the IR image because the main purpose is to provide the estimated positions of the detected targets; nevertheless, if the Imaging Modes and Tracking capabilities are operated simultaneously in an integrated framework, the overall scenario representation can be improved and the situation awareness increased. This paper will focus on the airborne navigation by means of Infrared Sensors by considering the benefits but also possible limits and areas of improvements.",2165-0152,978-1-4673-0289-0,10.1109/CNNA.2012.6331477,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6331477,,Sensors;Head;Humans;Image sensors;Navigation;Visualization;Magnetic heads,aircraft displays;aircraft navigation;human computer interaction;infrared imaging;object detection;optoelectronic devices;target tracking,airborne navigation;onboard infrared sensors;infrared information;navigation functions;imaging modes;human machine interfaces;IR images;airborne optoelectronics equipment;aircraft pilot;adverse weather conditions;external threats;search & track-while-scan;automatic detection;automatic tracking;threat position generation;flight path;target detection,,2,,7,,18-Oct-12,,,IEEE,IEEE Conferences
Design of a vibrotactile display via a rigid surface,Y. Visell; J. R. Cooperstock,"McGill University, Centre for Intelligent Machines and CIRMMT, Montreal, Canada; McGill University, Centre for Intelligent Machines and CIRMMT, Montreal, Canada",2010 IEEE Haptics Symposium,8-Apr-10,2010,,,133,140,"This paper describes the analysis, optimized redesign and evaluation of a high fidelity vibrotactile interface integrated in a rigid surface. The main application of the embodiment described here is vibrotactile display of virtual ground surface material properties for immersive environments, although the design principles are general. The device consists of a light, composite plate mounted on an elastic suspension, with integrated force sensors. It is actuated by a single voice coil motor. The structural dynamics of the device were optimized, within constraints imposed by the requirements of user interaction, and corrected via digital inverse filtering, in order to enable accurate simulation of virtual ground materials. Measurements of the resulting display demonstrate that it is capable of accurately reproducing forces of more than 40 N across a usable frequency band from 50 Hz to 750 Hz.",2324-7355,978-1-4244-6822-5,10.1109/HAPTIC.2010.5444664,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444664,Vibrotactile display design;Vibrotactile rendering;Foot interfaces,Displays;Frequency;Haptic interfaces;Force measurement;Foot;Humans;Rendering (computer graphics);Actuators;Biological system modeling;Vehicle dynamics,display devices;force sensors;haptic interfaces,vibrotactile display;rigid surface;vibrotactile interface;virtual ground surface material property;immersive environment;design principle;light composite plate;elastic suspension;force sensor;voice coil motor;structural dynamics;user interaction;digital inverse filtering;frequency 50 Hz to 750 Hz,,14,1,41,,8-Apr-10,,,IEEE,IEEE Conferences
A comparative study of local feature extraction for age estimation,S. E. Choi; Y. J. Lee; S. J. Lee; K. R. Park; J. Kim,"School of Electrical and Electronic Engineering, Yonsei University, Biometrics Engineering Research Center; School of Electrical and Electronic Engineering, Yonsei University, Biometrics Engineering Research Center; School of Electrical and Electronic Engineering, Yonsei University, Biometrics Engineering Research Center; Division of Electronics and Electrical Engineering, Dongguk University, Biometrics Engineering Research Center; School of Electrical and Electronic Engineering, Yonsei University, Biometrics Engineering Research Center",2010 11th International Conference on Control Automation Robotics & Vision,4-Feb-11,2010,,,1280,1284,"Many age estimation methods have been proposed for various applications such as Age Specific Human Computer Interaction (ASHCI) system, age simulation system and so on. Because the performance of the age estimation is greatly affected by the aging feature, the aging feature extraction from facial images is very important. The aging features used in previous works can be divided into global and local features. As global features, Active Appearance Models (AAM) was mainly used for age estimation in previous works. However, AAM is not enough to represent local features such as wrinkle and skin. Therefore, the research about local features is required. In previous works, local features were generally used to determine age group rather than detailed age, and the comparative studies about various local features extraction methods were not conducted. In this paper, the performances of sobel filter, difference image between original and smoothed image, ideal high pass filter (IHPF), gaussian high pass filter (GHPF), Haar and Daubechies discrete wavelet transform (DWT) are compared for extracting local features and detailed age estimation is performed by Support Vector Regression (SVR) on BERC and PAL aging database. The experimental results show that local features can be used for detailed age estimation and GHPF gives a better performance than other methods.",,978-1-4244-7815-6,10.1109/ICARCV.2010.5707432,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5707432,age estimation;active appearance models;sobel filter;high pass filter;discrete wavelet transform;support vector regression,Feature extraction;Estimation;Aging;Databases;Skin;Discrete wavelet transforms;Active appearance model,discrete wavelet transforms;face recognition;feature extraction;Gaussian processes;Haar transforms;high-pass filters;human computer interaction;regression analysis;support vector machines,feature extraction;age specific human computer interaction;facial image;active appearance model;sobel filter;ideal high pass filter;gaussian high pass filter;Haar transform;Daubechies discrete wavelet transform;support vector regression;aging database;age estimation,,10,,18,,4-Feb-11,,,IEEE,IEEE Conferences
Game Prototype for Understanding Safety Issues of Life Boat Launching Process,M. Jiang; J. Chang; M. Dodwell; J. Jekins; H. J. Yang; J. J. Zhang,"Nat. Centre for Comput. Animation, Bournemouth Univ., Bournemouth, UK; Nat. Centre for Comput. Animation, Bournemouth Univ., Bournemouth, UK; Nat. Centre for Comput. Animation, Bournemouth Univ., Bournemouth, UK; R. Nat. Lifeboat Instn., Poole, UK; Northwest A&F Univ., Xianyang, China; Nat. Centre for Comput. Animation, Bournemouth Univ., Bournemouth, UK",2016 8th International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES),18-Oct-16,2016,,,1,8,"Novel advanced game techniques provide us with new possibilities to mimic a complicated training process, with the benefit of safety enhancement. In this paper, we design and implement a 3D game which imitates the lifeboat launching process. Lifeboat launching is such a complex but vital process which can on one side saving people's life on sea and on the other side associating many potential hazards. It involves both the tractor manoeuvres and boat operations. The primary objective of the game is to allow novices to better understand the sequence of the operations in launching process and manager the potential hazards happening during the launching. There is also great educational significance with the promotion of the game to the general public for enhanced awareness of safety issues. The key modules of the game are designed based on physical simulation which gives the players enhanced plausible cognition and enjoyable interaction.",,978-1-5090-2722-4,10.1109/VS-GAMES.2016.7590351,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590351,,Games;Training;Agricultural machinery;Hazards;Boats;Solid modeling,boats;computer based training;computer games;digital simulation;hazards;marine safety,complicated training process;enhanced plausible cognition;physical simulation;boat operations;tractor manoeuvres;lifeboat launching hazards;3D game;life boat launching process safety issues,,,,29,,18-Oct-16,,,IEEE,IEEE Conferences
Semantics-based software techniques for maintainable multimodal input processing in real-time interactive systems,M. Fischbach; D. Wiebusch; M. E. Latoschik,University of Wurzburg; University of Wurzburg; University of Wurzburg,2016 IEEE 9th Workshop on Software Engineering and Architectures for Realtime Interactive Systems (SEARIS),29-Aug-16,2016,,,1,6,"Maintainability, i.e. reusability, modifiability, and modularity, is a critical non-functional quality requirement, especially for software frameworks. Its fulfilment is already challenging for low-interactive application areas. It is additionally complicated by complex system designs of Real-time Interactive Systems (RISs), required for Augmented, Mixed, and Virtual Reality, as well as computer games. If such systems incorporate AI methods, as required for the implementation of multimodal interfaces or smart environments, it is even further exacerbated. Existing approaches strive to establish software technical solutions to support the close temporal and semantic coupling required for multimodal processing and at the same time preserve a general decoupling principle between involved software modules. We present two key solutions that target the semantic coupling issue: (1) a semantics-based access scheme to principal elements of the application state and (2) the specification of effects by means of semantic function descriptions for multimodal processing. Both concepts are modeled in an OWL ontology. The applicability of our concepts is showcased by a prototypical implementation and explained by an interaction example that is applied for two application areas.",2328-7829,978-1-5090-4275-3,10.1109/SEARIS.2016.7551582,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7551582,D.2.11 [Software Engineering]: Software Architectures‚Äî;H.5.2 [Interfaces and Presentation]: User Interfaces,Semantics;Couplings;Green products;Software;OWL;Ontologies;Interactive systems,interactive systems;knowledge representation languages;ontologies (artificial intelligence);software quality;software reusability,semantics-based software techniques;maintainable multimodal input processing;real-time interactive systems;RISs;software reusability;software modifiability;software modularity;nonfunctional software quality requirement;AI methods;multimodal interfaces;temporal coupling;semantic coupling;semantics-based access scheme;semantic function descriptions;OWL ontology,,2,,29,,29-Aug-16,,,IEEE,IEEE Conferences
Message from the ISMAR 2018 General Chairs,,,2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),29-Apr-19,2018,,,xviii,xviii,The following topics are dealt with: augmented reality; virtual reality; helmet mounted displays; human computer interaction; image colour analysis; cameras; mobile computing; rendering (computer graphics); user interfaces; gesture recognition.,,978-1-5386-7592-2,10.1109/ISMAR-Adjunct.2018.00005,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699252,,,augmented reality;helmet mounted displays;human computer interaction;image colour analysis;virtual reality,augmented reality;virtual reality;helmet mounted displays;human computer interaction;image colour analysis;cameras;mobile computing;rendering (computer graphics);user interfaces;gesture recognition,,,,,,29-Apr-19,,,IEEE,IEEE Conferences
Mobile Augmented Reality in Nursing Educational Environments,E. Quqandi; M. Joy; M. Rushton; I. Drumm,"Computer Science Department, Warwick University, Coventry, UK; Computer Science Department, Warwick University, Coventry, UK; School of Health and Society, The University of Salford, Manchester, UK; Computer, Science and Engineer, The University of Salford, Manchester, UK",2018 10th Computer Science and Electronic Engineering (CEEC),28-Mar-19,2018,,,266,269,"The possibility of using Augmented Reality (AR) in learning and training has become more straightforward than before, as a result of the extensive use of Information and Communication Technologies (ICT) in the computer and mobile industries. Even though AR is used in education, and it is generally acknowledged that it has a positive impact on learning outcomes, the value of integrating AR applications into learning environments has not yet been fully investigated [1]. This in progress work considers the integration of AR technology into nursing clinical lab training, introduces new ways of interacting with manikins, and allows students to view patient scenarios instead of relying on teacher explanations. AR allows students to visualize hidden objects such as internal organs, which makes simulations more realistic and immersive. The study investigates the potential of this technology in terms of enhancing nursing students' self-regulation skills.",,978-1-5386-7275-4,10.1109/CEEC.2018.8674182,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8674182,Augmented Reality;Mobile Learning;Nursing;Higher Education;Self-learning;Self-Regulation;Clinical skills,Medical services;Education;Augmented reality;Three-dimensional displays;Solid modeling;Videos;Task analysis,augmented reality;biomedical education;computer aided instruction;medical computing;mobile computing;patient care,learning environments;AR technology;clinical lab training;patient scenarios;nursing educational environments;ICT;mobile augmented reality;information and communication technologies;hidden objects visualization;nursing students self-regulation skills;manikins,,,,17,,28-Mar-19,,,IEEE,IEEE Conferences
Research and Realization of Computer Network Complex Practical Teaching Platform of Virtual Reality,Z. Jie; Z. Jianwei; D. Yaxing,"Comput. Sci. & Commun. Eng. Dept., ZhengZhou Univ. of Light Ind., ZhengZhou, China; Comput. Sci. & Commun. Eng. Dept., ZhengZhou Univ. of Light Ind., ZhengZhou, China; Comput. Sci. & Commun. Eng. Dept., ZhengZhou Univ. of Light Ind., ZhengZhou, China",2012 International Conference on Computer Science and Electronics Engineering,23-Apr-12,2012,1,,383,387,"Analyzing teaching status of computer network practical courses in colleges and universities, the paper proposes the design program and the specific implementation method of complex practical teaching platform of virtual reality computer network, and builds a general practical teaching environment of computer network, which can combine reality with virtual, break the constrains of time and space, improve the utilization of laboratory equipment fully and train engineering application skills of students.",,978-0-7695-4647-6,10.1109/ICCSEE.2012.316,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188073,network remote control;computer network;virtual reality;Lab,Laboratories;Computer networks;Instruments;Educational institutions;Virtual reality;Computers,computer based training;computer networks;computer science education;educational courses;educational institutions;teaching;virtual reality,computer network complex practical teaching platform;virtual reality;computer network practical course;colleges;universities;laboratory equipment utilization;engineering application skill training,,,,12,,23-Apr-12,,,IEEE,IEEE Conferences
Organ Texture Synthesis for Virtual Reality-Based Surgical Simulators,L. Xue-mei; H. Ai-min; Z. Qin-ping,"State Key Lab. of Virtual Reality Technol. & Syst., Beihang Univ., Beijing, China; State Key Lab. of Virtual Reality Technol. & Syst., Beihang Univ., Beijing, China; State Key Lab. of Virtual Reality Technol. & Syst., Beihang Univ., Beijing, China",2009 Second International Workshop on Computer Science and Engineering,2-Feb-10,2009,1,,238,241,"Virtual Reality-based simulators is an important tool for surgical skills training and assessment. In general, the degree of realism experienced by the trainees is determined by the visual and biomechanical fidelity of the simulator. Organ textures can greatly affect visual realism and hence the overall quality of the simulation. In this paper, we use a very simple algorithm that can efficiently synthesize a wide variety of organ textures. The algorithm uses pixel-based texture synthesize technology. For each pixel in the output image, an L-shaped neighborhood of current pixel of a specific size is considered. Each pixel from this neighborhood generates a ¬øshifted¬ø candidate pixel according to its original position in the input texture. The best pixel is chosen with a neighborhood most similar to the current L-shaped neighborhood in the output image. This method is fast and its implementation is straightforward. The experiment results show the algorithm is feasility and validity.",,978-0-7695-3881-5,10.1109/WCSE.2009.661,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5403478,Organ Texture;Texture Synthesis;Surgical Simulators,Surgery;Virtual reality;Pixel;Layout;Power engineering and energy;Computational modeling;Computer simulation;Painting;Biomedical imaging;Surface texture,computer based training;image texture;medical computing;surgery;virtual reality,organ texture synthesis;virtual reality based surgical simulators;surgical skills training;surgical skills assessment;biomechanical fidelity;pixel based texture synthesize technology;L-shaped neighborhood,,,,6,,2-Feb-10,,,IEEE,IEEE Conferences
A multi-body mass-spring model for virtual reality training simulators based on a robotic guide wire operating system,S. Mi; Z. Hou; F. Yang; X. Xie; G. Bian,"State Key Laboratory of Management and Control for Complex Systems the Institute of Automation, Chinese Academy of Science Beijing 100190, China; State Key Laboratory of Management and Control for Complex Systems the Institute of Automation, Chinese Academy of Science Beijing 100190, China; State Key Laboratory of Management and Control for Complex Systems the Institute of Automation, Chinese Academy of Science Beijing 100190, China; State Key Laboratory of Management and Control for Complex Systems the Institute of Automation, Chinese Academy of Science Beijing 100190, China; State Key Laboratory of Management and Control for Complex Systems the Institute of Automation, Chinese Academy of Science Beijing 100190, China",2013 IEEE International Conference on Robotics and Biomimetics (ROBIO),17-Mar-14,2013,,,2031,2036,"Generally, surgeons of minimally invasive surgery should possess good ability to coordinate their both hands. The manipulation of guide wire is considered a core skill. Obtaining that core skill to perform minimally invasive surgery requires training. In minimally invasive surgery, a surgical robot can assist doctors to position precisely and provide stable operation platform. Therefore, to develop a virtual reality simulators for training purpose based on a robotic guide wire operating system is an important and challenging subject. In this paper, a multi-body mass-spring model for simulating guide wire is presented and evaluated. In order to overcome the disadvantage of using mass-spring approach to model the guide wire, we propose a new collision detection algorithm and a new collision response algorithm. Finally, we test our guide wire with a complex and realistic 3D vascular model, which is selected from computer tomography database of real patients. The result shows that the virtual reality training simulators is effective and promising.",,978-1-4799-2744-9,10.1109/ROBIO.2013.6739768,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6739768,,Wires;Solid modeling;Force;Computational modeling;Training;Robots;Virtual reality,computer based training;computerised tomography;control engineering computing;database management systems;digital simulation;medical computing;medical robotics;operating systems (computers);springs (mechanical);surgery;virtual reality,multibody mass-spring model;virtual reality training simulators;robotic guide wire operating system;minimally invasive surgery;guide wire manipulation;surgical robot;collision detection algorithm;collision response algorithm;3D vascular model;computer tomography database,,10,,17,,17-Mar-14,,,IEEE,IEEE Conferences
VR Technology in English Teaching from the Perspective of Knowledge Visualization,Y. Zhou,"School of Foreign Languages, Xiangnan University, Chenzhou 423000, Hunan, China. (e-mail: zhouyanfang1818@163.com)",IEEE Access,,2020,PP,99,1,1,"VR technology is virtual reality. Most people think that speaking English is the most important language skill, but at the same time speaking English is considered to be the most difficult learning skill. Virtual reality technology, namely VR technology, is a comprehensive information technology, which provides new ideas for English teaching. The purpose of this article is to study the application of VR technology in English teaching. Using the teaching simulation method, we discussed the feasibility of using VR technology to solve the problems of poor oral English, poor English expression ability, and lack of English thinking ability. The analysis technology performs a series of data analysis on the results of the survey data analysis. The analysis of the research results shows that the application of VR video in the educational teaching process not only enriches the teaching form, but also provides a new way of thinking for the teaching and experience of the course. The application of VR technology in actual English teaching not only improve the learner‚Äôs learning effect by 45%, and also enhance the modernity and modernization of English teaching activities, effectively achieve the cultivation of students‚Äô comprehensive English quality.",2169-3536,,10.1109/ACCESS.2020.3022093,Teaching reform research project of general universityPractical Research on the Cultivation of Teaching Ability of English Normal University Students in the Information Age; Key research projects of Education Department of Hunan ProvinceResearch on the Cultivation Path of Excellent English Normal University Students in Local Universities under the Times of New Liberal Arts.; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187244,VR Technology;Teaching Program;Experimental Investigation;VR Application,Education;Virtual reality;Solid modeling;Computational modeling;Cultural differences;Global communication;Hardware,,,,,,,CCBY,7-Sep-20,,,IEEE,IEEE Early Access Articles
Effect of Proprioception Training of patient with Hemiplegia by Manipulating Visual Feedback using Virtual Reality: The Preliminary results,S. Cho; K. Han; H. Lee; J. Park; I. Y. Kim; S. I. Kim; J. Ku; Y. J. Kang,"Department of Biomedical Engineering, Hanyang University, Korea; Department of Biomedical Engineering, Hanyang University, Korea; Department of Biomedical Engineering, Hanyang University, Korea; Department of Biomedical Engineering, Hanyang University, Korea; Department of Biomedical Engineering, Hanyang University, Korea; Department of Biomedical Engineering, Hanyang University, Korea; Department of Biomedical Engineering, Hanyang University, Korea Dept. of Biomedical Engineering, Hanyang University, Sungdong P. O. Box 55, Seoul, KOREA 133-605, kujh@bme.hanyang.ac.kr; Department of Rehabilitation medicine, Eulji University School of Medicine, Eulji General Hospital",2009 IEEE Virtual Reality Conference,7-Apr-09,2009,,,283,284,"In this study, we confirmed proprioception training effect of patients with hemiplegia by manipulating visual feedback. Six patients with hemiplegia were participated in the experiment. Patients have trained with the reaching task with visual feedback without visual feedback for two weeks. Patients were evaluated with pre-, middle test and post-test with the task with and without visual feedback. In the results, the first-click error distance after the training of the reaching task was reduced when they got the training with the task removed visual feedback. In addition, the performance velocity profile of reaching movement formed an inverse U shape after the training. In conclusion, visual feedback manipulation using virtual reality could provide a tool for training reaching movement by enforcing to use their proprioception, which enhances reaching movement skills for patients with hemiplegia.",2375-5334,978-1-4244-3943-0,10.1109/VR.2009.4811056,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811056,Virtual Reality;Proprioception;Visual Feedback;J.3 [Computer applications]: LIFE AND MEDICAL SCIENCES¬øHealth,Virtual reality;Force feedback;Biomedical engineering;Muscles;Engine cylinders;Sun;Hospitals;Testing;Shape;Computer applications,patient treatment;virtual reality;visual perception,patient proprioception training;hemiplegia;virtual reality;visual feedback manipulation,,,,6,,7-Apr-09,,,IEEE,IEEE Conferences
Applying Role Reversal Strategy to Conduct the Virtual Job Interview: A Practice in Second Life Immersive Environment,B. Chang; J. Lee; Y. Chen; F. Yu,"Dept. of E-Learning Design & Manage., Nat. Chiayi Univ., Chiayi, Taiwan; Dept. of E-Learning Design & Manage., Nat. Chiayi Univ., Chiayi, Taiwan; Dept. of E-Learning Design & Manage., Nat. Chiayi Univ., Chiayi, Taiwan; Inst. of Educ., Nat. Cheng Kung Univ., Tainan, Taiwan",2012 IEEE Fourth International Conference On Digital Game And Intelligent Toy Enhanced Learning,19-Apr-12,2012,,,177,181,"College students are going to face a new stage career as soon as they graduate from school, and how to assist college students to step into the career well is a very crucial issue in the college career counseling programming. Regarding the college career counseling programming, in general, the student-oriented activity helping the student to have the self-reflection is considered as a much more effective approach. Among the student-oriented activities, the role reversal strategy is the one that encourages students to actively take part in the activity and help students organize their thinking skills. Moreover, the role reversal strategy makes students have the empathy ability to make a right response in an opposite position. The study aims to apply the role reversal strategy to conduct the virtual job interview in Second Life immersive environment. Second Life which is an immersive technology can provide the innovative learning method and situated learning to reduce the obstacles where happened in the traditional classroom when applying role play and role reversal activities. Twenty-eight undergraduate students were recruited in the study. The study result indicates that most of the students prefer being the interviewers than to being the interviewees. And that they like to play role reversal activity in Second Life immersive environment to gain the interview experiences and improve their interview skills.",,978-1-4673-0885-4,10.1109/DIGITEL.2012.51,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6185614,role play;role reversal strategy;immersive environment;Second Life,Second Life;Interviews;Employee welfare;Engineering profession;Educational institutions;Internet,computer aided instruction;further education;virtual reality,role reversal strategy;virtual job interview;college students;college career counseling programing;self-reflection;student-oriented activities;empathy ability;second life immersive environment;immersive technology;innovative learning method;undergraduate students,,4,,10,,19-Apr-12,,,IEEE,IEEE Conferences
Medical Educational e-Platform through Virtual Reality technologies,M. F. Cabrera-Umpierrez; C. M. Ramirez; A. Sevillano; M. T. Arredondo; A. De Smedt,"Life Supporting Technolgies, Departmento de Tecnologia, Fotonica ETSI de Telecomunicacion, Universidad Politecnica de, Madrid (UPM), Madrid, Spain. chiqui@lst.tfo.upm.es; Departamento de Tecnologia Fotonica, Univ. Politecnica de Madrid; Departamento de Tecnologia Fotonica, Univ. Politecnica de Madrid; Departamento de Tecnologia Fotonica, Univ. Politecnica de Madrid; MINF-BISI",MELECON 2006 - 2006 IEEE Mediterranean Electrotechnical Conference,24-Jul-06,2006,,,453,456,"In the information society, medical information is dispersed and untrustworthy or the reliable medical information is not free, because it is required to pay a subscription. Generally, teachers, professors and trainers who are responsible for teaching medical skills, use traditional learning techniques which are not based in communication and information technologies. This paper presents an accessible educational framework that is being elaborated, based on the principles of evidence-based medicine, relying on real life scenarios and using virtual reality technologies through the Internet",2158-8481,1-4244-0087-2,10.1109/MELCON.2006.1653136,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1653136,,Virtual reality;Educational technology,biomedical education;computer aided instruction;Internet;medical information systems;virtual reality,medical educational e-platform;virtual reality technologies;information society;medical information;medical skill teaching;accessible educational framework;evidence-based medicine;Internet,,2,,11,,24-Jul-06,,,IEEE,IEEE Conferences
Comparison of a Gamified and Non-Gamified Virtual Reality Training Assembly Task,F. Palmas; D. Labode; D. A. Plecher; G. Klinker,"Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Research Group Augmented Reality, Technical University of Munich, Munich, Germany",2019 11th International Conference on Virtual Worlds and Games for Serious Applications (VS-Games),14-Oct-19,2019,,,1,8,"By using simulations in virtual reality (VR), people have the chance to train without supervision in a safe and controlled environment. VR simulation training allows users to gain new skills and apply them to real-life situations. However, the learning curve of this technology from a novice level could influence the expected learning results of a training session. A training approach based on the combination of VR and gamification could speed up this overall learning process and not just for a novice. In this paper we evaluate how gamification in a VR training session can improve the efficiency of the training and the accuracy of the task execution in a real-world practical test. In the training scenario of this study, 50 randomly assigned participants were divided into two groups. The groups were assigned to a gamified and a non-gamified version of the same VR training and were then guided through a step-by-step tutorial outlining how to solve an assembly task. Performance differences were evaluated based on time taken and specific errors made during the training session. The results of this study show, in general, that beneficial effects can be attributed to the use of gamification in the conducted VR training simulation, particularly for the VR novice participants.",2474-0489,978-1-7281-4540-2,10.1109/VS-Games.2019.8864583,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8864583,virtual training;virtual reality;gamification;training;learning transfer;assembly task,Training;Task analysis;Games;Tutorials;Solid modeling;Augmented reality,computer based training;computer simulation;serious games (computing);virtual reality,VR simulation training;learning curve;novice level;gamification;learning process;VR training session;task execution;virtual reality training assembly task,,3,,44,,14-Oct-19,,,IEEE,IEEE Conferences
Virtual Reality and Statistical Thinking Enhancement,O. L. R√≠os; L. J. L. L√≥pez,"Ind. Eng. Dept., ITESM, Monterrey, Mexico; UNAM, USA",2019 IEEE Integrated STEM Education Conference (ISEC),24-Oct-19,2019,,,367,370,"For decades, simulation has been a highly reliable tool for decision making. Even before its fundamental origin, the mathematical branch of system dynamics led to pioneering advances in research, technology and business. Today, virtual reality has become a mainstream technique for employee training. The combination of augmented and virtual reality technologies along with traditional methods of simulation has led to the development of a new powerful instrument of learning applied to complex systems. Our work is the first step of an ambitious project which aims to reinforce the Statistical Thinking of undergraduate students at the Monterrey Institute of Technology and Higher Education. Using virtual reality and numerical simulation methods our project connects processes and statistics. The student faces the challenge to solve a process problem, which is presented in a first step as a 3D video. By using virtual reality, we expect to develop strong and soft skills in our students enhanced by what we call the five S linked by the five C: Scope-Strategy-Standard-Seamless and Success with Choice-Collaboration-Communication-Critical-Thinking and Creativity. We have measured the impact of using this strategy on student learning. For the last two semesters the outcome has been positive for our learning model, in both quantitative and qualitative variables. We have carried out a parametric hypotheses test, comparing the mean grades obtained in a similar final exam, by students having followed our new method with those having a traditional learning method. Finally, by means of a general survey, we obtained that the student's general opinion, concerning learning statistics by visualizing the 3D real process and challenges, is highly motivating and rewarding.",2330-331X,978-1-7281-1502-3,10.1109/ISECon.2019.8881966,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8881966,Statistical Thinking;STEM;Virtual Reality;Educational Innovation,Three-dimensional displays;Virtual reality;Education;Industries;Creativity;Headphones;Solid modeling,computer aided instruction;educational institutions;further education;mathematics computing;statistical analysis;virtual reality,virtual reality;learning method;statistical thinking enhancement;system dynamics;employee training;augmented reality;undergraduate students;Monterrey Institute of Technology;higher education,,1,,5,,24-Oct-19,,,IEEE,IEEE Conferences
Development and user validation of driving tasks for a power wheelchair simulator,P. S. Archambault; √â. Blackburn; F. Routhier; D. Reid; W. C. Miller; R. L. Kirby,"School of Physical and Occupational Therapy, McGill University and CRIR, Montreal, Canada; School of Physical and Occupational Therapy, McGill University and CRIR, Montreal, Canada; Dept of Rehabilitation, Laval University and CIRRIS, Quebec City, Canada; Dept of Occupational Science and Occupational Therapy, University of Toronto, Toronto, Canada; Dept of Occupational Science and Occupational Therapy, University of British Columbia, Vancouver, Canada; Division of Physical Medicine and Rehabilitation, University of Dalhousie, Dalhousie, Canada",2015 International Conference on Virtual Rehabilitation (ICVR),17-Dec-15,2015,,,172,173,"Mobility is important for participation in daily activities and a power wheelchair (PW) can improve quality of life in individuals with mobility impairments. A VR simulator may be helpful for PW skills training, which is generally seen as insufficient by both clinicians and PW users. In previous work, challenging PW driving activities have been identified by interviews with expert clinicians and PW users. These activities were developed for the McGill Immersive Wheelchair simulator (miWe). Our objective was to validate these driving activities through a group of PW users, who practiced with the miWe simulator at home for two weeks. In interviews, this group made similar comments about the activities as our previous expert clinicians and PW users. They also insisted on the importance of realism in the activities, for the miWe to be useful as a training tool. A PW simulator may be helpful if it provides the practice of activities in specific contexts to complement the basic skills training received in the clinic.",2331-9569,978-1-4799-8984-3,10.1109/ICVR.2015.7358618,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358618,power wheelchair;training;simulator;validation,,handicapped aids;medical disorders;wheelchairs,basic skill training;mobility impairments;power wheelchair simulator;driving tasks,,1,,7,,17-Dec-15,,,IEEE,IEEE Conferences
A Study and Simulation on Thermal Cycling System of CFB Boiler,Y. Hou; X. Jiang,"State Grid Jibei Electr. Power Co. Limite Skills Training Center, Baoding Electr. Power VOC.& TECH. Coll., Baoding, China; State Grid Jibei Electr. Power Co. Limite Skills Training Center, Baoding Electr. Power VOC.& TECH. Coll., Baoding, China","2017 International Conference on Computer Network, Electronic and Automation (ICCNEA)",7-Dec-17,2017,,,507,511,"Energy is the main resource for our country to survive. However, in recent years, the excessive consumption of energy has made the environment worse and worse, and made the development of our country restricted. Technology of circulating fluid-bed boiler is the main way of general clean coal at present, and is a hot topic for each country in the world. However, the experimental process of the technology often spend a great cost, therefore is not suitable in practice. So simulation technology of circulating fluid-bed was used in this paper to solve practical problems. This paper established a circulating fluid-bed (CFB) boiler simulation system based on XinXiang HG-440 CFB, and analyzed final simulation system. Simulation process from thermal efficiency to thermal energy transformation were researched based on rules of thermal cycling and outlet of improving thermal energy utilization. This technology can not only improved the efficiency of energy, but also effectively reduced the energy generated in the process of burning gas pollution. Moreover, it has played an important role in China's energy construction.",,978-1-5386-3981-8,10.1109/ICCNEA.2017.45,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128619,Thermal cycling;Heat transfer model;Thermal energy utilization;Cyclone separator;CFB boiler,Coal;Combustion;Boilers;Furnaces;Thermal analysis;Particle separators;Mathematical model,air pollution;boilers;coal;combustion;fluidised beds,general clean coal;experimental process;simulation technology;practical problems;circulating fluid-bed boiler simulation system;XinXiang HG-440 CFB;final simulation system;simulation process;thermal efficiency;thermal energy transformation;thermal energy utilization;thermal cycling system;CFB boiler;excessive consumption;burning gas pollution;China energy construction,,,,10,,7-Dec-17,,,IEEE,IEEE Conferences
Helicopter visual signaling simulation: Integrating VR and ML into a low-cost solution to optimize Brazilian Navy training,A. L. C. Doneda; J. C. de Oliveira,"Military Institute of Engineering (IME),Computer Engineering Department,Rio de Janeiro,Brazil; Laboratory of Applied Multimedia and Virtual Environments, National Laboratory for Scientific Computing (LNCC),Petr√≥polis,Brazil",2020 22nd Symposium on Virtual and Augmented Reality (SVR),23-Nov-20,2020,,,434,442,"Landing Signalman (LS) is the military in charge of visually signaling the helicopter pilot when landing and taking off from a moving ship, ensuring general safety conditions of the flight deck area. It requires self-confidence, knowledge, skills, team coordination, and appropriate reaction capacity only achieved with intensive training. After studying the theory, Brazilian Navy LS trainees go directly to the practice stage at sea. This hands-on training phase straight after classroom reveals a series of limitations on LS trainee's performance. To better prepare the LS trainee, reduce training costs and provide a safe environment to perform unlimited training opportunities, we developed a lightweight, portable, and low-cost VR simulator for training optimization, denominated Helicopter Visual Signal Simulator (HVSS). Due to its specificities, a Machine Learning gesture recognition method was integrated into the virtual environment, and two datasets were created. This study details the process of achieving the design goals, developing the VR simulator prototype, and analyzing the tests we performed With 15 experienced instructors. The results indicate that HVSS meets all requirements to provide a reliable training solution.",,978-1-7281-9231-4,10.1109/SVR51698.2020.00071,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262459,Simulation;Virtual Reality;Machine Learning;Gesture Recognition,Training;Visualization;Helicopters;Virtual environments;Prototypes;Safety;Reliability,computer based training;gesture recognition;helicopters;learning (artificial intelligence);ships;virtual reality,general safety conditions;flight deck area;intensive training;hands-on training phase;unlimited training opportunities;lightweight cost VR simulator;training optimization;machine learning;virtual environment;VR simulator prototype;helicopter pilot;helicopter visual signal simulator;gesture recognition;landing signalman;Brazilian navy training,,,,46,,23-Nov-20,,,IEEE,IEEE Conferences
Doctoral Colloquium‚ÄîEnhancing Brain Plasticity and Cognition Utilizing Immersive Technology and Virtual Reality Contexts for Gameplay,C. M. Eng; D. M. Calkosz; S. Y. Yang; N. C. Williams; E. D. Thiessen; A. V. Fisher,"Carnegie Mellon University,Psychology,Pittsburgh,USA; Carnegie Mellon University,Computer Science,Pittsburgh,USA; Carnegie Mellon University,Information Systems,Pittsburgh,USA; Carnegie Mellon University,Logic and Computation,Pittsburgh,USA; Carnegie Mellon University,Psychology,Pittsburgh,USA; Carnegie Mellon University,Psychology,Pittsburgh,USA",2020 6th International Conference of the Immersive Learning Research Network (iLRN),4-Aug-20,2020,,,395,398,This work-in-progress paper examines the effects of immersive virtual experiences on cognition and neuroplasticity. Study 1 examined the separate and combined effects of physically active and cognitively demanding immersive gameplay on executive function and associated neural substrates. Results indicated that cognition and neuroplasticity-the building of new brain connections-increase when learning novel skills via active gameplay. Study 2 devised an experimental design to reproduce Study 1 in virtual reality to examine whether the findings of enhanced cognition and neuroplasticity generalize across virtual contexts and development. Incorporating neuroimaging measures into virtual experiences may identify the underlying mechanisms for behavioral changes in learning.,,978-1-7348995-0-4,10.23919/iLRN47897.2020.9155120,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155120,executive function;neuroplasticity;exergames,Task analysis;Neuroplasticity;Games;Neuroimaging;Training;Fish;Cognition,brain;cognition;computer games;neurophysiology;virtual reality,immersive technology;brain plasticity;virtual contexts;neuroplasticity;active gameplay;brain connection;neural substrates;executive function;immersive gameplay;immersive virtual experiences;virtual reality contexts;cognition utilizing immersive technology;doctoral colloquium,,1,,16,,4-Aug-20,,,IEEE,IEEE Conferences
Constrained 3D navigation with 2D controllers,A. J. Hanson; E. A. Wernert,"Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA; NA",Proceedings. Visualization '97 (Cat. No. 97CB36155),6-Aug-02,1997,,,175,182,"Navigation through 3D spaces is required in many interactive graphics and virtual reality applications. The authors consider the subclass of situations in which a 2D device such as a mouse controls smooth movements among viewpoints for a ""through the screen"" display of a 3D world. Frequently, there is a poor match between the goal of such a navigation activity, the control device, and the skills of the average user. They propose a unified mathematical framework for incorporating context-dependent constraints into the generalized viewpoint generation problem. These designer-supplied constraint modes provide a middle ground between the triviality of a single camera animation path and the confusing excess freedom of common unconstrained control paradigms. They illustrate the approach with a variety of examples, including terrain models, interior architectural spaces, and complex molecules.",,0-8186-8262-0,10.1109/VISUAL.1997.663876,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=663876,,Navigation;Computer graphics;Cameras;Layout;Virtual reality;Application software;Mice;Animation;Interpolation;Control systems,virtual reality,2D controllers;constrained 3D navigation;interactive graphics;virtual reality;mouse;2D device;controls smooth movements;viewpoints;3D world display;unified mathematical framework;context-dependent constraints;designer-supplied constraint modes;terrain models;interior architectural spaces;complex molecules,,32,1,25,,6-Aug-02,,,IEEE,IEEE Conferences
Control System Functioning Algorithm Software and Hardware Platform for the Training Complex,D. Dedov; A. Siuhin; A. Volkov,"Tambov State Technical University,Dept. of Computer-integrated systems in engineering,Tambov,Russia; Tambov State Technical University,Dept. of Computer-integrated systems in engineering,Tambov,Russia; Tambov State Technical University,Dept. of Automated Systems of Decision-Making Support,Tambov,Russia",2019 International Multi-Conference on Industrial Engineering and Modern Technologies (FarEastCon),19-Dec-19,2019,,,1,5,"Virtual training complexes are used to train professional ergatic system personnel, develop the necessary practical skills and reduce the possibility of human mistake in working and emergency situations. However, the use of virtual reality tools does not provide a complete sense of realism for the trainees, so the topical problem is to develop and integrate into the training complexes various simulation systems that increase the degree of human immersion into the virtual world. In this study the problem of simulation of physical loads and realistic movement of the user in the virtual world is considered. In order to solve it, it is proposed to develop a universal software and hardware platform based on an automated treadmill, which allows organizing the user's natural movement in a virtual environment with the ability to programmatically control various movement parameters, such as speed and incline of the running belt. Thus, it is required to implement the software of the control system, as well as the algorithmic support necessary for its work for the realization of these functions. This paper considers the general scheme of functioning of the software and hardware platform, its hardware and software components, as well as the algorithm of controlling the hardware actuating elements of the platform. The results were applied in the implementation of the control system of the software and hardware platform to ensure its correct functioning. The conducted tests of the platform allowed us to conclude about the applicability of the obtained scientific results and to formulate areas for the further research.",,978-1-7281-0061-6,10.1109/FarEastCon.2019.8933994,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933994,training complex;software and hardware platform;functioning algorithm;structural diagram;automata theory,Software;Control systems;Hardware;Belts;Training;Software algorithms;Servers,computer based training;control engineering computing;virtual reality,hardware platform;control system functioning algorithm software;virtual training complexes;professional ergatic system personnel;virtual reality tools;simulation systems;control system software,,,,24,,19-Dec-19,,,IEEE,IEEE Conferences
A Model for Understanding How Virtual Reality Aids Complex Conceptual Learning,M. C. Salzman; C. Dede; R. B. Loftin; J. Chen,"Human Factors and Applied Cognitive Psychology Department, George Mason University, Fairfax, VA 22030, mcsalzm@advtech.uswest.com; Graduate School of Education, George Mason University, cdede@gmu.edu; Virtual Environment Technology Lab, University of Houston, Houston, TX 77023, bloftin@uh.edu; Computer Science Department, George Mason University, jchen@cs.gmu.edu",Presence,19-May-14,1999,8,3,293,316,"Designers and evaluators of immersive virtual reality systems have many ideas concerning how virtual reality can facilitate learning. However, we have little information concerning which of virtual reality's features provide the most leverage for enhancing understanding or how to customize those affordances for different learning environments. In part, this reflects the truly complex nature of learning. Features of a learning environment do not act in isolation; other factors such as the concepts or skills to be learned, individual characteristics, the learning experience, and the interaction experience all play a role in shaping the learning process and its outcomes. Through Project Science Space, we have been trying to identify, use, and evaluate immersive virtual reality's affordances as a means to facilitate the mastery of complex, abstract concepts. In doing so, we are beginning to understand the interplay between virtual reality's features and other important factors in shaping the learning process and learning outcomes for this type of material. In this paper, we present a general model that describes how we think these factors work together and discuss some of the lessons we are learning about virtual reality's affordances in the context of this model for complex conceptual learning.",1054-7460,,10.1162/105474699566242,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6788183,,,,,,16,,,,19-May-14,,,MIT Press,MIT Press Journals
An improved VR training system for vascular interventional surgery,S. Guo; X. Cai; B. Gao; J. Yuhua,"Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, the Ministry of Industry and Information Technology, School of Life Science, Beijing Institute of Technology, No.5, Zhongguancun South Street, Haidian District, 100081, China; Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, the Ministry of Industry and Information Technology, School of Life Science, Beijing Institute of Technology, No.5, Zhongguancun South Street, Haidian District, 100081, China; Key Laboratory of Convergence Medical Engineering System and Healthcare Technology, the Ministry of Industry and Information Technology, School of Life Science, Beijing Institute of Technology, No.5, Zhongguancun South Street, Haidian District, 100081, China; Department of Interventional Neurosurgery, Beijing Neurosurgical Institute and Beijing Tiantan Hospital, China",2016 IEEE International Conference on Robotics and Biomimetics (ROBIO),2-Mar-17,2016,,,1667,1672,"Minimally invasive surgery is a specialized surgical technique that permits vascular interventions through very small incisions. It minimizes the patient's trauma and permits a faster recovery compared to traditional surgery. Although traditional invasive surgery training system can complete general training work, real-time performance and accuracy of most training system failed to meet the requirements of training work. Therefore, in this study, three parts, including 3D modeling, collision detection algorithm and application architecture were improved in the existing training system. Firstly, an improved Marching cubes algorithm was adopted to simplify the mathematical modeling of vessels by merging the related points of the mesh model. Secondly, a hybrid collision detection algorithm was proposed and implemented. Lastly, the CPU-GPU parallel computing architecture was adopted. Particularly, the design of the improved VR-based system and the experimental results were presented and analyzed. Moreover, experimental results showed that the proposed system was beneficial to improve the skill of surgeons in manipulating the catheter and guide wire. Thus, the simulators could be used for trial surgery training.",,978-1-5090-4364-4,10.1109/ROBIO.2016.7866567,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7866567,,Surgery;Training;Solid modeling;Real-time systems;Collision avoidance;Algorithm design and analysis;Rendering (computer graphics),catheters;medical computing;parallel processing;software architecture;surgery;virtual reality;wires,virtual reality;VR training system;vascular interventional surgery;minimally invasive surgery;3D modelling;collision detection algorithm;application architecture;CPU-GPU parallel computing architecture;catheter manipulation;guide wire manipulation,,3,,19,,2-Mar-17,,,IEEE,IEEE Conferences
Exploring individual differences of public speaking anxiety in real-life and virtual presentations,M. Yadav; M. N. Sakib; E. H. Nirjhar; K. Feng; A. Behzadan; T. Chaspari,"Computer Science & Engineering, Texas A and M University College Station, 14736 College Station, Texas, United States, (e-mail: meghakyadav@gmail.com); Multidisciplinary Engineering, Texas A&M University College Station, 14736 College Station, Texas, United States, (e-mail: mnsakib@tamu.edu); Computer Science & Engineering, Texas A&M University System, 2655 College Station, Texas, United States, (e-mail: nirjhar71@tamu.edu); Computer Science & Engineering, Texas A&M University College Station, 14736 College Station, Texas, United States, (e-mail: kexin0814@tamu.edu); Construction Science, Texas A&M University College Station, 14736 College Station, Texas, United States, (e-mail: abehzadan@tamu.edu); Computer Science & Engineering, Texas A&M Engineering, 122656 College Station, Texas, United States, (e-mail: chaspari@tamu.edu)",IEEE Transactions on Affective Computing,,2020,PP,99,1,1,"Public speaking is a vital skill for making good impressions, effectively exchanging ideas, and influencing others. Yet, public speaking anxiety (PSA) ranks as a top social phobia. Recent advancements in wearable devices and ubiquitous virtual reality (VR) interfaces can help measure and mitigate PSA. This research quantifies PSA through bio-behavioral markers related to individuals' physiological and acoustic characteristics. The effect of virtual reality (VR) training on alleviating PSA is measured through self-reported and bio-behavioral indices. Psychological (e.g., general trait anxiety, personality) and demographic (e.g., age, gender, highest education, native language) traits are examined as moderating factors between bio-behavioral indices and PSA, as well as moderating factors for measuring the VR effectiveness in mitigating PSA. These measures are also used as clustering criteria for stratifying participants in group-based models of PSA. Results indicate the significance of such traits to modeling PSA with the proposed group-based models yielding Spearman's correlation of 0:55 ($p \lt 0:05$) between the actual and predicted outcome. Results further demonstrate that systematic exposure to public speaking in VR can alleviate PSA in terms of both self-reported ($p \lt 0:05$) and physiological ($p \lt 0:05$) indices. Findings from this study will enable researchers to better understand antecedents and causes of PSA and lay the foundation for personalized adaptive feedback for PSA interventions.",1949-3045,,10.1109/TAFFC.2020.3048299,Engineering Information Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311251,Public speaking anxiety;virtual reality;physiology;speech;wearable devices;individual differences,Public speaking;Physiology;Training;Psychology;Task analysis;Particle measurements;Atmospheric measurements,,,,,,,IEEE,30-Dec-20,,,IEEE,IEEE Early Access Articles
Virtual Reality as a Tool to Learn Interpersonal Coordination: Example of Team Rowing,M. Varlet; A. Filippeschi; G. Ben-sadoun; M. Ratto; L. Marin; E. Ruffaldi; B. G. Bardy,"Movement to Health Laboratory, EuroMov, Montpellier-1 University; PERCRO Lab, Scuola Superiore S. Anna; Movement to Health Laboratory, EuroMov, Montpellier-1 University; Movement to Health Laboratory, EuroMov, Montpellier-1 University; Movement to Health Laboratory, EuroMov, Montpellier-1 University; PERCRO Lab, Scuola Superiore S. Anna; PERCRO Lab, Scuola Superiore S. Anna, and Institut Universitaire de France",Presence,20-May-14,2013,22,3,202,215,"Abstract The success of interpersonal activities strongly depends on the coordination between our movements and those of others. Learning to coordinate with other people requires a long training time and is often limited by the difficulty of having people available at the same time and of giving them accurate and real-time feedback about their coordination. The goal of the present study was to determine in an indoor team rowing situation whether virtual-reality and motion-capture technologies can help the acquisition of interpersonal coordination. More specifically, we investigated the possibility for participants to (1) learn the skill of interpersonal coordination when training with a virtual teammate, (2) accelerate learning with real-time visual feedback, and (3) transfer this skill to synchronizing situations with a real teammate. Our results show that participants improved their coordination with both virtual and real teammates, and that this improvement was better for participants who received the feedback. Generally, our results demonstrate the interest of virtual reality for learning the coordination with other people; further, our results open promising training perspectives for team rowing but also for several other interpersonal activities.",1054-7460,,10.1162/PRES_a_00151,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6818592,,,,,,1,,,,20-May-14,,,MIT Press,MIT Press Journals
Hybrid memory-based control of robotic manipulators,Choon-Young Lee; Ju-Jang Lee,"Dept. of Electr. Eng. & Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Taejon, South Korea; NA",Proceedings of IEEE Region 10 International Conference on Electrical and Electronic Technology. TENCON 2001 (Cat. No.01CH37239),7-Aug-02,2001,1,,433,438 vol.1,"Robotics research aims to realize some aspects of human control skills in a mechanical system. We considered another approach for the control of robotic manipulators using a multi-valued function regularization network (MVRN) approximating a multiple inverse kinematics solution. We assume that we have only the input-output data pairs of joint and Cartesian space for the unknown forward kinematics relation. Using these data, we approximate global inverse kinematics mapping using the MVRN. After approximating the inverse kinematics mapping, we find collision-free joint trajectories like a human being for the given task and the environment. We also adopt an adaptive neural network control scheme for motion control with unknown dynamics. From the global viewpoint, the MVRN may be considered as the long-term memory for relatively unchanging information for the robot manipulator and an adaptive neural network controller can be thought of as the short-term memory for the time-varying information for the change of load and dynamic parameters of the plant. Using these two components, we construct a more general and global control scheme for robotic manipulators. Simulation results are presented to illustrate the overall scheme of the proposed method.",,0-7803-7101-1,10.1109/TENCON.2001.949630,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=949630,,Robot control;Kinematics;Manipulator dynamics;Humans;Adaptive systems;Programmable control;Adaptive control;Neural networks;Motion control;Control systems,motion control;manipulator kinematics;adaptive control;neurocontrollers;manipulator dynamics;learning systems;path planning,hybrid memory-based control;robotic manipulators;collision-free joint trajectories;adaptive neural network control scheme;motion control;unknown dynamics;long-term memory;short-term memory;time-varying information;learning control;multi-valued function approximation;human control skills;multi-valued function regularization network;multiple inverse kinematics solution;joint space;Cartesian space;mechanical system,,,,9,,7-Aug-02,,,IEEE,IEEE Conferences
Assessment of the pilot implementation of a game-based gear design laboratory,Y. Chang; E. Aziz; S. K. Esche; C. Chassapis,"Stevens Institute of Technology, Department of Mechanical Engineering, Hoboken, New Jersey 07030, USA; Stevens Institute of Technology, Department of Mechanical Engineering, Hoboken, New Jersey 07030, USA; Stevens Institute of Technology, Department of Mechanical Engineering, Hoboken, New Jersey 07030, USA; Stevens Institute of Technology, Department of Mechanical Engineering, Hoboken, New Jersey 07030, USA",2011 Frontiers in Education Conference (FIE),2-Feb-12,2011,,,S4H-1,S4H-6,"Taking advantage of game technology for offering truly immersive and interactive learning experiences to undergraduate engineering and science students has now become a real possibility. An immersive interactive virtual laboratory environment has been created for the laboratory component of a junior-level undergraduate mechanical engineering course on mechanisms and machine dynamics. For instance, a laboratory system implemented using a multi-player computer game engine provides the students with the flexibility to perform various experiments related to the concepts of the fundamental law of gearing and to the planetary motion of gears. Assessment tools such as pre- and post-experiment tests are an integral part of this game-based laboratory environment and form the basis for providing different levels of support to the students at every step of the laboratory exercise. Furthermore, the game environment can be equipped with functionality for monitoring the students' progress and learning outcomes, thus enabling skill-based assessment. This paper will report on the learning assessment conducted as part of a pilot implementation of this gear design laboratory. The evaluation metrics for the virtual laboratory environment as well as the collected data on learning effectiveness will be presented and the general student feedback will be discussed.",2377-634X,978-1-61284-469-5,10.1109/FIE.2011.6143031,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6143031,Game-based laboratory;Gear design;Virtual experiment;Assessment;Game engine,Gears;Laboratories;Games;Assembly;Engines;Conferences;Mechanical engineering,computer aided instruction;computer games;design engineering;educational courses;engineering education;gears;laboratories;mechanical engineering computing;virtual reality,game-based gear design laboratory;game technology;immersive interactive virtual laboratory environment;junior-level undergraduate mechanical engineering course;mechanisms course;machine dynamics course;multiplayer computer game engine;gear planetary motion;gearing law;learning assessment;evaluation metrics;learning effectiveness;student feedback;immersive learning experience;interactive learning experience,,3,,18,,2-Feb-12,,,IEEE,IEEE Conferences
Message from the IEEE AIVR 2018 General Co-Chairs,,,2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),17-Jan-19,2018,,,12,13,"Research in Virtual Reality (VR) is concerned with computing technologies that allow humans to see, hear, talk, think, learn, and solve problems in virtual and augmented environments. Research in Artificial Intelligence (AI) addresses technologies that allow computing machines to mimic these same human abilities. Although these two fields evolved separately, they share an interest in human senses, skills, and knowledge production. Thus, bringing them together will enable us to create more natural and realistic virtual worlds and develop better, more effective applications. Ultimately, this will lead to a future in which humans and humans, humans and machines, and machines and machines are interacting naturally in virtual worlds, with use cases and benefits we are only just beginning to imagine. The First IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR 2018) is a unique event, addressing researchers and industries from all areas of AI as well as Virtual, Augmented, and Mixed Reality. It provides an international forum for the exchange between those fields, to present advances in the state of the art, identify emerging research topics, and together define the future of these exciting research domains.",,978-1-5386-9269-1,10.1109/AIVR.2018.00005,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613624,,,,,,,,,,17-Jan-19,,,IEEE,IEEE Conferences
Will we ever become used to immersion? Art history and image science,O. Grau,NA,2011 10th IEEE International Symposium on Mixed and Augmented Reality,5-Mar-12,2011,,,1,1,"3D Television and Immersive Cinema, Virtual and Augmented Reality, do we enter soon a total space of polysensual illusion? The aim of this contribution is to create an understanding that the present image revolution using indeed new technologies has also developed a large number of so far unknown visual expressions that cannot be conceived without our image history. Art History and Image Science help in understanding the leading and forming functions of today¬¥s image worlds in our society. With the history of illusion and immersion, the history of artificial life or the tradition of telepresence, Image Science offers sub-histories of the present image revolutions. We know that a central problem of current cultural policy stems from serious lack of knowledge about the origins of the audiovisual media and this stands in complete contradistinction to current demands for more media and image competence. Social media competence, which goes beyond mere technical skills, is difficult to acquire if the area of historic media experience is excluded. Although many people view the concept of presence, virtual or mixed realities as a totally new phenomenon, it has its foundations in an unrecognized history of immersive images. Immersion is undoubtedly a key to any understanding of the development of media in general. Overseeing 2000 years of immersive images and by bringing them in a relativity with the image competence of their users, this talk aims to gain distance and with that a reflective thinking space towards the desire to create ever new immersive image experiences.",,978-1-4577-2185-4,10.1109/ISMAR.2011.6092347,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6162848,,,,,,,,,,5-Mar-12,,,IEEE,IEEE Conferences
Will we ever become used to immersion? Art history and image science,O. Grau,NA,"2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities",1-Dec-11,2011,,,1,1,"Summary form only given. 3D Television and Immersive Cinema, Virtual and Augmented Reality, do we enter soon a total space of polysensual illusion? The aim of this contribution is to create an understanding that the present image revolution using indeed new technologies has also developed a large number of so far unknown visual expressions that cannot be conceived without our image history. Art History and Image Science help in understanding the leading and forming functions of today's image worlds in our society. With the history of illusion and immersion, the history of artificial life or the tradition of telepresence, Image Science offers sub-histories of the present image revolutions. We know that a central problem of current cultural policy stems from serious lack of knowledge about the origins of the audiovisual media and this stands in complete contradistinction to current demands for more media and image competence. Social media competence, which goes beyond mere technical skills, is difficult to acquire if the area of historic media experience is excluded. Although many people view the concept of presence, virtual or mixed realities as a totally new phenomenon, it has its foundations in an unrecognized history of immersive images. Immersion is undoubtedly a key to any understanding of the development of media in general. Overseeing 2000 years of immersive images and by bringing them in a relativity with the image competence of their users, this talk aims to gain distance and with that a reflective thinking space towards the desire to create ever new immersive image experiences.",2381-8360,978-1-4673-0059-9,10.1109/ISMAR-AMH.2011.6093635,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6093635,,,art;augmented reality;three-dimensional television,art history;image science;3D television;immersive cinema;virtual reality;augmented reality;polysensual illusion;image revolution;artificial life;telepresence;social media competence;immersion,,,,,,1-Dec-11,,,IEEE,IEEE Conferences
Augmented Reality to Improve Surgical Simulation: Lessons Learned Towards the Design of a Hybrid Laparoscopic Simulator for Cholecystectomy,R. M. Viglialoro; N. Esposito; S. Condino; F. Cutolo; S. Guadagni; M. Gesi; M. Ferrari; V. Ferrari,"EndoCAS Center, Department of Translational Research and New Technologies in Medicine and Surgery, University of Pisa, Pisa, Italy; EndoCAS Center, Department of Translational Research and New Technologies in Medicine and SurgeryUniversity of Pisa; EndoCAS Center, Department of Translational Research and New Technologies in Medicine and SurgeryUniversity of Pisa; EndoCAS Center, Department of Translational Research and New Technologies in Medicine and SurgeryUniversity of Pisa; Department of General Surgery UnitCisanello University Hospital AOUP; Department of Translational Research on New Technologies in Medicine and SurgeryUniversity of Pisa; EndoCAS Center, Department of Translational Research and New Technologies in Medicine and SurgeryUniversity of Pisa; EndoCAS Center, Department of Translational Research and New Technologies in Medicine and SurgeryUniversity of Pisa",IEEE Transactions on Biomedical Engineering,21-Jun-19,2019,66,7,2091,2104,"Hybrid surgical simulators based on augmented reality (AR) solutions benefit from the advantages of both the box trainers and the virtual reality simulators. This paper reports on the results of a long development stage of a hybrid simulator for laparoscopic cholecystectomy that integrates real and the virtual components. We first outline the specifications of the AR simulator and then we explain the strategy adopted for implementing it based on a careful selection of its simulated anatomical components, and characterized by a real-time tracking of both a target anatomy and of the laparoscope. The former is tracked by means of an electromagnetic field generator, while the latter requires an additional camera for video tracking. The new system was evaluated in terms of AR visualization accuracy, realism, and hardware robustness. Obtained results show that the accuracy of AR visualization is adequate for training purposes. The qualitative evaluation confirms the robustness and the realism of the simulator. In conclusion, the proposed AR simulator satisfies all the initial specifications in terms of anatomical appearance, modularity, reusability, minimization of spare parts cost, and ability to record surgical errors and to track in real-time the Calot's triangle and the laparoscope. Thus, the proposed system could be an effective training tool for learning the task of identification and isolation of Calot's triangle in laparoscopic cholecystectomy. Moreover, the presented strategy could be applied to simulate other surgical procedures involving the task of identification and isolation of generic tubular structures, such as blood vessels, biliary tree, and nerves, which are not directly visible.",1558-2531,,10.1109/TBME.2018.2883816,Augmented Reality Simulation; Italian Minister of Health; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8550677,Surgical simulator;laparoscopic simulation;augmented reality;hybrid simulators;physical anatomical model;cholecystectomy training,Laparoscopes;Solid modeling;Visualization;Training;Task analysis;Minimally invasive surgery,augmented reality;blood vessels;computer based training;data visualisation;medical computing;surgery;virtual reality,surgical simulation;hybrid laparoscopic simulator;hybrid surgical simulators;virtual reality simulators;hybrid simulator;laparoscopic cholecystectomy;virtual components;AR simulator;simulated anatomical components;real-time tracking;laparoscope;electromagnetic field generator;video tracking;AR visualization accuracy;hardware robustness;surgical errors;Calot's triangle;surgical procedures;augmented reality solutions,,2,,50,,28-Nov-18,,,IEEE,IEEE Journals
Virtual and Augmented Reality: Enhancing the learning experience in higher education in the U.A.E. Current standing & research directions,D. Xanthidis; C. Manolas; S. Paul; O. K. Xanthidou,"Computer and Information Science, Higher Colleges of Technology,Dubai,U.A.E.; Music and Sound Design for Media Ravensbourne University,London,U.K.; Computer and Information Science, Higher Colleges of Technology,Dubai,U.A.E.; University of Malaya,Computer Science and Information Technology,Kuala Lumpur,Malaysia",2020 Seventh International Conference on Information Technology Trends (ITT),19-Jan-21,2020,,,206,211,"In addition to the established and widespread technological tools and trends of the past decades, such as the surge of mobile computing, high-speed networks and social media, new technologies utilizing the increased power and capabilities of modern computers is developing rapidly. Perhaps, no better example of this can be found than the rapid developments in Virtual and Augmented Reality (VR/AR), that have recently made the step from the laboratories and specialized, bespoke training applications of the past, to the mainstream. Advances in VR/AR have opened the floodgates to digital internships, virtual labs, and novel collaborative and experiential learning. The magnitude and impact of these emerging technologies is also evident on the significant interest in their application and use in various commercial, professional, and industrial contexts. Examples of these include, but are not limited to, the entertainment industries, specialized training, corporate demonstrations and conferencing, and prototyping and modelling in the technical and engineering areas. Since universities play a vital role in moulding tomorrow's talents, integrating such technologies can help them not only by supporting teaching and learning, but also by contributing to related research and enhancing the learning technology frameworks in their entirety. The aim of this research paper is to briefly discuss the position of these emerging technologies in the educational sector in general, and explore what their role, impact, and structure may be in the educational systems of the future with a focus on higher education in the U.A.E. Eventually, it will contribute by suggesting areas of interest for its future use in higher education in the U.A.E.",,978-1-7281-8379-4,10.1109/ITT51279.2020.9320882,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9320882,Higher Education;Augmented Reality;Virtual Reality;Learning Object;U.A.E.,Three-dimensional displays;Training;Tools;Market research;Technological innovation;Visualization;Solid modeling,augmented reality;computer aided instruction;educational institutions;entertainment;further education;mobile learning;social networking (online);teaching,augmented reality;learning experience;higher education;mobile computing;high-speed networks;social media;digital internships;virtual labs;experiential learning;entertainment industries;corporate demonstrations;learning technology frameworks;educational sector;educational systems;virtual reality,,,,35,,19-Jan-21,,,IEEE,IEEE Conferences
A Virtual-Reality System Integrated With Neuro-Behavior Sensing for Attention-Deficit/Hyperactivity Disorder Intelligent Assessment,S. -C. Yeh; S. -Y. Lin; E. H. -K. Wu; K. -F. Zhang; X. Xiu; A. Rizzo; C. -R. Chung,"Computer Science and Information Engineering Department, National Central University, Taoyuan, Taiwan; Computer Science and Information Engineering Department, National Central University, Taoyuan, Taiwan; Computer Science and Information Engineering Department, National Central University, Taoyuan, Taiwan; Department of Child Health Care, Children‚Äôs Hospital of Fudan University, Shanghai, China; Department of Child Health Care, Children‚Äôs Hospital of Fudan University, Shanghai, China; Institute for Creative Technologies, University of Southern California, Los Angeles, CA, USA; Computer Science and Information Engineering Department, National Central University, Taoyuan, Taiwan",IEEE Transactions on Neural Systems and Rehabilitation Engineering,7-Sep-20,2020,28,9,1899,1907,"Attention-deficit/Hyperactivity disorder(ADHD) is a common neurodevelopmental disorder among children. Traditional assessment methods generally rely on behavioral rating scales (BRS) performed by clinicians, and sometimes parents or teachers. However, BRS assessment is time consuming, and the subjective ratings may lead to bias for the evaluation. Therefore, the major purpose of this study was to develop a Virtual Reality (VR) classroom associated with an intelligent assessment model to assist clinicians for the diagnosis of ADHD. In this study, an immersive VR classroom embedded with sustained and selective attention tasks was developed in which visual, audio, and visual-audio hybrid distractions, were triggered while attention tasks were conducted. A clinical experiment with 37 ADHD and 31 healthy subjects was performed. Data from BRS was compared with VR task performance and analyzed by rank-sum tests and Pearson Correlation. Results showed that 23 features out of total 28 were related to distinguish the ADHD and non-ADHD children. Several features of task performance and neuro-behavioral measurements were also correlated with features of the BRSs. Additionally, the machine learning models incorporating task performance and neuro-behavior were used to classify ADHD and non-ADHD children. The mean accuracy for the repeated cross-validation reached to 83.2%, which demonstrated a great potential for our system to provide more help for clinicians on assessment of ADHD.",1558-0210,,10.1109/TNSRE.2020.3004545,Ministry of Science and Technology Taiwan; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9123917,Attention deficit and hyperactivity disorder;virtual reality;neuro-behavior;machine learning;assessment,Task analysis;Pediatrics;Machine learning;Medical services;Virtual environments;Computer science;Medical diagnostic imaging,cognition;diseases;learning (artificial intelligence);medical computing;medical diagnostic computing;medical disorders;neurophysiology;paediatrics;patient diagnosis;statistical analysis;virtual reality,virtual-reality system;neuro-behavior;common neurodevelopmental disorder;behavioral rating scales;BRS assessment;subjective ratings;Virtual Reality classroom;intelligent assessment model;immersive VR classroom;sustained attention tasks;selective attention tasks;visual-audio hybrid distractions;VR task performance;nonADHD children;neuro-behavioral measurements,,,,24,IEEE,24-Jun-20,,,IEEE,IEEE Journals
Tablet VR-Learning System: Chemical Laboratory Experience System,K. Uchiyama; K. Funahashi,"Nagoya Inst. of Technol., Nagoya, Japan; Nagoya Inst. of Technol., Nagoya, Japan",2013 International Conference on Signal-Image Technology & Internet-Based Systems,30-Jan-14,2013,,,416,423,"Education builds culture of human for many years. The method of education has been developed from oral communication and textbook to broadcasting and e-learning. According to development, children have become to be free for place, time and teacher who gives some advice. On the other hand, the opportunities that children contact with real things and experience is getting decrease. Generally speaking, experience is important for the education such as physical education, art and also science. In addition, it is usually difficult to have a good environment for experience at a self learning situation and e-learning systems. In this paper, we describe a chemical laboratory experience system using VR technology for primary school students, as a VR-learning system. In addition, we confirm the usefulness through experiments that several primary school students use this system.",,978-1-4799-3211-5,10.1109/SITIS.2013.74,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6727223,Education culture;VR-learning;Chemical laboratory system;3D tablet interface,Liquids;Containers;Three-dimensional displays;Equations;Educational institutions;Mathematical model,chemistry computing;computer aided instruction;notebook computers;student experiments;virtual reality,tablet VR-learning system;culture;oral communication;textbook;broadcasting;physical education;art;science;self learning situation;e-learning systems;chemical laboratory experience system;VR technology;primary school students,,,,15,,30-Jan-14,,,IEEE,IEEE Conferences
Towards a Machine-Learning Approach for Sickness Prediction in 360¬∞ Stereoscopic Videos,N. Padmanaban; T. Ruban; V. Sitzmann; A. M. Norcia; G. Wetzstein,Stanford Electrical Engineering Department; Stanford Electrical Engineering Department; Stanford Electrical Engineering Department; Stanford Psychology Department; Stanford Electrical Engineering Department,IEEE Transactions on Visualization and Computer Graphics,19-Mar-18,2018,24,4,1594,1603,"Virtual reality systems are widely believed to be the next major computing platform. There are, however, some barriers to adoption that must be addressed, such as that of motion sickness - which can lead to undesirable symptoms including postural instability, headaches, and nausea. Motion sickness in virtual reality occurs as a result of moving visual stimuli that cause users to perceive self-motion while they remain stationary in the real world. There are several contributing factors to both this perception of motion and the subsequent onset of sickness, including field of view, motion velocity, and stimulus depth. We verify first that differences in vection due to relative stimulus depth remain correlated with sickness. Then, we build a dataset of stereoscopic 3D videos and their corresponding sickness ratings in order to quantify their nauseogenicity, which we make available for future use. Using this dataset, we train a machine learning algorithm on hand-crafted features (quantifying speed, direction, and depth as functions of time) from each video, learning the contributions of these various features to the sickness ratings. Our predictor generally outperforms a na√Øve estimate, but is ultimately limited by the size of the dataset. However, our result is promising and opens the door to future work with more extensive datasets. This and further advances in this space have the potential to alleviate developer and end user concerns about motion sickness in the increasingly commonplace virtual world.",1941-0506,,10.1109/TVCG.2018.2793560,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8267239,Virtual reality;simulator sickness;vection;machine learning,Videos;Stereo image processing;Three-dimensional displays;Visualization;Virtual environments;Machine learning algorithms;Trajectory,human factors;image motion analysis;learning (artificial intelligence);medical image processing;stereo image processing;video signal processing;virtual reality;visual perception,sickness ratings;commonplace virtual world;virtual reality systems;stereoscopic videos;sickness prediction;machine-learning approach;machine learning algorithm;stereoscopic 3D videos;relative stimulus depth;motion velocity;motion sickness,"Adult;Algorithms;Computer Graphics;Databases, Factual;Depth Perception;Female;Humans;Machine Learning;Male;Middle Aged;Motion Sickness;User-Computer Interface;Video Recording;Virtual Reality;Young Adult",18,,40,,23-Jan-18,,,IEEE,IEEE Journals
Computer-aided 3D Virtual Training in Power System Education,A. N. Angelov; Z. A. Styczynski,"Member, IEEE, Faculty of Electrical Engineering and Information Technology, Otto-von-Guericke-Univeristy-Magdeburg, Magdeburg, 39106 Germany. e-mail: angel.angelov@e-technik.uni-magdeburg.de; Senior Member, IEEE, Faculty of Electrical Engineering and Information Technology, Otto-von-Guericke-Univeristy-Magdeburg, Magdeburg, 39106 Germany",2007 IEEE Power Engineering Society General Meeting,23-Jul-07,2007,,,1,4,"The implementation of computer-aided three dimensional (3D) virtual training and the combination of traditional evaluated learning programs with virtual reality systems in the area of power system education will be presented in this paper. As new complex systems, electric plants and machines are becoming increasingly more intricate, such learning methods provide effective training and fast adjustment with operation, control and process sequences. Without these new methods, the understanding and operation of such systems would be very time consuming. For specialized engineers a regular and high-quality training is additionally necessary. The interactive computer-aided three dimensional representation allows online development and utilization of 3D environments and assures deeper contact, than any drawing or written description. During the development of the computer-aided learning modules a distinction was drawn between teaching / training scenarios and research scenarios. The learning modules consist of didactic model and learning form. The special feature of this work is the use of three-dimensional presentation in the service and schooling area of power systems.",1932-5517,1-4244-1296-X,10.1109/PES.2007.386078,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4275844,electrical engineering;virtual reality;learning scenarios;virtual seminar;e-learning,Power systems;Computer science education;Educational programs;Power system modeling;Virtual reality;Learning systems;Process control;Control systems;Engineering drawings;Computer aided instruction,computer aided instruction;computer based training;power engineering education;power system analysis computing;teaching;virtual reality,interactive computer-aided 3D virtual training;power system education;learning programs;virtual reality systems;electric plants;electric machines;didactic model;teaching scenario,,16,,9,,23-Jul-07,,,IEEE,IEEE Conferences
Design and construction of a Virtual Reality wire cut Electrical Discharge Machining system,Y. Kao; J. Tsai; H. Cheng; C. Chao,"Department of Mechanical Engineering, National Kaohsiung University of Applied Sciences, Kaohsiung City, Taiwan; Department of Computer Science and Information, Engineering, Far East University Tainan County, Taiwan; Department of Computer Science and Information, Engineering, Far East University Tainan County, Taiwan; Department of Mechanical Engineering, National Kaohsiung University of Applied Sciences, Kaohsiung City, Taiwan","2010 International Symposium on Computer, Communication, Control and Automation (3CA)",29-Jul-10,2010,2,,45,48,"Wire Electrical Discharge Machining (WEDM) uses a metallic wire to cut a product profile such as extrusion dies and blanking punches. The cost of possession and maintenance of the WEDM equipment is generally high. Hence, it is important to reduce the machine operation training cost, to provide simulation verification, and to investigate the correctness of the NC codes. This paper presents the development of a Virtual Reality (VR) based WEDM system which can emulate a real WEDM machine. The research result can be adopted to serve as a cost-effective tutoring system that has the benefits of improving the inefficient and dangerous drawbacks in operating the real machine. The developed system can provide an effective application in digital education and training environment for academics and industries.",2324-8017,978-1-4244-5568-3,10.1109/3CA.2010.5533343,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5533343,Virtual Reality (VR);Virtual Machine Tool;Digital Education and Training,Virtual reality;Wire;Design automation;Layout;Virtual machining;Costs;Industrial training;Object oriented modeling;Machine learning;Unified modeling language,blanking;computer based training;cutting;dyes;electrical discharge machining;extrusion;production engineering computing;virtual reality;wires,virtual reality wire cut electrical discharge machining system;wire electrical discharge machining;metallic wire;product profile;extrusion dies;blanking punches;simulation verification;cost-effective tutoring system;digital education;training environment,,2,,6,,29-Jul-10,,,IEEE,IEEE Conferences
The Introduction of a Novel Virtual Reality Training System for Gynecology Learning and Its User Experience Research,C. Chang; S. Yeh; M. Li; E. Yao,"School of Journalism, Fudan University, Shanghai, China; School of Information Science and Technology, Fudan University, Shanghai, China; Department of Psychology, Fudan University, Shanghai, China; Iforeal Intelligent Technology, Shanghai, China",IEEE Access,11-Apr-19,2019,7,,43637,43653,"The researchers of this study designed a new virtual reality (VR)-assisted training system, IFOREAL, for gynecology students at their university and introduced it to potential trainees. Two versions of IFOREAL, each employing different devices, were developed. The consumer version uses a traditional LCD display and computer mouse, whereas the professional version utilizes a head-mounted display (HMD) and joystick controller for the virtual learning. Trainees watched simulated videos and interacted with the system to accomplish tasks. IFOREAL consists of several major learning modules of gynecology. This study used the normal spontaneous delivery module to research user experience and perceptions of the IFOREAL VR training system. The results suggested that most of the trainees' user experiences and perceptions of IFOREAL, using both the types of VR-assisted technology, were positively reported. Trainees who used the consumer version of IFOREAL perceived a stronger internal control, whereas trainees using the professional version perceived a better sense of virtual presence. Overall, trainees perceived the usefulness of the IFOREAL system which predicted their future intention to use the system and other similar VR-assisted training systems for learning. Furthermore, whether the virtual content of IFOREAL grabbed the trainees' attention predicted their future intenon to use professional devices of HMD/joysck for learning other subjects. The gender difference was also explored in the study. Generally speaking, female trainees gave better evaluations of IFOREAL compared to their male counterparts. They perceived a better internal control while using the consumer version than the professional version. Male trainees believed that the gadgets used in the professional version provided a better virtual presence and met their expectation of a virtual experience better. This study suggested that different versions of IFOREAL could serve trainees' different needs. Technology developers and trainers should tailor the application of different VR devices to assist with the training/learning in accordance with different conditions/trainees.",2169-3536,,10.1109/ACCESS.2019.2905143,"Iforreal Intelligent Technology (Shanghai) Co., Ltd.; Fudan University; Xijia Great Education Technology Co., Ltd.; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8667417,Virtual reality;training/learning system;immersive and interactive design;user experience;acceptance and adoption of systems,Training;Gynecology;Visualization;Fetus;Standards;Videos;Pregnancy,biomedical education;computer based training;gynaecology;helmet mounted displays;interactive devices;medical computing;virtual reality,novel virtual reality training system;gynecology learning;user experience research;virtual reality-assisted training system;potential trainees;consumer version;computer mouse;professional version utilizes;joystick controller;virtual learning;research user experience;IFOREAL VR training system;VR-assisted technology;virtual presence;IFOREAL system;similar VR-assisted training systems;virtual content;female trainees;male trainees;virtual experience;VR devices,,7,,48,,14-Mar-19,,,IEEE,IEEE Journals
The Design and Evaluate of Virtual Reality Immersive Learning - the Case of Serious Game ‚ÄúCalcium Looping for Carbon Capture‚Äù,S. Wang; L. Liu; S. Wang,"The National Taipei University of Technology, Taipei, 10608, Taiwan; The National Taipei University of Technology, Taipei, 10608, Taiwan; The National Taipei University of Technology, Taipei, 10608, Taiwan",2018 International Conference on System Science and Engineering (ICSSE),4-Nov-18,2018,,,1,4,"This research focuses on design and evaluation of using virtual reality (VR) serious game for general science energy education immersive learning and uses the case study of learning knowledge from calcium looping carbon capture technology. The ARCS model of motivation design is used in this research as the core for promoting and sustaining motivation in the learning process. The domain knowledge of calcium looping carbon capture technology has been analyzed and integrated to develop a VR serious game. This research deployment a pilot study to 30 gifted students in an elementary school for collecting results by using questionnaire, drawing activities, and focus group interview. The five aspects of STEAM education that combine with the ARCS motivation model are then using for analyzing the results. The research results show that the VR immersive learning mechanism designed in this research can effectively trigger the motivation of learners for learning new knowledge as well as improve the learning results.",2325-0925,978-1-5386-6285-4,10.1109/ICSSE.2018.8520002,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8520002,Virtual Reality;Immersive learning;ARCS motivation model;Serious Game;STEAM education,Games;Education;Solid modeling;Calcium;Carbon;Virtual reality;Interviews,carbon capture and storage;computer aided instruction;evolution (biological);human factors;physics computing;serious games (computing);virtual reality,general science energy education immersive learning;calcium looping carbon capture technology;ARCS model;motivation design;learning process;domain knowledge;VR serious game;research deployment;pilot study;STEAM education;ARCS motivation model;VR immersive learning mechanism;learning results;virtual reality immersive learning;Calcium Looping for Carbon Capture,,,,8,,4-Nov-18,,,IEEE,IEEE Conferences
The research and education application of distributed virtual reality platform based on Web3D,R. Yang,"College of Communication, LinYi Normal University, LinYi, China",2010 2nd International Conference on Signal Processing Systems,23-Aug-10,2010,3,,V3-489,V3-492,"At present, many virtual learning communities are just simple two-dimensional replicas of former teaching materials, most virtual learning environments are not capable of realizing multi-person cooperation, and lots of educational researchers lack basics about computer network server programming. In addressing to these problems, first a Web3D-based distributed virtual reality platform is introduced and analyzed, then a general Web3D-based distributed virtual reality platform ABNet is introduced, finally its education application is elaborated, hoping to provide basis and references for the design of distributed virtual learning environments and the education application.",,978-1-4244-6893-5,10.1109/ICSPS.2010.5555718,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5555718,Web3D;Distributed Virtual Veality;Virtual Learning Environment,Education;Virtual environment;Avatars;Servers;Solid modeling;Art,computer aided instruction;Internet;virtual reality,education application;distributed virtual reality platform;Web3D;virtual learning communities;teaching materials;ABNet;computer network server programming,,,,13,,23-Aug-10,,,IEEE,IEEE Conferences
Using Eye Tracked Virtual Reality to Classify Understanding of Vocabulary in Recall Tasks,J. Orlosky; B. Huynh; T. Hollerer,Osaka University; Osaka University; University of California Santa Barbara,2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),27-Dec-19,2019,,,66,667,"In recent years, augmented and virtual reality (AR/VR) have started to take a foothold in markets such as training and education. Although AR and VR have tremendous potential, current interfaces and applications are still limited in their ability to recognize context, user understanding, and intention, which can limit the options for customized individual user support and the ease of automation. This paper addresses the problem of automatically recognizing whether or not a user has an understanding of a certain term, which is directly applicable to AR/VR interfaces for language and concept learning. To do so, we first designed an interactive word recall task in VR that required non-native English speakers to assess their knowledge of English words, many of which were difficult or uncommon. Using an eye tracker integrated into the VR Display, we collected a variety of eye movement metrics that might correspond to the user's knowledge or memory of a particular word. Through experimentation, we show that both eye movement and pupil radius have a high correlation to user memory, and that several other metrics can also be used to help classify the state of word understanding. This allowed us to build a support vector machine (SVM) that can predict a user's knowledge with an accuracy of 62% in the general case and and 75% for easy versus medium words, which was tested using cross-fold validation. We discuss these results in the context of in-situ learning applications.",,978-1-7281-5604-0,10.1109/AIVR46125.2019.00019,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942340,virtual reality;eye tracking;memory;cognition;pupillometry;classification,Measurement;Gaze tracking;Pupils;Virtual reality;Task analysis;Cognition;Head,augmented reality;computer aided instruction;gaze tracking;interactive systems;linguistics;support vector machines;user interfaces;vocabulary,concept learning;interactive word recall task;eye tracker;VR display;eye movement metrics;pupil radius;user memory;support vector machine;in-situ learning applications;virtual reality;vocabulary understanding classification;AR/VR interfaces;language learning,,2,,28,,27-Dec-19,,,IEEE,IEEE Conferences
Virtual reality sickness detection: an approach based on physiological signals and machine learning,N. Martin; N. Mathieu; N. Pallamin; M. Ragot; J. -M. Diverrez,"IRT b<>com,Cesson-Sevigne,France; Ubisoft,Montreuil,France; IRT b<>com,Cesson-Sevigne,France; IRT b<>com,Cesson-Sevigne,France; IRT b<>com,Cesson-Sevigne,France",2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),14-Dec-20,2020,,,387,399,"Virtual Reality (VR) is spreading to the general public but still has a major issue: VR sickness. To take it into consideration and minimize its occurrence, evaluation methods are required. The current methods are mainly based on subjective measurements and therefore have several drawbacks (e.g., non-continuous, intrusive). Physiological signals combined with Machine Learning (ML) methods seem an interesting approach to go beyond these limits. In this paper, we present a large-scale experimentation (103 participants) where physiological data (cardiac and electrodermal activities) and subjective data (perceived VR sickness) were gathered during 30-minute VR video game sessions. Using ML methods, models were trained to predict VR sickness level (based on the physiological data labeled with the subjective data). Results showed an explained variance up to 75% (in a regression approach) and an accuracy up to 91% (in a classification approach). Despite generalization issues, this method seems promising and valuable for a real time, automatic and continuous evaluation of VR sickness, based on physiological signals and ML models.",1554-7868,978-1-7281-8508-8,10.1109/ISMAR50242.2020.00065,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284654,H.1.2 [Models and principles]: User/Machine Systems;Human factors;I.3.6 [Computer graphics]: Methodology and Techniques;Ergonomics,Solid modeling;Machine learning;Games;Predictive models;Particle measurements;Physiology;Real-time systems,ergonomics;learning (artificial intelligence);regression analysis;virtual reality,machine learning;general public;evaluation methods;subjective measurements;physiological signals;large-scale experimentation;subjective data;perceived VR sickness;30-minute VR video game sessions;VR sickness level;physiological data;regression approach;classification approach;generalization issues;automatic evaluation;continuous evaluation;ML models;virtual reality sickness detection,,,,133,,14-Dec-20,,,IEEE,IEEE Conferences
K-12 VR Applications Based on ViveFocus Platform,C. Zhang; X. Wen; W. Yao,NA; NA; NA,2018 International Conference on Virtual Reality and Visualization (ICVRV),26-Aug-19,2018,,,135,135,"In the traditional teaching mode, students generally learn knowledge through words and pictures. This method sometimes increases the difficulty of learning and reduces the efficiency of learning because it is not intuitive. We explore a new teaching model that applies virtual reality technology to K-12 education to change the traditional teaching method. In this article, we use the two knowledge points of science and Chinese(the shape of the earth, and poem Snow) to display in the form of virtual reality, providing students with an immersive and rich sensory experience, deepening Students' memory and understanding of knowledge points.",2375-141X,978-1-5386-8497-9,10.1109/ICVRV.2018.00043,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8710846,"Virtual Reality, education, K-12",Virtual reality;Visualization,computer aided instruction;teaching;virtual reality,sensory experience;students memory;K-12 VR applications;immersive experience;virtual reality technology;teaching model;traditional teaching mode;ViveFocus platform;knowledge points,,,,0,,26-Aug-19,,,IEEE,IEEE Conferences
Explore Convolutional Neural Networks in Virtual Reality,N. Meissler; A. Wohlan; N. Hochgeschwender; A. Schreiber,German Aerospace Center (DLR); German Aerospace Center (DLR); German Aerospace Center (DLR); German Aerospace Center (DLR),2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),27-Dec-19,2019,,,249,2491,We visualize the functionality of Convolutional Neural Networks (CNN) in Virtual Reality to help newcomers understand the general functioning of these algorithms. Our interactive visualization allows users to explore CNNs layer by layer.,,978-1-7281-5604-0,10.1109/AIVR46125.2019.00056,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942281,virtual-reality;neural-networks;interactive-learning,Visualization;Conferences;Virtual reality;Learning (artificial intelligence);Convolutional neural networks,convolutional neural nets;data visualisation;virtual reality,convolutional neural networks;virtual reality;general functioning;interactive visualization;CNN,,,,4,,27-Dec-19,,,IEEE,IEEE Conferences
Group immersive education with digital fulldome planetariums,K. C. Yu; K. Saham; V. Sahami; L. Sessions; G. Denn,"Denver Museum of Nature & Science, USA; Metropolitan State University of Denver, USA; Metropolitan State University of Denver, USA; Metropolitan State University of Denver, USA; Metropolitan State University of Denver, USA",2017 IEEE Virtual Reality (VR),6-Apr-17,2017,,,237,238,"Although fulldome video digital theaters evolved from traditional plan√©tariums, they are more akin to virtual reality (VR) theaters that create large-scale, group immersive experiences. In order to help understand how immersion and wide fields-of-view (FOV) impact learning, we studied the use of visualizations on topics that do and do not require spatial understanding in astronomy classes. We find a significant difference between students who viewed visualizations in the dome versus those that saw non-immersive content in their classrooms, with the former showing the greatest retention. Our results suggest that immersive visuals help free up cognitive resources that can be used to build mental models requiring spatial understanding, and the physical display size combined with the wide FOV may result in greater attention. Although fulldome is a complementary medium to traditional VR, our results have implications for future head-mounted displays.",2375-5334,978-1-5090-6647-6,10.1109/VR.2017.7892264,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892264,1.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism ‚Äî Virtual reality;1.4.0 [Image Processing and Computer Vision]: General ‚Äî Image displays,Visualization;Education;Astronomy;Virtual environments;Three-dimensional displays;Cognitive science,virtual reality,group immersive education;digital fulldome planetariums;virtual reality;cognitive resources;FOV;fulldome video digital theaters,,,,15,,6-Apr-17,,,IEEE,IEEE Conferences
Can Virtual Reality Enhance Learning: A Case Study in Materials Science,V. Caro; B. Carter; S. Dagli; M. Schissler; J. Millunchick,"Materials Science and Engineering, University of Michigan, Ann Arbor, Michigan, USA; Materials Science and Engineering, University of Michigan, Ann Arbor, Michigan, USA; Materials Science and Engineering, University of Michigan, Ann Arbor, Michigan, USA; Stamps School of Art & Design, University of Michigan, Ann Arbor, Michigan, USA; Materials Science and Engineering, University of Michigan, Ann Arbor, Michigan, USA",2018 IEEE Frontiers in Education Conference (FIE),7-Mar-19,2018,,,1,4,"This Innovative Practice Work in Progress tests whether virtual reality (VR) can enhance students' understanding in scientific fields, specifically Materials Science and Engineering (MSE), when compared to more traditional approaches. Of interest is how VR-based learning activities impact the performance of individuals with experience ranging from none to expert level in MSE compared to paper-based learning activities. To test this, an activity related to crystal structures, similar to what students would see in an introductory level MSE course, was administered to a group of students with varying knowledge levels in MSE. Each participant completed the same worksheet in either VR or on paper. The testing group was composed of seven students, which was too small of a sample size to draw definitive conclusions, yet significant observations could be made. On questions that required recall of prior knowledge, participants using paper-based activities generally performed better, whereas on questions requiring more spatial reasoning and critical thinking, VR participants generally performed better. Most of the participants reported enjoying the VR activities and platform, indicating high usability. These results suggest that VR may be beneficial in teaching complex spatial concepts.",2377-634X,978-1-5386-1174-6,10.1109/FIE.2018.8659267,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8659267,Virtual Reality;Engineering;Education;Materials;Science,Materials science and technology;Virtual reality;Crystals;Education;Three-dimensional displays;Solid modeling;Computational modeling,computer aided instruction;materials science;materials science computing;teaching;virtual reality,Innovative Practice Work;scientific fields;expert level;crystal structures;paper-based activities;VR participants;VR activities;virtual reality enhance learning;knowledge levels;Materials Science and Engineering;introductory level MSE course,,,,11,,7-Mar-19,,,IEEE,IEEE Conferences
Development and application of a surgical process simulation system using VR technology,L. Zhou; R. Sato,"Osaka Electro-Communication University,Faculty of Information Science and Arts,Department of Digital Games,Shijonawateshi,Osaka,Japan; Osaka Electro-Communication University,Faculty of Information Science and Arts,Department of Digital Games,Shijonawateshi,Osaka,Japan",2020 IEEE 9th Global Conference on Consumer Electronics (GCCE),21-Dec-20,2020,,,655,657,"For medical students, instruction via on-site observation of surgery is often a mandatory part of their training. Being present in an operating room allows students to deepen their understanding of various surgical procedures while giving them an opportunity to experience the hands-on environment and general atmosphere. However, traditional instruction methods through observation contain many disadvantages that make learning surgical procedures difficult and problematic. For example, during long sessions of endoscopic surgery, the pictures taken display only a small portion of the internal body, making it difficult for students to fully understand the details of the entire process. Locating the positions of internal organs and understanding the direction of instrument movement is also inconvenient. However, with the aid of a virtual reality support system, students can learn through real-time interactive demonstrations of the surgical process that include details about operating position and other specificities. The result is increased accessibility to facilitate the understanding of the entire surgery process coupled with the reduction of fatigue and other distractions that arise from prolonged observation in a traditional operating room. So far, in medical research, the ""Production of patient explanation video for transrectal prostate biopsy"" jointly researched and produced with the Department of Renal Urology, Kansai Medical University, has been reviewed by the Research Ethics Review Board (IRB) and obtained permission for use Later, through actual use by patients and medical practitioners, great results have been obtained.",2378-8143,978-1-7281-9802-6,10.1109/GCCE50665.2020.9291758,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9291758,Robot-assisted laparoscopic radical prostatectomy;surgical apprenticeship for medical students;virtual reality support;Process Demonstration System,Training;Solid modeling;Surgery;Virtual reality;Production;Real-time systems;Robots,biological organs;biomedical education;cancer;computer aided instruction;endoscopes;medical computing;medical robotics;surgery;virtual reality,surgical process simulation system;VR technology;medical students;on-site observation;mandatory part;surgical procedures;hands-on environment;general atmosphere;traditional instruction methods;long sessions;endoscopic surgery;internal body;internal organs;instrument movement;virtual reality support system;real-time interactive demonstrations;operating position;entire surgery process;prolonged observation;traditional operating room;medical research;Kansai Medical University;medical practitioners,,,,4,,21-Dec-20,,,IEEE,IEEE Conferences
The Use of Virtual Reality as the Object of Mathematics Learning,B. V. Frade; P. H. C. C. Gondim; P. Moises De Sousa,"Cienc. Exatas e TecnoIogicas, Univ. Fed. de VicŒøsa, Rio Paranalba, Brazil; Cienc. Exatas e TecnoIogicas, Univ. Fed. de VicŒøsa, Rio Paranalba, Brazil; Cienc. Exatas e TecnoIogicas, Univ. Fed. de VicŒøsa, Rio Paranalba, Brazil",2015 XVII Symposium on Virtual and Augmented Reality,26-Oct-15,2015,,,137,141,"Combining education the fun, it designed are creational / educational game, in order to support the idea that the teacher must have the knowledge to develop and find new, more appropriate teaching strategies to help in the learning ability of students, It emphasized that the use of technology, specifically the integrated virtual reality tithe concept of learning object, together with the knowledge presented by teachers and traditional teaching methods, there may be changes and improvements in the learning capacity of students. Therefore, it is expected that the game can be used as a learning object in mathematics education, improving the performance of students during their school year and evaluation programs of knowledge of Brazilian education in general.",,978-1-4673-7204-6,10.1109/SVR.2015.27,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7300739,games;education;virtual reality;mathematics,Software;Games;Education;Virtual reality;Mathematics;Visualization;Rabbits,computer aided instruction;computer games;mathematics computing;teaching;virtual reality,virtual reality;educational game;teaching strategies;mathematics education;Brazilian education,,1,,11,,26-Oct-15,,,IEEE,IEEE Conferences
Virtual Reality Video Game Paired with Physical Monocular Blurring as Accessible Therapy for Amblyopia,O. Hurd; S. Kurniawan; M. Teodorescu,"University of California, Santa Cruz; University of California, Santa Cruz; University of California, Santa Cruz",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,492,499,"This paper discusses a virtual reality (VR) therapeutic video game for treatment of the neurological eye disorder, Amblyopia. Amblyopia is often referred to as lazy eye, and it entails weaker vision in one eye due to a poor connection between the eye and the brain. Until recently it was thought to be untreatable in adults, but new research has proven that with consistent therapy even adults can improve their Amblyopia, especially through perceptual learning and video games. Even so, therapy compliance remains low due to the fact that conventional therapies are perceived as either invasive, dull and/or boring. Our game aims to make Amblyopia therapy more immersive, enjoyable and playful. The game was perceived by our users to be a fun and accessible alternative, as it involves adhering a Bangerter foil (an opaque sticker) on a VR headset to blur vision in an Amblyopic person's dominant eye while having them playa VR video game. To perform well in the video game, their brain must adapt to rely on seeing with their weaker eye, thereby reforging that neurological connection. While testing our game, we also studied users behavior to investigate what visual and kinetic components were more effective therapeutically. Our findings generally show positive results, showing that visual acuity in adults increases with 45 minutes of therapy. Amblyopia has many negative symptoms including poor depth perception (nec-essary for daily activities such as driving), so this therapy could be life changing for adults with Amblyopia.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8797997,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797997,Visual acuity‚ÄîVisual stereopsis‚ÄîLogMAR‚ÄîCrowding,Games;Vision defects;Medical treatment;Visualization;Virtual reality;Headphones;Testing,computer games;eye;medical computing;neurophysiology;patient treatment;virtual reality;vision;vision defects;visual perception,accessible therapy;virtual reality therapeutic video game;neurological eye disorder;lazy eye;consistent therapy;Amblyopia therapy;Amblyopic person;playa VR video game;weaker eye;VR headset;kinetic components;visual components;depth perception,,,,31,,15-Aug-19,,,IEEE,IEEE Conferences
Using Visualization of Convolutional Neural Networks in Virtual Reality for Machine Learning Newcomers,N. Meissler; A. Wohlan; N. Hochgeschwender; A. Schreiber,German Aerospace Center (DLR); German Aerospace Center (DLR); German Aerospace Center (DLR); German Aerospace Center (DLR),2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),27-Dec-19,2019,,,152,1526,"Software systems and components are increasingly based on machine learning methods, such as Convolutional Neural Networks (CNNs). Thus, there is a growing need for common programmers and machine learning newcomers to understand the general functioning of these algorithms. However, as neural networks are complex in nature, novel presentation means are required to enable rapid access to the functionality. For that purpose, we examine how CNNs can be visualized in Virtual Reality (VR), as it offers the opportunity to focus users on content through effects such as immersion and presence. With a first exploratory study, we confirmed that our visualization approach is both intuitive to use and conductive to learning. Moreover, users indicated an increased motivation to learning due to the unusual virtual environment. Based on our findings, we propose a follow-up study that specifically compares the benefits of a virtual visualization approach to a traditional desktop visualization.",,978-1-7281-5604-0,10.1109/AIVR46125.2019.00031,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942366,"neural networks, visualization, virtual reality, knowledge learning",Data visualization;Visualization;Virtual environments;Neurons;Convolutional neural networks,convolutional neural nets;data visualisation;learning (artificial intelligence);virtual reality,convolutional neural networks;virtual reality;machine learning newcomers;machine learning methods;CNNs,,1,,32,,27-Dec-19,,,IEEE,IEEE Conferences
A review of tele-immersive applications in the CAVE research network,J. Leigh; A. E. Johnson; T. A. DeFanti; M. Brown; M. D. Ali; S. Bailey; A. Banerjee; P. Benerjee; Jim Chen; K. Curry; J. Curtis; F. Dech; B. Dodds; I. Foster; S. Fraser; K. Ganeshan; D. Glen; R. Grossman; R. Heiland; J. Hicks; A. D. Hudson; T. Imai; M. A. Khan; A. Kapoor; R. V. Kenyon; J. Kelso; R. Kriz; C. Lascara; X. Liu; Y. Lin; T. Mason; A. Millman; K. Nobuyuki; K. Park; B. Parod; P. J. Rajlich; M. Rasmussen; M. Rawlings; D. H. Robertson; S. Thongrong; R. J. Stein; K. Swartz; S. Tuecke; H. Wallach; Hong Yee Wong; G. H. Wheless,"Nat. Center for Supercomput. Appl., Illinois Univ., Urbana, IL, USA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA",Proceedings IEEE Virtual Reality (Cat. No. 99CB36316),6-Aug-02,1999,,,180,187,"This paper presents an overview of the tele-immersion applications that have been built by collaborators around the world using the CAVERNsoft toolkit, and the lessons learned from building these applications. In particular the lessons learned are presented as a set of rules-of-thumb for developing tele-immersive applications in general.",1087-8270,0-7695-0093-5,10.1109/VR.1999.756949,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=756949,,Intelligent networks;Laboratories;Visualization;Virtual reality;Collaborative work;Virtual environment;Image databases;Industrial training;Computer networks;Sea measurements,virtual reality;groupware;teleconferencing;user interfaces;application generators,tele-immersive applications;CAVE research network;CAVERNsoft toolkit;videoconferencing;collaborative virtual reality,,37,17,18,,6-Aug-02,,,IEEE,IEEE Conferences
On Benchmarking Iris Recognition within a Head-mounted Display for AR/VR Applications,F. Boutros; N. Damer; K. Raja; R. Ramachandra; F. Kirchbuchner; A. Kuijper,"Mathematical and Applied Visual Computing, TU Darmstadt,Darmstadt,Germany; Mathematical and Applied Visual Computing, TU Darmstadt,Darmstadt,Germany; Norwegian Biometrics Laboratory, NTNU,Gjovik,Norway; Norwegian Biometrics Laboratory, NTNU,Gjovik,Norway; Mathematical and Applied Visual Computing, TU Darmstadt,Darmstadt,Germany; Mathematical and Applied Visual Computing, TU Darmstadt,Darmstadt,Germany",2020 IEEE International Joint Conference on Biometrics (IJCB),6-Jan-21,2020,,,1,10,"Augmented and virtual reality is being deployed in different fields of applications. Such applications might involve accessing or processing critical and sensitive information, which requires strict and continuous access control. Given that Head-Mounted Displays (HMD) developed for such applications commonly contains internal cameras for gaze tracking purposes, we evaluate the suitability of such setup for verifying the users through iris recognition. In this work, we first evaluate a set of iris recognition algorithms suitable for HMD devices by investigating three well-established handcrafted feature extraction approaches, and to complement it, we also present the analysis using four deep learning models. While taking into consideration the minimalistic hardware requirements of stand-alone HMD, we employ and adapt a recently developed miniature segmentation model (EyeMMS) for segmenting the iris. Further, to account for non-ideal and non-collaborative capture of iris, we define a new iris quality metric that we termed as Iris Mask Ratio (IMR) to quantify the iris recognition performance. Motivated by the performance of iris recognition, we also propose the continuous authentication of users in a non-collaborative capture setting in HMD. Through the experiments on a publicly available OpenEDS dataset, we show that performance with EER = 5% can be achieved using deep learning methods in a general setting, along with high accuracy for continuous user authentication.",2474-9699,978-1-7281-9186-7,10.1109/IJCB48548.2020.9304919,"German Federal Ministry of Education and Research and the Hessen State Ministry for Higher Education, Research; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9304919,,Iris recognition;Resists;Feature extraction;Image segmentation;Cameras;Pupils;Authentication,authorisation;biometrics (access control);feature extraction;helmet mounted displays;image recognition;iris recognition;learning (artificial intelligence);virtual reality,recently developed miniature segmentation model;minimalistic hardware requirements;deep learning models;HMD devices;iris recognition algorithms;gaze tracking purposes;internal cameras;Head-Mounted Displays;continuous access control;strict access control;sensitive information;critical information;virtual reality;augmented reality;Head-mounted display;benchmarking Iris recognition;continuous user authentication;noncollaborative capture setting;iris recognition performance;Iris Mask Ratio;iris quality,,,,50,,6-Jan-21,,,IEEE,IEEE Conferences
Using Virtual Reality to Enhance Learning in a Chinese Architectures Course: A Flipped Classroom Approach,S. W. T. Im; P. H. P. Chiu; C. H. Shek; M. Ng; L. Li,"Office of Education Development and Gateway Education, City University of Hong Kong, Hong Kong SAR; Office of Education Development and Gateway Education, City University of Hong Kong, Hong Kong SAR; Office of Education Development and Gateway Education, City University of Hong Kong, Hong Kong SAR; Office of Education Development and Gateway Education, City University of Hong Kong, Hong Kong SAR; Chinese Civilization Centre, City University of Hong Kong, Hong Kong SAR","2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)",17-Jan-19,2018,,,624,629,"This paper reports a flipped classroom strategy to encourage students to adopt self-learning and peer-learning pedagogies, by using virtual reality technologies to provide immersive environment for the learners. A course of General Education modules in the Arts and Humanities area was selected to design relevant teaching and learning activities. It has always been a challenge to plan activities that engage students from different colleges and departments to learn architectural terminologies. All students enrolled in this module were requested to accomplish VR group activities with assigned mini-tasks, and a questionnaire to assess their perceived learning experience. Also, feedbacks from the survey in open-ended questions of this cohort were collected and analysed qualitatively.",2470-6698,978-1-5386-6522-0,10.1109/TALE.2018.8615369,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8615369,technology-enhanced learning;virtual reality;Chinese architectures;flipped learning,5G mobile communication;Australia;Conferences;Education,architecture;computer aided instruction;educational courses;structural engineering computing;teaching;virtual reality,chinese architectures course;flipped classroom approach;flipped classroom strategy;peer-learning pedagogies;virtual reality technologies;immersive environment;General Education modules;relevant teaching;plan activities;architectural terminologies;VR group activities;perceived learning experience;colleges,,2,,16,,17-Jan-19,,,IEEE,IEEE Conferences
Does virtual reality affect visual perception of egocentric distance?,T. Rousset; C. Bourdin; C. Goulon; J. Monnoyer; J. Vercher,"Aix Marseille Universit√©, CNRS, ISM UMR 7287, 13288, Marseille, France; Aix Marseille Universit√©, CNRS, ISM UMR 7287, 13288, Marseille, France; Aix Marseille Universit√©, CNRS, ISM UMR 7287, 13288, Marseille, France; PSA Peugeot Citro√´n, Velizy Villacoublay; Aix Marseille Universit√©, CNRS, ISM UMR 7287, 13288, Marseille, France",2015 IEEE Virtual Reality (VR),27-Aug-15,2015,,,277,278,"Virtual reality (driving simulators) tends to generalize for the study of human behavior in mobility. It is thus crucial to ensure that perception of space and motion is little or not affected by the virtual environment (VE). The aim of this study was to determine a metrics of distance perception in VEs and whether this metrics depends on interactive factors: stereoscopy and motion parallax. After a training session, participants were asked, while driving, to estimate the relative location (5 to 80 m) of a car on the same road. The overall results suggest that distance perception in this range does not depend on interactive factors. In average, as generally reported, subjects underestimated the distances whatever the vision conditions. However, the study revealed a large interpersonal variability: two profiles of participants were defined, those who quite accurately perceived distances in VR and those who underestimated distances as usually reported. Overall, this classification was correlated to the level of performance of participants during the training phase. Furthermore, learning performance is predictive of the behavior of participants.",2375-5334,978-1-4799-1727-3,10.1109/VR.2015.7223403,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223403,Driving simulation;distance perception;stereoscopy;parallax;variability,Virtual environments;Training;Vehicles;Measurement;Roads;Three-dimensional displays,human factors;traffic engineering computing;virtual reality,virtual reality;visual perception;egocentric distance;driving simulators;human behavior;space perception;motion perception;virtual environment;distance perception;VE;stereoscopy factor;motion parallax factor;interpersonal variability,,1,,8,,27-Aug-15,,,IEEE,IEEE Conferences
Level of Presence in Max Where Virtual Reality,B. Berki,"Sz√©chenyi Istv√¢n University, Doctoral School of Multidisciplinary Engineering Sciences,Gy≈ër,Hungary",2020 11th IEEE International Conference on Cognitive Infocommunications (CogInfoCom),2-Nov-20,2020,,,485,490,"Presence is the sense of being inside a virtual environment, that can be experienced also in desktop virtual realities not only in full-immersive VRs. MaxWhere is a desktop virtual reality that is used in education and for collaborative work. This VR can be considered as a 3D browser because in the space there are several smartboards where any web-content, document, or image can be displayed. This study compares the sense of presence in MaxWhere virtual reality to other desktop virtual realities with the Igroup Presence Questionnaire. This VR is in focus of numerous scientific research, thus this comparison of presence level could be a great starting point for them. The analysis showed that the level of presence in MaxWhere virtual reality corresponds to the average presence level in other desktop virtual realities. The analysis of the presence profile has shown that the general sense of presence and the spatial presence are relatively high in this VR. The experienced realism scale is the lowest because this VR is designed to foster working and learning inside the virtual space and not for having a high fidelity.",2380-7350,978-1-7281-8213-1,10.1109/CogInfoCom50765.2020.9237826,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237826,virtual reality;presence;desktop virtual reality;IPQ,Three-dimensional displays;Conferences;Education;Virtual environments;Virtual reality;Collaborative work;Browsers,virtual reality,MaxWhere virtual reality;Igroup presence questionnaire;desktop virtual reality;virtual environment;virtual space;VR,,,,26,,2-Nov-20,,,IEEE,IEEE Conferences
Age and technology: Adult learning performance in desktop virtual reality environments,D. Steele; S. Fulbright; A. N. Nichols,"College of Applied Science and Technology University of Arkansas Fort Smith; Surgical Technology University of Arkansas Fort Smith; Computer-Aided Drafting & Design, University of Arkansas Fort Smith",2010 IEEE Frontiers in Education Conference (FIE),23-Dec-10,2010,,,S1F-1,T1A-3,"The research project was conducted by the University of Arkansas Fort Smith (UAFS) and the Occupational Education virtual reality research team at Oklahoma State University with the purpose of the learning effects of desktop virtual reality (VR) in college and technical training. Participants were from the UAFS two year surgical Technicians program and students from a career tech center. The paper presents findings from a five-year program of research on desktop virtual reality (VR) in college and technical education and describes what the research team has discovered to be important factors in its successful implementation. It defines desktop VR, outlines theoretical and empirical foundations for desktop VR research, summarizes important findings from research on desktop VR in technical education, and draws conclusions regarding implementation and further research in this field.",2377-634X,978-1-4244-6262-9,10.1109/FIE.2010.5673624,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5673624,VR/VEs;ATI;Supplantation Theory;General Efficacy;SPT1,Virtual reality;Computers;Training;Navigation;Solid modeling;Surgery,computer aided instruction;educational institutions;engineering education;further education;virtual reality,adult learning performance;desktop virtual reality environments;University of Arkansas Fort Smith;occupational education virtual reality research team;Oklahoma state university;college training;technical training;surgical technicians program;career tech center;technical education,,1,,4,,23-Dec-10,,,IEEE,IEEE Conferences
Design and Evaluate Immersive Learning Experience for Massive Open Online Courses (MOOCs),H. H. S. Ip; C. Li; S. Leoni; Y. Chen; K. Ma; C. H. Wong; Q. Li,"Department of Computer Science, AIMtech Centre, City University of Hong Kong, Hong Kong; Department of Computer Science, AIMtech Centre, City University of Hong Kong, Hong Kong; AIMtech Centre, City University of Hong Kong, Hong Kong; Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Chinese and History, City University of Hong Kong, Kowloon Tong, Hong Kong; Department of Chinese and History, City University of Hong Kong, Kowloon Tong, Hong Kong; Department of Computer Science, City University of Hong Kong, Hong Kong",IEEE Transactions on Learning Technologies,17-Dec-19,2019,12,4,503,515,"Massive open online courses (MOOCs), a unique form of online education enabled by web-based learning technologies, allow learners from anywhere in the world with any level of educational background to enjoy online education experience provided by many top universities all around the world. Traditionally, MOOC learning contents are always delivered as text-based or video-based materials. Although introducing immersive learning experience for MOOCs may sound exciting and potentially significative, there are a number of challenges given this unique setting. In this paper, we present the design and evaluation methodologies for delivering immersive learning experience to MOOC learners via multiple media. Specifically, we have applied the techniques in the production of a MOOC entitled Virtual Hong Kong: New World, Old Traditions, led by AIMtech Centre, City University of Hong Kong, which is the first MOOC (as our knowledge) that delivers immersive learning content for distant learners to appreciate and experience how the traditional culture and folklore of Hong Kong impact upon the lives of its inhabitants in the 21st Century. The methodologies applied here can be further generalized as the fundamental framework of delivering immersive learning for future MOOCs.",1939-1382,,10.1109/TLT.2018.2878700,City University of Hong Kong; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8515107,Massive open online course;virtual reality;immersive learning;e-learning.,Solid modeling;Education courses;Virtual environments;Urban areas;Information and communication technology,computer aided instruction;distance learning;educational courses,massive open online courses;unique form;educational background;online education experience;MOOC learning contents;video-based materials;immersive learning experience;evaluation methodologies;MOOC learners;immersive learning content;future MOOCs;Web-based learning technologies;text-based materials,,4,,52,IEEE,30-Oct-18,,,IEEE,IEEE Journals
"A comparison of virtual reality and active video game usage, attitudes and learning needs among therapists in Canada and the US",D. E. Levac; S. Glegg; S. Pradhan; E. J. Fox; D. Espy; E. Chicklis; J. E. Deutsch,"Northeastern University,Dept. of Physical Therapy,Boston,USA; Sunny Hill Health Centre for Children,Therapy Department,Vancouver,Canada; University of Washington,Div. of Physical Therapy,Seattle,USA; University of Florida,Dept. of Physical Therapy,Gainesville,FL; Cleveland State University,Dept. of Health Sciences,Cleveland,USA; Northeastern University,Rehabilitation Games & Virtual Reality Lab,Boston,MA; Rutgers University,Dept. of Rehab & Movement Sciences,Newark,USA",2019 International Conference on Virtual Rehabilitation (ICVR),13-Feb-20,2019,,,1,7,"Differences in health care funding and policies between the United States and Canada may influence uptake of and attitudes towards virtual reality (VR) and active video gaming (AVG) systems by physical (PTs) and occupational therapists (OTs) in each country. The purpose of this study was to undertake a cross-country comparison of VR/AVG uptake to inform the content of educational interventions designed to promote implementation of these technologies into practice. A cross-sectional online survey that included the Assessing Determinants of Prospective Take-up of Virtual Reality (version 2; ADOPT-VR2) Instrument was conducted in 2014-2015 (Canada) and replicated in 2017-2018 (US). Recruitment took place via convenience and snowball sampling, using email, social media and newsletter postings. Therapists in the US reported greater past experience with, current use of, and intention to use VR/AVGs than did those in Canada. They also rated facilitators more positively and barriers less negatively. Use of customized VR systems was low, with specific system prevalence differing between countries. The most frequently used AVG systems, populations and settings of use, functional goals, predictors of use, learning needs and preferred forms of support were similar between countries. These similarities support the generalizability of educational interventions for both countries. Materials to be developed will focus on non-customized AVG systems. Subsequent work will examine how uptake relates to country-specific health care funding and policies, probe differences in learning needs between therapists with experience using customized versus non-customized VR/AVG systems, and extend the survey to other countries where VR/AVG use is prevalent.",2331-9569,978-1-7281-1285-5,10.1109/ICVR46560.2019.8994624,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994624,virtual reality;active video games;rehabilitation;survey;knowledge translation,,biomedical education;computer aided instruction;computer games;health care;medical information systems;virtual reality,virtual reality;active video game usage;Canada;US;occupational therapists;cross-country comparison;educational interventions;cross-sectional online survey;ADOPT-VR2;social media;newsletter postings;customized VR systems;noncustomized AVG systems;country-specific health care funding;system prevalence;PT,,1,,21,,13-Feb-20,,,IEEE,IEEE Conferences
Virtual Reality for Robots,M. Suomalainen; A. Q. Nilles; S. M. LaValle,"University of Oulu,Center of Ubiquitous Computing,Faculty of Information Technology and Electrical Engineering,Finland; University of Illinois at Urbana-Champaign,Department of Computer Science,Illinois,USA; University of Oulu,Center of Ubiquitous Computing,Faculty of Information Technology and Electrical Engineering,Finland",2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),10-Feb-21,2020,,,11458,11465,"This paper applies the principles of Virtual Reality (VR) to robots, rather than living organisms. A simulator, of either physical states or information states, renders outputs to custom displays that fool the robot's sensors. This enables a robot to experience a combination of real and virtual sensor inputs, combining the efficiency of simulation and the benefits of real world sensor inputs. Thus, the robot can be taken through targeted experiences that are more realistic than pure simulation, yet more feasible and controllable than pure real-world experiences. We define two distinctive methods for applying VR to robots, namely black box and white box; based on these methods we identify potential applications, such as testing and verification procedures that are better than simulation, the study of spoofing attacks and anti-spoofing techniques, and sample generation for machine learning. A general mathematical framework is presented, along with a simple experiment, detailed examples, and discussion of the implications.",2153-0866,978-1-7281-6212-6,10.1109/IROS45743.2020.9341344,Business Finland; Academy of Finland; National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9341344,,Solid modeling;Virtual reality;Sensor fusion;Robot sensing systems;Sensors;Robots;Testing,control engineering computing;learning (artificial intelligence);rendering (computer graphics);sensors;virtual reality,Virtual Reality;VR;physical states;information states;renders outputs;custom displays;virtual sensor inputs;world sensor inputs;targeted experiences;pure simulation;real-world experiences;simple experiment;Virtual reality,,,,41,,10-Feb-21,,,IEEE,IEEE Conferences
Architectural design for the 3D virtual Radiology Department using Virtual reality technology,A. Boukerche; A. Al Hamidi; R. Pazzi; L. Ahmad,"Paradise Research Lab, School of Information Technology and Engineering (SITE), University of Ottawa, Canada; Paradise Research Lab, School of Information Technology and Engineering (SITE), University of Ottawa, Canada; Paradise Research Lab, School of Information Technology and Engineering (SITE), University of Ottawa, Canada; Paradise Research Lab, School of Information Technology and Engineering (SITE), University of Ottawa, Canada",2009 IEEE Workshop on Computational Intelligence in Virtual Environments,15-May-09,2009,,,45,52,"Web based Virtual reality application can be helpful in many real world applications such as education, virtual conferences, entertainment. Observing the progress of the gaming industry over the years can show the advancement in virtual reality web application and virtual environments clearly. In this paper, we present a virtual hospital in the form of a 3D virtual environment. This virtual environment depicts the Department of Radiology at Ottawa General Hospital where learners experiment on radiology equipment by carrying out specific learning scenarios we apply our proposed architecture on a test bed that consists of a cancer treatment scenario within a 3D virtual Radiology Department. We will incorporate the High Level Architecture HLA standard as an important corner stone in allowing the e-learning environment to be distributed and interactive.",,978-1-4244-2772-7,10.1109/CIVE.2009.4926317,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4926317,,Radiology;Virtual reality;Virtual environment;Hospitals;Computed tomography;Electronic learning;Computational modeling;Diagnostic radiography;Medical simulation;Industrial training,biomedical education;computer aided instruction;virtual reality,architectural design;3D Virtual Radiology Department;virtual reality technology;gaming industry;Ottawa General Hospital;cancer treatment scenario;high level architecture;HLA standard;e-learning,,1,,15,,15-May-09,,,IEEE,IEEE Conferences
Reducing latency when using Virtual Reality for teaching in sport,Y. H. P. Iskandar; L. Gilbert; G. B. Wills,"Learning Technologies Research Group, Electronics & Computer Science, University of Southampton, SO17 IBJ, United Kingdom; Learning Technologies Research Group, Electronics & Computer Science, University of Southampton, SO17 IBJ, United Kingdom; Learning Technologies Research Group, Electronics & Computer Science, University of Southampton, SO17 IBJ, United Kingdom",2008 International Symposium on Information Technology,26-Sep-08,2008,3,,1,5,"Latency is a frequently cited shortcoming of virtual reality (VR) applications. To compensate for excessive latency, prediction mechanisms may use sophisticated mathematical algorithms, which may not be appropriate for complex virtual teaching applications. This paper suggests that heuristic prediction algorithms could be used to develop more effective and general systems for VR educational applications. A fast synchronization squash simulation illustrates where heuristic prediction can be used to deal with latency problems.",2155-899X,978-1-4244-2327-9,10.1109/ITSIM.2008.4632076,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4632076,,Prediction algorithms;Heuristic algorithms;Humans;Training;Education;Algorithm design and analysis;Virtual environment,computer aided instruction;digital simulation;optimisation;sport;teaching;virtual reality,latency reduction;virtual reality;sport teaching;mathematical algorithms;complex virtual teaching applications;heuristic prediction algorithms;synchronization squash simulation,,,,26,,26-Sep-08,,,IEEE,IEEE Conferences
Fidelity in Simulation-Based Serious Games,X. Ye; P. Backlund; J. Ding; H. Ning,"School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; University of Skovde, Skovde, Sweden; University of Skovde, Skovde, Sweden; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China",IEEE Transactions on Learning Technologies,18-Jun-20,2020,13,2,340,353,"The extensive use of simulation-based serious games (SSGs) has made a revolution in educational techniques. As a potentially significant feature for SSG design and evaluation, the term fidelity (the similarity between an SSG and its real reference) emerges and attracts increasing attention. The study of fidelity not only benefits the design, development, and analysis of an SSG with the consideration of improving the learning effect but also contributes to the investment reduction of an SSG. However, the term fidelity is used inconsistently in the current literature. The introduction of new technologies (e.g., virtual reality) and the blend of multiform SSGs also facilitate the extension of fidelity with new connotations. All lead to confusing concepts and vague measure metrics. Besides, the relationship between fidelity and learning effect is still uncertain. A new vision and a comprehensive conceptual framework of fidelity for more general applications are in need. In this paper, further exploration and discussion of these issues in relation to fidelity of SSGs are presented through a systematic review. A general conceptual framework considering both aspects of the SSG system itself and the learners is developed and applied to analyze fidelity in SSGs. Based on that, a discussion on fidelity-related issues of SSG design and development is presented.",1939-1382,,10.1109/TLT.2019.2913408,National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8700243,Fidelity;simulation;serious games;learning;educational games;virtual reality,Solid modeling;Virtual reality;Games;Investment;Current measurement;Three-dimensional displays,computer aided instruction;serious games (computing),educational techniques;multiform SSGs;simulation-based serious games;learning effect,,2,,97,IEEE,26-Apr-19,,,IEEE,IEEE Journals
A 3D serious game for medical students training in clinical cases,R. M. de Lima; A. de Medeiros Santos; F. M. Mendes Neto; A. Fran√ßa de Sousa Neto; F. C. P. Le√£o; F. T. de Macedo; A. M. de Paula Canuto,"Department of Exact and Natural Sciences, Rural Federal University of the Semiarid, Mossor√≥ - RN, Brazil; Department of Exact and Natural Sciences, Rural Federal University of the Semiarid, Mossor√≥ - RN, Brazil; Department of Exact and Natural Sciences, Rural Federal University of the Semiarid, Mossor√≥ - RN, Brazil; Department of Exact and Natural Sciences, Rural Federal University of the Semiarid, Mossor√≥ - RN, Brazil; Department of Exact and Natural Sciences, Rural Federal University of the Semiarid, Mossor√≥ - RN, Brazil; Department of Exact and Natural Sciences, Rural Federal University of the Semiarid, Mossor√≥ - RN, Brazil; Department of Informatics and Applied Mathematics, Federal University of Rio Grande do Norte, Natal - Brazil",2016 IEEE International Conference on Serious Games and Applications for Health (SeGAH),10-Oct-16,2016,,,1,9,"This paper describes an auxiliary environment in the process of teaching and learning for students and professors of medicine. The environment has a serious game available in various computing devices to simulate clinical cases in order to assess students' knowledge. Diagnostics are simulated using 3D environment, mobile application using voice synthesizer and immersion through virtual reality goggles. The environment has gamification features as a motivational mechanism for users. Within the 3D environment, medical subjects are offered by the NPCs (Non Playable Characters), in order to provide auxiliary knowledge to facilitate the identification of diseases in patients or medical issues in general. Professors can check the score of their students and take extra steps in class to clarify doubts. The system has a multi-agent system and machine learning for disease classification offered by virtual patients.",,978-1-5090-2210-6,10.1109/SeGAH.2016.7586255,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586255,voice synthesizer;virtual glasses;simulators for clinical case;virtual environment;multi-agent system;machine learning;gamification,Games;Medical diagnostic imaging;Three-dimensional displays;Training;Computers;Virtual reality,computer aided instruction;learning (artificial intelligence);medical diagnostic computing;multi-agent systems;serious games (computing);virtual reality,3D serious game;medical students training;clinical cases;teaching;learning;computing devices;3D environment;mobile application;voice synthesizer;virtual reality goggles;motivational mechanism;NPC;nonplayable characters;multi-agent system;machine learning;disease classification;virtual patients,,3,,36,,10-Oct-16,,,IEEE,IEEE Conferences
The Effect of 360-Degree Video Authentic Materials on EFL Learners' Listening Comprehension,S. Ji; K. Li; L. Zou,Hankou University; Wuhan University; Hankou University,"2019 International Joint Conference on Information, Media and Engineering (IJCIME)",16-Apr-20,2019,,,288,293,"Although the increased use of authentic materials in listening comprehension teaching has become general practice, it is crucial to find out whether or not the new technology-supported authentic material could be beneficial to English as a Foreign Language (EFL) learners' listening comprehension. The present study examined the effect of authentic material presentation modes (the traditional presentation mode versus virtual reality mode) on EFL learners' English listening comprehension and cognitive load. Subjects were 53 English major sophomores of a university in Wuhan. The control group received the common traditional video playback (the traditional presentation mode) and the experimental group were provided material on Head-Mounted Display (HMD) by 360-degree video playback (the virtual reality mode). The same authentic video material-360-degree video journalism was used in the two groups. The results demonstrated that the EFL learners who watched 360-degree video journalism encountered higher cognitive load and did not outperform in English listening comprehension test than those who watched the material in traditional presentation mode. Pedagogical implications for English listening teaching were provided at the end of the study.",,978-1-7281-5586-9,10.1109/IJCIME49369.2019.00065,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9066355,English listening comprehension;cognitive load;360-degree video journalism;EFL learners,Visualization;Education;Resists;Virtual reality;Vocabulary;Media;Head-mounted displays,cognition;computer aided instruction;educational institutions;helmet mounted displays;linguistics;multimedia systems;teaching;video signal processing;virtual reality,English as a foreign language learners;authentic material presentation modes;virtual reality mode;360-degree video playback;authentic video material-360-degree video journalism;English listening comprehension test;English listening teaching;360-degree video authentic materials;comprehension teaching;technology-supported authentic material;head-mounted display;university;cognitive load;EFL learners English listening comprehension,,,,36,,16-Apr-20,,,IEEE,IEEE Conferences
Investigating into Visual Representations for Foreign Language Knowledge,J. Ge; X. Li,National University of Defense Technology; National University of Defense Technology,2019 International Symposium on Educational Technology (ISET),1-Aug-19,2019,,,202,204,"With the development of information technology, the application of visual elements has become an important feature of foreign language learning resources (FLLRs) in the new media age. However, visual presentation of FLLRs lacks theoretical guidance, which results in the problem of being monotonous in form and inadequate manifestation of knowledge. Knowledge visualization theory provides a new perspective for FLLR design in which selection of proper foreign language knowledge (FLK) visual representations is one of the key steps to facilitate knowledge communication to learners. By analyzing the relevant concepts of visual representation, the study proposes six types of FLK visual representations, namely general text, graph and diagram, static image, camera video, animation and virtual reality. Moreover, the study puts forward five representation dimensions, including knowledge description, logic presentation, context building, pragmatic demonstration and culture exhibition. Then, the representing capacities of the six types of FLK visual representations within the five dimensions is discussed.",,978-1-7281-3388-1,10.1109/ISET.2019.00049,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8782245,foreign language learning;learning resource design;knowledge visualization;visual representation,Visualization;Virtual reality;Animation;Pragmatics;Educational technology;Cameras;Cultural differences,computer aided instruction;data visualisation;linguistics;natural language processing;virtual reality,knowledge description;FLK visual representations;information technology;visual elements;foreign language learning resources;visual presentation;knowledge visualization theory;knowledge communication;static image;foreign language knowledge visual representations;FLLR;general text;graph and diagram;camera video;animation;virtual reality;logic presentation;context building;pragmatic demonstration;culture exhibition,,,,11,,1-Aug-19,,,IEEE,IEEE Conferences
A Comparison of Virtual and Physical Training Transfer of Bimanual Assembly Tasks,M. Murcia-L√≥pez; A. Steed,University College London; University College London,IEEE Transactions on Visualization and Computer Graphics,13-Mar-18,2018,24,4,1574,1583,"As we explore the use of consumer virtual reality technology for training applications, there is a need to evaluate its validity compared to more traditional training formats. In this paper, we present a study that compares the effectiveness of virtual training and physical training for teaching a bimanual assembly task. In a between-subjects experiment, 60 participants were trained to solve three 3D burr puzzles in one of six conditions comprised of virtual and physical training elements. In the four physical conditions, training was delivered via paper- and video-based instructions, with or without the physical puzzles to practice with. In the two virtual conditions, participants learnt to assemble the puzzles in an interactive virtual environment, with or without 3D animations showing the assembly process. After training, we conducted immediate tests in which participants were asked to solve a physical version of the puzzles. We measured performance through success rates and assembly completion testing times. We also measured training times as well as subjective ratings on several aspects of the experience. Our results show that the performance of virtually trained participants was promising. A statistically significant difference was not found between virtual training with animated instructions and the best performing physical condition (in which physical blocks were available during training) for the last and most complex puzzle in terms of success rates and testing times. Performance in retention tests two weeks after training was generally not as good as expected for all experimental conditions. We discuss the implications of the results and highlight the validity of virtual reality systems in training.",1941-0506,,10.1109/TVCG.2018.2793638,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260860,Learning transfer;virtual reality;assembly;training,Training;Testing;Three-dimensional displays;Virtual environments;Haptic interfaces,assembling;computer animation;computer based training;interactive systems;virtual reality,physical training transfer;bimanual assembly task;consumer virtual reality technology;traditional training formats;virtual training;3D burr puzzles;physical puzzles;interactive virtual environment;physical blocks;virtual reality systems;assembly completion testing,"Adult;Female;Humans;Male;Task Performance and Analysis;Transfer, Psychology;User-Computer Interface;Virtual Reality;Young Adult",9,,23,CCBY,17-Jan-18,,,IEEE,IEEE Journals
Significance and Possibility of VR Technology Embedded in the Teaching of Ideological and Political Theory Course in Colleges and Universities,N. Zhang; X. Chen; H. Yin,"School of Economics and Management, Xi‚Äôan University, Xi‚Äôan, China; Academy of Fine Arts, Shandong University of Arts, Jinan, China; Centre for Marxist Education, Wenhua University, Wuhan, China",IEEE Access,1-Dec-20,2020,8,,209835,209843,"The main function of Ideological and political theory course in Colleges and universities is to carry out ideological and political education and moral education to help students establish a good world outlook, outlook on life and values. The main purpose of this paper is to combine VR technology with ideological and political theory course in Colleges and universities. The data of this experiment is from our school to select economics class 1, economics class 2, financial management class 1, and financial management class 2. The average score of Ideological and political theory course in the final examination of last semester of the four classes is close to and close to each other, and 50 people are selected as samples. They were randomly divided into two groups: VR teaching group (economics class 1: A1, financial management class 1: B1) and general teaching group (economics class 2: A2, financial management class 2: B2). VR teaching group lasted for one month, VR ideological and political theory class classroom teaching, ordinary teaching group or traditional teaching. One month later, the four groups of students were tested for ideological and political theory. Before and after the experiment, group A1 and group B1 were investigated: the learning attitude and classroom state of Ideological and political theory course. The experimental results show that: after VR classroom learning, the proportion of A1 and B2 groups who like to think about political theory class increased by 8.2% and 8.14%. The proportion of A1 and B1 aversion to ideological and political theory courses decreased to 1.2% and 3.54%. After VR classroom teaching, the average score of Ideological and political theory course in A1 and B1 groups was 13.81 and 9.68 points higher than that of A2 and B2 groups, and the scores were increased by 19.7% and 13.5%. VR classroom teaching can stimulate students' interest in learning; promote the understanding of knowledge, as well as the establishment of emotional attitude and values.",2169-3536,,10.1109/ACCESS.2020.3023151,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9275403,VR technology;ideological and political theory course;colleges and universities;significance and possibility,Economics;Education;Virtual reality;Financial management;Media;Software;Hardware,computer aided instruction;educational courses;educational institutions;financial management;teaching;virtual reality,political theory courses;VR classroom teaching;A2 management class;financial management class;A1 management class;economics class;ideological theory courses;political theory class;VR ideological;VR teaching group;political education;ideological education;political theory course,,,,32,CCBY,1-Dec-20,,,IEEE,IEEE Journals
Virtual Reality Applications in Education Domain,G. AlFarsi; A. B. Mohd Yusof,"AlBuraimi University College,Buraimi,Oman; College of Graduate Studies, University Tenaga Nasional,Malaysia",2020 21st International Arab Conference on Information Technology (ACIT),4-Jan-21,2020,,,1,7,"Virtual reality catches individuals' consideration. This innovation has been applied in numerous divisions, for example, medication, industry, training, computer games, or the travel industry. Maybe its most significant zone of intrigue has been relaxation and amusement. In any case, the part, the presentation of virtual or increased reality had a few limitations: it was costly, it had poor ergonomics, or inferred an excessive amount of work to make the substance. This study gives a general view of virtual reality applications that used primarily in the education sector. Late mechanical developments, including the quick selection of cell phones by society, have encouraged the entrance to computer-generated reality and enlarged the truth of anybody. Instructive organizations profit by better openness to virtual innovations. VR will make it conceivable to educate in virtual situations that are difficult to picture in physical study halls, such as getting into virtual research facilities, imagining machines, mechanical plants, or even clinical cases. The gigantic prospects of open virtual advancements will make it conceivable to break the limits of formal instruction.",,978-1-7281-8855-3,10.1109/ACIT50332.2020.9300056,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9300056,Virtual Reality;Virtual Learning Environment;Computer Games;Educational Technology,Technological innovation;Virtual reality;Solid modeling;Training;Glass;Cellular phones;Augmented reality,computer aided instruction;virtual reality,education domain;virtual reality;education sector;computer-generated reality;virtual innovations;virtual situations;virtual research facilities;open virtual advancements;instructive organizations,,,,36,,4-Jan-21,,,IEEE,IEEE Conferences
An Explicit Criterion for the Positional Relationship of an Ellipse and a Parabola,M. Chen; X. Hou; X. Qiu,"Faculty of Science, Ningbo University, Ningbo 315211, P.R.China; Faculty of Science, Ningbo University, Ningbo 315211, P.R.China. E-MAIL: houxiaorong@nbu.edu.cn; Faculty of Science, Ningbo University, Ningbo 315211, P.R.China",2007 International Conference on Machine Learning and Cybernetics,29-Oct-07,2007,3,,1774,1778,"Detecting the positional relationship between two planar conics is a common problem in fields of computer animation, computer graphics, machine vision, robotics, virtual reality and CAD/CAM. Based on the generalized characteristic polynomial and the affine invariants of two conics, explicit conditions are derived for classifying the various positional relationships of an ellipse and a parabola by considering all the cases: separation, exterior tangency, intersection, interior tangency and inclusion. The explicit conditions can be expressed in terms of the coefficients of the quadratic forms representing the ellipse and the parabola.",2160-1348,978-1-4244-0972-3,10.1109/ICMLC.2007.4370435,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370435,Affine invariant;Collision detection;Generalized characteristic polynomial;Ellipse;Parabola,Polynomials;Machine learning;Cybernetics;Animation;Computer graphics;Machine vision;Robot vision systems;Virtual reality;Computer aided manufacturing;CADCAM,CAD/CAM;computational geometry;computer animation;polynomials;robot vision;virtual reality,ellipse;parabola;planar conics;computer animation;computer graphics;machine vision;robotics;virtual reality;CAD/CAM;polynomial;tangency;intersection;inclusion,,,,5,,29-Oct-07,,,IEEE,IEEE Conferences
Delay Compensation for a Telepresence System With 3D 360 Degree Vision Based on Deep Head Motion Prediction and Dynamic FoV Adaptation,T. Aykut; M. Karimi; C. Burgmair; A. Finkenzeller; C. Bachhuber; E. Steinbach,"Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany",IEEE Robotics and Automation Letters,31-Aug-18,2018,3,4,4343,4350,"The usability of telepresence applications is strongly affected by the communication delay between the user and the remote system. Special attention needs to be paid in case the distant scene is experienced by means of a Head Mounted Display. A high motion-to-photon latency, which describes the time needed to fully reflect the user's motion on the display, results in a poor feeling of presence. Further consequences involve unbearable motion sickness, indisposition, and termination of the telepresence session in the worst case. In this letter, we present our low-cost MAVI telepresence system, which is equipped with a stereoscopic 360¬∞ vision system and high-payload manipulation capabilities. Special emphasis is placed on the stereoscopic vision system and its delay compensation. More specifically, we propose velocity-based dynamic field-of-view adaptation techniques to decrease the emergence of simulator sickness and to improve the achievable level of delay compensation. The proposed delay compensation approach relies on deep learning to predict the prospective head motion. We use our previously described head motion dataset for training, validation, and testing. To prove the general validity of our approach, we perform cross validation with another independent dataset. We use both qualitative measures and subjective experiments for evaluation. Our results show that the proposed approach is able to achieve mean compensation rates of around 99.9% for latencies between 0.1 and 0.5 s.",2377-3766,,10.1109/LRA.2018.2864359,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8429079,3D vision;telepresence;virtual reality;remote reality;omnidirectional vision,Deep learning;Visualization;Delays;Telepresence;Virtual reality;Stereo image processing,compensation;delays;haptic interfaces;helmet mounted displays;learning (artificial intelligence);optical tracking;stereo image processing;three-dimensional displays;virtual reality;visual perception,field-of-view adaptation techniques;delay compensation approach;prospective head motion;mean compensation rates;dynamic FoV adaptation;telepresence applications;communication delay;remote system;Head Mounted Display;unbearable motion sickness;telepresence session;low-cost MAVI telepresence system;stereoscopic 360¬∞ vision system;high-payload manipulation capabilities;head motion dataset;3D 360 degree vision;velocity-based dynamic field-of-view adaptation techniques;high motion-to-photon latency;deep head motion prediction;simulator sickness;deep learning,,2,,29,,8-Aug-18,,,IEEE,IEEE Journals
Deep Neural Classifiers For Eeg-Based Emotion Recognition In Immersive Environments,J. Teo; J. T. Chia,"Faculty of Computing & Informatics, Universiti Malaysia Sabah, Kota Kinabalu, Sabah, Malaysia; Faculty of Computing & Informatics, Universiti Malaysia Sabah, Kota Kinabalu, Sabah, Malaysia",2018 International Conference on Smart Computing and Electronic Enterprise (ICSCEE),18-Nov-18,2018,,,1,6,"Emotion recognition has become a major endeavor in artificial general intelligence applications in recent years. Although significant progress has been made in emotion recognition for music, image and video stimuli, it remains largely unexplored for immersive virtual stimuli. Our main objective for this line of investigation is to enable consistently reliable emotion recognition for virtual reality stimuli using only cheap, commercial-off-the-shelf electroencephalography (EEG) headsets which have significantly less recording channels and far lower signal resolution commonly called ‚ÄúWearable EEG‚Äù as opposed to medical-grade EEG headsets with the ultimate goal of applying EEG-based emotion prediction to procedurally-generated affective content such as immersive computer games and virtual learning environments through machine learning. Our prior preliminary study has found that the use of a 4-channel, 256-Hz was indeed able to perform the required emotion recognition tasks from VR stimuli albeit at classification rates of between 65-89% classification accuracy only using Support Vector Machines (SVMs) and K-Nearest Neighbor (KNN) classifiers. For this particular study, we attempt to improve the classification rates to above 95% by conducting a comprehensive investigation into the use of various deep neural-based learning architectures for this domain. By tuning the deep neural classifiers in terms of the number of hidden layers, number of hidden nodes and the nodal dropout ratio, the emotion prediction accuracy was able to be improved to over 96%. This shows the continued promise of the application of wearable EEG for emotion prediction as a cost-effective and userfriendly approach for consistent and reliable prediction deployment in virtual reality-related content and environments through deep learning approaches.",,978-1-5386-4838-4,10.1109/ICSCEE.2018.8538382,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8538382,electroencephalography;emotion recognition;machine learning;virtual reality;wearable EEG.,Electroencephalography;Virtual reality;Emotion recognition;Headphones;Electrodes;Feature extraction;Reliability,electroencephalography;emotion recognition;medical signal processing;nearest neighbour methods;neural nets;pattern classification;support vector machines;virtual reality,recording channels;medical-grade EEG headsets;virtual learning environments;machine learning;VR stimuli;classification rates;deep neural classifiers;emotion prediction accuracy;reliable prediction deployment;virtual reality-related content;deep learning approaches;eeg-based emotion recognition;immersive environments;artificial general intelligence applications;video stimuli;virtual reality stimuli;signal resolution;computer games;K-nearest neighbor classifiers;image stimuli;emotion recognition;electroencephalography headsets;support vector machines;wearable EEG,,,,17,,18-Nov-18,,,IEEE,IEEE Conferences
Dynamic Visual Communication Image Framing of Graphic Design in a Virtual Reality Environment,Z. Tian,"College of Arts, Henan University of Animal Husbandry and Economy, Zhengzhou, China",IEEE Access,4-Dec-20,2020,8,,211091,211103,"This paper explores dynamic visual communication image framing for graphic design based on virtual reality algorithms; it defines corresponding feature representations by delineating layers of pixels, elements, relationships, planes, and applications; and it investigates methods for quantifying geometric features, perceptual features, and style features. The contents include extraction methods for element colors, calculation methods for layout perceptual features and color-matching perceptual features, and pairwise comparison methods for style features. By overfitting the distribution of geometric features in the data, the model can predict the probability density distribution of features such as element position and color under specific conditions to support the generation of flat images. To construct a prediction model, the sampling method of features, the model optimization method, and the data learning strategy are investigated. This thesis involves the design and implementation of a lossless/near-lossless compression system for high-frame-rate gaze camera image data, which is faced with the technical problems of high fidelity and strong real-time and reliable compression. The image single-frame lossless/near-loss-free compression ratio is generally low, and the compression ratio can be improved by using the correlation between image frames. In this paper, we study the application of lossless compression between image frames, the efficient computing structure of FPGA, and an onboard compression system.",2169-3536,,10.1109/ACCESS.2020.3022644,"2019 Young Backbone Teachers Training Plan of Henan Colleges and Universities by Henan Education Department, Research on the Living Protection and Inheritance of the Regional Culture of Traditional Villages in Central China through the Rural Revitalization Strategy; 2020 Henan Provincial Key Research, Development and Promotion Special Project (Soft Science Research) General Project, Science and Technology Department of Henan Province, Research on the Construction and Application of Traditional Village Culture Database; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187835,Virtual reality;graphic design;dynamic visual communication;image framing,Image coding;Education;Virtual reality;Feature extraction;Heuristic algorithms;Bandwidth,computer graphics;data compression;data visualisation;feature extraction;image coding;image colour analysis;image matching;learning (artificial intelligence);optimisation;probability;virtual reality,extraction methods;element colors;layout perceptual features;color-matching perceptual features;comparison methods;style features;geometric features;element position;flat images;prediction model;model optimization method;high-frame-rate gaze camera image data;image frames;dynamic visual communication image framing;graphic design;virtual reality environment;virtual reality algorithms;corresponding feature representations,,,,35,CCBY,8-Sep-20,,,IEEE,IEEE Journals
Incremental learning and model selection under virtual concept drifting environments,K. Yamauchi,"Department of Computer Sciences, Chubu University, Matsumoto 1200 kasugai Aichi, Japan",The 2010 International Joint Conference on Neural Networks (IJCNN),14-Oct-10,2010,,,1,8,"This paper presents an incremental learning and model selection method under the virtual concept drifting environments, where their prior distribution of inputs is changing over time. In the previous work, a statistical model of the virtual concept drift was constructed, and the model-selection criterion for radial basis function neural networks (RBFNNs) under such environments was built with the environmental model (Yamauchi 2009). However, in the previous model, no consideration was given to reducing the computational complexity and storage space for storing learned samples used in future re-learning. This study extends the previous model to a new one that uses less storage space. The extended model uses pseudo-learning samples generated by its RBFNN predecessor instead of using the real old learning samples.",2161-4407,978-1-4244-6918-5,10.1109/IJCNN.2010.5596670,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596670,Incremental Learning;Virtual Concept Drift;Covariate Shift;Radial Basis Function Neural Network (RBFNN);Generalization Capabilities;Student's-t distribution;Model Selection;Pseudo-Inputs,Learning systems;Computational modeling;Artificial neural networks;Robot sensing systems;Gaussian distribution;Manganese,computational complexity;learning (artificial intelligence);radial basis function networks;statistical analysis;virtual reality,incremental learning;model selection method;virtual concept drifting environments;statistical model;model-selection criterion;radial basis function neural networks;computational complexity;pseudolearning samples;RBFNN predecessor,,3,,21,,14-Oct-10,,,IEEE,IEEE Conferences
Effects of Lighting Variations in Virtual Learning Environments,A. M. Velentza; E. Economou,"University of Crete,Lab of Experimental Psychology,Department of Psychology,Rethymnon,Crete,Greece; University of Crete,Lab of Experimental Psychology,Department of Psychology,Rethymnon,Crete,Greece","2020 11th International Conference on Information, Intelligence, Systems and Applications (IISA",11-Dec-20,2020,,,1,6,"The use of virtual reality in education is giving researchers new designing opportunities to create learning environments with characteristics that are difficult or even impossible to implement in the real world. There are plenty of educational, cognitive, architectural and neuroscience theories suggesting that certain environmental aspects can enhance the learning process. Such an example is the variation of lighting conditions, in terms of intensity (high or low luminance) and/or temperature (cold or warm), that have been shown to improve memory, attention and executive functions. In this paper, we investigate the differences between a real and a Virtual Learning Environment (VLE) regarding the effects of the lighting conditions on several cognitive functions while we apply, for the first time, certain lighting theories directly into a University level VLE. The first main outcome of our study is that lighting conditions in VLEs affect students' cognitive functions in a similar way to traditional/physical learning environments, i.e. high luminance enhance memory, attention and executive functions when compared with low luminance. Our results indicate that if we need to test a cognitive or learning hypothesis, we can test it directly into a virtual environment since it gives us similar results/outcomes with those triggered in real one. Moreover, our results demonstrate that exposure to blue (cold) lighting in VLEs increase students' scores, in the given pseudoword test, in comparison with their exposure to red (warm) lighting.",,978-0-7381-2346-2,10.1109/IISA50023.2020.9284416,Hellenic Foundation for Research and Innovation; General Secretariat for Research and Technology; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284416,virtual learning environment;lighting conditions;color temperature;memory test;executive task;real environments,Neuroscience;Education;Lighting;Virtual environments;Task analysis,cognition;computer aided instruction;virtual reality,virtual learning environments;red lighting;blue lighting;virtual environment;lighting theories;cognitive functions;virtual learning environment;lighting conditions;learning process;architectural neuroscience theories;cognitive neuroscience theories;educational neuroscience theories;virtual reality;lighting variations,,,,25,,11-Dec-20,,,IEEE,IEEE Conferences
Functional Workspace Optimization via Learning Personal Preferences from Virtual Experiences,W. Liang; J. Liu; Y. Lang; B. Ning; L. -F. Yu,Beijing Institute of Technology; Beijing Institute of Technology; Beijing Institute of Technology; Beijing Institute of Fashion Technology; George Mason University,IEEE Transactions on Visualization and Computer Graphics,27-Mar-19,2019,25,5,1836,1845,"The functionality of a workspace is one of the most important considerations in both virtual world design and interior design. To offer appropriate functionality to the user, designers usually take some general rules into account, e.g., general workflow and average stature of users, which are summarized from the population statistics. Yet, such general rules cannot reflect the personal preferences of a single individual, which vary from person to person. In this paper, we intend to optimize a functional workspace according to the personal preferences of the specific individual who will use it. We come up with an approach to learn the individual's personal preferences from his activities while using a virtual version of the workspace via virtual reality devices. Then, we construct a cost function, which incorporates personal preferences, spatial constraints, pose assessments, and visual field. At last, the cost function is optimized to achieve an optimal layout. To evaluate the approach, we experimented with different settings. The results of the user study show that the workspaces updated in this way better fit the users.",1941-0506,,10.1109/TVCG.2019.2898721,National Natural Science Foundation of China; National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642445,Affordance;Human-centered Design;Virtual Environments;Workspace Design;Remodeling,Layout;Task analysis;Cost function;Visualization;Software;Three-dimensional displays,ergonomics;learning (artificial intelligence);virtual reality,functional workspace optimization;virtual experiences;virtual world design;interior design;cost function;personal preference learning,Algorithms;Computer Graphics;Computer Simulation;Ergonomics;Humans;Interior Design and Furnishings;Posture;Task Performance and Analysis;User-Computer Interface;Virtual Reality;Workplace,1,,52,,14-Feb-19,,,IEEE,IEEE Journals
Research on the Visual Simulation Platform of Acupoint Massage Based on Unity 3D,H. Xiaomei; B. Wen; C. Jianfei,"Shanghai University,Shanghai Key Laboratory of Intelligent Manufacturing and Robotics,Shanghai,China; Shanghai University,Shanghai Key Laboratory of Intelligent Manufacturing and Robotics,Shanghai,China; Shanghai University,Information Technology office,Shanghai,China","2019 IEEE 4th International Conference on Image, Vision and Computing (ICIVC)",6-Feb-20,2019,,,1,5,"With the progress of the times, people's rhythm of life is speeding up day by day, followed by various diseases caused by great pressure. Acupoint massage is an important way for people to take care of their bodies in addition to Chinese and western medicine, so a human-computer interactive platform is needed to help the general public learn basic massage techniques. According to the development of virtual reality and the demand of acupoint massage learning, a visual simulation platform of acupoint massage based on Unity3D is proposed in this paper. The structure of the visual simulation platform of acupoint massage is designed and five layers are divided. The relationship between different layers and the functions of each layer are introduced in detail. The interface of simulation platform is given to show how it works. It is an immersive visual platform which can meet the demands of contemporary people.",,978-1-7281-2325-7,10.1109/ICIVC47709.2019.8981062,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8981062,unity3d;acupoint massage;visualization;visual simulation,,data visualisation;interactive systems;medical computing;medicine;virtual reality,immersive visual platform;visual simulation platform;Unity 3D;human-computer interactive platform;massage techniques;acupoint massage learning;Unity3D;Chinese medicine;western medicine,,,,10,,6-Feb-20,,,IEEE,IEEE Conferences
Network-Assisted Neural Adaptive Naked-Eye 3D Video Streaming Over Wireless Networks,Y. Liu; W. He; Y. Wang; H. Yang,"School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China",IEEE Access,7-Oct-19,2019,7,,141363,141373,"High quality transmission of Virtual Reality (VR) video depends strictly on bandwidth and delay requirements. It becomes possible with the maturity and commercialization of 5G technology. However, to transmit VR video streaming over wireless communication system, we must cope with the challenge that fluctuation exists in the wireless channel conditions. For example, available channel bandwidth, packet loss rate, and interference level may vary with time due to channel fading and user's mobility. The problem is more prominent when transmitting naked-eye 3D video which generally consists of multiple viewpoints with different resolutions. In order to optimize the quality of experience (QoE) of watching naked-eye VR video over wireless networks, this paper proposes a network-assisted neural adaptive video streaming algorithm (NAVSA). Specifically, we present a modified QoE function to describe the quality of naked-eye 3D streaming quantitatively, which not only considers the quality of naked-eye 3D video itself, but also considers the phenomenon of rebuffering and video fluctuation that occurs during video transmission. Next, with the network-assisted feedback, the physical layer information, the buffer occupancy of the video client, and the size of the next video chunk are collected to train a reinforcement learning model. Based on dynamic adaptive streaming over HTTP (DASH), the model can automatically choose appropriate viewpoints and resolutions corresponding to the current condition of the wireless networks such that the network capacity can be fully explored. To verify the performance of our proposed NAVSA, we simulate 3 naked-eye 3D video application scenarios on the NS3 platform. The results show that the performance of NAVSA is about 5~8% better than some state-of-the-art algorithms in wireless networks.",2169-3536,,10.1109/ACCESS.2019.2944437,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852692,Reinforcement learning;adaptive transmission;naked-eye 3D;network assistance;wireless networks,Streaming media;Three-dimensional displays;Quality of experience;Wireless networks;Bandwidth;Adaptive systems;Reinforcement learning,5G mobile communication;bandwidth allocation;channel allocation;fading channels;learning (artificial intelligence);mobility management (mobile radio);neural nets;quality of experience;radiofrequency interference;transport protocols;video streaming;virtual reality,naked-eye 3D video;naked-eye 3D video application;5G technology;quality of experience;NAVSA;reinforcement learning model;dynamic adaptive streaming over HTTP;DASH;network-assisted neural adaptive video streaming algorithm;naked-eye VR video;channel bandwidth;wireless channel conditions;wireless communication system;Virtual Reality video;network-assisted neural adaptive naked-eye 3D video streaming;NS3 platform;wireless networks;network-assisted feedback;video transmission,,,,45,CCBY,30-Sep-19,,,IEEE,IEEE Journals
A hybrid neural network and virtual reality system for spatial language processing,G. C. Martinez; A. Cangelosi; K. R. Coventry,"Sch. of Comput., Plymouth Univ., UK; NA; NA",IJCNN'01. International Joint Conference on Neural Networks. Proceedings (Cat. No.01CH37222),7-Aug-02,2001,1,,16,21 vol.1,"Describes a neural network model for the study of spatial language. It deals with both geometric and functional variables, which have been shown to play an important role in the comprehension of spatial prepositions. The network is integrated with a virtual reality interface for the direct manipulation of geometric and functional factors. The training uses experimental stimuli and data. Results show that the networks reach low training and generalization errors. Cluster analyses of hidden activation show that stimuli primarily group according to extra-geometrical variables.",1098-7576,0-7803-7044-9,10.1109/IJCNN.2001.938984,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=938984,,Neural networks;Virtual reality;Psychology;Cognition;Natural languages;Geometry;Computer networks;Error analysis;Testing;Virtual prototyping,virtual reality;psychology;learning (artificial intelligence);generalisation (artificial intelligence);multilayer perceptrons;natural language interfaces,hybrid neural network;virtual reality system;spatial language processing;functional variables;geometric variables;spatial prepositions;experimental stimuli;cluster analyses;hidden activation,,1,,14,,7-Aug-02,,,IEEE,IEEE Conferences
Virtual training of potential function based guiding styles,P. Korondi; A. R. Varkonyi-Koczy; S. Kovacs; P. Baranyi; M. Sugiyama,"Japanese-Hungarian Lab., Budapest Univ. of Technol. & Econ., Hungary; NA; NA; NA; NA",Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569),7-Aug-02,2001,,,2529,2533 vol.5,"The main goal of this paper is two-fold. One goal is to adapt the advantages of using an immersive virtual environment for teaching robots. The subsequent aim is to define a suitable model for a robot guiding-style description, which can serve as an easily adaptable and implementable general guiding-style description of various mobile robots. Guidelines for virtual training and the proposed general neural network-based guiding-style description model are also introduced in this paper.",,0-7803-7078-3,10.1109/NAFIPS.2001.943620,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=943620,,Humans;Employment;Telerobotics;Education;Laboratories;Environmental economics;Virtual environment;Mobile robots;Space technology;Displays,mobile robots;robot programming;learning systems;virtual reality;path planning;neural nets,virtual training;potential function-based guiding styles;immersive virtual environment;mobile robot teaching;robot guiding-style description;neural network-based model,,3,,14,,7-Aug-02,,,IEEE,IEEE Conferences
Virtual reality without borders: ‚Ä¶Mini-conference for pupils and students,I. Varhan√≠kov√°; M. B√°torov√°; Z. Haladov√°; M. Hud√°k; Z. Chovancov√°; K. J√°no≈°ov√°; B. Kamrlov√°; J. Kuƒçerov√°; J. Romer; M. Val√≠kov√°; R. Val√≠k; P. Vank√∫≈°,"Faculty of mathematics, physics and informatics Comenius University Bratislava, Slovakia; Faculty of mathematics, physics and informatics Comenius University Bratislava, Slovakia; Faculty of mathematics, physics and informatics Comenius University Bratislava, Slovakia; Faculty of mathematics, physics and informatics Comenius University Bratislava, Slovakia; Faculty of mathematics, physics and informatics Comenius University Bratislava, Slovakia; Faculty of mathematics, physics and informatics Comenius University Bratislava, Slovakia; Faculty of mathematics, physics and informatics Comenius University Bratislava, Slovakia; Faculty of mathematics, physics and informatics Comenius University Bratislava, Slovakia; Faculty of mathematics, physics and informatics Comenius University Bratislava, Slovakia; Faculty of mathematics, physics and informatics Comenius University Bratislava, Slovakia; Faculty of mathematics, physics and informatics Comenius University Bratislava, Slovakia; Faculty of mathematics, physics and informatics Comenius University Bratislava, Slovakia",2012 15th International Conference on Interactive Collaborative Learning (ICL),7-Jan-13,2012,,,1,8,"Science and mathematics education are generally hardly accepted by pupils of any age as something agreeable or even fun. There are various studies showing increasing interest for STEM topics when proposed in children-friendly format, encouraging personal engagement of children. The thinking-asking-exploring-doing approach was attacked by our ‚ÄúVirtual reality without borders‚Äù. The first part consisted in an individual writing on selected topics from various scientific fields, the second part presented workshops and active lectures during the mini-conference intended for pupils and students under the age of 18 and their parents, teachers and friends. Virtual reality without borders is for anybody who enjoys thinking, playing and listening to the great thoughts and inventions of others.",,978-1-4673-2427-4,10.1109/ICL.2012.6402133,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402133,learning by doing;alternative education;playing;writing contest,,computer aided instruction;mathematics computing;virtual reality,virtual reality;mathematics education;science education;STEM topics,,,,13,,7-Jan-13,,,IEEE,IEEE Conferences
Image Recognition and Safety Risk Assessment of Traffic Sign Based on Deep Convolution Neural Network,R. Chen; L. Hei; Y. Lai,"School of Communications and Information Engineering, Xi‚Äôan University of Posts and Telecommunications, Xi‚Äôan, China; Institute of Xi‚Äôan Aerospace Solid Propulsion Technology, Xi‚Äôan, China; School of Communications and Information Engineering, Xi‚Äôan University of Posts and Telecommunications, Xi‚Äôan, China",IEEE Access,18-Nov-20,2020,8,,201799,201805,"A neural network model based on deep learning is utilized to explore the traffic sign recognition (TSR) and expand the application of deep intelligent learning technology in the field of virtual reality (VR) image recognition, thereby assessing the road traffic safety risks and promoting the construction of intelligent transportation networks. First, a dual-path deep CNN (TDCNN) TSR model is built based on the convolutional neural network (CNN), and the cost function and recognition accuracy are selected as indicators to analyze the training results of the model. Second, the recurrent neural network (RNN) and long-short-term memory (LSTM) RNN are utilized to assess the road traffic safety risks, and the prediction and evaluation effects of them are compared. Finally, the changes in safety risks of road traffic accidents are analyzed based on the two key influencing factors of the number of road intersections and the speed of vehicles traveling. The results show that the learning rate of the network model and the number of hidden neurons in the fully-connected layer directly affect the training results, and there are differences in the choices between the early and late training periods. Compared with RNN, the LSTM network model has higher evaluation accuracy, and its corresponding root square error (RSE) is 0.36. The rational control of the number of intersections and the speed of roads traveled has a significant impact on improving the safety level and promoting road traffic efficiency. The VR image recognition algorithm and safety risk prediction method based on a neural network model positively affect the construction of an intelligent transport network.",2169-3536,,10.1109/ACCESS.2020.3032581,Education Department of Shaanxi Province; Shaanxi Provincial Natural Science Basic Research Project; Education Department of Shaanxi Provincen; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9233325,TDCNN;image recognition;RNN;LSTM;security risk;assessment,Training;Roads;Safety;Deep learning;Image recognition;Convolution;Predictive models,convolutional neural nets;image recognition;learning (artificial intelligence);recurrent neural nets;road accidents;road safety;road traffic;traffic engineering computing;virtual reality,VR image recognition algorithm;road traffic efficiency;safety level;LSTM network model;learning rate;road intersections;road traffic accidents;RNN;recognition accuracy;cost function;convolutional neural network;dual-path deep CNN TSR model;intelligent transportation networks;road traffic safety risks;virtual reality image recognition;deep intelligent learning technology;traffic sign recognition;deep convolution neural network;safety risk assessment;intelligent transport network;neural network model;safety risk prediction method,,,,23,CCBY,20-Oct-20,,,IEEE,IEEE Journals
"Machine Learning for 5G/B5G Mobile and Wireless Communications: Potential, Limitations, and Future Directions",M. E. Morocho-Cayamcela; H. Lee; W. Lim,"Department of Electronic Engineering, Kumoh National Institute of Technology, Gumi, South Korea; 5G Innovation Centre (5GIC), Institute for Communication Systems (ICS), University of Surrey, Guildford, U.K.; Department of IT Convergence, Kumoh National Institute of Technology, Gumi, South Korea",IEEE Access,30-Sep-19,2019,7,,137184,137206,"Driven by the demand to accommodate today's growing mobile traffic, 5G is designed to be a key enabler and a leading infrastructure provider in the information and communication technology industry by supporting a variety of forthcoming services with diverse requirements. Considering the ever-increasing complexity of the network, and the emergence of novel use cases such as autonomous cars, industrial automation, virtual reality, e-health, and several intelligent applications, machine learning (ML) is expected to be essential to assist in making the 5G vision conceivable. This paper focuses on the potential solutions for 5G from an ML-perspective. First, we establish the fundamental concepts of supervised, unsupervised, and reinforcement learning, taking a look at what has been done so far in the adoption of ML in the context of mobile and wireless communication, organizing the literature in terms of the types of learning. We then discuss the promising approaches for how ML can contribute to supporting each target 5G network requirement, emphasizing its specific use cases and evaluating the impact and limitations they have on the operation of the network. Lastly, this paper investigates the potential features of Beyond 5G (B5G), providing future research directions for how ML can contribute to realizing B5G. This article is intended to stimulate discussion on the role that ML can play to overcome the limitations for a wide deployment of autonomous 5G/B5G mobile and wireless communications.",2169-3536,,10.1109/ACCESS.2019.2942390,"National Research Foundation of Korea; Korea Government (MSIP Ministry of Science, ICT and Future Planning); ITRC Program; Ministry of Trade, Industry and Energy; Ministry of Trade, Industry and Energy; H2020 European Institute of Innovation and Technology; Government of Taiwan; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8844682,Machine learning;5G mobile communication;B5G;wireless communication;mobile communication;artificial intelligence,Wireless communication;Training;5G mobile communication;Supervised learning;Task analysis;Reinforcement learning,5G mobile communication;innovation management;learning (artificial intelligence);telecommunication computing,machine learning;wireless communications;mobile traffic;leading infrastructure provider;communication technology industry;diverse requirements;complexity;autonomous cars;industrial automation;virtual reality;intelligent applications;5G vision;supervised reinforcement learning;mobile communication;wireless communication,,23,,193,CCBY,19-Sep-19,,,IEEE,IEEE Journals
Impact of machine learning on improvement of user experience in museums,M. Majd; R. Safabakhsh,"Computer engineering and IT, Amirkabir University of Technology, Tehran, Iran; Computer engineering and IT, Amirkabir University of Technology, Tehran, Iran",2017 Artificial Intelligence and Signal Processing Conference (AISP),26-Mar-18,2017,,,195,200,"Utilizing new technologies is the key to improve user experience in museums. Natural and unobtrusive methods like those offered by machine learning approaches are more desired by users. So far, the research on machine learning applications in museums is mostly limited to art authentication, guiding and virtual reality. Yet, machine learning has powerful methods to extract information from any type of data and therefore there are other interesting applications which can have a significant effect on museum experience. The current work is an attempt to find an abstract and yet elaborate view into the existing machine learning applications in museums in general and automatic guide methods in particular. To do so, applications are grouped into different categories and for each category the usefulness of applying machine learning along with the existing methods, if any, are presented. Furthermore, a precise explanation on new directions accompanied by examples is provided. We expect this paper to be of interest to the machine learning researchers since it provides a guideline to proper directions of research in this realm.",,978-1-5386-2585-9,10.1109/AISP.2017.8324080,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8324080,machine learning application;computer vision;museum experience;automatic guide;museum data analysis,Mobile handsets;Computer vision;Art;Cameras;Learning (artificial intelligence);Data mining,learning (artificial intelligence);museums;virtual reality,museums;machine learning approaches;virtual reality;automatic guide methods;user experience improvement,,1,,32,,26-Mar-18,,,IEEE,IEEE Conferences
STEM collaboration in virtual world academy,L. Divine; R. Williams,"Virtual Reality Academy Deputy Director, Tec^Edge Innovation and Collaboration Center, Dayton, Ohio, United States; AFRL Discovery Lab Director, Tec^Edge Innovation and Collaboration Center, Dayton, Ohio, United States",2013 International Conference on Collaboration Technologies and Systems (CTS),25-Jul-13,2013,,,569,575,"There is general agreement about the importance of increasing the number of students choosing career fields in Science, Technology, Engineering, and Mathematics (STEM). However most of the initiatives designed to get students interested in STEM fields are constrained by floor space, budget, or driving distance. These factors, in combination, act to limit the affordability and accessibility of research opportunities in STEM fields to students in schools faced with increasingly limited budgets or lacking access to experienced STEM teachers. Since a trained STEM workforce is crucial to tackling research challenges of importance to the Air Force and the nation, the Air Force Research Laboratory (AFRL) Discovery Lab program has developed a Virtual Reality Academy (VRA) program utilizing open source virtual reality software, Open Simulator, to create a virtual collaboration environment called Virtual (reality) Discovery Center (VDC). This 16-region VDC is the key to the Discovery Lab's 1,000 Student Outreach initiative designed to greatly expand the Discovery Lab's ability to make project-based ‚Äúhands-on‚Äù research experience accessible to students across the country via the Open Simulator collaboration technologies. This paper highlights many of the successful efforts to establish VDC Virtual Learning Academies in areas such as Biology, Nanotechnology, Computer Vision, and Mobile Computing (smartphone apps). This paper is not a scientific study of Open Simulator as a collaboration tool for STEM but rather a descriptive overview of its successful implementation locally and nationally - suggesting its potential as a game-changer in STEM education and research.",,978-1-4673-6404-1,10.1109/CTS.2013.6567288,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6567288,,Collaboration;Solid modeling;Dinosaurs;Avatars;Educational institutions;Space shuttles,computer aided instruction;engineering education;groupware;public domain software;teaching;virtual reality,STEM collaboration;science-technology-engineering-mathematics;STEM fields;driving distance;floor space;STEM teachers;STEM workforce;Air Force Research Laboratory Discovery Lab program;Virtual Reality Academy program;VRA program;open source virtual reality software;virtual collaboration environment;Virtual Discovery Center;16-region VDC;project-based hands-on research experience;Open Simulator collaboration technologies;virtual learning academies,,1,,6,,25-Jul-13,,,IEEE,IEEE Conferences
"Data and Knowledge Visualization with Virtual Reality Spaces, Neural Networks and Rough Sets: Application to Geophysical Prospecting",J. J. Valdes; E. Romero; R. Gonzalez,"National Research Council Canada, Institute for Information Technology. M50 1200 Montreal Rd, Ottawa, ON K1A 0R6, Canada. email: julio.valdes@nrc-cnrc.gc.ca; Departament de Llenguatges i Sistemes Inform√†tics, Universitat Polit√®cnica de Catalunya, c/ Jordi Girona, 1-3, 08034 Barcelona, Spain. email: eromero@lsi.upc.edu; Facultat d'Inform√†tica de Barcelona, Universitat Polit√®cnica de Catalunya, c/ Jordi Girona, 1-3, 08034 Barcelona, Spain. email: e3450650@est.fib.upc.edu",2007 International Joint Conference on Neural Networks,29-Oct-07,2007,,,160,165,"Visual data mining with virtual reality spaces are used for the representation of data and symbolic knowledge. The approach is illustrated with data from a geophysical prospecting case in which partially defined fuzzy classes are present. In order to understand the structure of both the data and knowledge extracted in the form of production rules, structure-preserving and maximally discriminative virtual spaces are constructed. High quality visual representations can be obtained using Samann and nonlinear discriminant neural networks. Rough set techniques are used for demonstrating the irreducibility of the set of original attributes and for learning the symbolic knowledge. Grid computing techniques are used for constructing sets of virtual reality spaces and for assessing the behavior of some of the neural network parameters controlling the quality of the virtual worlds. The general properties of the symbolic knowledge can be found with greater ease in the virtual reality space whereas both the prediction of unknown objects to the target class, as well as a derivation of a fuzzy membership function from the virtual reality space and the neural network results are obtained.",2161-4407,978-1-4244-1379-9,10.1109/IJCNN.2007.4370948,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4370948,,Data visualization;Virtual reality;Neural networks;Rough sets;Data mining;Biological neural networks;Humans;Information systems;Production;Grid computing,data mining;data visualisation;fuzzy set theory;geophysical prospecting;grid computing;knowledge based systems;neural nets;rough set theory;virtual reality,data visualization;knowledge visualization;virtual reality spaces;rough sets;geophysical prospecting;visual data mining;symbolic knowledge;visual representations;nonlinear discriminant neural networks;Samann neural networks;grid computing techniques;fuzzy membership function,,2,,20,,29-Oct-07,,,IEEE,IEEE Conferences
A virtual-learning service platform and its API based programming learning and design refinement,Y. Wang; J. Wang; L. Mei; Q. Li,IBM Research - China; IBM Research - China; IBM Research - China; IBM Research - China,"Proceedings of 2012 IEEE International Conference on Service Operations and Logistics, and Informatics",20-Aug-12,2012,,,383,388,"The evolution of 3D internet technologies has opened a whole new range of opportunities for enhanced learning, and has offered new support in programming learning fields. In this paper, we present a framework for the virtual-learning service platform over 3D virtual worlds. Our framework provides a set of fundamental services that can effectively help to reduce the learning curve in learning programming on a new specific platform and improve the targeted platform development work. The proposed framework is a generalization of our experience gained in developing of a fully immersive 3D e-Iearning system which has been tested and used for customer training.",,978-1-4673-2401-4,10.1109/SOLI.2012.6273567,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6273567,,Programming profession;Web sites;Web services;Education;Tutorials,application program interfaces;computer aided instruction;computer science education;Internet;programming;virtual reality,virtual-learning service platform;API based programming learning;design refinement;3D Internet technology evolution;learning enhancement;3D virtual world;learning curve;platform development work;fully immersive 3D e-learning system;customer training,,,,22,,20-Aug-12,,,IEEE,IEEE Conferences
"gPhysics‚ÄîUsing Smart Glasses for Head-Centered, Context-Aware Learning in Physics Experiments",J. Kuhn; P. Lukowicz; M. Hirth; A. Poxrucker; J. Weppner; J. Younas,"Physics Education Research Group, Department of Physics, University of Kaiserslautern, Kaiserslautern, Germany; German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; Physics Education Research Group, Department of Physics, University of Kaiserslautern, Kaiserslautern, Germany; German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany",IEEE Transactions on Learning Technologies,14-Dec-16,2016,9,4,304,317,"Smart Glasses such as Google Glass are mobile computers combining classical Head-Mounted Displays (HMD) with several sensors. Therefore, contact-free, sensor-based experiments can be linked with relating, near-eye presented multiple representations. We will present a first approach on how Smart Glasses can be used as an experimental tool for head-centered, context-aware, wearable-technology-enhanced, and inquiry-based learning in physics education. Therefore, we developed an app that is based on the Google Glass platform and designed to perform educational physical experiments on the topic of acoustics. Its initial application is intended for high-school students whose task is to study the relationship between the frequency of the sound generated by hitting a glass of water and the amount of water in the glass. The core idea is to have Google Glass automatically measure both the water fill level with the camera and the sound frequency with the microphone, and incrementally generate a fill level/frequency graph in the HMD. We designed an educational setting and studied its effect on cognitive and affective variables with an intervention-control-group design. While the intervention group analyzed the fill level/frequency relationship with the Google Glass platform, control group 1 worked on the phenomenon using the same platform implemented on a tablet PC. Control group 2 analyzed the phenomenon using a tablet PC with a typical mobile-based education platform. We used a two-way ANCOVA to study learning outcome, wondering, curiosity, cognitive load, and experimentation time as dependent variables of 46 high-school eighth-graders together with group membership and gender influence as independent variables. While the positive effects of using Google Glass as a mobile lab on wondering and curiosity as well as a positive trend for experimentation time were detected, no differences were analyzed for learning achievement. Although students have a higher cognitive load when working with Google Glass compared to other devices, the cognitive load level is very low in general.",1939-1382,,10.1109/TLT.2016.2554115,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7452644,Wearable computers;physics education;student experiments;acoustic measurements;wearable sensors;image recognition,Smart devices;Google;Sensors;Wearable computing;Mobile computers;Glasses,cameras;computer aided instruction;helmet mounted displays;microphones;mobile computing;notebook computers;physics computing;physics education;student experiments;wearable computers,fill level/frequency relationship;tablet PC;mobile-based education platform;two-way ANCOVA;learning outcome;wondering;curiosity;cognitive load;experimentation time;high-school eighth-graders;group membership;gender influence;mobile lab;intervention-control-group design;affective variables;cognitive variables;educational setting;fill level/frequency graph;microphone;camera;water fill level;sound frequency;high-school students;educational physical experiments;Google Glass platform;physics education;inquiry-based learning;wearable-technology-enhanced learning;sensor-based experiments;contact-free experiments;HMD;classical head-mounted displays;mobile computers;context-aware learning;head-centered learning;smart glasses;gPhysics,,23,,55,,14-Apr-16,,,IEEE,IEEE Journals
Application of Two Synaptic Weight Neural Networks for Nonlinear Control,Wenmin Cao; Shoujue Wang,Zhejiang University of Technology and Chinese Academy of Science; NA,Third International Conference on Information Technology and Applications (ICITA'05),1-Aug-05,2005,2,,28,31,"In this paper, adaptive identification and control of nonlinear dynamical systems are investigated using two synaptic weight neural networks (TSWNN). Firstly, a novel approach to train the TWSWNN is introduced, which employs an adaptive fuzzy generalized learning vector quantization (AFGLVQ) technique and recursive least squares algorithm with variable forgetting factor (VRLS). The AFGLVQ adjusts the kernels of the TSWNN while the VRLS updates the connection weights of the network. The identification algorithm has the properties of rapid convergence and persistent adaptability that make it suitable for real-time control. Secondly, on the basis of the one-step ahead TSWNN predictor, the control law is optimized iteratively through a numerical stable Davidon's least squares-based (SDLS) minimization approach. A nonlinear example is simulated to demonstrate the effectiveness of the identification and control algorithms",,0-7695-2316-1,10.1109/ICITA.2005.72,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1488923,Neural networks;Adaptive control;Nonlinear control;Two synaptic Weight neural networks;Recursive least squares,Neural networks;Iterative algorithms;Programmable control;Adaptive control;Nonlinear control systems;Control systems;Nonlinear dynamical systems;Vector quantization;Least squares methods;Kernel,adaptive control;generalisation (artificial intelligence);iterative methods;learning (artificial intelligence);least mean squares methods;neural nets;nonlinear dynamical systems,adaptive control;nonlinear dynamical system;two synaptic weight neural networks;adaptive fuzzy technique;generalized learning technique;vector quantization technique;recursive least squares algorithm;Davidon least squares-based minimization,,,,7,,1-Aug-05,,,IEEE,IEEE Conferences
A Large-scale Simulation Dataset: Boost the Detection Accuracy for Special Weather Conditions,D. Liu; Y. Cui; Z. Cao; Y. Chen,"Purdue University,Department of Computer Graphics Technology,West Lafayette,USA,47907; University of Florida,Department of Electrical & Computer Engineering,Gainesville,FL,USA,32611; Purdue University,Department of Computer Graphics Technology,West Lafayette,USA,47907; Purdue University,Department of Computer Graphics Technology,West Lafayette,USA,47907",2020 International Joint Conference on Neural Networks (IJCNN),28-Sep-20,2020,,,1,8,"Object detection is a fundamental task for autonomous driving systems. One bottleneck hindering detection accuracy is a shortage of well-annotated image data. Virtual reality has provided a feasible low-cost way to facilitate computer vision related developments. In autonomous driving area, existing public datasets from real world generally have data biases and cannot represent a wide range of weather conditions, such as rainy or snowy roads. To address this challenge, we introduce a new large-scale simulation dataset which is generated by an automated pipeline from a high realism video game. Our dataset focuses on weather conditions, which can be adopted to train networks to effectively detect objects under such conditions. We use extensive experiments to evaluate our dataset by comparing it with public datasets. The experiment results show that networks trained with our dataset outperform the networks trained by other public datasets. Our work demonstrates the effectiveness of using simulation data to address real-world challenges in the practice of object detection.",2161-4407,978-1-7281-6926-2,10.1109/IJCNN48605.2020.9206716,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206716,Large-scale dataset for autonomous driving;simulation data;automated data generation;special weather autonomous driving;object detection accuracy,Solid modeling;Meteorology;Object detection;Data models;Autonomous vehicles;Games;Computational modeling,computer games;computer vision;feature extraction;intelligent transportation systems;learning (artificial intelligence);neural nets;object detection;traffic engineering computing;virtual reality,special weather conditions;object detection;autonomous driving systems;detection accuracy;image data;virtual reality;computer vision;high realism video game;network training;deep learning networks,,,,38,,28-Sep-20,,,IEEE,IEEE Conferences
Enter the Serious E-scape Room: A Cost-Effective Serious Game Model for Deep and Meaningful E-learning,S. Mystakidis; E. Cachafeiro; I. Hatzilygeroudis,"University of Jyv√§skyl√§ & Patras,Faculty of Information Technology,Jyv√§skyl√§,Finland & Patras,Greece; OESO Duke Health,Durham,USA; University of Patras,Department of Computer Engineering & Informatics,Patras,Greece","2019 10th International Conference on Information, Intelligence, Systems and Applications (IISA)",14-Nov-19,2019,,,1,6,"Escape rooms are a phenomenon that has taken the world by storm in the last decade. Simultaneously Virtual Reality is a promising technology for innovation in education, training and e-learning. Combining these two concepts, this paper outlines a new model for designing serious games in virtual reality environments for high quality, deep and meaningful learning, the Serious E-scape Room. It describes the theoretical grounding, general guidelines and principles of the model. It also presents the case study ‚ÄúRoom of Keys‚Äù, a serious virtual escape room for biology concepts. To test the assumptions of the model, researchers conducted a mixed research study with 148 students in a US high school. Pre-post test results recorded a 13.8% performance increase and high overall satisfaction. The game has been received enthusiastically by students, it increased their motivation and helped them build a deeper understanding of the learned concepts.",,978-1-7281-4959-2,10.1109/IISA.2019.8900673,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900673,escape room;virtual reality;serious games;deep and meaningful learning;biology,,computer aided instruction;educational institutions;serious games (computing);virtual reality,serious e-scape room;serious virtual escape room;serious game model;e-learning;virtual reality environments;US high school,,4,,32,,14-Nov-19,,,IEEE,IEEE Conferences
Virtual Classroom: An ADHD Assessment and Diagnosis System Based on Virtual Reality,Y. Tan; D. Zhu; H. Gao; T. -W. Lin; H. -K. Wu; S. -C. Yeh; T. -Y. Hsu,"Fudan University, Shanghai, China; Children's Hospital of Fudan University, Shanghai, China; Children's Hospital of Fudan University, Shanghai, China; National Central University, Taiwan, China; National Central University, Taiwan, China; Fudan University, Shanghai, China; National Central University, Taiwan, China",2019 IEEE International Conference on Industrial Cyber Physical Systems (ICPS),1-Aug-19,2019,,,203,208,"Attention deficit hyperactivity disorder (ADHD), i.e., children's hyperactivity, is a common neurodevelopmental disorder in childhood. ADHD is mainly characterized by having difficulty in staying focused, behavioral impulsivity and hyperactivity, and is often accompanied by conduct disorders, learning disabilities or learning difficulties. Traditional therapies generally rely on doctors and parents who can observe and assess patients' behavior through behavioral scales; however, these therapies are time consuming and ineffective in quantifying behavior. Basing on virtual reality technology, this study integrated multiple sensor technologies, such as eye movement sensors and EEG sensors, and developed an assessment and diagnosis system for ADHD. This system constructed a virtual classroom environment and integrated some tasks, such as audio test, Continuous Performance Task (CPT) and Wisconsin Card Sorting Test (WCST), to judge the subject's sustained attention, abstract reasoning ability and cognitive ability. Distraction elements were also added to the experiment by analyzing the attention shift of the test taker to diagnose ADHD. Physiological data, such as head movements, eyes movements, and EEG, were used to supplement test results to assess the subject's sustained attention and attention shift.",,978-1-5386-8500-6,10.1109/ICPHYS.2019.8780300,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8780300,Attention deficit hyperactivity disorder;Virtual Reality;Eye Tracking;EEG,5G mobile communication,cognition;electroencephalography;medical computing;medical disorders;neurophysiology;paediatrics;patient treatment;virtual reality,ADHD assessment;neurodevelopmental disorder;continuous performance task;Wisconsin card sorting test;children hyperactivity;integrated multiple sensor technologies;audio test;abstract reasoning ability;cognitive ability;distraction elements;physiological data;head movements;attention shift;virtual classroom environment;EEG sensors;eye movement sensors;virtual reality technology;behavioral scales;doctors;traditional therapies;learning difficulties;conduct disorders;behavioral impulsivity;attention deficit hyperactivity disorder;diagnosis system,,2,,13,,1-Aug-19,,,IEEE,IEEE Conferences
Collaborative Remote Laboratories for Serving Sciences and Engineering Education in Iraq: Rexnet Project,R. M. Salah; J. Cecil; D. Atrushi,"Computer Science Department, University Of Duhok, Duhok, Kurdistan Region, Iraq; Computer Science Department, Oklahoma State University, Oklahoma, USA; Computer Science Department, University Of Duhok, Duhok, Kurdistan Region, Iraq",2018 International Conference on Advanced Science and Engineering (ICOASE),29-Nov-18,2018,,,134,139,"Currently, higher education systems in the Middle East and North Africa region face several challenges in terms of developing, learning, and teaching. For example, the higher education system in Iraq, which is the same as in other countries as a whole, has not adapted instructional technology into the education system efficiently. Nowadays, several technologies have been implemented (e.g. Remote Experimentation Labs and Virtual Reality) to serve the higher education systems and their teaching abilities, especially in Sciences and Engineering disciplinary. This paper presents a Remote Experimentation Labs project, named ""Building a Remote Experimentation Network for serving higher education teachers and students in Iraq (REXNet)"", that is implemented to serve students and teachers of Iraqi universities. It is a collaborative work among three universities (i.e. Duhok University, Zakho University, Duhok Polytechnic University) in Kurdistan Region-Iraq and Oklahoma State University (OSU) in United States, and supported by the International Research & Exchanges Board organization for creating Virtual Learning Environments (Cyberlearning Environment) for enhancing students learning experience and pedagogical by using Remote Experimentation Labs. In general, the project aimed to include several modules for students from those universities that can be running via the Internet, and helping to increase the collaborative work among researchers in Kurdistan region and Iraq.",,978-1-5386-6696-8,10.1109/ICOASE.2018.8548885,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8548885,Remote Experimentation Labs;REXNet project;Modules;Cyberlearning Environment;Virtual Learning Environments;Collaborative work,Education;Robots;Laboratories;Internet;Computer science;Virtual reality;Collaborative work,computer aided instruction;control engineering education;distance learning;educational courses;educational institutions;engineering education;further education;groupware;Internet;student experiments;virtual reality,higher education system;higher education teachers;collaborative work;collaborative remote laboratories;North Africa region;Iraqi universities;sciences and engineering education;Middle East Africa region;teaching;cyberlearning environment;instructional technology;remote experimentation labs project;virtual reality;remote experimentation network;students;Rexnet project;Duhok polytechnic university;Zakho University;Oklahoma state university;OSU;United States;international research and exchanges board organization;virtual learning environments;Internet;Kurdistan region,,1,,17,,29-Nov-18,,,IEEE,IEEE Conferences
A Family of New Ergonomic Harness Mechanisms for Full-Body Natural Constrained Motions in Virtual Environments,R. E. Kaufman,"Dept. of Mech. & Aerosp. Eng., George Washington Univ., DC",2007 IEEE Symposium on 3D User Interfaces,10-Apr-07,2007,,,,,"A family of new virtual reality harness mechanisms has been developed by this investigator to constrain an immersed user within the field of view of a virtual locomotion sensing system while permitting natural motions such as twisting, turning, jogging in place, dropping to the knees or moving to a prone position. The author has also developed a generalized synthesis approach to the design of such harness systems. Unwanted rotational inertial loads felt by the user are minimized while compliant constraints have been tailored to provide natural feedback forces. These ergonomic forces enhance the experience of virtual motion by partially substituting for the missing real-world dynamic loads encountered in locomotion. They also provide subtle, natural cues to the immersed user that aid the user in remaining centered. Unlike some other virtual locomotion systems, these devices are passive, relatively low-cost, easy and natural to use, making them minimally intrusive on the process of learning the simulated task",,1-4244-0907-1,10.1109/3DUI.2007.340776,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4142847,,Ergonomics;Virtual environment;Virtual reality;Turning;Haptic interfaces;Human factors;User interfaces;Tracking;Magnetic heads;Aerospace engineering,ergonomics;virtual reality,ergonomic harness mechanism;full-body natural constrained motion;virtual environment;virtual reality harness mechanism;virtual locomotion sensing system;rotational inertial;natural feedback force;ergonomic force;virtual motion;real-world dynamic load;virtual locomotion system,,3,3,2,,10-Apr-07,,,IEEE,IEEE Conferences
Agent and user inhabited virtual communities: a case study,A. Nijholt,"Parlevink Res. Group, Twente Univ., Enschede, Netherlands",KES'2000. Fourth International Conference on Knowledge-Based Intelligent Engineering Systems and Allied Technologies. Proceedings (Cat. No.00TH8516),6-Aug-02,2000,1,,337,340 vol.1,"We report ongoing research in a virtual reality environment where visitors can interact with agents that help them to obtain information, to perform certain transactions and to collaborate with them in order to get some tasks done. This environment is a laboratory for research and experiments on users interacting with agents in multimodal ways, referring to visualized information and making use of knowledge possessed by domain agents, but also by agents that represent other visitors of this environment. Although the environment is tuned to a theatre environment, we think there are sufficient general properties in order to learn about other applications, e.g other theme oriented, educational and entertainment environments and even electronic commerce environments. In addition, especially in the home environment, there will be a growing need for social interfaces that are inhabited by visualized domain agents, user agents, friends and relatives that help, advise, and 'negotiate' on matters that range from what to prepare for dinner to how to end a relationship.",,0-7803-6400-7,10.1109/KES.2000.885825,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=885825,,Computer aided software engineering;Virtual reality;Buildings;Intelligent systems;Speech;Navigation;Collaboration;Electronic commerce;Visualization;Natural languages,virtual reality;natural languages;software agents;humanities,virtual communities;virtual reality environment;visitors;agents;visualized information;domain agents;theatre environment;education;entertainment;electronic commerce;home environment;social interfaces;visualized domain agents;user agents;natural language dialogue,,,2,8,,6-Aug-02,,,IEEE,IEEE Conferences
Volumetric Capture of Humans With a Single RGBD Camera via Semi-Parametric Learning,R. Pandey; A. Tkach; S. Yang; P. Pidlypenskyi; J. Taylor; R. Martin-Brualla; A. Tagliasacchi; G. Papandreou; P. Davidson; C. Keskin; S. Izadi; S. Fanello,Google; Google; Google; Google; Google Inc.; Google; Google Inc.; Ariel AI; Google Inc.; Google; Google; Google,2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),9-Jan-20,2019,,,9701,9710,"Volumetric (4D) performance capture is fundamental for AR/VR content generation. Whereas previous work in 4D performance capture has shown impressive results in studio settings, the technology is still far from being accessible to a typical consumer who, at best, might own a single RGBD sensor. Thus, in this work, we propose a method to synthesize free viewpoint renderings using a single RGBD camera. The key insight is to leverage previously seen ‚Äúcalibration‚Äù images of a given user to extrapolate what should be rendered in a novel viewpoint from the data available in the sensor. Given these past observations from multiple viewpoints, and the current RGBD image from a fixed view, we propose an end-to-end framework that fuses both these data sources to generate novel renderings of the performer. We demonstrate that the method can produce high fidelity images, and handle extreme changes in subject pose and camera viewpoints. We also show that the system generalizes to performers not seen in the training data. We run exhaustive experiments demonstrating the effectiveness of the proposed semi-parametric model (i.e. calibration images available to the neural network) compared to other state of the art machine learned solutions. Further, we compare the method with more traditional pipelines that employ multi-view capture. We show that our framework is able to achieve compelling results, with substantially less infrastructure than previously required.",2575-7075,978-1-7281-3293-8,10.1109/CVPR.2019.00994,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8954320,3D from Single Image;Deep Learning ; Image and Video Synthesis,,calibration;cameras;image colour analysis;image sensors;image texture;interactive systems;learning (artificial intelligence);rendering (computer graphics);virtual reality,single RGBD camera;semiparametric learning;volumetric performance capture;4D performance capture;studio settings;typical consumer;single RGBD sensor;free viewpoint renderings;calibration images;multiple viewpoints;current RGBD image;end-to-end framework;data sources;novel renderings;high fidelity images;camera viewpoints;training data;semiparametric model;employ multiview capture;machine learned solutions,,,,51,,9-Jan-20,,,IEEE,IEEE Conferences
Real-time unsupervised neural networks for non-implementable in natural noise: A refutable hypothesis based on experiment,E. Nold; K. Tucker; R. Long; M. Georgiopoulos,"Univ. of Central Florida, Orlando, FL, USA; Univ. of Central Florida, Orlando, FL, USA; Univ. of Central Florida, Orlando, FL, USA; Univ. of Central Florida, Orlando, FL, USA",IJCNN-91-Seattle International Joint Conference on Neural Networks,6-Aug-02,1991,ii,,924 vol.2,,"Summary form only given. An analog computer implementation of an unsupervised neural network was investigated. Results indicate that the implementation of the nonlinear ordinary differential equations of the Outstar learning model are destabilized by unavoidable multiplicative biases produced by physical circuitry, attributable to 1/f noise drift. A multiplicative offset perturbation model was developed to simulate the instabilities discovered in the analog implementation. Timing and scaling optimizations are required to allow stable learning of spatial patterns. These results were generalized with the hypothesis that real-time unsupervised neural networks are nonimplementable in natural noise. The perturbation model facilitates the testing of this hypothesis. It seems that 1/f phenomena are teleologically related to physically occurring self-organizing systems. The authors suggest a fractional calculus. Outstar generalization for incorporating nonzero mean noise-induced parameters caused by multiple scales of self-organizing interactions.<>",,0-7803-0164-1,10.1109/IJCNN.1991.155579,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=155579,,Neural networks;1f noise;Analog computers;Differential equations;Circuit noise;Computational modeling;Circuit simulation;Timing;Testing;Fractional calculus,analogue simulation;electron device noise;learning systems;neural nets;nonlinear differential equations;perturbation techniques;random noise;real-time systems;self-adjusting systems;stability;virtual machines,timing optimizations;natural noise;analog computer implementation;nonlinear ordinary differential equations;Outstar learning model;multiplicative biases;1/f noise drift;multiplicative offset perturbation model;instabilities;scaling optimizations;spatial patterns;real-time unsupervised neural networks;self-organizing systems;fractional calculus;nonzero mean noise-induced parameters,,,,,,6-Aug-02,,,IEEE,IEEE Conferences
Self-Supervised Pose Adaptation for Cross-Domain Image Animation,C. Wang; C. Xu; D. Tao,"School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW, Australia; School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW, Australia; School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW, Australia",IEEE Transactions on Artificial Intelligence,25-Nov-20,2020,1,1,34,46,"Image animation is to animate a still image of the object of interest using poses extracted from another video sequence. Through training on a large-scale video dataset, most existing approaches aim to explore disentangled appearance and pose representations of training frames. Then, the desired output with a specific appearance and pose can be synthesized via recombining learned representations. However, in some real-world applications, test images may lack the corresponding video ground-truth or follow a different distribution than the distribution of the training video frames (i.e., different domains), which largely limit the performance of existing methods. In this paper, we propose domain-independent pose representations that are compatible with and accessible by still images from a different domain. Specifically, we devise a two-stage self-supervised pose adaptation framework for general image animation tasks. A domain-independent pose adaptation generative adversarial network (DIPA-GAN) and a shuffle-patch generative adversarial network (Shuffle-patch GAN) are proposed to penalize the rationality of the synthesized frame's pose and appearance, respectively. Finally, experiments evaluated on various image animation tasks, which include same/cross-domain moving objects, facial expression transfer and human pose retargeting, demonstrate the superiority of the proposed framework over prior literature. Impact Statement-Image animation is a popular technology in video production. Benefiting from the rapid development of artificial intelligence (AI), recent image animation algorithms have been widely used in real-world applications, such as virtual AI news anchor, virtual try-on, and face swapping. However, most existing methods are designed for specific cases. To animate a new portrait, users are asked to collect hundreds of images of the same person and train a new model. The technology proposed in this paper overcomes these training limitations and generalizes image animations. In the challenging cross-domain facial expression transfer task, the user study demonstrated that our technology achieved more than 20% increase in animation success rate. The proposed technology could benefit users in a wide variety of industries including movie production, virtual reality, social media and online retail.",2691-4581,,10.1109/TAI.2020.3031581,Australian Research Council Projects; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229197,Adversarial learning;deep learning;representation learning,Animation;Task analysis;Training;Generative adversarial networks;Artificial intelligence;Solid modeling;Adaptation models,computer animation;face recognition;feature extraction;image classification;image motion analysis;image sequences;learning (artificial intelligence);neural nets;pose estimation;video signal processing;virtual reality,cross-domain image animation;video sequence;large-scale video dataset;learned representations;adaptation framework;general image animation tasks;adaptation generative adversarial network;shuffle-patch generative adversarial network;synthesized frame;video production;animation success rate;cross-domain facial expression transfer task;image animation algorithm;video ground-truth,,,,59,IEEE,19-Oct-20,,,IEEE,IEEE Journals
Technology meets psychology: Psychological background in virtual realities,P. P√ºrcher; M. H√∂fler,"University of Graz, Austria; Danube University Krems, Austria","2018 41st International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)",2-Jul-18,2018,,,633,637,"In recent years, virtual realities (VRs) have become an important resource for various applications such as entertainment, architecture, therapy and learning. Previous research already investigated the effects of psychological processes such as immersion, flow and involvement in context of VRs. However, there are also more basic psychological processes such as perception and attention which both play a crucial role when creating and using VRs. Due to perceptual processes we perceive input from our environment and create a subjective reality in our mind which often does not correspond to the objective reality. Due to attentional processes, we are able to filter relevant information that is processed via our senses from all perceivable information. In the current study, we interviewed technicians about their degree of awareness and knowledge about such attentional and perceptual processes in general and within VRs. The findings showed that there is a lack of knowledge regarding these processes, suggesting that there is need for a broader discussion of the topic. This work aims to be the first step towards this direction.",,978-953-233-095-3,10.23919/MIPRO.2018.8400119,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8400119,virtual realities;perception;attention;technicians,Psychology;Virtual reality;Entertainment industry;Computer architecture;Medical treatment;Information filters,psychology;virtual reality,Psychological background;virtual realities;VR;relevant information filtering,,,,21,,2-Jul-18,,,IEEE,IEEE Conferences
Machine Learning Driven Method for Indoor Positioning Using Inertial Measurement Unit,J. Deng; Q. Xu; A. Ren; Y. Duan; A. Zahid; Q. H. Abbasi,"Xidian University,School of Engineering,Xi‚Äôan,China; Xidian University,School of Engineering,Xi‚Äôan,China; Xidian University,School of Engineering,Xi‚Äôan,China; Xidian University,School of Engineering,Xi‚Äôan,China; University of Glasgow,James Watt School of Engineering,Glasgow,United Kingdom; University of Glasgow,James Watt School of Engineering,Glasgow,United Kingdom",2020 International Conference on UK-China Emerging Technologies (UCET),29-Sep-20,2020,,,1,4,"The application of inertial measurement unit (IMU) is widespread in many domains, but the main hindrance in localization is the errors accumulation in the integration process over a long time. Recently, we notice that many researchers have applied machine learning (ML) algorithms to indoor positioning by using IMU sensor data, which sufficiently proves that the 6-dim data collected by IMU sensor contain a lot of information. In this paper, we present a ML driven method to make a regression between IMU sensor data and 2-D coordinates. To build a regression model with better generalization and lower computational complexity, this paper carries out feature extraction in the time-and time-frequency domain. The simulation run on Intel core i5-4200h shows that the method is able to suppress the drift of the inertial navigation system after a long-time travel. In comparison of GPS+IMU using extended Kalman filtering (EKF), the positioning RMS of our method on circular trajectories with a radius of 7 meters and 10.5 meters is reduced by at most 70.1% and 86.1%, respectively.",,978-1-7281-9488-2,10.1109/UCET51115.2020.9205369,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9205369,inertial measurement unit;machine learning;regression problem;feature extraction;indoor positioning,Feature extraction;Trajectory;Time-frequency analysis;Kalman filters;Navigation;Machine learning;Measurement units,computational complexity;feature extraction;Global Positioning System;indoor navigation;inertial navigation;Kalman filters;learning (artificial intelligence);least mean squares methods;nonlinear filters;regression analysis;telecommunication computing;time-frequency analysis,indoor positioning;inertial measurement unit;integration process;machine learning algorithms;IMU sensor data;ML driven method;regression model;time-frequency domain;inertial navigation system;long-time travel;GPS+IMU;positioning RMS;2D coordinates;computational complexity;feature extraction;Intel core i5-4200h;extended Kalman filtering;EKF,,,,21,,29-Sep-20,,,IEEE,IEEE Conferences
Driver's cognitive state classification toward brain computer interface via using a generalized and supervised technology,C. Chuang; P. Lai; L. Ko; B. Kuo; C. Lin,"Institute of Electrical Control Engineering and Brain Research Center, National Chiao-Tung University, 1001 Ta Hsueh Rd., Hsinchu 300, Taiwan; Graduate Institute of Educational Measurement and Statistics, National Taichung University, 140 MinShen Rd., 403, Taiwan; Department of Biological Science and Technology and Brain Research Center, National Chiao Tung University, 1001 Ta Hsueh Rd., Hsinchu 300, Taiwan; Graduate Institute of Educational Measurement and Statistics, National Taichung University, 140 MinShen Rd., 403, Taiwan; Institute of Electrical Control Engineering and Brain Research Center, National Chiao-Tung University, 1001 Ta Hsueh Rd., Hsinchu 300, Taiwan",The 2010 International Joint Conference on Neural Networks (IJCNN),14-Oct-10,2010,,,1,7,"Growing numbers of traffic accidents had become a serious social safety problem in recent years. The main factor of the high fatalities was the obvious decline of the driver's cognitive state in their perception, recognition and vehicle control abilities while being sleepy. The key to avoid the terrible consequents is to build a detecting system for ongoing assessment of driver's cognitive state. A quickly growing research, brain-computer interface (BCI), offers a solution offering great assistance to those who require alternative communicatory and control mechanisms. In this study, we propose an alertness/drowsiness classification system based on investigating electroencephalographic (EEG) brain dynamics in lane-keeping driving experiments in a virtual reality (VR) driving environment with a motion platform. The core of the classification system is composed of dimension reduction technique and classifier learning algorithm. In order to find the suitable method for better describing the data structure, we explore the performances using different feature extraction and feature selection methods with different classifiers. Experiment results show that the accuracy is over 80% in most combinations and even near 90% under Principal Component Analysis (PCA) and Nonparametric Weighted Feature Extraction (NWFE) going with Gaussian Maximum Likelihood classifier (ML) and k-Nearest-Neighbor classifier (kNN), respectively. In addition, this developed classification system can also solve the individual brain dynamic differences caused from different subjects and overcome the subject dependent limitation. The optimized solution with better accuracy performance out of all combinations can be considered to implement in the kernel brain-computer interface.",2161-4407,978-1-4244-6918-5,10.1109/IJCNN.2010.5596835,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5596835,,Feature extraction;Driver circuits;Electroencephalography;Classification algorithms;Brain modeling;Principal component analysis;Support vector machines,brain-computer interfaces;cognition;data structures;driver information systems;electroencephalography;feature extraction;Gaussian processes;maximum likelihood estimation;medical signal processing;principal component analysis;road accidents;road safety;road traffic;signal classification;virtual reality,driver cognitive state classification;social safety problem;vehicle control;detecting system;BCI;alertness-drowsiness classification system;electroencephalographic brain dynamics;lane-keeping driving experiments;virtual reality;motion platform;classifier learning algorithm;dimension reduction technique;data structure;feature selection methods;principal component analysis;PCA;nonparametric weighted feature extraction;NWFE;Gaussian maximum likelihood classifier;ML classifier;k-nearest-neighbor classifier;kNN;kernel brain-computer interface,,9,,25,,14-Oct-10,,,IEEE,IEEE Conferences
Parallel image pre-processing for in-game object classification,P. Sundareson,"GPU-SW, Nvidia",2017 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia),8-Mar-18,2017,,,115,116,"Games that involve photo-realistic rendering of virtual worlds, Special effects, VR, involve highly complex calculations on the GPU (Graphics Processing Unit). While GPUs have specialized cores that accelerate Graphics operations, they are also capable of general purpose computing. In this paper, a specific data flow is chosen for the use-case of in-game object-classification. This use-case involves converting large input graphics resolutions (4k) to much lower resolutions (256√ó256) needed for compute. We compare the different approaches available for executing the data flow using CUDA (Compute Unified Device Architecture) without impacting gaming performance, and publish comparisons on different classes of GPUs for the first time. It is shown that best performance is achieved with a combination of well optimized algorithms, priority of work assignment, and a flexible execution framework.",,978-1-5386-2787-7,10.1109/ICCE-ASIA.2017.8309316,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8309316,Compute Unified Device Architecture (CUDA);DirectX;Gaming;Machine Learning;GPU;Image Preprocessing,Graphics processing units;Games;Performance evaluation;Image resolution;Object detection;Conferences,computer games;graphics processing units;image classification;image resolution;parallel architectures;rendering (computer graphics);virtual reality,virtual worlds;Special effects;highly complex calculations;Graphics Processing Unit;Graphics operations;general purpose computing;specific data flow;input graphics resolutions;Compute Unified Device Architecture;in-game object classification;photo-realistic rendering;flexible execution framework;work assignment;CUDA;parallel image preprocessing;GPU,,,,10,,8-Mar-18,,,IEEE,IEEE Conferences
Making 360¬∞ Video Watchable in 2D: Learning Videography for Click Free Viewing,Y. Su; K. Grauman,"Univ. of Texas at Austin, Austin, TX, USA; Univ. of Texas at Austin, Austin, TX, USA",2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),9-Nov-17,2017,,,1368,1376,"360¬∞ Video requires human viewers to actively control where to look while watching the video. Although it provides a more immersive experience of the visual content, it also introduces additional burden for viewers, awkward interfaces to navigate the video lead to suboptimal viewing experiences. Virtual cinematography is an appealing direction to remedy these problems, but conventional methods are limited to virtual environments or rely on hand-crafted heuristics. We propose a new algorithm for virtual cinematography that automatically controls a virtual camera within a 360¬∞ video. Compared to the state of the art, our algorithm allows more general camera control, avoids redundant outputs, and extracts its output videos substantially more efficiently. Experimental results on over 7 hours of real in the wild video show that our generalized camera control is crucial for viewing 360¬∞ video, while the proposed efficient algorithm is essential for making the generalized control computationally tractable.",1063-6919,978-1-5386-0457-1,10.1109/CVPR.2017.150,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8099633,,Cameras;Trajectory;Two dimensional displays;Visualization;Cinematography;Computational efficiency;Lenses,cameras;cinematography;learning (artificial intelligence);video recording;video signal processing;virtual reality,videography;click free viewing;human viewers;visual content;virtual cinematography;virtual environments;virtual camera;generalized camera control;360¬∞ video watchable,,16,,43,,9-Nov-17,,,IEEE,IEEE Conferences
Education and Training for Troubleshooting in Automotive Chassis,J. S. Liang,"Yung-Ta Institute of Technology and Commerce, Taiwan",Fourth International Conference on Information Technology (ITNG'07),16-Apr-07,2007,,,311,316,"There are several subjects discussed in this research: (1) developing the learning contents for repairing automotive chassis; (2) building the virtual and interactive platform for browsing and practice of troubleshooting; (3) creating the online evaluation tools and effectiveness analysis. Meanwhile, the framework has been tested and implemented in the course, ""Automotive Practice: Chassis,"" in the spring semester of 2004. The platform developed is not dependent on specific automobile style and software configuration and it uses open software (e.g. Java, VRML, PHP, MySQL, etc.) in the virtual display and data storage. The system can achieve the advantages and goals of (1) constructing a Web-based troubleshooting architecture of automotive chassis that can enhance learners' knowledge and promote practical technologies; (2) providing references for drivers in self-detection of general chassis problems to raise driving safety; (3) creating a prototype environment for distance learning to eliminate the limitation of space and time on learning; (4) raising the learning effectiveness and motivation of on-site and distant learners",,0-7695-2776-0,10.1109/ITNG.2007.81,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4151702,,Automotive engineering;Space technology;Testing;Automobiles;Java;Displays;Memory;Computer architecture;Safety;Prototypes,automotive engineering;computer based training;distance learning;Internet;public domain software;virtual reality languages,automotive chassis troubleshooting;Virtual Reality Modelling Language;online evaluation tools;open software;Web-based troubleshooting architecture;distance learning,,,,14,,16-Apr-07,,,IEEE,IEEE Conferences
Bangla Sign Language recognition using convolutional neural network,F. Yasir; P. W. C. Prasad; A. Alsadoon; A. Elchouemi; S. Sreedharan,"Charles Sturt University Study Centre, Sydney, Australia; Charles Sturt University Study Centre, Sydney, Australia; Charles Sturt University Study Centre, Sydney, Australia; Walden University, USA; Department of Computer Engineering, College of Computer Science, King Khalid University, KSA","2017 International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT)",23-Apr-18,2017,,,49,53,"This paper presents a learning based approach to Bangla Sign Language(BdSL) recognition using the convolutional neural network. In our proposed method, a virtual reality-based hand tracking controller known as Leap motion controller (LMC) has introduced to track the continuous motion of the hands. LMC provides a skeletal model of the hand with appropriate data of hand position, orientation, rotation, fingertips, grabbing and more non-linear features. This controller preprocessed all the motion features and provides error free data. This machine calibrates with the environment and builds a virtual hand in a space. LMC also calculates the rotation, orientation, and textures from hands to determine and to extract hand gesture. In the next process, an efficient method is established to proceed a sequence of frames for positional hand gestures and summarize them to a shorter and more generalized sequence of lines and curves which are added to a Hidden Markov Model. For each sign of expression, we considered a start and an end point of state and segmented the state transitions into segmented HMM. In the segmentation, we assumed the state scope of the hidden variables is discrete. The transition probabilities controlled the way of hidden state at a distinct time. If there is a histogram difference in any state, the transition state moved to new frame to achieve a new sign expression. If there is no hand gesture in the frame, the state has ended by moving to the end point of the model. In the end point, we evaluated the desired hand gesture for recognition. After evaluation, hand gesture data set are proceeded over the convolutional neural network (CNN) and built a decision network. Each neuron is built up by calculating the dot product of extracted features in the dataset. In CNN, a single vector of hand gesture data is received and connected through a series of hidden layers and in the end point computed as a single vector loss function. Each feature is considered as a hidden layer. Determining the least loss function, the network recognizes the expected sign expression. In our experiment, we considered training data first to create the neurons in our network as a supervised way. We achieved significant results from our basic sign expressions in a 3% rate of error where without distortion the rate reduced to 2%. This is an enormous achievement in the Bangla sign language recognition method.",,978-1-5090-6106-8,10.1109/ICICICT1.2017.8342533,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8342533,Bangla Sign Language Recognition;Hidden Markov model;Convolution neural network;leap motion controller,Thumb;Hidden Markov models;Assistive technology;Gesture recognition;Bones;Feature extraction,computer vision;convolution;feature extraction;feedforward neural nets;gesture recognition;hidden Markov models;learning (artificial intelligence);motion control;object detection;sign language recognition;virtual reality,LMC;skeletal model;hand position;motion features;error free data;positional hand gestures;shorter sequence;Hidden Markov Model;end point;state transitions;state scope;hidden state;transition state;desired hand gesture;hand gesture data;convolutional neural network;decision network;hidden layer;basic sign expressions;Bangla sign language recognition method;virtual reality;Leap motion controller;continuous motion;virtual hands;generalized sequence;sign expression;BdSL recognition;CNN,,,,19,,23-Apr-18,,,IEEE,IEEE Conferences
Development of Internet virtual butterfly museum,Wernhuar Tarng,"Dept. of Math. & Sci. Educ., Nat. Hsin-Chu Teachers Coll., Taiwan","International Conference on Computers in Education, 2002. Proceedings.",20-Mar-03,2002,,,1139,1143 vol.2,"The butterfly is a valuable nature resource from the viewpoint of education and tourism. In recent years, the over-exploitation of mountainous areas and overuse of pesticide results in dramatic decrease of butterfly species and populations. This paper studies the related network and virtual reality technologies for developing a virtual butterfly museum and the objective is to provide students and the general public with a web-learning environment for studying butterfly ecology. The virtual museum exhibits several species of butterflies, including Pieridae, Papilionidae, Danaidae, Satyridae, Nymphalidae, as well as insects often seen in Taiwan. We can visit it through network at any time and from anywhere to proceed with observation and learning activities, and discuss with others on the website. Therefore, it can help people understand butterfly ecology and promote the protection of natural environments.",,0-7695-1509-6,10.1109/CIE.2002.1186174,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1186174,,Internet;Virtual reality;Insects;Educational institutions;Environmental factors;Ecosystems;Feeds;Mathematics;Protection;Earth,computer aided instruction;teaching;virtual reality;biology,Internet virtual butterfly museum;education;tourism;students;web-learning environment;butterfly ecology;observation activities;learning activities;website,,,,14,,20-Mar-03,,,IEEE,IEEE Conferences
Part-based robot grasp planning from human demonstration,J. Aleotti; S. Caselli,"RIMLab - Robotics and Intelligent Machines Laboratory, Dipartimento di Ingegneria dell'Informazione, University of Parma, Italy; RIMLab - Robotics and Intelligent Machines Laboratory, Dipartimento di Ingegneria dell'Informazione, University of Parma, Italy",2011 IEEE International Conference on Robotics and Automation,18-Aug-11,2011,,,4554,4560,"In this work we introduce a novel approach for robot grasp planning. The proposed method combines the benefits of programming by human demonstration for teaching appropriate grasps with those of automatic 3D shape segmentation for object recognition and semantic modeling. The work is motivated by important studies on human manipulation suggesting that when an object is perceived for grasping it is first parsed in its constituent parts. Following these findings we present a manipulation planning system capable of grasping objects by their parts which learns new tasks from human demonstration. The central advantage over previous approaches is the use of a topological method for shape segmentation enabling both object retrieval and part-based grasp planning according to the affordances of an object. Manipulation tasks are demonstrated in a virtual reality environment using a data glove. After the learning phase, each task is planned and executed in a robot environment that is able to generalize to similar, but previously unknown, objects.",1050-4729,978-1-61284-385-8,10.1109/ICRA.2011.5979632,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5979632,,Planning;Robots;Shape;Grasping;Humans;Three dimensional displays;Solid modeling,data gloves;image retrieval;image segmentation;learning (artificial intelligence);manipulators;object recognition;planning (artificial intelligence);solid modelling;task analysis;topology;virtual reality,part-based robot grasp planning;human demonstration;appropriate grasps teaching;automatic 3D shape segmentation;object recognition;semantic modeling;human manipulation;manipulation planning system;grasping objects;topological method;object retrieval;part-based grasp planning;manipulation tasks;virtual reality environment;data glove;learning phase;robot environment,,31,,30,,18-Aug-11,,,IEEE,IEEE Conferences
Positioning. Navigation and Awareness of the !VAMOS! Underwater Robotic Mining System,J. Almeida; A. Martins; C. Almeida; A. Dias; B. Matias; A. Ferreira; P. Jorge; R. Martins; M. Bleier; A. Nuchter; J. Pidgeon; S. Kapusniak; E. Silva,"INESC Technology and Science, ISEP -School of Engineering, Porto, Portugal; INESC Technology and Science, ISEP -School of Engineering, Porto, Portugal; INESC Technology and Science, Porto, Portugal; INESC Technology and Science, ISEP -School of Engineering, Porto, Portugal; INESC Technology and Science, Porto, Portugal; INESC Technology and Science, Porto, Portugal; INESC Technology and Science, Porto, Portugal; INESC Technology and Science, Porto, Portugal; Zentrum fur Telematik e.V., Wurzburg, Germany; Informatics VII Robotics and Telematics, Julius Maximilian University of Wurzburg and Zentrum fur Telematik e. V., Wurzburg, Germany; BMT WBM Pty Ltd, Brisbane, Australia; Soil Machine Dynamics, Newcastle-Upon Tyne, United Kingdom; INESC Technology and Science, ISEP -School of Engineering, Porto, Portugal",2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),6-Jan-19,2018,,,1527,1533,"This paper presents the positioning, navigation and awareness (PNA) system developed for the Underwater Robotic Mining System of the !VAMOS! project [1]. It describes the main components of the !VAMOS! system, the PNA sensors in each of those components, the global architecture of the PNA system, and its main subsystems: Position and Navigation, Realtime Mine Modeling, 3D Virtual reality HMI and Real-time grade system. General results and lessons learn during the first mining field trial in Lee Moor, Devon, UK during the months of September and October 2017 are presented.",2153-0866,978-1-5386-8094-0,10.1109/IROS.2018.8593869,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593869,,Three-dimensional displays;Sensor systems;Solid modeling;Presence network agents;Virtual reality;Real-time systems,control engineering computing;mining;mobile robots;position control;virtual reality,global architecture;real-time grade system;3D virtual reality HMI;realtime mine modeling;¬°VAMOS!;underwater robotic mining system;navigation;mining field trial;PNA system;PNA sensors,,,,15,,6-Jan-19,,,IEEE,IEEE Conferences
Interestingness Prediction & its Application to Immersive Content,G. Marquant; C. Demarty; C. Chamaret; J. Sirot; L. Chevallier,"Technicolor, Cesson-S√©vign√©, France; Technicolor, Cesson-S√©vign√©, France; Technicolor, Cesson-S√©vign√©, France; Technicolor, Cesson-S√©vign√©, France; Technicolor, Cesson-S√©vign√©, France",2018 International Conference on Content-Based Multimedia Indexing (CBMI),1-Nov-18,2018,,,1,6,"Which parts or objects are interesting in a content? In this paper we first propose three computational models to automatically predict interestingness rankings of areas/objects inside a 2D picture. We based our modeling on previous experimental findings to ensure reliability of the prediction when compared to the human assessement of interestingness. Our two first models are based on low level features, extracted from image regions, which have been stated as useful in the human interest process. A baseline model is built by estimating a linear regression from a small dataset of 49 images. The second model estimates a rewarding term based on additional experimental observations. By adding image semantics, we then construct a last model, which more generally benefits from a better understanding of the content. It also integrates notions such that unusualness or human beings' presence that have proven to play key roles in the interestingness process. Finally, targeting VR applications, we extend our models to immersive content, both images and videos, and propose an innovative application to guide the viewer in his/her navigation based on intuitive visual or audio cues.",,978-1-5386-7021-7,10.1109/CBMI.2018.8516524,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516524,interestingness prediction;objectinterestingness;immersive content,Computational modeling;Feature extraction;Semantics;Predictive models;Task analysis;Solid modeling;Videos,data mining;feature extraction;learning (artificial intelligence);very large databases;video signal processing;virtual reality,image semantics;additional experimental observations;linear regression;baseline model;human interest process;image regions;low level features;interestingness rankings;computational models;interestingness prediction;innovative application;immersive content;VR applications;interestingness process,,,,33,,1-Nov-18,,,IEEE,IEEE Conferences
Extending Linden Scripting Language on OpenSim,B. Sun; X. Zhang; H. Wu,"Coll. of Inf. Sci. & Technol., Beijing Normal Univ., Beijing, China; Coll. of Inf. Sci. & Technol., Beijing Normal Univ., Beijing, China; Coll. of Inf. Sci. & Technol., Beijing Normal Univ., Beijing, China",2012 19th Asia-Pacific Software Engineering Conference,18-Feb-13,2012,1,,488,492,"OpenSim is a 3D virtual reality platform and now has been widely used in many fields. Its powerful scripting technology is helpful for third party development. Linden scripting language is the most important scripting language in OpenSim, which only supports virtual worlds' common applications but is weak in domain-specific applications. In order to extend Linden scripting functions, a general extended scheme is proposed in this paper. The structure and rule of OpenSim's scripting engine are analyzed. Then the management mechanisms of thread pool and queue are summed up. We present four extending approaches. Their implementations and scopes of applications are compared. We choose expanding service modules as the general extended scheme. By extending database service of the item bank, scripting functions (e.g., llMakeTest) are developed to support teaching evaluation in 3D virtual learning environments on OpenSim platform. The correctness of the extended scheme is proved by the case study. The scheme provides a guideline for developing Linden scripting functions for specific applications. It is verified that expanding OpenSim's domain-specific applications based on scripting technology is feasible.",1530-1362,978-1-4673-4930-7,10.1109/APSEC.2012.111,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6462700,OpenSim;Linden scripting language;scripting engine;extended scheme,Education;Engines;Libraries;Instruction sets;Electronic publishing;Internet,authoring languages;virtual reality,Linden scripting language;3D virtual reality platform;scripting technology;Linden scripting function;management mechanism;database service;item bank;3D virtual learning environment;OpenSim platform,,5,,22,,18-Feb-13,,,IEEE,IEEE Conferences
Web-Based Virtual Research Environments (VRE): Support Collaboration in e-Science,X. Yang; R. Allan,"Daresbury Laboratory, UK; Daresbury Laboratory, UK",2006 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology Workshops,8-Jan-07,2006,,,184,187,"Interdisciplinary challenges in research today require increasingly cooperation among researchers. The demand for building up virtual research environments (VRE) becomes more and more urgent than ever before. Built on top of Web, VRE systems aim at supporting research activities with much more efficient methods for sharing data and knowledge bases. In this paper, we present our recent work on development of a general-purpose VRE system by extending Sakai, an advanced collaboration and learning platform, with tools for accessing Microsoft exchange server through WebDAV, integrating existing grid tools to access remote computing and data grid resources via Web services for remote portlets (WSRP), and managing documents to help organising workshops and conferences",,0-7695-2749-3,10.1109/WI-IATW.2006.148,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4053231,,Collaboration;Collaborative work;Collaborative tools;Grid computing;Conference management;Web services;Video sharing;Videoconference;Laboratories;Information systems,grid computing;groupware;natural sciences computing;network servers;virtual reality;Web services,Web-based virtual research environments;support collaboration;e-science;Microsoft exchange server;WebDAV;Web services;remote portlets;grid tools,,2,,8,,8-Jan-07,,,IEEE,IEEE Conferences
Robust Adaptive Neural Tracking Control for a Class of Stochastic Nonlinear Interconnected Systems,H. Wang; X. Liu; K. Liu,"Department of Mathematics, Bohai University, Jinzhou, China; Faculty of Engineering, Lakehead University, Thunder Bay, ON, Canada; Faculty of Engineering, Lakehead University, Thunder Bay, ON, Canada",IEEE Transactions on Neural Networks and Learning Systems,20-May-17,2016,27,3,510,523,"In this paper, an adaptive neural decentralized control approach is proposed for a class of multiple input and multiple output uncertain stochastic nonlinear strong interconnected systems. Radial basis function neural networks are used to approximate the packaged unknown nonlinearities, and backstepping technique is utilized to construct an adaptive neural decentralized controller. The proposed control scheme can guarantee that all signals of the resulting closed-loop system are semiglobally uniformly ultimately bounded in the sense of fourth moment, and the tracking errors eventually converge to a small neighborhood around the origin. The main feature of this paper is that the proposed approach is capable of controlling the stochastic systems with strong interconnected nonlinearities both in the drift and diffusion terms that are the functions of all states of the overall system. Simulation results are used to illustrate the effectiveness of the suggested approach.",2162-2388,,10.1109/TNNLS.2015.2412035,National Natural Science Foundation of China; General Project of Education Department of Liaoning Province; Program for Liaoning Innovative Research Team in University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7066958,Adaptive decentralized control;backstepping approach;neural networks;stochastic nonlinear interconnected systems.;Adaptive decentralized control;backstepping approach;neural networks;stochastic nonlinear interconnected systems,Adaptive systems;Nonlinear systems;Backstepping;Neural networks;Decentralized control;Approximation methods;Vectors,adaptive control;approximation theory;closed loop systems;control nonlinearities;decentralised control;interconnected systems;MIMO systems;neurocontrollers;nonlinear control systems;radial basis function networks;robust control;stochastic systems;uncertain systems,robust control;adaptive neural tracking control;stochastic system;nonlinear interconnected system;uncertain system;radial basis function neural network;backstepping technique;adaptive neural decentralized controller;closed-loop system;interconnected nonlinearities,,152,,50,,24-Mar-15,,,IEEE,IEEE Journals
Comparing CNNs and JPEG for Real-Time Multi-view Streaming in Tele-Immersive Scenarios,K. Konstantoudakis; E. Christakis; P. Drakoulis; A. Doumanoglou; N. Zioulis; D. Zarpalas; P. Daras,"Visual Comput. Lab., Centre for Res. & Technol. - Hellas, Thessaloniki, Greece; Visual Comput. Lab., Centre for Res. & Technol. - Hellas, Thessaloniki, Greece; Visual Comput. Lab., Centre for Res. & Technol. - Hellas, Thessaloniki, Greece; Visual Comput. Lab., Centre for Res. & Technol. - Hellas, Thessaloniki, Greece; Visual Comput. Lab., Centre for Res. & Technol. - Hellas, Thessaloniki, Greece; Visual Comput. Lab., Centre for Res. & Technol. - Hellas, Thessaloniki, Greece; Visual Comput. Lab., Centre for Res. & Technol. - Hellas, Thessaloniki, Greece",2018 14th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS),6-May-19,2018,,,77,83,"Deep learning-based codecs for lossy image compression have recently managed to surpass traditional codecs like JPEG and JPEG 2000 in terms of rate-distortion trade-off. However, they generally utilize architectures with large numbers of stacked layers, often making their inference execution prohibitively slow for time-sensitive applications. In this work, we assess the suitability of such compression techniques in real-time video streaming, and, more specifically, next-generation interactive tele-presence applications, which impose stringent latency requirements. To that end, we compare a recently published work on image compression based on convolutional neural networks which achieves state-of-the-art compression ratio using a relatively lightweight architecture, against a CPU and a GPU implementation of JPEG, measuring compression ratios and timings. With these results, we run a simulation of a tele-immersion pipeline for various networking conditions and examine the performance of the compared codecs, calculating framerates and latencies for different codec/network combinations.",,978-1-5386-9385-8,10.1109/SITIS.2018.00022,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8706250,Video;Compression;Tele-Immersion;3D Media Streaming;Performance Evaluation,Image coding;Streaming media;Codecs;Transform coding;Real-time systems;Decoding;Bit rate,convolutional neural nets;data compression;image coding;learning (artificial intelligence);telecommunication computing;video streaming,inference execution;time-sensitive applications;convolutional neural networks;deep learning-based codecs;rate-distortion trade-off;video streaming;lightweight architecture;multiview streaming;lossy image compression techniques;next-generation interactive telepresence applications;teleimmersion pipeline;codec-network combinations;JPEG 2000;rate-distortion;CPU;GPU,,,,23,,6-May-19,,,IEEE,IEEE Conferences
Nautilus-the environment for training and testing,J. Chludil; J. Zara,"Dept. of Comput. Sci. & Eng., Czech Tech. Univ., Prague, Czech Republic; Dept. of Comput. Sci. & Eng., Czech Tech. Univ., Prague, Czech Republic",Proceedings. Sixth IEEE International Workshop on Distributed Simulation and Real-Time Applications,22-Jan-03,2002,,,134,139,The paper describes an experimental Web-based environment for teaching and testing. The application named Nautilus has been developed using Virtual Reality Modeling Language (VRML) and Java language with two special libraries: DILEWA and Vrmlworld. Although the resulting system is intended for low-level virtual reality systems without specialized hardware support it is powerful enough to accurately simulate various situations and scenarios. The currently implemented multi-user environment for training and testing of yacht captains serves as an experimental workbench for creation of general applications where a developer combines a simulated environment from simpler simulation elements. Design and implementation of the system are presented together with several practical observations concerning efficiency of the real-time rendering and the level of implementation difficulty.,1530-1990,0-7695-1853-2,10.1109/DISRTA.2002.1166899,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1166899,,Testing;Marine vehicles;Boats;Libraries;Virtual reality;Java;Computer science;Application software;Computational modeling;Communication system signaling,virtual reality languages;digital simulation;Java;computer based training;teaching;Internet;groupware;software libraries,Nautilus;Web-based environment;teaching;testing;VRML;Java;DILEWA library;Vrmlworld library;multi-user environment;yacht captains;simulation;real-time rendering,,,,12,,22-Jan-03,,,IEEE,IEEE Conferences
Design of Virtual Disassembly System of Front Pump Based on Unity-3d,Z. Xie; Y. Zhou; Y. He; X. Fu,"Hunan City University; Changsha University of Science and Technology; Hunan Flying Roc Information Technology Co., Ltd.; Changsha University of Science and Technology",2019 International Conference on Virtual Reality and Intelligent Systems (ICVRIS),5-Dec-19,2019,,,17,19,"Based on the virtual disassembly technology extended by virtual reality technology in the field of mechanical design and manufacturing, many experiments do not allow students to operate freely for various reasons, but are not affected in the computer. Since the training of employees in thermal power plants is generally based on the mentoring system, the training period is long and the effect is slow, so the virtual pump is used to model the front pump and build the fault library, including common mechanical faults, electrical fault types and disposal. The way to build the database, so that the new factory personnel can quickly master the system, thus saving manpower training costs. In the design process, 3D MAX, Unity, Visual Studio and other software were used to design the 3D graphics and disassemble the process according to the equipment standard, and the virtual simulation teaching can be combined with the physical equipment.",,978-1-7281-5050-5,10.1109/ICVRIS.2019.00012,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920806,virtual reality;virtual disassembly;pre-pump;Unity3D,Solid modeling;Three-dimensional displays;Virtual reality;Shafts;Maintenance engineering;Training;Impellers,assembling;design engineering;fault diagnosis;pumps;recycling;solid modelling;teaching;virtual reality,virtual disassembly technology;virtual reality technology;mechanical design;thermal power plants;virtual pump;mechanical faults;electrical fault;employees training;personnel,,,,13,,5-Dec-19,,,IEEE,IEEE Conferences
An Advanced Computational Intelligence System for Training of Ballet Dance in a Cave Virtual Reality Environment,G. Sun; P. Muneesawang; M. Kyan; H. Li; L. Zhong; N. Dong; B. Elder; L. Guan,"Commun. Univ. of China, Beijing, China; NA; NA; NA; NA; NA; NA; NA",2014 IEEE International Symposium on Multimedia,9-Feb-15,2014,,,159,166,"This paper presents a computer-based system for assessment and training of ballet dance in a CAVE virtual reality environment. The system utilizes Kinect sensor to capture student's dance and extracts features from skeleton joints. This system depends on a structured posture space, which comprises a set of dance elements that represent key moments -- ""postures"", that typically will be so briefly held as to experience as a fleeting moment in a flux -- in the dance movements whose performance we are attempting to assess. The recording captured from the Kinect allows the parsing of dance movement into a structured posture space using the spherical self-organizing map (SSOM). From this, a unique descriptor can be obtained by following gesture trajectories through posture space on the SSOM, which appropriately reflects the subtleties of ballet dance movements. Consequently, the system can recognize the category of movement the student is attempting, and this allows us make a quantitative assessment of individual movements. Based on the experimental results, the proposed system appears to be very effective for recognition and offering generalization across instances of movement. Thus, it is possible for the construction of assessment and visualization of ballet dance movements performed by the student in an instructional, virtual reality setting.",,978-1-4799-4311-1,10.1109/ISM.2014.55,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7033015,dance traning system;dance assesment;CAVE virtual reality environment;gesture recognition;spherical-self-organizing map,Trajectory;Training;Vectors;Gesture recognition;Joints;Histograms;Feature extraction,computer based training;gesture recognition;humanities;self-organising feature maps;virtual reality,computational intelligence system;ballet dance training;computer-based system;ballet dance assessment;CAVE virtual reality environment;Kinect sensor;student dance capture;feature extraction;skeleton joints;structured posture space;dance elements;key posture-moment representation;fleeting moment;dance movement parsing;spherical self-organizing map;SSOM;gesture trajectories;posture space;ballet dance movement subtleties;movement category recognition;quantitative assessment;generalization;movement instances;ballet dance movement assessment construction;ballet dance movement visualization construction;instructional virtual reality,,3,,25,,9-Feb-15,,,IEEE,IEEE Conferences
Crowd Simulation for Emergency Response using BDI Agent Based on Virtual Reality,A. Shendarkar; K. Vasudevan; S. Lee; Y. Son,"Dept. of Computer Science, University of Arizona, Tucson, AZ 85719, U.S.A. email ameya@cs.arizona.edu; Dept. of Systems and Industrial Engineering, University of Arizona, Tucson, AZ 85719, U.S.A. email karthikv@email.arizona.edu; Dept. of Systems and Industrial Engineering, University of Arizona, Tucson, AZ 85719, U.S.A. email mountlee@email.arizona.edu; Dept. of Systems and Industrial Engineering, University of Arizona, Tucson, AZ 85719, U.S.A. email son@sie.arizona.edu",Proceedings of the 2006 Winter Simulation Conference,5-Mar-07,2006,,,545,553,"This paper presents a novel VR (virtual reality) trained BDI (belief, desire, intention) software agent used to construct crowd simulations for emergency response. The BDI framework allows modeling of human behavior with a high degree of fidelity. The proposed simulation has been developed using AnyLogic software to mimic crowd evacuation from an area under a terrorist bomb attack. The attributes that govern the BDI characteristics of the agent are studied by conducting human in the loop experiments in VR using the CAVE (cave automatic virtual environment). To enhance generality and interoperability of the proposed crowd simulation modeling scheme, input data models have been developed to define environment attributes. Experiments are also conducted to demonstrate the effect of various parameters on key performance indicators such as crowd evacuation rate and densities",1558-4305,1-4244-0500-9,10.1109/WSC.2006.323128,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4117652,,Virtual reality;Humans;Computational modeling;Disaster management;Discrete event simulation;Terrorism;Data models;Management training;Intelligent agent;Weapons,emergency services;open systems;software agents;terrorism;virtual reality,emergency response;virtual reality;belief-desire-intention software agent;human behavior;AnyLogic software;terrorist bomb attack;cave automatic virtual environment;interoperability;crowd simulation modeling,,56,,8,,5-Mar-07,,,IEEE,IEEE Conferences
Equipment maintenance system based on virtual reality technology,P. Duan; L. Pang; Y. Jin; Q. Guo; Z. Jia,"Wu Han Military Representative Office of The General Armament Department, China; Wu Han Military Representative Office of The General Armament Department, China; Wu Han Military Representative Office of The General Armament Department, China; Wu Han Military Representative Office of The General Armament Department, China; Wu Han Military Representative Office of The General Armament Department, China","2012 International Conference on Quality, Reliability, Risk, Maintenance, and Safety Engineering",23-Jul-12,2012,,,1396,1399,"This article elaborates the concept and meaning of virtual reality technology and virtual maintenance, discusses the virtual reality technology application in the process of equipment maintenance, and gives a brief introduction to virtual maintenance system, which use VC and vega software as a platform and set up by Multigen Creator and 3D MAX, quoted an cannon as an example.",,978-1-4673-0788-8,10.1109/ICQR2MSE.2012.6246482,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6246482,virtual reality;virtual maintenance;cannon;simulation,Maintenance engineering;Solid modeling;Training;Computational modeling;Virtual reality;Assembly;Data models,maintenance engineering;virtual reality,equipment maintenance system;virtual reality technology application;virtual maintenance system;vega software;Multigen Creator;3D MAX,,1,,8,,23-Jul-12,,,IEEE,IEEE Conferences
ATVR: An Attention Training System using Multitasking and Neurofeedback on Virtual Reality Platform,M. Zhang; J. Zhang; D. Zhang,"University of California, San Diego; Xiamen University; Shandong Academy of Sciences",2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),27-Dec-19,2019,,,159,1593,"We present an attention training system based on the principles of multitasking training scenario and neurofeedback, which can be targeted on PCs and VR platforms. Our training system is a video game following the principle of multitasking training, which is designed for all ages. It adopts a non-invasive Electroencephalography (EEG) device Emotiv EPOC+ to collect EEG. Then wavelet package transformation(WPT) is applied to extract specific components of EEG signals. We then build a multi-class supporting vector machine(SVM) to classify different attention levels. The training system is built with the Unity game engine, which can be targeted on both desktops and Oculus VR headsets. We also launched an experiment by applying the system to preliminarily evaluate the effectiveness of our system. The results show that our system can generally improve users' abilities of multitasking and attention level.",,978-1-7281-5604-0,10.1109/AIVR46125.2019.00032,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942249,Multitasking;Neurofeedback;Attention Training;Virtual Reality,Training;Games;Electroencephalography;Neurofeedback;Multitasking;Support vector machines;Wavelet packets,bioelectric potentials;computer games;electroencephalography;medical signal processing;support vector machines;virtual reality;wavelet transforms,attention training system;virtual reality platform;multitasking training scenario;neurofeedback;noninvasive Electroencephalography device Emotiv EPOC;multitasking attention level;video game;non-invasive electroencephalography device;multi-class supporting vector machine;unity game engine;oculus VR headsets,,,,19,,27-Dec-19,,,IEEE,IEEE Conferences
Design and Implementation of Virtual Training Scenario Editing System of Emergency Disposal,D. Yuan; M. Wu; L. Pan,"Chinese People's Armed Police Forces Acad., Langfang, China; Chinese People's Armed Police Forces Acad., Langfang, China; Chinese People's Armed Police Forces Acad., Langfang, China",2014 7th International Conference on Intelligent Computation Technology and Automation,8-Jan-15,2014,,,174,177,"Based on open-source 3-D graphics engine OSG technique, this paper expounds the framework and function modules of a virtual training scenario editing system of emergency disposal based on VR. Taking a hazmat leakage accident on the road as an example, the prototype system was implemented. Research shows that the scenario editing system can be used to build all kinds of training simulation scenarios with a highly 3-D immersive virtual environment, which provides a general modular computer-based simulation training platform for the fire department to carry out the training of emergency rescue command and research on emergency rescue tactics.",,978-1-4799-6636-3,10.1109/ICICTA.2014.49,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7003512,Emergency Rescue;Simulation Training;Virtual Reality;Scenario Editor;Delta3D,Training;Solid modeling;Fires;Computational modeling;Object oriented modeling;Engines;Educational institutions,computer based training;digital simulation;emergency services;public domain software;road accidents;virtual reality,open-source 3-D graphics engine;OSG technique;virtual training scenario editing system;emergency disposal;VR;hazmat leakage accident;training simulation scenarios;3-D immersive virtual environment;modular computer-based simulation training platform;fire department;emergency rescue command;emergency rescue tactics,,,,10,,8-Jan-15,,,IEEE,IEEE Conferences
Complex Brain Networks and Simulated Military Reactions using a Virtual Reality System,O. Mosquera; D. Guzm√°n; J. Zamudio; J. Garcia; C. Rodriguez; D. Botero,"Escuela Militar de Cadetes ""General Jose Mar√≠a C√≥rdova"", Colombia; Escuela Militar de Cadetes ""General Jose Mar√≠a C√≥rdova"", Colombia; Escuela Militar de Cadetes ""General Jose Mar√≠a C√≥rdova"", Colombia; Escuela Militar de Cadetes ""General Jose Mar√≠a C√≥rdova"", Colombia; Escuela Militar de Cadetes ""General Jose Mar√≠a C√≥rdova"", Colombia; Universidad de La Sabana, Colombia",2019 IEEE 19th International Conference on Bioinformatics and Bioengineering (BIBE),27-Dec-19,2019,,,553,556,"Considering the strategic direction of the Colombian National Army, the need to increase training effectiveness using technological developments in biomedical engineering is highlighted. This study evaluates brain electrical activity via complex networks in virtual reality situations which simulate military reactions. Results suggest that a high network degree may be related to an appropriate decision-making process, whereas a lower value may be associated with poor performances according to military doctrine. While not entirely significant, some difference is appreciated, mainly between the base period and the event related to subject elimination (p=0.058). The authors also noted the burst suppression pattern when the subject was eliminated. As this is a work in progress, more research subjects are being recruited and more complex networks descriptors are being explored.",2471-7819,978-1-7281-4617-1,10.1109/BIBE.2019.00105,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941743,"Electroencephalogram, Complex Brain Networks, Signal Processing, Virtual Reality, Military Reactions.",Virtual reality;Electroencephalography;Complex networks;Decision making;Headphones;Training;Brain,bioelectric phenomena;brain;complex networks;decision making;electroencephalography;medical computing;neurophysiology;virtual reality,burst suppression pattern;complex network descriptors;subject elimination;base period;military doctrine;decision-making process;network degree;virtual reality situations;brain electrical activity;biomedical engineering;technological developments;training effectiveness;Colombian National Army;strategic direction;virtual reality system;simulated military reactions;complex brain networks,,,,11,,27-Dec-19,,,IEEE,IEEE Conferences
Pedagogical Agent Responsive to Eye Tracking in Educational VR,A. Khokhar; A. Yoshimura; C. W. Borst,University of Louisiana at Lafayette; University of Louisiana at Lafayette; University of Louisiana at Lafayette,2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,1018,1019,"We present an architecture to make a VR pedagogical agent responsive to shifts in user attention monitored by eye tracking. The behavior-based AI includes low-level sensor elements, sensor combiners that compute attention metrics for higher-level sensors called generalized hotspots, an annotation system for arranging scene elements and responses, and its response selection system. We show that the techniques can control the playback of teacher avatar clips that point out and explain objects in a VR oil rig for training.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8797896,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797896,Human-centered computing-Visualization,Gaze tracking;History;Computer architecture;Artificial intelligence;Monitoring;Conferences;Virtual reality,avatars;computer aided instruction;object detection;object tracking;virtual reality,pedagogical agent responsive;eye tracking;educational VR;VR pedagogical agent;user attention;behavior-based AI;low-level sensor elements;annotation system;scene elements;response selection system;VR oil rig;attention metrics,,1,,6,,15-Aug-19,,,IEEE,IEEE Conferences
Design and realization of flight simulation system based on Virtual Reality technology,K. Zhao; S. Xu; Q. Ye; Y. Li,"Northwestern Polytechnical University, Xi'an, Shaanxi, 710072 P.R. China; NA; NA; Northwestern Polytechnical University, Xi'an, Shaanxi, 710072",2011 Chinese Control and Decision Conference (CCDC),1-Aug-11,2011,,,4361,4364,"Visual simulation system is an important part of VR(Virtual Reality), and control law simulation is a general method of verifying the control algorithm. A visual simulation system that combined with control law simulation system was constructed for the application of pilot simulation training and as a method for the control designer to observe the control effects in visual forms. In this system, the 3D model was realized, and the simulation environment and special effects were added and established. The real-time results of flight simulation were transmited by Reflective Memory Network, and it was used to drive the scene model. The aircraft flight control laws simulation and visual simulation are realized. Besides, some key technologies of the scene simulation system, such as dynamics Modeling, scene modeling, real-time network communication and the input of peripheral device were also been described in detail.",1948-9447,978-1-4244-8738-7,10.1109/CCDC.2011.5968994,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5968994,Visual simulation;Virtual Reality;Flight simulation,Atmospheric modeling;Solid modeling;Mathematical model;Computational modeling;Visualization;Aircraft;Load modeling,aerospace simulation;solid modelling;virtual reality,flight simulation system;virtual reality;visual simulation system;control law simulation;pilot simulation training;control designer;reflective memory network;aircraft flight control,,2,,7,,1-Aug-11,,,IEEE,IEEE Conferences
Hyperion : A Simulation of High Places in the Form of Virtual Reality for Acrophobia Sufferers,O. Lengkong; J. Bororing,"Universitas Klabat,Faculty of Computer Science,Manado,Indonesia; Universitas Klabat,Faculty of Computer Science,Manado,Indonesia",2020 2nd International Conference on Cybernetics and Intelligent System (ICORIS),18-Jan-21,2020,,,1,4,"Acrophobia is the generally high common phobia. This phobia can make activity and the person's lifestyle limited because the person is avoiding high places. Acrophobia can be overcome by the centrifugal therapy method, which is the person who had this phobia is involved in the situation that triggers this phobia step by step. In virtual reality format and the sound effect, VR can simulate like in the high places in virtual. Scientists used virtual reality technology to make an application that can visualize high places' conditions through option mode. The purpose of making this application is to reduce Acrophobia by using virtual reality technology. The simulation of this research is served by showing a virtual environment of high places by using an accelerometer and gyroscope on a smartphone to interact with the social environment. The method used in this research is the prototyping model-Adobe photoshop to make application interface and game engine unity as an authoring tool to build the application. As a result of this research, the user can train by itself or with a therapist using the smartphone android and VR headset application.",,978-1-7281-7257-6,10.1109/ICORIS50180.2020.9320824,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9320824,Acrophobia;Virtual Reality;Simulation;Therapy;High Place,Virtual reality;Medical treatment;Solid modeling;Unified modeling language;Visualization;Virtual environments;Operating systems,accelerometers;authoring systems;computer games;computer simulation;data visualisation;gyroscopes;medical computing;patient treatment;smart phones;virtual reality,virtual reality;virtual environment;Hyperion;high places simulation;acrophobia sufferers;centrifugal therapy;option mode;accelerometer;gyroscope;smartphone;social environment;Adobe photoshop;application interface;game engine unity;authoring tool;Android;VR headset application;visualization,,,,16,,18-Jan-21,,,IEEE,IEEE Conferences
Design of a Virtual Reality and Haptic Setup Linking Arousals to Training Scenarios: A Preliminary Stage,K. Koumaditis¬†; F. Chinello; S. Venckute,"Dept. of Bus. Dev. & Technol., Aarhus Univ., Aarhus, Denmark; Aarhus University, Dep. of Business Development and Technology Herning Campus; Aarhus University, Dep. of Business Development and Technology Herning Campus",2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),30-Aug-18,2018,,,1,2,"Using Virtual Reality (VR) to realise immersive training environments is not a new concept. However, investigating arousal in immersive environments is. By arousal, we denote a general physical and psychological activity that in the form of anxiety and stress for example, can affect trainees' performance. In this work, we describe the setup design for a two-phase explorative experiment linking arousal and performance, during training in a Virtual Reality (VR) environment. To do so we are using an appraised well-crafted VR puzzle game, questionnaires (i.e. NASA Task Load Index [3]), and sensors (skin conductance response / pulse). The experiment will involve participants from the public that will be trained in two predefined processes of variant difficulty.",,978-1-5386-3365-6,10.1109/VR.2018.8446528,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446528,Virtual Reality;Haptics;Arousal;Stress;Training,Training;Task analysis;Sensors;Haptic interfaces;Games;Virtual reality;Skin,computer based training;computer games;haptic interfaces;psychology;skin;virtual reality,immersive environments;general physical activity;psychological activity;stress;trainees;setup design;two-phase explorative experiment;arousal performance;Virtual Reality environment;VR puzzle game;NASA Task Load Index;haptic setup linking arousals;training scenarios;preliminary stage;immersive training environments,,,,5,,30-Aug-18,,,IEEE,IEEE Conferences
Virtual Reality Image Technology Assists Training Optimization of Motion Micro-Time Scale,H. Cao; X. Shang; H. Qi,"Department of Physical Education, Hohai University, Changzhou, China; Department of Physical Education, Sangmyung University, Seoul, South Korea; Department of Physical Education, Sangmyung University, Seoul, South Korea",IEEE Access,15-Jul-20,2020,8,,123215,123227,"Virtual reality image local features are highly repetitive and are not easily affected by target occlusion, so research on virtual reality image local feature extraction techniques has received increasing attention. For the purpose of global scale selection, this article considers the virtual reality image in the global scope from the theoretical perspectives of the continuity of virtual reality images, the repeatability of virtual reality image features, the scale of scene virtual reality images in the global scope, and the visual saliency. This paper gives a general framework of multi-scale geometric analysis and particle swarm optimization virtual reality image matching algorithm. For the problem of virtual reality image matching, the original particle swarm optimization algorithm is improved. A more reasonable inertia weight change formula, a method for selecting the optimal solution when two objectives are optimized at the same time, and a method for selecting a reasonable input are designed. In this paper, performance evaluation experiments are performed on several feature description algorithms. The experimental results show that the descriptors constructed by these feature description algorithms are significantly more robust than SIFT (Scale Invariant Feature Transform) descriptors. The improved multi-scale geometric analysis and particle swarm optimization are robust due to the introduction of multiple support domains. It has the best discriminative ability, but at the same time, the introduction of multiple support domains leads to the worst real-time algorithm; DGOH (Dual Gradient Orientation Histogram) algorithm is more robust than FRDOH (Fast Repre-sentation Based on a Double Orientation Histogram) and SIFT algorithm, and DGOH algorithm has the best real-time performance.",2169-3536,,10.1109/ACCESS.2020.3007389,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9133523,Virtual reality images;particle swarm optimization;multi-scale geometric analysis;inertial weights;feature description,Virtual reality;Feature extraction;Visualization;Particle swarm optimization;Optimization;Image matching,feature extraction;gradient methods;image matching;image motion analysis;image representation;particle swarm optimisation;transforms;virtual reality,feature description algorithms;SIFT descriptors;Scale Invariant Feature Transform;virtual reality image local features;virtual reality image local feature extraction techniques;global scale selection;scene virtual reality images;particle swarm optimization virtual reality image matching algorithm;virtual reality image technology;training optimization;motion microtime scale;target occlusion;visual saliency;inertia weight change formula;improved multiscale geometric analysis;dual gradient orientation histogram algorithm;FRDOH;fast representation based on a double orientation histogram;DGOH algorithm;performance evaluation experiments,,,,31,CCBY,6-Jul-20,,,IEEE,IEEE Journals
Clinical research on therapeutic effect of virtual reality technology on Broca Aphasia patients,Y. Zhang; P. Chen; X. Li; G. Wan; C. Xie; X. Yu,"Rehabilitation Medicine Department, Third Affiliated Hospital of Sun Yat-sen University, Guangdong, China; Rehabilitation Medicine Department, Third Affiliated Hospital of Sun Yat-sen University, Guangdong, China; Rehabilitation Medicine Department, Third Affiliated Hospital of Sun Yat-sen University, Guangdong, China; Rehabilitation Medicine Department, Third Affiliated Hospital of Sun Yat-sen University, Guangdong, China; Rehabilitation Medicine Department, Third Affiliated Hospital of Sun Yat-sen University, Guangdong, China; Shanghai Institute of Intelligence and Electronics and Systems, Fudan University, Shanghai, China",2017 2nd International Conference on Information Technology (INCIT),15-Jan-18,2017,,,1,5,"Objective: To explore the therapeutic effect of virtual reality technology on speech function of Broca Aphasia patients after stroke. Method: Eighteen patients with stroke were enrolled in the Rehabilitation Medicine Department, the Third Affiliated Hospital of Sun Yat-sen University from December 2016 to August 2017. The patients were divided into observation group and control group by random number table. Both groups were trained in speech function. The observation group received regular speech training for 20 minutes per day, Virtual Reality (VR) training for 20 minutes per day; the control group was given conventional speech training 40 minutes per day but the same training content with the observation group. And both groups of patients were treated for 5 days per week lasting for 4 weeks. CRRCAE was used to evaluate the language ability before and after treatment. The Boston Diagnostic Aphasia Examination, BDAE was used to assess the severity of aphasia. Bucco-facial-apraxia and speech apraxia Methods were used to assess the patient's state of bucco facial function and speech function. Result: There was no significant difference (P > 0.5) between the situations of two groups in general data, bucco-facial-apraxia and speech apraxia. Before treatment, the difference in CRRCAE and BDAE between the two groups is also not so big(P > 0.05). After 4 weeks of treatment, the severity of aphasia was improved in both groups (P <; 0.05). Except computing ability, listening comprehension, repetition, expression, readout, reading, transcription, depiction and dictation were all improved (P <; 0.01). And in noun repetition(P = 0.03), sentence repetition (P = 0.01), noun expression(P <; 0.01), verb expression (P = 0.02), sentence expression (P <; 0.01), comic expression (P = 0.01), enumeration (P = 0.03), verb readout(P = 0.04), verb reading(P <; 0.01), sentence reading (P = 0.04), noun transcription (P = 0.02), sentence transcription (P = 0.048), verb depiction (P = 0.01) and so on, language ability of the observation group is significantly better than the control group. Conclusion: Virtual reality technology combined with speech function training can improve the language ability of patients with Broca Aphasia, and its improvement is better than the simple speech function training.",,978-1-5386-1431-0,10.1109/INCIT.2017.8257880,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8257880,Virtual Reality;Broca Aphasia;Speech function training,Speech;Training;Virtual reality;Hospitals;Videos;Information technology;Diseases,diseases;medical computing;medical disorders;neurophysiology;patient rehabilitation;patient treatment;speech;virtual reality,therapeutic effect;virtual reality technology;Broca Aphasia patients;stroke;Virtual Reality training;language ability;Boston Diagnostic Aphasia Examination;bucco facial function;simple speech function training;bucco-facial-apraxia method;speech apraxia method;noun repetition;sentence repetition;noun expression;verb expression;sentence expression;comic expression;enumeration;verb readout;verb reading;sentence reading;noun transcription;sentence transcription;verb depiction,,,,17,,15-Jan-18,,,IEEE,IEEE Conferences
A prototype implementation of an educational system in distributed virtual environment,Be-Sung Choi; Seong-Jin Kim; Shingeol Lee; Heesung Jun,"Sch. of Comput. Eng. & Inf. Technol., Ulsan Univ., South Korea; NA; NA; NA",Proceedings KORUS 2000. The 4th Korea-Russia International Symposium On Science and Technology,6-Aug-02,2000,2,,39,42 vol. 2,"We have implemented a prototype educational system based on the distributed virtual environment. The developed system has a client-server architecture: the platform-independent server is implemented by Java virtual machine and the client is composed of VRML, EAI, and general web browser. If a change occurs in this virtual environment, all connected users can perceive the updated environment immediately. The system maintains its virtual environment after it is modified by users. Also, the system can accommodate many users by minimizing the information exchange. Since users can share multimedia information and virtual objects in spite of the limitation of time and space, the educational effects can be progressed through the use of the developed system.",,0-7803-6486-4,10.1109/KORUS.2000.865990,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=865990,,Virtual prototyping;Virtual environment;Internet;Layout;Service oriented architecture;Java;Web server;Space technology;Virtual reality;User interfaces,computer based training;client-server systems;virtual reality;Java;multimedia computing,educational system;distributed virtual environment;client-server architecture;Java virtual machine;VRML;EAI;general web browser;updated environment;information exchange;multimedia information;virtual objects;educational effects;platform-independent server,,,,5,,6-Aug-02,,,IEEE,IEEE Conferences
Serious Virtual Reality Game for Isometric Eye Training of Strabismic Patients,J. H. Kim; S. Hee Oh,"Gachon University,Republic of Korea; Gachon University,Republic of Korea",2020 International Conference on Information and Communication Technology Convergence (ICTC),21-Dec-20,2020,,,468,473,"Along with the development of IT technology, the healthcare industry is growing by converging with IT technology, and studies on various fusion medical clinical trials using virtual reality technology, which have been particularly noticeable after the 4th industrial revolution, are actively progressing. In particular, there is a trend of active research on strabismus treatment in combination with virtual reality technology at home and abroad. In this paper, through collaboration with an ophthalmologist, we developed 3 types of mini-game contents that can be used to train strabismus patients in virtual reality space by wearing an HMD, and we study how to control prism diopter value to obtain strabismus training effect in general virtual reality games.",2162-1233,978-1-7281-6758-9,10.1109/ICTC49870.2020.9289585,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9289585,VR;VR Contents;Ophthalmology;Strabismus;Rehabilitation,Training;Solid modeling;Virtual reality;Games;Clinical trials;Stability analysis;Usability,gaze tracking;medical image processing;patient treatment;serious games (computing);virtual reality;vision defects,industrial revolution;mini-game contents;strabismus patients;serious virtual reality game;isometric eye training;health care industry;fusion medical clinical trials;prism diopter value;ophthalmologist;IT technology,,,,12,,21-Dec-20,,,IEEE,IEEE Conferences
A method of equipment operation rules modeling in training system,G. Chen; J. Shen; J. Yang; P. Chen,"Information Campaign Department Communications Academy Wuhan, China; Information Campaign Department Communications Academy Wuhan, China; Information Campaign Department Communications Academy Wuhan, China; Information Campaign Department Communications Academy Wuhan, China",2010 2nd IEEE International Conference on Information Management and Engineering,3-Jun-10,2010,,,505,509,"Modeling for operation rules is essential function requirement in equipment simulation training system based on VR. Aiming at the modeling actuality of present equipment operation rules, which has no systematic, no generality and no formatting expression, layered modeling system framework based on federation is brought forward referencing to the ""Federation and Member"" concept of HLA. Open modeling method is adopted to modeling equipment operation rules and it can be described with XML syntax structure. Finally, the basic implement principle of equipment operation rules is presented combing with some large tactical communication system equipment. It can provide beneficial reference for constructing similar large scale equipment simulation training system based on VR.",,978-1-4244-5263-7,10.1109/ICIME.2010.5477801,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5477801,operation rules;open modeling method;modeling;simulation training system,Virtual reality;XML;Concrete;Layout;Humans;Solid modeling;Large-scale systems;Buildings;Auditory system;Mice,computer based training;military computing;virtual reality;XML,equipment operation rules modeling method;training system;HLA;open modeling method;XML syntax structure;federation and member concept;VR system,,,,10,,3-Jun-10,,,IEEE,IEEE Conferences
An experimental design and preliminary results for a cultural training system simulation,P. A. Fishwick; A. J. Coffey; R. Kamhawi; J. Henderson,"CISE Department, Bldg. CSE, Room 301, University of Florida, Gainesville, 32611, USA; Journalism and Communications, Weimer Hall, Room 2042, University of Florida, Gainesville, 32611, USA; Journalism and Communications, Weimer Hall, Room 2040, University of Florida, Gainesville, 32611, USA; P. K. Yonge Research Developmental School, 1080 SW 11th Street, University of Florida, Gainesville, 32601, USA",Proceedings of the 2010 Winter Simulation Conference,6-Jan-11,2010,,,799,810,"Computer simulation has been widely deployed by the military for force-on-force based training but only more recently for training researchers, analysts, and war-fighters in matters of cross cultural sensitivity. This latter type of training gives the trainee a sense of ‚Äúbeing inside‚Äù a target culture. We built the Second China Project as a hybrid immersive, knowledge-based software platform for use in cultural training. Is this training effective? More specifically, what are the effects of immersion on memory and other cognitive variables? We chose to base our research questions, not around a specific user group, but more generally around a category of training system-one involving the use of multi-user virtual environments (MUVEs). We present the architecture of an experiment designed to test whether MUVEs are effective training platforms, and to explain the process used in developing a testing environment to determine the precise nature of that effectiveness. We also discuss lessons learned from the earlier pilot study and ongoing experiment.",1558-4305,978-1-4244-9865-9,10.1109/WSC.2010.5679110,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5679110,,Cultural differences;Training;Humans;Analytical models;Computational modeling;USA Councils;Virtual environment,computer based training;cultural aspects;knowledge based systems;military computing,cultural training system simulation;computer simulation;force on force based training;cross cultural sensitivity;target culture;knowledge based software platform;multiuser virtual environment;testing environment;pilot study,,3,,20,,6-Jan-11,,,IEEE,IEEE Conferences
Compare virtual reality and augmented reality systems for claustrophobia from HRV,Shih-Ching Yeh; Chia-Fen Tsai; C. Yu; Tzu-Chuan Huang,"Department of Computer Science & Information Engineering, National Central University, Taiwan; Department of Psychiatry, Taipei Veterans General Hospital, Taiwan; Department of Computer Science & Information Engineering, National Central University, Taiwan; Department of Computer Science & Information Engineering, National Central University, Taiwan",2012 12th International Conference on ITS Telecommunications,31-Jan-13,2012,,,155,159,"Claustrophobia is certain type of anxiety disorder on closed space. Claustrophobia patient, under certain conditions, for example, elevator, railway carriage or passenger compartment, might be attacked by panic disorder, or panic disorder might occur in very high probability. Flood method is a traditional therapeutic method for anxiety disorder. It is similar to system sensitivity-reducing method, but different than it is that in flood method and in the very beginning, the strongest anxiety stimulus is given so that the anxiety of the patient can reach a peak. This is to train the tolerance from the patient on the anxiety event, hence, when the patient meets slighter anxiety event, the patient won't feels that anxious. This research focuses on traditional diagnosis method of claustrophobia. It will associate virtual reality technology and game technology to develop immersion virtual reality training task, meanwhile, it will investigate if in virtual reality and augmented reality situation, people's anxiety situation can be similarly triggered. Comparisons between virtual reality and augmented reality systems are made via measurements of heart rate variability, technology acceptance model and anxiety assessment.",,978-1-4673-3070-1,10.1109/ITST.2012.6425155,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6425155,claustrophobia;virtual reality;augmented reality;heart rate variability,Augmented reality;Medical treatment;Heart rate variability;Virtual environments;Elevators;Fires,augmented reality;computer based training;computer games;medical computing;patient diagnosis,augmented reality systems;HRV;claustrophobia patient;flood method;therapeutic method;anxiety disorder;system sensitivity reduction method;patient anxiety stimulus;claustrophobia diagnosis method;game technology;immersion virtual reality training task;people anxiety situation;heart rate variability measurement;technology acceptance model;anxiety assessment,,,,4,,31-Jan-13,,,IEEE,IEEE Conferences
Using Industrial Robots as Haptic Devices for VR-Training,S. Knopp; M. Lorenz; L. Pelliccia; P. Klimant,"University of Technology, Institute for Machine Tools and Production Processes, Chemnitz; Department of Orthopedics Trauma and Plastic Surgery University Clinics of Leipzig, Institute for Machine Tools and Production Processes University of Technology, Chemnitz; University of Technology, Institute for Machine Tools and Production Processes, Chemnitz; Chemnitz University of Technology Fraunhofer Institute for Machine Tools and Forming Technology IWU, Institute for Machine Tools and Production Processes University of Technology, Chemnitz",2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),30-Aug-18,2018,,,607,608,"Many VR-training application require the integration of haptics, i.e. for surgical training. However, surgical VR-training is still limited to minimal invasive surgeries. For surgeries where high forces occur, like hip replacement, no VR-training applications have been developed. One cause for this is the lack of appropriate haptic devices which can deliver high forces. Novel industrial collaborative robots can provide high forces. Although, they lack control interfaces allowing to use them as haptic devices. We present 4 approaches for using these robots as general, multipurpose haptic input and output devices. The implemented approach was integrated into a VR hip replacement training application. An initial assessment demonstrates the general feasibility of our solution.",,978-1-5386-3365-6,10.1109/VR.2018.8446614,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446614,Haptics;Industrial robot;Virtual reality;Surgery;Medicine;Training;Applied computing ‚Üí Life and medical sciences;Human-centered computing ‚Üí Virtual reality;Human-centered computing ‚Üí Haptic devices,Conferences;Virtual reality;Three-dimensional displays;User interfaces,haptic interfaces;industrial robots;medical robotics;prosthetics;surgery;virtual reality,surgical VR-training;VR hip replacement training application;haptic devices;industrial collaborative robots,,6,,7,,30-Aug-18,,,IEEE,IEEE Conferences
Computer-based cognitive and socio-emotional training in personal health information management,R. Volner; D. Tich√°; H. Pal√°sthy,"Department of Informatics, Pedagogical faculty, The Catholic, University in Ruzomberok; University of Zilina, Department of Telecommunications and multimedia; Department of Informatics, Pedagogical faculty, The Catholic, University in Ruzomberok",2011 Carnahan Conference on Security Technology,8-Dec-11,2011,,,1,4,"Personal information management (PIM) pervades every aspect of our lives, including health care. As users of the health care system, we rely on our ability to manage information to combat illness and stay healthy. When seeking help for a health-related problem or question, we navigate a complex system where health services are distributed across multiple clinicians in a variety of specializations and institutions. Within the system, efforts to reduce costs have limited the time clinicians are able to spend with patients. Recent years have witnessed a growing interest of psychopathology for therapeutic uses of Information and Communication Technologies (ICT). Researchers and clinicians are carrying out interdisciplinary projects and empirical investigations of computer-based treatments dedicated to the rehabilitation of psychiatric patients. Some projects gave rise to practical implementations in clinical settings, a quite publicized example being the use of virtual reality for treating various forms of phobias and anxiety disorders. Companies specialized in developing software intended for psychotherapy are starting to emerge. Effective management of information is particularly challenging for patients facing conditions (such as cancer) requiring extended outpatient care. For cancer patients, a primary intervention (such as surgery) is generally followed by therapy (such as radiation, chemotherapy, or hormone therapy) that can last additional weeks, months, or years. As a result, they must stay on top of changing treatment regimens while trying to maintain their routine at work and at home.",2153-0742,978-1-4577-0903-6,10.1109/CCST.2011.6095892,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6095892,personal information management;health,Security;Training;Computers;Electronic mail;Computational modeling;Medical treatment,computer based training;health care;information management;medical disorders;patient treatment;virtual reality,computer-based cognitive;socio-emotional training;personal health information management;health care system;health services;psychopathology;information and communication technologies;computer-based treatments;psychiatric patient rehabilitation;virtual reality;phobia treatment;anxiety disorders,,1,,11,,8-Dec-11,,,IEEE,IEEE Conferences
"A distributed, collaborative and haptic-enabled eye cataract surgery application with a user interface on desktop, stereo desktop and immersive displays",A. Hamam; S. Nourian; N. R. El-far; F. Malric; X. Shen; N. D. Georganas,"Sch. of Inf. Technol. & Eng., Ottawa Univ., Ont.; Sch. of Inf. Technol. & Eng., Ottawa Univ., Ont.; Sch. of Inf. Technol. & Eng., Ottawa Univ., Ont.; Sch. of Inf. Technol. & Eng., Ottawa Univ., Ont.; Sch. of Inf. Technol. & Eng., Ottawa Univ., Ont.; Sch. of Inf. Technol. & Eng., Ottawa Univ., Ont.",2006 IEEE International Workshop on Haptic Audio Visual Environments and their Applications (HAVE 2006),15-Jan-07,2006,,,105,110,"In this paper, we discuss the technologies and approaches utilized in developing a cataract eye surgery simulation that will be used for training novice surgeons. The three different techniques described in this paper, are all hapto-visual techniques that resulted in three different implementations of the application: 2D simulation, 3D immersive simulation, and completely immersive simulation. The paper begins with an introduction and a general overview of the medical procedure of the cataract surgery. Then an overview of the eye and surgical tools modeling is given. Following that, the architecture and technology of each of the three design techniques is given. Finally the paper concludes with future work to improve the application",,1-4244-0760-5,10.1109/HAVE.2006.283773,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4062520,,Surgery;User interfaces;Displays;Haptic interfaces;Lenses;Medical simulation;Collaborative work;Cornea;International collaboration;Virtual environment,computer based training;computer displays;digital simulation;diseases;groupware;medical computing;surgery;user interfaces,distributed collaborative haptic-enabled eye cataract surgery application;stereo desktop;immersive displays;cataract eye surgery simulation;surgeon training;hapto-visual techniques;2D simulation;3D immersive simulation;surgical tool modeling;immersive haptic application;surgical simulation;virtual reality;physics engine;software engineering;immersive projection technology;graphical user interface;telesurgery;DIVINE System;cave automatic virtual environment;VRJuggler;CAVElib;OpenSceneGraph;Reachin,,7,,20,,15-Jan-07,,,IEEE,IEEE Conferences
Modeling QoE of Virtual Reality Video Transmission over Wireless Networks,J. Li; R. Feng; Z. Liu; W. Sun; Q. Li,"Sch. of Comput. & Inf., Hefei Univ. of Technol., Hefei, China; Sch. of Comput. & Inf., Hefei Univ. of Technol., Hefei, China; Dept. of Math. & Syst. Eng., Shizuoka Univ., Shizuoka, Japan; Sch. of Electr. Eng. & Autom., Hefei Univ. of Technol., Hefei, China; Sch. of Electr. Eng. & Autom., Hefei Univ. of Technol., Hefei, China",2018 IEEE Global Communications Conference (GLOBECOM),21-Feb-19,2018,,,1,7,"Virtual Reality (VR) provides an immersive 360 viewing experience and has been widely used in vast areas such as education, entertainment and training. To further widen its applications, networked 360 VR video becomes essential. Quality of Experience (QoE), which objectively measures user experience, is vital for 360 VR video transmission mechanism design. However, to the best of our knowledge, there are few subjective QoE metric for 360 VR video transmission over wireless networks. In this paper, we aim to fill this gap by proposing a general QoE model based on subjective quality evaluation experiments. First, the state-of-the-art 360 VR video processing and wireless transmission schemes are used to conduct subjective experiments according to the international standard. Then, how user experience is affected by different factors, including users' viewing angle, tiling (how the 360 VR video is partitioned into smaller parts to facilitate transmission), stall and resolution switch, is analyzed mathematically. A general QoE model is finally proposed to facilitate the future 360 VR video streaming mechanism design.",2576-6813,978-1-5386-4727-1,10.1109/GLOCOM.2018.8647729,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8647729,,Streaming media;Quality of experience;Switches;Measurement;Wireless networks;Bandwidth,quality of experience;video streaming;virtual reality,360 VR video transmission;360 VR video streaming;quality of experience;international standard;wireless transmission schemes;state-of-the-art 360 VR video processing;subjective quality evaluation experiments;general QoE model;subjective QoE metric;immersive 360 viewing experience;wireless networks;virtual reality video transmission,,5,,17,,21-Feb-19,,,IEEE,IEEE Conferences
Development and Validation of a Virtual Reality Tutor to Teach Clinically Oriented Surgical Anatomy of the Ear,S. Wijewickrema; B. Copson; X. Ma; R. Briggs; J. Bailey; G. Kennedy; S. O‚ÄôLeary,"Univ. of Melbourne, Melbourne, VIC, Australia; Univ. of Melbourne, Melbourne, VIC, Australia; Univ. of Melbourne, Melbourne, VIC, Australia; Univ. of Melbourne, Melbourne, VIC, Australia; Univ. of Melbourne, Melbourne, VIC, Australia; Univ. of Melbourne, Melbourne, VIC, Australia; Univ. of Melbourne, Melbourne, VIC, Australia",2018 IEEE 31st International Symposium on Computer-Based Medical Systems (CBMS),23-Jul-18,2018,,,12,17,"Virtual reality (VR) is being increasingly used in medical education. However, investigations into its effectiveness in this field have yielded mixed results, indicating that no general conclusions can be drawn in this regard. Therefore, the suitability of a system to teach a given task has to be investigated on a case-by-case basis. In this paper, we focus on teaching clinically oriented surgical ear anatomy, as it is important to provide a well-rounded view of ear anatomy as a foundation for understanding clinical surgery. Although there are some VR systems that teach basic ear anatomy, for example, identification of structures and spatial relationships, to our knowledge, those that deliver a complete clinical understanding of ear anatomy do not yet exist. As such, we discuss the design and development of a 3D interactive VR tutor with integrated haptic capability to teach clinically oriented surgical anatomy of the ear and establish its effectiveness through a user study.",2372-9198,978-1-5386-6060-7,10.1109/CBMS.2018.00010,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8417205,"Anatomy Education, Virtual Reality, Simulation Based Training",Ear;Bones;Surgery;Anatomical structure;Three-dimensional displays;Training,biomedical education;computer aided instruction;ear;haptic interfaces;medical computing;surgery;teaching;virtual reality,teaching;haptic capability;3D interactive VR tutor;complete clinical understanding;VR systems;clinically oriented surgical ear anatomy;case-by-case basis;medical education;virtual reality tutor,,,,18,,23-Jul-18,,,IEEE,IEEE Conferences
Improved Ada Boost Classifier for Sports Scene Detection in Videos: from Data Extraction to Image Understanding,Y. Yue; Y. Yang,"Shaoyang University,Shaoyang,China,422000; Shaoyang University,Shaoyang,China,422000",2020 International Conference on Inventive Computation Technologies (ICICT),9-Jun-20,2020,,,1,4,"Improved Ada Boost classifier for the sports scene detection in videos: from data extraction to image understanding is proposed in this paper. Virtual reality technology is the basic condition for the development of VR sports simulation system, and the accurate simulation of all kinds of competitive sports is completed on this basis. This technique can provide technical reference for coaches and athletes, on the basis of which the training means are deepened continuously, while improving the training effect, ensuring that the athletes do not suffer physical injury in the training. Traditional scene recognition methods generally use the low-level features or high-level features. The advantages of these methods are simple and easy to implement, however, this paper uses the Ada Boost model for the efficient analysis. The simulation results have proven the performance.",,978-1-7281-4685-0,10.1109/ICICT48043.2020.9112444,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9112444,Ada Boost;data extraction;image understanding;scene detection;video processing,,computer based training;feature extraction;image classification;image recognition;sport;virtual reality,Ada Boost classifier;sports scene detection;data extraction;image understanding;virtual reality technology;VR sports simulation system;competitive sports;athletes;scene recognition methods;Ada Boost model,,,,22,,9-Jun-20,,,IEEE,IEEE Conferences
The design and implementation of virtual system for the robot-assisted setting-bone surgery,M. Wang; L. Sun; Z. Du; Z. Jia,Harbin Inst. of Technol.; Harbin Inst. of Technol.; Harbin Inst. of Technol.; Harbin Inst. of Technol.,2006 Bio Micro and Nanosystems Conference,26-Mar-07,2006,,,53,57,"Current training methods for interns and residents in teaching hospitals do not adequately raise spatial perception about geometry and topology changes of skeletal morphology. Two reasons for the inability are trainees can only observe an operation before he participates in a surgery and preoperative rehearsal usually involves 2D (two dimensional) paper surgical simulations based on X-ray images. Moreover, surgery visiting doctors may also fail in real operations even after evaluating topology and geometry changes on rigid bones, prostheses and bone grafts of all procedures by 2D paper simulations. The failure rates were reported as 10-20% for setting-bone surgery. Computer-based surgery simulation represents a rapidly emerging and increasingly important area of research that combines a number of disciplines for the common purpose of improving health care. Generally, the goal of computer-based surgery simulation is to enable a surgeon to experiment with different surgical procedures in an artificial environment. We are developing a virtual surgical simulator specifically for HIT-RAOS, the robot-assisted setting-bone surgery system, which involves both various robots modeling and patients modeling. To satisfy requires on surgery programming and surgery rehearse based on special patient, a novel method of biological tissue model and simulation based special CT images includes 10 series is proposed in this article. Biological tissue geometry model, physical model and mechanical equilibrium equation based on strain energy function are built. Biomechanical equations are solved by finite element method. To make sure the simulator can be available in diverse operation systems, Java3D and VRML are chosen as the main developing tools. Based all the works above, As application examples, femur models and simulation are given and a cutting skin experiment was conducted, the results are contented. This validity of method and mathematics model is tested to compare simulation outcome with biomechanical experimentation",,1-4244-0056-2,10.1109/BMN.2006.330928,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4129414,,Robots;Surgery;Biological system modeling;Computational modeling;Solid modeling;Computational geometry;Topology;Bones;Computer simulation;Biological tissues,biological tissues;biomechanics;biomedical education;bone;computer based training;computerised tomography;digital simulation;finite element analysis;health care;medical computing;medical robotics;orthopaedics;physiological models;surgery;virtual reality languages,virtual surgical simulator;robot-assisted setting-bone surgery;computer-based surgery simulation;health care;robots modeling;patients modeling;surgery programming;biological tissue geometry model;CT images;biological tissue physical model;mechanical equilibrium equation;strain energy function;biomechanical equations;finite element method;Java3D;VRML;femur models,,2,,11,,26-Mar-07,,,IEEE,IEEE Conferences
3D force/torque characterization of emergency cricothyroidotomy procedure using an instrumented scalpel,A. Ryason; G. Sankaranarayanan; K. L. Butler; M. DeMoya; S. De,"Rensselaer Polytechnic Institute, Troy, NY USA; Baylor University Medical Center, Dallas, TX USA; Massachusetts General Hospital, Boston, MA USA; Massachusetts General Hospital, Boston, MA USA; Rensselaer Polytechnic Institute, Troy, NY USA",2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),18-Oct-16,2016,,,2145,2148,"Emergency Cricothyroidotomy (CCT) is a surgical procedure performed to secure a patient's airway. This high-stakes, but seldom-performed procedure is an ideal candidate for a virtual reality simulator to enhance physician training. For the first time, this study characterizes the force/torque characteristics of the cricothyroidotomy procedure, to guide development of a virtual reality CCT simulator for use in medical training. We analyze the upper force and torque thresholds experienced at the human-scalpel interface. We then group individual surgical cuts based on style of cut and cut medium and perform a regression analysis to create two models that allow us to predict the style of cut performed and the cut medium.",1558-4615,978-1-4577-0220-4,10.1109/EMBC.2016.7591153,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7591153,,,biomedical education;computer based training;regression analysis;surgery;torque;virtual reality,3D torque characterization;emergency cricothyroidotomy;surgical procedure;instrumented scalpel;patient airway;virtual reality CCT simulator;medical training;3D force characterization;physician training;human-scalpel interface;surgical cuts;cut medium;regression analysis;cut style,Computer Simulation;Cricoid Cartilage;Emergency Medicine;Humans;Otorhinolaryngologic Surgical Procedures;Surgical Instruments;Thyroid Gland;Torque,1,,13,,18-Oct-16,,,IEEE,IEEE Conferences
Research on Multiple 3D Models Rebuilding of Scene Simulation Platform,W. Huang; H. Lv; G. Chen; Q. Chen,"Xianfan Sub-Dept., Mil. Econ. Acad., Xiangfan, China; NA; NA; NA",2009 International Conference on Digital Image Processing,4-Aug-09,2009,,,297,301,"There are so many scene simulation application systems and they are built based on the different special 3D models data formats such as OpenFlight, 3DS, VRML, GLS, etc. These systems are developed almost in all fields. For example, urban programming, battlefield environment, traffic design ,virtual touring, simulation training, and so on. Actually, they are same at the development flow and key technologies in common. All the difference is only in simulation objects and simulation concrete functions. So a general scene simulation platform based on multiple 3D models rebuilding can prove development efficiency obviously and improve expansibility on 3D models data formats. Firstly, in the article, platform architecture and function framework is presented based on hierarchy structure. Secondly, key technologies involving model rebuilding and simulation driving framework are also detailed. Finally, plug-in software framework is adopted to realize the platform and simulation examples are brought forward by a scene simulation system based on the platform.",,978-0-7695-3565-4,10.1109/ICDIP.2009.54,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5190582,scene simulation;model rebuilding;simulation driving;plug-in framework,Layout;Environmental economics;Military communication;Software systems;Weapons;Buildings;Digital images;Finance;Traffic control;Concrete,digital simulation;solid modelling;virtual reality,3D models rebuilding;scene simulation platform;OpenFlight;3DS;VRML;GLS;3D models data formats;platform architecture;function framework;hierarchy structure;plug-in software framework;virtual reality,,,,10,,4-Aug-09,,,IEEE,IEEE Conferences
Stereo Generation from a Single Image Using Deep Residual Network,J. Huang; T. Bi; Y. Liu; Y. Wang,"Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Photonics, Beijing Institute of Technology, Beijing, 100081, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Photonics, Beijing Institute of Technology, Beijing, 100081, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Photonics, Beijing Institute of Technology, Beijing, 100081, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Photonics, Beijing Institute of Technology, Beijing, 100081, China",2018 25th IEEE International Conference on Image Processing (ICIP),6-Sep-18,2018,,,3653,3657,"In this paper, we propose a framework to generate stereoscopic content from a single image using the relative depth label predicted from deep residual network. Specifically, our framework first obtains a coarse relative depth label from the network and refines it to painting depth by sampling and interpolation, then an unsupervised clustering algorithm is employed to separate pixels of different depths into different layers to generate stereoscopic images. Experimental results with good visual effects demonstrate that the proposed method can be generally applied in both outdoor and indoor scenes. Meanwhile the quantitative results on relative depth estimation from a single image are comparable to state-of-the-art. Further experiments show the application possibility of our method in VR and panorama.",2381-8549,978-1-4799-7061-2,10.1109/ICIP.2018.8451311,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8451311,Stereo generation;relative depth;residual networks;layered images,Painting;Three-dimensional displays;Training;Interpolation;Measurement;Stereo image processing;Image edge detection,interpolation;painting;pattern clustering;stereo image processing;virtual reality,unsupervised clustering algorithm;relative depth estimation;stereo generation;deep residual network;coarse relative depth label;painting depth;stereoscopic content generation;interpolation;stereoscopic image generation;panorama;virtual reality,,,,24,,6-Sep-18,,,IEEE,IEEE Conferences
Definition of Test Criteria Based on the Scene Graph for VR Applications,A. Bezerra; M. E. Delamaro; F. L. S. Nunes,"Inst. de Cienc. Matemdticas e de Comput. (ICMC), Univ. de Sao Paulo (USP), Sao Carlos, Brazil; Inst. de Cienc. Matemdticas e de Comput. (ICMC), Univ. de Sao Paulo (USP), Sao Carlos, Brazil; Inst. de Cienc. Matemdticas e de Comput. (ICMC), Univ. de Sao Paulo (USP), Sao Carlos, Brazil",2011 XIII Symposium on Virtual Reality,14-Jul-11,2011,,,56,65,"Virtual Reality applications are becoming more popular. In general, the development of these applications does not include a testing phase, or, at best, the evaluation is conducted only with the users. The activity of software testing has received considerable attention from researchers and software engineers who recognize its usefulness in creating quality products. However, the tests are expensive and prone to errors, which imposes the need to systematize and hence the definition of techniques to increase quality and productivity in their driving. Several testing techniques have been developed and have been used, each with its own characteristics in terms of effectiveness, cost, implementation stages, etc. Moreover, these techniques can also be adapted. In this paper, testing criteria based on scene graph are studied in order to ensure the quality of the Virtual Reality applications implementation. In addition, a proof of concept is presented, by using the defined criteria applied to a VR framework built to generate applications in the medical training area.",,978-0-7695-4445-8,10.1109/SVR.2011.34,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5951835,Virtual reality;software testing;test criteria;test;scene graph,Software;Visualization;Instruments;Computational modeling;Java;Testing;Virtual reality,program testing;software quality;virtual reality,scene graph;VR applications;virtual reality applications;software testing;quality products;medical training area,,1,,32,,14-Jul-11,,,IEEE,IEEE Conferences
Insights into the Impactful usage of Virtual Reality for End Users,K. Malvika; S. Malathi,"Panimalar Engineering College,Chennai,India; Panimalar Engineering College,Chennai,India","2020 Fourth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)",10-Nov-20,2020,,,938,944,"‚ÄúCampus Visit‚Äù is the most significant facet of college enrolment program. An in-person strolling ‚Äúcampus-tour‚Äù is a tiresome task that is generally infeasible for the guests to explore all the amenities within a day due to distance, time constraints, or due to budgetary imperatives. With the innovative movements, the idea of the computerized visit goes under a bigger brolly of Virtual Reality and because of the ongoing COVID-19 pandemic, the demand for virtual exploration is on the rise. VR has an incredible potential to reimagine and reconstruct the reality with magnificent visualizations by allowing virtual access to objects and places that may be out of reach in the real world. Undoubtedly, ‚ÄúVirtual-Tour‚Äù has become a celebrated methodology for cheap and cheerful voyaging. This perlustration perspicuously elucidates the impactful usage of VR in assorted fields and spotlights the use of VR in ‚ÄúCampus-Tour‚Äù. Additionally, it focusses on featuring the quality and restrictions of prior proposed VR techniques and ultimately, drives out the supreme strategy that offers an immersive experience to the end-user.",,978-1-7281-5464-0,10.1109/I-SMAC49090.2020.9243539,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9243539,Virtual Reality;Campus Tour;360-Degree;HMD;3D Modelling etc,Visualization;Solid modeling;Analytical models;Computational modeling;Virtual environments;Tools;Time factors,computer based training;educational institutions;virtual reality,VR;end-user;virtual reality;end users;college enrolment program;in-person strolling campus-tour;tiresome task;time constraints;budgetary imperatives;innovative movements;computerized visit;bigger brolly;COVID-19 pandemic;virtual exploration;virtual access;campus visit,,,,31,,10-Nov-20,,,IEEE,IEEE Conferences
Investigating the application of virtual environment technology for use in the petroleum exploration industry,K. V. Nesbitt; R. J. Gallimore; B. J. Orenstein,"Dept. of Comput. Sci., Newcastle Univ., NSW, Australia; NA; NA",Proceedings 23rd Australasian Computer Science Conference. ACSC 2000 (Cat. No.PR00518),6-Aug-02,2000,,,181,188,"Although the concepts of virtual environments or virtual reality have been researched for many years, the industrial application of these concepts is a relatively recent event in the evolution of the human-computer interface. This paper outlines an investigation by a commercial research organization (BHP Research) into the applications of this technology. The major domain under investigation was that of petroleum exploration. The focus of the research was two-fold, namely, the use of virtual environments to enable multi-sensory interpretation of data and the ability of virtual environments to enhance collaboration amongst work teams. Appraisal was conducted by trialing the applications amongst a wide user base. While it is not possible to divulge in full the recommendations that resulted from this work, a number of observations are made about the use of this technology for petroleum exploration. Furthermore, various general implications for the use of this technology are discussed.",,0-7695-0518-X,10.1109/ACSC.2000.824400,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=824400,,Virtual environment;Industrial training;Computational modeling;Marine technology;Medical simulation;Biomedical imaging;Prototypes;Testing;Petroleum industry;Psychology,virtual reality;petroleum industry;geophysics computing,virtual environment;petroleum exploration;virtual reality;human-computer interface;BHP Research,,,,15,,6-Aug-02,,,IEEE,IEEE Conferences
Sitting to standing and walking therapy for post-stroke patients using virtual reality system,W. N. Khotimah; R. W. Sholikah; R. R. Hariadi,"Informatics Department, Institut Teknologi Sepuluh Nopember Surabaya; Informatics Department, Institut Teknologi Sepuluh Nopember Surabaya; Informatics Department, Institut Teknologi Sepuluh Nopember Surabaya",2015 International Conference on Information & Communication Technology and Systems (ICTS),14-Jan-16,2015,,,145,150,"Generally, post-stroke patients suffer physical disorder or paralysis in various level. Common treatment to restore the functionality of the paralyzed limb is by doing motoric therapy. This therapy was done in hospital and was monitored by therapists. However, most of the post-stroke patients choose not to do therapy since their access to hospital is difficult or their motivation to do therapy is low. To overcome the limitations of traditional therapy methods some interactive game-based therapy systems were introduced i.e: AR-therapy and Wii-based movement therapy. Unfortunately, their performance is low due to user ergonomic factor problem. In this study, we proposed a virtual reality system for sitting to standing and walking therapy for post-stroke patients called KOMY. This application is integrated with Kinect technology. Four VR game-based training tasks were adopted from sitting to standing therapy and walking therapy that was done by therapist. These tasks are sitting-standing-sitting, moving leg aside, moving leg freely, and walking. Each task has tree difficulty level. From observation that involving post-stroke patient, elderly healthy people, and therapist, we find that all of them give positive comment to this application. They said that this application not only can be used for therapy of post-stroke patients but also can be used for exercise to elderly. Further, KOMY can be used as alternative for playing therapy and home education therapy.",,978-1-5090-0096-8,10.1109/ICTS.2015.7379889,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379889,Sitting and Standing Therapy;Walking Therapy;Kinect;Virtual Reality,Decision support systems;Information and communication technology,computer games;patient treatment;virtual reality,sitting to standing therapy;Kinect technology;KOMY;VR game-based training task;virtual reality system;poststroke patient therapy;walking therapy,,3,1,10,,14-Jan-16,,,IEEE,IEEE Conferences
Focus of attention and dynamic postural control in individuals post-stroke,D. McEwen; M. Bilodeau; H. Sveistrup,"School of Rehabilitation Sciences, University of Ottawa, Canada; School of Rehabilitation Sciences, University of Ottawa, Canada; School of Rehabilitation Sciences, University of Ottawa, Canada",2017 International Conference on Virtual Rehabilitation (ICVR),14-Aug-17,2017,,,1,2,"Maintaining an external focus of attention (FA), as with virtual reality exercise gaming, may be effective in encouraging greater dynamic lateral movements and greater weight bearing for individuals post stroke. This study sought to compare center of pressure movements for individuals post-stroke under three conditions (internal FA, external FA, virtual reality) and compare these differences to healthy older and younger adults. The post-stroke group had greater average weight bearing on the paretic limb during VR tasks than the internal and external FA tasks. The PS group had consistently lower values on all dynamic postural variables compared with both YA and OA groups. However, all three groups showed a similar FA effect, with generally greater range in the VR compared with the internal FA task.",2331-9569,978-1-5090-3053-8,10.1109/ICVR.2017.8007478,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007478,Center of Pressure;Stroke;Dynamic Stability,Force;Virtual environments;Training;Software;Standards;Analysis of variance,biomechanics;computer games;medical computing;patient rehabilitation;virtual reality,focus of attention;dynamic postural control;post-stroke individuals;virtual reality exercise gaming;dynamic lateral movements;weight bearing;center of pressure movements;internal FA;external FA;paretic limb;VR tasks;dynamic postural variables,,,,5,,14-Aug-17,,,IEEE,IEEE Conferences
Augmented virtuality for the next generation production intelligence,I. J. Rudas,"√ìbuda University, Budapest, Hungary",2017 IEEE 14th International Scientific Conference on Informatics,29-Mar-18,2017,,,12,12,"Several compelling IT trends of the past few years show us how the next possible paradigm change in business intelligence could remodel everything in production informatics. Along the example of Virtual Reality and a community-based granulated software ecosystem, namely the Node.js world and its interference with the System of Systems and Internet of Anything concepts, the presentation will uncover a really powerful future of Industrial software systems. Evolution of the Node.js world started back in 2008, when Google released the powerful V8 JavaScript engine and Ryan Dahl began using it as a general purpose virtual machine allowing millions of JS developers to create server-side or practically any computer applications for all purposes using common web technologies. Thanks to many beneficial conjunctions like the GitHub and Npm communities as well as the Node friendly PaaS (e.g., MS Azure, Google Cloud, IBM Bluemix, Heroku) today Node.js-based technologies aspire to be a common language of large-scale distributed Internet of Anything systems considering the non mission critical layers. Our research team investigates new ideas to connect distributed Industrial system elements (sensors, actuators, control logic, intelligent machines, data logging and data mining) to each other and represents them in a Virtual World forming a general purpose information pool which allows for large-scale heterogeneous production systems. The last part of the presentation summarizes the results and ideas of a newly developed software engine, called MAXWHERE that provides effective working environments with spatial (Virtual Reality) multimedia arrangement and Intelligent System of Systems connectivity. The fundamental idea behind MAXWHERE is the generalization of the Document Object Model (DOM) introducing the Where Object Model (WOM) concept that covers the conventional WEB contents as well as the VR/AR building blocks in a coherent way empowered by the newest generation web APIs. Typical applications of MAXWHERE includes industrial monitoring and facility support, context-based collaborative working environment, industrial training, and Interactive live presentations.",,978-1-5386-0889-0,10.1109/INFORMATICS.2017.8327213,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8327213,,Informatics;Service robots;Production;Internet;Cybernetics;Computational intelligence,application program interfaces;cloud computing;data mining;Java;production engineering computing;software engineering;virtual machines;virtual reality,control logic;intelligent machines;data logging;data mining;general purpose information pool;large-scale heterogeneous production systems;spatial multimedia arrangement;virtual world;virtual reality;web APIs;Node.js;industrial system elements;V8 JavaScript engine;node friendly PaaS;common language;Google Cloud;JS developers;general purpose virtual machine;Node.js world;granulated software ecosystem;production informatics;business intelligence;generation production intelligence;augmented virtuality;Where Object Model concept,,,,,,29-Mar-18,,,IEEE,IEEE Conferences
A Design and Analysis of a Hybrid Multicast Transport Protocol for the Haptic Virtual Reality Tracheotomy Tele-Surgery Application,A. Boukerche; H. Maamar; A. Hossain,"PARADISE Research Laboratory SITE, University of Ottawa; PARADISE Research Laboratory SITE, University of Ottawa; PARADISE Research Laboratory SITE, University of Ottawa",2007 IEEE International Parallel and Distributed Processing Symposium,11-Jun-07,2007,,,1,6,"Nowadays, distributed collaborative virtual environments are used in many scenarios such as tele-surgery, gaming, and industrial training, however several challenging issues remain to be resolved before haptic virtual reality based class of applications become a common place. In this paper, we focus upon a tracheotomy tele-surgery application that is based on closely coupled and highly synchronized haptic tasks that require a high-level of coordination among the participants. We also propose a hybrid protocol that is able to satisfy all the collaborative and haptic virtual environment requirements in general and tracheotomy tele-surgery in particular. We discuss our C-HAVE tracheotomy tele-surgery framework and report on the performance results we have obtained to evaluate our protocol using an extensive set of experiments.",1530-2075,1-4244-0909-8,10.1109/IPDPS.2007.370592,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4228320,,Multicast protocols;Transport protocols;Haptic interfaces;Virtual reality;Virtual environment;Collaboration;Industrial training;Delay;Scalability;Region 7,groupware;medical computing;multicast protocols;surgery;telemedicine;transport protocols;virtual reality,hybrid multicast transport protocol;haptic virtual reality tracheotomy telesurgery application;distributed collaborative virtual environments,,,,10,,11-Jun-07,,,IEEE,IEEE Conferences
Improving Quality of Life from Birth to Old Age with Ubiquitous Computing and Virtual Reality,S. Duval; C. Hoareau; H. Hashizume,"Nat. Inst. of Inf., Tokyo; Nat. Inst. of Inf., Tokyo; Nat. Inst. of Inf., Tokyo",2008 International Conference on Convergence and Hybrid Information Technology,9-Sep-08,2008,,,371,377,"Virtual reality and ubiquitous computing can significantly improve the general public's quality of life worldwide from birth to old age because they allow monitoring, awareness and support in real and digital worlds thanks to sensors, actuators, remote connections, and dedicated knowledge bases. However, age influences their usefulness and appropriateness due to growth and decline as well as changes in activities and uses of technology. Based on the cognitive, physical, physiological, and sensory characteristics of young people and older adults, we discuss dedicated systems that exploit intelligent environments, wearable computers and virtual reality. Our most significant contribution is the analysis of the potential and limits of ubiquitous computing and virtual reality to improve quality of life, taking into account all age ranges.",,978-0-7695-3328-5,10.1109/ICHIT.2008.202,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4622854,Virtual Reality;Ubiquitous Computing;Age;Design;Sociology,Virtual reality;Biomedical monitoring;Monitoring;Temperature sensors;Temperature measurement;Pediatrics;Training,artificial intelligence;social aspects of automation;ubiquitous computing;virtual reality;wearable computers,ubiquitous computing;virtual reality;public quality of life;sensors;actuators;remote connections;dedicated knowledge bases;intelligent environments;wearable computers,,1,,26,,9-Sep-08,,,IEEE,IEEE Conferences
Virtual-reality-based multidimensional therapy for the treatment of body image disturbances in binge eating disorders: a preliminary controlled study,G. Riva; M. Bacchetta; M. Baruffi; E. Molinari,"Appl. Technol. for Neuro-Psychol. Lab., Ist. Auxologico Italiano, Verbania, Italy; NA; NA; NA",IEEE Transactions on Information Technology in Biomedicine,7-Nov-02,2002,6,3,224,234,"The main goal of this paper is to preliminarily evaluate the efficacy of a virtual-reality (VR)-based multidimensional approach in the treatment of body image attitudes and related constructs. The female binge eating disorder (BED) patients (n=20), involved in a residential weight control treatment including low-calorie diet (1200 cal/day) and physical training, were randomly assigned either to the multidimensional VR treatment or to psychonutritional groups based on the cognitive-behavior approach. Patients were administered a battery of outcome measures assessing eating disorders symptomathology, attitudes toward food, body dissatisfaction, level of anxiety, motivation for change, level of assertiveness, and general psychiatric symptoms. In the short term, the VR treatment was more effective than the traditional cognitive-behavioral psychonutritional groups in improving the overall psychological state of the patients. In particular, the therapy was more effective in improving body satisfaction, self-efficacy, and motivation for change. No significant differences were found in the reduction of the binge eating behavior. The possibility of inducing a significant change in body image and its associated behaviors using a VR-based short-term therapy can be useful to improve the body satisfaction in traditional weight reduction programs. However, given the nature of this research that does not include a followup study, the obtained results are preliminary only.",1558-0032,,10.1109/TITB.2002.802372,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1033951,,Multidimensional systems;Medical treatment;Psychology;Virtual reality;Laboratories;Heart;Attitude control;Weight control;Battery charge measurement;Books,virtual reality;psychology;medical computing;patient treatment;user interfaces,virtual reality;multidimensional therapy;body image disturbances;binge eating disorders;obesity;patient therapy;residential weight control treatment;psychonutritional groups;cognitive-behavior approach;anxiety;psychiatric symptoms,"Adolescent;Adult;Body Image;Bulimia;Bulimia;Chronic Disease;Cognitive Therapy;Computer Graphics;Computer Simulation;Female;Humans;Reproducibility of Results;Sensitivity and Specificity;Severity of Illness Index;Therapy, Computer-Assisted;Treatment Outcome;User-Computer Interface",44,,68,,7-Nov-02,,,IEEE,IEEE Journals
A 4-dof haptic device for hysteroscopy simulation,U. Spaelter; T. Moix; D. Ilic; H. Bleuler; M. Bajka,"Laboratoire de Syst. Robotiques, Fed. Inst. of Technol., Lausanne, Switzerland; Laboratoire de Syst. Robotiques, Fed. Inst. of Technol., Lausanne, Switzerland; Laboratoire de Syst. Robotiques, Fed. Inst. of Technol., Lausanne, Switzerland; Laboratoire de Syst. Robotiques, Fed. Inst. of Technol., Lausanne, Switzerland; NA",2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),14-Feb-05,2004,4,,3257,3263 vol.4,"In minimal-invasive surgery surgeons are generally confronted with complex scenario and sometimes they have to overcome unexpected pathologies or life-threatening injuries. Therefore there is a demand for realistic training without risk to the patient. Since a decade ago there have been research activities on virtual reality surgery simulators with haptic feedback with the goal to provide an alternative to traditional training methods on animals or cadavers. Haptic feedback is a key feature for every surgery simulator for the training of hand-eye coordination. In this paper a 4-dof haptic device is presented for hysteroscopy, the examination and treatment of the uterine cavity through the vagina. Specifications are presented, and kinematics as well as force transmission are analyzed. The realized prototype, result of a systematic design process, is based on a 2-dof spherical manipulator with low inertia and a 2-dof serial extension, which allows the use of slightly adapted original instruments. With difference to common surgery simulators tool insertion and complete removal can be performed. The performance of the prototype is shortly discussed.",,0-7803-8463-6,10.1109/IROS.2004.1389919,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1389919,,Haptic interfaces;Surgery;Feedback;Prototypes;Pathology;Injuries;Virtual reality;Animals;Cadaver;Kinematics,haptic interfaces;surgery;virtual reality;medical robotics;manipulators;medical computing,4dof haptic device;hysteroscopy simulation;minimal invasive surgery surgeon;virtual reality surgery simulator;haptic feedback;spherical manipulator,,4,,18,,14-Feb-05,,,IEEE,IEEE Conferences
Bayesian neural network approach to hand gesture recognition system,L. Li; S. Dai,"Science and Technology on Aircraft Control Laboratory, Beihang University, Beijing, 100191 China; Science and Technology on Aircraft Control Laboratory, Beihang University, Beijing, 100191 China","Proceedings of 2014 IEEE Chinese Guidance, Navigation and Control Conference",15-Jan-15,2014,,,2019,2023,This paper presents a hand gesture recognition system as a part of our virtual reality system called non-contact flight auxiliary (NCFAC) system. The system is developed using Bayesian neural network to translate hand gestures to corresponding commands and utilizes one hand gesture to prepare for collision detection. Cyberglove sensory glove and Flock of Birds motion tracker are applied to this system to extract hand features. The Bayesian neural network model is trained and tested with different sample groups. Experiment shows that our system is able to recognize 16 kinds of hand gestures with the accuracy of 95.6% and greater generalization capability. The system can also be extended and use other algorithms for future works.,,978-1-4799-4699-0,10.1109/CGNCC.2014.7007487,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7007487,Gesture recognition;Bayesian neural network;Glove;Virtual reality,Gesture recognition;Biological neural networks;Bayes methods;Computers;Neurons;Backpropagation,Bayes methods;data gloves;generalisation (artificial intelligence);gesture recognition;neural nets;virtual reality,Bayesian neural network approach;hand gesture recognition system;virtual reality system;noncontact flight auxiliary system;NCFAC system;collision detection;cyberglove sensory glove;flock of birds motion tracker;hand feature extraction;Bayesian neural network model;generalization capability,,,,17,,15-Jan-15,,,IEEE,IEEE Conferences
Photorealistic Large-Scale Urban City Model Reconstruction,C. Poullis; S. You,"University of Southern California, Los Angeles; University of Southern California, Los Angeles",IEEE Transactions on Visualization and Computer Graphics,12-May-09,2009,15,4,654,669,"The rapid and efficient creation of virtual environments has become a crucial part of virtual reality applications. In particular, civil and defense applications often require and employ detailed models of operations areas for training, simulations of different scenarios, planning for natural or man-made events, monitoring, surveillance, games, and films. A realistic representation of the large-scale environments is therefore imperative for the success of such applications since it increases the immersive experience of its users and helps reduce the difference between physical and virtual reality. However, the task of creating such large-scale virtual environments still remains a time-consuming and manual work. In this work, we propose a novel method for the rapid reconstruction of photorealistic large-scale virtual environments. First, a novel, extendible, parameterized geometric primitive is presented for the automatic building identification and reconstruction of building structures. In addition, buildings with complex roofs containing complex linear and nonlinear surfaces are reconstructed interactively using a linear polygonal and a nonlinear primitive, respectively. Second, we present a rendering pipeline for the composition of photorealistic textures, which unlike existing techniques, can recover missing or occluded texture information by integrating multiple information captured from different optical sensors (ground, aerial, and satellite).",1941-0506,,10.1109/TVCG.2008.189,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4653489,Large-scale modeling;rapid reconstruction;photorealistic model.;Three-Dimensional Graphics and Realism;Modeling packages;Computer Graphics;General;Virtual reality;Applications,Large-scale systems;Cities and towns;Virtual environment;Buildings;Virtual reality;Discrete event simulation;Surveillance;Surface reconstruction;Pipelines;Optical sensors,structural engineering;virtual reality,photorealistic model;urban city model reconstruction;virtual reality;rapid reconstruction;automatic building identification,,29,,21,,17-Oct-08,,,IEEE,IEEE Journals
Overcoming Glossophobia Based on Virtual Reality and Heart Rate Sensors,D. Herumurti; A. Yuniarti; P. Rimawan; A. A. Yunanto,"Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia","2019 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)",5-Aug-19,2019,,,139,144,"Glossophobia or commonly called speech anxiety is the fear of public speaking. It is a psychological disorder which a person is afraid to speak in public or can be interpreted as nervous. This problem is caused by the lack of preparation or training carried out to public speaking. In Addition, the training is generally lack the atmosphere or impression like speaking in public. Therefore, this system was created for helping someone in preparation before public speaking. This system simulation for practicing public speaking based on technology such as virtual reality, video 360, and arduino heart rate sensors. The results of the functionality and non-functionality of the system have been fully implemented and are running well. In addition, based on the results of the questionnaire and test of objectivity, this system has good feedback for helping someone to prepare and practice in public speaking based on virtual reality technology.",,978-1-7281-3745-2,10.1109/ICIAICT.2019.8784846,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8784846,Public Speaking;Glossophobia;Virtual Reality;Heart Rate Sensors,Heart rate;Public speaking;Virtual reality;Sensors;Testing;Solid modeling;Tools,biosensors;medical computing;medical disorders;patient treatment;psychology;virtual reality,glossophobia;virtual reality;public speaking;Arduino heart rate sensors;speech anxiety;psychological disorder;video 360,,6,,14,,5-Aug-19,,,IEEE,IEEE Conferences
Real Time Pathfinding with Genetic Algorithm,A. F. d. V. Machado; U. O. Santos; H. Vale; R. Gon√ßalvez; T. Neves; L. S. Ochi; E. W. G. Clua,"Depto. Academico de Cienc. da Comput., Inst. Fed. de Educ. Tec. do Sudeste de Minas, Rio Pomba, Brazil; Depto. Academico de Cienc. da Comput., Inst. Fed. de Educ. Tec. do Sudeste de Minas, Rio Pomba, Brazil; Depto. Academico de Cienc. da Comput., Inst. Fed. de Educ. Tec. do Sudeste de Minas, Rio Pomba, Brazil; Depto. Academico de Cienc. da Comput., Inst. Fed. de Educ. Tec. do Sudeste de Minas, Rio Pomba, Brazil; Dept. de Comput., Univ. Fed. Fluminense, Niteroi, Brazil; Dept. de Comput., Univ. Fed. Fluminense, Niteroi, Brazil; Dept. de Comput., Univ. Fed. Fluminense, Niteroi, Brazil",2011 Brazilian Symposium on Games and Digital Entertainment,29-Nov-12,2011,,,215,221,"This paper presents a method to optimize the process of finding paths using a model based on genetic algorithms and A* for real time systems, such as video games, virtual reality environments. The proposed solution uses obstacle pattern detection based on online training system that is generally used in systems with real time requirements and in dynamic environments. The architecture, named Real Time Path finding with Genetic Algorithm (RTP-GA), uses a Genetic Algorithm in order to create an agent adapted to the environment that is able to optimize the search for paths even in the presence of obstacles. In specific cases, the RTP-GA architecture presents a complexity that is better than A* algorithm.",2159-6662,978-0-7695-4648-3,10.1109/SBGAMES.2011.23,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6363236,pathfinding;genetic algorithm;dynamic environment,Biological cells;Genetic algorithms;Linear programming;Heuristic algorithms;Real-time systems;Games;Vectors,computer games;genetic algorithms;real-time systems;virtual reality,video games;virtual reality environments;obstacle pattern detection;dynamic environments;real time path finding with genetic algorithm;RTP-GA,,2,,9,,29-Nov-12,,,IEEE,IEEE Conferences
Study on force display system using couple of ER brakes,K. Koyanagi; J. Furusho; Li-Cheng Dong,"Dept. of Eng., Osaka Univ., Japan; Dept. of Eng., Osaka Univ., Japan; Dept. of Eng., Osaka Univ., Japan",2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),14-Feb-05,2004,4,,3251,3256 vol.4,"Force information in virtual space is important and often required for tele-operation, training, amusement, design supporting and other virtual reality systems. While conventional force displays are active systems with actuators and therefore may become inherently dangerous, passive force displays, which use only passive elements, are an effective methods for assuring safety. However, passive type systems have some directions and link postures, which are hard to present force. To this problem, a method for improvement of controllability using redundant couple of brakes had been suggested. It was able to be considered this method made it possible to display various force directions and various postures of virtual objects. The purpose of this study was, for further improvement of controllability of systems with redundant couples of brakes, design and development of more generalized redundant mechanism by adding another element of design freedom. Moreover, improvement of force display-ability by reducing equivalent inertia was also aimed. In this paper, the developed system was outlined and basic experiments with it discussed.",,0-7803-8463-6,10.1109/IROS.2004.1389918,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1389918,,Displays;Erbium;Force sensors;Safety;Control systems;Force measurement;Controllability;Virtual reality;Haptic interfaces;TV,controllability;electrorheology;force feedback;virtual reality,force display system;controllability;electrorheological fluid brake;passive force display;virtual object,,8,,10,,14-Feb-05,,,IEEE,IEEE Conferences
Exploiting Transfer Learning for Emotion Recognition Under Cloud-Edge-Client Collaborations,D. Wu; X. Han; Z. Yang; R. Wang,"Chongqing Key Laboratory of Optical Communication and Networks, Chongqing Key Laboratory of Ubiquitous Sensing and Networking, School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Optical Communication and Networks, Chongqing Key Laboratory of Ubiquitous Sensing and Networking, School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Optical Communication and Networks, Chongqing Key Laboratory of Ubiquitous Sensing and Networking, School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China",IEEE Journal on Selected Areas in Communications,14-Jan-21,2021,39,2,479,490,"Emerging virtual reality/augmented reality games and self-driving cars necessitate accurate/responsive/private emotion recognition. Usually, traditional emotion recognition models are deployed at central servers, which results in the lack of abilities in generalization and covering the individual variation of clients. This paper proposes a responsive, localized, and private transfer learning based emotion recognition framework under the cloud-edge-client collaborations. Additionally, a 3-dimensional channel mapping method is designed to aggregate features extracted from electroencephalogram (EEG) signals for the generic emotion recognition model, which is further localized and personalized using transfer learning. Simulation results validate the performance of the proposed TLER framework in reducing model training time and improving emotion recognition accuracy.",1558-0008,,10.1109/JSAC.2020.3020677,National Natural Science Foundation of China; Science and Technology Research Program of Chongqing Municipal Education Commission; Natural Science Foundation of Chongqing of China; Science and Technology Research Program of Chongqing Municipal Education Commission; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187207,Electroencephalogram;emotion recognition;transfer learning;cloud-edge-client collaboration,Brain modeling;Emotion recognition;Electroencephalography;Feature extraction;Machine learning;Collaboration;Scalp,augmented reality;cloud computing;computer games;electroencephalography;emotion recognition;feature extraction;learning (artificial intelligence);medical signal processing,cloud-edge-client collaborations;self-driving cars;3-dimensional channel mapping;responsive transfer learning based emotion recognition;localized transfer learning based emotion recognition;private transfer learning based emotion recognition;electroencephalogram signals;feature extraction;TLER framework;virtual reality-augmented reality games,,1,,43,IEEE,7-Sep-20,,,IEEE,IEEE Journals
Evaluating Competition in Training of Deep Reinforcement Learning Agents in First-Person Shooter Games,P. B. S. Serafim; Y. L. B. Nogueira; C. A. Vidal; J. B. C. Neto,"Dept. of Comput., Fed. Univ. of Ceara, Fortaleza, Brazil; Dept. of Comput., Fed. Univ. of Ceara, Fortaleza, Brazil; Dept. of Comput., Fed. Univ. of Ceara, Fortaleza, Brazil; Dept. of Comput., Fed. Univ. of Ceara, Fortaleza, Brazil",2018 17th Brazilian Symposium on Computer Games and Digital Entertainment (SBGames),7-Feb-19,2018,,,117,11709,"This work evaluates competition in training of autonomous agents immersed in First-Person Shooter games using Deep Reinforcement Learning. The agents are composed of a Deep Neural Network, which is trained using Deep QLearning. The inputs of the networks are only the pixels of the screen, allowing the creation of general players, capable of handling several environments without the need for further modifications. ViZDoom, an Application Programming Interface based on the game Doom, is used as the testbed because of its appropriate features. Fifteen agents were divided into three groups, two of which were trained by competing with each other, and the third was trained by competing against opponents that act randomly. The developed agents were able to learn adequate behaviors to survive in a custom one-onone scenario. The tests showed that the competitive training of autonomous agents leads to a greater number of wins compared to training against non-intelligent agents.",2159-6662,978-1-5386-9605-7,10.1109/SBGAMES.2018.00023,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8636940,autonomous agents;deep reinforcement learning;digital games;competitive learning;first-person shooter games,Games;Training;Reinforcement learning;Autonomous agents;Neurons;Biological neural networks;Kernel,application program interfaces;computer games;learning (artificial intelligence);multi-agent systems;neural nets,autonomous agents;nonintelligent agents;First-Person Shooter games;Deep Neural Network;Application Programming Interface;competitive training;deep reinforcement learning agents;deep Q learning;competition evaluation;Doom game;ViZDoom,,2,,39,,7-Feb-19,,,IEEE,IEEE Conferences
MPEG Media Transport (MMT) for 3D Tele-Immersion Systems,K. Venkatraman; S. Vellingiri; B. Prabhakaran; N. Nguyen,"Univ. of Texas at Dallas, Richardson, TX, USA; Univ. of Texas at Dallas, Richardson, TX, USA; Univ. of Texas at Dallas, Richardson, TX, USA; TIN Consulting, Richardson, TX, USA",2014 IEEE International Symposium on Multimedia,9-Feb-15,2014,,,279,282,"3D Tele-Immersion (3DTI) environments are a new medium for highly interactive and immersive means of collaborations through a shared virtual 3D environment. They have many applications in the areas of education, entertainment, sports training, tele-medicine etc. The data in these systems are multi-modal, some high volume, some high frequency and all highly correlated. We identify three major challenges in a general 3DTI system, session management, synchronization and data format conversion. We discuss the shortcomings of some of the existing protocols/solutions to them. We describe some features relevant to 3DTI of the MPEG Media Transport (MMT) standard. In this paper we evaluate the use of MMT in a 3DTI application. We provide a feature comparison with the most popular protocols currently being used in such applications, RTP, RTSP, TCP and UDP etc. MPEG DASH was another protocol that was being considered, but that also fails to fully address some of the challenges that 3DTI applications face. Through this comparison study we advocate the use of MMT in 3DTI applications.",,978-1-4799-4311-1,10.1109/ISM.2014.65,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7033039,Tele-Immersion;MPEG Media Transport;Haptic;Body Sensor Networks,Media;Synchronization;Transform coding;Encapsulation;Three-dimensional displays;Transport protocols,multimedia computing;synchronisation;virtual reality,MPEG media transport;MMT;3D tele-immersion systems;3DTI;shared virtual 3D environment;session management;data format conversion;synchronization;feature comparison;RTP;RTSP;TCP;UDP;MPEG DASH,,3,,9,,9-Feb-15,,,IEEE,IEEE Conferences
Lung capacity estimation through acoustic signal of breath,A. Abushakra; M. Faezipour,"Department of Computer Science & Engineering University of Bridgeport, Bridgeport, CT 06604; Department of Computer Science & Engineering University of Bridgeport, Bridgeport, CT 06604",2012 IEEE 12th International Conference on Bioinformatics & Bioengineering (BIBE),3-Jan-13,2012,,,386,391,"Breathing disorders are generally associated with the lung cancer disease. Through daily treatment, lung cancer patients often use a traditional spirometer to measure their lung capacity. However, the use of a spirometer device for accurate measurement requires some sort of training and adjustment, which may be inconvenient for certain groups of patients, especially the elderly. In addition, the spirometer readings can become unreliable if the measurements are not taken as instructed. On the other hand, a microphone, say the microphone on a hand-held device such as a smart-phone, can easily capture the acoustic signal of breath without certain instructions. This signal can then be processed to estimate the lung capacity. In this paper, we propose a methodology through the simply recorded acoustic signal of breath, splitting the breathing cycle to inhale, pause, exhale and pause phases to measure the depth of the breath along with the time duration and signal energy of the breathing phases. We show how these computed parameters are used to estimate the lung size with a high degree of accuracy. This work is part of a virtual reality platform embedded within a smart-phone to assist lung cancer patients regulate their breath. Furthermore, the lung capacity estimation methodology proposed in this paper can also be used to aid patients with other breathing disorders.",,978-1-4673-4358-9,10.1109/BIBE.2012.6399655,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6399655,Acoustic signal of breath;lung capacity;microphone,Lungs;Cancer;Speech;Microphones;Acoustics;Equations;Mathematical model,acoustic signal processing;bioacoustics;biomedical measurement;cancer;lung;medical computing;medical disorders;microphones;pneumodynamics;smart phones;virtual reality,lung capacity estimation;breath acoustic signal;breathing disorders;lung cancer disease;spirometer device;elderly patients;microphone;handheld device;smartphone;simply recorded acoustic signal;breathing cycle;computed parameters;lung size;virtual reality platform,,9,,22,,3-Jan-13,,,IEEE,IEEE Conferences
A Real-Time ECG Feature Extraction Algorithm for Detecting Meditation Levels within a General Measurement Setup,H. Alawieh; Z. Dawy; E. Yaacoub; N. Abbas; J. El-Imad,"Department of Electrical and Computer Engineering, American University of Beirut, Beirut, Lebanon; Department of Electrical and Computer Engineering, American University of Beirut, Beirut, Lebanon; Department of Electrical and Computer Engineering, American University of Beirut, Beirut, Lebanon; NeuroPro AG, Zurich, Switzerland; Department of Electrical & Electronic Engineering, Imperial College, London, UK",2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),7-Oct-19,2019,,,99,103,"This paper presents a setup for the real-time extraction of Electroencephalography (EEG) and Electrocardiogram (ECG) features indicating the level of focus, relaxation, or meditation of a given subject. An algorithm for detecting meditation in real-time using the extracted ECG features is designed and shown to lead to accurate results using an online ECG measurement dataset. Similar methods can be used for EEG data, such that the proposed measurement setup can be used, for example, for investigating the effect of virtual reality based EEG training, with and without neurofeedback, on the capability of subjects to focus, relax, or meditate.",1558-4615,978-1-5386-1311-5,10.1109/EMBC.2019.8857832,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8857832,,Feature extraction;Electrocardiography;Electroencephalography;Biomedical monitoring;Heart rate variability;Real-time systems,electrocardiography;electroencephalography;feature extraction;medical signal detection;medical signal processing;virtual reality,electrocardiogram features;extracted ECG features;online ECG measurement dataset;real-time ECG feature extraction algorithm;meditation levels;electroencephalography;EEG data;virtual reality;neurofeedback,Algorithms;Electrocardiography;Electroencephalography;Meditation;Neurofeedback,1,,8,,7-Oct-19,,,IEEE,IEEE Conferences
Understanding Limb Position and External Load Effects on Real-Time Pattern Recognition Control in Amputees,Y. Teh; L. J. Hargrove,"Regenstein Center for Bionic Medicine, Shirley Ryan AbilityLab, Chicago, IL, USA; Regenstein Center for Bionic Medicine, Shirley Ryan AbilityLab, Chicago, IL, USA",IEEE Transactions on Neural Systems and Rehabilitation Engineering,7-Jul-20,2020,28,7,1605,1613,"Limb position is a factor that negatively affects myoelectric pattern recognition classification accuracy. However, prior studies evaluating impact on real-time control for upper-limb amputees have done so without a physical prosthesis on the residual limb. It remains unclear how limb position affects real-time pattern recognition control in amputees when their residual limb is supporting various weights. We used a virtual reality target achievement control test to evaluate the effects of limb position and external load on real-time pattern recognition control in fourteen intact limb subjects and six major upper limb amputee subjects. We also investigated how these effects changed based on different control system training methods. In a static training method, subjects kept their unloaded arm by their side with the elbow bent whereas in the dynamic training method, subjects moved their arm throughout a workspace while supporting a load. When static training was used, limb position significantly affected real-time control in all subjects. However, amputee subjects were still able to adequately complete tasks in all conditions, even in untrained limb positions. Moreover, increasing external loads decreased controller performance, albeit to a lesser extent in amputee subjects. The effects of limb position did not change as load increased, and vice versa. In intact limb subjects, dynamic training significantly reduced the limb position effect but did not completely remove them. In contrast, in amputee subjects, dynamic training eliminated the limb position effect in three out of four outcome measures. However, it did not reduce the effects of load for either subject population. These findings suggest that results obtained from intact limb subjects may not generalize to amputee subjects and that advanced training methods can substantially improve controller robustness to different limb positions regardless of limb loading.",1558-0210,,10.1109/TNSRE.2020.2991643,National Institutes of Health NIH; Congressionally Directed Medical Research Program; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9090887,Prosthetics;myoelectric control;pattern recognition (PR);limb position,Training;Wrist;Real-time systems;Prosthetics;Elbow;Muscles;Electrodes,biomechanics;electromyography;medical control systems;medical signal processing;pattern recognition;prosthetics;signal classification;virtual reality,untrained limb positions;limb position effect;limb loading;real-time pattern recognition control;myoelectric pattern recognition classification accuracy;upper-limb amputees;residual limb;virtual reality target achievement control test;control system training methods,,,,43,CCBY,11-May-20,,,IEEE,IEEE Journals
Design and realization of virtual scene explore system for artillery reconnaissance radar,Shan Xian-ming; Yang He-yong; Xiao Jun-ling,"Department of Electronic Reconnaissance, Shenyang Artillery Academy, Liaoning, China; Department of Electronic Reconnaissance, Shenyang Artillery Academy, Liaoning, China; Department of Electronic Reconnaissance, Shenyang Artillery Academy, Liaoning, China",2010 3rd International Conference on Computer Science and Information Technology,7-Sep-10,2010,4,,284,287,"Virtual Scene Technology is one of the important parts of VR systems. It takes charge of Vision issue in VR systems, and is the most important fact to affect the immersive of the system. There are many problems in training simulation of artillery reconnaissance radar, such as the battlefield environment isn't living, the load of assemble and disassemble is large, the training cost is high. The virtual scene explore system was developed. The general structure of VS Explore System is analyzed and demonstrated, and connection between different parts of VS explore system in system construction process is explained. Several key techniques such as the building of virtual topography based on Delaunay triangle through Delaunay arithmetic, the building of radar, virtual scene explore, etc, are also given in detail.",,978-1-4244-5540-9,10.1109/ICCSIT.2010.5564786,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5564786,virtual scene;navigation;virtual topograph;DEM;model,Three dimensional displays;Clocks;Computers;Solid modeling;Visualization,mesh generation;radar;terrain mapping;virtual reality,virtual scene explore system;VR systems;artillery reconnaissance radar;virtual topography;Delaunay triangle,,,,6,,7-Sep-10,,,IEEE,IEEE Conferences
Postural balance analysis using force platform for K-theragame users,O. Postolache; P. S. Gir√£o; A. L√≥pez; F. J. Ferrero; J. M. Dias Pereira; G. Postolache,"Instituto de Telecomunica√ß√µes, ISCTE-IUL, Lisbon Portugal; Instituto de Telecomunica√ß√µes, DEEC/IST, Lisbon Portugal; DEEE/Universidad de Oviedo, Spain; DEEE/Universidad de Oviedo, Spain; Instituto de Telecomunica√ß√µes, EST, Lisbon, Portugal; Instituto de Telecomunica√ß√µes, Instituto Medicina Molecular, Lisbon, Portugal",2016 IEEE International Symposium on Medical Measurements and Applications (MeMeA),8-Aug-16,2016,,,1,6,"Serious games based physical therapy is currently gaining a lot of interest by the physiotherapists and game developers that are using new natural user interfaces devices to assure an easy interaction between the user under rehabilitation and his avatar immersed in a virtual reality scenario. Arm motion training, as part of stroke rehabilitation program, can be one of the main objectives of the serious games, and was the object of several serious games developed by our group, the previous works being followed by postural stability monitoring during rehabilitation developments. Thus, the balance analysis on static conditions and during the arm rehabilitation based on implemented serious games represents the objective of the work. The system presented in the paper combine Kinect Serious Game Framework and a developed force platform architecture characterized by Bluetooth communication capabilities that provide the data related to postural balance to be processed together with the upper limb training data for general evaluation of stroke rehabilitation outcome. Experimental results, including time and frequency analysis of the data obtained by the Kinect and force platform, are included in the paper.",,978-1-4673-9172-6,10.1109/MeMeA.2016.7533705,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7533705,physical rehabilitation;serious games;force platform;electronic health record,Games;Force;Training;Sensors;Active filters;Digital filters;Trajectory,avatars;biomedical equipment;Bluetooth;graphical user interfaces;medical computing;medical disorders;patient monitoring;patient rehabilitation;serious games (computing),avatar;Kinect platform;force platform;time frequency analysis;stroke rehabilitation outcome;upper limb training data;postural balance;Bluetooth communication capabilities;developed force platform architecture;Kinect Serious Game Framework;arm rehabilitation;balance analysis;postural stability monitoring;stroke rehabilitation program;arm motion training;virtual reality scenario;natural user interface devices;game developers;serious game based physical therapy;K-Theragame users;force platform;postural balance analysis,,7,,11,,8-Aug-16,,,IEEE,IEEE Conferences
EEG-based motion sickness classification system with genetic feature selection,L. Ko; H. Lee; S. Tsai; T. Shih; Y. Chuang; H. Huang; S. Ho; C. Lin,"Department of Biological Science and Technology, National Chiao Tung University (NCTU), Taiwan; Department of Biological Science and Technology, National Chiao Tung University (NCTU), Taiwan; Department of Computer Science, NCTU, Taiwan; Department of Biological Science and Technology, National Chiao Tung University (NCTU), Taiwan; Department of Biological Science and Technology, National Chiao Tung University (NCTU), Taiwan; Department of Biological Science and Technology, National Chiao Tung University (NCTU), Taiwan; Department of Biological Science and Technology, National Chiao Tung University (NCTU), Taiwan; Department of Biological Science and Technology, National Chiao Tung University (NCTU), Taiwan","2013 IEEE Symposium on Computational Intelligence, Cognitive Algorithms, Mind, and Brain (CCMB)",26-Sep-13,2013,,,158,164,"People tend to get motion sickness on a moving boat, train, airplane, car, or amusement park rides. Many previous studies indicated that motion sickness sometimes led to traffic accidents, so it becomes an important issue in our daily life. In this study, we designed a VR-based motion-sickness platform with a 32-channel EEG system and a joystick which is used to report the motion sickness level (MSL) in real time during experiments. The results show it is feasible to estimate subject's MSL based on re-sampling frequency band proved by the high test accuracy. A comparison between general prediction models (such as LDA, QDA, KNN) and IBCGA shows that the IBCGA can be effectively increase the accuracy. In this paper, an extended-IBCGA (e-IBCGA) is proposed and it provides more accuracy than the prior-art research. The test results show that e-IBCGA increases at least 10% to 20% test accuracy in 6 subjects.",,978-1-4673-5871-2,10.1109/CCMB.2013.6609180,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6609180,,Electroencephalography;Accuracy;Support vector machines;Brain;Visualization;Estimation;Roads,electroencephalography;medical signal processing;virtual reality,motion sickness classification system;genetic feature selection;VR-based motion sickness platform;EEG system;e-IBCGA,,5,,18,,26-Sep-13,,,IEEE,IEEE Conferences
Virtual environments in neuroscience,G. Riva,"Lab. of Appl. Technol. for Neuro-Psychol., IRCCS, Verbania, Italy",IEEE Transactions on Information Technology in Biomedicine,6-Aug-02,1998,2,4,275,281,"Virtual environments (VEs) let users navigate and interact with computer generated three dimensional (3D) environments in real time, allowing for the control of complex stimuli presentation. These VEs have attracted much attention in medicine, especially in remote or augmented surgery, and surgical training, which are critically dependent on hand-eye coordination. Recently, however, some research projects have begun to test the possibility of using VEs for the study and rehabilitation of human cognitive and functional activities. The paper highlights recent and ongoing research related to the applications of VEs in the neuroscience arena. In particular, it focuses on the American and European initiatives in this field, including a description of the European Commission (EC) funded VREPAR projects. Finally, the paper provides a general introduction to virtual reality (VR), as it relates to its impact on cognitive and functional abilities.",1558-0032,,10.1109/4233.737583,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=737583,,Neuroscience;Virtual reality;Biomedical imaging;Surgery;Medical services;Computer displays;Testing;Humans;Telemedicine;Computer graphics,virtual reality;real-time systems;biomedical education;computer aided instruction;medical computing;neurophysiology,virtual environments;neuroscience;computer generated three dimensional environments;complex stimuli presentation;VEs;augmented surgery;surgical training;hand-eye coordination;human cognitive activities;European initiatives;European Commission funded VREPAR projects;virtual reality;functional abilities,Computer Systems;Neurosciences,28,,47,,6-Aug-02,,,IEEE,IEEE Journals
Personalized Image Aesthetic Quality Assessment by Joint Regression and Ranking,K. Park; S. Hong; M. Baek; B. Han,"Dept. of Comput. Sci. & Eng., POSTECH, Pohang, South Korea; Dept. of Comput. Sci. & Eng., POSTECH, Pohang, South Korea; Dept. of Comput. Sci. & Eng., POSTECH, Pohang, South Korea; Dept. of Comput. Sci. & Eng., POSTECH, Pohang, South Korea",2017 IEEE Winter Conference on Applications of Computer Vision (WACV),15-May-17,2017,,,1206,1214,"We propose an image aesthetic quality assessment algorithm, which considers personal taste in addition to generally perceived preference. This problem is formulated by a combination of two different learning frameworks based on support vector machines-Support Vector Regression (SVR) and Ranking SVM (R-SVM), where SVR learns a general model based on public datasets and R-SVM adjusts the model to accommodate personal preference obtained from user interactions. The combined framework, called R-SVR, is represented by a single objective function, which is optimized jointly to learn a model for personalized image aesthetic quality assessment. For the optimization, we use only a small subset of public dataset identified by k-nearest neighbor search instead of using all available training data. This strategy is useful in practice because it reduces training time significantly and alleviates data imbalance problem between regression and ranking. The proposed algorithm is tested through simulation and user study, and we present that our interactive learning algorithm by R-SVR is effective to increase user's satisfaction and improve prediction performance.",,978-1-5090-4822-9,10.1109/WACV.2017.139,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7926722,,Training;Testing;Quality assessment;Support vector machines;Image quality;Training data;Databases,human factors;image processing;learning (artificial intelligence);optimisation;regression analysis;search problems;support vector machines;visual databases,personalized image aesthetic quality assessment;joint regression-and-ranking;support vector machines;support vector regression;ranking SVM;SVR;public datasets;R-SVM;personal preference;user interactions;objective function;k-nearest neighbor search;train-ing time reduction;data imbalance problem;interactive learning algorithm;user satisfaction;prediction performance improvement,,6,,30,,15-May-17,,,IEEE,IEEE Conferences
[Front cover],,,2017 International Conference on Robots & Intelligent System (ICRIS),9-Nov-17,2017,,,c1,c1,The following topics are dealt with: education; Web technology; hospital; ZigBee; feature extraction; mobile smart tourism; marketing system; digital privacy; cement production; virtual reality; fire protection; rescue training; sports information dissemination model; lightning damage; electromechanical equipment fault signals; generalized regression neural network; cloud security intrusion detection; urban cultural landscape heritage protection; suspended centrifuge drum; VPN isolation gateway; Internet of Things; IBMS; service-oriented architecture; electronic product information; household service robot; power management chip; control system; PLC; pumped storage power station; fuzzy clustering algorithm; high performance CQRS architecture; association rule mining algorithm; electronic manufacturing industry; micro-blog; SVM; network anomaly traffic detection algorithm; parking lot; die mold process; moving target detection; tor anonymous network; IPv6 NetStream; domain ontology; machine tool; logistics; smart factory; SPSS analysis; agricultural monitoring data; computer software development; digital watermarking algorithm; and Big Data.,,978-1-5386-1227-9,10.1109/ICRIS.2017.101,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8101323,,,agriculture;computer applications;control systems;data handling;data mining;humanities;Internet;neural nets;pattern clustering;power systems;security;signal processing;software engineering;ubiquitous computing;virtual reality,Web technology;hospital;ZigBee;feature extraction;mobile smart tourism;marketing system;digital privacy;cement production;virtual reality;fire protection;rescue training;sports information dissemination model;lightning damage;electromechanical equipment fault signals;generalized regression neural network;cloud security intrusion detection;urban cultural landscape heritage protection;suspended centrifuge drum;VPN isolation gateway;Internet of Things;IBMS;service-oriented architecture;electronic product information;household service robot;power management chip;control system;PLC;pumped storage power station;fuzzy clustering algorithm;high performance CQRS architecture;association rule mining algorithm;electronic manufacturing industry;education;micro-blog;SVM;network anomaly traffic detection algorithm;parking lot;die mold process;moving target detection;tor anonymous network;IPv6 NetStream;domain ontology;machine tool;logistics;smart factory;SPSS analysis;agricultural monitoring data;computer software development;digital watermarking algorithm;Big Data,,,,,,9-Nov-17,,,IEEE,IEEE Conferences
QoE-Driven Resource Allocation Optimized for Delay-Sensitive VR Video Uploading over Cellular Network,J. Yang; J. Luo; D. Meng; J. -N. Hwang,"Chongqing University of Posts & Telecom, Chongqing,School of Communication and Information Engineering,China; Electronic Information and Networking Research Institute, Chongqing University of Posts & Telecom,Chongqing,China; University of Washington,Electrical Engineering Department,Seattle,USA; University of Washington,Electrical Engineering Department,Seattle,USA",2019 IEEE Symposium on Computers and Communications (ISCC),27-Jan-20,2019,,,1,6,"Uploading Virtual Reality (VR) video over cellular networks is expected to boom in near future, as general consumers could generate high-quality VR videos with portable 360-degree cameras and are willing to share with others. Con-sequently, concerns of uplink bandwidth and delay arose for current popular technology of tile-based VR video streaming, which requires high quality video to transcode into multiple representations for further adaptive streaming. Motivated by this, we proposed a novel scheme for uplink delivery of tile-based VR video over cellular network, in which encoding bit rate of each tile is determined by uplink resource allocation (RA), and quality of content (QoC) contribution of each tile and channel quality of user equipments (UEs) are jointly considered during RA. Moreover, the RA problem is formulated as a frequency and time dependent non-deterministic polynomial(NP)-hard problem, which can be effectively solved by our proposed approximate convex algorithm. Simulation results show that the proposed algorithm can achieve higher utility, that is higher total quality of experience (QoE) for viewers.",2642-7389,978-1-7281-2999-0,10.1109/ISCC47284.2019.8969778,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8969778,VR video;quality of experience (QoE);resource allocation;SC-FDMA;saliency;utility optimization,Streaming media;Uplink;Bit rate;Encoding;Quality of experience;Downlink;Resource management,cellular radio;computational complexity;convex programming;delays;quality of experience;resource allocation;transcoding;video coding;video streaming;virtual reality,QoE-driven resource allocation;delay-sensitive VR video uploading;cellular network;high-quality VR videos;uplink bandwidth;tile-based VR video streaming;high quality video;adaptive streaming;uplink delivery;uplink resource allocation;channel quality;RA problem;quality of experience;portable 360-degree cameras;virtual reality video;transcoding;quality of content;user equipments;frequency-and-time dependent nondeterministic polynomial-hard problem;NP-hard problem;approximate convex algorithm,,1,,16,,27-Jan-20,,,IEEE,IEEE Conferences
Full-duplex multichannel communication: real-time implementations in a general framework,W. Herbordt; H. Buchner; W. Kellermann; R. Rabenstein; S. Spors; H. Teutsch,"Telecommun. Lab., Erlangen-Nurnberg Univ., Erlangen, Germany; Telecommun. Lab., Erlangen-Nurnberg Univ., Erlangen, Germany; Telecommun. Lab., Erlangen-Nurnberg Univ., Erlangen, Germany; Telecommun. Lab., Erlangen-Nurnberg Univ., Erlangen, Germany; Telecommun. Lab., Erlangen-Nurnberg Univ., Erlangen, Germany; Telecommun. Lab., Erlangen-Nurnberg Univ., Erlangen, Germany",2003 International Conference on Multimedia and Expo. ICME '03. Proceedings (Cat. No.03TH8698),18-Aug-03,2003,3,,III,49,"In this combustion, we embed full-duplex multichannel communication interfaces for tele-presence systems into a general framework. On the reproduction side, we consider a wide range of multichannel acoustic rendering techniques including traditional stereophony, '5.1' systems, and wave field synthesis using loud speaker arrays for sound immersion. On the recording side, microphone arrays are discussed for capturing clean desired signals with spatial information. Based on this general framework, real-time implementations of such full-duplex multichannel communication systems are then described. We combine wave field synthesis with multichannel acoustic echo cancellation and adaptive beamforming and discuss a real-time implementation on standard desktop and laptop PCs.",,0-7803-7965-9,10.1109/ICME.2003.1221245,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1221245,,Acoustic waves;Signal synthesis;Microphone arrays;Combustion;Rendering (computer graphics);Loudspeakers;Acoustic arrays;Disk recording;Real time systems;Echo cancellers,telecommunication channels;computer interfaces;loudspeakers;microphones;echo suppression;array signal processing;laptop computers;virtual reality;acoustic signal processing,full-duplex multichannel communication system;communication interfaces;telepresence systems;multichannel acoustic rendering techniques;traditional stereophony;wave field synthesis;loud speaker arrays;sound immersion;microphone arrays;multichannel acoustic echo cancellation;adaptive beamforming;standard desktop;laptop PC,,1,,15,,18-Aug-03,,,IEEE,IEEE Conferences
Dynamic Pose Tracking Performance Evaluation of HTC Vive Virtual Reality System,M. S. Ikbal; V. Ramadoss; M. Zoppi,"Department of Mechanical, Energy, Management, and Transportation Engineering, PMAR Robotics Group, University of Genoa, Genoa, (GE), Italy; Department of Mechanical, Energy, Management, and Transportation Engineering, PMAR Robotics Group, University of Genoa, Genoa, (GE), Italy; Department of Mechanical, Energy, Management, and Transportation Engineering, PMAR Robotics Group, University of Genoa, Genoa, (GE), Italy",IEEE Access,6-Jan-21,2021,9,,3798,3815,"Virtual reality tracking devices are rapidly becoming the go-to system for cost-effective motion tracking solutions across different communities such as robotics, biomechanics, sports, rehabilitation, motion simulators, etc. This article focuses on the spatial tracking performance of HTC Vive's lighthouse tracking system (VLTS) devices (tracker, controller, and head mount display). A comprehensive literature survey on the performance analysis of VLTS on the various aspects is presented along with its shortcomings in terms of spatial tracking evaluation. The two key limitations have been identified: in static cases, there is a lack of standard procedures and criteria, and in dynamic cases, the entire study of spatial tracking. We address the first by assessing VLTS using the optical tracking system standard specified by ASTM International, and the latter by revising the standards to determine the upper-velocity limit for reliable tracking. The findings are substantiated with the trajectories of human wrist motion. Each evaluation's results are systematically analyzed with statistical hypothesis tests and criteria fulfillment. Comau NS16, an industrial serial robot, was used as the ground truth motion generator due to its repeatability and 6 degrees of workspace freedom. One of the major reasons for not having more generalized spatial tracking studies is that the tracking performance heavily depends on the configurations of the setup, work volume, environment, etc. Thus, the guidelines for configuring VLTS and the approach adapted from ASTM standards for evaluating VLTS for custom applications using our reported findings for both static and dynamic cases are included in the appendix.",2169-3536,,10.1109/ACCESS.2020.3047698,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9309218,Lighthouse tracking;motion tracking;performance evaluation and bench-marking;virtual reality and interfaces,Tracking;Standards;Performance evaluation;Dynamics;Service robots;Base stations;Virtual reality,biomechanics;CAD;collision avoidance;helmet mounted displays;industrial manipulators;manipulator kinematics;medical robotics;mobile robots;motion control;motion estimation;object tracking;optical tracking;patient rehabilitation;pose estimation;small-to-medium enterprises;target tracking;tracking;virtual reality,dynamic pose tracking performance evaluation;HTC Vive virtual reality system;virtual reality tracking devices;cost-effective motion;motion simulators;spatial tracking performance;HTC Vive's lighthouse tracking system;head mount display;comprehensive literature survey;performance analysis;VLTS;spatial tracking evaluation;static cases;standard procedures;dynamic cases;optical tracking system standard;upper-velocity limit;reliable tracking;human wrist motion;statistical hypothesis tests;criteria fulfillment;industrial serial robot;ground truth motion generator;generalized spatial tracking studies;ASTM standards,,,,35,CCBY,28-Dec-20,,,IEEE,IEEE Journals
Toward Emotionally Adaptive Virtual Reality for Mental Health Applications,S. Berm√∫dez i Badia; L. V. Quintero; M. S. Cameir√£o; A. Chirico; S. Triberti; P. Cipresso; A. Gaggioli,"Madeira Interactive Technologies Institute, Funchal, Portugal; Madeira Interactive Technologies Institute, Funchal, Portugal; Madeira Interactive Technologies Institute, Funchal, Portugal; Department of Psychology, Universit√† Cattolica del Sacro Cuore, Milan, Italy; Department of Oncology and Hemato-Oncology, University of Milan, Milan, Italy; Department of Psychology, Universit√† Cattolica del Sacro Cuore, Milan, Italy; Department of Psychology, Universit√† Cattolica del Sacro Cuore, Milan, Italy",IEEE Journal of Biomedical and Health Informatics,4-Sep-19,2019,23,5,1877,1887,"Here, we introduce the design and preliminary validation of a general-purpose architecture for affectivedriven procedural content generation in virtual reality (VR) applications in mental health and wellbeing. The architecture supports seven commercial physiological sensing technologies and can be deployed in immersive and nonimmersive VR systems. To demonstrate the concept, we developed the ‚ÄúThe Emotional Labyrinth,‚Äù a non-linear scenario in which navigation in a procedurally generated three-dimensional maze is entirely decided by the user, and whose features are dynamically adapted according to a set of emotional states. During navigation, affective states are dynamically represented through pictures, music, and animated visual metaphors chosen to represent and induce affective states. The underlying hypothesis is that exposing users to multimodal representations of their affective states can create a feedback loop that supports emotional self-awareness and fosters more effective emotional regulation strategies. We carried out a first study to, first, assess the effectiveness of the selected metaphors in inducing target emotions, and second, identify relevant psycho-physiological markers of the emotional experience generated by the labyrinth. Results show that the Emotional Labyrinth is overall a pleasant experience in which the proposed procedural content generation can induce distinctive psychophysiological patterns, generally coherent with the meaning.",2168-2208,,10.1109/JBHI.2018.2878846,Funda√ß√£o para a Ci√™ncia e Tecnologia; European Commission; Fondazione Cariplo; UCSC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516285,Emotion regulation;physiological computing;physiology-driven VR;procedural content generation,Physiology;Biological control systems;Games;Heart rate;Stress;Biomedical monitoring;Computer architecture,affective computing;computer animation;computer games;emotion recognition;health care;medical computing;music;physiology;psychology;user interfaces;virtual reality,mental health applications;general-purpose architecture;emotional states;affective states;music;emotional self-awareness;emotional experience;emotional adaptive virtual reality;physiological sensing technologies;The Emotional Labyrinth;visual metaphor animation;psycho-physiological markers,Adult;Electrocardiography;Electromyography;Emotions;Female;Humans;Male;Mental Health;Psychophysiology;Virtual Reality;Young Adult,,,74,Traditional,31-Oct-18,,,IEEE,IEEE Journals
A Critical Review of Virtual Reality and Geographical Information Systems for Management of the Built Environment,R. Franklin; D. Heesom; A. Felton,"University of Wolverhampton; Sch. of Eng. & the Built Environ., Wolverhampton Univ.; Sch. of Eng. & the Built Environ., Wolverhampton Univ.",Tenth International Conference on Information Visualisation (IV'06),24-Jul-06,2006,,,349,356,"In the field of urban planning, virtual reality systems are currently used as a consultation tool providing the ability to demonstrate the impact of a proposal on the environment. VR simulation models can be driven in real time by the client and adapted by the designer in response to the feedback from architects, planners and also the general public. Within the planning process, GIS systems are often used to analyse geographic data and real time VR has been used as a medium to view the results of data calculations. However, previous initiatives that have integrated VR and GIS to assist in urban planning have focused primarily on the aesthetics of development locations. This paper proposes the development framework of a novel system that allows users to interact with 3D visual data and more traditional GIS data to perform complex 'what if' scenarios in real time. The results of the queries will then be visualised not as text or 2D information, but in real time 3D",2375-0138,0-7695-2602-0,10.1109/IV.2006.6,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1648284,,Virtual reality;Management information systems;Environmental management;Information management;Geographic Information Systems;Urban planning;Real time systems;Proposals;Feedback;Process planning,data visualisation;geographic information systems;town and country planning;virtual reality,virtual reality;geographical information system;urban planning;VR simulation model;GIS system;3D visual data;real time 3D visualisation,,3,,21,,24-Jul-06,,,IEEE,IEEE Conferences
Computational Glasses: Vision Augmentations Using Computational Near-Eye Optics and Displays,J. Sutton; T. Langlotz; Y. Itoh,University of Otago; University of Otago; Tokyo Institute of Technology,2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),9-Jan-20,2019,,,438,442,"Wearable computing devices are small enough that they can be worn on the body and are a constant companion to the user. While many wearable devices have been associated with monitoring health or managing diseases, head-mounted displays are traditionally linked to Augmented and Virtual Reality, and generally overlay 3D information that supports professionals or for edutainment. This is surprising as prescription glasses, their traditional siblings, are widely accepted as a standard device for managing focusing errors of the human eye. In this work, we want to make the case for Computational Glasses that utilise technologies from optical see-through head-mounted displays or computational optics to compensate visual impairments. We will introduce some of the seminal works in the field as well as introduce our own work in the field. We will also include some of the challenges for doing research on Computational Glasses as well as give an outlook for future developments.",,978-1-7281-4765-9,10.1109/ISMAR-Adjunct.2019.00050,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951961,Computational-Glasses;Augmented-Human;OSTHMD;Near-Eye-Optics;Near-Eye-Display;Vision-Aid;Vision-Augmentation;Head-mounted-Displays,Glass;Prototypes;Cameras;Adaptive optics;Visualization;Image color analysis,augmented reality;handicapped aids;helmet mounted displays;wearable computers,Computational Glasses;vision augmentations;wearable computing devices;health monitoring;optical see-through head-mounted displays;prescription glasses;standard device;human eye;focusing error management;computational near-eye optics;disease management;visual impairment compensation;virtual reality;augmented reality;overlay 3D information;edutainment,,,,18,,9-Jan-20,,,IEEE,IEEE Conferences
Simulating Plant Growth with Multi-Agent System,J. Chen; H. Liu; X. Zhang,"School of Information Science and Engineering, Shandong Normal University, Jinan, P.R.. China, 250014; Information Management College, Shandong Economy University, Jinan, P.R.. China, 250014. chenjie112358@163.com; School of Information Science and Engineering, Shandong Normal University, Jinan, P.R.. China, 250014; Information Management College, Shandong Economy University, Jinan, P.R.. China, 250014",2007 2nd International Conference on Pervasive Computing and Applications,29-Oct-07,2007,,,44,49,"Virtual reality technique is widely used in pervasive computing. Plant model is a hotspot study issue in this area. It has been generally recognized that 3D plant model based on growth can make the morphologies of plants lifelike. The paper has put forward a plant growing model based on evolvement of multi-agent system. With multi-agent system, plant growing process can be really simulated. Usually, a plant has many growth points which are growing synchronously. Grow points grow out branches and leaves, and germinate new grow points. Grow points are independent in behavior and adaptable to circumstance, they compete and co-operate with each other, and finally form the shape of plant. So it is nature to employ an agent to simulate behavior of growth point, and employ a multi-agent system to simulate behavior of plant growth system.",,978-1-4244-0970-9,10.1109/ICPCA.2007.4365410,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4365410,Plant Model;Multi-Agent System;Virtual Reality;Nature Scene Simulating,Multiagent systems;Computational modeling;Virtual reality;Layout;Pervasive computing;Logic;Educational institutions;Character recognition;Nonlinear dynamical systems;Chaos,botany;multi-agent systems;solid modelling;ubiquitous computing;virtual reality,multiagent system;virtual reality technique;pervasive computing;plant growing model;grow points;plant growth system,,1,,10,,29-Oct-07,,,IEEE,IEEE Conferences
Gyrolog ‚Äì Creating a 3-Dimensional Digital Collection of Classical Gyro Instruments,M. Niklaus; K. Zhan; J. F. Wagner,"University of Stuttgart,Chair of Adaptive Structures in Aerospace Engineering,70569 Stuttgart,GERMANY; University of Stuttgart,Chair of Adaptive Structures in Aerospace Engineering,70569 Stuttgart,GERMANY; University of Stuttgart,Chair of Adaptive Structures in Aerospace Engineering,70569 Stuttgart,GERMANY",2019 DGON Inertial Sensors and Systems (ISS),30-Dec-19,2019,,,1,23,"Gyro instruments represent a demanding technology, which became increasingly important during the 20th century. Its significant influence on navigation and guidance of especially maritime and aerospace vehicles make them more and more interesting for historians of technology and museums. Furthermore, they form the essential background for understanding the origin of modern inertial systems.The Chair of Adaptive Structures in Aerospace Engineering of the University of Stuttgart maintains a unique, large collection of all kinds of classic, rotating mass gyro instruments like artificial horizons, directional gyros and rate gyros. The collection was established in the 1960s and was initially used for university teaching and research.To support historical as well as didactical research, it is intended to make these gyro instruments virtually available for experts, but also for a broader community in general. This is done by creating 3-dimensional (3D) digital models of the objects - the purpose of the current Gyrolog project at the University of Stuttgart.The highly complex structures of the gyro instruments represent especially demanding digitisation requirements. Therefore, a combination of methods from photogrammetry, endoscopy and computed tomography (CT) is employed. They aim at creating vectorised 3D models being usable for environments of Virtual Reality and Augmented Reality.It is planned to make the digital collection available via Internet by the library of the University of Stuttgart in 2020. The access of each instrument is enhanced by relevant metadata, regular photographs as well as details about specifications, origin, and usage.",2377-3480,978-1-7281-1935-9,10.1109/ISS46986.2019.8943640,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943640,,Instruments;Aerospace engineering;History;Education;Computed tomography;Three-dimensional displays;Computational modeling,aerospace computing;augmented reality;computerised tomography;digital libraries;gyroscopes;inertial navigation;Internet;meta data;museums;photogrammetry;teaching,Internet;augmented reality;virtual reality;University of Stuttgart;University of Stuttgart;computed tomography;endoscopy;photogrammetry;3-dimensional digital models;directional gyros;rotating mass gyro instruments;classic mass gyro instruments;museums;maritime aerospace vehicles;classical gyro instruments;3-dimensional digital collection;vectorised 3D models,,,,29,,30-Dec-19,,,IEEE,IEEE Conferences
QoE-Driven Resource Allocation Optimized for Uplink Delivery of Delay-Sensitive VR Video Over Cellular Network,J. Yang; J. Luo; D. Meng; J. Hwang,"School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; Electronic Information and Networking Institute, Chongqing University of Posts and Telecommunications, Chongqing, China; Electrical Engineering Department, University of Washington, Seattle, WA, USA; Electrical Engineering Department, University of Washington, Seattle, WA, USA",IEEE Access,20-May-19,2019,7,,60672,60683,"Uploading virtual reality (VR) video over cellular networks is expected to boom in the near future, as general consumers could generate the high-quality VR videos with portable 360-degree cameras and are willing to share with others. Consequently, the concerns of uplink bandwidth and delay arose for current popular technology of tile-based VR video streaming, which requires high-quality video to transcode into multiple representations for further adaptive streaming. Motivated by this, we proposed a novel scheme for uplink delivery of tile-based VR video over cellular networks, in which encoding bit rate of each tile is determined by the uplink resource allocation (RA), and the quality of content (QoC) contribution of each tile and channel quality of user equipments (UEs) are jointly considered during RA. Moreover, the RA problem is formulated as a frequency and time dependent non-deterministic polynomial (NP)-hard problem. Furthermore, we propose three algorithms to explore solving the RA problem. The simulation results show that the proposed approximate convex algorithm with low-complexity can achieve higher utility, i.e., higher total quality of experience (QoE) for viewers.",2169-3536,,10.1109/ACCESS.2019.2915370,Chongqing Municipal Education Commission; Ministry of Education‚ÄìChina Mobile Research Fund Project; Chongqing Municipal Education Commission; Chongqing University of Posts and Telecommunications; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8715472,VR video;quality of experience (QoE);resource allocation;cellular network;saliency;utility optimization,Streaming media;Uplink;Bit rate;Bandwidth;Quality of experience;Cellular networks;Encoding,cellular radio;convex programming;quality of experience;resource allocation;video streaming;virtual reality,uplink delivery;delay-sensitive VR video;cellular network;virtual reality video;uplink resource allocation;channel quality;QoE-driven resource allocation;quality of experience;quality of content;VR video streaming,,1,,31,,15-May-19,,,IEEE,IEEE Journals
Virtual Reality and Recommendation System to Design Mobility System,A. Gabriel; M. Ortiz,"LCPI, Arts et Metiers ParisTech, Paris, France; ERPI, Univ. de Lorraine, Nancy, France",2017 13th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS),12-Apr-18,2017,,,490,495,"In the domain of urbanism and more particularly the design of mobility system, the end-users are poorly involved whereas they condition the success of new infrastructure. The generalization of policies for active mobility urges the importance of correctly design the system of mobility. The success goes through the consideration of end-user needs. However, there is always a gap between the needs of the users and reality. We assume that virtual reality can ease user-centered design approach by letting the users experiment the technical solutions. Although maps and mockup permit exchanges between designers and end-users to improve the final design, this research assume that immersive environment is more efficient. Virtual reality seems to be a relevant tool for a user-centered approach applied to mobility system. The difficulty remains providing the adapted information to the designers who are the responsible to make the decision of the solution. The aim is not only to use virtual reality in the design process but also suggests a methodology to imply users in the design process and assist the designer during the decision-making.",,978-1-5386-4283-2,10.1109/SITIS.2017.86,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8334792,virtual reality;recommandation system;mobility system,Virtual environments;Solid modeling;Tools;Legged locomotion;Decision making;Buildings,recommender systems;user centred design;virtual reality,virtual reality;recommendation system;active mobility;correctly design;end-user needs;user-centered design approach;user-centered approach;mobility system design,,,,34,,12-Apr-18,,,IEEE,IEEE Conferences
Partially decentralised wireless routing for distributed augmented reality applications,J. Leskela,"VTT Electron. & Infotech Res. Center, Oulu Univ., Finland","Proceedings of ICICS, 1997 International Conference on Information, Communications and Signal Processing. Theme: Trends in Information Systems Engineering and Wireless Multimedia Communications (Cat. ",6-Aug-02,1997,1,,210,214 vol.1,"Mobile communication can in general be divided into two categories. Centralised mobile communication interfaces the mobile terminals through base stations that are connected to a fixed network. A good example of a centralised mobile system is GSM. Decentralised mobile communication does not have the concept of a base station but the messages are relayed towards their destinations through other mobile terminals. This kind of approach has been considered, for example, in disaster information systems that cannot rely on the fixed infrastructures. This paper presents one routing solution to a wireless low-power picocell network where the flexibility of decentralised communication systems is required, together with the good connectivity brought by centralised and authorised networks. These features are applied in order to provide flexible communication between augmented reality services embedded to electromechanical products and the users wearing light weight virtual reality user interfaces. A routing mechanism that quickly adapts itself with low overhead is a key factor for the success of such an environment.",,0-7803-3676-3,10.1109/ICICS.1997.647089,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=647089,,Routing;Augmented reality;Base stations;Mobile communication;User interfaces;GSM;Relays;Virtual reality;Network topology;Telecommunication traffic,cellular radio;land mobile radio;telecommunication network routing;user interfaces;virtual reality;radio networks;telecommunication computing;data visualisation,partially decentralised wireless routing;distributed augmented reality applications;centralised mobile communication interfaces;mobile terminals;base stations;fixed network;GSM;decentralised mobile communication;disaster information systems;wireless low-power picocell network;authorised networks;augmented reality services;electromechanical products;virtual reality user interfaces;visualisation tool,,1,,10,,6-Aug-02,,,IEEE,IEEE Conferences
Characteristic evaluation of the audio and visual system of haptic device,M. Ishihara; T. Komori,"Dept. Innovative Electrical and Electronic Engineering, Oyama National College of Technology, 323-0806 JAPAN; Advanced Course of General Engineering Program, Oyama National College of Technology, 323-0806 JAPAN",2014 IEEE 3rd Global Conference on Consumer Electronics (GCCE),5-Feb-15,2014,,,356,357,"This paper illustrates the effectiveness of a proactive data transfer scheme for adaptive display control in a distributed haptic system with virtual reality, which is an application using haptic, audio and visual media. Presentation experiments of an audio-visual stimulus were carried out using a computer graphics of a moving ball and its collision sound. The results obtained show that the sound image at the beginning of an audio-visual presentation is more strongly captured with the visual image than that at the ending, and that the sound image is perceived separately from the visual image even at the timing of the presentation positions of the audio and visual stimuli coincide with each other when the sound source is moving in the collision of the visual image.",2378-8143,978-1-4799-5145-1,10.1109/GCCE.2014.7031219,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7031219,audio-visual;haptic;collision sound,Atmospheric measurements;Particle measurements;Interpolation;Phantoms;Quality of service;Distributed databases;Computers,audio-visual systems;computer graphics;haptic interfaces;virtual reality,characteristic evaluation;audio system;visual system;haptic device;proactive data transfer scheme;adaptive display control;distributed haptic system;virtual reality;audio media;visual media;audio-visual stimulus;computer graphics;moving ball;collision sound;sound image;audio-visual presentation;visual image;presentation positions;sound source,,1,,5,,5-Feb-15,,,IEEE,IEEE Conferences
Motion adaptation on a wheelchair driving simulator,F. Goncalves; L. Trenoras; E. Monacelli; A. Schmid,"Laboratoire d'Ingenierie des Systemes de Versailles 10-12 avenue de l'Europe, 78140 Velizy, France; Laboratoire d'Ingenierie des Systemes de Versailles 10-12 avenue de l'Europe, 78140 Velizy, France; Laboratoire d'Ingenierie des Systemes de Versailles 10-12 avenue de l'Europe, 78140 Velizy, France; Electricite de France 1 avenue du General de Gaulle 92140 Clamart, France",2014 2nd Workshop on Virtual and Augmented Assistive Technology (VAAT),17-Apr-14,2014,,,17,22,"The objective of the AccesSim project is to design a wheelchair simulator using Virtual Reality and a robotic platform to detect and illustrate accessibility issues in complex environments. In order to be efficient, the robotic platform must provide haptic and vestibular feedbacks to different profile of end users: urbanists to wheelchair users. It must be modular and adaptable to each one of them. In this paper we focus our robotic platform capable of adapting its configuration and feedback rendering based on the user. The design of the platform is described. The capacity of the platform to reproduce the motion of a wheelchair in a specific study case is tested experimen-tally. Finally the results introduce the possibility of adapting the dynamic feedback rendering based on a specific user and environmental situations.",,978-1-4799-4070-7,10.1109/VAAT.2014.6799463,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6799463,I.3.7 [COMPUTERS AND SOCIETY]: Social Issues ‚Äî Assistive technologies for persons with disabilities;I.3.7 [COMPUTER GRAPHICS]: Three-Dimensional Graphics and Realism ‚Äî Virtual reality;H.3.4 [INFORMATION STORAGE AND RETRIEVAL]: Systems and Software ‚Äî Performance evaluation,Wheelchairs;Acceleration;Mobile robots;Dynamics;Robot sensing systems;Wheels,digital simulation;handicapped aids;medical robotics;virtual reality;wheelchairs,motion adaptation;wheelchair driving simulator;AccesSim project;virtual reality;robotic platform;haptic feedbacks;vestibular feedbacks;urbanists;dynamic feedback rendering;environmental situations,,1,,14,,17-Apr-14,,,IEEE,IEEE Conferences
Toed-in vs Parallel Displays in Video See-Through Head-Mounted Displays for Close-Up View,N. Cattari; F. Cutolo; R. D‚Äôamato; U. Fontana; V. Ferrari,"Department of Translational Research and New Technologies in Medicine and Surgery, EndoCAS Centre, University of Pisa, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy; Department of Translational Research and New Technologies in Medicine and Surgery, EndoCAS Centre, University of Pisa, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy",IEEE Access,8-Nov-19,2019,7,,159698,159711,"In non-orthostereoscopic video see-through (VST) head-mounted displays (HMDs), the perception of the three-dimensional space is negatively altered by geometrical aberrations, which may lead to perceptual errors, problems of hand-eye coordination, and discomfort for the user. Parallax-free VST HMDs have been proposed, yet their embodiments are generally difficult to create. The present study investigates the guidelines for the development of non-orthostereoscopic VST HMDs capable of providing perceptually coherent augmentations for close-up views, hence specifically devoted to guide high-precision manual tasks. Our underlying rationale is that, under VST view, a perspective-preserving conversion of the camera frames is sufficient to restore the natural perception of the relative depths around a pre-defined working distance in non-orthostereoscopic VST HMDs. This perspective conversion needs to account for the geometry of the visor and the working distance. A simulation platform was designed to compare the on-image displacements between the direct view of the world and the perspective-corrected VST view, considering three different geometrical arrangements of cameras and displays. A user study with a custom-made VST HMD was then conducted to evaluate quantitatively and qualitatively which of the three configurations was the most effective in mitigating the impact of the geometrical aberrations around the reference distance. The results of the simulations and of the user study both proved that, in non-orthostereoscopic VST HMDs, display convergence can be prevented, as the perspective conversion of the camera frames is sufficient to restore the correct stereoscopic perception by the user in the peripersonal space.",2169-3536,,10.1109/ACCESS.2019.2950877,HORIZON2020 Project VOSTARS; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8888173,Head-mounted display;stereoscopic displays;augmented reality;video see-through displays;orthoscopic view;optical aberrations,Optical distortion;Cameras;Optical imaging;Nonlinear optics;Adaptive optics;Optical sensors;Resists,aberrations;augmented reality;cameras;helmet mounted displays;stereo image processing;three-dimensional displays;video cameras;visual perception,display convergence;custom-made VST HMD;cameras;perspective-corrected VST view;direct view;perspective conversion;camera frames;perspective-preserving conversion;high-precision manual tasks;perceptually coherent augmentations;nonorthostereoscopic VST HMDs capable;parallax-free VST HMDs;hand-eye coordination;perceptual errors;geometrical aberrations;nonorthostereoscopic video;toed-in vs parallel displays,,4,,41,CCBY,31-Oct-19,,,IEEE,IEEE Journals
HySAR: Hybrid Material Rendering by an Optical See-Through Head-Mounted Display with Spatial Augmented Reality Projection,T. Hamasaki; Y. Itoh; Y. Hiroi; D. Iwai; M. Sugimoto,Keio University; Tokyo Institue of TechnologyRIKENKeio University; Keio University; Osaka University; Keio University,IEEE Transactions on Visualization and Computer Graphics,13-Mar-18,2018,24,4,1457,1466,"Spatial augmented reality (SAR) pursues realism in rendering materials and objects. To advance this goal, we propose a hybrid SAR (HySAR) that combines a projector with optical see-through head-mounted displays (OST-HMD). In an ordinary SAR scenario with co-located viewers, the viewers perceive the same virtual material on physical surfaces. In general, the material consists of two components: a view-independent (VI) component such as diffuse reflection, and a view-dependent (VD) component such as specular reflection. The VI component is static over viewpoints, whereas the VD should change for each viewpoint even if a projector can simulate only one viewpoint at one time. In HySAR, a projector only renders the static VI components. In addition, the OST-HMD renders the dynamic VD components according to the viewer's current viewpoint. Unlike conventional SAR, the HySAR concept theoretically allows an unlimited number of co-located viewers to see the correct material over different viewpoints. Furthermore, the combination enhances the total dynamic range, the maximum intensity, and the resolution of perceived materials. With proof-of-concept systems, we demonstrate HySAR both qualitatively and quantitatively with real objects. First, we demonstrate HySAR by rendering synthetic material properties on a real object from different viewpoints. Our quantitative evaluation shows that our system increases the dynamic range by 2.24 times and the maximum intensity by 2.12 times compared to an ordinary SAR system. Second, we replicate the material properties of a real object by SAR and HySAR, and show that HySAR outperforms SAR in rendering VD specular components.",1941-0506,,10.1109/TVCG.2018.2793659,JSPS; JST CREST; JST PRESTO; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260968,Optical see-through displays;hybrid material rendering;spatial augmented reality,Augmented realtiy;Head-mounted displays;Rendering (computer graphics);Optical reflection;Adaptive optics,augmented reality;helmet mounted displays;rendering (computer graphics),optical see-through head-mounted display;VD specular components;static VI components;view-dependent component;view-independent component;virtual material;hybrid SAR;spatial augmented reality projection;hybrid material rendering,,1,,37,Traditional,17-Jan-18,,,IEEE,IEEE Journals
"A Survey on Adaptive 360¬∞ Video Streaming: Solutions, Challenges and Opportunities",A. Yaqoob; T. Bi; G. -M. Muntean,"Insight Centre for Data Analytics, Dublin City University, Dublin, Ireland; Performance Engineering Laboratory, Dublin City University, Dublin, Ireland; Performance Engineering Laboratory, Dublin City University, Dublin, Ireland",IEEE Communications Surveys & Tutorials,20-Nov-20,2020,22,4,2801,2838,"Omnidirectional or 360¬∞ video is increasingly being used, mostly due to the latest advancements in immersive Virtual Reality (VR) technology. However, its wide adoption is hindered by the higher bandwidth and lower latency requirements than associated with traditional video content delivery. Diverse researchers propose and design solutions that help support an immersive visual experience of 360¬∞ video, primarily when delivered over a dynamic network environment. This paper presents the state-of-the-art on adaptive 360¬∞ video delivery solutions considering end-to-end video streaming in general and then specifically of 360¬∞ video delivery. Current and emerging solutions for adaptive 360¬∞ video streaming, including viewport-independent, viewport-dependent, and tile-based schemes are presented. Next, solutions for network-assisted unicast and multicast streaming of 360¬∞ video content are discussed. Different research challenges for both on-demand and live 360¬∞ video streaming are also analyzed. Several proposed standards and technologies and top international research projects are then presented. We demonstrate the ongoing standardization efforts for 360¬∞ media services that ensure interoperability and immersive media deployment on a massive scale. Finally, the paper concludes with a discussion about future research opportunities enabled by 360¬∞ video.",1553-877X,,10.1109/COMST.2020.3006999,European Regional Development Fund through the Science Foundation Ireland (SFI) Research Centres Programme; Insight Centre for Data Analytics; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9133103,360¬∞ video streaming;virtual reality;HTTP adaptive streaming;MPEG-DASH;video tiling;viewport prediction;quality assessment;standards,Streaming media;Quality of service;Quality assessment;Real-time systems;Bandwidth;Quality of experience,multicast communication;open systems;video streaming;virtual reality,360¬∞ media services;360¬∞ video content;end-to-end video;adaptive 360¬∞ video delivery solutions;traditional video content delivery;immersive Virtual Reality technology;omnidirectional video;adaptive 360¬∞ video streaming,,1,,308,IEEE,3-Jul-20,,,IEEE,IEEE Journals
Motion Sickness in Virtual Reality: An Empirical Evaluation,U. A. Chattha; U. I. Janjua; F. Anwar; T. M. Madni; M. F. Cheema; S. I. Janjua,"Department of Computer Science, COMSATS University Islamabad, Islamabad, Pakistan; Department of Computer Science, COMSATS University Islamabad, Islamabad, Pakistan; Department of Health Informatics, COMSATS University Islamabad, Islamabad, Pakistan; Department of Computer Science, COMSATS University Islamabad, Islamabad, Pakistan; Department of Computer Science, FAST University (NUCES) Islamabad, Islamabad, Pakistan; Medical Hospital, Islamabad, Pakistan",IEEE Access,23-Jul-20,2020,8,,130486,130499,"Due to rapid growth in Virtual Reality (VR) technology, the industry of VR is expected to grow around $26.89 billion by 2022. However, with its extensive growth and immersive inclusion in human life, health-related issues are reported including, but not limited to nauseated feeling, vomiting, dizziness and cold sweats. These issues introduce a well-known side effect termed as motion sickness in VR users. Consequently, motion sickness limits the VR community in the full adaptation of this immersive technology. Since there is no lack of literature investigating motion sickness caused by VR, yet researches on the effect of VR on human's physiology is still in its infancy. This study presents novel findings, by comparing different factors such as gender, motion sickness experience, 3D games experience and VR experience. Furthermore, it reports the impact of concerning factors in a within-subjects design (46 participants participated in an experiment) under different virtual environment genres. The key findings of this article report that there is a significant difference in the amount of motion sickness when shifting from pleasant to the horror genre of the environment and having a strong dependence on gender. Moreover, the type of virtual environment is an essential factor that has a notable effect on the user's blood pressure, blood sugar and heart rate. However, past experiences with motion sickness and 3D games show no significant impact on the user's level of motion sickness.",2169-3536,,10.1109/ACCESS.2020.3007076,Higher Education Commission of Pakistan through the Start-Up Research Grant Program; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9133071,Motion sickness;simulator sickness;virtual reality;virtual worlds;virtual environments;VR sickness,Virtual environments;Physiology;Heart rate;Industries;Three-dimensional displays;Games;Blood pressure,gender issues;human factors;physiology;virtual reality,heart rate;blood sugar;3D games;user blood pressure;virtual environment genres;3D games experience;human physiology;immersive technology;health-related issues;empirical evaluation;motion sickness experience;VR community;virtual reality technology,,,,42,CCBY,3-Jul-20,,,IEEE,IEEE Journals
An analysis of eye-tracking data in foveated ray tracing,T. Roth; M. Weier; A. Hinkenjann; Y. Li; P. Slusallek,"Bonn-Rhein-Sieg University of Applied Sciences and Brunel University London; Bonn-Rhein-Sieg University of Applied Sciences and Saarland University; Bonn-Rhein-Sieg University of Applied Sciences; Brunel University London; Saarland University, Intel Visual Computing Institute and German Research Center for Artificial Intelligence (DFKI)",2016 IEEE Second Workshop on Eye Tracking and Visualization (ETVIS),16-Feb-17,2016,,,69,73,"We present an analysis of eye tracking data produced during a quality-focused user study of our own foveated ray tracing method. Generally, foveated rendering serves the purpose of adapting actual rendering methods to a user's gaze. This leads to performance improvements which also allow for the use of methods like ray tracing, which would be computationally too expensive otherwise, in fields like virtual reality (VR), where high rendering performance is important to achieve immersion, or fields like scientific and information visualization, where large amounts of data may hinder real-time rendering capabilities. We provide an overview of our rendering system itself as well as information about the data we collected during the user study, based on fixation tasks to be fulfilled during flights through virtual scenes displayed on a head-mounted display (HMD). We analyze the tracking data regarding its precision and take a closer look at the accuracy achieved by participants when focusing the fixation targets. This information is then put into context with the quality ratings given by the users, leading to a surprising relation between fixation accuracy and quality ratings.",,978-1-5090-4731-4,10.1109/ETVIS.2016.7851170,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7851170,,Rendering (computer graphics);Visualization;Ray tracing;Target tracking;Electronic mail;Tunneling;Focusing,data analysis;data visualisation;gaze tracking;helmet mounted displays;ray tracing;rendering (computer graphics);virtual reality,eye-tracking data analysis;foveated ray tracing method;foveated rendering;actual rendering methods;virtual reality;scientific visualization;information visualization;real-time rendering capabilities;fixation tasks;virtual scenes;head-mounted display;HMD;quality ratings,,5,,17,,16-Feb-17,,,IEEE,IEEE Conferences
MAC Scheduling for Multiuser Wireless Virtual Reality in 5G MIMO-OFDM Systems,M. Huang; X. Zhang,"Intel Corp., USA; Intel Corp., USA",2018 IEEE International Conference on Communications Workshops (ICC Workshops),5-Jul-18,2018,,,1,6,"Wireless Virtual Reality (VR) is a new-arising technology to enable the untethered connection between VR server and VR client, which needs to support simultaneously ultra-high data rate and ultra-high transfer reliability for video streaming, and also ultra-high responsive speed for motion-to-photon latency. Such three ultra-high (3UH) requirements constitute the basic characteristics of the generalized tactile internet. This paper proposes a multiuser MAC scheduling scheme for VR service in 5G MIMO-OFDM system, which can maximize the number of simultaneous VR clients while guaranteeing their 3UH quality-of-experience (QoE). Specifically, this scheme is composed of three novel functions, including video frame differentiation and delay-based weight calculation, spatial-frequency user selection based on maximum aggregate delay-capacity utility (ADCU), and link adaptation with dynamic block-error-rate (BLER) target. In addition, a low-complexity downlink MIMO user selection algorithm is developed, which can reduce the calculation amount with one order. It is demonstrated by the simulation results that the proposed scheme increases 31.6% for the maximum number of simultaneously served VR users than the traditional scheme with maximum-sum-capacity based scheduling and fixed BLER target based link adaptation.",2474-9133,978-1-5386-4328-0,10.1109/ICCW.2018.8403486,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8403486,,Streaming media;Wireless communication;5G mobile communication;Servers;Base stations;Payloads;Reliability,5G mobile communication;access protocols;Internet;MIMO communication;multi-access systems;OFDM modulation;quality of experience;radio links;telecommunication scheduling;video streaming;virtual reality,untethered connection;VR server;ultra-high data rate;ultra-high transfer reliability;video streaming;ultra-high responsive speed;ultra-high requirements;multiuser MAC scheduling scheme;VR service;simultaneous VR clients;3UH quality-of-experience;video frame differentiation;spatial-frequency user selection;maximum aggregate delay-capacity utility;dynamic block-error-rate target;low-complexity downlink MIMO user selection algorithm;simultaneously served VR users;multiuser wireless virtual reality;5G MIMO-OFDM systems;motion-to-photon latency;generalized tactile Internet;delay-based weight calculation;ADCU;link adaptation;BLER,,5,,15,,5-Jul-18,,,IEEE,IEEE Conferences
Finite element methods for real-time haptic feedback of soft-tissue models in virtual reality simulators,A. O. Frank; I. A. Twombly; T. J. Barth; J. D. Smith,"Center for Bioinf., NASA Ames Res. Center, Moffett Field, CA, USA; NA; NA; NA",Proceedings IEEE Virtual Reality 2001,7-Aug-02,2001,,,257,263,"Applies the linear elastic finite element method to compute haptic force feedback and domain deformations of soft-tissue models for use in virtual reality simulators. Our results show that, for virtual object models of high-resolution 3D data (>10,000 nodes), haptic real-time computations (<500 Hz) are nor currently possible using traditional methods. Current research efforts are focused in the following areas: (1) efficient implementation of fully adaptive multi-resolution methods, and (2) multi-resolution methods with specialized basis functions to capture the singularity at the haptic interface (point loading). To achieve real-time computations, we propose parallel processing of a Jacobi pre-conditioned conjugate gradient method applied to a reduced system of equations resulting from surface domain decomposition. This can effectively be achieved using reconfigurable computing systems such as field programmable gate arrays (FPGAs), thereby providing a flexible solution that allows for new FPGA implementations as improved algorithms become available. The resulting soft-tissue simulation system would meet NASA Virtual Glovebox requirements and, at the same time, provide a generalized simulation engine for any immersive environment application, such as biomedical/surgical procedures or interactive scientific applications.",,0-7695-0948-7,10.1109/VR.2001.913794,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=913794,,Finite element methods;Haptic interfaces;Virtual reality;Computational modeling;Field programmable gate arrays;Deformable models;Force feedback;Real time systems;Concurrent computing;Parallel processing,biological tissues;finite element analysis;real-time systems;haptic interfaces;force feedback;virtual reality;digital simulation;elastic deformation;parallel programming;Jacobian matrices;reconfigurable architectures;field programmable gate arrays;medical computing,linear elastic finite element method;real-time haptic feedback;soft-tissue models;virtual reality simulators;domain deformations;virtual object models;high-resolution 3D data;fully adaptive multi-resolution methods;multi-resolution methods;specialized basis functions;haptic interface singularity;point loading;parallel processing;Jacobi preconditioned conjugate gradient method;reduced equation system;surface domain decomposition;reconfigurable computing systems;field programmable gate arrays;FPGA implementations;flexible solution;NASA Virtual Glovebox;generalized simulation engine;immersive environment;biomedical procedures;surgical procedures;interactive scientific applications,,15,,39,,7-Aug-02,,,IEEE,IEEE Conferences
Evaluating the Effectiveness of Redirected Walking with Auditory Distractors for Navigation in Virtual Environments,N. Rewkowski; A. Rungta; M. Whitton; M. Lin,"UNC, Chapel Hill; UNC, Chapel Hill; UNC, Chapel Hill; UMD College, Park UNC Chapel Hill",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,395,404,"Many virtual locomotion interfaces allowing users to move in virtual reality have been built and evaluated, such as redirected walking (RDW), walking-in-place (WIP), and joystick input. RDW has been shown to be among the most natural and immersive as it supports real walking, and many newer methods further adapt RDW to allow for customization and greater immersion. Most of these methods have been demonstrated to work with vision, in this paper we evaluate the ability for a general distractor-based RDW framework to be used with only auditory display. We conducted two studies evaluating the differences between RDW with auditory distractors and other distractor modalities using distraction ratio, virtual and physical path information, immersion, simulator sickness, and other measurements. Our results indicate that auditory RDW has the potential to be used with complex navigational tasks, such as crossing streets and avoiding obstacles. It can be used without designing the system specifically for audio-only users. Additionally, sense of presence and simulator sickness remain reasonable across all user groups.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8798286,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798286,virtual locomotion‚Äîredirected walking‚Äîdistractors,Legged locomotion;Distortion;Navigation;Task analysis;Visualization;Virtual environments;Dogs,cognition;ergonomics;interactive devices;virtual reality,redirected walking;auditory distractors;virtual environments;virtual locomotion interfaces;virtual reality;walking-in-place;joystick input;general distractor-based RDW framework;auditory display;distractor modalities;virtual path information;physical path information;simulator sickness;auditory RDW;complex navigational tasks,,,,49,,15-Aug-19,,,IEEE,IEEE Conferences
Distributed Video Transcoding System for 8K 360¬∞ VR Tiled Streaming Service,Y. Kim; J. Huh; J. Jeong,"Intelligent Image Processing Research Center, Korea Electronics Technology Institute (KETI), Seongnam-si, Republic of Korea; Intelligent Image Processing Research Center, Korea Electronics Technology Institute (KETI), Seongnam-si, Republic of Korea; Intelligent Image Processing Research Center, Korea Electronics Technology Institute (KETI), Seongnam-si, Republic of Korea",2018 International Conference on Information and Communication Technology Convergence (ICTC),18-Nov-18,2018,,,592,595,"360¬∞ Virtual Reality (VR) services with resolutions of 8K and beyond are a challenging task due to limits of both decoding complexity and constrained public internet bandwidth of consumer devices. Also, general streaming servers cannot service these large-resolution video streams to many clients because of bandwidth limitation. In this paper, we propose a distributed video transcoding system for achieving viewport adaptive streaming, which is known as tiled streaming, of 8K 360¬∞ VR video. The proposed system consists of many motion-constrained High Efficiency Video Coding (HEVC) encoders, a Hadoop/Spark-based distributed computing platform, light-weight bitstream stitcher, and dual HEVC decoders. Experimental results show that 8K 360¬∞ videos which are split by 8√ó8 tiles, respectively, can be encoded at 99 fps, and 4√ó4 tiles are stitched at 9,585 fps, on average.",2162-1233,978-1-5386-5041-7,10.1109/ICTC.2018.8539372,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8539372,360¬∞ video;virtual reality;distributed transcoding;HEVC;tiles;bitstream stitching,Streaming media;Transcoding;Decoding;Bit rate;Media;High efficiency video coding;Transform coding,data compression;Internet;parallel processing;transcoding;video coding;video streaming;virtual reality,distributed video transcoding system;VR tiled streaming service;decoding complexity;large-resolution video streams;bandwidth limitation;viewport adaptive streaming;dual HEVC decoders;VR video;motion-constrained high efficiency video coding;virtual reality services;constrained public internet bandwidth;streaming servers;Hadoop-Spark-based distributed computing;light-weight bitstream stitcher,,1,,12,,18-Nov-18,,,IEEE,IEEE Conferences
Adaptive Parameters Estimation for Light Field Reconstruction using Shearlet Transform,S. Jinming; H. Xinjue; L. Yu; L. Zhang,"School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China",2018 International Conference on Network Infrastructure and Digital Content (IC-NIDC),8-Nov-18,2018,,,125,129,"The research of light field can provide the VR (Virtual Reality)/AR (Augmented Reality) products' more realistic immersion effect and bring revolutionary development to the VR/AR industry. The light field reconstruction is one of the most important technologies in light field. The methods to reconstruct the light field can generally be divided into the time domain and the frequency domain. The advantage of reconstructing the light field from frequency domain is that it can eliminate the effect of occlusion on the light field reconstruction to a certain extent. Although many reconstruction algorithms in frequency domain has been put forward, their performance on different data sources strongly depends on pre-set fixed parameters. There is a great need for a method that can adaptively adjust parameters in dealing with various sources of data to improve this situation. This paper utilizes the correlation between the parameters to improve the efficiency of light field reconstruction using Sheartlet Transform and proposes an adaptive parameter estimation method to adjust the parameters to be suitable for all types of light fields. Simulation results illustrates that the PSNR is obviously higher than that of the original method, which verify the adaptability of the proposed parameter estimation method of the shearlet light field reconstruction to different light fields.",2575-4955,978-1-5386-6067-6,10.1109/ICNIDC.2018.8525651,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8525651,Light field reconstruction;EPI images;Correlation;Loop nesting,Image reconstruction;Parameter estimation;Transforms;Frequency-domain analysis;Correlation;Cameras,adaptive estimation;Bayes methods;image denoising;image reconstruction;parameter estimation;virtual reality;wavelet transforms,VR/AR products;frequency domain;adaptive parameter estimation method;shearlet light field reconstruction;Shearlet transform;time domain,,,,10,,8-Nov-18,,,IEEE,IEEE Conferences
Efficient multiview image compression using quadtree disparity estimation,D. R. Clewer; L. J. Luo; C. N. Canagarajah; D. R. Bull; M. H. Barton,"Centre for Commun. Res., Bristol Univ., UK; NA; NA; NA; NA",ISCAS 2001. The 2001 IEEE International Symposium on Circuits and Systems (Cat. No.01CH37196),7-Aug-02,2001,5,,295,298 vol. 5,"Viewpoint adaptation, or ""look-around"" capability, is likely to be vital to the success of future immersive multimedia services such as 3D video-conferencing, virtual reality and 3DTV. This paper proposes a low complexity and efficient compression system for multiview images using quadtree disparity estimation and multiview synthesis. Previous approaches to the problem have generally involved the transmission of a coded stereo image pair, usually using fixed block size disparity compensation, along with a pair of dense disparity maps used for intermediate view synthesis. In this work, the quadtree disparity map coded implicitly in the stereo compression process is re-used in the multiview synthesis process. The other map is also efficiently represented using a quadtree structure at low resolution. Improved multiview compression results are presented, along with intermediate views synthesised at the decoder.",,0-7803-6685-9,10.1109/ISCAS.2001.922043,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=922043,,Image coding;Motion estimation;Image segmentation;Decoding;Virtual reality;TV;Web and internet services;Mobile communication;Quality of service;Displays,data compression;image coding;stereo image processing;quadtrees;computational complexity;multimedia communication;virtual reality;teleconferencing,multiview image compression;quadtree disparity estimation;low complexity compression system;multiview synthesis;stereo compression process,,4,4,10,,7-Aug-02,,,IEEE,IEEE Conferences
Progress towards a resilient power grid infrastructure,W. H. Sanders,"Department of Electrical and Computer Engineering, University of Illinois, Urbana, 61801 USA",IEEE PES General Meeting,30-Sep-10,2010,,,1,3,"This panel presentation gives an overview of the DOE/NSF/DHS TCIP Center which is addressing the challenge of how to design, build, and validate a cyber infrastructure for the next generation power grid that can survive malicious cyber attacks while providing continuous power delivery. TCIP's research plan is focused on securing the low-level devices, communications, and data systems that make up the power grid, to ensure trustworthy operation during normal conditions, cyber-attacks, and/or power emergencies. At the device level, new key functionality is being designed in hardware in order to detect attacks and failures and to restore proper system operation. Likewise, virtual machine technology is being developed and adapted for advanced power meters in order to permit new power use scenarios while preserving privacy. At the protocol level, new techniques are being developed to detect, react to, and recover from cyber attacks that occur while preserving integrity, availability, and real-time requirements. Further, lightweight authorization and authentication techniques are being developed that can react quickly in emergency situations. Simulation and evaluation techniques are employed to analyze real power grid scenarios and validate the effectiveness of the TCIP designs and implementations. TCIP has also developed interactive and open-ended applets for middle-school students, along with activity materials and teacher guides to facilitate the integration of research, education, and knowledge transfer by linking researchers, educators, and students. In addition to providing an overview of current TCIP research, this presentation will suggest challenges that remain, and future research that is needed to create the resilient power grid of the future.",1944-9925,978-1-4244-6551-4,10.1109/PES.2010.5589686,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5589686,,Power grids;Security;Protocols;Education;Power system reliability;Computational modeling,authorisation;power engineering computing;power engineering education;power grids;power meters,resilient power grid infrastructure;TCIP design;cyber infrastructure;next generation power grid;cyber attacks;power delivery;virtual machine technology;advanced power meters;lightweight authorization;emergency situations;open-ended applets;teacher guides,,9,,,,30-Sep-10,,,IEEE,IEEE Conferences
QuadTIN: quadtree based triangulated irregular networks,R. Pajarola; M. Antonijuan; R. Lario,"Dept. of Inf. & Comput. Sci., California Univ., Irvine, CA, USA; NA; NA","IEEE Visualization, 2002. VIS 2002.",25-Feb-08,2002,,,395,402,"Interactive visualization of large digital elevation models is of continuing interest in scientific visualization, GIS, and virtual reality applications. Taking advantage of the regular structure of grid digital elevation models, efficient hierarchical multiresolution triangulation and adaptive level-of-detail (LOD) rendering algorithms have been developed for interactive terrain visualization. Despite the higher triangle count, these approaches generally outperform mesh simplification methods that produce irregular triangulated network (TIN) based LOD representations. In this project we combine the advantage of a TIN based mesh simplification preprocess with high-performance quadtree based LOD triangulation and rendering at run-time. This approach, called QuadTIN, generates an efficient quadtree triangulation hierarchy over any irregular point set that may originate from irregular terrain sampling or from reducing oversampling in high-resolution grid digital elevation models.",,0-7803-7498-3,10.1109/VISUAL.2002.1183800,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1183800,,Tin;Digital elevation models;Data visualization;Computer graphics;Geographic Information Systems;Virtual reality;Rendering (computer graphics);Strips;Computer science;Application software,rendering (computer graphics);data visualisation;quadtrees;computational geometry;virtual reality,QuadTIN;quadtree based triangulated irregular networks;interactive visualization;digital elevation models;scientific visualization;virtual reality;multiresolution triangulation;adaptive level-of-detail rendering algorithms;terrain sampling;computational geometry;interactive terrain visualization;irregular triangulated network,,30,4,28,,25-Feb-08,,,IEEE,IEEE Conferences
Non-local pose means for denoising motion capture data,C. J. Dean; J. P. Lewis,"Computer Graphics Group, Victoria University, Wellington, New Zealand; SEED Electronic Arts and Victoria University",2017 International Conference on Image and Vision Computing New Zealand (IVCNZ),5-Jul-18,2017,,,1,6,"Motion capture is commonly used in movies and games, and may become more widespread if anticipated virtual reality and augmented reality applications become popular. Unfortunately, body motion capture generally suffers from significant noise resulting from intrinsic factors not present in other media such as images and videos. This paper adapts the nonlocal means (NLM) principle from image processing to noise reduction in motion capture data. We show that the NLM principle can be applied while respecting the rotational nature of skeletal movement by operating in the vector space obtained by a log/exponential map. NLM has been previously overlooked in the field of motion data. The results are compellingly effective motion denoising for small and large amounts of Gaussian noise. Our results rival or outperform other techniques in a survey of standard denoising methods in signal processing.",2151-2205,978-1-5386-4276-4,10.1109/IVCNZ.2017.8402451,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8402451,motion capture;noise;denoising;noise reduction;character animation,Noise reduction;Animation;Quaternions;Software;Smoothing methods;Image processing;Standards,augmented reality;Gaussian noise;image denoising;motion estimation,noise reduction;motion capture data;NLM principle;body motion capture;image processing;virtual reality;nonlocal pose means principle;rotational skeletal movement;Gaussian noise,,,,27,,5-Jul-18,,,IEEE,IEEE Conferences
Adaptive interfaces for advanced airborne crew stations,L. J. Hettinger; J. D. Cress; B. J. Brickman; M. W. Haas,"Logicon Tech. Services Inc., Dayton, OH, USA; NA; NA; NA",Proceedings Third Annual Symposium on Human Interaction with Complex Systems. HICS'96,6-Aug-02,1996,,,188,192,"This paper discusses several general research and development issues that the authors view as critical to the design of adaptive interfaces for future US Air Force crew stations. Its major intent is to propose and describe three classes of variables and events that are considered to be potentially useful ""triggers"" for the introduction of functional adaptations to crew station displays and controls. These include the interdependent categories of external-environmental events, internal-physiological and behavioral events. This discussion describes an approach to the development of adaptive interfaces being pursued within the US Air Force Armstrong Laboratory's Human Engineering Division, and evaluated within the Synthesized Immersion Research Environment (SIRE) Facility. It is intended to stimulate discussion and debate on the nature of factors that might reasonably be expected to reliably drive the dynamic processes that can adapt interfaces in real time to enhance the human use of complex tactical aviation systems.",,0-8186-7493-8,10.1109/HUICS.1996.549514,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=549514,,Displays;Ergonomics;Control system synthesis;Humans;Research and development;Drives;Real time systems;Virtual environment;Force control;Control systems,human factors,adaptive interfaces;advanced airborne crew stations;research and development;user interface design;US Air Force crew stations;crew station displays;crew station controls;external-environmental events;internal-physiological events;behavioral events;Synthesized Immersion Research Environment Facility;SIRE Facility;real time systems;tactical aviation systems,,12,,12,,6-Aug-02,,,IEEE,IEEE Conferences
Buffer Based Adaptation Using Scalable Video Coding for 360-Degree Video Streaming over NDN,T. Ogasawara; M. Bandai,"Sophia University,Graduate School of Science and Technology,Tokyo,Japan,102-8554; Sophia University,Graduate School of Science and Technology,Tokyo,Japan,102-8554",2020 International Conference on Information Networking (ICOIN),2-Mar-20,2020,,,142,145,"360-degree video streaming is an important component of virtual reality. A video streaming server stores video streams with various quality levels. These streams are fragmented into several video segments. In 360-degree video streaming, these segments are tiled into video tiles. In general, the client changes the viewport quality level based on predictions of the user's viewport and network throughput. In named data networking (NDN), the throughput measured at the client is not always stable due to network-inherent caching. Therefore, the viewport video quality changes (referred to as quality switching) frequently in 360-degree video streaming over NDN. In this paper, we propose buffer-based adaptation using scalable video coding for 360-degree video streaming over NDN. In the proposed method, a buffer-based adaptation algorithm and the prefetching of video tiles are used to avoid video quality switching. A simple performance evaluation using computer simulations shows that the proposed method reduces the quality switching compared with that for a rate-based adaptation algorithm.",1976-7684,978-1-7281-4199-2,10.1109/ICOIN48656.2020.9016449,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9016449,360-degree video;streaming;named data networking (NDN),Streaming media;Prefetching;Switches;Servers;Static VAr compensators;Throughput;Video recording,buffer storage;image segmentation;Internet;video coding;video streaming;virtual reality,video tiles;video quality switching;scalable video coding;video streaming;video quality;NDN;named data networking,,,,11,,2-Mar-20,,,IEEE,IEEE Conferences
The impact of advanced e-clinical systems and IT-based technologies on medical practice at Saudi tertiary hospitals,D. M. Barakah; S. S. Alwakeel; M. M. Shira,"Registrar HI Dental Clinic Department King Saud Medical City, Riyadh, Saudi Arabia; Department of Computer Engineering, King Saud university Riyadh, Saudi Arabia; Consultant DDS Dental Clinic Department, King Saud Medical City, Riyadh, Saudi Arabia","2017 IEEE International Conference on Power, Control, Signals and Instrumentation Engineering (ICPCSI)",21-Jun-18,2017,,,178,184,"Studying the impact of advanced IT-based technologies and E-clinical systems on healthcare service is currently active area of research. This study main objective is to evaluate the medical staff proficiency and implementation of IT based technologies and instrumentation in medical research, education and clinical practice at Saudi General Tertiary Hospitals. The study was carried out at King Saud Medical City (KSMC) in Riyadh, Saudi Arabia. The research main data was collected predominantly using a cross-sectional survey questionnaire. The research results showed that an average overall rate of 61.68% of the participants' usage (sometimes, often, or always) of IT based technologies in clinical tasks. When comparing various clinical tasks, the highest average rate for IT usage was for continuing medical education task (65.9%). The lowest average rate for IT clinical task usage was for teaching interim resident (34.1%). With respect to adoption of IT for enhancing medical knowledge & education, the most used E-resource, was research databases and On line journals (40.4% reported using it), and the leased used was Virtual Reality and Simulations (17%). A relatively high percentage of participants (50.28% reported that all the survey questioned medical E-resources are unavailable to them in their work settings). For most adapted E-clinical systems, KSMC participants selected the CPOE system (53.2 % claimed using it often and always), while the least E-clinical system used was the LIMS system (19.1 %). Main results from this research showed that IT based technologies diffusion at King Saud medical city is very comparable to similar institutions in advanced countries. Furthermore, more advanced IT medical education resources (such as virtual reality systems, Web based multimedia ...etc.) are needed to overcome its limited availability, and to increase the diffusion of IT technologies in medical knowledge, education and daily practice.",,978-1-5386-0814-2,10.1109/ICPCSI.2017.8392058,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8392058,IT diffusion in clinical practice;E-Health Literacy;physicians' adoption of IT technologies;Saudi health System;King Saud Medical City,Task analysis;Hospitals;Urban areas;Education;Internet;Dentistry,biomedical education;health care;hospitals;medical computing;virtual reality,clinical tasks;continuing medical education task;clinical task usage;medical E-resources;adapted E-clinical systems;KSMC participants;CPOE system;E-clinical system;LIMS system;King Saud medical city;medical education resources;virtual reality systems;advanced e-clinical systems;medical practice;Saudi tertiary hospitals;healthcare service;medical staff proficiency;Saudi General Tertiary Hospitals;King Saud Medical City;Saudi Arabia,,1,,19,,21-Jun-18,,,IEEE,IEEE Conferences
Adaptive Precision-Enhancing Hand Rendering for Wearable Fingertip Tracking Devices,H. Park; J. -M. Park,"intern researcher at Korea Institute of Science and Technology (KIST),Seoul,Korea; Korea Institute of Science and Technology (KIST),Senior Research Scientist at the Center for Intelligent and Interactive Robotics,Seoul,Korea",2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),10-Feb-21,2020,,,11452,11457,"We introduce a 3D hand rendering framework to reconstruct a visually realistic hand from a set of fingertip positions. One of the key limitations of wearable fingertip tracking devices used in VR/AR applications is the lack of detailed measurements and tracking of the hand, making the hand rendering difficult. The motivation for this paper is to develop a general framework to render a visually plausible hand given only the fingertip positions. In addition, our framework adjusts the size of a virtual hand based on the fingertip positions and device's structure, and reduces a mismatch between the pose of the rendered and user's hand by retargeting virtual finger motions. Moreover, we impose a new hinge constraint on the finger model to employ a real-time inverse kinematic solver. We show our framework is helpful for performing virtual grasping tasks more efficiently when only the measurements of fingertip positions are available.",2153-0866,978-1-7281-6212-6,10.1109/IROS45743.2020.9341459,National Research Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9341459,,Performance evaluation;Three-dimensional displays;Tracking;Position measurement;Rendering (computer graphics);Real-time systems;Task analysis,control engineering computing;dexterous manipulators;force feedback;haptic interfaces;kinematics;rendering (computer graphics);virtual reality,adaptive precision-enhancing hand rendering;wearable fingertip tracking devices;visually realistic hand;fingertip positions;visually plausible hand;virtual hand;device,,,,29,,10-Feb-21,,,IEEE,IEEE Conferences
A programming interface for network resource management,E. Takahashi; P. Steenkiste; Jun Gao; A. Fisher,"Dept. of Electr. & Comput. Eng., Carnegie Mellon Univ., Pittsburgh, PA, USA; NA; NA; NA",1999 IEEE Second Conference on Open Architectures and Network Programming. Proceedings. OPENARCH '99 (Cat. No.99EX252),6-Aug-02,1999,,,34,44,"The deployment of advanced network services such as virtual reality games, distributed simulation, and video conferencing, will require sophisticated resource management support. The reason is that the quality of the delivered service will depend both on what resources are allocated to the user, and how these resources are managed at runtime. This problem is challenging because the definition of Quality of Service (QoS) is in general user specific, so hardwired resource management mechanisms will not be sufficient. To address the runtime resource management problem, we introduce the concept of a delegate, a code segment that applications or service providers inject into the network to assist in the management of the network resources that are allocated to them. This approach allows users to tailor runtime resource management to best meet their specific needs. Moreover, since delegates execute inside the network, they can easily collect information on changing network conditions, and can quickly adapt the resource allocations for the flows they are responsible for. Delegates have been implemented in the CMU Darwin system, which provides an integrated set of customizable resource management mechanisms in support of sophisticated network services. In this paper we present the design of the delegate runtime system, focusing on the programming interface that delegates use to monitor the network and modify resource use. We describe how delegates are supported in Darwin, and we show how delegates can be used to deal with a number of problems such as congestion control for video streaming, tracking down non-adaptive sources, and balancing traffic load.",,0-7803-5261-0,10.1109/OPNARC.1999.758432,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=758432,,Resource management;Runtime;Quality of service;Virtual reality;Games;Videoconference;Quality management;Monitoring;Streaming media;Telecommunication traffic,application program interfaces;resource allocation;virtual reality;quality of service,programming interface;network resource management;advanced network services;virtual reality games;distributed simulation;video conferencing;hardwired resource management mechanisms;runtime resource management problem;code segment;CMU Darwin system;customizable resource management mechanisms;congestion control;video streaming;traffic load,,11,3,36,,6-Aug-02,,,IEEE,IEEE Conferences
Gesture Controlled Virtual Reality Based Conferencing,K. Deherkar; G. Martin; N. George; V. Maurya,"Computer Engineering Department, Don Bosco Institute of Technology, Mumbai, India; Computer Engineering Department, Don Bosco Institute of Technology, Mumbai, India; Computer Engineering Department, Don Bosco Institute of Technology, Mumbai, India; Computer Engineering Department, Don Bosco Institute of Technology, Mumbai, India",2018 International Conference on Smart City and Emerging Technology (ICSCET),18-Nov-18,2018,,,1,4,"The technology available today for interacting with a virtual environment involves wired or wireless hand controls with limited buttons or a large setup involving a camera and/or a sensor to capture movements. The cost of such a setup is such that it makes it inaccessible to most. The project aims at providing a cost effective VR solution which can produce the same effect with precision and flexibility, which is accessible to all. The proposed idea is to provide a hardware device that provides the user with an immersive VR experience and uses hand gestures captured via a camera placed on the device to control and interact with the VR environment. As an application of the project, an interactive workspace environment would be simulated, using a single hardware component that provides the user the viewing interface as well as can be controlled by simple hand gestures eliminating the need for additional hand-held devices controls. The project will also delve into the field of supervised learning to make possible the implementation of gesture recognition.",,978-1-5386-1185-2,10.1109/ICSCET.2018.8537334,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8537334,Virtual Reality;VR;Gesture Recognition;Sensor;Hand Gesture Controls;VOIP;File transfer;Supervised learning,Tracking;Virtual environments;Cameras;Servers;Gesture recognition;Python,gesture recognition;human computer interaction;learning (artificial intelligence);virtual reality,virtual reality;virtual environment;wireless hand controls;cost effective VR solution;hardware device;immersive VR experience;VR environment;interactive workspace environment;single hardware component;gesture recognition;hand gestures;hand-held devices controls;gesture controlled virtual reality based conferencing;supervised learning,,,,20,,18-Nov-18,,,IEEE,IEEE Conferences
Non-minimum phase inverse filter methods for immersive audio rendering,A. Mouchtaris; P. Reveliotis; C. Kyriakakis,"Integrated Media Syst. Center, Univ. of Southern California, Los Angeles, CA, USA; NA; NA","1999 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings. ICASSP99 (Cat. No.99CH36258)",6-Aug-02,1999,6,,3077,3080 vol.6,"Immersive audio systems are being envisioned for applications that include teleconferencing and telepresence; augmented and virtual reality for manufacturing and entertainment; air traffic control, pilot warning, and guidance systems; displays for the visually-impaired; distance learning; and professional sound and picture editing for television and film. The principal function of such systems is to synthesize, manipulate and render sound fields in real time. In this paper we examine several signal processing considerations in spatial sound rendering over loudspeakers. We propose two methods that can be used to implement the necessary filters for generating virtual sound sources based on synthetic head-related transfer functions with the same spectral characteristics as those of the real source.",1520-6149,0-7803-5041-3,10.1109/ICASSP.1999.757491,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=757491,,Filters;Audio systems;Teleconferencing;Virtual reality;Manufacturing;Air traffic control;Auditory displays;Computer aided instruction;TV;Control system synthesis,filtering theory;inverse problems;audio signal processing;transfer functions;teleconferencing;audio systems;virtual reality;air traffic control;entertainment;distance learning;handicapped aids;loudspeakers;crosstalk;adaptive signal processing;adaptive filters;least mean squares methods,nonminimum phase inverse filter methods;immersive audio rendering;immersive audio systems;teleconferencing;telepresence;augmented reality;virtual reality;manufacturing;entertainment;air traffic control;pilot warning;guidance systems;displays;visually-impaired;distance learning;professional sound editing;professional picture editing;television;film;sound fields;signal processing;spatial sound rendering;loudspeakers;virtual sound sources;synthetic head-related transfer functions;spectral characteristics;real source;crosstalk cancellation;adaptive algorithm;LMS method,,5,,11,,6-Aug-02,,,IEEE,IEEE Conferences
The effects of olfaction on training transfer for an assembly task,A. G. Moore; N. S. Herrera; T. C. Hurst; R. P. McMahan; S. Poeschl,The FIVE Lab at the University of Texas at Dallas; The FIVE Lab at the University of Texas at Dallas; The FIVE Lab at the University of Texas at Dallas; The FIVE Lab at the University of Texas at Dallas; Ilmenau University of Technology,2015 IEEE Virtual Reality (VR),27-Aug-15,2015,,,237,238,"Context-dependent memory studies have indicated that olfaction, the sense of smell, has a special odor memory that can significantly improve recall in some cases. Virtual reality (VR), which has been investigated as a training tool, could feasibly benefit from odor memory by incorporating olfactory stimuli. There have been a few studies on this concept for semantic learning, but not for procedural training. To address this gap in knowledge, we investigated the effects of olfaction on the transfer of knowledge from training to next-day execution for building a complex LEGO jet-plane model. Our results indicate that the pleasantness of an odor significantly affects training transfer more than whether the encoding and recall contexts match.",2375-5334,978-1-4799-1727-3,10.1109/VR.2015.7223383,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223383,Olfactory fidelity;training transfer,Training;Olfactory;Encoding;Virtual environments;Semantics;Testing,chemioception;computer based training;virtual reality,assembly task;context-dependent memory;smell-sense;odor memory;recall improvement;virtual reality;VR;training tool;olfactory stimuli;semantic learning;knowledge transfer;complex LEGO jet-plane model;odor pleasantness;training transfer,,2,,13,,27-Aug-15,,,IEEE,IEEE Conferences
On-line simultaneous learning and recognition of everyday activities from virtual reality performances,T. Bates; K. Ramirez-Amaro; T. Inamura; G. Cheng,"Institute for Cognitive Systems, Technical University of Munich, Arcisstra√üe 21, 80333 Munich Germany; Institute for Cognitive Systems, Technical University of Munich, Arcisstra√üe 21, 80333 Munich Germany; National Institute of Informatics, 2 Chome-2-1-2 Hitotsubashi, Chiyodaku, Tokyo 100-0003, Japan; Institute for Cognitive Systems, Technical University of Munich, Arcisstra√üe 21, 80333 Munich Germany",2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),14-Dec-17,2017,,,3510,3515,"Capturing realistic human behaviors is essential to learn human models that can later be transferred to robots. Recent improvements in virtual reality (VR) head-mounted displays provide a viable way to collect natural examples of human behavior without the difficulties often associated with capturing performances in a physical environment. We present a realistic, cluttered, VR environment for experimentation with household tasks paired with a semantic extraction and reasoning system able to utilize data collected in real-time and apply ontology-based reasoning to learn and classify activities performed in VR. The system performs continuous segmentation of the motions of users' hands and simultaneously classifies known actions while learning new ones on demand. The system then constructs a graph of all related activities in the environment through its observations, extracting the task space utilized by observed users during their performance. The action recognition and learning system was able to maintain a high degree of accuracy of around 92% while dealing with a more complex and realistic environment compared to earlier work in both physical and virtual spaces.",2153-0866,978-1-5386-2682-5,10.1109/IROS.2017.8206193,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8206193,,Motion segmentation;Training;Cognition;Avatars;Semantics,helmet mounted displays;image recognition;learning (artificial intelligence);ontologies (artificial intelligence);virtual reality,virtual reality performances;realistic human behaviors;human models;robots;virtual reality head;human behavior;physical environment;VR environment;household tasks;semantic extraction;reasoning;continuous segmentation;task space;observed users;action recognition;learning system;complex environment;realistic environment;physical spaces;virtual spaces;on-line simultaneous learning,,10,,14,,14-Dec-17,,,IEEE,IEEE Conferences
Investigating the effect of immersive virtual reality and planning on the outcomes of simulation-based learning: A media and method experiment,J. Nie; B. Wu,"East China Normal University,Department of Educational Informational Technology,Shanghai,China; East China Normal University,Department of Educational Informational Technology,Shanghai,China",2020 IEEE 20th International Conference on Advanced Learning Technologies (ICALT),4-Aug-20,2020,,,329,332,"The application of the immersive virtual reality (VR) has injected new vitality into educational innovation, but there are also some voices of doubt on its practical learning effects. Considering two aspects of media and instructional methods, the study investigated the effect of immersive virtual reality and planning strategy on simulation-based learning by a 2 √ó 2 experimental cross - panel design. The results showed that both of them had a significant main effect, indicating that the immersive VR and planning led to better behavioral transfer performance and immersive VR increased sense of presence and self-efficacy as well. No interaction effect between media and method was found.",2161-377X,978-1-7281-6090-0,10.1109/ICALT49669.2020.00106,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155971,immersive virtual reality;planning strategy;virtual simulation;simulation-based learning,Xenon,computer aided instruction;virtual reality,immersive VR;interaction effect;immersive virtual reality;simulation-based learning;practical learning effects;2 √ó 2 experimental cross-panel design;educational innovation;planning strategy,,,,18,,4-Aug-20,,,IEEE,IEEE Conferences
The effects of presentation method and simulation fidelity on psychomotor education in a bimanual metrology training simulation,J. Bertrand; A. Bhargava; K. C. Madathil; A. Gramopadhye; S. V. Babu,"Clemson University, USA; Clemson University, USA; Clemson University, USA; Clemson University, USA; Clemson University, USA",2017 IEEE Symposium on 3D User Interfaces (3DUI),6-Apr-17,2017,,,59,68,"In this study, we empirically evaluated the effects of presentation method and simulation fidelity on task performance and psychomotor skills acquisition in an immersive bimanual simulation towards precision metrology education. In a 2 √ó 2 experiment design, we investigated a large-screen immersive display (LSID) with a head-mounted display (HMD), and the presence versus absence of gravity. Advantages of the HMD include interacting with the simulation in a more natural manner as compared to using a large-screen immersive display due to the similarities between the interactions afforded in the virtual compared to the real-world task. Suspending the laws of physics may have an effect on usability and in turn could affect learning outcomes. Our dependent variables consisted of a pre and post cognition questionnaire, quantitative performance measures, perceived workload and system usefulness, and a psychomotor assessment to measure to what extent transfer of learning took place from the virtual to the real world. Results indicate that the HMD condition was preferable to the immersive display in several metrics while the no-gravity condition resulted in users adopting strategies that were not advantageous for task performance.",,978-1-5090-6716-9,10.1109/3DUI.2017.7893318,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7893318,"H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems‚ÄîArtificial, augmented, and virtual realities",Solid modeling;Training;Aerospace electronics;Resists;Metrology;Visualization;Gravity,computer based training;digital simulation;helmet mounted displays;measurement;virtual reality,presentation method;simulation fidelity;psychomotor education;bimanual metrology training simulation;psychomotor skill acquisition;immersive bimanual simulation;precision metrology education;large-screen immersive display;LSID;head-mounted display;HMD;no-gravity condition,,3,,36,,6-Apr-17,,,IEEE,IEEE Conferences
‚ÄúWoodlands‚Äù - a Virtual Reality Serious Game Supporting Learning of Practical Road Safety Skills,K. Szczurowski; M. Smith,"Department of Informatics, Institute of Technology Blanchardstown, Dublin, Ireland; Department of Informatics, Institute of Technology Blanchardstown, Dublin, Ireland","2018 IEEE Games, Entertainment, Media Conference (GEM)",1-Nov-18,2018,,,1,9,"In developed societies road safety skills are taught early and often practiced under the supervision of a parent, providing children with a combination of theoretical and practical knowledge. At some point children will attempt to cross a road unsupervised, at that point in time their safety depends on the effectiveness of their road safety education. To date, various attempts to supplement road safety education with technology were made. Most common approach focus on addressing declarative knowledge, by delivering road safety theory in an engaging fashion. Apart from expanding on text based resources to include instructional videos and animations, some stakeholders (e.g.: Irish Road Safety Authority) attempt to take advantage of game-based learning [1]. However, despite the high capacity for interaction being common in Virtual Environments, available game-based solutions to road safety education are currently limited to delivering and assessing declarative knowledge. With recent advancements in the field of Virtual Reality (VR) Head Mounted Displays, procedural knowledge might also be addressed in Virtual Environments. This paper describes the design and development process of a computer-supported learning system that attempts to address psycho-motor skills involved in crossing a road safely, changing learners' attitude towards road safety best practices, and enabling independent practice of transferable skills. By implementing game-based learning principles and following best practice for serious game design (such as making educational components essential to successful game-play, or instructional scaffolding) we hope to make it not only more effective, but also engaging, allowing us to rely on learners' intrinsic motivation [2], to increase their independent practice time and provide them with feedback that will help to condition safe behaviour and increase retention. Presence in Virtual Reality might evoke responses to Virtual Environment as if it was real (RAIR) [3] and enable learners to truly experience learning scenarios. In consequence leading to formation of autobiographical memories constructed from multisensory input, which should result in an increased knowledge retention and transfer [4].",,978-1-5386-6304-2,10.1109/GEM.2018.8516493,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516493,Virtual Reality;VR;Road Safety;Serious Game;Experiential Learning;Game-Based Learning;Virtual Environment,Games;Road safety;Virtual environments;Training,computer aided instruction;helmet mounted displays;road safety;serious games (computing);virtual reality,road safety education;declarative knowledge;road safety theory;road safety best practices;serious game design;virtual reality serious game;virtual environment;virtual reality head mounted displays;Woodlands;game-based learning,,4,,34,,1-Nov-18,,,IEEE,IEEE Conferences
Object location memory error in virtual and real environments,M. Xu; M. Murcia-L√≥pez; A. Steed,"University College London, UK; University College London, UK; University College London, UK",2017 IEEE Virtual Reality (VR),6-Apr-17,2017,,,315,316,"We aim to further explore the transfer of spatial knowledge from virtual to real spaces. Based on previous research on spatial memory in immersive virtual reality (VR) we ran a study that looked at the effect of three locomotion techniques (joystick, pointing-and-teleporting and walking-in-place) on object location learning and recall. Participants were asked to learn the location of a virtual object in a virtual environment (VE). After a short period of time they were asked to recall the location by placing a real version of the object in the real-world equivalent environment. Results indicate that the average placement error, or distance between original and recalled object location, is approximately 20cm for all locomotion technique conditions. This result is similar to the outcome of a previous study on spatial memory in VEs that used real walking. We report this unexpected finding and suggest further work on spatial memory in VR by recommending the replication of this study in different environments and using objects with a wider diversity of properties, including varying sizes and shapes.",2375-5334,978-1-5090-6647-6,10.1109/VR.2017.7892303,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892303,"H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems ‚Äî Artificial, augmented, and Virtual Realities;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism ‚Äî Virtual Reality",Legged locomotion;Virtual environments;Navigation;Visualization;Standards,brain;human computer interaction;realistic images;virtual reality,object location memory error;virtual environment;real environment;spatial knowledge transfer;spatial memory;immersive virtual reality;locomotion technique;joystick;pointing-and-teleporting;walking-in-place;object location learning;object location recall;placement error,,3,,9,,6-Apr-17,,,IEEE,IEEE Conferences
Echo state transfer learning for data correlation aware resource allocation in wireless virtual reality,M. Chen; W. Saad; C. Yin; M. Debbah,"Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, China 100876; Wireless@VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, China 100876; Mathematical and Algorithmic Sciences Lab, Huawei France R&D, Paris, France","2017 51st Asilomar Conference on Signals, Systems, and Computers",16-Apr-18,2017,,,1852,1856,"In this paper, the problem of data correlation-aware resource management is studied for a network of wireless virtual reality (VR) users communicating over cloud-based small cell networks (SCNs). In the studied model, small base stations (SBSs) with limited computational resources act as VR control centers that collect the tracking information from VR users over the cellular uplink and send them to the VR users over the downlink. In such a setting, VR users may send or request correlated or similar data (panoramic images and tracking data). This potential spatial data correlation can be factored into the resource allocation problem to reduce the traffic load in both uplink and downlink. This VR resource allocation problem is formulated as a noncooperative game that allows jointly optimizing the computational and spectrum resources, while being cognizant of the data correlation. To solve this game, a transfer learning algorithm based on the machine learning framework of echo state networks (ESNs) is proposed. Unlike conventional reinforcement learning algorithms that must be executed each time the environment changes, the proposed algorithm can intelligently transfer information on the learned utility, across time, to rapidly adapt to environmental dynamics due to factors such as changes in the users' content or data correlation. Simulation results show that the proposed algorithm achieves up to 16.7% and 18.2% gains in terms of delay compared to the Q-learning with data correlation and Q-learning without data correlation. The results also show that the proposed algorithm has a faster convergence time than Q-learning and can guarantee low delays.",2576-2303,978-1-5386-1823-3,10.1109/ACSSC.2017.8335683,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8335683,,Correlation;Uplink;Delays;Wireless communication;Downlink;Resource management;Games,cellular radio;learning (artificial intelligence);optimisation;resource allocation;telecommunication computing;virtual reality,panoramic images;tracking data;potential spatial data correlation;VR resource allocation problem;computational spectrum resources;transfer learning algorithm;echo state networks;conventional reinforcement learning algorithms;echo state transfer learning;data correlation aware resource allocation;wireless virtual reality;data correlation-aware resource management;computational resources;VR control centers;VR users;similar data,,4,,12,,16-Apr-18,,,IEEE,IEEE Conferences
Research into Learning in an Intelligent Agent Augmented Multi-user Virtual Environment,M. J. Jacobson; C. Miao; B. Kim; Z. Shen; M. Chavez,"Univ. of Sydney, Sydney, NSW; Nanyang Technol. Univ., Nanyang; Nanyang Technol. Univ., Nanyang; Nanyang Technol. Univ., Nanyang; Nanyang Technol. Univ., Nanyang",2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology,6-Jan-09,2008,3,,348,351,This paper describes ongoing learning and intelligent agent research involving a new class of educational Interactive and Digital Media (IDM) that integrates computational intelligent agents with the functionality and affordances of 3D Multi-User Virtual Environment (MUVE). This research builds upon a proof-of-concept VIRTUAL SINGAPURA immersive learning environment project. Ongoing technical development work and planned learning research are described.,,978-0-7695-3496-1,10.1109/WIIAT.2008.402,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740795,multi-user virtual environments;intelligent agents;learning;science education,Intelligent agent;Virtual environment;Diseases;Competitive intelligence;Cognition;Cities and towns;Hospitals;Educational technology;Games;Knowledge transfer,computer aided instruction;multi-agent systems;virtual reality,educational learning;intelligent agent augmented multiuser virtual environment;Interactive and Digital Media;computational intelligent agents;3D MultiUser Virtual Environment;VIRTUAL SINGAPURA immersive learning environment project,,10,,24,,6-Jan-09,,,IEEE,IEEE Conferences
Extending a Virtual Reality Nasal Cavity Education Tool with Volume Rendering,M. Magdics; D. White; S. Marks,"Dept. of Control Eng. & Inf. Technol., Budapest Univ. of Technol. & Econ., Budapest, Hungary; Sch. of Eng. Comput. & Math. Sci., Auckland Univ. of Technol., Auckland, New Zealand; Fac. oj Design & Creative Technol., Auckland Univ. of Technol., Auckland, New Zealand","2018 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)",17-Jan-19,2018,,,811,814,"Answering the question whether virtual reality (VR), thanks to its ability to invoke real three-dimensional sensation in users, can improve the learning of spatial structures compared to traditional methods requires well-designed VR applications. We aim to investigate this question through a VR education tool that teaches the structure of the human nasal cavity. Our earlier studies suggested that an important feature of such VR education tools should be to give the context of the nasal cavity, i.e. visualize the rest of the anatomy of the head. In this paper, we discuss our approach of a VR learning application that achieves this using direct volume rendering.",2470-6698,978-1-5386-6522-0,10.1109/TALE.2018.8615248,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8615248,virtual reality;volume rendering;nasal cavity;education;learning,Rendering (computer graphics);Cavity resonators;Tools;Education;Magnetic resonance imaging;Transfer functions;Games,biology computing;computer aided instruction;rendering (computer graphics);virtual reality,VR education tool;human nasal cavity;VR learning application;virtual reality nasal cavity education tool;three-dimensional sensation;VR applications;direct volume rendering,,1,,13,,17-Jan-19,,,IEEE,IEEE Conferences
The role of dimensional symmetry on bimanual psychomotor skills education in immersive virtual environments,J. Bertrand; D. Brickler; S. Babu; K. Madathil; M. Zelaya; T. Wang; J. Wagner; A. Gramopadhye; J. Luo,Clemson University; Clemson University; Clemson University; Clemson University; Clemson University; Clemson University; Clemson University; Clemson University; Clemson University,2015 IEEE Virtual Reality (VR),27-Aug-15,2015,,,3,10,"The need for virtual reality applications for education and training involving bimanual dexterous activities has been increasing in recent years. However, it is unclear how the amount of correspondence between a virtual interaction metaphor to the real-world equivalent, otherwise known as dimensional symmetry, affects bimanual pscyhomotor skills training and how skills learned in the virtual simulation transfer to the real world. How does the number of degrees of freedom enhance or hinder the learning process? Does the increase in dimensional symmetry affect cognitive load? In an empirical evaluation, we compare the effectiveness of a natural 6-DOF interaction metaphor to a simplified 3-DOF metaphor. Our simulation interactively educates users in the step-by-step process of taking a precise measurement using calipers and micrometers in a simulated technical workbench environment. We conducted a usability study to evaluate the user experience and pedagogical benefits using measures including a pre and post cognition questionnaire over all levels of Bloom's taxonomy, workload assessment, system usability, and real world psychomotor assessment tasks. Results from the pre and post cognition questionnaires suggest that learning outcomes improved throughout all levels of Bloom's taxonomy for both conditions, and trends in the data suggest that the 6-DOF metaphor was more effective in real-world skill transference compared to the 3-DOF metaphor.",2375-5334,978-1-4799-1727-3,10.1109/VR.2015.7223317,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223317,Bimanual interaction;psychomotor skills education;dimensional symmetry,Atmospheric measurements;Particle measurements;Instruments;Training;Metrology;Solid modeling,computer aided instruction;user interfaces;virtual reality,dimensional symmetry role;bimanual psychomotor skills education;immersive virtual environment;virtual reality applications;education application;training application;virtual simulation;learning process;cognitive load;natural 6-DOF interaction;degrees-of-freedom;calipers;micrometers;user experience;pedagogical benefits;psychomotor assessment tasks;Bloom taxonomy;bimanual dexterous activities,,9,,27,,27-Aug-15,,,IEEE,IEEE Conferences
"Impact of World Wide Web, Java, and virtual environments on education in computational science and engineering",T. Singh; M. Zhu; U. Thakkar; U. Ravaioli,"Beckman Inst. for Adv. Sci. & Technol., Illinois Univ., Urbana, IL, USA; NA; NA; NA",Technology-Based Re-Engineering Engineering Education Proceedings of Frontiers in Education FIE'96 26th Annual Conference,6-Aug-02,1996,3,,1007,1010 vol.3,"The World Wide Web (WWW) on the Internet has been recognized as an effective environment to create new distributed applications that have the potential to bring instruction beyond the bounds of the classroom. The availability of browsers (e.g. Mosaic, Netscape, Hot Java) has enormously simplified the access to the WWW, and there have been numerous initiatives to take advantage of this new technology for teaching. This work will illustrate recent developments of tools for engineering education and technology transfer which take advantage of WWW browsers, Java applets, and virtual reality. We have developed modules based on WWW browsers incorporating educational and research software, including advanced visualization, which find use for multimedia classroom presentations accessible by Internet users, and which can also improve interaction among academic groups and industry. Therefore, the material is suitable for asynchronous distance learning and technology transfer. Examples of interactive WWW applications include device simulation, semiconductor band structure calculation, numerical techniques, and electromagnetics.",0190-5848,0-7803-3348-9,10.1109/FIE.1996.567665,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=567665,,Web sites;Java;Virtual environment;World Wide Web;Internet;Technology transfer;Engineering education;Virtual reality;Visualization;Computer industry,Internet;engineering education;virtual reality;technology transfer;multimedia systems;computer science education,World Wide Web;Java;virtual environments;computational science education;engineering education;Internet;browsers;Mosaic;Netscape;teaching;technology transfer;virtual reality;educational and research software;multimedia classroom presentations;asynchronous distance learning;device simulation;semiconductor band structure calculation;numerical techniques;electromagnetics,,,1,5,,6-Aug-02,,,IEEE,IEEE Conferences
Virtual Training: Learning Transfer of Assembly Tasks,P. Carlson; A. Peters; S. B. Gilbert; J. M. Vance; A. Luse,"Department of Human-Computer Interaction (HCI), Iowa State University, Ames, IA; Department of Human-Computer Interaction (HCI), Iowa State University, Ames, IA; Department of Industrial and Manufacturing Systems Engineering, Iowa State University, Ames, IA; Department of Mechanical Engineering, Iowa State University, Ames, IA; Department of Management Science and Information Systems, Oklahoma State University, Stillwater, OK",IEEE Transactions on Visualization and Computer Graphics,29-Apr-15,2015,21,6,770,782,"In training assembly workers in a factory, there are often barriers such as cost and lost productivity due to shutdown. The use of virtual reality (VR) training has the potential to reduce these costs. This research compares virtual bimanual haptic training versus traditional physical training and the effectiveness for learning transfer. In a mixed experimental design, participants were assigned to either virtual or physical training and trained by assembling a wooden burr puzzle as many times as possible during a twenty minute time period. After training, participants were tested using the physical puzzle and were retested again after two weeks. All participants were trained using brightly colored puzzle pieces. To examine the effect of color, testing involved the assembly of colored physical parts and natural wood colored physical pieces. Spatial ability as measured using a mental rotation test, was shown to correlate with the number of assemblies they were able to complete in the training. While physical training outperformed virtual training, after two weeks the virtually trained participants actually improved their test assembly times. The results suggest that the color of the puzzle pieces helped the virtually trained participants in remembering the assembly process.",1941-0506,,10.1109/TVCG.2015.2393871,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7014246,learning transfer;haptics;assembly;Learning transfer;Haptics;virtual reality;assembly;training,Training;Assembly;Virtual environments;Color;Haptic interfaces;Testing;Educational institutions,computer based training;virtual reality,virtual training;learning transfer;assembly tasks;assembly worker training;virtual reality;virtual bimanual haptic training;physical training;wooden burr puzzle;physical puzzle;colored physical parts;natural wood colored physical pieces;spatial ability;mental rotation;puzzle pieces;virtually trained participants;assembly process,,34,,56,,19-Jan-15,,,IEEE,IEEE Journals
Conditions that Facilitate Transfer of Learning in Virtual Environment,C. Bossard; G. Kermarrec,"European Center for virtual reality, BP 38, F-29280 Plouzan√©, France, Tel: 02 98 05 89 89 ; fax: 02 98 05 89 79. E-mail: bossard@enib.fr; LISyC, Eur. Center for Virtual Reality, Plouzane",2006 2nd International Conference on Information & Communication Technologies,16-Oct-06,2006,1,,604,609,"The aim of all education is to apply what we learn in different contexts, to recognize and to extend such learning to new situations. Particularly, virtual environments for learning are used to construct competences. Researches in cognitive psychology and education show acquisitions as linked to initial context. It provides a challenge for virtual reality in education or training. This paper discusses how new perspectives in cognitive psychology influence and promote conditions that facilitate transfer of learning by the use of virtual environment",,0-7803-9521-2,10.1109/ICTTA.2006.1684440,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1684440,,Virtual environment;Psychology;Management training;Virtual reality;Computer science education;Employment;Knowledge management;Computer simulation;Mathematics;Problem-solving,computer aided instruction;psychology;virtual reality,learning transfer;virtual reality;education;training;cognitive psychology,,1,,36,,16-Oct-06,,,IEEE,IEEE Conferences
Transfer of a skilled motor learning task between virtual and conventional environments,J. Anglin; D. Saldana; A. Schmiesing; S. Liew,"University of Southern California, Los Angeles, California, United States of America; University of Southern California, Los Angeles, California, United States of America; University of Southern California, Los Angeles, California, United States of America; University of Southern California, Los Angeles, California, United States of America",2017 IEEE Virtual Reality (VR),6-Apr-17,2017,,,401,402,"Immersive, head-mounted virtual reality (HMD-VR) can be a potentially useful tool for motor rehabilitation. However, it is unclear whether the motor skills learned in HMD-VR transfer to the non-virtual world and vice-versa. Here we used a well-established test of skilled motor learning, the Sequential Visual Isometric Pinch Task (SVIPT), to train individuals in either an HMD-VR or conventional training (CT) environment. Participants were then tested in both environments. Our results show that participants who train in the CT environment have an improvement in motor performance when they transfer to the HMD-VR environment. In contrast, participants who train in the HMD-VR environment show a decrease in skill level when transferring to the CT environment. This has implications for how training in HMD-VR and CT may affect performance in different environments.",2375-5334,978-1-5090-6647-6,10.1109/VR.2017.7892346,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892346,Virtual reality;skilled motor learning;transfer,Training;Logic gates;Virtual reality;Computed tomography;Electroencephalography;Visualization;Indexes,medical computing;patient rehabilitation;virtual reality,skilled motor learning task;virtual environments;head-mounted virtual reality;HMD-VR;motor rehabilitation;sequential visual isometric pinch task;SVIPT;conventional training environment;CT environment,,8,,4,,6-Apr-17,,,IEEE,IEEE Conferences
Approach on a new methodology for skills transfer using a parallel planar robot with visuo-vibrotactile feedback,P. Humblot-Ni√±o; O. Sandoval-Gonz√°lez; I. Herrera-Aguilar; D. Rangel-Pe√±uelas; A. Flores-Cuautle; B. Gonz√°lez-S√°nchez,"Divisi√≥n de Estudios de Posgrado e Investigaci√≥n, Instituto Tecnol√≥gico de Orizaba, Orizaba, M√©xico; Divisi√≥n de Estudios de Posgrado e Investigaci√≥n, Instituto Tecnol√≥gico de Orizaba, Orizaba, M√©xico; Divisi√≥n de Estudios de Posgrado e Investigaci√≥n, Instituto Tecnol√≥gico de Orizaba, Orizaba, M√©xico; Divisi√≥n de Estudios de Posgrado e Investigaci√≥n, Instituto Tecnol√≥gico de Orizaba, Orizaba, M√©xico; CONACYT - Divisi√≥n de Estudios de Posgrado e Investigaci√≥n, Instituto Tecnol√≥gico de Orizaba, Orizaba, M√©xico; Divisi√≥n de Estudios de Posgrado e Investigaci√≥n, Instituto Tecnol√≥gico de Orizaba, Orizaba, M√©xico","2017 14th International Conference on Electrical Engineering, Computing Science and Automatic Control (CCE)",16-Nov-17,2017,,,1,5,"An approach of a new methodology for skills transfer from machine to human is proposed in this research. This methodology transmits a haptic feed-back using vibrotactile perception to transfer motor skills using a parallel planar robot and virtual reality environments. During the experimentation, the participants tried to learn a specific motion trajectory given by the system. During the process, the system computes the current position and generates a vibrotactile feed-back proportional to the error computed between the actual and the desired position of the motion trajectory. The results of the user studies showed this system can help with learning new skills.",,978-1-5386-3406-6,10.1109/ICEEE.2017.8108861,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8108861,Skill Transfer;Parallel Planar Robot;Methodology,Haptic interfaces;Virtual environments;Robot sensing systems;Training;End effectors;Trajectory,feedback;haptic interfaces;human computer interaction;human-robot interaction;position control;virtual reality,haptic feedback;motion trajectory;visuo-vibrotactile feedback;virtual reality environments;parallel planar robot;motor skills;vibrotactile perception;skills transfer,,,,16,,16-Nov-17,,,IEEE,IEEE Conferences
Implement Multi-Character Display in Virtual Reality Environment Based on Unet and Tracker,Y. Zou; P. Wang; Q. Tang; Y. Sun,"Zunyi Power Supply Bureau,Safety Supervision Department,Zunyi,Guizhou,China; Zunyi Power Supply Bureau,Safety Supervision Department,Zunyi,Guizhou,China; Zunyi Power Supply Bureau,Safety Supervision Department,Zunyi,Guizhou,China; Zunyi Power Supply Bureau,Safety Supervision Department,Zunyi,Guizhou,China",2019 2nd International Conference on Safety Produce Informatization (IICSPI),19-May-20,2019,,,530,532,"Power grid operation is a very safe operation site, it is very important to be able to carry out related operations in accordance with the safe operation process, the existing traditional safe operation process, mainly in the traditional teaching mode or simulated real scene operation mode. In the links of management and training, operators lack intuitive experience and interaction, and they are not enough to show the serious consequences of illegal operation; As the head-mounted display becomes the most important interactive virtual reality display device, the 3d interactive display and the expressive force of the game engine are gradually improved, significantly improving participants' sense of immersion. Virtual reality technology can be used to build a simulation teaching platform for authentic visual experience, authentic representation of work flow and convincing interactive feedback. Virtual reality technology is used to establish a practical environment for grid operation in the virtual three-dimensional space of the computer that integrates class a illegal operation events. Users participating in the learning practice can operate in the virtual space according to the process. In this paper, based on unity built-in HAPI unet and third-party plug-in VRTK, the complex interaction of large-scale training business process is realized. Through VRTK, steam VR interface, the handle button state is obtained and information is transmitted on multiple instances, so as to determine the transfer and pickup state of interactive objects.",,978-1-7281-4566-2,10.1109/IICSPI48186.2019.9096025,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9096025,Multiplayer networking technology;Virtual reality technology;Multiplayer online interaction;Inverse dynamics,Games;Training;Servers;Virtual reality;Synchronization;Production;Safety,helmet mounted displays;interactive systems;power engineering computing;power grids;user interfaces;virtual reality,virtual reality environment;power grid operation;head-mounted display;virtual reality technology;simulation teaching platform;interactive feedback;large-scale training business process;interactive virtual reality display device;3D interactive display;multicharacter display;Unet;Tracker;VR interface;VRTK,,,,8,,19-May-20,,,IEEE,IEEE Conferences
PhD Forum: Strengthening Social Emotional Skills for Individuals with Developmental Disabilities Through Virtual Reality Games,T. Thang,"Comput. Media, Univ. of California, Santa Cruz, Santa Cruz, CA, USA",2018 IEEE International Conference on Smart Computing (SMARTCOMP),30-Jul-18,2018,,,242,243,"Defining qualities of developmental disabilities include deficits in social-emotional skills, especially with respect to emotion recognition. This study aims to assist adults with developmental disabilities in strengthening emotion recognition skills through the research and development of virtual reality games to increase accessibility to life-changing therapies. Work previously accomplished in this study includes the development of EmotionVR, a virtual reality game created for the HTC Vive. EmotionVR takes traditional methods of therapy aimed at teaching emotion recognition and translates it into an interesting and interactive narrative that provides users the opportunity to learn and practice emotion recognition in realistic settings. This work observed and analyzed the interaction between adults with developmental disabilities, and the HTC Vive and virtual environments. While the game supports the idea that virtual reality is a feasible method of providing such therapies, users found some discomfort with using the HTC Vive, and had slight difficulty translating what they had learned from the game in different situational contexts. To resolve those issues, we investigate interactions between adults with developmental disabilities and other virtual reality systems, and develop a 360 video based virtual reality game to assist with transfer of skills.",,978-1-5386-4705-9,10.1109/SMARTCOMP.2018.00061,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8421355,assistive technology;virtual reality;human computer interaction;developmental disabilities,Conferences,computer aided instruction;computer games;emotion recognition;handicapped aids;teaching;virtual reality,social-emotional skills;adults;developmental disabilities;emotion recognition skills;HTC Vive;virtual reality systems;EmotionVR;teaching;interactive narrative;virtual environments;video based virtual reality game,,,,9,,30-Jul-18,,,IEEE,IEEE Conferences
Virtual Reality Instruction Followed by Enactment Can Increase Procedural Knowledge in a Science Lesson,N. K. Andreasen; S. Baceviciute; P. Pande; G. Makransky,Aalborg University; University of Copenhagen; Roskilde University; Aalborg University,2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,840,841,"A 2√ó2 between-subjects experiment (a) investigated and compared the instructional effectiveness of immersive virtual reality (VR) versus video as media for teaching scientific procedural knowledge, and (b) examined the efficacy of enactment as a generative learning strategy in combination with the respective instructional media. A total of 117 high school students (74 females) were randomly distributed across four instructional groups - VR and enactment, video and enactment, only VR, and only video. Outcome measures included declarative knowledge, procedural knowledge, knowledge transfer, and subjective ratings of perceived enjoyment. Results indicated that there were no main effects or interactions for the outcomes of declarative knowledge or transfer. However, there was a significant interaction between media and method for the outcome of procedural knowledge with the VR and enactment group having the highest performance. Furthermore, media also seemed to have a significant effect on student perceived enjoyment, indicating that the groups enjoyed the VR simulation significantly more than the video. The results deepen our understanding of how we learn with immersive technology, as well as suggest important implications for implementing VR in schools.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8797755,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797755,Virtual Reality;generative learning strategy;enactment;learning;procedural knowledge,Media;Biological system modeling;Virtual reality;Education;Solid modeling;Psychology;Knowledge transfer,computer aided instruction;teaching;virtual reality,generative learning strategy;instructional groups;declarative knowledge;knowledge transfer;student perceived enjoyment;VR simulation;immersive virtual reality;instructional media;high school students;virtual reality instruction;scientific procedural knowledge teaching;science lesson,,,,9,,15-Aug-19,,,IEEE,IEEE Conferences
Improving wheelchair driving performance in a virtual reality simulator,P. S. Archambault; C. Bigras,"McGill University,School of Physical and Occupational Therapy,Montreal,Canada; McGill University,School of Physical and Occupational Therapy,Montreal,Canada",2019 International Conference on Virtual Rehabilitation (ICVR),13-Feb-20,2019,,,1,2,"In this study, we measured if practice of a wheelchair activity in a virtual reality simulator (entering an elevator) improved wheelchair positioning skills in na√Øve, healthy adults. Performance was assessed immediately after practice, two days later (retention) and in a real-world equivalent task (transfer). The influence of augmented feedback on retention and transfer was also assessed. Forty participants were randomized to either an augmented feedback group (who received information on collisions and on task completion time) and a no-feedback group. Following training, both groups improved their wheelchair positioning abilities. Learning was maintained at retention and skills transferred to the real-world wheelchair. Augmented feedback did not procure any additional effects. Practice in a virtual reality simulator significantly improved wheelchair positioning skills. Higher performance gains could be achieved by providing task-specific feedback.",2331-9569,978-1-7281-1285-5,10.1109/ICVR46560.2019.8994644,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994644,power wheelchair;simulator;performance;learning;transfer,,computer simulation;feedback;handicapped aids;virtual reality;wheelchairs,no-feedback group;wheelchair positioning abilities;virtual reality simulator;task-specific feedback;wheelchair activity;augmented feedback group;wheelchair positioning skills;wheelchair driving performance,,,,8,,13-Feb-20,,,IEEE,IEEE Conferences
Research on 10kV Line Breaker Check Training System Based on Virtual Reality,X. Xu; L. Shen; S. Li; S. Wang,Shibei Power Supply Company of SMEPC; Shibei Power Supply Company of SMEPC; Shibei Power Supply Company of SMEPC; Shibei Power Supply Company of SMEPC,2019 International Conference on Smart Grid and Electrical Automation (ICSGEA),14-Nov-19,2019,,,18,21,"The training is the important means to improve power system operators' quality and ensure the safe, stable and reliable operation of power system. The job of 10kV line breaker check is one of the most important tasks of relay protection, and the training effect of this job is directly related to the work efficiency and quality of relay protection employees. However, in the training for relay protection trainees, it is impossible to carry out the actual operation in the substation considering the safety factor, and the construction of simulated substation costs a lot. To solve this problem, this paper uses Unity to develop a 10kV line breaker check training system based on virtual reality (VR). The training system development tools, 10kV line breaker check project, the training system structure and function design are introduced in the paper. Practical application shows that the training system is simple to use, easy to learn, can timely and quickly transfer data and results, which has achieved a good training effect.",,978-1-7281-4463-4,10.1109/ICSGEA.2019.00013,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8901373,10kV line breaker check;relay protection;virtual reality,,circuit breakers;computer based training;power engineering computing;power engineering education;power supply quality;power system reliability;power system stability;relay protection;virtual reality,safe operation;stable operation;relay protection employees;relay protection trainees;virtual reality;training system development tools;training system structure;function design;training effect;power system operators;line breaker check project;voltage 10.0 kV,,,,11,,14-Nov-19,,,IEEE,IEEE Conferences
Immersive virtual environments for tacit knowledge transfer focusing on gestures: A workflow,H. Esmaeili; H. Thwaites; P. C. Woods,"Centre for Research-Creation in Digital Media, School of Arts, Sunway University, Malaysia; Centre for Research-Creation in Digital Media, School of Arts, Sunway University, Malaysia; Faculty of Creative Multimedia, Multimedia University, Malaysia",2017 23rd International Conference on Virtual System & Multimedia (VSMM),26-Apr-18,2017,,,1,6,"This study presents a workflow for creating immersive virtual environments for tacit knowledge transfer. The main focus is on gestures, which are related to skill, performance, or physical emotion (not facial) e.g. sports, martial arts, playing instruments, acting, etc. The initial idea behind this design is to provide a virtual practice environment mainly for actors in order to learn new gestures or moves. However, this virtual environment can also be used by many other target audiences based on their needs. Sometimes, ambiguity is part of knowledge transfer and becomes more salient or critical when it comes to tacit knowledge, especially at early stages of transfer. Performance while maintaining believable gesture is a must have requirement for actors. Visual references (mainly video in absence of trainer) are commonly used by actors in order to learn specific moves or gestures. However, videos are limited to 2D screen view (even if stereoscopic or 360¬∞) and do not provide chance of studying a freezing moment from all angles, simultaneously. Although this can be partly mimicked using multi-camera rig, it is still limited to the number of shots taken and only provides a linear frame sequence (mostly used as VFX). Immersive virtual environments not only eliminate this limitation but also provide one to one scale experience. In this study, the process of creating such environment is discussed in detail. This includes planning, concept design, selecting tools, establishing the environment, properly selecting or creating the virtual character(s), capturing the motion or using existing ones from different Mocap libraries, actor's interaction with VR equipment, user experience, etc. In addition to studying reference moves and gestures (frame by frame and from any angle), the user is able to observe his/her performance in VR. This can be achieved using motion capture cameras installed at the practice location. The captured content is later assigned to the user's virtual representative i.e. a 3d character created based on his/her physical body features for side by side analysis with the reference. This provides countless interaction possibilities that cannot be achieved in the real world. Few examples are: multiplying the reference character and freeze two or more different moments (frames) and create a walkthrough, creating an immersive timeline based on the actor's progress (also requires multiplying), assigning reference moves to the user's avatar to be compared with his/her movements by himself/herself or anyone else (different from side by side comparison with the reference character), and many others. What has been discussed above is fully illustrated and described in this paper including detailed figures. The contribution of this study can be extended to various fields from acting and sport to stop motion and creative art, as the processes presented in the paper are designed in the most affordable way, using hardware and software currently available to basic users.",2474-1485,978-1-5386-4494-2,10.1109/VSMM.2017.8346255,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8346255,immersive virtual environments;immersive virtual reality;tacit knowledge transfer;gesture;virtual reality;mocap;learning in virtual reality;htc vive;oculus rift;unity;steam vr,Teleportation;Knowledge transfer;Observers;Virtual environments;Art;Tools;Three-dimensional displays,gesture recognition;virtual reality,reference character;reference moves;immersive virtual environments;tacit knowledge transfer;virtual practice environment;believable gesture;virtual character;virtual representative,,1,,10,,26-Apr-18,,,IEEE,IEEE Conferences
Teaching a Robot to Grasp Real Fish by Imitation Learning from a Human Supervisor in Virtual Reality,J. S. Dyrstad; E. Ruud √òye; A. Stahl; J. Reidar Mathiassen,"SINTEF Ocean AS, Trondheim, Norway; SINTEF Ocean AS, Trondheim, Norway; Department of Engineering Cybernetics, NTNU, Trondheim, Norway; SINTEF Ocean AS, Trondheim, Norway",2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),6-Jan-19,2018,,,7185,7192,"We teach a real robot to grasp real fish, by training a virtual robot exclusively in virtual reality. Our approach implements robot imitation learning from a human supervisor in virtual reality. A deep 3D convolutional neural network computes grasps from a 3D occupancy grid obtained from depth imaging at multiple viewpoints. In virtual reality, a human supervisor can easily and intuitively demonstrate examples of how to grasp an object, such as a fish. From a few dozen of these demonstrations, we use domain randomization to generate a large synthetic training data set consisting of 100 000 example grasps of fish. Using this data set for training purposes, the network is able to guide a real robot and gripper to grasp real fish with good success rates. The newly proposed domain randomization approach constitutes the first step in how to efficiently perform robot imitation learning from a human supervisor in virtual reality in a way that transfers well to the real world.",2153-0866,978-1-5386-8094-0,10.1109/IROS.2018.8593954,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593954,,Robots;Task analysis;Three-dimensional displays;Grippers;Grasping;Cameras;Virtual reality,convolutional neural nets;grippers;learning (artificial intelligence);mobile robots;pose estimation;virtual reality,teaching;gripper;domain randomization approach;depth imaging;3D occupancy grid;robot imitation learning;deep 3D convolutional neural network;virtual robot;grasp real fish;virtual reality;human supervisor,,2,,19,,6-Jan-19,,,IEEE,IEEE Conferences
Liquid State Based Transfer Learning for 360¬∞ Image Transmission in Wireless VR Networks,M. Chen; W. Saad; C. Yin,"Beijing Key Lab. of Network Syst. Archit. & Convergence, Beijing Univ. of Posts & Telecommun., Beijing, China; Bradley Dept. of Electr. & Comput. Eng., Virginia Tech, Blacksburg, VA, USA; Beijing Key Lab. of Network Syst. Archit. & Convergence, Beijing Univ. of Posts & Telecommun., Beijing, China",ICC 2019 - 2019 IEEE International Conference on Communications (ICC),15-Jul-19,2019,,,1,6,"In this paper, the problem of 360¬∞ image transmission is studied for a wireless network of virtual reality (VR) users that communicate with cellular base stations (BSs). The VR users will send their uplink tracking information to the BS and receive the VR images in the downlink. To satisfy VR users' delay target, the BSs can change the image transmission format for each image requested by users so as to reduce the downlink traffic load. Meanwhile, the VR users can directly rotate the already received VR image and use the rotated VR images at a later time to further reduce the downlink traffic load. This 360¬∞ image transmission and image rotation problem is then formulated as an optimization problem whose goal is to maximize the users' successful transmission probability which is defined as the probability that the delay of tracking information and image transmission for each VR user satisfies the VR delay requirement. A liquid state machine (LSM) based transfer learning algorithm is proposed to solve this optimization problem. The proposed LSM-baseda transfer learning algorithm enables each BS to transfer the already learned successful transmission to the new successful transmission that must be learned so as to increase the convergence speed. Simulation results show that the proposed algorithm achieves 14.9% gain in terms of successful transmission probability compared to Q-learning.",1938-1883,978-1-5386-8088-9,10.1109/ICC.2019.8761494,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8761494,,Image communication;Wireless communication;Delays;Downlink;Standards;Liquids;Optimization,optimisation;probability;radio networks;telecommunication traffic;virtual reality,VR delay requirement;learned successful transmission;wireless VR networks;virtual reality users;downlink traffic load;received VR image;rotated VR images;image rotation problem;image transmission;liquid state based transfer learning,,2,,15,,15-Jul-19,,,IEEE,IEEE Conferences
VREX: Virtual reality education expansion could help to improve the class experience (VREX platform and community for VR based education),L. Ying; Z. Jiong; S. Wei; W. Jingchun; G. Xiaopeng,"School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; Dept. for Cyber Online Popularization of Science, Chinese Science and Technology Museum, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China",2017 IEEE Frontiers in Education Conference (FIE),14-Dec-17,2017,,,1,5,"This paper proposed an innovative education platform-VREX (Virtual Reality based Education eXpansion), with combination of online and offline, to improve the curriculum building and teaching experience. VREX is based on Virtual Reality (VR) and we believe VR can revolutionize the education ecosystem. With some trials, we found VR can be used to promote curriculum effectiveness in an immersive environment so that students can have intuitive sense to understand some abstract knowledge, which is always hard for teachers to describe. We have tried to transfer slides into VR scenes, for the students to learn knowledge in a rather real but totally virtual world. The main contributions were made: (1) VREX build an open and immersion virtual O2O classroom with internet and VR devices so that real classrooms might be used in a different way in the future. (2) VREX provides a distributed mode for students to experience an interactive learning process at anytime, anywhere and any-frequency. (3) VREX can be used to support education in different disciplines, from K-12 to Universities, and we provided some practical cases, like `Marine Life' to show creatures in deep sea, which provides immersive experience to makes students feel they were there. Finally, the feasibility and advantage of VREX are proved by the actual statistical data in the 3rd season 2017.",,978-1-5090-5920-1,10.1109/FIE.2017.8190660,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8190660,Virtual Reality;Immersion;Interaction;Virtual classroom;VR Cloud Platform,Cloud computing;Games;Computer architecture;Hardware;Courseware;Training,computer aided instruction;educational courses;interactive systems;Internet;teaching;virtual reality,immersive experience;virtual reality education expansion;VR based education;innovative education platform-VREX;curriculum building;teaching experience;education ecosystem;VR scenes;immersion virtual O2O classroom;class experience improvement;VREX platform;open virtual O2O classroom;interactive learning process,,5,,10,,14-Dec-17,,,IEEE,IEEE Conferences
Assistive VR Gym: Interactions with Real People to Improve Virtual Assistive Robots,Z. Erickson; Y. Gu; C. C. Kemp,"Georgia Institute of Technology,Health-care Robotics Lab,Atlanta,GA,USA; Georgia Institute of Technology,Health-care Robotics Lab,Atlanta,GA,USA; Georgia Institute of Technology,Health-care Robotics Lab,Atlanta,GA,USA",2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),14-Oct-20,2020,,,299,306,"Versatile robotic caregivers could benefit millions of people worldwide, including older adults and people with disabilities. Recent work has explored how robotic caregivers can learn to interact with people through physics simulations, yet transferring what has been learned to real robots remains challenging. Virtual reality (VR) has the potential to help bridge the gap between simulations and the real world. We present Assistive VR Gym (AVR Gym), which enables real people to interact with virtual assistive robots. We also provide evidence that AVR Gym can help researchers improve the performance of simulation-trained assistive robots with real people. Prior to AVR Gym, we trained robot control policies (Original Policies) solely in simulation for four robotic caregiving tasks (robot-assisted feeding, drinking, itch scratching, and bed bathing) with two simulated robots (PR2 from Willow Garage and Jaco from Kinova). With AVR Gym, we developed Revised Policies based on insights gained from testing the Original policies with real people. Through a formal study with eight participants in AVR Gym, we found that the Original policies performed poorly, the Revised policies performed significantly better, and that improvements to the biomechanical models used to train the Revised policies resulted in simulated people that better match real participants. Notably, participants significantly dis-agreed that the Original policies were successful at assistance, but significantly agreed that the Revised policies were successful at assistance. Overall, our results suggest that VR can be used to improve the performance of simulation-trained control policies with real people without putting people at risk, thereby serving as a valuable stepping stone to real robotic assistance.",1944-9437,978-1-7281-6075-7,10.1109/RO-MAN47096.2020.9223609,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9223609,,,biomechanics;geriatrics;handicapped aids;humanoid robots;learning (artificial intelligence);medical computing;medical robotics;mobile robots;virtual reality,simulated robots;simulated people;simulation-trained control policies;robotic assistance;virtual assistive robots;versatile robotic caregivers;physics simulations;simulation-trained assistive robots;robot control policies;robotic caregiving tasks;drinking;assistive VR gym;revised policies;AVR gym,,,,48,,14-Oct-20,,,IEEE,IEEE Conferences
Learning about renewables using VRML-technology,A. N. Angelov; J. Haubrock; B. Hadzi-Kostova; Z. Styczynski; P. Schweizer-Ries,"Ottovon-Guericke-University Magdeburg, Germany; Ottovon-Guericke-University Magdeburg, Germany; Ottovon-Guericke-University Magdeburg, Germany; Ottovon-Guericke-University Magdeburg, Germany; Ottovon-Guericke-University Magdeburg, Germany",2005 IEEE Russia Power Tech,16-May-08,2005,,,1,5,"This paper presents the implementation of different learning possibilities and the mixing of traditional evaluated learning programs with hypermedia systems in the area of renewable energy sources. Virtual Reality Modelling Language (VRML) has developed a standard for characterizing three dimensional objects which are particularly for transfer to the internet, and it is feasible in any e-learning concept. The interactive three dimensional representation allows online development and utilization of three dimensional environments and deeper contact, better than any drawing or written description. The goal of integrating complex three dimensional models into modern education is to increase the motivation of the students.",,978-5-93208-034-4,10.1109/PTC.2005.4524508,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4524508,electrical engineering;learning scenarios;virtual seminar;VRML;blended learning,Fuel cells;Renewable energy resources;Virtual reality;Electronic learning;Internet;Navigation;Mice;Seminars;Power system simulation;Education,computer aided instruction;power engineering education;renewable energy sources;virtual reality languages,hypermedia systems;renewable energy sources;virtual reality modelling language;interactive three dimensional representation;modern education,,1,,12,,16-May-08,,,IEEE,IEEE Conferences
"Empirical Evidence of Priming, Transfer, Reinforcement, and Learning in the Real and Virtual Trillium Trails",M. C. R. Harrington,"University of Pittsburgh, Pittsburgh",IEEE Transactions on Learning Technologies,9-Jun-11,2011,4,2,175,186,"Over the past 20 years, there has been a debate on the effectiveness of virtual reality used for learning with young children, producing many ideas but little empirical proof. This empirical study compared learning activity in situ of a real environment (Real) and a desktop virtual reality (Virtual) environment, built with video game technology, for discovery-based learning. The experiences were in the form of two field trips featuring statistically identical wildflower reserves. While the results support that the Real is superior for learning activity, they also show that the Virtual is useful for priming and reinforcing in-curriculum material, or for situations when the real environment is inaccessible. Offering the Virtual first primes for learning activity in the Real; if used second, it reinforces the Real experience, as supporting evidence shows significant transfer effects. Thus, the Virtual may serve educational goals, if used appropriately, and can come close to the Real. As informal learning environments, such as field trips and video games, are accepted as motivational, an attitudinal survey was conducted postexperiences to capture motivational factors at play, to aid in comparison and contrast, and to provide context to the empirical results on learning activity in situ; however, more work is needed.",1939-1382,,10.1109/TLT.2010.20,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5539765,Child-computer-environment interaction;child-computer interface;discovery-based learning;educational simulation;evaluation/methodology;serious games;human factors in software design;human-computer interaction;human information processing;informal learning;intrinsic learning;salient events;simulation;modeling;visualization;software psychology;virtual reality;user-centered design;user interfaces.,Biological system modeling;Solid modeling;Software;Virtual environment;Games;Environmental factors,computer aided instruction;computer games;virtual reality,virtual trillium trails;virtual reality used;learning activity;video game technology;discovery-based learning;informal learning environments,,17,,51,,5-Aug-10,,,IEEE,IEEE Journals
User Performance of VR-Based Dissection: Direct Mapping and Motion Coupling of a Surgical Tool,F. Trejo; Y. Hu,"Dept. of Electr. & Comput. Eng., Univ. of Calgary, Calgary, AB, Canada; Dept. of Electr. & Comput. Eng., Univ. of Calgary, Calgary, AB, Canada","2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",17-Jan-19,2018,,,3039,3044,"Robot-assisted surgical systems aim at enhancing surgeon's skills. Nonetheless, the learning curve for mastering such systems is very slow due to the motion-coupling mode that is usually presented in these systems for manipulating a surgical tool. This mode has limitations compared to the direct mapping mode used in open surgery for manipulating a tool. Virtual reality (VR) surgical simulators may reduce the learning time for transferring the surgeon's skills from direct mapping to motion coupling of tool manipulation. This may be accomplished by adding two features to the simulator. First, force models of tool-tissue interaction can be implemented in the haptic interface of the simulator. Second, VR-based surgical tasks can be designed to recreate directmapping mode and motion coupling mode of tool manipulation, as in open and robot-assisted surgeries, respectively. This may permit to transfer the surgeon's skills from open surgery to robotassisted surgery in a timely manner. This work presents a preliminary study on the effect of direct mapping mode and motion coupling mode of tool manipulation on the performance of na√Øve participants for VR-based brain tissue dissection. An Analytic force model of soft-tissue dissection was implemented in the simulator along with visual feedback of a predefined tool speed of 1 mm/s, which is observed in neurosurgery. The outcomes indicated that the motion quality of the tool via direct mapping was significantly better than with motion coupling. Thus, the study might serve as a first step toward the assessment of user's skills for VR-based robot-assisted dissection.",2577-1655,978-1-5386-6650-0,10.1109/SMC.2018.00516,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8616512,VR-based surgical simulation;direct mapping;motion coupling;robot-assisted surgery;soft-tissue dissection,Tools;Surgery;Task analysis;Robots;Couplings;Analytical models;Force,biological tissues;brain;haptic interfaces;medical computing;medical robotics;surgery;virtual reality,VR-based dissection;surgical tool;robot-assisted surgical systems;surgeon;motion-coupling mode;direct mapping mode;open surgery;surgical simulators;tool manipulation;tool-tissue interaction;VR-based surgical tasks;motion coupling mode;robot-assisted surgeries;VR-based brain tissue dissection;predefined tool speed;motion quality;VR-based robot-assisted dissection;direct-mapping mode;velocity 1.0 mm/s,,,,22,,17-Jan-19,,,IEEE,IEEE Conferences
Data Correlation-Aware Resource Management in Wireless Virtual Reality (VR): An Echo State Transfer Learning Approach,M. Chen; W. Saad; C. Yin; M. Debbah,"Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, China; Bradley Department of Electrical and Computer Engineering, Wireless@VT, Virginia Tech, Blacksburg, VA, USA; Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, China; Mathematical and Algorithmic Sciences Lab, Huawei France R&D, Paris, France",IEEE Transactions on Communications,14-Jun-19,2019,67,6,4267,4280,"Providing seamless connectivity for wireless virtual reality (VR) users has emerged as a key challenge for future cloud-enabled cellular networks. In this paper, the problem of wireless VR resource management is investigated for a wireless VR network in which VR contents are sent by a cloud to cellular small base stations (SBSs). The SBSs will collect tracking data from the VR users, over the uplink, in order to generate the VR content and transmit it to the end-users using downlink cellular links. For this model, the data requested or transmitted by the users can exhibit correlation, since the VR users may engage in the same immersive virtual environment with different locations and orientations. As such, the proposed resource management framework can factor in such spatial data correlation, so as to better manage uplink and downlink traffic. This potential spatial data correlation can be factored into the resource allocation problem to reduce the traffic load in both the uplink and downlink. In the downlink, the cloud can transmit 360¬∞ contents or specific visible contents (e.g., user field of view) that are extracted from the original 360¬∞ contents to the users according to the users' data correlation so as to reduce the backhaul traffic load. In the uplink, each SBS can associate with the users that have similar tracking information so as to reduce the tracking data size. This data correlation-aware resource management problem is formulated as an optimization problem whose goal is to maximize the users' successful transmission probability, defined as the probability that the content transmission delay of each user satisfies an instantaneous VR delay target. To solve this problem, a machine learning algorithm that uses echo state networks (ESNs) with transfer learning is introduced. By smartly transferring information on the SBS's utility, the proposed transfer-based ESN algorithm can quickly cope with changes in the wireless networking environment due to users' content requests and content request distributions. Simulation results demonstrate that the developed algorithm achieves up to 15.8% and 29.4% gains in terms of successful transmission probability compared to Q-learning with data correlation and Q-learning without data correlation, respectively.",1558-0857,,10.1109/TCOMM.2019.2900624,National Natural Science Foundation of China; 111 Project; BUPT Excellent Ph.D. Students Foundation; National Science Foundation; ERC Starting MORE (Advanced Mathematical Tools for Complex Network Engineering); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648419,Virtual reality;resource allocation;echo state networks;transfer learning,Correlation;Wireless communication;Resource management;Downlink;Uplink;Cloud computing;Virtual reality,cellular radio;cloud computing;learning (artificial intelligence);optimisation;probability;resource allocation;virtual reality,resource allocation problem;data correlation-aware resource management problem;optimization problem;content transmission delay;instantaneous VR delay target;transfer learning;transfer-based ESN algorithm;wireless networking environment;content request distributions;wireless virtual reality users;wireless VR resource management;wireless VR network;VR content;cellular small base stations;SBSs;VR users;downlink cellular links;immersive virtual environment;resource management framework;downlink traffic;spatial data correlation;cloud-enabled cellular networks;echo state transfer learning approach,,12,,31,,21-Feb-19,,,IEEE,IEEE Journals
Head-related transfer function synthesis for immersive audio,A. Mouchtaris; J. -. Lim; T. Holman; C. Kyriakakis,"Integrated Media Syst. Center, Univ. of Southern California, Los Angeles, CA, USA; NA; NA; NA",1998 IEEE Second Workshop on Multimedia Signal Processing (Cat. No.98EX175),6-Aug-02,1998,,,155,160,"Immersive audio systems are being envisioned for applications that include teleconferencing and telepresence; augmented and virtual reality for manufacturing and entertainment; air traffic control, pilot warning, and guidance systems; displays for the visually- or aurally-impaired; home entertainment; distance learning; and professional sound and picture editing for television and film. The principal function of such systems is to synthesize, manipulate, and render sound fields in real time. In this paper we examine the limitations that are inherent in spatial sound delivery over loudspeakers and propose a method that generates virtual sound sources based on synthetic head-related transfer functions with the same spectral characteristics as those of the real source.",,0-7803-4919-9,10.1109/MMSP.1998.738928,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=738928,,Transfer functions;Control system synthesis;Audio systems;Teleconferencing;Virtual reality;Manufacturing;Air traffic control;Auditory displays;Computer aided instruction;TV,audio systems;teleconferencing;virtual reality;loudspeakers;transfer functions;least squares approximations;signal synthesis;crosstalk;audio signal processing,head-related transfer function synthesis;teleconferencing;immersive audio systems;telepresence;augmented reality;virtual reality;manufacturing;entertainment;air traffic control;pilot warning;guidance systems;displays;visually-impaired;aurally-impaired;home entertainment;distance learning;professional sound editing;professional picture editing;television;film;sound fields;spatial sound delivery;loudspeakers;virtual sound sources;spectral characteristics;real source;spatial audio rendering;crosstalk cancellation;least squares method,,6,1,7,,6-Aug-02,,,IEEE,IEEE Conferences
VirtualTablet: Extending Movable Surfaces with Touch Interaction,A. H. Hoppe; F. Marek; F. van de Camp; R. Stiefelhagen,"Karlsruhe Institute of Technology (KIT), IAR; Karlsruhe Institute of Technology (KIT); Fraunhofer IOSB; Karlsruhe Institute of Technology (KIT), IAR",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,980,981,"Immersive output and effortless input are two core aspects of a virtual reality (VR) experience. We transfer ubiquitous touch interaction with haptic feedback into a virtual environment (VE). The movable and cheap real world object supplies an accurate touch detection equal to a ray-casting interaction with a controller. Moreover, the virtual tablet extends the functionality of a real world tablet. Additional information is displayed in mid-air around the touchable area and the tablet can be turned over to interact with both sides. It allows easy to learn and precise system interaction and can even augment the established touch metaphor with new paradigms.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8797993,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797993,Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality,Three-dimensional displays;Cameras;Haptic interfaces;Visualization;Virtual environments;User interfaces,haptic interfaces;human computer interaction;notebook computers;touch sensitive screens;ubiquitous computing;virtual reality,VirtualTablet;movable surfaces;virtual reality experience;VR;ubiquitous touch interaction;haptic feedback;virtual environment;ray-casting interaction;touch metaphor;VE,,,,9,,15-Aug-19,,,IEEE,IEEE Conferences
Training Transfer of Bimanual Assembly Tasks in Cost-Differentiated Virtual Reality Systems,S. Shen; H. -T. Chen; T. W. Leong,"School of Software, University of Technology, Sydney; School of Software, University of Technology, Sydney; School of Software, University of Technology, Sydney",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,1152,1153,"Recent advances of the affordable virtual reality headsets make virtual reality training an economical choice when compared to traditional training. However, these virtual reality devices present a range of different levels of virtual reality fidelity and interactions. Few works have evaluated their validity against the traditional training formats. This paper presents a study that compares the learning efficiency of a bimanual gearbox assembly task among traditional training, virtual reality training with direct 3D inputs (HTC VIVE), and virtual reality training without 3D inputs (Google Cardboard). A pilot study was conducted and the result shows that HTC VIVE brings the best learning outcomes.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8797917,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797917,Assistive systems;Head-mounted Display;Virtual Reality;Learning Transfer,Training;Task analysis;Virtual reality;Three-dimensional displays;Headphones;Google;Software,assembling;gears;helmet mounted displays;industrial training;production engineering computing;virtual reality,virtual reality training;bimanual gearbox assembly task;cost-differentiated virtual reality systems;virtual reality headsets;traditional training;head-mounted display,,,,3,,15-Aug-19,,,IEEE,IEEE Conferences
Incorporation of motor control and motor learning principles into VR applications,M. F. Levin; S. K. Subramanian; M. T. Robert,"School of Physical and Occupational Therapy, McGill University; Department of Neuroscience, University of Montreal; Integrated Program in Neuroscience, McGill University",2015 International Conference on Virtual Rehabilitation (ICVR),17-Dec-15,2015,,,2,2,"The primary focus of rehabilitation for individuals with motor deficits is the relearning of specific motor skills and daily tasks. Rehabilitation strives to take advantage of neuroplastic processes during recovery, a process that can be addressed by creating enriched training environments using virtual reality (VR) based simulations. The objectives of this workshop are to review motor control and motor learning principles, to discuss how they can be exploited by VR training environments and to provide examples of how these principles have been incorporated into different VR simulations for improving upper limb motor recovery. The workshop includes a practical component in which participants will design a specific intervention for improving a typical motor problem incorporating motor control and motor learning principles, in both a VR-based and a non-VR-based clinical application. Finally, we will discuss the limitations of the current technologies with respect to their effectiveness and transfer of learning to daily life tasks.",2331-9569,978-1-4799-8984-3,10.1109/ICVR.2015.7358630,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358630,,Motor drives;Neuroscience;Training;Solid modeling;Conferences;Medical treatment;Virtual reality,bioelectric potentials;learning (artificial intelligence);neurophysiology;patient rehabilitation;virtual reality,motor control principles;motor learning principles;patient rehabilitation;neuroplastic processes;virtual reality based simulations;upper limb motor recovery,,,,,,17-Dec-15,,,IEEE,IEEE Conferences
Transfer Learning of a Temporal Bone Performance Model via Anatomical Feature Registration,Y. Zhou; I. Ioannou; S. Wijewickrema; J. Bailey; P. Piromchai; G. Kennedy; S. OLeary,"Dept. of Comput. & Inf. Syst., Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Comput. & Inf. Syst., Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Centre for the Study of Higher Educ., Univ. of Melbourne, Melbourne, VIC, Australia; NA",2014 22nd International Conference on Pattern Recognition,6-Dec-14,2014,,,1916,1921,"Evaluation of the outcome (end-product) of surgical procedures carried out in virtual reality environments is an essential part of simulation-based surgical training. Automated end-product assessment can be carried out by performance classifiers built from a set of expert performances. When applied to temporal bone surgery simulation, these classifiers can evaluate performance on the bone specimen they were trained on, but they cannot be extended to new specimens. Thus, new expert performances need to be recorded for each new specimen, requiring considerable time commitment from time-poor expert surgeons. To eliminate this need, we propose a transfer learning framework to adapt a classifier built on a single temporal bone specimen to multiple specimens. Once a classifier is trained, we translate each new specimens' features to the original feature space, which allows us to carry out performance evaluation on different specimens using the same classifier. In our experiment, we built a surgical end-product performance classifier from 16 expert trials on a simulated temporal bone specimen. We applied the transfer learning approach to 8 new specimens to obtain machine generated end-products. We also collected end-products for these 8 specimens drilled by a single expert. We then compared the machine generated end-products to those drilled by the expert. The drilled regions generated by transfer learning were similar to those drilled by the expert.",1051-4651,978-1-4799-5209-0,10.1109/ICPR.2014.335,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977047,transfer learning;anatomy registration;automatic evaluation,Surgery;Bones;Anatomical structure;Solid modeling;Adaptation models;Decision trees;Training,bone;feature extraction;image classification;image registration;learning (artificial intelligence);medical image processing;surgery;virtual reality,temporal bone performance model;anatomical feature registration;surgical procedures;virtual reality environments;simulation-based surgical training;automated end-product assessment;performance classifiers;temporal bone surgery simulation;bone specimen;time-poor expert surgeons;transfer learning framework;surgical end-product performance classifier;transfer learning approach;machine generated end-products,,,,17,,6-Dec-14,,,IEEE,IEEE Conferences
Validation of virtual humanoid intelligent agents in virtual reality systems,A. Sadagic,"Naval Postgraduate School - NPS, MOVES Institute",2012 IEEE Virtual Reality Workshops (VRW),12-Apr-12,2012,,,91,92,"One of the great benefits VR systems offer is their ability to simulate a number of virtual humans when their presence is needed in the context of some learning or training experience. Being that the real humans may not be available to play different roles and support virtual sessions, the ability of a system to generate highly believable representations of autonomous virtual humans - virtual intelligent agents - is vital in achieving specific learning and training objectives. Eliminating the elements of the system that can cause a negative learning and training transfer is a paramount in those systems. We illustrate the results of two user studies focused on validation of non-deterministic domain-specific behaviors generated by our system (example: behaviors typical for a well coordinated group of paramedics or military unit). The results and observations confirmed that when it comes to VR systems with stringent requirements and high expectations for positive learning/training transfer, we still need humans to evaluate and validate synthesized human-like agent behaviors.",2375-5334,978-1-4673-1246-2,10.1109/VR.2012.6180897,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180897,virtual/digital characters;validation;simulation and behavior;intelligent agents;military applications,Training;Humans;Analytical models;Virtual reality;Intelligent agents;Solid modeling;Context,learning (artificial intelligence);software agents;virtual reality,virtual humanoid intelligent agent validation;virtual reality systems;VR systems;negative learning;training transfer;nondeterministic domain-specific behavior validation;positive learning;human-like agent behavior synthesis,,,,1,,12-Apr-12,,,IEEE,IEEE Conferences
The Effect of Virtual Reality on Knowledge Transfer and Retention in Collaborative Group-Based Learning for Neuroanatomy Students,V. Souza; A. Maciel; L. Nedel; R. Kopper; K. Loges; E. Schlemmer,"Institute of Informatics (INF), Federal University of Rio Grande do Sul (UFRGS),Porto Alegre,Brazil; Institute of Informatics (INF), Federal University of Rio Grande do Sul (UFRGS),Porto Alegre,Brazil; Institute of Informatics (INF), Federal University of Rio Grande do Sul (UFRGS),Porto Alegre,Brazil; University of North Carolina at Greensboro (UNCG),Department of Computer Science,Greensboro,USA; University of Vale do Rio dos Sinos (UNISINOS),S√£o Leopoldo,Brazil; University of Vale do Rio dos Sinos (UNISINOS),S√£o Leopoldo,Brazil",2020 22nd Symposium on Virtual and Augmented Reality (SVR),23-Nov-20,2020,,,92,101,"There are many uses for virtual reality (VR) in education, and there is a consensus about its contribution in the teaching and learning processes. However, the majority of the studies assess the effectiveness of an individual learning in VR, and there is a need to explore more on the effects of VR using different levels of immersion and collaboration. This paper presents an experiment to investigate knowledge transfer in a group-based learning game. We introduce a VR serious game to support teaching and learning processes in neuroanatomy health education. A between-subjects experiment was conducted with 23 students to jointly assess learning, knowledge retention, and sense of presence. As a control condition, grouped students assembled a physical model of the human brain, while in the experimental condition, a virtual brain was assembled. In each group, one participant assembled the brain, while the others observed and verbally collaborated in a group-based learning strategy. Results shown high mean scores in the virtual condition. When comparing the knowledge test performance before and immediately after the experiment, we found significant difference only for the virtual condition. The same can be observed for retention. Because of the promising results achieved and motivated by the need of more engaging new tools for remote learning - fully used in quarantine conditions, such as the current one because of the Covid-19 pandemic - we conducted a pilot user study to evaluate the learning effect of a remote version of our collaborative VR game.",,978-1-7281-9231-4,10.1109/SVR51698.2020.00028,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262701,Virtual Reality;Presence;User Evaluation,Education;Games;Training;Neuroanatomy;Collaboration;Three-dimensional displays;Solid modeling,computer aided instruction;human factors;serious games (computing);teaching;virtual reality,virtual condition;remote learning;learning effect;collaborative VR game;virtual reality;knowledge transfer;collaborative group-based learning;neuroanatomy students;teaching;learning processes;individual learning;VR serious game;neuroanatomy health education;between-subjects experiment;knowledge retention;control condition;grouped students;virtual brain;knowledge test performance,,,,44,,23-Nov-20,,,IEEE,IEEE Conferences
Facial Expression Recognition Under Partial Occlusion from Virtual Reality Headsets based on Transfer Learning,B. Houshmand; N. Mefraz Khan,"Ryerson University,Data Science,Toronto,Canada; Ryerson University,Electrical and Computer Engineering,Toronto,Canada",2020 IEEE Sixth International Conference on Multimedia Big Data (BigMM),20-Oct-20,2020,,,70,75,"Facial expressions of emotion are a major channel in our daily communications, and it has been subject of intense research in recent years. To automatically infer facial expressions, convolutional neural network based approaches has become widely adopted due to their proven applicability to Facial Expression Recognition (FER) task.On the other hand Virtual Reality (VR) has gained popularity as an immersive multimedia platform, where FER can provide enriched media experiences. However, recognizing facial expression while wearing a head-mounted VR headset is a challenging task due to the upper half of the face being completely occluded. In this paper we attempt to overcome these issues and focus on facial expression recognition in presence of a severe occlusion where the user is wearing a head-mounted display in a VR setting. We propose a geometric model to simulate occlusion resulting from a Samsung Gear VR headset that can be applied to existing FER datasets. Then, we adopt a transfer learning approach, starting from two pretrained networks, namely VGG and ResNet. We further fine-tune the networks on FER+ and RAF-DB datasets. Experimental results show that our approach achieves comparable results to existing methods while training on three modified benchmark datasets that adhere to realistic occlusion resulting from wearing a commodity VR headset. Code for this paper is available at: https://github.com/bita-github/MRP-FER.",,978-1-7281-9325-0,10.1109/BigMM50055.2020.00020,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9232653,Facial expression recognition;Facial occlusion;Transfer learning;VR,Face recognition;Headphones;Solid modeling;Feature extraction;Training;Virtual reality;Systematics,convolutional neural nets;emotion recognition;face recognition;helmet mounted displays;learning (artificial intelligence);virtual reality,transfer learning approach;commodity VR headset;partial occlusion;virtual reality headsets;convolutional neural network;facial expression recognition task;head-mounted VR headset;samsung gear VR headset;FER datasets;immersive multimedia platform;head-mounted display;RAF-DB datasets,,1,,25,,20-Oct-20,,,IEEE,IEEE Conferences
Game Based Learning of Blood Clotting Concepts,A. Deep; P. Prasad; S. Narayana; M. Chang; S. Murthy,NA; NA; NA; NA; NA,2016 IEEE 16th International Conference on Advanced Learning Technologies (ICALT),1-Dec-16,2016,,,526,530,"In this paper we describe the architecture of virtual clot (vCLOT), a virtual world system designed to teach procedural knowledge of blood clotting process, in a game based learning environment. vCLOT utilizes virtual world to give learners an immersive learning experience while actively participating in tasks that require them to apply the procedural knowledge they have learned. Design of vCLOT combines the immersivity of virtual worlds with the power of knowledge structures. Immersivity provides learners with the opportunity to make decisions at every level of the game. This transfers control of interaction to the learner, enabling the learner to be actively engaged in knowledge construction process. Knowledge structures are a neat way to represent domain and learner data. The user interface of vCLOT is designed and implemented with Open Wonderland which is an open-source 3D toolkit. The learning goal which is to learn about blood clotting process, is aligned with the game goal, which is application of blood clot process steps to heal an injury. The game goal is presented as a quest in which the learner interacts with concepts by either dragging them or synthesizing them from other concepts. Learners complete the quest on successful formation of blood clot which in turn implies that they have learnt the blood clot process. We plan to do a usability study to improve the system before starting actual intervention.",2161-377X,978-1-4673-9041-5,10.1109/ICALT.2016.70,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7757042,Game Based Learning;Procedural Knowledge;Blood Clotting;Open Wonderland;Quest,Games;Coagulation;XML;Calcium;Ions;Education,computer aided instruction;computer games;public domain software;teaching;user interfaces;virtual reality,procedural knowledge teaching;open-source 3D toolkit;Open Wonderland;user interface;knowledge construction process;decision making;knowledge structures;immersive learning experience;game based learning environment;blood clotting process;virtual world system;vCLOT;virtual clot architecture,,,,10,,1-Dec-16,,,IEEE,IEEE Conferences
Games and Learning Alliance (GaLA) Supporting Education and Training through Hi-Tech Gaming,F. Bellotti; R. Berta; A. De Gloria,"Dynatech - Dept. of Naval, Electr. & Inf. Technol. Eng., Univ. of Genoa, Genoa, Italy; Dynatech - Dept. of Naval, Electr. & Inf. Technol. Eng., Univ. of Genoa, Genoa, Italy; Dynatech - Dept. of Naval, Electr. & Inf. Technol. Eng., Univ. of Genoa, Genoa, Italy",2012 IEEE 12th International Conference on Advanced Learning Technologies,16-Aug-12,2012,,,740,741,"Games and Learning Alliance (GaLA) is the EU Network of Excellence on serious games (SG). The main expected outcome is the set-up a Virtual Research Centre (VRC) aimed at integrating, harmonizing and coordinating research on SGs and disseminating knowledge, best practices and tools as a reference point at an international level. The other two key focuses of the project are (1) the support to deployment in the actual educational and training settings and (2) the fostering of innovation and knowledge transfer through research-business dialogue. The NoE is composed of organizations that aim to integrate their activities and resources in a long-term view. A long-term perspective is systematically pursued as GaLA sets-up an infrastucture and aims at making it viable and sustainable. The major expected outcomes include: the European Society on Serious Games; the European conference on Serious Games; journal special issues; the Virtual Research Environment (VRE); the SG Living Labs (SG LLs); a MSc programme on SGs, with the relevant didactic tools; PhD projects on SGs; the schools (alignment and summer) on SGs.",2161-377X,978-1-4673-1642-2,10.1109/ICALT.2012.146,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6268245,Serious Games;Technology Enhanced Learning;Virtual Research Environment;Virtual research Center;Living Labs,Games;Europe;Educational institutions;Training;Best practices;Industries;Media,computer aided instruction;computer games;interactive programming;knowledge management;virtual reality,games and learning alliance;serious game;EU network;virtual research centre;VRC;training;knowledge transfer;innovation;research-business dialogue;NoE;GaLA;virtual research environment;SG;VRE;hi-tech game,,7,,2,,16-Aug-12,,,IEEE,IEEE Conferences
An Evaluation of Inanimate and Virtual Reality Training for Psychomotor Skill Development in Robot-Assisted Minimally Invasive Surgery,G. Caccianiga; A. Mariani; E. De Momi; G. Cantarero; J. D. Brown,"Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Biorobotics Institute, Scuola Superiore Sant‚ÄôAnna, Pisa, Italy; Department of Electronics, Information, and Bioengineering, Politecnico di Milano, Milan, Italy; Department of Physical Medicine and Rehabilitation, Johns Hopkins Medical Institute, Baltimore, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA",IEEE Transactions on Medical Robotics and Bionics,20-May-20,2020,2,2,118,129,"Robot-assisted minimally invasive surgery (RAMIS) is gaining widespread adoption in many surgical specialties, despite the lack of a standardized training curriculum. Current training approaches rely heavily on virtual reality simulators, in particular for basic psychomotor and visuomotor skill development. It is not clear, however, whether training in virtual reality is equivalent to inanimate model training. In this manuscript, we seek to compare virtual reality training to inanimate model training, with regard to skill learning and skill transfer. Using a custom-developed needle-driving training task with inanimate and virtual analogs, we investigated the extent to which N=18 participants improved their skill on a given platform post-training, and transferred that skill to the opposite platform. Results indicate that the two approaches are not equivalent, with more salient skill transfer after inanimate training than virtual training. These findings support the claim that training with real physical models is the gold standard, and suggest more inanimate model training be incorporated into training curricula for early psychomotor skill development.",2576-3202,,10.1109/TMRB.2020.2990692,JHU internal fundings; Tesi All‚Äôestero Scholarship of Politecnico di Milano; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9080087,Automated;inanimate;minimally invasive;objective;robot-assisted;sensors;simulation;skill transfer;surgery;training;virtual reality,Training;Task analysis;Solid modeling;Robot sensing systems;Needles,computer based training;control engineering computing;medical computing;medical robotics;surgery;training;virtual reality,current training approaches;virtual reality simulators;basic psychomotor;visuomotor skill development;inanimate model training;virtual reality training;skill learning;custom-developed needle-driving training task;inanimate analogs;virtual analogs;given platform post-training;salient skill transfer;inanimate training;virtual training;training curricula;early psychomotor skill development;robot-assisted minimally invasive surgery;standardized training curriculum,,,,53,IEEE,28-Apr-20,,,IEEE,IEEE Journals
Text Entry in Immersive Head-Mounted Display-Based Virtual Reality Using Standard Keyboards,J. Grubert; L. Witzani; E. Ofek; M. Pahud; M. Kranz; P. O. Kristensson,Coburg University of Applied Sciences and Arts; University of Passau; Microsoft Research; Microsoft Research; University of Passau; University of Cambridge,2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),30-Aug-18,2018,,,159,166,"We study the performance and user experience of two popular mainstream text entry devices, desktop keyboards and touchscreen keyboards, for use in Virtual Reality (VR) applications. We discuss the limitations arising from limited visual feedback, and examine the efficiency of different strategies of use. We analyze a total of 24 hours of typing data in VR from 24 participants and find that novice users are able to retain about 60% of their typing speed on a desktop keyboard and about 40-45% of their typing speed on a touchscreen keyboard. We also find no significant learning effects, indicating that users can transfer their typing skills fast into VR. Besides investigating baseline performances, we study the position in which keyboards and hands are rendered in space. We find that this does not adversely affect performance for desktop keyboard typing and results in a performance trade-off for touchscreen keyboard typing.",,978-1-5386-3365-6,10.1109/VR.2018.8446059,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446059,H.5.2: [User Interfaces - Input devices and strategies.],Keyboards;Visualization;Electronic mail;Virtual reality;Error analysis;Performance evaluation;User interfaces,helmet mounted displays;keyboards;learning (artificial intelligence);touch sensitive screens;user interfaces;virtual reality,immersive head-mounted display-based Virtual Reality;standard keyboards;user experience;popular mainstream text entry devices;Virtual Reality applications;VR;novice users;typing speed;typing skills;baseline performances;desktop keyboard typing;touchscreen keyboard typing,,23,,38,,30-Aug-18,,,IEEE,IEEE Conferences
Multi-user networked framework for virtual reality platform,A. Rai; R. J. Kannan; S. Ramanathan,"School of Computing Science & Engineering, VIT University, Chennai, India; School of Computing Science & Engineering, VIT University, Chennai, India; School of Computing Science & Engineering, VIT University, Chennai, India",2017 14th IEEE Annual Consumer Communications & Networking Conference (CCNC),20-Jul-17,2017,,,584,585,"Networked Virtual Environments (NEV) are sets of disjointed virtual worlds which are topographically set apart from the users yet connected through the communication network to give them the illusion of being in the same virtual location. NVEs are increasingly receiving consideration from business and research point of view. Contrasted with various sorts of possible applications, NVEs require a high responsiveness to ensure continuous streaming of live data for full immersion. It is as yet difficult to develop such applications since it require to create virtual reality framework over distributed databases; as every user needs locally adequate data flow to concurrently construct a scene as with other users and able to accommodate multi-user interactions in the virtual environment. Such information requires simultaneous computation and communication of streaming data. In this study we built up a prototype of a NVE in view of the blend of Minority Game (MG) and Online Induction Algorithm (OIA) with lossless transfer functions.",2331-9860,978-1-5090-6196-9,10.1109/CCNC.2017.7983177,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7983177,Networked Virtual Environments;Online Learning;Data Stream control;Adaptive Networking,Rendering (computer graphics);Virtual environments;Databases;Feature extraction;Conferences;Tracking,game theory;inference mechanisms;transfer functions;virtual reality,multiuser networked framework;NVE;networked virtual environments;minority game;MG;online induction algorithm;OIA;lossless transfer functions;virtual reality platform,,,,3,,20-Jul-17,,,IEEE,IEEE Conferences
Comparing HMD-Based and Paper-Based Training,S. Werrlich; A. Daniel; A. Ginger; P. Nguyen; G. Notni,"BMW Group, Munich, Germany; BMW Group, Munich, Germany; BMW Group, Munich, Germany; BMW Group, Munich, Germany; Tech. Univ. Ilmenau, Ilmenau, Germany",2018 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),17-Jan-19,2018,,,134,142,"Collaborative Systems are in daily use by millions of people promising to improve everyone's life. Smartphones, smartwatches and tablets are everyday objects and life without these unimaginable. New assistive systems such as head-mounted displays (HMDs) are becoming increasingly important for various domains, especially for the industrial domain, because they claim to improve the efficiency and quality of procedural tasks. A range of scientific laboratory studies already demonstrated the potential of augmented reality (AR) technologies especially for training tasks. However, most researches are limited in terms of inadequate task complexity, measured variables and lacking comparisons. In this paper, we want to close this gap by introducing a novel multimodal HMD-based training application and compare it to paper-based learning for manual assembly tasks. We perform a user study with 30 participants measuring the training transfer of an engine assembly training task, the user satisfaction and perceived workload during the experiment. Established questionnaires such as the system usability scale (SUS), the user experience questionnaire (UEQ) and the Nasa Task Load Index (NASA-TLX) are used for the assessment. Results indicate significant differences between both learning approaches. Participants perform significantly faster and significantly worse using paper-based instructions. Furthermore, all trainees preferred HMD-based learning for future assembly trainings which was scientifically proven by the UEQ.",1554-7868,978-1-5386-7459-8,10.1109/ISMAR.2018.00046,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613759,Augmented Reality;Evaluation;Head Mounted Displays;Training,Task analysis;Training;Engines;Software;Resists;Atmospheric measurements;Particle measurements,augmented reality;computer based training;groupware;helmet mounted displays;human computer interaction;human factors;user interfaces;virtual reality,paper-based training;Collaborative Systems;smartwatches;head-mounted displays;industrial domain;scientific laboratory studies;augmented reality;training tasks;inadequate task complexity;training transfer;engine assembly training task;user satisfaction;system usability scale;user experience questionnaire;Nasa Task Load Index;paper-based instructions;assistive systems;multimodal HMD-based learning,,5,,28,,17-Jan-19,,,IEEE,IEEE Conferences
Region-Specific Automated Feedback in Temporal Bone Surgery Simulation,S. Wijewickrema; I. Ioannou; Y. Zhou; P. Piromchai; J. Bailey; G. Kennedy; S. O'Leary,"Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Comput. & Inf. Syst., Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Comput. & Inf. Syst., Univ. of Melbourne, Melbourne, VIC, Australia; Centre for the Study of Higher Educ., Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia",2015 IEEE 28th International Symposium on Computer-Based Medical Systems,27-Jul-15,2015,,,310,315,"The use of virtual reality simulators for surgical training has gained popularity in recent years, with an ever increasing body of evidence supporting the benefits and validity of simulation-based training. However, a crucial component of effective skill acquisition has not been adequately addressed, namely the provision of timely performance feedback. The utility of a surgical simulator is limited if it still requires the presence of experts to guide trainees. Automated feedback that emulates the advise provided by experts is necessary to facilitate independent learning. We propose an automated system that provides region-specific feedback on surgical technique within a temporal bone surgery simulator. The design of this system allows easy transfer of feedback models to multiple temporal bone specimens in the simulator. The system was validated by an expert otologist and was found to provide highly accurate and timely feedback.",2372-9198,978-1-4673-6775-2,10.1109/CBMS.2015.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7167506,Automated Feedback in Surgery Simulation;Simulation-Based Surgical Training;Virtual Reality Temporal Bone Surgery,Surgery;Bones;Measurement;Accuracy;Solid modeling;Force;Anatomical structure,biomedical education;bone;computer based training;ear;educational aids;feedback;medical computing;surgery;teaching;virtual reality,region-specific automated surgical feedback;temporal bone surgery simulation;virtual reality simulator;surgical training;simulation-based training;effective skill acquisition;timely performance feedback;surgical simulator utility limitation;independent learning facilitation;temporal bone surgery simulator design;feedback model transfer;temporal bone specimen;system validation;otology,,4,,14,,27-Jul-15,,,IEEE,IEEE Conferences
A virtual environment for learning to pilot remotely operated vehicles,N. J. Pioch; B. Roberts; D. Zeltzer,"BBN Corp., Cambridge, MA, USA; NA; NA",Proceedings. International Conference on Virtual Systems and MultiMedia VSMM '97 (Cat. No.97TB100182),6-Aug-02,1997,,,218,226,"Remotely operated vehicles (ROVs) are used extensively for underwater searching and salvage, inspection, surveying, scientific exploration and mine countermeasures. ROV pilots must learn to rely on limited data from video and sonar displays and a few other positional indicators to maintain a sense of their vehicle, its tether and its surroundings. Pilot training typically occurs on-the-job, where equipment is placed at risk, controlled learning situations are hard to create, and time for instruction is minimal. The TRANSoM (TRAiNing for remote Sensing and Manipulation) project is developing a training environment that combines two emerging technologies to overcome these limitations. A virtual environment (VE) simulates the ROV and its surroundings, and also has instructional enhancements such as external views of the ROV, directional cues and alternate modes of interaction with the vehicle, e.g. a head-tracked head-mounted display (HMD). An intelligent tutoring system (ITS) monitors student pilot behavior and offers verbal and graphical feedback, a mission review and a performance assessment. Near-transfer experiments comparing the utility of different artificial viewpoints have been completed, with full transfer experiments involving a real ROV to follow.",,0-8186-8150-0,10.1109/VSMM.1997.622350,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=622350,,Virtual environment;Remotely operated vehicles;Inspection;Sonar equipment;On the job training;Remote sensing;Intelligent systems;Artificial intelligence;Computer displays;Feedback,marine systems;virtual reality;intelligent tutoring systems;telecontrol;computer based training;control engineering computing,virtual environment;remotely operated vehicle simulation;pilot training;underwater vehicles;video displays;sonar displays;positional indicators;TRANSoM project;remote sensing;remote manipulation;instructional enhancements;external views;directional cues;interaction modes;head-tracked head-mounted display;intelligent tutoring system;student pilot behavior monitoring;verbal feedback;graphical feedback;mission review;performance assessment;near-transfer experiments;artificial viewpoints,,5,,15,,6-Aug-02,,,IEEE,IEEE Conferences
A Novel Robot Teaching System Based on Mixed Reality,Y. Xu; C. Yang; X. Liu; Z. Li,"Key Lab of Autonomous Systems and Networked Control, School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; Key Lab of Autonomous Systems and Networked Control, School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; Hohai University, Jiangsu, China; Key Lab of Autonomous Systems and Networked Control, School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China",2018 3rd International Conference on Advanced Robotics and Mechatronics (ICARM),13-Jan-19,2018,,,250,255,"In this paper, we have developed a robot teaching system where the robot learns the point-to-point motions from human demonstrations. In the demonstration phase, the operator's gestures and palm position are used to guide the robot to complete the task. At the same time, the scene of robots and its work environment, and the virtual model of the palms are integrated into Unity. Then the mixed reality scene is transferred to a virtual reality(VR) helmet, which provides operator real-time visual feedback. In the learning and reproduction phase, the Extreme Learning Machine(ELM) is used to generate a new trajectory from the training data. The experimental result shows that the robot teaching system based on mixed reality has more realistic and natural interaction. And the learning algorithm based on ELM has a good fitting ability.",,978-1-5386-7066-8,10.1109/ICARM.2018.8610861,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8610861,Robot Teaching;Mixed Reality;Teaching by Demonstration;Extreme Learning Machine,Robot kinematics;Education;Zirconium;Service robots;Virtual reality;End effectors,gesture recognition;human-robot interaction;learning (artificial intelligence);virtual reality,reproduction phase;novel robot teaching system;point-to-point motions;human demonstrations;demonstration phase;mixed reality scene;operator real-time visual feedback;extreme learning machine;virtual reality helmet,,2,,22,,13-Jan-19,,,IEEE,IEEE Conferences
The Impact of Haptic and Visual Feedback on Teaching,K. Qi; D. Borland; E. Jackson; N. L. Williams; J. Minogue; T. C. Peck,"Davidson College; RENCI, UNC Chapel Hill; North Carolina State University; University of Maryland,College Park; North Carolina State University; Davidson College",2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),11-May-20,2020,,,612,613,"Haptic feedback, an important aspect of learning in virtual reality, has been demonstrated in contexts such as surgical training. However, deploying haptic feedback in other educational practices remains understudied. Haptically-enabled science simulations enable students to experience abstract scientific concepts through concrete and observable lessons in which students can physically experience the concepts being taught through haptic feedback. The present study aims to investigate the effect of an educational simulation on the understanding of basic physics concepts related to buoyancy. Specifically, we hypothesize that a simulation with visual and haptic feedback will improve participant learning transfer.",,978-1-7281-6532-5,10.1109/VRW50115.2020.00157,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9090605,Human computer interaction (HCI);Interaction paradigms;Virtual reality;Education;Interactive learning environments,Haptic interfaces;Visualization;Training;Buoyancy;Solid modeling;Liquids,computer aided instruction;educational courses;haptic interfaces;physics education;teaching;virtual reality,haptic feedback;haptically-enabled science simulations;visual feedback;teaching;virtual reality learning;participant learning transfer;educational practices;physics concepts;buoyancy,,,,5,,11-May-20,,,IEEE,IEEE Conferences
A Cross-Platform Classroom Training Simulator: Interaction Design and EvaluationA Cross-Platform Classroom Training Simulator: Interaction Design and Evaluation,A. Delamarre; C. Lisetti; C. Buche,"Florida International University,VISAGE Lab, SCIS,Miami,USA; Florida International University,VISAGE Lab, SCIS,Miami,USA; LAB-STICC CNRS, ENIB,Brest,France",2020 International Conference on Cyberworlds (CW),30-Oct-20,2020,,,86,93,"Virtual training environments experienced with different immersive technologies can accommodate users' preferences, proficiency, and platform availability. Whereas research comparing the effects of immersive technologies can provide important insights about their impact on users' experience (e.g. engagement, transfer of learning), current studies do not address how to design the user interface (UI) to ensure sound comparisons across platforms. For effective comparisons, however, the UI designs must be adapted for the platform used to provide comparable usability. In this article we describe our UI design methodology for the development of an effective and usable virtual classroom training simulator built for three technologies: (1) desktop; (2) Head-Mounted Display (HMD); and (3) Cave Automatic Virtual Environment (CAVE). Usability and other user experience factors were evaluated for each platform with concurrent think-aloud protocol and semi-structured interviews indicating that all three UIs were easy to use and to learn. We discuss insights for future development of cross-platform VTEs.",2642-3596,978-1-7281-6497-7,10.1109/CW49994.2020.00020,Florida International University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240533,Immersive Virtual Environment;Virtual Reality;Human Computer Interaction;User Study;Design,Training;Virtual environments;Resists;User interfaces;User experience;Usability;Interviews,computer based training;computer simulation;helmet mounted displays;user interfaces;virtual reality,interaction design;virtual training environments;platform availability;user interface;UI designs;comparable usability;UI design;usable virtual classroom training simulator;user experience factors;cross-platform VTEs;classroom training simulator;immersive technologies;cross-platform classroom training simulator;desktop;head-mounted display;cave automatic virtual environment,,,,24,,30-Oct-20,,,IEEE,IEEE Conferences
The role of feedback on cognitive motor learning in children with cerebral palsy: A protocol,M. T. Robert; M. F. Levin; R. Guberek; K. Sambasivan; M. F. Levin,"Integrated Program of Neuroscience and CRIR, McGill University, Montreal, Canada; Integrated Program of Neuroscience and CRIR, McGill University, Montreal, Canada; School of Physical and Occupational Therapy and CRIR, McGill University, Montreal, Canada; School of Physical and Occupational Therapy and CRIR, McGill University, Montreal, Canada; School of Physical and Occupational Therapy and CRIR, McGill University, Montreal, Canada",2015 International Conference on Virtual Rehabilitation (ICVR),17-Dec-15,2015,,,141,142,"Evidence of provision of extrinsic feedback for improvement and retention of upper limb kinematics in children with cerebral palsy (CP) is scarce, especially following training interventions using virtual environments. Benefits of using a virtual environment can range from increasing the participant's motivation to the ease of adapting extrinsic feedback for optimizing motor learning. In the proposed research, children with CP will be randomly allocated to one of three groups: no additional feedback, continuous feedback and faded feedback. For all groups, upper-limb motor training will be done in a virtual environment using the Jintronix virtual reality system. Motor improvements will be evaluated after an 8 hour training intervention and motor learning will be evaluated after one month. Transfer of motor gains to performance of a similar upper-limb task will also be used to assess learning. Findings from this research will provide crucial information on which frequency of feedback should be used to optimize motor learning and upper-limb rehabilitation in children with CP.",2331-9569,978-1-4799-8984-3,10.1109/ICVR.2015.7358617,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358617,Cerebral Palsy;Motor learning;Upper limb;Feedback,,feedback;medical computing;medical disorders;neurophysiology;patient rehabilitation;virtual reality,upper-limb rehabilitation;upper-limb task;Jintronix virtual reality system;upper-limb motor training;faded feedback;continuous feedback;additional feedback;extrinsic feedback;virtual environment;training intervention;upper limb kinematics retention;upper limb kinematics improvement;cerebral palsy;cognitive motor learning;time 8 h;time 1 month,,1,,7,,17-Dec-15,,,IEEE,IEEE Conferences
Predicting behavior patterns using adaptive workload models [computer networks],S. V. Raghavan; N. Swaminathan; J. Srinivasan,"Dept. of Comput. Sci. & Eng., Indian Inst. of Technol., Madras, India; NA; NA","MASCOTS '99. Proceedings of the Seventh International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems",6-Aug-02,1999,,,226,233,"Workload characteristics in a modern networking environment are very dynamic. In order to maximize performance continuously, it is natural to explore the possibility of intelligent systems which can take cognizance of the workload dynamics and adapt themselves for future control applications. In this paper, we propose a mechanism which represents the previous state of the system as a string. The user is allowed to define relevant information for better management as substrings. The adaptive workload model, which is called the SVR model (named after the first author's initials), predicts the short-term future as a string in which the information content (conveyed as a substring) reflects the future. We illustrate the applicability of the SVR model through Web traffic generation and ATM bandwidth management. We use genetic algorithms as the vehicle to address the learning aspects of the model.",,0-7695-0381-0,10.1109/MASCOT.1999.805059,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=805059,,Predictive models;Vehicle dynamics;Computer science;Bandwidth;Genetics;Vehicles;Electronic switching systems;Optimization;Resource management;Computer networks,genetic algorithms;telecommunication traffic;human factors;asynchronous transfer mode;bandwidth allocation;adaptive control;telecommunication congestion control;learning systems;intelligent control;optimal control;Internet;behavioural sciences,user behavior pattern prediction;adaptive workload models;networking environment;dynamic workload characteristics;continuous performance maximization;intelligent systems;control applications;substrings;SVR model;short-term future;information content;World Wide Web traffic generation;ATM bandwidth management;genetic algorithms;learning;computer networks;Internet,,1,,14,,6-Aug-02,,,IEEE,IEEE Conferences
Towards Fine-Grained Human Pose Transfer With Detail Replenishing Network,L. Yang; P. Wang; C. Liu; Z. Gao; P. Ren; X. Zhang; S. Wang; S. Ma; X. Hua; W. Gao,"Video Coding Laboratory, Institute of Digital Media, Peking University (PKU-IDM-VCL), Beijing, China; Video Coding Laboratory, Institute of Digital Media, Peking University (PKU-IDM-VCL), Beijing, China; School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China; Video Coding Laboratory, Institute of Digital Media, Peking University (PKU-IDM-VCL), Beijing, China; Video Coding Laboratory, Institute of Digital Media, Peking University (PKU-IDM-VCL), Beijing, China; School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China; Institute of Digital Media, Peking University, Beijing, China; Institute of Digital Media, Peking University, Beijing, China; Video Coding Laboratory, Institute of Digital Media, Peking University (PKU-IDM-VCL), Beijing, China; Institute of Digital Media, Peking University, Beijing, China",IEEE Transactions on Image Processing,29-Jan-21,2021,30,,2422,2435,"Human pose transfer (HPT) is an emerging research topic with huge potential in fashion design, media production, online advertising and virtual reality. For these applications, the visual realism of fine-grained appearance details is crucial for production quality and user engagement. However, existing HPT methods often suffer from three fundamental issues: detail deficiency, content ambiguity and style inconsistency, which severely degrade the visual quality and realism of generated images. Aiming towards real-world applications, we develop a more challenging yet practical HPT setting, termed as Fine-grained Human Pose Transfer (FHPT), with a higher focus on semantic fidelity and detail replenishment. Concretely, we analyze the potential design flaws of existing methods via an illustrative example, and establish the core FHPT methodology by combing the idea of content synthesis and feature transfer together in a mutually-guided fashion. Thereafter, we substantiate the proposed methodology with a Detail Replenishing Network (DRN) and a corresponding coarse-to-fine model training scheme. Moreover, we build up a complete suite of fine-grained evaluation protocols to address the challenges of FHPT in a comprehensive manner, including semantic analysis, structural detection and perceptual quality assessment. Extensive experiments on the DeepFashion benchmark dataset have verified the power of proposed benchmark against start-of-the-art works, with 12%-14% gain on top-10 retrieval recall, 5% higher joint localization accuracy, and near 40% gain on face identity preservation. Our codes, models and evaluation tools will be released at https://github.com/Lotayou/RATE.",1941-0042,,10.1109/TIP.2021.3052364,National Natural Science Foundation of China; High-performance Computing Platform of Peking University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9335507,Image generation;pose transfer;detail replenishment,Semantics;Strain;Solid modeling;Faces;Protocols;Media;Hybrid power systems,feature extraction;information retrieval;Internet;learning (artificial intelligence);object detection;object tracking;pose estimation;virtual reality,perceptual quality assessment;replenishing network;fine-grained evaluation protocols;coarse-to-fine model training scheme;feature transfer;content synthesis;core FHPT methodology;potential design flaws;detail replenishment;semantic fidelity;fine-grained human pose transfer;HPT setting;real-world applications;visual quality;style inconsistency;content ambiguity;detail deficiency;HPT methods;user engagement;production quality;fine-grained appearance details;visual realism;virtual reality;online advertising;media production;fashion design,,,,43,IEEE,25-Jan-21,,,IEEE,IEEE Journals
Using of social networks in educational process,N. Kalinenko; V. Krasnopolsky; V. Kukharenko; A. Serebryakov,"Volodymyr Dahl East Ukrainian National University, Molodizhnyi kvartal, 20-a, Luhansk, 91034, Ukraine; Volodymyr Dahl East Ukrainian National University, Molodizhnyi kvartal, 20-a, Luhansk, 91034, Ukraine; National Technical University ‚ÄúKharkiv Polytechnic Institute‚Äù, 21, Frunze Street, 61002, Ukraine; Volodymyr Dahl East Ukrainian National University, Molodizhnyi kvartal, 20-a, Luhansk, 91034, Ukraine",2013 IEEE 7th International Conference on Intelligent Data Acquisition and Advanced Computing Systems (IDAACS),14-Nov-13,2013,2,,781,784,The learning process can now be described as targeted joint activities of the teacher and students in the educational environment. Education - a purposeful process of bilateral activities of the teacher and the student in the transfer and assimilation of knowledge. Development of Personal Learning Environment in virtual reality plays the key role.,,978-1-4799-1429-6,10.1109/IDAACS.2013.6663031,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6663031,personal environment;virtual reality;mind mapping;social networks;web services;online learning;information technologies;educational environment,Social network services;Training;Materials;Educational institutions;Communities;Internet,computer aided instruction;social networking (online);virtual reality,social networks;educational process;learning process;educational environment;bilateral activity process;virtual reality;personal learning environment development,,1,,4,,14-Nov-13,,,IEEE,IEEE Conferences
Transferring an Interactive Display Service to the Virtual Reality,J. Naber; C. Krupitzer; C. Becker,"Univ. of Mannheim, Mannheim, Germany; Univ. of Mannheim, Mannheim, Germany; Univ. of Mannheim, Mannheim, Germany",2017 IEEE International Conference on Smart Computing (SMARTCOMP),15-Jun-17,2017,,,1,8,"In today's world, smart devices - such as laptops, smartphones, or smart watches - may substitute the need for physical presence of people. By offering a virtual representation, these devices support social interactions, e.g., telecommuting, remote studying through e-learning, or long-distance relationships. With audio and video streaming platforms like Skype, Apple FaceTime, or Google Hangouts it is possible to stay in contact with friends and colleagues. However, these platforms only allow communication between two peers or at most in very small groups. Additionally, they are very inflexible regarding content sharing and support only limited, defined use cases. In this paper, we present an extension to our pervasive display service for a remote virtual environment. This allows an immersive participation at remote activities in larger groups, while retaining the flexibility regarding joining devices of a pervasive middleware. Our contributions are threefold. First, we present a reusable design for integrating an interactive display service into virtual environments. Second, we implement our approach using the BASE middleware and the Unity 3D engine. Third, we evaluate our approach in a smart meeting room scenario.",,978-1-5090-6517-2,10.1109/SMARTCOMP.2017.7947054,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7947054,,Virtual environments;Middleware;Smart phones;Access control;Companies,middleware;ubiquitous computing;virtual reality,interactive display service;virtual reality;smart devices;virtual representation;social interactions;audio streaming;video streaming;pervasive display service;remote virtual environment;immersive participation;pervasive middleware;reusable design;BASE middleware;Unity 3D engine;smart meeting room,,2,,10,,15-Jun-17,,,IEEE,IEEE Conferences
Mobility Management With Transferable Reinforcement Learning Trajectory Prediction,Z. Zhao; M. Karimzadeh; L. Pacheco; H. Santos; D. Ros√°rio; T. Braun; E. Cerqueira,"School of Electronic and Information Engineering, Beihang University, Beijing, China; Institute of Computer Science, University of Bern, Bern, Switzerland; Institute of Computer Science, University of Bern, Bern, Switzerland; Institute of Computer Science, University of Bern, Bern, Switzerland; Institute of Technology, Federal University of Par√°, Belem, Brazil; Institute of Computer Science, University of Bern, Bern, Switzerland; Institute of Technology, Federal University of Par√°, Belem, Brazil",IEEE Transactions on Network and Service Management,9-Dec-20,2020,17,4,2102,2116,"Future mobile networks will enable the massive deployment of mobile multimedia applications anytime and anywhere. In this context, mobility management schemes, such as handover and proactive multimedia service migration, will be essential to improve network performance. In this article, we propose a proactive mobility management approach based on group user trajectory prediction. Specifically, we introduce a mobile user trajectory prediction algorithm by combining the Long-Short Term Memory networks (LSTM) with Reinforcement Learning (RL) to automate the model training procedure. We further develop a group user trajectory predictor to reduce prediction calculation overheads of users with similar movement patterns. To validate the impact of the proposed mobility management approach, we present a virtual reality (VR) service migration scheme built on the top of the proactive handover mechanism that benefits from trajectory predictions. Experiment results validate our predictor's outstanding accuracy and its impacts on enhancing handover and service migration performance to provide quality of service assurance.",1932-4537,,10.1109/TNSM.2020.3034482,Beihang Zhuobai program; Orange research project Context Awareness Engine; CAPES‚ÄîFinance Code 001; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9244233,Mobility management;trajectory prediction;reinforcement learning;transfer learning;service migration,Trajectory;Mobile handsets;Streaming media;Handover;Computer architecture;Prediction algorithms,learning (artificial intelligence);mobility management (mobile radio);multimedia communication;telecommunication computing;virtual reality,mobile multimedia applications;proactive multimedia service migration;network performance;proactive mobility management approach;group user trajectory prediction;mobile user trajectory prediction algorithm;long-short term memory networks;model training procedure;group user trajectory predictor;virtual reality service migration scheme;proactive handover mechanism;service migration performance;future mobile networks;transferable reinforcement learning trajectory prediction,,,,48,IEEE,29-Oct-20,,,IEEE,IEEE Journals
Human Action Recognition Based on a Two-stream Convolutional Network Classifier,V. de Oliveira Silva; F. de Barros Vidal; A. R. Soares Romariz,"Department of Electrical Engineering, University of Bras√≠lia, Bras√≠lia, Brazil; Department of Computer Science, University of Bras√≠lia, Bras√≠lia, Brazil; Department of Electrical Engineering, University of Bras√≠lia, Bras√≠lia, Brazil",2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA),18-Jan-18,2017,,,774,778,"Currently, video generation devices are simpler to manipulate, more portable and with lower prices. This allowed easy storage and transmission of large amounts of media, such as videos, which has facilitated the analysis of information, independent of human assistance for evaluation and exhaustive search of videos. Virtual reality, robotics, tele-medicine, humanmachine interface and tele-surveillance are applications for these techniques. This paper describes a method for human action recognition in videos using two convolutional neural networks (CNNs). The first one Spatial Stream (trained with frames of the video) and the second one Temporal Stream, trained with stacks of Dense Optical Flow (DOF). Both streams were trained separately and from both of them we generated a classification histogram based on the most frequent class assignment. For final classification, those histograms were combined to produce a single output. The technique was tested in two public action video datasets: Weizmann and UCF Sports. We achieve 84.44% of accuracy on Weizmann dataset for Spatial stream and 78.46% on UCF Sports dataset. For the Weizmann dataset we obtained 91.11% with networks combination.",,978-1-5386-1418-1,10.1109/ICMLA.2017.00-64,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260728,Human action recognition;Convolutional Neural networks;Dense Optical Flow;Transfer Learning,Histograms;Streaming media;Training;Image recognition;Kernel,feature extraction;image classification;image motion analysis;image recognition;image representation;image sequences;learning (artificial intelligence);neural nets;object recognition;video signal processing;virtual reality,videos;virtual reality;tele-medicine;humanmachine interface;tele-surveillance;human action recognition;convolutional neural networks;Spatial Stream;Temporal Stream;Dense Optical Flow;public action video datasets;Weizmann dataset;networks combination;two-stream convolutional network classifier;video generation devices;human assistance;exhaustive search;spatial stream,,2,,29,,18-Jan-18,,,IEEE,IEEE Conferences
Virtual Reality medical training system for anatomy education,J. Falah; S. Khan; T. Alfalah; S. F. M. Alfalah; W. Chan; D. K. Harrison; V. Charissis,"School of Engineering and Built Environment, Glasgow Caledonian University, Glasgow, UK; School of Engineering and Built Environment, Glasgow Caledonian University, Glasgow, UK; School of Business, Applied Science University, Amman, Jordan; King Abdullah II School for Information Technology University of Jordan, Amman, Jordan; School of Engineering and Built Environment, Glasgow Caledonian University, Glasgow, UK; School of Engineering and Built Environment, Glasgow Caledonian University, Glasgow, UK; School of Engineering and Built Environment, Glasgow Caledonian University, Glasgow, UK",2014 Science and Information Conference,9-Oct-14,2014,,,752,758,"Medical education is a dynamic field that witnesses continuous evolution and development. The employment of Virtual Reality (VR) based visualization and training environments in the delivery of anatomy teaching transfers the learning experience from one that involves memorising the structures without a true understanding of the 3-Dimensional (3D) relations, to a process that involves a thorough understanding of the structure based on visualisation rather than memorising, which makes the learning process more efficient and enjoyable, and less time consuming. This paper describes the development of a Virtual Reality and 3D visualisation system for anatomy teaching. The developed system offers a real-time 3D representation of the heart in an interactive VR environment that provides self-directed learning and assessment tools through a variety of interfaces and functionalities. To ensure the accuracy and precision of the developed system it was evaluated by a group of medical professionals.",,978-0-9893193-1-7,10.1109/SAI.2014.6918271,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6918271,Medical Education;Virtual Reality;Anatomy;3D;Heart,Heart;Three-dimensional displays;Solid modeling;Educational institutions;Biomedical imaging;Visualization,biomedical education;computer based training;data visualisation;medical computing;virtual reality,virtual reality;medical training system;anatomy education;medical education;training environments;3-dimensional relations;3D visualisation system,,18,,25,,9-Oct-14,,,IEEE,IEEE Conferences
A Training System of Orientation and Mobility for Blind People Using Acoustic Virtual Reality,Y. Seki; T. Sato,"Human Technology Research Institute, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Ibaraki, Japan; College of Rehabilitation for the Blind, National Rehabilitation Center for Persons with Disabilities, Tokorozawa, Saitama, Japan",IEEE Transactions on Neural Systems and Rehabilitation Engineering,7-Feb-11,2011,19,1,95,104,"A new auditory orientation training system was developed for blind people using acoustic virtual reality (VR) based on a head-related transfer function (HRTF) simulation. The present training system can reproduce a virtual training environment for orientation and mobility (O&M) instruction, and the trainee can walk through the virtual training environment safely by listening to sounds such as vehicles, stores, ambient noise, etc., three-dimensionally through headphones. The system can reproduce not only sound sources but also sound reflection and insulation, so that the trainee can learn both sound location and obstacle perception skills. The virtual training environment is described in extensible markup language (XML), and the O&M instructor can edit it easily according to the training curriculum. Evaluation experiments were conducted to test the efficiency of some features of the system. Thirty subjects who had not acquired O&M skills attended the experiments. The subjects were separated into three groups: a no-training group, a virtual-training group using the present system, and a real-training group in real environments. The results suggested that virtual-training can reduce ‚Äúveering‚Äù more than real-training and also can reduce stress as much as real training. The subjective technical and anxiety scores also improved.",1558-0210,,10.1109/TNSRE.2010.2064791,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5559478,Auditory orientation;blindness;head-related transfer function;obstacle perception;orientation and mobility;sound localization;stress pulse ratio,Training;Roads;Coils;Magnetic heads;Acoustics;Knee;Stress measurement,biomechanics;computer based training;handicapped aids;headphones;hearing;medical computing;virtual reality;XML,mobility;blind people;acoustic virtual reality;auditory orientation training system;head-related transfer function;HRTF simulation;listening;headphones;extensible markup language;XML,"Acoustic Stimulation;Acoustics;Blindness;Computer-Assisted Instruction;Equipment Design;Equipment Failure Analysis;Therapy, Computer-Assisted;User-Computer Interface",35,,18,,30-Aug-10,,,IEEE,IEEE Journals
Applying Entertaining Aspects of Serious Game in Medical Training: Systematic Review and Implementation,R. S. Torres; F. L. S. Nunes,"Lab. de Aplic. de Inf. em Saude, Univ. de Sao Paulo, Sao Paulo, Brazil; Lab. de Aplic. de Inf. em Saude, Univ. de Sao Paulo, Sao Paulo, Brazil",2011 XIII Symposium on Virtual Reality,14-Jul-11,2011,,,18,27,"Virtual Reality (VR) has been widely used for medical area applications in order to help students and health care professionals to practice procedures before execute them on real patients. The evaluation of the user's learning is a very important step in any educational process, including systems for medical training. Serious Games are intended to employ entertaining aspects to training, knowledge transfer and simulations. This category of software can provide more motivation in the use of tools for training and also help in the evaluation of the learner. The aim of this paper is to present a serious game as a way to enhance the user experience in the use of medical training tools that use VR. This serious game contains entertaining aspects that are designed to stimulate the student to perform virtually the examination of breast biopsy.",,978-0-7695-4445-8,10.1109/SVR.2011.33,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5951831,framework;realidade virtual;serious games,Games;Instruments;Training;Software;Virtual reality;Mice;Application programming interfaces,biomedical education;computer based training;computer games;medical computing;virtual reality,serious game;medical training;virtual reality;educational process;knowledge transfer,,4,,21,,14-Jul-11,,,IEEE,IEEE Conferences
Mobile Augmented Reality as an Orientation Aid: A Scavenger Hunt Prototype,K. Rogers; J. Frommel; L. Breier; S. Celik; H. Kramer; S. Kreidel; J. Brich; V. Riemer; C. Schrader,"Ulm Univ., Ulm, Germany; Ulm Univ., Ulm, Germany; Ulm Univ., Ulm, Germany; Ulm Univ., Ulm, Germany; Ulm Univ., Ulm, Germany; Ulm Univ., Ulm, Germany; Ulm Univ., Ulm, Germany; Ulm Univ., Ulm, Germany; Ulm Univ., Ulm, Germany",2015 International Conference on Intelligent Environments,13-Aug-15,2015,,,172,175,"Orientation in public environments is a critical skill for new arrivals, yet also one that is usually only learned gradually through trial and error. This paper suggests the use of pervasive augmented reality (AR) for the design of a serious game that teaches navigational skills in a public environment. Many AR scavenger hunt games confront players with new environments by default, however they rarely focus explicitly on teaching navigational skills. We propose a concept that utilises augmented reality techniques for increased immersion and motivation, while upholding the real-world sense of presence for an easy transfer of orientation skills to everyday life. For this purpose, we implemented a first prototypical serious game in the form of an AR scavenger hunt. A preliminary evaluation regarding its usability produced promising results. As such, the prototype constitutes a first proof of concept. In future iterations, it will be further developed as an adaptive AR serious game, and evaluated in respect to its efficacy in teaching orientation and navigation skills.",,978-1-4673-6654-0,10.1109/IE.2015.37,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194292,,Games;Navigation;Prototypes;Augmented reality;Usability;Education;Cities and towns,augmented reality;computer aided instruction;graphical user interfaces;mobile learning;serious games (computing);teaching,navigation skills;teaching orientation;adaptive AR serious game;orientation skills transfer;AR scavenger hunt games;navigational skills teaching;serious game design;pervasive augmented reality;critical skill;public environments;scavenger hunt prototype;orientation aid;mobile augmented reality,,6,,24,,13-Aug-15,,,IEEE,IEEE Conferences
A Deep Cybersickness Predictor Based on Brain Signal Analysis for Virtual Reality Contents,J. Kim; W. Kim; H. Oh; S. Lee; S. Lee,Yonsei University; Yonsei University; Electronics & Telecommunications Research Institute; Yonsei University; Yonsei University. Korea,2019 IEEE/CVF International Conference on Computer Vision (ICCV),27-Feb-20,2019,,,10579,10588,"What if we could interpret the cognitive state of a user while experiencing a virtual reality (VR) and estimate the cognitive state from a visual stimulus? In this paper, we address the above question by developing an electroencephalography (EEG) driven VR cybersickness prediction model. The EEG data has been widely utilized to learn the cognitive representation of brain activity. In the first stage, to fully exploit the advantages of the EEG data, it is transformed into the multi-channel spectrogram which enables to account for the correlation of spectral and temporal coefficient. Then, a convolutional neural network (CNN) is applied to encode the cognitive representation of the EEG spectrogram. In the second stage, we train a cybersickness prediction model on the VR video sequence by designing a Recurrent Neural Network (RNN). Here, the encoded cognitive representation is transferred to the model to train the visual and cognitive features for cybersickness prediction. Through the proposed framework, it is possible to predict the cybersickness level that reflects brain activity automatically. We use 8-channels EEG data to record brain activity while more than 200 subjects experience 44 different VR contents. After rigorous training, we demonstrate that the proposed framework reliably estimates cognitive states without the EEG data. Furthermore, it achieves state-of-the-art performance comparing to existing VR cybersickness prediction models.",2380-7504,978-1-7281-4803-8,10.1109/ICCV.2019.01068,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010856,,Electroencephalography;Brain modeling;Spectrogram;Visualization;Predictive models;Solid modeling;Feature extraction,cognition;convolutional neural nets;electroencephalography;image sequences;medical image processing;recurrent neural nets;video signal processing;virtual reality,VR video sequence;recurrent neural network;cognitive representation;visual features;cognitive features;cybersickness level;brain activity;8-channels EEG data;cognitive state;deep cybersickness predictor;brain signal analysis;virtual reality contents;visual stimulus;VR cybersickness prediction model;multichannel spectrogram;spectral coefficient;temporal coefficient;convolutional neural network;electroencephalography;EEG spectrogram,,7,,32,,27-Feb-20,,,IEEE,IEEE Conferences
Enhancing engineering education through distributed virtual reality,T. Sulbaran; N. C. Baker,"Sch. of Civil & Environ. Eng., Georgia Inst. of Technol., Atlanta, GA, USA; NA",30th Annual Frontiers in Education Conference. Building on A Century of Progress in Engineering Education. Conference Proceedings (IEEE Cat. No.00CH37135),6-Aug-02,2000,2,,S1D/13,S1D/18 vol.2,"Visual interaction can greatly change the way engineering is performed both in learning new materials and in terms of explaining activities between practicing professionals. The paper presents a study to develop and assess distributed virtual reality (DVR) for engineering education. Strategic key criteria are presented followed with the development and assessment of a DVR tool that allows the evaluation of learner issues such as: reading/following instructions, navigation, interaction, responsiveness, knowledge transfer, engagement and acceptance. The results suggest that DVR has the potential for enhancing engineering education. More extensive DVR development and assessment and international distributed deployment will further our understanding of more precise interactions.",0190-5848,0-7803-6424-4,10.1109/FIE.2000.896621,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=896621,,Engineering education;Virtual reality;Internet;IEC standards;ISO standards;Educational institutions;Distributed computing;Engineering students;Navigation;Delay,courseware;teaching;engineering education;engineering computing;virtual reality;distributed processing,engineering education;distributed virtual reality;visual interaction;practicing professionals;strategic key criteria;DVR tool;learner issues;reading;instruction following;navigation;interaction;responsiveness;knowledge transfer;DVR development;international distributed deployment,,4,,15,,6-Aug-02,,,IEEE,IEEE Conferences
A Transferable Adaptive Domain Adversarial Neural Network for Virtual Reality Augmented EMG-Based Gesture Recognition,U. C√¥t√©-Allard; G. Gagnon-Turcotte; A. Phinyomark; K. Glette; E. Scheme; F. Laviolette; B. Gosselin,"Department of Informatics, University of Oslo, Oslo, Norway; Laboratoire de recherche sur les Microsyst√®mes Biom√©dicaux, Universit√© Laval, Quebec, QC, Canada; Angkoon Phinyomark and Erik Scheme~are with the Institute of Biomedical Engineering, University of New Brunswick, Fredericton, NB, Canada; Department of Informatics, University of Oslo, Oslo, Norway; Angkoon Phinyomark and Erik Scheme~are with the Institute of Biomedical Engineering, University of New Brunswick, Fredericton, NB, Canada; D√©partement de G√©nie Electrique et de G√©nie Informatique, Universit√© Laval, Quebec, QC, Canada; Department of Electrical and Computer Engineering, Universit√© Laval, Quebec, QC, Canada",IEEE Transactions on Neural Systems and Rehabilitation Engineering,3-Mar-21,2021,29,,546,555,"Within the field of electromyography-based (EMG) gesture recognition, disparities exist between the off line accuracy reported in the literature and the real-time usability of a classifier. This gap mainly stems from two factors: 1) The absence of a controller, making the data collected dissimilar to actual control. 2) The difficulty of including the four main dynamic factors (gesture intensity, limb position, electrode shift, and transient changes in the signal), as including their permutations drastically increases the amount of data to be recorded. Contrarily, online datasets are limited to the exact EMG-based controller used to record them, necessitating the recording of a new dataset for each control method or variant to be tested. Consequently, this paper proposes a new type of dataset to serve as an intermediate between off line and online datasets, by recording the data using a real-time experimental protocol. The protocol, performed in virtual reality, includes the four main dynamic factors and uses an EMG-independent controller to guide movements. This EMG-independent feedback ensures that the user is in-the-loop during recording, while enabling the resulting dynamic dataset to be used as an EMG-based benchmark. The dataset is comprised of 20 able-bodied participants completing three to four sessions over a period of 14 to 21 days. The ability of the dynamic dataset to serve as a benchmark is leveraged to evaluate the impact of different-recalibration techniques for long-term (across-day) gesture recognition, including a novel algorithm, named TADANN. TADANN consistently and significantly (p <; 0.05) outperforms using fine-tuning as the recalibration technique.",1558-0210,,10.1109/TNSRE.2021.3059741,Natural Sciences and Engineering Research Council of Canada (NSERC); Institut de recherche Robert-Sauv√© en sante et en s√©curit√© du travail (IRSST); Research Council of Norway; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354785,EMG;myoelectric control;gesture recognition;leap motion;transfer learning;virtual reality,Protocols;Virtual reality;Gesture recognition;Electromyography;Three-dimensional displays;Real-time systems;Heuristic algorithms,electromyography;medical signal processing;neural nets;virtual reality,transferable adaptive domain adversarial neural network;virtual reality augmented EMG-based gesture recognition;electromyography-based gesture recognition;real-time usability;gesture intensity;online datasets;exact EMG-based controller;control method;real-time experimental protocol;EMG-independent controller;EMG-independent feedback;dynamic dataset;EMG-based benchmark,,,,62,CCBY,16-Feb-21,,,IEEE,IEEE Journals
Education in Virtual Worlds: Virtual Storytelling,P. Danilicheva; S. Klimenko; Y. Baturin; A. Serebrov,"Inst. of Comput. for Phys. & Technol., Protvino, Russia; Inst. of Comput. for Phys. & Technol., Protvino, Russia; Inst. of Comput. for Phys. & Technol., Protvino, Russia; Inst. of Comput. for Phys. & Technol., Protvino, Russia",2009 International Conference on CyberWorlds,6-Oct-09,2009,,,333,338,"This paper is dedicated to the idea of studying in virtual worlds and discusses how virtual storytelling technology (VST) can provide an educational process. We try to answer the question - is it possible to substitute a real learning environment with a fully immersive 3D virtual space? And if so, what role should a virtual teacher play and what skills should he have? We describe several advantages that virtual environment (VE) has as compared to an ordinary classroom. It enables children to explore a phenomenon involved and gives them a strong incentive to study. Further, in VE we can transfer a lesson to inaccessible places and carry out demonstrations and experiments that are unrealizable on Earth. We consider the relationship between VST and game-like environments. We present some particular educational applications developed at our institute on the basis of Avango VR-system. Finally, we discuss the future of educational virtual environments and virtual storytelling.",,978-1-4244-4864-7,10.1109/CW.2009.57,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5279531,virtual storytelling;interactive narrative;education in virtual worlds;lessons from space,Virtual environment;Educational technology;Paper technology;Space technology;Game theory;Application software;Information systems;Physics education;Physics computing;Earth,computer aided instruction;virtual reality,virtual world;virtual storytelling technology;educational process;learning environment;fully immersive 3D virtual space;virtual teacher;avango VR-system;educational virtual environment,,13,,22,,6-Oct-09,,,IEEE,IEEE Conferences
Pseudo-Haptic Feedback in Teleoperation,C. Neupert; S. Matich; N. Scherping; M. Kupnik; R. Werthsch√ºtzky; C. Hatzfeld,"Haptic Systems Group, Institute of Electromechanical Design, Technische Universit√§t Darmstadt, Darmstadt, Germany; Haptic Systems Group, Institute of Electromechanical Design, Technische Universit√§t Darmstadt, Darmstadt, Germany; Haptic Systems Group, Institute of Electromechanical Design, Technische Universit√§t Darmstadt, Darmstadt, Germany; Haptic Systems Group, Institute of Electromechanical Design, Technische Universit√§t Darmstadt, Darmstadt, Germany; Haptic Systems Group, Institute of Electromechanical Design, Technische Universit√§t Darmstadt, Darmstadt, Germany; Haptic Systems Group, Institute of Electromechanical Design, Technische Universit√§t Darmstadt, Darmstadt, Germany",IEEE Transactions on Haptics,19-May-17,2016,9,3,397,408,"In this paper, we develop possible realizations of pseudo-haptic feedback in teleoperation systems based on existing works for pseudo-haptic feedback in virtual reality and the intended applications. We derive four potential factors affecting the performance of haptic feedback (calculation operator, maximum displacement, offset force, and scaling factor), which are analyzed in three compliance identification experiments. First, we analyze the principle usability of pseudo-haptic feedback by comparing information transfer measures for teleoperation and direct interaction. Pseudo-haptic interaction yields well above-chance performance, while direct interaction performs almost perfectly. In order to optimize pseudo-haptic feedback, in the second study we perform a full-factorial experimental design with 36 subjects performing 6,480 trials with 36 different treatments. Information transfer ranges from 0.68 bit to 1.72 bit in a task with a theoretical maximum of 2.6 bit, with a predominant effect of the calculation operator and a minor effect of the maximum displacement. In a third study, short- and long-term learning effects are analyzed. Learning effects regarding the performance of pseudo-haptic feedback cannot be observed for single-day experiments. Tests over 10 days show a maximum increase in information transfer of 0.8 bit. The results show the feasibility of pseudo-haptic feedback for teleoperation and can be used as design basis for task-specific systems.",2329-4051,,10.1109/TOH.2016.2557331,Deutsche Forschungsgemeinschaft; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7457685,Haptics;pseudo-haptics;teleoperation;medical robotics,Haptic interfaces;Force;Iron;Manipulators;Actuators;Couplings;Virtual environments,haptic interfaces;medical robotics;surgery;telerobotics;virtual reality,pseudo-haptic feedback;teleoperation system;virtual reality;calculation operator;maximum displacement;offset force;scaling factor;compliance identification experiments;information transfer measures;direct interaction;minimal invasive surgery,Adult;Computer Simulation;Equipment Design;Feedback;Female;Humans;Learning;Male;Robotic Surgical Procedures;Robotics;Telemedicine;Touch;User-Computer Interface,9,,29,,21-Apr-16,,,IEEE,IEEE Journals
An Immersive Mobile Application For Improved Learning and Virtual Tour Experience: A Nature Reserve Perspective,C. Oersen; R. Wyngaard; L. Nkabinde,University of Western Cape; University of Western Cape; University of Western Cape,2020 ITU Kaleidoscope: Industry-Driven Digital Transformation (ITU K),30-Dec-20,2020,,,1,8,"The purpose of this study was to develop an immersive virtual reality application for the University of Western Cape's nature reserve in South Africa. For this focus on a nature reserve project, the project team was requested to build a self-guided tour capable of achieving knowledge transfer, and which has aesthetic pleasure. The study was informed by the peculiar challenge of the nature reserve and existing literature to identify gaps that may occur in the body of knowledge. The scrum project methodology was used to manage the life cycle of the project. The application was successfully built within the given time frame and the client's feedback was overwhelmingly positive.",,978-92-61-31391-3,10.23919/ITUK50268.2020.9303226,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9303226,4IR;immersive technology;nature reserve;self-guided tour,Virtual reality;Design methodology,computer aided instruction;geophysics computing;mobile computing;virtual reality,immersive mobile application;improved learning;virtual tour experience;immersive virtual reality;South Africa;nature reserve project;project team;knowledge transfer;Scrum project;University of Western Cape;self-guided tour;project life cycle;client feedback,,,,29,,30-Dec-20,,,IEEE,IEEE Conferences
LadderNet: Knowledge Transfer Based Viewpoint Prediction in 360‚ó¶ Video,P. Zhao; Y. Zhang; K. Bian; H. Tuo; L. Song,"Peking University, Beijing, China; Peking University, Beijing, China; Peking University, Beijing, China; iQIYI Co. Ltd., Beijing, China; Peking University, Beijing, China","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",16-Apr-19,2019,,,1657,1661,"In the past few years, virtual reality (VR) has become an enabling technique, not only for enriching our visual experience but also for providing new channels for businesses. Untethered mobile devices are the main players for watching 360-degree content, thereby the precision of predicting the future viewpoints is one key challenge to improve the quality of the playbacks. In this paper, we investigate the image features of the 360-degree videos and the contextual information of the viewpoint trajectories. Specifically, we design ladder convolution to adapt for the distorted image, and propose LadderNet to transfer the knowledge from the pre-trained model and retrieve the features from the distorted image. We then combine the image features and the contextual viewpoints as the inputs for long short-term memory (LSTM) to predict the future viewpoints. Our approach is compared with several state-of-the-art viewpoint prediction algorithms over two 360-degree video datasets. Results show that our approach can improve the Intersection over Union (IoU) by at least 5% and meeting the requirements of the playback of 360-degree video on mobile devices.",2379-190X,978-1-4799-8131-1,10.1109/ICASSP.2019.8682776,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682776,Untethered virtual reality;image distortion;viewpoint prediction,Trajectory;Streaming media;Strips;Kernel;Convolution;Mobile handsets;Shape,feature extraction;learning (artificial intelligence);mobile computing;user interfaces;video cameras;video recording;video signal processing;virtual reality,LadderNet;pre-trained model;distorted image;image features;contextual viewpoints;future viewpoints;state-of-the-art viewpoint prediction algorithms;360-degree video datasets;playback;knowledge transfer based viewpoint prediction;virtual reality;enabling technique;visual experience;untethered mobile devices;main players;360-degree content;contextual information;viewpoint trajectories;design ladder convolution;intersection over union;IoU,,3,,19,,16-Apr-19,,,IEEE,IEEE Conferences
Qualitative Prediction and Recognition of ongoing Human Action Sequences Using Deep Neural Networks,M. V. K; R. K. Thandil; M. B. K. P,"Sullamussalam Science College,Department of Computer Science,Areekode,India; Sullamussalam Science College,Department of Computer Science,Areekode,India; Sullamussalam Science College,Department of Computer Science,Areekode,India",2020 3rd International Conference on Intelligent Sustainable Systems (ICISS),18-Jan-21,2020,,,605,610,"Human action detection (HAD) is an important research area in the recent decades that can be applied in many applications such as security, gaming, virtual reality interfaces, surveillance systems, etc. The authors have used object detection algorithms with deep neural network-based classifiers in this experiment. Further, the proposed research work aims to explore the solutions for object detection in HAD. The model has been provided with a set of images, wherein each image, a person will be performing an activity such as standing, sitting, bending, waving, or sleeping. The label of an image will be the activity that is being performed in those images. The model will learn this relationship, and then it can predict the label of an input that it has never seen. The model is trained and tested with a dataset consisting of random images downloaded from the internet.",,978-1-7281-7089-3,10.1109/ICISS49785.2020.9315962,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9315962,Object detection;human action recognition;faster R-CNN;machine learning;transfer learning,Training;Computational modeling;Object detection;Proposals;Solid modeling;Feature extraction;Predictive models,deep learning (artificial intelligence);image motion analysis;image recognition;image sequences;object detection;virtual reality,human action sequences;human action detection;virtual reality interfaces;surveillance systems;object detection algorithms;deep neural network-based classifiers;random images;qualitative prediction;HAD;internet,,,,25,,18-Jan-21,,,IEEE,IEEE Conferences
An Augmented Social Interactive Learning Approach through Web2.0,L. Jin; Z. Wen,"Sch. of Comput. Sci., Univ. of Westminster, London, UK; Imagination Technol. Ltd., Watford, UK",2009 33rd Annual IEEE International Computer Software and Applications Conference,22-Sep-09,2009,1,,607,611,"With the rapid development of the Internet, Web2.0 as the next generation of networking services emphasizes social interaction and share of user-generated content in a collaborative environment. It has evolved and transferred the Internet into a platform by supporting rich digital media technology for the development of innovative business and educational applications. In conjunction with Web 3D technology, social networking has already begun to foster an intuitive and immersive system that allows effective visual communication and delivers real time natural interactive experience for enhancing user motivation and engagement compared with the traditional static and text-oriented Web. This paper presents an augmented social interactive learning approach to incorporating social networking services on Web2.0 into traditional distance learning and on-site teaching for blended learning. This paper also discusses the key issues including user interaction and communication forms and examines different educational activities involving user content generation, e-tutoring, and role-playing.",0730-3157,978-0-7695-3726-9,10.1109/COMPSAC.2009.86,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5254206,Social networking;e-Learning,Social network services;IP networks;Web and internet services;Next generation networking;User-generated content;Collaboration;Educational technology;Visual communication;Real time systems;Computer aided instruction,augmented reality;computer aided instruction;distance learning;groupware;human computer interaction;human factors;social networking (online);teaching,augmented social interactive learning approach;Web2.0;Internet platform;social networking service;user-generated content sharing;collaborative environment;digital media technology;innovative business application development;innovative educational application development;3D social virtual world;immersive system;visual communication;real-time natural interactive experience;user motivation;user engagement;static text-oriented Web;distance learning;on-site teaching;blended learning;user interaction;e-tutoring;user role-playing;e-learning,,3,,17,,22-Sep-09,,,IEEE,IEEE Conferences
Visual and Haptic Error Modulating Controllers for Robotic Gait Training,P. Tsangaridis; D. Obwegeser; S. Maggioni; R. Riener; L. Marchal-Crespo,"Department of Health Sciences and Technology (HEST), Sensory-Motor Systems (SMS) Lab, Zurich, ETH, Switzerland; Department of Health Sciences and Technology (HEST), Sensory-Motor Systems (SMS) Lab, Zurich, ETH, Switzerland; Department of Health Sciences and Technology (HEST), Sensory-Motor Systems (SMS) Lab, Zurich, ETH, Switzerland; Department of Health Sciences and Technology (HEST), Sensory-Motor Systems (SMS) Lab, Zurich, ETH, Switzerland; University of of Bern, The Gerontechnology and Rehabilitation group, ARTORG Center for Biomedical Engineering Research, Switzerland",2018 7th IEEE International Conference on Biomedical Robotics and Biomechatronics (Biorob),11-Oct-18,2018,,,1050,1055,"Robotic algorithms that augment movement errors have been proposed as promising training strategies to enhance motor training and neurorehabilitation. However, research effort has mainly focused on rehabilitation of upper limbs. In this study, we investigated the effect of training with novel error modulating strategies on learning an asymmetric gait pattern. Thirty healthy young participants walked in the robotic exoskeleton Lokomat, while learning a foot target-tracking task which required an increased hip and knee flexion in the dominant leg. Learning with three different strategies was evaluated: (i) No guidance: no disturbance/guidance was applied, (ii) Haptic error amplification: dangerous and discouraging large errors were limited with haptic guidance, while awareness of task relevant errors was enhanced with error amplification, and (iii) Visual error amplification: visually perceived errors were amplified in a virtual reality environment. We also evaluated whether increasing the movement variability during training by adding randomly-varying haptic disturbances on top of the other training strategies further enhanced learning. We found that training with the novel haptic error amplification strategy limited large errors during training, did not hamper learning and enhanced transfer of the learned asymmetric gait pattern. Training with visual error amplification, on the other hand, increased errors during training and hampered motor learning. Adding haptic disturbances did not have a significant effect on learning. The novel haptic error modulating controller that amplifies small task-relevant errors while limiting large errors provided the best framework to enhance motor learning.",2155-1782,978-1-5386-8183-1,10.1109/BIOROB.2018.8488011,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8488011,,Training;Haptic interfaces;Legged locomotion;Visualization;Task analysis;Trajectory,gait analysis;haptic interfaces;learning (artificial intelligence);medical robotics;neurophysiology;patient rehabilitation;virtual reality,task-relevant errors;visual error modulating controllers;haptic error modulating controllers;novel haptic error modulating controller;hampered motor learning;increased errors;learned asymmetric gait pattern;enhanced transfer;novel haptic error amplification strategy;enhanced learning;haptic disturbances;visually perceived errors;visual error amplification;task relevant errors;haptic guidance;disturbance/guidance;different strategies;knee flexion;increased hip;foot target-tracking task;robotic exoskeleton Lokomat;thirty healthy young participants;motor training;promising training strategies;augment movement errors;robotic algorithms;robotic gait training,,,,26,,11-Oct-18,,,IEEE,IEEE Conferences
Human-like Planning for Reaching in Cluttered Environments,M. Hasan; M. Warburton; W. C. Agboh; M. R. Dogar; M. Leonetti; H. Wang; F. Mushtaq; M. Mon-Williams; A. G. Cohn,"University of Leeds,School of Computing,UK; University of Leeds,School of Psychology,UK; University of Leeds,School of Computing,UK; University of Leeds,School of Computing,UK; University of Leeds,School of Computing,UK; University of Leeds,School of Computing,UK; University of Leeds,School of Psychology,UK; University of Leeds,School of Psychology,UK; University of Leeds,School of Computing,UK",2020 IEEE International Conference on Robotics and Automation (ICRA),15-Sep-20,2020,,,7784,7790,"Humans, in comparison to robots, are remarkably adept at reaching for objects in cluttered environments. The best existing robot planners are based on random sampling of configuration space- which becomes excessively high-dimensional with large number of objects. Consequently, most planners often fail to efficiently find object manipulation plans in such environments. We addressed this problem by identifying high-level manipulation plans in humans, and transferring these skills to robot planners. We used virtual reality to capture human participants reaching for a target object on a tabletop cluttered with obstacles. From this, we devised a qualitative representation of the task space to abstract the decision making, irrespective of the number of obstacles. Based on this representation, human demonstrations were segmented and used to train decision classifiers. Using these classifiers, our planner produced a list of waypoints in task space. These waypoints provided a high-level plan, which could be transferred to an arbitrary robot model and used to initialise a local trajectory optimiser. We evaluated this approach through testing on unseen human VR data, a physics-based robot simulation, and a real robot (dataset and code are publicly available1). We found that the human-like planner outperformed a state-of-the-art standard trajectory optimisation algorithm, and was able to generate effective strategies for rapid planning- irrespective of the number of obstacles in the environment.",2577-087X,978-1-7281-7395-5,10.1109/ICRA40945.2020.9196665,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9196665,,Task analysis;Planning;Robots;Testing;Feature extraction;Trajectory;Standards,collision avoidance;decision making;dexterous manipulators;grippers;learning (artificial intelligence);planning (artificial intelligence);robot programming;robot vision;trajectory control;virtual reality,decision making;decision classifiers;cluttered environments;robot planners;random sampling;object manipulation plans;virtual reality;trajectory optimisation;physics based robot simulation;human-like planning;depth camera;Robotiq two finger gripper,,,,31,,15-Sep-20,,,IEEE,IEEE Conferences
Face to face with the white rabbit - sharing ideas in Second Life,P. Rive; M. Billinghurst; A. Thomassen; M. Lyons,"Victoria University of Wellington, New Zealand; University of Canterbury New Zealand; Victoria University of Wellington, New Zealand; Victoria University of Wellington, New Zealand",2008 IEEE International Professional Communication Conference,16-Dec-08,2008,,,1,14,"The popular virtual world, second life, presents a number of opportunities and limitations for the sharing of ideas in the information economy. In this paper we ask the question, dasiato what extent can second life simulate an actual face-to-face meeting?psila Many authors have written that tacit knowledge transfer requires face-to-face meetings, however, virtual reality technology can provide tools that enable people to show facial expressions, body language and concepts in graphical form. In this way it is possible to use computer mediated communication to convey nonverbal information that would normally be very difficult to share remotely. In this paper we explore how closely second life can simulate actual face-to-face communication. We give examples of lessons learned from students learning in second life, and make recommendations on how to support natural communication in online environments.",2158-1002,978-1-4244-2085-8,10.1109/IPCC.2008.4610236,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4610236,Second Life;virtual world;nonverbal communications;presence;tacit knowledge,,virtual reality,virtual world;information economy;second life simulation;knowledge transfer;facial expressions;computer mediated communication;face-to-face communication;online environments,,4,,83,,16-Dec-08,,,IEEE,IEEE Conferences
Camera Motion Style Transfer,C. Kurz; T. Ritschel; E. Eisemann; T. Thorm√§hlen; H. Seidel,"MPI Inf., Saarbr√ºcken, Germany; CNRS-LTCI, Telecom ParisTech, Paris, France; CNRS-LTCI, Telecom ParisTech, Paris, France; MPI Inf., Saarbr√ºcken, Germany; MPI Inf., Saarbr√ºcken, Germany",2010 Conference on Visual Media Production,20-Jan-11,2010,,,9,16,"When depicting both virtual and physical worlds, the viewer's impression of presence in these worlds is strongly linked to camera motion. Plausible and artist-controlled camera movement can substantially increase scene immersion. While physical camera motion exhibits subtle details of position, rotation, and acceleration, these details are often missing for virtual camera motion. In this work, we analyze camera movement using signal theory. Our system allows us to stylize a smooth user-defined virtual base camera motion by enriching it with plausible details. A key component of our system is a database of videos filmed by physical cameras. These videos are analyzed with a camera-motion estimation algorithm (structure-from-motion) and labeled manually with a specific style. By considering spectral properties of location, orientation and acceleration, our solution learns camera motion details. Consequently, an arbitrary virtual base motion, defined in any conventional animation package, can be automatically modified according to a user-selected style. As shown in our experiments, the resulting shots are still fully artist-controlled, but appear richer and more physically plausible.",,978-1-4244-8872-8,10.1109/CVMP.2010.9,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5693126,style transfer;camera shake;camera motion estimation;structure-from-motion,Cameras;Videos;Databases;Animation;Time frequency analysis;Motion pictures;Three dimensional displays,cameras;image motion analysis;virtual reality,camera motion style transfer;virtual worlds;physical worlds;camera movement;scene immersion;user-defined virtual base camera motion;camera-motion estimation algorithm,,,,39,,20-Jan-11,,,IEEE,IEEE Conferences
A Framework for Collaborative Real-Time 3D Teleimmersion in a Geographically Distributed Environment,G. Kurillo; R. Vasudevan; E. Lobaton; R. Bajcsy,"Dept. of Electr. Eng. & Comput. Sci., Univ. of California, Berkeley, CA; Dept. of Electr. Eng. & Comput. Sci., Univ. of California, Berkeley, CA; Dept. of Electr. Eng. & Comput. Sci., Univ. of California, Berkeley, CA; Dept. of Electr. Eng. & Comput. Sci., Univ. of California, Berkeley, CA",2008 Tenth IEEE International Symposium on Multimedia,9-Jan-09,2008,,,111,118,"In this paper, we present a framework for immersive 3D video conferencing and geographically distributed collaboration. Our multi-camera system performs a full-body 3D reconstruction of users in real time and renders their image in a virtual space allowing remote interaction between users and the virtual environment. The paper features an overview of the technology and algorithms used for calibration, capturing, and reconstruction. We introduce stereo mapping using adaptive triangulation which allows for fast (under 25 ms) and robust real-time 3D reconstruction. The chosen representation of the data provides high compression ratios for transfer to a remote site. The algorithm produces partial 3D meshes, instead of dense point clouds, which are combined on the renderer to create a unified model of the user. We have successfully demonstrated the use of our system in various applications such as remote dancing and immersive Tai Chi learning.",,978-0-7695-3454-1,10.1109/ISM.2008.32,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4741155,remote collaboration;teleimmersion;3D reconstruction;real-time systems,Collaboration;Image reconstruction;Space technology;Videoconference;Real time systems;Rendering (computer graphics);Virtual environment;Paper technology;Calibration;Stereo image processing,data compression;distributed processing;image reconstruction;image representation;teleconferencing;video communication;video signal processing;virtual reality,collaborative real-time 3D teleimmersion;geographically distributed environment;3D video conferencing;multicamera system;full-body 3D reconstruction;stereo mapping;adaptive triangulation;partial 3D meshes;immersive Tai Chi learning;remote dancing,,9,4,24,,9-Jan-09,,,IEEE,IEEE Conferences
The participatory design of a simulation training game,H. Lukosch; T. van Ruijven; A. Verbraeck,"Delft University of Technology, Jaffalaan 5 2600 GA Delft, The Netherlands; Delft University of Technology, Jaffalaan 5 2600 GA Delft, The Netherlands; Delft University of Technology Jaffalaan 5 2600 GA Delft, The Netherlands",Proceedings of the 2012 Winter Simulation Conference (WSC),21-Feb-13,2012,,,1,11,"Serious games show to have positive impact on training results. Advantages of simulation games lay in the provision of a safe training environment, where users are able to play, test and probe without serious consequences. At the same time, it is important to engage learners by providing a motivating, challenging environment, which becomes meaningful to the player when skills and knowledge acquired within the game are transferrable to real work tasks. With the use of a participatory game design approach, we developed an immersive, meaningful virtual training environment to improve situational awareness skills. Feedback of game developers as well as from test groups shows that the participatory approach to game development lead to a meaningful experience within an authentic virtual training environment. High functional and physical fidelity, a high degree of realism, compared with challenging game elements makes the developed serious game an appropriate training tool for situational awareness skills.",1558-4305,978-1-4673-4782-2,10.1109/WSC.2012.6465218,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6465218,,Games;Training;Security;Engines;Prototypes;Context;Educational institutions,computer based training;computer games;knowledge management;virtual reality,simulation training games;knowledge transfer;participatory game design approach;virtual training environment;situational awareness skills;game developers;test groups;game development;physical fidelity;functional fidelity;safe training environment,,13,,25,,21-Feb-13,,,IEEE,IEEE Conferences
FES-based upper-limb stroke rehabilitation with advanced sensing and control,M. Kutlu; C. T. Freeman; E. Hallewell; A. Hughes; D. S. Laila,"Electronics and Computer Science, University of Southampton, UK, SO17 1BJ; Electronics and Computer Science, University of Southampton, UK, SO17 1BJ; Health Sciences, University of Southampton, UK, SO17 1BJ; Health Sciences, University of Southampton, UK, SO17 1BJ; Engineering Sciences, University of Southampton, UK, SO17 1BJ",2015 IEEE International Conference on Rehabilitation Robotics (ICORR),1-Oct-15,2015,,,253,258,"Functional electrical stimulation (FES) has shown effectiveness in restoring movement post-stroke when applied to assist participants' voluntary action during repeated, motivating tasks. Recent clinical trials have used advanced controllers that precisely adjust FES to assist functional reach and grasp tasks, showing significant reduction in impairment. The system reported in this paper advances the state-of-the-art by: (1) integrating an FES electrode array on the forearm to assist complex hand and wrist gestures; (2) utilising non-contact PrimeSense and Kinect sensors to accurately record the arm, hand and wrist position in 3D; and (3) employing an interactive touch table to present motivating virtual reality (VR) tasks. Feasibility of the system has been evaluated in clinical trials with 4 hemiparetic, chronic stroke participants. Results show that performance error reduced across all tasks and confirm the feasibility of applying precisely controlled FES to multiple muscle groups in the upper limb using advanced sensors, controllers and array hardware. This low-cost, compact technology hence has potential to be transferred to participants' homes in order to reduce upper-limb impairment following chronic stroke.",1945-7901,978-1-4799-1808-9,10.1109/ICORR.2015.7281208,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7281208,Stroke Rehabilitation;Functional Electrical Stimulation;Iterative Learning Control;Sensing Technology,Joints;Electrodes;Wrist;Muscles;Arrays;Hardware;Sensors,biosensors;electrodes;medical computing;medical control systems;patient rehabilitation;virtual reality,upper-limb stroke rehabilitation;functional electrical stimulation;movement post-stroke;FES electrode array;hand gesture;wrist gesture;noncontact PrimeSense;Kinect sensors;interactive touch table;virtual reality;performance error;upper limb;array hardware;upper-limb impairment;chronic stroke,,2,,18,,1-Oct-15,,,IEEE,IEEE Conferences
Beyond DoD: non-defense training and education applications of DIS,E. A. Fitzsimmons; J. D. Fletcher,"Office of Sci. & Technol. Policy, Washington, DC, USA; NA",Proceedings of the IEEE,6-Aug-02,1995,83,8,1179,1187,"Networked simulation for education and training is discussed as a functional capability though which distributed interactive simulation (DIS) may find application in the non-defense world. Effectiveness of networked simulation in defense education and training applications has yet to be conclusively demonstrated, but studies completed thus far have yielded positive results. Results from non-defense applications are also likely to be positive. The characteristics of networked simulation that are relevant to its transfer to non-defense applications include a focus on group performance, physical dispersion of participants, requirements for real-time response, emergent task environments, visual task environments, accessible performance data, provisions for practice, immersive realism, and interactions with many entities. These characteristics are matched with potential, non-defense applications of networked simulation such as training for crews, teams, and units, edutainment, education, training, school-to-work transitions, and lifelong learning. Remaining issues include further development of technical standards, legal standards, research and development, fiscal and regulatory policies, and development of the communications infrastructure.<>",1558-2256,,10.1109/5.400457,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=400457,,US Department of Defense;Computational modeling;Computer simulation;Communication standards;Standards development;Computer networks;Military computing;Safety;Stress;Law,computer based training;training;computer aided instruction;digital simulation;simulation;standards;interactive systems;legislation;groupware;local area networks,nondefense training applications;nondefense education applications;DIS;functional capability;networked simulation;distributed interactive simulation;group performance;physical participant dispersion;real-time response;emergent task environments;visual task environments;accessible performance data;practice provisions;immersive realism;interactions;crews;teams;units;edutainment;school-to-work transitions;lifelong learning;technical standards,,4,,22,,6-Aug-02,,,IEEE,IEEE Journals
Developing an Evaluation Methodology for Immersive Learning Experiences in a Virtual World,S. de Freitas; G. Rebolledo-Mendez; F. Liarokapis; G. Magoulas; A. Poulovassilis,"Serious Games Inst., Coventry Univ., Coventry; Serious Games Inst., Coventry Univ., Coventry; NA; NA; NA",2009 Conference in Games and Virtual Worlds for Serious Applications,26-Jun-09,2009,,,43,50,"This article proposes an evaluation methodology for supporting the development of specified learning activities in virtual worlds, based upon inductive methods and augmented by the four dimensional framework. The study undertaken aimed to test the efficacy of the evaluation methodology and to evaluate the broader uses of Second Life for supporting lifelong learners in their educational choices and career decisions. The paper presents the findings of the study and argues that virtual worlds are reorganising how we relate to the design and delivery of learning. This is opening up a transition in learning predicated upon the notion of learning as made up of immersive experiences rather than sets of knowledge to be transferred between tutor and learner. The challenge for tutors remains in the design and delivery of these activities and experience and the approach advocated here builds upon an incremental testing and evaluation of virtual world learning experiences.",,978-0-7695-3588-3,10.1109/VS-GAMES.2009.41,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5116552,Evaluation methodologies;virtual worlds;serious games,Life testing;Second Life;Engineering profession,educational computing;virtual reality,evaluation methodology;immersive learning experience;inductive method;4D framework;Second Life;ducational choices;career decisions;tutors;virtual world learning experience,,28,,16,,26-Jun-09,,,IEEE,IEEE Conferences
Multimodal interface for temporal pattern based interactive large volumetric visualization,P. Kumar; A. Agrawal; S. Prasad,"Indian Institute of Information Technology, Allahabad, India; Indian Institute of Information Technology, Allahabad, India; Nanyang Technical University, Singapore",TENCON 2017 - 2017 IEEE Region 10 Conference,21-Dec-17,2017,,,1239,1244,"Scientific data visualization is a prominent area of research in the development of Virtual Reality Applications in order to make it more interactive and robotic. But the efficient interaction with the large size of medical data is a challenging task to diagnose virtual surgerical environment learning for a Physician. In this paper, we proposed a multimodal interface for GPU-accelerated interactive large scale volumetric data rendering to overcome this limitation. The large data has been pre-processed by octree method. An improved raycasting algorithm is used in association with a transfer function classification method for the effective rendering. The temporal data is used for defining gestures, retrieving in a pattern from the wearable device for providing multimodality with the large rendered data. A gesture vocabulary has been defined by these patterns for the navigation in visualizing the large scale medical data, which consists of five complex interactive postures used for Normal, Picking, Rotation, Dragging, and Zooming gestures. These gesture vocabularies have been categorized by kNN classification method of pattern recognition. Experimental results of the proposed approach are analyzed with the help of various ANOVA and T-testing graphs using SPSS 20 version tool and confidence interval of interaction with hand gestures vocabulary. The results of proposed approach are further compared with the existing approaches in which Microsoft Kinect and P5 dataglove have been used. The proposed system has been navigated by the DG5 VHand 2.0 Bluetooth version hand dataglove as wearable assistive device to achieve an effective interaction. The system has been tested on 10 different sizes of volume datasets ranging from 10MB to 3.15 GB. The scope of this paper is basically to develop system training with robotic arm in medical domain.",2159-3450,978-1-5090-1134-6,10.1109/TENCON.2017.8228047,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8228047,Hand DataGlove;Volume Rendering;Human-Computer Interaction;Multimodal Inteface;Medical Dataset;Large scale,Data visualization;Three-dimensional displays;Virtual reality;Rendering (computer graphics);Thumb;Vocabulary;Biomedical imaging,Bluetooth;data gloves;data visualisation;feature extraction;gesture recognition;human computer interaction;interactive systems;medical computing;octrees;pattern classification;rendering (computer graphics);surgery;virtual reality,multimodal interface;temporal pattern;interactive large volumetric visualization;scientific data visualization;interactive large scale volumetric data rendering;octree method;improved raycasting algorithm;transfer function classification method;wearable device;multimodality;rendered data;gesture vocabulary;complex interactive postures;kNN classification method;pattern recognition;DG5 VHand 2.0 Bluetooth version hand dataglove;wearable assistive device;virtual reality applications;zooming gesture;normal gesture;picking gesture;rotation gesture;dragging gesture;hand gesture vocabulary;virtual surgical environment,,1,,17,,21-Dec-17,,,IEEE,IEEE Conferences
Virtual lesson and its application to virtual calligraphy system,K. Henmi; T. Yoshikawa,"Dept. of Mech. Eng., Kyoto Univ., Japan; NA",Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No.98CH36146),6-Aug-02,1998,2,,1275,1280 vol.2,"The concept of a virtual lesson is proposed for transferring a teacher's skill to a student using haptic virtual reality technology. We have developed a virtual calligraphy system as one of its applications. In this system, the position and force trajectories of the teacher's writing brush is recorded first and then these trajectories are displayed to the student. What the student can learn is the teacher's horizontal brush position trajectory, his normal pushing force against a virtual paper, and the distance between the teacher's brush and the virtual paper. Recognizing that it is impossible to display both the normal force information and the normal position information at the same time, we have implemented two methods of skill display: one is to use the haptic display device for displaying the position information, and the other is to use it for displaying the force information. The remaining information is displayed using a secondary display device, visual display in the developed system. A preliminary experimental result is also presented.",1050-4729,0-7803-4300-X,10.1109/ROBOT.1998.677278,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=677278,,Education;Computer displays;Brushes;Haptic interfaces,virtual reality;computer aided instruction,virtual calligraphy system;virtual lesson;teacher's skill;haptic virtual reality technology;force trajectories;writing brush;student;horizontal brush position trajectory;normal pushing force;virtual paper;skill display,,65,,17,,6-Aug-02,,,IEEE,IEEE Conferences
Specification and design of a new haptic interface for maxillo facial surgery,F. Gosselin; F. Ferlay; S. Bouchigny; C. M√©gard; F. Taha,"CEA, LIST, Interactive Robotics Laboratory, 18, route du Panorama, BP6, 92265 Fontenay-aux-Roses, France; CEA, LIST, Sensory and Ambient Interfaces Laboratory, 18, route du Panorama, BP6, 92265 Fontenay-aux-Roses, France; CEA, LIST, Sensory and Ambient Interfaces Laboratory, 18, route du Panorama, BP6, 92265 Fontenay-aux-Roses, France; CEA, LIST, Sensory and Ambient Interfaces Laboratory, 18, route du Panorama, BP6, 92265 Fontenay-aux-Roses, France; Amiens University Hospital, Department of Oral and Maxillofacial Surgery, Place Victor Pauchet, 80054, France",2011 IEEE International Conference on Robotics and Automation,18-Aug-11,2011,,,737,744,"Multimodal VR training platforms appear as a very promising complement to traditional learning methods for the transfer of skills. The environment is fully controlled and the content of the application, as well as the feedbacks, can be tuned to the performances and progress of the user. The efficiency of this approach depends however on the ability to realistically reproduce the situations encountered in the real world. If not, users could develop false perception-action loops or illusionary conjunctions. This would be detrimental for the transfer of the training to the real world. Our institute, the Lab of applied research on Software-Intensive Technologies from the French Atomic Energy Commission, CEA, LIST, is currently developing such a platform for the training of maxillo facial surgery. As no existing haptic device fits the requirements of this application, we specifically developed a new interface. This paper presents its specification, design and performances.",1050-4729,978-1-61284-385-8,10.1109/ICRA.2011.5980052,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5980052,,Surgery;Wrist;Haptic interfaces;Training;Robots;Actuators;Bones,CAD;haptic interfaces;medical computing;surgery;virtual reality,haptic interface;maxillo facial surgery;multimodal VR training;Lab of applied research on Software-Intensive Technologies;French Atomic Energy Commission;CEA;LIST,,10,1,17,,18-Aug-11,,,IEEE,IEEE Conferences
[Front matter],,,2016 22nd International Conference on Virtual System & Multimedia (VSMM),28-Feb-17,2016,,,I,X,The following topics are dealt with: virtual system; multimedia; architectural history; privacy preservation; medical image; virtual reality; interactive application; patient treatment; Google Glass; AMbiART; cultural heritage; MMO players; independent learning environment; knowledge transfer; drones; serious games; museum; emergency management; elderly; 3D model; digital archive; augmented reality system; location-aware media; image compression; and gamification.,2474-1485,978-1-4673-8993-8,10.1109/VSMM.2016.7863145,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7863145,,,computer aided instruction;computer games;computer graphics;data privacy;geriatrics;humanities;information retrieval systems;knowledge management;medical image processing;patient treatment,architectural history;privacy preservation;medical image;virtual reality;interactive application;patient treatment;Google Glass;AMbiART;cultural heritage;MMO players;independent learning environment;knowledge transfer;drones;serious games;emergency management;elderly;3D model;digital archive;augmented reality system;location-aware media;image compression;gamification;museum,,,,,,28-Feb-17,,,IEEE,IEEE Conferences
Joint Entropy-Based Morphology Optimization of Soft Strain Sensor Networks for Functional Robustness,T. G. Thuruthel; J. Hughes; F. Iida,"Department of Engineering, Bio-Inspired Robotics Lab, University of Cambridge, Cambridge, U.K.; Department of Engineering, Bio-Inspired Robotics Lab, University of Cambridge, Cambridge, U.K.; Department of Engineering, Bio-Inspired Robotics Lab, University of Cambridge, Cambridge, U.K.",IEEE Sensors Journal,14-Aug-20,2020,20,18,10801,10810,"Dense and distributed tactile sensors are critical for robots to achieve human-like manipulation skills. Soft robotic sensors are a potential technological solution to obtain the required high dimensional sensory information unobtrusively. However, the design of this new class of sensors is still based on human intuition or derived from traditional flex sensors. This work is a first step towards automated design of soft sensor morphologies based on optimization of information theory metrics and machine learning. Elementary simulation models are used to develop the optimized sensor morphologies that are more accurate and robust with the same number of sensors. Same configurations are replicated experimentally to validate the feasibility of such an approach for practical applications. Furthermore, we present a novel technique for drift compensation in soft strain sensors that allows us to obtain accurate contact localization. This work is an effort towards transferring the paradigm of morphological computation from soft actuator designing to soft sensor designing for high performance, resilient tactile sensory networks.",1558-1748,,10.1109/JSEN.2020.2995237,"SHERO Project, a Future and Emerging Technologies (FET) Programme of the European Commission; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9094585,Soft robotics;tactile sensors;information entropy;optimization methods;machine learning,Morphology;Strain;Capacitive sensors;Robot sensing systems;Entropy;Robustness,actuators;learning (artificial intelligence);manipulators;mobile robots;optimisation;sensor arrays;strain sensors;tactile sensors;wireless sensor networks,joint entropy-based morphology optimization;soft strain sensor networks;functional robustness;distributed tactile sensors;manipulation skills;soft robotic sensors;human intuition;flex sensors;automated design;soft sensor morphologies;elementary simulation models;optimized sensor morphologies;soft strain sensors;morphological computation;soft actuator;resilient tactile sensory networks;high dimensional sensory information;dense tactile sensors;information theory metric optimization;machine learning;drift compensation;contact localization,,1,,33,CCBY,18-May-20,,,IEEE,IEEE Journals
MOCEM - An 'all in one' tool to simulate SAR image,C. COCHIN; P. POULIGUEN; B. DELAHAYE; D. l. HELLARD; P. GOSSELIN; F. AUBINEAU,"French MoD, DGA / CELAR, Bruz, France; French MoD, DGA / CELAR, Bruz, France; French MoD, DGA / CELAR, Bruz, France; Alyotech/CRIL Technology - Rennes, France; Alyotech/CRIL Technology - Rennes, France; Alyotech/CRIL Technology - Rennes, France",7th European Conference on Synthetic Aperture Radar,1-Jun-11,2008,,,1,4,"MOCEM is a compact SAR image generator that can produce high resolution SAR images from CAD models (VRML, 3DS...) taking into account basic material descriptions. As an innovative approach, this software uses: - an original EM formulation based on the object geometry analysis to build SAR images in a very short computation time. These formulations have been developed by skillful SAR and RCS experts; - an original geometrical algorithm which handles the various facets visibility, including the multiple inner reflections and the interaction with the object surroundings (i.e. ground). SAR images are typically produced in a matter of minutes, using a 2D SAR radar transfer function that takes into account the main parameters of SAR image quality (resolution, Nesigmadeg, tapering). Many studies suffer from the lack of SAR images or control on SAR image content. This tool will interest scientists and labs, working on SAR image features extraction and SAR image analysis. A dedicated version called MOCEM LT has been developed for educational purposes. It offers an attractive way to explain capabilities and limits of SAR images to the scientific community which is more familiar with optical and IR images than radar.",,978-3-8007-3084-7,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5757200,,Solid modeling;Radar imaging;Synthetic aperture radar;Radar cross section;Computational modeling;Image resolution,,,,2,,,,1-Jun-11,,,VDE,VDE Conferences
Haptic Microrobotic Cell Injection System,A. Ghanbari; B. Horan; S. Nahavandi; X. Chen; W. Wang,"Department of Mechanical Engineering, University of Canterbury, Christchurch, New Zealand; School of Engineering, Deakin University, Geelong, Australia; Centre for Intelligent Systems Research, Deakin University, Melbourne, Australia; Department of Mechanical Engineering, University of Canterbury, Christchurch, New Zealand; Department of Mechanical Engineering, University of Canterbury, Christchurch, New Zealand",IEEE Systems Journal,22-May-14,2014,8,2,371,383,"Microrobotic cell injection is the subject of increasing research interest. At present, an operator relies completely on visual information and can be subject to low success rates, poor repeatability, and extended training times. This paper focuses on increasing operator performance during cell injection in two ways. First, our completed haptic cell injection system aims to increase the operator's performance during real-time cell injection. Haptic bilateralism is investigated and a mapping framework provides an intuitive method for manoeuvring the micropipette in a manner similar to handheld needle insertion. Volumetric virtual fixtures are then introduced to haptically assist the operator to penetrate the cell at the desired location. The performance of the volumetric virtual fixtures is also discussed. Second, the haptically enabled cell injection system is replicated as a virtual environment facilitating virtual offline operator training. Virtual operator training utilizes the same mapping framework and haptic virtual fixtures as the physical system allowing the operator to train offline and then directly transfer their skills to real-time cell injection.",1937-9234,,10.1109/JSYST.2012.2206440,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6255757,Haptic cell injection;haptic virtual fixtures;virtual cell injection;virtual operator training;Haptic cell injection;haptic virtual fixtures;virtual cell injection;virtual operator training,Haptic interfaces;Micromanipulators;Hip;Joints;Phantoms;Kinematics;Training,biology computing;control engineering computing;haptic interfaces;microrobots;virtual reality,haptic microrobotic cell injection system;visual information;operator performance;realtime cell injection;haptic bilateralism;mapping framework;micropipette manoeuver;handheld needle insertion;volumetric virtual fixtures;virtual environment;haptic virtual fixtures,,30,,39,,31-Jul-12,,,IEEE,IEEE Journals
"Feedback, Affordances, and Accelerators for Training Sports in Virtual Environments",E. Ruffaldi; B. Bardy; D. Gopher; M. Bergamasco,"PERCRO Lab Scuola Superiore S. Anna 56100 Pisa, Italy; M2H EuroMov Montpellier University France; Technion Haifa, Israel; PERCRO Lab Scuola Superiore S. Anna 56100 Pisa, Italy",Presence,19-May-14,2011,20,1,33,46,"The use of virtual environments (VE) for training sports is quite natural when considering strategic or cognitive aspects. Using VE for sensorimotor training is more challenging, in particular with the difficulty of transferring the task learned in the virtual world to the real. Of special concern for the successful transfer is the adequate combination of training experience protocols and the delivery modes of multimodal feedback. Analyzing feedback in terms of information exchange, this work discusses different feedback combinations and their application to virtual reality training of rowing skills.",1054-7460,,10.1162/pres_a_00034,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6797590,,,,,,5,,,,19-May-14,,,MIT Press,MIT Press Journals
Teleoperating space robots. Impact for the design of industrial robots,G. Hirzinger; B. Brunner; R. Koeppe; K. Landzettel; J. Vogel,"German Aerosp. Res. Establ., Oberpfaffenhofen, Germany; NA; NA; NA; NA",ISIE '97 Proceeding of the IEEE International Symposium on Industrial Electronics,6-Aug-02,1997,1,,SS250,SS256 vol.1,"The paper discusses the features of advanced telerobotic systems. ROTEX-the first remotely controlled spacerobot-serves as kind of a baseline. Future telerobotic systems need powerful man-machine interfaces which allow skill-transfer from human operator to robot and thus may be the foundations for new ways in industrial robot programming. VRML and JAVA open up wide potentials for telerobotic control via the Internet, including teleservicing and telepresence in medicine.",,0-7803-3936-3,10.1109/ISIE.1997.651771,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=651771,,Service robots;Orbital robotics;Telerobotics;Electrical equipment industry;User interfaces;Humans;Medical robotics;Robot programming;Java;Medical control systems,telerobotics;virtual reality;user interfaces;Internet;aerospace control;robot programming;industrial robots;aerospace computing,teleoperating space robots;advanced telerobotic systems;ROTEX;industrial robot design;man-machine interfaces;skill-transfer;robot programming;VRML;JAVA;Internet;teleservicing;telepresence,,3,1,14,,6-Aug-02,,,IEEE,IEEE Conferences
Does virtual-reality training on orthopaedic simulators improve performance in the operating room?,N. Vaughan; V. N. Dubey; T. W. Wainwright; R. G. Middleton,"Faculty of Science and Technology, Bournemouth University (BU) Bournemouth, UK; Faculty of Science and Technology, Bournemouth University (BU) Bournemouth, UK; Department of Orthopaedics, Royal Bournemouth Hospital NHS Foundation Trust, Bournemouth, UK; Department of Orthopaedics, Royal Bournemouth Hospital NHS Foundation Trust, Bournemouth, UK",2015 Science and Information Conference (SAI),3-Sep-15,2015,,,51,54,This paper summarises recent validation studies and evidence demonstrating whether training on virtual reality (VR) simulators directly relates to improved performance in-vivo for orthopaedic surgical procedures. This research provides a summary of transfer validity on virtual reality orthopaedic simulators. This covers studies which have shown validation of simulators and have shown the transfer of simulator-acquired skill to the operating room. The findings of this study are that there are 6 studies showing transfer of skill for VR to in-vivo However more studies assessing efficacy and transfer validity are required to conclusively quantify the transfer validity of VR orthopaedic simulators. However there is a popular positive opinion for the ability of VR training to convert into better in-vivo performance.,,978-1-4799-8547-0,10.1109/SAI.2015.7237125,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7237125,Orthopeadic;Simulator;Transfer validity;Efficacy;Testing;Surgery;Performance,Training;Surgery;Virtual reality;Hip;Solid modeling;Injuries,computer based training;medical computing;orthopaedics;surgery;virtual reality,virtual-reality training;operating room performance;orthopaedic surgical procedures;virtual reality orthopaedic simulators;simulator-acquired skill transfer;VR orthopaedic simulators,,3,,18,,3-Sep-15,,,IEEE,IEEE Conferences
Virtual Reality-Based Casting Skill Transfer and Human Resource Development,K. Watanuki,"Saitama Univ., Saitama",17th International Conference on Artificial Reality and Telexistence (ICAT 2007),2-Jan-08,2007,,,316,317,"This paper proposes a new virtual reality-based skill transfer and human resource development system for casting design, which is composed of the explicit and tacit knowledge transfer systems using synchronized multimedia and the knowledge internalization system using portable virtual environment. In our proposed system, the education content is displayed in the immersive virtual environment, whereby a trainee may experience work in the virtual site operation. Provided that the trainee has gained explicit and tacit knowledge of casting through the multimedia-based knowledge transfer system, the immersive virtual environment catalyzes the internalization of knowledge and also enables the trainee to gain tacit knowledge before undergoing on- the-job training at a real-time operation site.",,0-7695-3056-7,10.1109/ICAT.2007.60,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4414664,,Casting;Humans;Virtual environment;Industrial training;Manufacturing industries;Knowledge transfer;On the job training;Force feedback;Multimedia systems;Libraries,casting;computer based training;design;engineering education;human resource management;industrial training;knowledge management;multimedia systems;multiskilling;on-the-job training;production engineering computing;virtual reality,virtual reality-based casting skill transfer;human resource development system;casting design;multimedia-based knowledge transfer system;education content;immersive virtual environment;training;virtual site operation;on-the-job training,,,,1,,2-Jan-08,,,IEEE,IEEE Conferences
Cognitive psychology and human factors engineering of virtual reality,A. K. T. Ng,"The University of Hong Kong, Hong Kong, China",2017 IEEE Virtual Reality (VR),6-Apr-17,2017,,,407,408,"This position paper summarizes the author's research interest in Cognitive Psychology and Human-Computer Interaction in the imseCAVE, a CAVE-like system in the University of Hong Kong. Several areas of interest were explored while finding the thesis topic for the Ph.D. research. They include a perception research on distance estimation with proposed error correction mechanism, neurofeedback meditation with EEG in VR and the effect with audio and video, the study of training transfer in VR training, the comparison and research of cybersickness between HMD and the imseCAVE, and comparing VR gaming in TV, HMD, and the imseCAVE by performance, activity level and time perception. With a broad interest, the exact direction is still in the search and requires future exploration.",2375-5334,978-1-5090-6647-6,10.1109/VR.2017.7892349,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892349,Virtual environment;cognitive psychology;HCI,Training;Psychology;Resists;Virtual reality;Human factors;Ergonomics;Human computer interaction,cognition;human factors;virtual reality,cognitive psychology;human factors engineering;virtual reality;CAVE-like system;error correction mechanism;neurofeedback meditation;EEG;VR;imseCAVE;distance estimation,,,,13,,6-Apr-17,,,IEEE,IEEE Conferences
Transferability of Spatial Maps: Augmented Versus Virtual Reality Training,N. R. Caluya; A. Plopski; J. F. Ty; C. Sandor; T. Taketomi; H. Kato,"Nara Institute of Science and Technology, Interactive Media Design Laboratory; Nara Institute of Science and Technology, Interactive Media Design Laboratory; Nara Institute of Science and Technology, Interactive Media Design Laboratory; Nara Institute of Science and Technology, Interactive Media Design Laboratory; Nara Institute of Science and Technology, Interactive Media Design Laboratory; Nara Institute of Science and Technology, Interactive Media Design Laboratory",2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),30-Aug-18,2018,,,387,393,"Work space simulations help trainees acquire skills necessary to perform their tasks efficiently without disrupting the workflow, forgetting important steps during a procedure, or the location of important information. This training can be conducted in Augmented and Virtual Reality (AR, VR) to enhance its effectiveness and speed. When the skills are transferred to the actual application, it is referred to as positive training transfer. However, thus far, it is unclear which training, AR or VR, achieves better results in terms of positive training transfer. We compare the effectiveness of AR and VR for spatial memory training in a control-room scenario, where users have to memorize the location of buttons and information displays in their surroundings. We conducted a within-subject study with 16 participants and evaluated the impact the training had on short-term and long-term memory. Results of our study show that VR outperformed AR when tested in the same medium after the training. In a memory transfer test conducted two days later AR outperformed VR. Our findings have implications on the design of future training scenarios and applications.",,978-1-5386-3365-6,10.1109/VR.2018.8447561,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8447561,H.5.1-Information Interfaces and Presentation: Multimedia Information Systems-Artificial;augmented;and virtual realities;H.5.2-Information Interfaces and Presentation: Multimedia Information Systems-Ergonomics;Evaluation/methodology;Theory and methods,Training;Task analysis;Virtual reality;Resists;Layout;Legged locomotion;Media,augmented reality;computer based training,work space simulations;VR;spatial memory training;information displays;long-term memory;memory transfer test;spatial maps;virtual reality training;augmented reality training;training transfer;AR,,,,24,,30-Aug-18,,,IEEE,IEEE Conferences
Distributed virtual environment for intravascular tele-surgery using multimedia telecommunication,F. Arai; M. Tanimoto; T. Fukuda; K. Shimojima; H. Matsuura; M. Negoro,"Dept. of Micro Syst. Eng., Nagoya Univ., Japan; Dept. of Micro Syst. Eng., Nagoya Univ., Japan; Dept. of Micro Syst. Eng., Nagoya Univ., Japan; Dept. of Micro Syst. Eng., Nagoya Univ., Japan; Dept. of Micro Syst. Eng., Nagoya Univ., Japan; NA",Proceedings of the IEEE 1996 Virtual Reality Annual International Symposium,6-Aug-02,1996,,,79,85,"The number of specialized medical doctors is decreasing. It is important to assist doctors in their operation of surgical tools. To solve this problem, we propose a distributed VR system using multimedia telecommunication for training, diagnosis, and assistance in surgery. To realize this system, it is important to exchange high quality moving pictures. We use high speed optical fiber network with ATM (Asynchronous Transfer Mode). ATM has excellent features such as bandwidth allocation which is suitable for multimedia communication on computer networks. Based on this new information infrastructure we built a prototype telesurgery system for intravascular neurosurgery. We made a virtual simulator for the operation of a catheter, that is designed for minimum invasive surgery inside complex and narrow brain blood vessels. A force display and visual assistance method are proposed to assist the doctor. We undertook teleoperation experiments between Nagoya and Tokyo, about 350 km away each other, using high speed optical fiber network, and evaluated the effectiveness of the proposed system.",,0-8186-7296-X,10.1109/VRAIS.1996.490514,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=490514,,Virtual environment;Asynchronous transfer mode;Surgery;Optical fiber networks;Medical diagnostic imaging;Virtual reality;Multimedia systems;Channel allocation;Multimedia communication;Computer networks,surgery;medical computing;multimedia communication;multimedia computing;optical fibre networks;asynchronous transfer mode;virtual reality,distributed virtual environment;intravascular telesurgery;multimedia telecommunication;medical doctors;surgical tools;distributed VR system;training;high quality moving pictures;high speed optical fiber network;ATM;Asynchronous Transfer Mode;bandwidth allocation;multimedia communication;computer networks;telesurgery system;intravascular neurosurgery;virtual simulator;catheter;minimum invasive surgery;visual assistance method;teleoperation experiments,,20,,12,,6-Aug-02,,,IEEE,IEEE Conferences
EMG and Kinematic Responses to Unexpected Slips After Slip Training in Virtual Reality,P. Parijat; T. E. Lockhart; J. Liu,"School of Biomedical Engineering and Science, Virginia Tech, Blacksburg, VA, USA; School of Biological and Health Systems Engineering, Arizona State University, Tempe, AZ, USA; Division of Applied Science and Technology, Marshall University, Huntington, WV, USA",IEEE Transactions on Biomedical Engineering,16-Jan-15,2015,62,2,593,599,"The objective of the study was to design a virtual reality (VR) training to induce perturbation in older adults similar to a slip and examine the effect of the training on kinematic and muscular responses in older adults. Twenty-four older adults were involved in a laboratory study and randomly assigned to two groups (VR training and control). Both groups went through three sessions including baseline slip, training, and transfer of training on slippery surface. The training group experienced 12 simulated slips using a visual perturbation induced by tilting a VR scene while walking on the treadmill and the control group completed normal walking during the training session. Kinematic, kinetic, and electromyography data were collected during all the sessions. Results demonstrated the proactive adjustments such as increased trunk flexion at heel contact after training. Reactive adjustments included reduced time to peak activations of knee flexors, reduced knee coactivation, reduced time to trunk flexion, and reduced trunk angular velocity after training. In conclusion, the study findings indicate that the VR training was able to generate a perturbation in older adults that evoked recovery reactions and such motor skill can be transferred to the actual slip trials.",1558-2531,,10.1109/TBME.2014.2361324,NSF; NIOSH; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6915881,Elderly;electromyography (EMG);fall prevention training;falls;virtual reality (VR),Training;Legged locomotion;Muscles;Electromyography;Knee;Virtual reality;Kinematics,electromyography;gait analysis;kinematics;medical signal processing;perturbation theory;virtual reality,EMG;kinematic responses;unexpected slips;slip training;virtual reality training;older adults;muscular responses;VR training;VR control;baseline slip;slippery surface;visual perturbation;VR scene;treadmill;normal walking;training session;electromyography data collection;proactive adjustments;trunk flexion;heel contact;knee flexors;peak activations;reduced knee coactivation;reduced trunk angular velocity;evoked recovery reactions;motor skill;actual slip trials,"Accidental Falls;Aged;Biofeedback, Psychology;Electromyography;Female;Gait;Humans;Male;Muscle Contraction;Photic Stimulation;Physical Stimulation;Postural Balance;Psychomotor Performance;Treatment Outcome;User-Computer Interface;Virtual Reality Exposure Therapy",13,,33,,3-Oct-14,,,IEEE,IEEE Journals
"Amplified Head Rotation in Virtual Reality and the Effects on 3D Search, Training Transfer, and Spatial Orientation",E. D. Ragan; S. Scerbo; F. Bacim; D. A. Bowman,"Texas A&M University, College Station, TX; Virginia Tech, Blacksburg, VA; Virginia Tech, Blacksburg, VA; Virginia Tech, Blacksburg, VA",IEEE Transactions on Visualization and Computer Graphics,28-Jun-17,2017,23,8,1880,1895,"Many types of virtual reality (VR) systems allow users to use natural, physical head movements to view a 3D environment. In some situations, such as when using systems that lack a fully surrounding display or when opting for convenient low-effort interaction, view control can be enabled through a combination of physical and virtual turns to view the environment, but the reduced realism could potentially interfere with the ability to maintain spatial orientation. One solution to this problem is to amplify head rotations such that smaller physical turns are mapped to larger virtual turns, allowing trainees to view the entire surrounding environment with small head movements. This solution is attractive because it allows semi-natural physical view control rather than requiring complete physical rotations or a fully-surrounding display. However, the effects of amplified head rotations on spatial orientation and many practical tasks are not well understood. In this paper, we present an experiment that evaluates the influence of amplified head rotation on 3D search, spatial orientation, and cybersickness. In the study, we varied the amount of amplification and also varied the type of display used (head-mounted display or surround-screen CAVE) for the VR search task. By evaluating participants first with amplification and then without, we were also able to study training transfer effects. The findings demonstrate the feasibility of using amplified head rotation to view 360 degrees of virtual space, but noticeable problems were identified when using high amplification with a head-mounted display. In addition, participants were able to more easily maintain a sense of spatial orientation when using the CAVE version of the application, which suggests that visibility of the user's body and awareness of the CAVE's physical environment may have contributed to the ability to use the amplification technique while keeping track of orientation.",1941-0506,,10.1109/TVCG.2016.2601607,Office of Naval Research; Virginia Tech Research Computing's Visionarium Lab; VisCube; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7547900,Virtual reality;spatial orientation;rotation amplification;3D interaction;search;cybersickness,Training;Legged locomotion;Three-dimensional displays;Games;Navigation;Visualization;Virtual reality,helmet mounted displays;virtual reality,amplified head rotation;virtual reality;3D search;training transfer;spatial orientation;VR systems;head movements;3D environment;virtual turns;seminatural physical view control;physical rotations;cybersickness;head-mounted display;surround-screen CAVE;VR search task,,13,,53,,19-Aug-16,,,IEEE,IEEE Journals
Transfer Learning algorithm in image analysis with Augmented Reality headset for Industry 4.0 technology,M. Kozek,"AGH University of Science and Technology,Faculty of Mechanical Engineering and Robotics,Krakow,Poland",2020 International Conference Mechatronic Systems and Materials (MSM),22-Sep-20,2020,,,1,5,"Modern technology lines in Industry 4.0 standard use many complex smart systems to improve the speed of production. Manufacturing becomes more flexible and, on the other hand, more demanding for a process operator. This article presents mixed reality glasses that supports the work of the operator integrated via a cloud with a technology line. Transfer learning algorithm is shown in a set of artificial neural network algorithms belonging to the Deep Learning class to analyze the image from ML headset. This algorithm is designed to recognize the current occupation of the storage tray with direct transmission of information to the control and measurement system.",,978-1-7281-6956-9,10.1109/MSM49833.2020.9201739,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201739,machine learning;Industry 4.0;Augmented Reality;Mixed Reality,Robots;Industries;Training;Augmented reality;Headphones;Neural networks,augmented reality;flexible manufacturing systems;image processing;learning (artificial intelligence);neural nets;production engineering computing,cloud computing;flexible manufacturing;smart systems;Industry 4.0 standard;augmented reality headset;image analysis;ML headset;deep learning;artificial neural network;transfer learning;mixed reality glasses,,,,13,,22-Sep-20,,,IEEE,IEEE Conferences
Virtual reality simulation training and assisted surgery: AYRA: Virtual and physical biomodels in surgery,C. Su√°rez-Mej√≠as; G. G. Ciriza; C. P. Calder√≥n; T. G. C√≠a; P. Gacto-S√°nchez,"Innovation Technologies Group, Virgen del Roc√≠o, University Hospital, Seville, Spain; Innovation Technologies Group, Virgen del Roc√≠o, University Hospital, Seville, Spain; Innovation Technologies Group, Virgen del Roc√≠o, University Hospital, Seville, Spain; Plastic and Reconstructive Surgery Department, Virgen del Roc√≠o, University Hospital, Seville, Spain; Plastic and Reconstructive Surgery Department, Virgen del Roc√≠o, University Hospital, Seville, Spain",2012 18th International Conference on Virtual Systems and Multimedia,3-Dec-12,2012,,,437,444,"In this paper we present a surgical application based on virtual reality called AYRA. AYRA allows surgeons training, planning and optimization of surgical procedures. AYRA was developed under a research, development and innovation project financed by the Andalusia Department of Health called VirSSPA. AYRA is very important for the health organization since the surgeons can be trained and helped by AYRA in decision making issues. Nowadays AYRA has been successfully used in more than 489 real cases and surgeons have declared their satisfaction with the results. After proving its efficiency it has been introduced in the clinical practice during the surgical planning sessions at the Virgen del Roc√≠o University Hospital. For example, the use of AYRA reduces by 45 % the complication rate and in two hours the operating room time in breast microvascular reconstruction by DIEAP free flap. The success rate is increased because physicians can see the exact anatomy of the case and the extent of the injury that the patient suffers before proceeding with the surgery. In addition, surgeons can see and interact in 3D with other similar cases made in AYRA by other surgeon colleagues, thus promoting the training of surgeons and the knowledge transfer in this field.",,978-1-4673-2563-9,10.1109/VSMM.2012.6365956,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365956,surgeons training;surgical planning;virtual reality;Computer assisted surgery;Simulation based training;biomodel printing,Surgery;Training;Solid modeling;Planning;Servers;DICOM;Virtual reality,biomedical education;computer based training;digital simulation;injuries;knowledge management;medical computing;surgery;virtual reality,virtual reality simulation training;AYRA;virtual biomodels;physical biomodels;surgical application;innovation project;Andalusia Department of Health;VirSSPA health organization;decision making issues;clinical practice;surgical planning sessions;Virgen del Rocio University Hospital;breast microvascular reconstruction;DIEAP free flap;injury;3D interaction;surgeon training;knowledge transfer;computer assisted surgery,,,,36,,3-Dec-12,,,IEEE,IEEE Conferences
Applied RFID and Virtual Reality Technology in professional training system for manufacturing,S. F. Wong; Z. X. Yang; N. Cao; W. I. Ho,"Department of Electromechanical Engineering, University of Macau, China; Department of Electromechanical Engineering, University of Macau, China; Department of Electromechanical Engineering, University of Macau, China; Department of Electromechanical Engineering, University of Macau, China",2010 IEEE International Conference on Industrial Engineering and Engineering Management,23-Dec-10,2010,,,676,680,"Enhancing the professional knowledge in different levels of operator is a critical success factor to advance the performance of manufacturing industry. However, the traditional training system is lack of scientific method to transfer the professional knowledge (tacit knowledge) to the operator. Applied RFID and Virtual Reality Technology in Knowledge-based Training System can convert the tacit knowledge to the explicit knowledge to different levels of operator. The trainee can capture the basic operation skill through the web-enabled and knowledge-based training system. Moreover, the system can provide the working experience and operation history about the production and tool application to the trainee through RFID technology. They can quickly and conveniently search their target tools that will apply the real manufacturing processes without any human-being supervising. The cost of training resource can be saved, because the workload of supervisor or senior operation is reduced. The senior operation can report the updating and real-time situation of production and tools through RFID technology with knowledge-based training system. The closed loop knowledge can enhance the precision level of analysis results of production system. The industry can be sustainable development through this system.",2157-362X,978-1-4244-8503-1,10.1109/IEEM.2010.5674534,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5674534,RFID;virtual reality technology;knowledge-based training system,Training;Knowledge engineering;Radiofrequency identification;Manufacturing;Computer numerical control;Knowledge based systems;Process control,continuing professional development;industrial training;intelligent tutoring systems;Internet;manufacturing industries;production engineering computing;radiofrequency identification;sustainable development;virtual reality,virtual reality technology;professional training system;professional knowledge enhancement;critical success factor;manufacturing industry;traditional training system;scientific method;tacit knowledge;knowledge-based training system;explicit knowledge;Web-enabled training system;RFID technology;manufacturing processes;human-being supervision;training resource;closed loop knowledge;production system;sustainable development,,2,,14,,23-Dec-10,,,IEEE,IEEE Conferences
Integration of Advanced Technology in Initial Flight Training,E. Pennington; R. Hafer; E. Nistler; T. Seech; C. Tossell,United States Air Force Academy (USAFA); United States Air Force Academy (USAFA); United States Air Force Academy (USAFA); United States Air Force Academy (USAFA); United States Air Force Academy (USAFA),2019 Systems and Information Engineering Design Symposium (SIEDS),13-Jun-19,2019,,,1,5,"As virtual reality and artificial intelligence technologies continue to advance, the United States Military is quickly integrating these capabilities into initial flight training through efforts like the Air Force's Pilot Training Next (PTN) program. A persistent issue, however, has been a lack of data guiding (1) the ideal degree of integration into traditional pilot training and (2) the optimal amount of structure for student pilots' training experience. The goal of this study was to evaluate the aforementioned PTN model when applied to the U.S. Air Force Academy's flight training program with special emphasis on the ideal degree of structure for airmanship success. To this end, a quasi-experimental approach was utilized, which included 60 USAFA cadets enrolled in the Powered Flight Program who were pseudo-randomly assigned to three independent groups with varying degrees of structure. The groups (i.e., High Structured, Scaffolded, and Low Structured Groups) represented a spectrum of VR-training curriculum structure ranging from a rigid, lineal objective-completion model (akin to traditional flight training) to an unguided, Montessori-like model. With group assignment as the independent variable, live-flight performance was used as the dependent variable, which was quantified using flight grade cards, number of ‚Äúlanding tabs‚Äù (i.e., modified solos) awarded, and a subjective Instructor Pilot rating. Subjective feedback was also obtained from students in each condition. Initial effectiveness data indicated an increased level of perceived self-efficacy in coordination with increased virtual reality simulator time as well as an accelerated rate of positive transfer to real aircraft from the strictly structured and scaffolded groups. The results of this study allow for initial recommendations for forthcoming airmanship training and undergraduate pilot training augmentation efforts across the Department of Defense.",,978-1-7281-0998-5,10.1109/SIEDS.2019.8735628,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8735628,,Training;Military aircraft;Artificial intelligence;Virtual reality;Solid modeling;Aircraft;Manuals,aerospace simulation;artificial intelligence;computer based training;military computing;virtual reality,advanced technology;initial flight training;artificial intelligence technologies;United States Military;traditional pilot training;VR-training curriculum structure;flight grade cards;Air Force Academy;virtual reality;pilot training next program;flight training program;undergraduate pilot training augmentation;airmanship training;powered flight program,,2,,8,,13-Jun-19,,,IEEE,IEEE Conferences
Greater Transfer to Walking of Lower Extremity Training with Robotics and Virtual Reality than Robotics Training Alone: Preliminary Findings,A. Mirelman; J. E. Deutsch; P. Bonato,"Sch. of Health Related Professions, Univ. of Medicine & Dentistry of New Jersey, Newark, NJ; Sch. of Health Related Professions, Univ. of Medicine & Dentistry of New Jersey, Newark, NJ; NA",2006 International Workshop on Virtual Rehabilitation,9-Oct-06,2006,,,155,159,"Virtual reality systems have been used to deliver goal directed repetitive training to promote rehabilitation of individuals post-stroke. Lower extremity training of individuals post-stroke who used a robot coupled with virtual environment has been shown to transfer to improved overground locomotion. To isolate the active components of training in this study we compared the outcomes of training with the robot-virtual reality (VR) system to the robot alone. Four individuals post-stroke participated in a four-week training protocol. One group trained with the robot-VR system and the other group with the robot alone. The improvement in walking speed and endurance for the robot-VR group was greater than the robot group alone. Adherence as well as the number of exercises performed in each session was comparable for the two groups. The duration of training sessions was comparable at the beginning of the study. However, subjects in the robot group reported higher fatigue and produced 16% fewer minutes of training towards the end of the study. These findings support the use of virtual environments coupled with a robot for transfer of training from the virtual to the real world environment",2331-9569,1-4244-0280-8,10.1109/IWVR.2006.1707545,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1707545,,Legged locomotion;Extremities;Virtual reality;Rehabilitation robotics;Virtual environment;Motion analysis;Robot kinematics;Protocols;Dentistry;Hospitals,computer based training;medical computing;medical robotics;patient rehabilitation;virtual reality,lower extremity training;robotics;virtual reality;repetitive training;post-stroke rehabilitation;virtual environment;overground locomotion;walking speed;walking endurance;fatigue,,,,19,,9-Oct-06,,,IEEE,IEEE Conferences
A conceptual model of agumented virtual and reality in cadet training,J. Tuta; L. Luiƒá; ≈Ω. Car,"Media and Communication, University North,Koprivnica,Croatia; Media and Communication, University North,Koprivnica,Croatia; University of Zagreb,Faculty of Electrical Engineering and Computing,Zagreb,Croatia",2019 3rd European Conference on Electrical Engineering and Computer Science (EECS),20-Nov-20,2019,,,128,133,"Through digital communication in the educational process, its stakeholders, professors and students, become creators of new information practices, which in involve modern technologies augmented reality (AR) virtual reality (VR). The research objective was aimed at detecting AR and VR information concepts important for determining students' digital intelligence in the digital creativity domain. In the education of the cadets, some issues have been observed acknowledged, particularly the issues of defining the set of information which is necessary to be transferred to the cadets by AR and VR and the issue of detecting feedback expressed through the learning outcomes previously acquired. The main research challenge is correlation of information sets and how to structure them into a standard cadet training information model. The research was conducted by using the method of content analysis of software solutions and the questionnaire method. The cadets and expert at military academy have been selected as the research sample as they undergo through both the process of acquiring theoretical knowledge as well as practical training. The paper presents the research aimed at VR prototype development and its evaluation with two cadets generations and military professionals, who were introduced to VR technology in different ways. The obtained research results present basis for an AR / VR conceptual model to be further defined, that will contain set of abstract elements, relationships, and information that depict a complex real cadet training system. In this sense, this paper represents an initial step in defining the framework of a standard AR / VR information model in the military training that can be further developed by creating additional categories of data that do not appear in any of the existing information models.",,978-1-7281-6109-9,10.1109/EECS49779.2019.00035,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9257549,communication;conceptual model;virtual reality;augmented reality;cadet training;military,Training;Prototypes;Solid modeling;Military aircraft;Military computing;Augmented reality;Three-dimensional displays,augmented reality;computer based training;military computing,digital communication;educational process;information practices;VR information concepts;digital creativity domain;information sets;standard cadet training information model;questionnaire method;military academy;VR prototype development;VR technology;VR conceptual model;VR information model;military training;agumented reality;cadet generations;virtual reality;digital intelligence;content analysis;software solutions;military professionals;AR conceptual model;abstract elements;complex real cadet training system;standard AR information model,,,,16,,20-Nov-20,,,IEEE,IEEE Conferences
On-Road Evaluation of Autonomous Driving Training,D. Sportillo; A. Paljic; L. Ojeda,"PSL Research University, Center for Robotics, MINES ParisTech Groupe PSA, Paris, France; PSL Research University, Center for Robotics, MINES ParisTech, Paris, France; Groupe PSA, Velizy-Villacoublay, France",2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI),25-Mar-19,2019,,,182,190,"Driver interaction with increasingly automated vehicles requires prior knowledge of system capabilities, operational know-how to use novel car equipment and responsiveness to unpredictable situations. With the purpose of getting drivers ready for autonomous driving, in a between-subject study sixty inexperienced participants were trained with an on-board video tutorial, an Augmented Reality (AR) program and a Virtual Reality (VR) simulator. To evaluate the transfer of training to real driving scenarios, a test drive on public roads was conducted implementing, for the first time in these conditions, the Wizard of Oz (WoZ) protocol. Results suggest that VR and AR training can foster knowledge acquisition and improve reaction time performance in take-over requests. Moreover, participants' behavior during the test drive highlights the ecological validity of the experiment thanks to the effective implementation of the WoZ methodology.",2167-2148,978-1-5386-8555-6,10.1109/HRI.2019.8673277,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8673277,Automated Vehicles;Virtual Reality;Augmented Reality;Transfer of Training;TOR;Wizard of Oz;Human-Vehicle Interaction,Automobiles;Training;Autonomous vehicles;Roads;Automation;Augmented reality,augmented reality;computer based training;traffic engineering computing,driving scenarios;public roads;knowledge acquisition;road evaluation;autonomous driving training;driver interaction;car equipment;on-board video tutorial;VR training;between-subject study;virtual reality simulator;augmented reality program;WoZ protocol;Wizard of Oz;AR training,,3,,36,,25-Mar-19,,,IEEE,IEEE Conferences
Influences on the Elicitation of Interpersonal Space with Virtual Humans,D. M. Krum; S. Kang; T. Phan,"University of Southern California, Institute for Creative Technologies; University of Southern California, Institute for Creative Technologies; University of Southern California, Institute for Creative Technologies",2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),30-Aug-18,2018,,,223,9,"The emergence of low cost virtual and augmented reality systems has encouraged the development of immersive training applications for medical, military, and many other fields. Many of the training scenarios for these various fields may require the presentation of realistic interactions with virtual humans. It is thus vital to determine the critical factors of fidelity required in those interactions to elicit naturalistic behavior on the part of trainees. Negative training may occur if trainees are inadvertently influenced to react in ways that are unexpected and unnatural, hindering proper learning and transfer of skills and knowledge back into real world contexts. In this research, we examined whether haptic priming (presenting an illusion of virtual human touch at the beginning of the virtual experience) and different locomotion techniques (either joystick or physical walking) might affect proxemic behavior in human users. The results of our study suggest that locomotion techniques can alter proxemic behavior in significant ways. Haptic priming did not appear to impact proxemic behavior, but did increase rapport and other subjective social measures. The results suggest that designers and developers of immersive training systems should carefully consider the impact of even simple design and fidelity choices on trainee reactions in social interactions.",,978-1-5386-3365-6,10.1109/VR.2018.8446235,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446235,Virtual humans;virtual reality;immersive training;fidelity;proxemics;haptic priming;locomotion techniques.: Human-centered computing-Human Computer Interaction (HCI)-Interaction Paradigms-Virtual Reality;Human-centered computing-Interaction design-Interaction design process and methods-User interface design,Haptic interfaces;Training;Legged locomotion;Virtual environments;Atmospheric measurements;Particle measurements,augmented reality;haptic interfaces;interactive devices;training,elicitation;interpersonal space;virtual humans;augmented reality systems;immersive training applications;training scenarios;realistic interactions;naturalistic behavior;negative training;proper learning;virtual human touch;virtual experience;human users;impact proxemic behavior;immersive training systems;trainee reactions;social interactions;locomotion techniques,,,,28,,30-Aug-18,,,IEEE,IEEE Conferences
Augmented Cues Facilitate Learning Transfer from Virtual to Real Environments,N. Cooper; F. Milella; I. Cant; C. Pinto; M. White; G. Meyer,NA; NA; NA; NA; NA; NA,2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct),2-Feb-17,2016,,,194,198,"The aim of this study was to investigate whether augmented cues that have previously been shown to enhance performance and user satisfaction in VR training translate into performance improvements in real environments. Subjects were randomly allocated into 3 groups. Group 1 were trained to perform a real tyre change, group 2 were trained in a conventional VR setting, while group 3 were trained in VR with augmented cues. After training participants were tested on a real tyre change task. Overall time to completion was recorded as objective measure; subjective ratings of presence, perceived workload and discomfort were recorded using questionnaires. The performances of the three groups were compared. Overall, participants who received VR training performed significantly faster on the real task than participants who completed the real tyre change only. The difference between the virtual reality training groups was found to be not significant. However, participants who were trained with augmented cues performed the real tyre change with fewer errors than participants in the minimal cues training group. Systematic differences in subjective ratings that reflected objective performance were also observed.",,978-1-5090-3740-7,10.1109/ISMAR-Adjunct.2016.0075,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836496,virtual reality;training transfer;multisensory feedback;augmented cues;performance;presence;workload;simulation sickness,Training;Solid modeling;Virtual reality;Atmospheric measurements;Particle measurements;Computational modeling;Wheels,augmented reality;computer based training,augmented cues;learning transfer;virtual environments;real environments;VR training,,4,,31,,2-Feb-17,,,IEEE,IEEE Conferences
Virtual Reality Based Knowledge Acquisition and Job Training for Advanced Casting Skills,K. Watanuki; K. Kojima,"Saitama University, Japan; Saitama University, Japan",16th International Conference on Artificial Reality and Telexistence--Workshops (ICAT'06),12-Feb-07,2006,,,666,671,"The environment where Japanese industry has beenpaid with respect is changing tremendously due to the globalization of economics, where Asian countries are undergoing economical and technical development as well as advancing in information technology. For example, in the design of custom-made casting product, a designer whom lacking of casting knowledge may not be able to produce a good design. In order to obtain a good design and manufacturing result, it is necessary to equip the designer and manufacturer with a support system related to casting design or so called, knowledge transfer and creation system. In recent years, the design supporting system using VR technology is developed, and introduced in the manufacturing industry. The merit of using VR system is being able to carry out the stereoscopy of the product model drawn by 3D CAD, and to carry out the design review of the product model in the same size as thing. However, since many systems extend the display of the conventional 3D CAD, they cannot input annotation and so on directly in VR environment. In this paper, the system which can input and display the annotation in VR environment is developed. By drawing annotation to the product model displayed on VR environment, sharing of technical tacit knowledge and engineers' communication are promoted, and engineers becomes possible gaining physical tacit knowledge.",,0-7695-2754-X,10.1109/ICAT.2006.147,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4089335,,Virtual reality;Knowledge acquisition;Casting;Environmental economics;Manufacturing;Design automation;Knowledge engineering;Industrial training;Industrial economics;Globalization,CAD;casting;computer aided instruction;multimedia systems;production engineering computing;virtual reality,virtual reality;knowledge acquisition;job training;advanced casting skills;Japanese industry;Asian countries;information technology;custom-made casting product;casting knowledge;casting design;knowledge transfer;design supporting system;manufacturing industry;VR system;3D CAD;technical tacit knowledge,,3,,4,,12-Feb-07,,,IEEE,IEEE Conferences
Virtual reality and medicine: from training systems to performance machines,J. M. Rosen; D. R. Laub; S. D. Pieper; A. M. Mecinski; H. Soltanian; M. A. McKenna; D. Chen; S. L. Delp; J. P. Loan; C. Basdogan,"Div. of Plastic & Reconstructive Surgery, Dartmouth-Hitchcock Med. Centre, Lebanon, NH, USA; Div. of Plastic & Reconstructive Surgery, Dartmouth-Hitchcock Med. Centre, Lebanon, NH, USA; NA; NA; NA; NA; NA; NA; NA; NA",Proceedings of the IEEE 1996 Virtual Reality Annual International Symposium,6-Aug-02,1996,,,5,13,"The paper reviews a decade of work in applying virtual reality to medicine. Beginning with a brief history of simulations and surgery, we present a background to surgery simulators and then discuss the problem of limited human body models in past systems. We present our work at developing human body models beginning with the first virtual reality leg simulator in 1989. This model allowed simple tendon transfers and osteotomies with the computer able to predict the resulting mechanics and ability to walk. We also discuss the leg model's evolution into a performance machine which will allow a surgeon to predict position and subsequent function of an Anterior Cruciate Ligament (ACL) repair. This is paralleled by Department of Defense work on a leg model that can have a simulated wound and predicts blood loss and its ability to function. We review computer aided surgery and virtual reality technologies. We then present our work in plastic surgery computer aided planning and predict the importance of this work for surgical training.",,0-8186-7296-X,10.1109/VRAIS.1996.490505,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=490505,,Virtual reality;Biological system modeling;Surgery;Predictive models;Medical simulation;Computational modeling;Leg;Humans;History;Tendons,medical computing;virtual reality;digital simulation;biomechanics;computer aided instruction;biomedical education,virtual reality;medicine;training systems;performance machines;surgery simulators;limited human body models;leg simulator;simple tendon transfers;osteotomies;Anterior Cruciate Ligament repair;simulated wound;blood loss;computer aided surgery;plastic surgery computer aided planning;surgical training,,6,2,28,,6-Aug-02,,,IEEE,IEEE Conferences
Large-scale Virtual Reality micro-robotic cell injection training,S. Faroque; B. Horan; M. Mortimer; M. Pangestu,"CADET Virtual Reality Lab, School of Engineering, Deakin University, Geelong, Australia; CADET Virtual Reality Lab, School of Engineering, Deakin University, Geelong, Australia; CADET Virtual Reality Lab, School of Engineering, Deakin University, Geelong, Australia; Department of Obstetrics and Gynaecology, Monash University, Melbourne, Australia",2016 World Automation Congress (WAC),6-Oct-16,2016,,,1,6,"Currently the micro-robotic cell injection procedure is performed manually by professional bio-operators. It is a challenging task requiring advanced skills including the ability to precisely control the movement of a micropipette. Developing these skills requires both lengthy and intensive training, and significant practical experience. This paper extends upon our previous work in desktop Virtual Reality (VR) cell injection training to introduce a large-scale VR micro-robotic cell injection system. Through utilization of large visual displays and the large workspace INCA 6D haptic device, the proprioception related to large arm movements (and corresponding visual representation) and the resulting movement of the micropipette in relation to the cell aims to provide the user with a better understanding of the spatial relationship between the micropipette and cell. The haptic device can be operated either with or without haptic guidance. When enabled, haptic guidance is provided in the form of virtual fixtures (VFs) and force feedback to assist the user in following the ideal trajectory towards the penetration point, applying appropriate force for penetration and stopping the micropipette's tip at the suitable deposition point. A user evaluation was conducted to study the usability of the system. Eighteen participants took part in the experiments and were randomly divided into six groups based on the display and haptic guidance modes assigned. The results demonstrated that the large-scale VR micro-robotic cell injection system is a feasible and effective method for bio-operator training where it is suggested that the skills and knowledge acquired can be transferred to the real-world task.",,978-1-8893-3551-3,10.1109/WAC.2016.7583006,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7583006,Micro-robot;cell injection;virtual reality;haptics;skill training,Image edge detection;Visualization;Robots,computer based training;haptic interfaces;large-scale systems;medical computing;medical robotics;microrobots;virtual reality,large-scale virtual reality;microrobotic cell injection training;bio-operators;micropipette;intensive training;INCA 6D haptic device;virtual fixtures;VF;user evaluation,,3,,18,,6-Oct-16,,,IEEE,IEEE Conferences
A virtual reality based exercise system for hand rehabilitation post-stroke: transfer to function,S. V. Adamovich; A. S. Merians; R. Boian; M. Tremaine; G. S. Burdea; M. Recce; H. Poizner,"Dept. of Biomedical Eng., New Jersey Inst. of Technol., Newark, NJ, USA; NA; NA; NA; NA; NA; NA",The 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,14-Mar-05,2004,2,,4936,4939,"We present preliminary results from a virtual reality (VR)-based system for hand rehabilitation that uses a CyberGlove and a Rutgers Master II-ND haptic glove. This system trains finger range of motion, finger flexion speed, independence of finger motion and finger strength. Eight chronic post-stroke subjects participated. In keeping with variability in both the lesion site and in initial upper extremity function, each subject showed improvement on a unique combination of movement parameters in VR training. These improvements transferred to gains on clinical tests, as well as to significant reductions in task completion times for the prehension of real objects. These results are indicative of the potential feasibility of this exercise system for rehabilitation in patients with hand dysfunction resulting from neurological impairment.",,0-7803-8439-3,10.1109/IEMBS.2004.1404364,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1404364,stroke;hand function;virtual reality (VR);CyberGlove;Rutgers Master II-ND;grasping,Virtual reality;Fingers;Data gloves;Biomedical engineering;Lesions;Medical treatment;Fractionation;Grasping;Kinematics;Kinetic theory,patient rehabilitation;virtual reality;biomechanics;data gloves,virtual reality;exercise system;post-stroke hand rehabilitation;CyberGlove;Rutgers Master II-ND haptic glove;finger flexion speed;finger motion;finger strength;hand dysfunction;neurological impairment,,32,,17,,14-Mar-05,,,IEEE,IEEE Conferences
Development of Virtual Reality Serious Game for Underground Rock-Related Hazards Safety Training,Z. Liang; K. Zhou; K. Gao,"School of Resources and Safety Engineering, Central South University, Changsha, China; School of Resources and Safety Engineering, Central South University, Changsha, China; School of Resources and Safety Engineering, Central South University, Changsha, China",IEEE Access,30-Aug-19,2019,7,,118639,118649,"Traditional safety training media to transfer safety knowledge specific to the rock-related hazards in underground mines are mainly video or manuals, which are inefficient and bring a poor training experience. In this paper, we designed and developed a serious game based on virtual reality (VR) technology in order to efficiently transfer safety knowledge and enable enhanced interactive safety training. For different training purposes and users, we designed two modes, one for professional scaling training suitable for novice scalers, the other for rock-related hazards perception training suitable for other miners. Our game is built based on game engine-Unity3D and equipped with HTC VIVE to improve immersion. The game pipeline is to have trainees basically understand safety knowledge through guided interaction and then make a self-adaptive practice to fully master it. We evaluated the effectiveness of our game, and the results of the comparative experiment show that our game is more efficient than the instructional video in both training modes. The application of our game is proven to have the potential to change the safety situation of underground mines and evaluate the level of safety awareness and risk aversion of the miners in the future.",2169-3536,,10.1109/ACCESS.2019.2934990,Central South University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8795446,Safety training;underground mining;virtual reality;rock-related hazards;serious game,Games;Training;Rocks;Hazards;Virtual reality;Accidents,computer based training;design engineering;health hazards;industrial training;mining;mining industry;occupational safety;risk management;rocks;serious games (computing);virtual reality,underground mines;professional scaling training;game engine-Unity3D;risk aversion;virtual reality serious game design;hazards perception training;underground rock;HTC VIVE equipment,,3,,48,CCBY,13-Aug-19,,,IEEE,IEEE Journals
"Virtual Reality for training - The impact of smell on presence, cybersickness, fatigue, stress and knowledge transfer",D. Narciso; M. Bessa; M. Melo; J. Vasconcelos-Raposo,"UTAD,Engineering Department,Vila Real,Portugal; UTAD,Engineering Department,Vila Real,Portugal; INESC TEC,Porto,Portugal; UTAD,Departament of Education and Psychology,Vila Real,Portugal",2019 International Conference on Graphics and Interaction (ICGI),14-Jan-20,2019,,,115,121,"The area of professional training using virtual reality technologies has received considerable investment due to the advantages that virtual reality provides over traditional training. In this paper, we present an experiment whose goal was to analyse the impact that an additional stimulus has on the effectiveness of a virtual environment designed to train firefighters. The additional stimulus is a smell, more specifically the smell of burnt wood, which is consistent with the audiovisual content presented, and the effectiveness of the VE is measured through participant's feeling of presence, cybersickness, fatigue, stress and transfer of knowledge. The results indicate that, although the VE was successful in transferring knowledge, the addition of smell did not influence any of the measured variables. In the discussion section, we present the various factors that we believe have influenced this result. As future work, more experiments will be performed, with other stimuli, to understand better which stimuli increase participant's feeling of presence in the VE.",,978-1-7281-6378-9,10.1109/ICGI47575.2019.8955071,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8955071,Virtual Reality;Olfactory Sense;Multisensory Stimulation,Training;Olfactory;Fatigue;Stress;Knowledge transfer;Atmospheric measurements,computer based training;continuing professional development;virtual reality,smell;stress;professional training;virtual reality technologies;additional stimulus;virtual environment;cybersickness;fatigue;knowledge transfer;firefighters;audiovisual content,,1,,44,,14-Jan-20,,,IEEE,IEEE Conferences
Training the Hubble space telescope flight team,R. B. Loftin; P. Kenney,"Houston Univ., TX, USA; NA",IEEE Computer Graphics and Applications,6-Aug-02,1995,15,5,31,37,"As the results demonstrate, members of the flight team judged, on average, that the use of a virtual environment for training had a positive effect on their job performance during the HST repair and maintenance mission. Moreover, audio and visual cues provided a positive aid in using the virtual environment. The discomfort experienced by some of the participants did not pose a serious problem with training transfer, but further study should be devoted to reducing these effects. The positive experiences reported here have broadened and deepened the interest of NASA in the use of VR technology as a training tool.<>",1558-1756,,10.1109/38.403825,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=403825,,Telescopes;Space technology;Virtual environment;NASA;Space missions;Personnel;Data visualization;Aerospace simulation;Space shuttles;Research and development,virtual reality;computer based training;training;computer aided instruction;aerospace computing,Hubble space telescope flight team;virtual environment;repair;maintenance mission;training transfer,,61,5,11,,6-Aug-02,,,IEEE,IEEE Magazines
A visual/haptic interface to virtual environment (WYSIWYF display) and its application,Y. Yokokohji,"Dept. of Mech. Eng., Kyoto Univ., Japan",Proceedings 1998 IEEE and ATR Workshop on Computer Vision for Virtual Reality Based Human Communications,6-Aug-02,1998,,,99,104,"VR training or skill transfer via virtual environment is a kind of human communication from one (expert) to others (trainee). To build a VR training system for visuo-motor skills, a visual interface should be correctly registered to a haptic interface so that the visual sensation and the haptic sensation are consistent spatially and temporally. Ideally a visual/haptic interface should be configured in such a way that what you see is what you feel as it is in the real life situations. In this paper, a reasonable method to realize correct visual/haptic registration is introduced. This method provides correct visual/haptic registration using a vision-based object tracking technique and a video keying technique. The first prototype called WYSIWYF Display has been built and the proposed concept was demonstrated. The paper then discusses a potential application to VR training using the WYSIWYF Display.",,0-8186-8283-3,10.1109/CVVRHC.1998.660376,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=660376,,Haptic interfaces;Virtual environment;Displays;Cameras;Rendering (computer graphics),virtual reality;graphical user interfaces,visual/haptic interface;virtual environment;WYSIWYF display;virtual reality;visuo-motor skills;visual interface;video keying technique,,2,,19,,6-Aug-02,,,IEEE,IEEE Conferences
VR-OOS: The DLR's virtual reality simulator for telerobotic on-orbit servicing with haptic feedback,M. Sagardia; K. Hertkorn; T. Hulin; S. Sch√§tzle; R. Wolff; J. Hummel; J. Dodiya; A. Gerndt,"German Aerospace Center (DLR), Muenchener Str. 20, 82234 Wessling, Germany; German Aerospace Center (DLR), Muenchener Str. 20, 82234 Wessling, Germany; German Aerospace Center (DLR), Muenchener Str. 20, 82234 Wessling, Germany; German Aerospace Center (DLR), Muenchener Str. 20, 82234 Wessling, Germany; German Aerospace Center (DLR), Lilienthalplatz 7, 38108 Braunschweig, Germany; German Aerospace Center (DLR), Lilienthalplatz 7, 38108 Braunschweig, Germany; German Aerospace Center (DLR), Lilienthalplatz 7, 38108 Braunschweig, Germany; German Aerospace Center (DLR), Lilienthalplatz 7, 38108 Braunschweig, Germany",2015 IEEE Aerospace Conference,8-Jun-15,2015,,,1,17,"The growth of space debris is becoming a severe issue that urgently requires mitigation measures based on maintenance, repair, and de-orbiting technologies. Such on-orbit servicing (OOS) missions, however, are delicate and expensive. Virtual Reality (VR) enables the simulation and training in a flexible and safe environment, and hence has the potential to drastically reduce costs and time, while increasing the success rate of future OOS missions. This paper presents a highly immersive VR system with which satellite maintenance procedures can be simulated interactively using visual and haptic feedback. The system can be used for verification and training purposes for human and robot systems interacting in space. Our framework combines unique realistic virtual reality simulation engines with advanced immersive interaction devices. The DLR bimanual haptic device HUG is used as the main user interface. The HUG is equipped with two light-weight robot arms and is able to provide realistic haptic feedback on both human arms. Additional devices provide vibrotactile and electrotactile feedback at the elbow and the fingertips. A particularity of the realtime simulation is the fusion of the Bullet physics engine with our haptic rendering algorithm, which is an enhanced version of the Voxmap-Pointshell Algorithm. Our haptic rendering engine supports multiple objects in the scene and is able to compute collisions for each of them within 1 msec, enabling realistic virtual manipulation tasks even for stiff collision configurations. The visualization engine ViSTA is used during the simulation to achieve photo-realistic effects, increasing the immersion. In order to provide a realistic experience at interactive frame rates, we developed a distributed system architecture, where the load of computing the physics simulation, haptic feedback and visualization of a complex scene is transferred to dedicated machines. The implementations are presented in detail and the performance of the overall system is validated. Additionally, a preliminary user study in which the virtual system is compared to a physical test bed shows the suitability of the VR-OOS framework.",1095-323X,978-1-4799-5380-6,10.1109/AERO.2015.7119040,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119040,,Computational modeling;Force;Haptic interfaces;Robots;Satellites;Solid modeling;Space vehicles,aerospace computing;aerospace robotics;aerospace safety;haptic interfaces;realistic images;real-time systems;rendering (computer graphics);space debris;telerobotics;virtual reality,DLR virtual reality simulator;telerobotic on-orbit servicing missions;space debris;mitigation measures;repair;de-orbiting technologies;OOS missions;immersive VR system;satellite maintenance procedures;visual feedback;robot systems;realistic virtual reality simulation engines;immersive interaction devices;DLR bimanual haptic device HUG;user interface;robot arms;realistic haptic feedback;vibrotactile feedback;electrotactile feedback;realtime simulation;Bullet physics engine;haptic rendering algorithm;Voxmap-Pointshell algorithm;haptic rendering engine;realistic virtual manipulation tasks;stiff collision configurations;visualization engine ViSTA;photo-realistic effects;realistic experience;interactive frame rates;distributed system architecture;physics simulation;complex scene;virtual system;VR-OOS framework,,9,1,43,,8-Jun-15,,,IEEE,IEEE Conferences
Phantom-based multimodal interactions for medical education and training: the Munich knee joint simulator,R. Riener; M. Frey; T. Proll; F. Regenfelder; R. Burgkart,"Autom. Control Lab., Swiss Fed. Inst. of Technol., Zurich, Switzerland; NA; NA; NA; NA",IEEE Transactions on Information Technology in Biomedicine,7-Jun-04,2004,8,2,208,216,"Simulation environments based on virtual reality technologies can support medical education and training. In this paper, the novel approach of an ""interactive phantom"" is presented that allows a realistic display of haptic contact information typically generated when touching and moving human organs or segments. The key idea of the haptic interface is to attach passive phantom objects to a mechanical actuator. The phantoms look and feel as real anatomical objects. Additional visualization of internal anatomical and physiological information and sound generated during the interaction with the phantom yield a multimodal approach that can increase performance, didactic value, and immersion into the virtual environment. Compared to classical approaches, this multimodal display is convenient to use, provides realistic tactile properties, and can be partly adjusted to different, e.g., pathological properties. The interactive phantom is exemplified by a virtual human knee joint that can support orthopedic education, especially for the training of clinical knee joint evaluation. It is suggested that the technical principle can be transferred to many other fields of medical education and training such as obstetrics and dentistry.",1558-0032,,10.1109/TITB.2004.828885,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1303564,,Knee;Medical simulation;Imaging phantoms;Displays;Haptic interfaces;Humans;Virtual reality;Educational technology;Actuators;Visualization,bone;orthopaedics;dentistry;biomedical education;training;phantoms;haptic interfaces;biomechanics;virtual reality;display devices;actuators;medical robotics;digital simulation;computer animation,phantom-based multimodal interaction;medical education;medical training;Munich knee joint simulator;virtual reality technologies;VR;haptic contact information;mechanical actuator;internal anatomical information;physiological information;multimodal sound approach;didactic value;realistic tactile properties;pathological properties;virtual human knee joint;orthopedic education;clinical knee joint evaluation;obstetrics;dentistry;acoustic display;animation;biomechanics;graphical display;multimodal display;robotics,"Computer Graphics;Computer Simulation;Education, Medical;Environment;Germany;Humans;Knee Joint;Models, Anatomic;Models, Biological;Online Systems;Phantoms, Imaging;Robotics;Robotics;Teaching;User-Computer Interface",21,,33,,7-Jun-04,,,IEEE,IEEE Journals
Keyboard control method for virtual reality micro-robotic cell injection training,S. Faroque; B. Horan; M. Joordens,"School of Engineering, Deakin University Geelong, VIC, Australia; School of Engineering, Deakin University Geelong, VIC, Australia; School of Engineering, Deakin University Geelong, VIC, Australia",2015 10th System of Systems Engineering Conference (SoSE),9-Jul-15,2015,,,416,421,"The rapid development of virtual reality offers significant potential for skills training applications. Our ongoing work proposes virtual reality operator training for the micro-robotic cell injection procedure. The interface between the operator and the system can be achieved in many different ways. The computer keyboard is ubiquitous in its use for everyday computing applications and also commonly utilized in virtual reality systems. Based on the premise that most people have experience in using a computer keyboard, as opposed to more sophisticated input devices, this paper considers the feasibility of using a keyboard to control the micro-robot for cell injection. In this study, thirteen participants underwent the experimental evaluation. The participants were asked to perform three simulated trial sessions in a virtual micro-robotic cell injection environment. Each session consisted of ten cell injection trials and relevant data for each trial were recorded and analyzed. Results showed participants' performance improvement after the three sessions. It was also observed that participants intuitively controlled multiple axes of the micro-robot simultaneously despite the absence of instruction on how to do so. This continued throughout the experiments and suggests skills transfer from other keyboard based interactions. Based on the results provided, it is suggested that keyboard control is a feasible, simple and low-cost control method for the virtual micro-robot.",,978-1-4799-7611-9,10.1109/SYSOSE.2015.7151946,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7151946,Cell injection;virtual reality;micromanipulation;micro-robot;skills training,Keyboards;Haptic interfaces;Training;Systems engineering and theory;Computers;Virtual environments,biomedical education;cellular biophysics;computer based training;keyboards;microrobots;virtual reality,keyboard control method;virtual reality microrobotic cell injection training;skill training applications;virtual reality operator training;microrobotic cell injection procedure;ubiquitous computer keyboard;input devices;keyboard based interactions;low-cost control method,,1,,15,,9-Jul-15,,,IEEE,IEEE Conferences
"Effectiveness of Virtual Versus Physical Training: The Case of Assembly Tasks, Trainer's Verbal Assistance, and Task Complexity",K. Koumaditis; F. Chinello; P. Mitkidis; S. Karg,Aarhus University; Aarhus University; Aarhus University; Aarhus University,IEEE Computer Graphics and Applications,24-Aug-20,2020,40,5,41,56,"Virtual immersive training (VIT) systems based on gamification of tasks are increasingly employed to train assembly workers. In this article, we present a study that compares the effectiveness of virtual and physical training for teaching a bimanual assembly task and in a novel approach, we introduce task complexity (TCXB) as an indicator of assembly errors during final assembly. In a between-subjects experiment, 100 participants were trained to assemble a 3-D cube in one of the four conditions (physical, virtual and with trainer's verbal assistance or not). The results demonstrate that the best-performing conditions, both in terms of successful assemblies and time performance, are the ones that the physical objects are included in the training, whereas no significant difference is found when the trainer's verbal assistance is present or absent during training. Additionally, we address the validity of a practical TCXB CXB list as a tool for supporting the design of VIT systems.",1558-1756,,10.1109/MCG.2020.3006330,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9130859,learning transfer;virtual reality;assembly;task complexity;training,Training;Task analysis;Complexity theory;Animation;Testing;Software tools;Virtual environments,assembling;computer based training;industrial training;personnel;teaching;virtual reality,VIT systems;physical training;task complexity;virtual immersive training systems;assembly workers;bimanual assembly task;TCXB CXB list;trainer verbal assistance;teaching process,,,,20,IEEE,1-Jul-20,,,IEEE,IEEE Magazines
Digital Twin and Virtual Reality for Safety Training,T. Kaarlela; S. Piesk√§; T. Pitk√§aho,"Centria University of Applied Sciences,Ylivieska,Finland; Centria University of Applied Sciences,Ylivieska,Finland; Centria University of Applied Sciences,Ylivieska,Finland",2020 11th IEEE International Conference on Cognitive Infocommunications (CogInfoCom),2-Nov-20,2020,,,115,120,"In this paper, our latest research related to digital twins and virtual reality environments for safety training purposes will be described and evaluated. We will present three practical use cases to outline the current maturity level of virtual reality technology for industrial environments. Two of our use cases are virtual reality applications for safety and emergency training scenarios. In addition, one use case is the implementation of a digital twin for off-site safety training. This use case presents a seamless real-time transfer of data between the physical and virtual worlds. Use cases were developed based on the needs of, and in co-operation with, local small and medium-sized enterprises (SMEs). The proposed affordable and simple approaches provide virtual safety training solutions that can be utilized by SMEs of different industries.",2380-7350,978-1-7281-8213-1,10.1109/CogInfoCom50765.2020.9237812,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237812,,Training;Digital twin;Virtual environments;Real-time systems;Production facilities;Safety;Task analysis,computer based training;industrial training;production engineering computing;safety;small-to-medium enterprises;virtual reality,digital twin;industrial environments;virtual reality;emergency training scenarios;off-site safety training;physical worlds;virtual worlds;virtual safety training;real-time data transfer;use cases;small and medium-sized enterprises;SME,,,,34,,2-Nov-20,,,IEEE,IEEE Conferences
Implementing overground turning on a linear treadmill,H. Park; S. H. Chae; J. W. Yoon; J. Kim; A. Sudduth; C. Stanley,"Department of Mechanical Engineering, KAIST, Daejeon, Korea; Department of Mechanical Engineering, KAIST, Daejeon, Korea; Department of Mechanical Engineering, Gyeongsang National University, Jinju, Korea; Department of Robotics Engineering, DGIST, Daegu, Korea; Rehabilitation Medicine Department, National Institutes of Health, Bethesda, USA; Rehabilitation Medicine Department, National Institutes of Health, Bethesda, USA",2015 12th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI),17-Dec-15,2015,,,390,391,"The purpose of treadmill-based locomotor training is to transfer walking skills obtained from training to real world walking (overground: OG). For optimal skill transfer, treadmill-based training should simulate OG as closely as possible. The constant speed of a standard treadmill encourages automaticity rather than engagement and fails to simulate the variable speeds encountered during OG walking. Our effort to overcome this limitation has focused on developing user-driven treadmill (UDT) velocity control schemes that allow the user to freely change walking speed and feel the same inertial force that they feel during OG walking. In this study, we have combined the user driven treadmill control with the virtual reality (VR) display to simulate realistic turning in a safe environment.",,978-1-4673-7971-7,10.1109/URAI.2015.7358882,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358882,Gait Rehabilitation;Turning;User-driven Treadmill;Virtual Reality,Turning;Legged locomotion;Virtual reality;Electronic mail;Training;Velocity control,force control;gait analysis;patient rehabilitation;velocity control;virtual reality,overground turning;linear treadmill;treadmill-based locomotor training;walking skills;optimal skill transfer;user-driven treadmill;velocity control;inertial force;virtual reality;VR display;walking speed,,,,4,,17-Dec-15,,,IEEE,IEEE Conferences
Hovercraft training simulator delay compensation design based on McFarland,L. Juan; L. Qing; C. Xinghua,"College of Automation, Harbin Engineering University, Heilongjiang, Harbin 150001; College of Automation, Harbin Engineering University, Heilongjiang, Harbin 150001; College of Automation, Harbin Engineering University, Heilongjiang, Harbin 150001",2012 IEEE International Conference on Mechatronics and Automation,27-Aug-12,2012,,,1021,1025,"The hovercraft is a high-performance amphibious ship. Hovercraft training simulator (HTS) is a virtual reality device in which a human being is able to feel as if they are actually driving the real Hovercraft. The transfer delay in the HTS is the main reason of degrading its performance and affecting its real-time which comes from many sources. To reduce the transfer delay effects, the improved McFarland compensator was used for HTS. It is an integral method, which doesn't involve the process of kinetic equation solver in the HTS. Three coefficients of the corresponding consecutive velocity are used to predict the next states. These three factors determine the compensation ability of the compensator. The improved McFarland compensator makes up for the limitation that classic McFarland compensator can only be used to compensate for a fixed input of the simulation systems. Analysis of simulation results shows that the improved McFarland compensator is an effectively delay compensation, and can meet our demands.",2152-744X,978-1-4673-1278-3,10.1109/ICMA.2012.6283390,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6283390,Hovercraft;Simulator;Transfer Delay;McFarland compensator,Delay;High temperature superconductors;Training;Mathematical model;Equations;Vehicles;Visualization,control engineering computing;control system synthesis;delays;hovercraft;integral equations;training;virtual reality,hovercraft training simulator;HTS;delay compensation design;amphibious ship;virtual reality;transfer delay effects;McFarland compensator;integral method;kinetic equation solver,,,,14,,27-Aug-12,,,IEEE,IEEE Conferences
Motion-based virtual reality cognitive training targeting executive functions in acquired brain injury community-dwelling individuals: A feasibility and initial efficacy pilot,G. Shochat; S. Maoz; A. Stark-Inbar; B. Blumenfeld; D. Rand; S. Preminger; Y. Sacher,"Department of Traumatic Brain Injury, Loewenstein Rehabilitation Center, Ra'anana, Israel; Intendu Ltd., Herzliya, Israel; Intendu Ltd., Herzliya, Israel; Intendu Ltd., Herzliya, Israel; Department of Occupational Therapy, Tel Aviv University, Israel; Intendu Ltd., Herzliya, Israel; Department of Traumatic Brain Injury, Loewenstein Rehabilitation Center, Ra'anana, Israel",2017 International Conference on Virtual Rehabilitation (ICVR),14-Aug-17,2017,,,1,8,"Acquired brain injury (ABI) is a leading cause of long-term cognitive disability, often involving deficits in executive functions (EF). ABI patients usually stop receiving cognitive treatment when leaving the rehabilitation facility or shortly thereafter, due to the high cost of therapy sessions and the mobility requirement to access therapy. Software solutions offer a promising tool for accessible and affordable cognitive rehabilitation in the home environment. However, research provides limited evidence for effective transfer of benefits from computerized cognitive training to real-life functions. Virtual reality (VR) exergames using motion-interaction offer a more realistic and natural training environment, and are therefore expected to facilitate a more effective transfer. Although commercial exergames may bring about some cognitive gains, they usually do not target cognitive functions directly. Here we describe a novel exergames platform, the Active Brain Trainer (ABT), designed to directly target EF, using games in multiple realistic contexts. The software adapts in real-time to the patient's behavior, providing feedback and rewards, and hence may enhance usability and compliance. The primary goal of the current study is to assess the feasibly and acceptability of this platform for community-dwelling ABI patients during the chronic phase. A secondary goal is to assess the initial efficacy on EF and functional benefits from program training. Participants were instructed to use the games for 15-20 sessions. Neuropsychological assessments of EF and daily life functions were performed before and after training. Participants also filled a satisfaction questionnaire following training. All training and assessments were conducted in the participants' homes. Game performance was recorded throughout training sessions. Preliminary results from the six ABI patients who successfully completed the program so far show no adverse effects. Participants reported enjoyment and satisfaction from training. Participants performed increasingly more challenging EF tasks within game environments. Initial results show improvements in functional tasks and most executive neuropsychological assessments following training. Additional participants are currently being trained to increase the power of the results. These preliminary findings support the feasibility and potential efficacy of the motion-based cognitive training of EF for community-dwelling individuals with ABI.",2331-9569,978-1-5090-3053-8,10.1109/ICVR.2017.8007530,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007530,cognitive training;exergames;motion-based;acquired brain injury;community-dwelling;executive functions,Games;Training;Avatars;Radiation detectors;Brain injuries;Medical treatment;Atmospheric measurements,brain;cognition;computer games;injuries;medical computing;neurophysiology;patient rehabilitation;virtual reality,motion-based virtual reality cognitive training;executive functions;acquired brain injury community-dwelling individuals;ABI;long-term cognitive disability;rehabilitation facility;therapy sessions;mobility requirement;home environment;computerized cognitive training;VR exergames;motion interaction;active brain trainer;ABT;chronic phase;neuropsychological assessments;daily life functions;game environments;functional tasks,,,,69,,14-Aug-17,,,IEEE,IEEE Conferences
Sport-specific virtual reality to identify profiles of anterior cruciate ligament injury risk during unanticipated cutting,A. W. Kiefer; C. DiCesare; S. Bonnette; K. Kitchen; B. Gadd; S. Thomas; K. D. Barber Foss; G. D. Myer; M. A. Riley; P. Silva,"Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Department of Psychology, Center for Cognition, Action, & Perception, University of Cincinnati, OH USA; Department of Psychology, Center for Cognition, Action, & Perception, University of Cincinnati, OH USA",2017 International Conference on Virtual Rehabilitation (ICVR),14-Aug-17,2017,,,1,8,"Female athletes are at an increased risk of anterior cruciate ligament (ACL) injury in competitive sport during running, jumping and cutting tasks. This risk is due to deficits in posterior chain and hip recruitment associated with aberrant frontal knee loads. The identification of these risk factors has led to targeted neuromuscular training (NMT) interventions to enhance hip neuromuscular control during such tasks. Despite the successful modification of ACL injury risk factors following NMT, the transfer of these corrected movement patterns to the sport-specific contexts has not been directly evaluated. Sport-specific virtual reality (VR) may provide the best method to measure training transfer to realistic sport performance, while still allowing appropriate experimental control and high-fidelity performance measurements. The current study examined the effect of a biofeedback-driven augmented NMT (aNMT) on skill transfer of ACL-injury resistant movement patterns during performance of sport-specific VR scenarios. Five trained athletes participated, and their performance on an unanticipated cutting task was assessed in VR prior to and after six weeks of aNMT. A significant 87% reduction in internal hip rotation was observed on the plant leg during the loading phase of cutting (p = .05), along with an observed 116% reduction during the push-off phase (p = .02), from pre- to post-training. A non-significant trend of a 19% reduction in knee abduction was also observed (p = .15). This study is the first that has utilized free ambulatory wireless VR to assess injury risk in athletes during performance of sport-specific tasks. The reduction in internal hip rotation and knee abduction align with previous findings on laboratory based tests. The current results are the first step in the validation of sport-specific VR as a tool for understanding injury risk during simulation of real-world sport performance.",2331-9569,978-1-5090-3053-8,10.1109/ICVR.2017.8007511,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007511,anterior cruciate ligament;virtual reality;sport;cutting;soccer,Injuries;Hip;Training;Neuromuscular;Biomechanics;Knee;Virtual reality,biomechanics;injuries;medical computing;muscle;neurophysiology;patient rehabilitation;sport;virtual reality,sport-specific virtual reality;anterior cruciate ligament injury risk;unanticipated cutting;female athletes;posterior chain;hip recruitment;aberrant frontal knee loads;neuromuscular training;biofeedback-driven augmented NMT;hip neuromuscular control;corrected movement patterns;sport-specific contexts;realistic sport performance;ACL-injury resistant movement patterns;push-off phase;free ambulatory wireless VR;internal hip rotation;knee abduction,,1,,62,,14-Aug-17,,,IEEE,IEEE Conferences
Virtual surgery system for abdominal organs based on VR helmet,M. Liu; J. Deng; Y. Wang; X. Zhang; X. Zhang,"School of Computer, Electronics and Information, Guangxi University, Nanning, Guangxi 530004, P. R. China; School of Computer, Electronics and Information, Guangxi University, Nanning, Guangxi 530004, P. R. China; School of Computer, Electronics and Information, Guangxi University, Nanning, Guangxi 530004, P. R. China; School of Computer, Electronics and Information, Guangxi University, Nanning, Guangxi 530004, P. R. China; Guangxi Key Laboratory of Multimedia Communications and Network Technology, Guangxi University, Nanning, Guangxi 530004, P. R. China",2018 International Workshop on Advanced Image Technology (IWAIT),31-May-18,2018,,,1,4,"Now Days doctors interpret the human body abdomen via CT images, which is always lack of intuitive, three-dimensional viewing. Statistics show that 80% of clinical errors are caused by human error. Therefore surgical training for young surgeons is very important to their experience growth. In order to observe the body structure of the human body efficiently and improve the technical proficiency of doctors, this paper designs a surgical system for abdominal organs based on VR helmet. Using 3D Labeling algorithm and time varying phase difference algorithm, the system can automatically segment the organs in medical image and transfer the reconstruction of the human abdominal body into three-dimensional model, from which a VR helmet could perform a real-time visualization of the human organs in different viewpoints. Our system provides a virtual tool set (scalpel, surgical clamp) that enable the use of collision detection and cutting algorithm to achieve the cutting effects of the abdominal organs. Experimental results show that our system are robust to achieve the establishment of three-dimensional abdominal organ model, and virtual surgery tools could help doctors to simulate the operation completely together with the use of force-feedback device.",,978-1-5386-2615-3,10.1109/IWAIT.2018.8369801,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8369801,Three-dimensional reconstruction;VR helmet;Virtual surgery,Surgery;Solid modeling;Three-dimensional displays;Biomedical imaging;Tools;Computed tomography;Labeling,biological organs;computerised tomography;force feedback;image segmentation;medical image processing;surgery;virtual reality,virtual surgery tools;three-dimensional abdominal organ model;cutting algorithm;collision detection;surgical clamp;virtual tool set;human organs;three-dimensional model;human abdominal body;medical image;phase difference algorithm;3D Labeling algorithm;body structure;young surgeons;surgical training;human error;clinical errors;three-dimensional viewing;CT images;human body abdomen;VR helmet;abdominal organs;virtual surgery system,,1,,10,,31-May-18,,,IEEE,IEEE Conferences
Anthropomorphic robotic system with 6 DOF for space positioning in the virtual reality applications for human machine interaction,M. Chavez-Gamboa; I. Herrera-Aguilar; O. Sandoval-Gonzalez; F. Malagon-Gonzalez; J. M. Jacinto-Villegas,"The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico; The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico; The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico; The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico; The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico","CONIELECOMP 2013, 23rd International Conference on Electronics, Communications and Computing",13-Jun-13,2013,,,212,217,This paper presents a spatial hand tracking system using a 6 DOF anthropomorphic robot applied in human machine interaction. The main objective of this mechatronic system is to obtain information about the spatial position of a user's hand movements in order to be used like a skills trainer to accelerate the skills transfer from the machine to the human by integrating the laws of physics of virtual objects and adapting different design techniques and use of computer software for three-dimensional virtual reality.,,978-1-4673-6155-2,10.1109/CONIELECOMP.2013.6525788,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6525788,DOF;virtual reality;skills transfer;upper limbs;physical human-computer interaction;computational design,Virtual environments;Robots;Sensors;Software;Assembly;Kinematics,anthropology;gesture recognition;human-robot interaction;mechatronics;position control;robots;virtual reality,6 DOF anthropomorphic robotic system;space positioning;virtual reality applications;human machine interaction;spatial hand tracking system;mechatronic system;user hand movements;virtual objects;computer software;three-dimensional virtual reality,,,,18,,13-Jun-13,,,IEEE,IEEE Conferences
Can immersive type of Virtual Reality bring EMG pattern changes post facial palsy?,U. Qidwai; M. S. Ajimsha,"KINDI Lab for Computing Research, Department of Computer Science & Engineering, Qatar University, Doha, Qatar; Physiotherapy Specialist, Dept. of Physical Therapy, Hamad Medical Corporation, Doha, Qatar",2015 Science and Information Conference (SAI),3-Sep-15,2015,,,756,760,"The loss of facial expression via facial paralysis is a devastating condition, both functionally and aesthetically. However, given the life-long plasticity of the brain one could assume that recovery could be facilitated by the harnessing of mechanisms underlying neuronal reorganization. Currently it is not clear how this reorganization can be mobilized. Novel technology based neurorehabilitation techniques hold promise to address this issue. In this paper an immersive Virtual Reality (VR) based system is presented that is based on a number of hypotheses related to the neural structures targeted for recovery/reorganization, the structure of training system, and the role of individualization. The purpose of this paper is to examine the effects of an immersive type virtual reality (VR) intervention on activation of facial upper quadrant muscles following facial palsy in comparison with a control program. The key components of an immersive Virtual Reality (VR) based system and its effectiveness on facial palsy rehabilitation has been described in the form of experimental findings. Experimental trial was performed on an individual with facial upper quadrant muscles weakness due to facial palsy in a crossover study methodology with and without VR. EMG patterns from the facial upper quadrant muscles were recorded and analyzed for results. This trial has plotted a positive relationship between VR and facial upper quadrant muscles activation following a neurological impetus. The results reported here also show a consistent transfer of movement kinematics between physical and virtual tasks. EMG analysis has shown progressing improvement in the muscle activation in response to the challenging and impulsive activities in the virtual environment provided by the immersive VR devise.",,978-1-4799-8547-0,10.1109/SAI.2015.7237227,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7237227,Facial palsy;Virtual Reality;EMG-based measurements;Impulsive impetus,Muscles;Virtual reality;Electromyography;Training;Medical treatment;Neuroplasticity;Psychology,brain;electromyography;medical disorders;medical signal processing;neurophysiology;patient rehabilitation;virtual reality,EMG pattern;facial expression;facial paralysis;life-long plasticity;brain;neuronal reorganization;neurorehabilitation technique;neural structure recovery;neural structure reorganization;immersive virtual reality system;facial upper quadrant muscles;facial palsy rehabilitation;facial upper quadrant muscle weakness;neurological impetus;movement kinematics;physical task;virtual task;EMG analysis;muscle activation;impulsive activity;virtual environment,,,,19,,3-Sep-15,,,IEEE,IEEE Conferences
Thermal Characterization of a Virtual Reality Headset during Transient and Resting Operation,R. McAfee; C. Haxton; M. Harrison; J. Gess,"Oregon State University,204 Rogers Hall, Corvallis,OR,97331; Oregon State University,204 Rogers Hall, Corvallis,OR,97331; Oregon State University,204 Rogers Hall, Corvallis,OR,97331; Oregon State University,204 Rogers Hall, Corvallis,OR,97331","2020 36th Semiconductor Thermal Measurement, Modeling & Management Symposium (SEMI-THERM)",17-Jul-20,2020,,,131,136,"Virtual Reality (VR) is a powerful tool for maintenance process development, engineering design, pedagogy, and combat training. The evolution of the gaming industry has driven the demand for comfortable and reliable VR performance. By using the headset's user datasheet defined MicroController Unit's (MCU) operational temperature, the thermal resistance of the headset used in this study was found to have an external resistance, Rja, of 29.1 K/W, but 28.6% of this heat load is transmitted to the user. Relying on the user's body, specifically the forehead, as a heat sink results in uncomfortable perspiration during usage. Collected data show that after 2 hours of operation, the temperature increases 2.8¬∞C on average when the headset is removed from the user and placed at rest while still operational. The maximum temperature increase is 5.6¬∞C at the top of the VR headset, the surface nearest the internal MCU. This temperature spike proves that the headset needs more effective convective surface area in order to maintain a steady and comfortable operational temperature during ‚Äúheadset on‚Äù and ‚Äúheadset off‚Äù usage as the user's body was not available as a heat sink in the latter mode. A copper sheet has been added inside the headset to thermally connect all of the external surfaces on the device, effectively increasing the optimal convective heat transfer by 61%. The temperature nearest the MCU dropped 6.5¬∞C with the improved thermal management solution and users reported a 25% reduction in perspiration during prolonged use.",,978-0-578-43862-7,10.23919/SEMI-THERM50369.2020.9142850,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9142850,Wearable;thermal management;consumer products;Virtual Reality;comfort measurements;free convection;heat transfer,Headphones;Temperature measurement;Heating systems;Temperature distribution;Convection;Forehead,convection;cooling;heat sinks;microcontrollers;thermal resistance;virtual reality,optimal convective heat transfer;comfortable operational temperature;steady temperature;temperature spike;VR headset;maximum temperature increase;heat sink results;heat load;external resistance;thermal resistance;MCU;MicroController Unit's operational temperature;reliable VR performance;comfortable VR performance;maintenance process development;resting operation;virtual Reality headset;thermal characterization;time 2.0 hour,,,,8,,17-Jul-20,,,IEEE,IEEE Conferences
Thinking Penguin: Multimodal Brain‚ÄìComputer Interface Control of a VR Game,R. Leeb; M. Lancelle; V. Kaiser; D. W. Fellner; G. Pfurtscheller,"Center for Neuroprosthetics, √âcole Polytechnique F√©d√©rale de Lausanne (EPFL), Lausanne, Switzerland; Nanyang Technological University, Singapore, Singapore; Laboratory of Brain-Computer Interfaces, Institute for Knowledge Discovery, Graz University of Technology, Graz, Austria; Institute of Computer Graphics and Knowledge Visualization, Graz University of Technology, Austria; Emeritus Professor at the Laboratory of Brain-Computer Interfaces, Institute for Knowledge Discovery, Graz University of Technology, Graz, Austria",IEEE Transactions on Computational Intelligence and AI in Games,10-Jun-13,2013,5,2,117,128,"In this paper, we describe a multimodal brain-computer interface (BCI) experiment, situated in a highly immersive CAVE. A subject sitting in the virtual environment controls the main character of a virtual reality game: a penguin that slides down a snowy mountain slope. While the subject can trigger a jump action via the BCI, additional steering with a game controller as a secondary task was tested. Our experiment profits from the game as an attractive task where the subject is motivated to get a higher score with a better BCI performance. A BCI based on the so-called brain switch was applied, which allows discrete asynchronous actions. Fourteen subjects participated, of which 50% achieved the required performance to test the penguin game. Comparing the BCI performance during the training and the game showed that a transfer of skills is possible, in spite of the changes in visual complexity and task demand. Finally and most importantly, our results showed that the use of a secondary motor task, in our case the joystick control, did not deteriorate the BCI performance during the game. Through these findings, we conclude that our chosen approach is a suitable multimodal or hybrid BCI implementation, in which the user can even perform other tasks in parallel.",1943-0698,,10.1109/TCIAIG.2013.2242072,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6418003,Brain‚Äìcomputer interfaces (BCI);brain switch;game;hybrid BCI;multimodal;multitasking;virtual reality (VR),Games;Electroencephalography;Electrodes;Training;Brain computer interfaces;Educational institutions;Feature extraction,brain-computer interfaces;computer games;virtual reality,thinking penguin game;multimodal brain computer interface control;VR game;highly immersive CAVE;virtual environment;virtual reality game;jump action;game controller;BCI performance;discrete asynchronous action;visual complexity;task demand;joystick control;hybrid BCI implementation,,49,,51,,23-Jan-13,,,IEEE,IEEE Journals
A semi-physical virtual simulation system for AUV,Wang Hong-jian; Shi Xiao-cheng; Zhao Jie; Li Juan; Fu Ming-yu,"Dept, of Mechatronic Eng., Harbin Inst. of Technol., China; Dept, of Mechatronic Eng., Harbin Inst. of Technol., China; Dept, of Mechatronic Eng., Harbin Inst. of Technol., China; NA; NA",Oceans '04 MTS/IEEE Techno-Ocean '04 (IEEE Cat. No.04CH37600),14-Mar-05,2004,3,,1560,1563 Vol.3,"Just as Healey and Brutzman(1997) stated that ""... a critical bottleneck exists in AUV design and development"". Integrated simulator testing of AUV software and hardware is a broad and versatile method that supports rapid diagnosis and robust correction of system faults in the lab environment. So a semi-physical virtual simulation system for AUV is developed based on software developing platform-MultiGen Creator and Vega, and acts as an effective capable tool for long range training and intelligent behavioral operation for AUV. It is the objective of such design and development work to simulate a large-scale oceanic environment and to demonstrate a dynamic procedure of AUV under the control of the autonomous planning technology and the dynamic controlling technology. Some schemes about hardware topology architecture and software architecture of AUV simulation system are presented in the paper. Some mathematic models of AUV motion, the method of space consistency in visual simulation and data transfer mechanisms are also detailed introduced. All of above-mentioned forms a basis for integrating the intelligence technology and virtual simulation technology into the semi-physical simulation system. Finally, some real-time operational experiment results are presented at form of three-dimensional graphics, which is simulating the ocean exploration progress of AUV in virtual reality under the control of intelligence. The result shows that the simulation system is reasonable and reliable, that the mathematics model and simulation algorithm completely satisfy the real-time requirement, and that the simulation system can realistically demonstrate the simulation process of AUV. This semi-physical simulation system has been successfully applied to validate the correctness, validity and practicability for the autonomous planning algorithms and dynamic control algorithm of a certain AUV",,0-7803-8669-8,10.1109/OCEANS.2004.1406354,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1406354,,Space technology;Marine technology;Hardware;Mathematics;Mathematical model;Heuristic algorithms;Software testing;System testing;Fault diagnosis;Robustness,oceanographic equipment;oceanographic techniques;remotely operated vehicles;test equipment;underwater vehicles;virtual reality,semiphysical virtual simulation system;autonomous underwater vehicle;integrated simulator testing;AUV software;AUV hardware;MultiGen Creator;Vega;long range training;intelligent behavioral operation;oceanic environment simulation;autonomous planning algorithm;dynamic control algorithm;hardware topology architecture;software architecture;mathematical model;AUV motion;visual simulation;data transfer;real-time operational experiment;3D graphics;ocean exploration;virtual reality,,1,,9,,14-Mar-05,,,IEEE,IEEE Conferences
Parameter evaluation for virtual Laparoscopic simulation,S. B. Mansoor; Z. Mukhtar; M. Malik; Z. Amjad; H. Qureshi,"School of EECS, National university of Sciences & Technology, Islamabad, Pakistan; School of EECS, National university of Sciences & Technology, Islamabad, Pakistan; School of EECS, National university of Sciences & Technology, Islamabad, Pakistan; School of EECS, National university of Sciences & Technology, Islamabad, Pakistan; School of EECS, National university of Sciences & Technology, Islamabad, Pakistan",2011 7th International Conference on Emerging Technologies,20-Oct-11,2011,,,1,6,"Virtual Reality based surgical simulators have become quite common for training of surgeons for different surgical skills. Simulators have been widely used particularly in minimal invasive surgery. In this paper we find parameters that would be required to create a real time working simulation for exercises given in the Fundamentals of Laparoscopic Surgery curriculum. We use peg transfer exercise as our example in this work and create simulations for parameter analysis using SOFA, an open source surgical framework [1]. The parameters we choose are generic and can be used to create other more complex simulations like cholecystectomy [2] (gall bladder removal) and appendectomy (appendix removal). We show the implementation of these parameters and their behavior in a virtual reality surgical simulation. This work can be used by researchers and developers to choose the right parameters in the context of the simulation they are developing. It also shows the cost and behavior of achieving good visualization (frames per second), physical characteristics and a realistic behavioral model to be used in simulations for training purposes.",,978-1-4577-0768-1,10.1109/ICET.2011.6048481,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6048481,Surgical Simulations;Virtual Reality;Biomechanical Modeling;Laparoscopic Surgery,Solid modeling;Surgery;Finite element methods;Computational modeling;Floors;Springs;Deformable models,data visualisation;digital simulation;medical computing;surgery;virtual reality,parameter evaluation;virtual laparoscopic simulation;virtual reality based surgical simulator;surgical skills;laparoscopic surgery curriculum;peg transfer exercise;parameter analysis;SOFA;open source surgical;complex simulation;cholecystectomy;appendectomy;realistic behavioral model,,,,15,,20-Oct-11,,,IEEE,IEEE Conferences
Multi-User Virtual System for Training of the Production and Bottling Process of Soft Drinks,J. I. Zambrano; D. A. Bermeo; C. A. Naranjo; V. H. Andaluz,"Universidad de las Fuerzas Armadas ESPE,Sangolqu√≠,Ecuador; Universidad de las Fuerzas Armadas ESPE,Sangolqu√≠,Ecuador; Universidad de las Fuerzas Armadas ESPE,Sangolqu√≠,Ecuador; Universidad de las Fuerzas Armadas ESPE,Sangolqu√≠,Ecuador",2020 15th Iberian Conference on Information Systems and Technologies (CISTI),15-Jul-20,2020,,,1,7,"The project consists of developing a virtual operational training system for the production and bottling process carried out in the soft drinks factory. For the virtualization of the industrial process, mathematical modeling is considered using a transfer function of the first order with downtime and control in relation to the flow plants that make up the substance mixing station in the company, for this, dynamic data and behaviors of the fully automated flow plants within the university are used and not the conventional station existing in the company, since its machines and data are kept confidential In addition, 3D CAD design techniques, electric diagrams of the process and instrumentation (P&ID) are used, all in order for multiple users to have immersive experiences sensory and can interact with each other within a virtual environment.",2166-0727,978-989-54659-0-3,10.23919/CISTI49556.2020.9141140,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141140,Virtual environment;Production and bottling process;Unity 3D;Multiple users;Training;4.0 Industry,Process control;Mathematical model;Training;Production facilities;Virtual environments;Industries,beverage industry;bottling;CAD;chemioception;computer based training;industrial plants;instrumentation;mathematical analysis;mixing;production engineering computing;virtual reality;virtualisation,mathematical modeling;transfer function;substance mixing station;3D CAD design techniques;multiuser virtual system;bottling process;virtual operational training system;soft drinks factory;virtualization;industrial process;automated flow plants;production process;electric diagrams;instrumentation;sensory experience,,,,17,,15-Jul-20,,,IEEE,IEEE Conferences
Advantages of Virtual Reality in the Teaching and Training of Radiation Protection during Interventions in Harsh Environments,A. Cryer; G. Kapellmann-Zafra; S. Abrego-Hern√°ndez; H. Marin-Reyes; R. French,"Department of Physics and Astronomy, University of Sheffield; Department of Physics and Astronomy, University of Sheffield; Department of Physics and Astronomy, University of Sheffield; Department of Physics and Astronomy, University of Sheffield; Department of Physics and Astronomy, University of Sheffield",2019 24th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA),17-Oct-19,2019,,,784,789,"Human interventions in radioactive environments have high stakes. They are often time-sensitive and radiation exposure must be minimised for the safety of personnel. Existing sites were not developed with remote decommissioning in mind, therefore human intervention remains the preferred approach for dexterous manual labour over robotic systems. For ageing sites, knowledge transfer after retirement is an increasingly relevant problem for maintenance and decommissioning tasks, where new workers lack the in-depth ‚Äúon the ground‚Äù experience of the installation. Virtual Reality provides workers the agency to explore an accurate representation of the area, enabling them to gain experience without undue radiation exposure. This paper explores and discusses the teaching and training applications of a Virtual Reality environment with integrated radiation dose maps, and looks at where the system may be developed further.",1946-0759,978-1-7281-0303-7,10.1109/ETFA.2019.8869433,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869433,,Detectors;Task analysis;Solid modeling;Virtual reality;Training;Headphones;Large Hadron Collider,dosimetry;fission reactor decommissioning;personnel;radiation protection;virtual reality,radiation protection;harsh environments;human intervention;radioactive environments;remote decommissioning;dexterous manual labour;robotic systems;maintenance tasks;decommissioning tasks;teaching applications;training applications;virtual reality environment;integrated radiation dose maps;maintenance,,,,28,,17-Oct-19,,,IEEE,IEEE Conferences
Virtual Reality as Cost Effective Tool for Distance Healthcare,R. Papara; R. Galatus; L. Buzura,"Technical University of Cluj-Napoca,Memorandumului 28th, Cluj-Napoca,Romania; Technical University of Cluj-Napoca,Memorandumului 28th, Cluj-Napoca,Romania; Technical University of Cluj-Napoca,Memorandumului 28th, Cluj-Napoca,Romania",2020 22nd International Conference on Transparent Optical Networks (ICTON),22-Sep-20,2020,,,1,6,"VR can provide a rich, interactive environment in distance assisted actions for serious games in healthcare. The location-based decisions can be transferred for distance-based assisted decisions, when the specialists cannot be present in time at the probe/case location. The specialists can consult at distance, a probe in the real lab, by using images that are taken with high resolution cameras and that are sent over the internet. In advanced healthcare the virtual environment is conducted by a surgeon and decision is transmitted to a robotic instrument that mimics the actions. In this case the cost effective solution refers to regular healthcare activity such as visual assisted diagnosis in real time, training of the specialists, assessing a situation and give an expert opinion on it, future actions and treatment. The advancement in technology allowed VR systems to run on personal computers thus decreasing the implementation cost for a sophisticated system. In the present implementation, a cost-effective solution is presented. The solution is easy to use by the medical specialists and is helpful to compensate the time-delay for the doctor mobility at the probe/case location. A user-friendly interface was developed in order to facilitate the communication between a specialist in the lab and the expert at distance, using the immersive technology of VR, in order to replicates an environment via computer-simulated reality.",2161-2064,978-1-7281-8423-4,10.1109/ICTON51198.2020.9203420,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9203420,virtual reality;interface for communication;camera distance-assisted diagnosis;smartphone assisted;real time transmission;healthcare,Medical services;Glass;Webcams;Software;Probes;Robots,health care;Internet;virtual reality,virtual reality;cost effective tool;distance healthcare;interactive environment;distance assisted actions;serious games;location-based decisions;distance-based assisted decisions;high resolution cameras;virtual environment;surgeon;robotic instrument;regular healthcare activity;visual assisted diagnosis;VR systems;implementation cost;cost-effective solution;time-delay;computer-simulated reality,,,,11,,22-Sep-20,,,IEEE,IEEE Conferences
Maintenance of Complex Machines in Electric Power Systems Using Virtual Reality Techniques,B. Arendarski; W. Termath; P. Mecking,"Fraunhofer Institute for Factory Operation and Automation (IFF), Sandtorstrasse 22, 39106 Magdeburg, Germany. bartlomiej.arendarski@iff.fraunhofer.de; Fraunhofer Institute for Factory Operation and Automation (IFF), Sandtorstrasse 22, 39106 Magdeburg, Germany; RWE Rhein-Ruhr-Netzservice GmbH, Reeser Landstrasse 41, 46483 Wesel, Germany",Conference Record of the 2008 IEEE International Symposium on Electrical Insulation,18-Jul-08,2008,,,483,487,"This paper illustrates how virtual reality (VR) techniques can be used in electric power systems visualization and how this can increase effectiveness of vocational training in field of power industry. The content of this article is based on a project oriented to specialized staff members, dealing with maintenance, repairs and diagnostics of complex machines such transformers and generators. Introducing a scheme that integrates VR technologies to electrical machines and equipment provides an efficient tool for implementing operator training methods. Three-dimensional (3D) visualization brings a new ways of knowledge transfer and education regarding complex equipment.",1089-084X,978-1-4244-2091-9,10.1109/ELINSL.2008.4570378,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4570378,,Virtual reality;Vocational training;Industrial training;Visualization;Transformers;Power system planning;Design engineering;Computational modeling;Testing;Power system modeling,electric generators;power systems;transformers;virtual reality,electric power systems;virtual reality;complex machines maintenance;power industry;transformers;generators;3D visualization,,17,,10,,18-Jul-08,,,IEEE,IEEE Conferences
WAVE: Interactive Wave-based Sound Propagation for Virtual Environments,R. Mehra; A. Rungta; A. Golas; M. Lin; D. Manocha,UNC Chapel Hill; UNC Chapel Hill; UNC Chapel Hill; UNC Chapel Hill; UNC Chapel Hill,IEEE Transactions on Visualization and Computer Graphics,20-Mar-15,2015,21,4,434,442,"We present an interactive wave-based sound propagation system that generates accurate, realistic sound in virtual environments for dynamic (moving) sources and listeners. We propose a novel algorithm to accurately solve the wave equation for dynamic sources and listeners using a combination of precomputation techniques and GPU-based runtime evaluation. Our system can handle large environments typically used in VR applications, compute spatial sound corresponding to listener's motion (including head tracking) and handle both omnidirectional and directional sources, all at interactive rates. As compared to prior wave-based techniques applied to large scenes with moving sources, we observe significant improvement in runtime memory. The overall sound-propagation and rendering system has been integrated with the Half-Life 2 game engine, Oculus-Rift head-mounted display, and the Xbox game controller to enable users to experience high-quality acoustic effects (e.g., amplification, diffraction low-passing, high-order scattering) and spatial audio, based on their interactions in the VR application. We provide the results of preliminary user evaluations, conducted to study the impact of wave-based acoustic effects and spatial audio on users' navigation performance in virtual environments.",1941-0506,,10.1109/TVCG.2015.2391858,Advanced Simulation and Training; ARO Contracts; National Science Foundation; Impulsonic Inc.; Acoustect SDK; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7014276,Sound propagation;dynamic sources;spatial sound;Sound propagation;dynamic sources;directivity;spatial sound;Helmholtz equation,Runtime;Acoustics;Vectors;Transfer functions;Virtual environments;Linear systems;Navigation,acoustic wave propagation;graphics processing units;rendering (computer graphics);virtual reality;wave equations,WAVE;interactive wave-based sound propagation;virtual environments;dynamic sources;wave equation;GPU-based runtime evaluation;VR applications;omnidirectional sources;rendering system;Half-Life 2 game engine;Oculus-Rift head-mounted display;Xbox game controller;high-quality acoustic effects;spatial audio;wave-based acoustic effects;user navigation performance,Acoustic Stimulation;Adult;Algorithms;Computer Graphics;Female;Humans;Male;Sound;User-Computer Interface;Video Games;Young Adult,20,,43,,19-Jan-15,,,IEEE,IEEE Journals
Development of a brachial plexus blocker prototype,S. C. Monteiro,"Escola Superior de Tecnologia e Gest√£o - Instituto Polit√©cnico de Bragan√ßa, Alameda de Santa Apol√≥nia, 5300-253 Bragan√ßa, Bragan√ßa, Portugal",2017 12th Iberian Conference on Information Systems and Technologies (CISTI),13-Jul-17,2017,,,1,6,"Although the area of surgical simulation has been the subject of study in recent years, it is still necessary to develop artificial experimental models with a perspective to dismiss the use of biological models. Since this makes the simulators more real, transferring the environment of the health professional to a physical or virtual reality, an anesthetic prototype has been developed, where the motor response is replicated when the brachial plexus is subjected to a proximal nervous stimulus. Using action-research techniques, with this simulator it was possible to validate that the human nerve response can be replicated, which will aid the training of health professionals, reducing possible risks in a surgical environment.",,978-9-8998-4347-9,10.23919/CISTI.2017.7976010,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7976010,Anesthesia;Simulation;brachial plexus blockade;Arduino;3D Print,Visualization;Solid modeling;Biological system modeling;Monitoring;Three-dimensional displays;Brachytherapy;Adaptation models,computer based training;digital simulation;medical computing;professional aspects;surgery;virtual reality,brachial plexus blocker prototype;surgical simulation;biological models;physical system;virtual reality;anesthetic prototype;motor response;proximal nervous stimulus;action-research techniques;human nerve response;health professional training;risk reduction;surgical environment,,,,8,,13-Jul-17,,,IEEE,IEEE Conferences
Evaluating exemplary training accelerators for Programming-by-Demonstration,T. Hulin; V. Schmirgel; E. Yechiam; U. E. Zimmermann; C. Preusche; G. P√∂hler,"Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; KUKA Roboter GmbH, Germany; Faculty of Industrial Engineering and Management, Technion, Israel; KUKA Roboter GmbH, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Otto-von-Guericke University, Magdeburg, Germany",19th International Symposium in Robot and Human Interactive Communication,11-Oct-10,2010,,,440,445,"Robot Programming by Demonstration requires comprehending the usage of a robotic system. This article is about accelerating the training of these skills, using the example of a DLR/KUKA light-weight robot. An augmented reality and a virtual reality setup are presented that aim to demonstrate and evaluate skills transfer of two different sub-tasks of this system: Avoiding robot singularities and setting correct compliance parameters. For this purpose training accelerators are introduced for visualising robot singularities, exploring robot singularities and feeling compliance parameters. An evaluation procedure for all three accelerators is suggested and has been performed on the first two. As interesting evaluation result a contrast to the Cognitive Theory of Multimedia Learning hypothesis could be observed: Additional visual information on the robot singularities impairs the participants' performance.",1944-9437,978-1-4244-7990-0,10.1109/ROMAN.2010.5598611,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5598611,,Robots;Visualization;Training;Haptic interfaces;Games;Joints;Collision avoidance,augmented reality;automatic programming;industrial robots;robot programming,exemplary training accelerators;robot programming by demonstration;DLR/KUKA light-weight robot;augmented reality;virtual reality;robot singularities;multimedia learning hypothesis;cognitive theory,,6,1,21,,11-Oct-10,,,IEEE,IEEE Conferences
Street Crossing by Typically Developed Children in Real and Virtual Environments,O. Bart; N. Katz; P. L. Tamar; W. W. Josman; N. Josman,"Dept. of Occupational Therapy, Tel Aviv Univ.; NA; NA; NA; NA",2006 International Workshop on Virtual Rehabilitation,9-Oct-06,2006,,,42,46,"Pedestrian injury is the second leading cause of death and serious injury among children between the ages of 5 and 14. The existing methods for teaching children how to cross the street safely are difficult to transfer to real life situations. The objective of this study was to evaluate the effectiveness of a virtual reality (VR) environment in teaching children how to cross a street safely. Eighty-six children (55 girls and 31 boys), aged 7-12 years, participated in the study. The children were observed while crossing a real street and tested on a test in the virtual environment (VE) prior to and following VR training. The children in the training group significantly improved their street crossing abilities in the VR simulation as well as in the real street crossing in comparison to the control group. Street crossing became safer with age however, no differences were found between boys and girls. This low-cost and readily available street crossing simulation had a positive effect on children's street crossing behavior and on their self-reported satisfaction",2331-9569,1-4244-0280-8,10.1109/IWVR.2006.1707525,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1707525,,Injuries;Virtual reality;Safety;Medical treatment;Education;Road accidents;Testing;Aging;Virtual environment;Cancer,computer aided instruction;psychology;road safety;road traffic;teaching;virtual reality,street crossing;pedestrian injury;teaching;virtual reality environment;street safety,,1,,44,,9-Oct-06,,,IEEE,IEEE Conferences
Furthering Service 4.0: Harnessing Intelligent Immersive Environments and Systems,A. Pena-Rios; H. Hagras; G. Owusu; M. Gardner,"Intelligent Environments Research Group, University of Essex, Colchester, United Kingdom; Intelligent Environments Research Group, University of Essex, Colchester, United Kingdom; Business Modelling and Operational Transformation Practice, British Telecom, Ipswich, United Kingdom; Intelligent Environments Research Group, University of Essex, Colchester, United Kingdom","IEEE Systems, Man, and Cybernetics Magazine",17-Jan-18,2018,4,1,20,31,"With the increasing complexity of service operations in different industries and more advanced uses of specialized equipment and procedures, the great current challenge for companies is to increase employees' expertise and their ability to maintain and improve service quality. In this regard, Service 4.0 aims to support and promote innovation in service operations using emergent technology. Current technological innovations present a significant opportunity to provide on-site, real-time support for field service professionals in many areas. It should be no surprise, then, that intelligent immersive environments have the potential to enhance service operations by improving customer service and increasing overall efficiency. Intelligent immersive systems combine immersive technologies with computational intelligence mechanisms to produce adaptive, context-aware environments for advanced decisionmaking support. Such technologies, e.g., mixed reality (MR) and augmented reality (AR), can potentially enhance working environments, optimizing resources by reducing time and location restrictions, leading to much faster knowledge transfer and a deeper understanding of different processes. These methods can also promote faster response times to provide field service technicians with on-the-job assistance in unfamiliar situations.",2333-942X,,10.1109/MSMC.2017.2769199,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260586,,Maintenance engineering;Training;Virtual reality;Tracking;Complexity theory;Industries;Service-oriented systems engineering,augmented reality;customer services;innovation management;knowledge management;personnel;ubiquitous computing,real-time support;service operations;customer service;intelligent immersive systems;computational intelligence mechanisms;context-aware environments;advanced decisionmaking support;field service technicians;service quality;technological innovations;intelligent immersive environments;employee expertise,,4,,70,,17-Jan-18,,,IEEE,IEEE Magazines
ImmerVol: An immersive volume visualization system,N. M. Khan; M. Kyan; L. Guan,"Department of Electrical and Computer Engineering, Ryerson University, Canada; Department of Electrical and Computer Engineering, Ryerson University, Canada; Department of Electrical and Computer Engineering, Ryerson University, Canada",2014 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA),23-Jun-14,2014,,,24,29,"Volume visualization is a popular technique for analyzing 3D datasets, especially in the medical domain. An immersive visual environment provides easier navigation through the rendered dataset. However, visualization is only one part of the problem. Finding an appropriate Transfer Function (TF) for mapping color and opacity values in Direct Volume Rendering (DVR) is difficult. This paper combines the benefits of the CAVE Automatic Virtual Environment with a novel approach towards TF generation for DVR, where the traditional low-level color and opacity parameter manipulations are eliminated. The TF generation process is hidden behind a Spherical Self Organizing Map (SSOM). The user interacts with the visual form of the SSOM lattice on a mobile device while viewing the corresponding rendering of the volume dataset in real time in the CAVE. The SSOM lattice is obtained through high-dimensional features extracted from the volume dataset. The color and opacity values of the TF are automatically generated based on the user's perception. Hence, the resulting TF can expose complex structures in the dataset within seconds, which the user can analyze easily and efficiently through complete immersion.",2377-9322,978-1-4799-2614-5,10.1109/CIVEMSA.2014.6841433,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6841433,,Image color analysis;Rendering (computer graphics);Lattices;Data visualization;Vectors;Training;Three-dimensional displays,data visualisation;feature extraction;image colour analysis;medical computing;opacity;rendering (computer graphics);self-organising feature maps;transfer functions;vectors,ImmerVol;immersive volume visualization system;3D datasets analysis;medical domain;navigation;rendered dataset;transfer function;color values;opacity values;direct volume rendering;DVR;CAVE;automatic virtual environment;spherical self organizing map;SSOM;feature extraction,,,,19,,23-Jun-14,,,IEEE,IEEE Conferences
Virtual Multi-Interaction for Rehabilitation Robotics,W. Li; A. Rovetta; X. Ding; L. Chen; Y. Han,"Beijing Microelectron. Technol. Inst., Beijing, China; School of Mechanical Engineering and Automation, Beihang University,Beijing, BJ,P.R.China,10086; School of Mechanical Engineering and Automation, Beihang University,Beijing, BJ,P.R.China,10086; Beijing Microelectronics Technology Institute,Beijing, BJ,P.R.China,10076; Beijing Microelectronics Technology Institute,Beijing, BJ,P.R.China,10076",2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM),14-Sep-20,2020,,,204,208,"This article is to develop an intelligent exoskeleton to support the wearable, interactive and customizable path on the rehabilitation needs of falling foot. In collaboration with engineers and doctors from Milan and Beijing, it is to realize an active device that performs function adapting perfectly to the anatomical characteristics of each subject, and it would supply greater possibilities and flexibility. Traditional devices are passive rigid orthoses (AFO) and active peroneal stimulation systems (FES). Although simple and cheap, AFO system can bring about phenomena of adaptation at the central level that gradually decrease muscle activity over time. More is the stiffness in the path. FES devices ensure a more natural movement of the foot but without control autonomy. Moreover, the efficiency is always limited with high costs. According analysis of the path, anatomy and biomechanics of the calf, considering combination of sensing and interaction technologies and devices, it focuses on using MEMS inertial sensors and force sensors to make a fusion and measure state of the calf's motion and attitude. It also uses 3D printing to construct lightweight and customable structures. The mobile device is used as local center to transfer data and feedback with Bluetooth and Internet, to give instruction and detect emotion with voice. Virtual Reality is used to build training scenes combined with rehabilitation plan, connections and feedbacks are also built between vision and motion states to form closed loop control. It expounds system construction, virtual scene construction, control method design, system tests, etc. according rehabilitation application, and preliminary application data indicates that the whole system works well with low cost and high efficiency.",,978-1-7281-6479-3,10.1109/ICARM49381.2020.9195384,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195384,,Exoskeletons;Cloud computing;Servers;Robots;Software;Training;Control systems,biomechanics;Bluetooth;closed loop systems;feedback;force sensors;Internet;medical robotics;microsensors;muscle;neuromuscular stimulation;patient rehabilitation;virtual reality,system construction;closed loop control;motion states;virtual reality;mobile device;lightweight structures;force sensors;MEMS inertial sensors;biomechanics;FES devices;muscle activity;central level;active peroneal stimulation systems;passive rigid orthoses;anatomical characteristics;intelligent exoskeleton;rehabilitation robotics;virtual multiinteraction;rehabilitation application;control method design;virtual scene construction,,,,13,,14-Sep-20,,,IEEE,IEEE Conferences
Optimal Wireless Charging Inclusive of Intellectual Routing Based on SARSA Learning in Renewable Wireless Sensor Networks,N. Aslam; K. Xia; M. U. Hadi,"School of Electronics and Information Engineering, Hebei University of Technology, Tianjin, China; School of Electronics and Information Engineering, Hebei University of Technology, Tianjin, China; Department of Electrical, Electronic and Information Engineering, Universita degli Studi di Bologna, Bologna, Italy",IEEE Sensors Journal,15-Aug-19,2019,19,18,8340,8351,"The next generation's sensor nodes will be more intelligent, energy conservative, and perpetual lifetime in the set-up of wireless sensor networks (WSNs). These sensors nodes are facing the overwhelming challenge of energy consumption which gradually decreases the lifetime of overall network. The wireless power transfer (WPT) is one of the most emerging technologies of energy harvesting that deploys at the heart of sensor nodes for efficient lifetime solution. A wireless portable charging device (WPCD) is drifting inside the WSN to recharge all the nodes which are questing for the eternal life. In this paper, we aspire to optimize a multi-objective function for charging trail of WPCD, and self-learning algorithm for data routing jointly. We formulated that the objective functions can optimize the fair energy consumption as well as maximize the routing efficiency of WPCD. The fundamental challenge of the problem is, to integrate the novel path for WPCD by applying the Nodal A* algorithm. We proposed a novel method of sensor node's training for intellectual data transmission by using of clustering and reinforcement learning (SARSA) defined as clustering SARSA (C-SARSA) along with an optimal solution of objective functions. The whole mechanism outperforms in terms of trade-off between energy consumption and stability (fair energy consumption among all nodes) of the WSN; moreover, it prolongs the lifetime of the WSN. The simulated results demonstrate that our proposed method did better than compared literature in terms of energy consumption, stability, and lifetime of the WSN.",1558-1748,,10.1109/JSEN.2019.2918865,Key Supporting Project of Joint Fund of the National Natural Science Foundation of China; Natural Science Foundation of Tianjin City; Natural Science Foundation of Hebei Province; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721665,Clustering;energy conservation;energy harvesting;machine learning (SARSA);wireless power transfer;wireless sensor network;wireless portable charging device,Wireless sensor networks;Energy consumption;Routing;Sensors;Batteries;Energy harvesting;Wireless communication,energy conservation;learning (artificial intelligence);optimisation;pattern clustering;radiofrequency power transmission;telecommunication computing;telecommunication network routing;telecommunication power management;wireless sensor networks,optimal wireless charging inclusive;intellectual routing;SARSA learning;renewable wireless sensor networks;sensor nodes;energy conservative;perpetual lifetime;sensors nodes;wireless power transfer;energy harvesting;efficient lifetime solution;wireless portable charging device;WPCD;WSN;multiobjective function;self-learning algorithm;data routing;objective functions;fair energy consumption;routing efficiency;sensor node;clustering;reinforcement learning,,5,,42,,24-May-19,,,IEEE,IEEE Journals
Fork-lift truck simulator for training in industrial environment,M. Bergamasco; S. Perotti; C. A. Avizzano; M. Angerilli; M. Carrozzino; E. Ruffaldi,"PERCRO, Pontedera, Italy; PERCRO, Pontedera, Italy; PERCRO, Pontedera, Italy; PERCRO, Pontedera, Italy; PERCRO, Pontedera, Italy; PERCRO, Pontedera, Italy",2005 IEEE Conference on Emerging Technologies and Factory Automation,3-Apr-06,2005,1,,5 pp.,693,"Since their first usage simulators have been employed in training staff in civil aeronautics and in military fields to improve driving skills without compromising safety of people and machines. The system proposed in this paper is suited to transfer this activity into the industrial field, in particular an innovative fork-lift simulator is presented. Actually most frequent causes of accident with fork-lifts are wrong manoeuvres accomplished by drivers. This simulator aims to improve skills in driving and handling materials using a fork-lift. The system can reply inertial feedback on the operator and allows the user to control all the tasks of a fork-lift as driving and handling materials. The paper presents an overall view of the system including Stewart platform, supporting structure, physical based model, wash-out filter, system architecture and a video system mounted on board of the moving platform",1946-0759,0-7803-9401-1,10.1109/ETFA.2005.1612593,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1612593,,Industrial training;Aerospace simulation;Personnel;Paper mills;Employment;Visualization;Defense industry;Industrial accidents;Context modeling;Cranes,accidents;fork lift trucks;industrial training,fork-lift truck simulator;industrial training;civil aeronautics;military fields;driving skills;accident;operator;Stewart platform;supporting structure;wash-out filter;system architecture;video system,,4,,11,,3-Apr-06,,,IEEE,IEEE Conferences
Finger-based manipulation in immersive spaces and the real world,E. Chapoulie; T. Tsandilas; L. Oehlberg; W. Mackay; G. Drettakis,"Inria, France; Inria, Univ Paris-Sud, France; Inria, Univ Paris-Sud, France; Inria, Univ Paris-Sud, France; Inria, France",2015 IEEE Symposium on 3D User Interfaces (3DUI),25-Jun-15,2015,,,109,116,"Immersive environments that approximate natural interaction with physical 3D objects are designed to increase the user's sense of presence and improve performance by allowing users to transfer existing skills and expertise from real to virtual environments. However, limitations of current Virtual Reality technologies, e.g., low-fidelity real-time physics simulations and tracking problems, make it difficult to ascertain the full potential of finger-based 3D manipulation techniques. This paper decomposes 3D object manipulation into the component movements, taking into account both physical constraints and mechanics. We fabricate five physical devices that simulate these movements in a measurable way under experimental conditions. We then implement the devices in an immersive environment and conduct an experiment to evaluate direct finger-based against ray-based object manipulation. The key contribution of this work is the careful design and creation of physical and virtual devices to study physics-based 3D object manipulation in a rigorous manner in both real and virtual setups.",,978-1-4673-6886-5,10.1109/3DUI.2015.7131734,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7131734,Immersive Cube-like Displays;Finger-based manipulation;Real/virtual world comparison,Three-dimensional displays;Haptic interfaces;Friction;Color;Visualization;Needles,virtual reality,finger-based manipulation;immersive spaces;real world;immersive environments;natural interaction;user sense-of-presence;performance improvement;users skills;virtual environments;virtual reality technologies;low-fidelity real-time physics simulations;tracking problems;finger-based 3D manipulation techniques;3D object manipulation;component movements;physical constraints;physical mechanics;physical devices;experimental conditions;immersive environment;ray-based object manipulation;physics-based 3D object manipulation,,4,,29,,25-Jun-15,,,IEEE,IEEE Conferences
Transfer of Coordination Skill to the Unpracticed Hand in Immersive Environments,S. Xiao; X. Ye; Y. Guo; B. Gao; J. Long,"Jinan University,College of Information Science and Technology,Guangzhou,China,510640; Jinan University,College of Information Science and Technology,Guangzhou,China,510640; Jinan University,College of Information Science and Technology,Guangzhou,China,510640; Jinan University,College of Information Science and Technology,Guangzhou,China,510640; Jinan University,College of Information Science and Technology,Guangzhou,China,510640",2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),11-May-20,2020,,,258,265,"Physical practice with one hand results in performance gains of the other (un-practiced) hand in a unilateral motor task. Yet how it induces performance gains of interlimb coordination in the bimanual movements between trained limb and the opposite, untrained limb is unclear. The present study designed a game-like interactive system for physical practice, in which an avatar‚Äôs hands could be controlled itself or by the subject during a bimanual movement task in an immersive virtual reality environment. Participants practiced with the bimanual task by simultaneously drawing non-symmetric three-sided squares (e.g., U and C) to learn limb coordination with the following training strategies: (1) performing and seeing a bimanual task (BH-BH); (2) performing a unimanual task with right hand and seeing a bimanual action (RH-BH); (3) not performing a task but seeing a bimanual action (noH-BH); (4) performing and seeing a unimanual task (RH-RH). We found that the learning performance was better after BH-BH and RH-BH compared with other training strategies. In addition, we examined the effects of virtual hand representations on the learning performance after RH-BH. We found that the performance after training was increased with the realism level of virtual hands. These findings suggest that the proposed approach of RH-BH with realistic virtual hand would result in transfer of coordination skill to the unpracticed hand, which puts forward a new approach for learning and rehabilitation of coordination skill in patients with unilateral motor deficit in immersive environments.",2642-5254,978-1-7281-5608-8,10.1109/VR46266.2020.00045,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9089455,Avatar hands;bimanual movement;coordination skill;virtual reality,Training;Task analysis;Visualization;Thumb;Shape;Virtual reality,,,,,,27,,11-May-20,,,IEEE,IEEE Conferences
An audio game for training navigation skills of blind children,K. Allain; B. Dado; M. Van Gelderen; O. Hokke; M. Oliveira; R. Bidarra; N. D. Gaubitch; R. C. Hendriks; B. Kybartas,"Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands",2015 IEEE 2nd VR Workshop on Sonic Interactions for Virtual Environments (SIVE),28-Dec-15,2015,,,1,4,"Training blind children to use audio-based navigation is a demanding and risky task, as children can walk into objects and hurt themselves. Furthermore, training outdoors is dangerous due to traffic, noise and weather conditions. Having a controlled indoor environment is safer but not always available. To tackle this problem, we developed an audio-based computer game, Legend of Iris (LOI), specifically designed to train navigation skills. The game is a 3D exploration game, which uses the headtracking capabilities of the Oculus Rift to create an immersive experience, and the new sound libraries AstoundSound and Phonon3D, to generate an accurate and realistic soundscape. These libraries use a head-related transfer function, allowing the player to localize the audio source in 3D space. The design of LOI involved selecting sounds that are easily recognizable to provide cues to blind people playing the game. A subset of these cues were incorporated into the game. To verify the effectiveness of the game in developing audio orientation and navigation skills, we performed a preliminary qualitative experiment with blind children in a dedicated school. LOI scored high in terms of accuracy and immersion, but a larger test is required to make statistical conclusions.",,978-1-4799-1969-7,10.1109/SIVE.2015.7361292,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7361292,,Games;Navigation;Training;Libraries;Visualization;Three-dimensional displays;Transfer functions,acoustic noise;hearing;transfer functions,audio game;training navigation skills;training blind children;audio-based navigation;risky task;training outdoors;traffic condition;weather condition;noise condition;controlled indoor environment;audio-based computer game;train navigation skills;3D exploration game;headtracking capability;sound libraries;phonon3D;realistic soundscape;head-related transfer function;audio source;3D space;blind people;audio orientation;statistical conclusion,,7,,12,,28-Dec-15,,,IEEE,IEEE Conferences
Transfer method of Force Information using Five-Fingered Haptic Interface Robot,T. Endo; H. Kawasaki; K. Kigaku; T. Mouri,"Gifu University, Japan; Gifu University, Japan; Gifu University, Japan; Gifu University, Japan",Second Joint EuroHaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems (WHC'07),2-Apr-07,2007,,,599,600,"In the expert skill transfer, it takes a great deal of time and effort to obtain new skills for beginners. In particular, it is difficult to teach the skills by using only words. So, the skill transfer system that uses VR attracts attention. In this paper, we propose a method for transferring force information and consider the skill transfer system for human five fingers by using five-fingered haptic interface robot",,0-7695-2738-8,10.1109/WHC.2007.119,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4145255,,Haptic interfaces;Robots;Humans;Fingers;Virtual reality;Information systems;Surgery;System testing;Virtual environment;Teleoperators,control engineering education;dexterous manipulators;haptic interfaces;robots;virtual reality,force information transfer;five-fingered haptic interface robot;skill transfer system;virtual reality;human five fingers,,6,,4,,2-Apr-07,,,IEEE,IEEE Conferences
Brain connectivity in spatial orientation task,G. Sharma; V. Singh; R. V. Daniel; A. P. Mittal; S. Chandra,"Bio Medical Engineering Department, Institute of Nuclear Medicine & Allied Sciences, DRDO, Delhi, India; Instrumentation & Control Engineering Department, NSIT, Delhi, India; Advanced Technology Development Centre, IIT Kharagpur, WB, India; AICTE, Delhi, India; Bio Medical Engineering Department, Institute of Nuclear Medicine & Allied Sciences, DRDO, Delhi, India",2016 International Conference on Emerging Trends in Communication Technologies (ETCT),23-Mar-17,2016,,,1,4,"Spatial orientation (SOT) is one of the spatial skill which is required in motor imagery and navigation. A lot of researches have shown underlying neural dynamics during SOT as an effect of spatial transformation strategy, but the consistent findings related to flow of information between designated brain areas are not present. The purpose of the study is to identify flux of information between pairs of channel to identify active hubs during the course of task. The directed transfer function (DTF) method is used to detect alterations in the functional coupling of EEG rhythms (0.5-30 Hz) in different brain cortical areas during virtual reality based perspective taking test. Results confirmed that there were common regions for motor imagery and SOT. It has also shed light on the active role of parietal and occipital lobe in SOT. This study proffers DTF as a useful technique for identifying hubs and flux of information in neuroscience.",,978-1-5090-4505-1,10.1109/ETCT.2016.7882958,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7882958,Spatial Orientation;Directed Transfer Function (DTF);Virtual Reality;Perspective Taking Test,Cognition;Electroencephalography;Psychology;Mathematical model;Virtual reality;Atmospheric measurements;Particle measurements,electroencephalography;medical computing;neurophysiology;virtual reality,brain connectivity;neuroscience;occipital lobe;parietal lobe;virtual reality based perspective taking test;brain cortical areas;EEG rhythms;functional coupling;DTF;directed transfer function method;active hubs;brain areas;spatial transformation strategy;SOT;neural dynamics;navigation;motor imagery;spatial skill;spatial orientation task;frequency 0.5 Hz to 30 Hz,,2,,25,,23-Mar-17,,,IEEE,IEEE Conferences
Development of Augmented Reality Body-Mark system to support echography,T. Yoshinaga; D. Arita; K. Masuda,"Institute of Systems, Information Technologies and Nanotechnologies, Fukuoka, Japan; Institute of Systems, Information Technologies and Nanotechnologies, Fukuoka, Japan; Graduate school of Bio-Applications and Systems Engineering, Tokyo University of Agriculture & Technology, Japan",2012 IEEE Biomedical Circuits and Systems Conference (BioCAS),24-Jan-13,2012,,,348,351,"We propose visualization system of 3D shape of internal organs using Augmented Reality and Virtual Reality technology. Echography has been used in every field of medical diagnosis because of its safety and cost-effectiveness. Therefore, portable echography device so called ‚ÄúUbiquitous Echo‚Äù was released by many manufacturers. However, the skill to recognize relationship between ultrasound probe and internal organ is required to acquire echogram. Therefore we have developed tracking system of probe orientation to transfer 2D position of echogram into 3D space. Then we have applied Radial Basis Function Interpolation to reconstruct the shape of internal organs. Furthermore, GUI interface to visualize the internal organ was developed by OpenGL. As a result of evaluation experiments, visualization of internal organ was satisfied to show the echogram for diagnosis.",2163-4025,978-1-4673-2293-5,10.1109/BioCAS.2012.6418425,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6418425,,Shape;Image reconstruction;Biological systems;Probes;Data visualization;Augmented reality;Phantoms,augmented reality;biological organs;biomedical ultrasonics;graphical user interfaces;image reconstruction;interpolation;medical image processing;portable instruments;radial basis function networks;ultrasonic imaging,augmented reality body-mark system;support echography;3D shape visualization system;internal organs;virtual reality;medical diagnosis;portable echography device;Ubiquitous Echo;ultrasound probe;tracking system;radial basis function interpolation;GUI interface;OpenGL;image reconstruction,,,,11,,24-Jan-13,,,IEEE,IEEE Conferences
MoVEROffice: Virtual Reality for Upper Limbs Rehabilitation,R. V. Aranha; L. V. Ara√∫jo; C. B. M. Monteiro; T. D. Da Silva; F. L. S. Nunes,"Lab. de Aplic. de Inf. em Saude, Univ. de Sao Paulo, Sao Paulo, Brazil; Lab. de Aplic. de Inf. em Saude, Univ. de Sao Paulo, Sao Paulo, Brazil; Lab. de Aplic. de Inf. em Saude, Univ. de Sao Paulo, Sao Paulo, Brazil; Lab. de Aplic. de Inf. em Saude, Univ. de Sao Paulo, Sao Paulo, Brazil; Lab. de Aplic. de Inf. em Saude, Univ. de Sao Paulo, Sao Paulo, Brazil",2016 XVIII Symposium on Virtual and Augmented Reality (SVR),21-Jul-16,2016,,,160,169,"Considering the complexity involved in the motor rehabilitation process, this paper presents the development of a serious game with virtual reality and natural interaction to act as a support tool for physical therapy professionals. The objective of the developed application is to enable that patients acquire skill in performing tasks in the virtual environment to transfer them later to the real environment. An experiment was conducted to compare the performance of people with and without mobility limitations in the use of the virtual environment. The results showed that the time spent for performing tasks tend to be reduced when the users familiarize them selves with natural interaction, and size and position of objects have influence in the interaction. The study allowed inferring in this sample evaluated that the motor limitations of the patients did not have influence in the performance of the volunteers.",,978-1-5090-4149-7,10.1109/SVR.2016.36,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7517270,Virtual Reality;Natural Interaction;Serious Game;Virtual Rehabilitation,Visualization;Games;Virtual environments;Mice;Augmented reality;Art,medical computing;patient treatment;serious games (computing);virtual reality,MoVEROffice;virtual reality;upper limbs rehabilitation;motor rehabilitation process;natural interaction;physical therapy professionals;virtual environment;mobility limitations,,2,,,,21-Jul-16,,,IEEE,IEEE Conferences
A network-adaptive compensation technique for tele-haptics using position prediction algorithm,T. H. Tee; K. S. Eu; K. M. Yap; A. Marshall; T. Lee,"Faculty of Science and Technology, Sunway University, Bandar Sunway, Malaysia; Faculty of Science and Technology, Sunway University, Bandar Sunway, Malaysia; Faculty of Science and Technology, Sunway University, Bandar Sunway, Malaysia; School of Electronics, Electrical Engineering and Computer Science, Queens University Belfast, Northern Ireland, UK; Department of Computer and Information Science, National Taichung University, Taiwan",2013 IEEE International Symposium on Haptic Audio Visual Environments and Games (HAVE),12-Dec-13,2013,,,39,44,"Haptic interfaces have been applied as controllers in many areas especially tele-operation and distributed virtual environments. They are used to manipulate objects in both physical and virtual environments. Haptics enhance force interactions and provides a better immersive user experience. Moreover haptic devices inherently function in close proximity to humans. In the case of network-based haptic control, the network criteria for stability in haptic interactions are much more sophisticated than that for tethered devices and the kinematic and force data are required to be transferred over communication link within a stringent time. Otherwise, users may feel unexpected vibration or abrupt force even when the device is in free motion. This is mainly due to position de-synchronization between local and remote environments. This paper addresses position synchronization which is the essential problem to lose stability of haptic experience under the influence of network and system impairments. A novel encoder referencing position synchronization algorithm is proposed in order to compensate the network latency and packet loss over network. This has been successfully tested under influence of the network impairment and low transmission rates.",,978-1-4799-0849-3,10.1109/HAVE.2013.6679608,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6679608,haptic traffic;tele-haptic;position prediction;network impairment;network-adaptive compensation,Haptic interfaces;Packet loss;Delays;Jitter;Prediction algorithms;Equations,compensation;haptic interfaces;virtual reality,network-adaptive compensation technique;tele-haptics;position prediction algorithm;haptic interfaces;tele-operation;distributed virtual environments;object manipulation;physical environment;force interactions;immersive user experience;network-based haptic control;network criteria;stability;haptic interactions;communication link;position de-synchronization;haptic experience;encoder referencing position synchronization algorithm;network impairment,,3,,15,,12-Dec-13,,,IEEE,IEEE Conferences
High Quality Light Field Extraction and Post-Processing for Raw Plenoptic Data,P. Matysiak; M. Grogan; M. Le Pendu; M. Alain; E. Zerman; A. Smolic,"School of Computer Science and Statistics, Trinity College Dublin, The University of Dublin, Dublin 2, Ireland; School of Computer Science and Statistics, Trinity College Dublin, The University of Dublin, Dublin 2, Ireland; School of Computer Science and Statistics, Trinity College Dublin, The University of Dublin, Dublin 2, Ireland; School of Computer Science and Statistics, Trinity College Dublin, The University of Dublin, Dublin 2, Ireland; School of Computer Science and Statistics, Trinity College Dublin, The University of Dublin, Dublin 2, Ireland; School of Computer Science and Statistics, Trinity College Dublin, The University of Dublin, Dublin 2, Ireland",IEEE Transactions on Image Processing,7-Feb-20,2020,29,,4188,4203,"Light field technology has reached a certain level of maturity in recent years, and its applications in both computer vision research and industry are offering new perspectives for cinematography and virtual reality. Several methods of capture exist, each with its own advantages and drawbacks. One of these methods involves the use of handheld plenoptic cameras. While these cameras offer freedom and ease of use, they also suffer from various visual artefacts and inconsistencies. We propose in this paper an advanced pipeline that enhances their output. After extracting sub-aperture images from the RAW images with our demultiplexing method, we perform three correction steps. We first remove hot pixel artefacts, then correct colour inconsistencies between views using a colour transfer method, and finally we apply a state of the art light field denoising technique to ensure a high image quality. An in-depth analysis is provided for every step of the pipeline, as well as their interaction within the system. We compare our approach to existing state of the art sub-aperture image extracting algorithms, using a number of metrics as well as a subjective experiment. Finally, we showcase the positive impact of our system on a number of relevant light field applications.",1941-0042,,10.1109/TIP.2020.2967600,Science Foundation Ireland; Trinity College Dublin; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8967224,Light fields;image coding;colour transfer;image enhancement;image denoising,Image color analysis;Cameras;Pipelines;Demultiplexing;Sensor arrays;Brightness;Lenses,cameras;computer vision;feature extraction;image colour analysis;image denoising;image enhancement;image resolution;image sensors;virtual reality,hot pixel artefacts;correct colour inconsistencies;colour transfer method;image quality;relevant light field applications;high quality light field extraction;computer vision research;virtual reality;handheld plenoptic cameras;visual artefacts;sub-aperture images;demultiplexing method;correction steps;sub-aperture image extracting algorithms,,4,,66,IEEE,23-Jan-20,,,IEEE,IEEE Journals
Accessing Urban History using Spatial Historical Photographs,F. Niebling; F. Maiwald; S. M√ºnster; J. Bruschke; F. Henze,"Human-Computer Interaction, University of W√ºrzburg, W√ºrzburg, Germany; Institute of Photogrammetry and Remote Sensing, TU Dresden, Dresden, Germany; Media Centre, TU Dresden, Dresden, Germany; Human-Computer Interaction, University of W√ºrzburg, W√ºrzburg, Germany; Media Centre, TU Dresden, Dresden, Germany",2018 3rd Digital Heritage International Congress (DigitalHERITAGE) held jointly with 2018 24th International Conference on Virtual Systems & Multimedia (VSMM 2018),26-Aug-19,2018,,,1,8,"We aim to investigate and develop methods and technologies to transfer extensive repositories of historical media and their contextual information into a three-dimensional spatial model, with an additional temporal component. This will make content accessible to different target groups, researchers and the public, via a 4D browser. A location-dependent virtual reality representation can be used as an information base, research tool, and to communicate historical knowledge. The data resources available for this research include extensive holdings of historical photographs of Dresden, which have documented the city over the decades, and digitized map collections on the Deutsche Fotothek (German photographic collection) platform. These will lay the foundation for a prototype model which will give users a virtual experience of historic parts of Dresden.",,978-1-7281-0292-4,10.1109/DigitalHeritage.2018.8809998,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809998,Urban History;Spatial Photography;Building Segmentation;Photogrammetry;Spatial Browsing,Buildings;Three-dimensional displays;Solid modeling;Urban areas;Image segmentation;Media;Photography,computer vision;history;town and country planning;virtual reality,urban history;spatial historical photographs;historical media;contextual information;three-dimensional spatial model;location-dependent virtual reality representation;information base;historical knowledge;data resources;extensive holdings;digitized map collections;Deutsche Fotothek platform;German photographic collection;prototype model;virtual experience;temporal component,,,,58,,26-Aug-19,,,IEEE,IEEE Conferences
An interactive visualization of the past using a situated simulation approach,J. B. Madsen; C. B. Madsen,"Department of Architecture, Design and Media Technology Aalborg University; Department of Architecture, Design and Media Technology Aalborg University",2013 Digital Heritage International Congress (DigitalHeritage),20-Feb-14,2013,1,,307,314,"This paper describes aspects of the development of an interactive installation for visualizing a 3D reconstruction of a historical church chapel in Kolding, Denmark. We focus on three aspects inherent to a mobile Augmented Reality development context; 1) A procedure for combating gyroscope drift on handheld devices, 2) achieving realistic lighting computation on a mobile platform at interactive frame-rates and 3) an approach to relocation within this applications situated location without position tracking. We present a solution to each of these three aspects. The development is targeted a specific application, but the presented solutions should be relevant to researchers and developers facing similar issues in other contexts. We furthermore present initial findings from everyday usage by visitors at the museum, and explore how these findings can be useful in connection with novel technology for facilitating information transfer to a museum audience. The installation is in active commercial use and is currently logging further user interactions via in-application logging for future investigations in line with this project.",,978-1-4799-3170-5,10.1109/DigitalHeritage.2013.6743754,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6743754,,Visualization;Tablet computers;Solid modeling;Gyroscopes;Three-dimensional displays;Compass;Lighting,augmented reality;data visualisation;history;mobile computing;museums,past interactive visualization;situated simulation approach;interactive installation;3D reconstruction visualization;historical church chapel;Kolding;Denmark;mobile augmented reality development;gyroscope drift;handheld devices;realistic lighting computation;interactive frame-rates;application situated location;museum;information transfer;in-application logging,,4,,25,,20-Feb-14,,,IEEE,IEEE Conferences
Experimental Verification of Force Interactions for Robinhand Prototype Motion Controller,L. Mucha; K. Lis; D. Krawczyk,"Foundation of Cardiac Surgery Development; Foundation of Cardiac Surgery Development; Faculty of Mechanical Engineering, Department of Machine Technology",2019 12th International Workshop on Robot Motion and Control (RoMoCo),5-Aug-19,2019,,,56,61,"In article, the design stages, principle of operation and static tests of the force that is exerted on the operator by the RobinHand motion controller were presented. Besides that, details of such issues as, the developed laboratory stand for testing the force interactions, all concepts and ways of implementing the transfer of tactile stimuli from real devices or virtual reality to the user/surgeon, subsequent variants of the developed devices with the short description of them, the project of the operator-surgeon stand that is based on the assumption that the method of control of this device is compatible with the natural work of the surgeon as well as the project of control console that is used to manipulate the surgical robot were presented.",2575-5579,978-1-7281-2975-4,10.1109/RoMoCo.2019.8787355,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8787355,,Surgery;Force;Robots;Haptic interfaces;Tools;Kinematics;Laparoscopes,control engineering computing;manipulators;medical computing;medical robotics;motion control;surgery;virtual reality,experimental verification;force interactions;static tests;tactile stimuli;virtual reality;operator-surgeon stand;Robinhand prototype motion controller;surgical robot,,,,16,,5-Aug-19,,,IEEE,IEEE Conferences
Design and implementation of a virtual-real interaction system,F. Zhang; Y. Zhao; J. Li,"College of Computer Science and Technology North China University of Technology Beijing, China; College of Computer Science and Technology North China University of Technology Beijing, China; College of Computer Science and Technology North China University of Technology Beijing, China","2017 10th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)",26-Feb-18,2017,,,1,5,"We design and implement a virtual-real interaction system using the optical motion capture device. First, we construct immersive interaction environment, such as setting OptiTrack parameter, calibrating cameras and transferring data, which play an important role in building environment. Second, we research virtual-real interaction technology based on optical motion capture device. And we acquire the motion data of human and rigid body, transferring them to the virtual scene. So we can accurately rotate and translate the corresponding virtual objects in real time. Finally, we design and implement natural immersive virtual-real interaction system. The experiment result shows that our system can preferably implement virtual-real interaction such as human and rigid body with markers, human and virtual objects.",,978-1-5386-1937-7,10.1109/CISP-BMEI.2017.8302079,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302079,Motion Capture;Motion Control;Virtual-Real Interaction,Cameras;Calibration;Optical devices;Real-time systems;Biomedical optical imaging;Solid modeling;Optical signal processing,human computer interaction;interactive systems;virtual reality,optical motion capture device;immersive interaction environment;motion data;human body;rigid body;virtual scene;virtual objects;virtual-real interaction system;virtual-real interaction technology,,,,7,,26-Feb-18,,,IEEE,IEEE Conferences
ADHD assessment and testing system design based on virtual reality,H. Lee; Y. Li; S. Yeh; Y. Huang; Z. Wu; Z. Du,"School of information science and technoogy, Fudan university; School of information science and technoogy, Fudan university; School of information science and technoogy, Fudan university; Huashan Hospital of Fudan University; Huashan Hospital of Fudan University; Huashan Hospital of Fudan University",2017 2nd International Conference on Information Technology (INCIT),15-Jan-18,2017,,,1,5,"Attention deficit hyperactivity disorder (ADHD) is a common psychological and behavioral disorder in children, adolescents, and even some adults. Several symptoms are observed in ADHD patients, such as difficulty in paying attention, hyperactivity, impulsivity, and cognitive abnormalities. In the past, clinical diagnosis of ADHD was mainly conducted through a paper test scale based on relevant standards. Subsequently, although the time efficiency of test based on computer has improved, disadvantages have remained, for those tests being too tedious to attract the interest of individuals and being restricted by the content and the type. In this study, a combination of virtual reality, eye tracking, and electroencephalogram (EEG) signal acquisition technologies was used to conduct diagnostic assessment and testing on patients with ADHD. Selective attention, sustained attention, abstract reasoning, and cognitive transfer abilities were evaluated by performing visual and auditory continuous performance test (CPT) and the Wisconsin card sorting test (WCST) in a 3D virtual classroom with optional distraction factors. This study also preliminarily analyzed the eye tracking and EEG data and validated their effectiveness and convenience in ADHD diagnosis. The system may provide a deeper level of ADHD diagnosis and cognitive rehabilitation.",,978-1-5386-1431-0,10.1109/INCIT.2017.8257860,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8257860,ADHD;virtual reality;continuous performance test;eye tracking;electroencephalogram,Testing;Visualization;Electroencephalography;Pediatrics;Auditory system;Gaze tracking;Information technology,cognition;electroencephalography;medical computing;medical disorders;neurophysiology;patient diagnosis;patient rehabilitation;patient treatment;psychology;virtual reality,virtual reality;attention deficit hyperactivity disorder;behavioral disorder;ADHD patients;cognitive abnormalities;clinical diagnosis;eye tracking;electroencephalogram signal acquisition technologies;diagnostic assessment;selective attention;sustained attention;cognitive transfer abilities;visual performance test;auditory continuous performance test;Wisconsin card sorting test;3D virtual classroom;ADHD diagnosis;psychological disorder;ADHD assessment;ADHD testing system design;cognitive rehabilitation,,1,,11,,15-Jan-18,,,IEEE,IEEE Conferences
Haze Correction for Contrast-Based Multispectral Pansharpening,S. Lolli; L. Alparone; A. Garzelli; G. Vivone,"Institute of Methodologies for Environmental Analysis, National Research Council, Tito Scalo, Italy; Department of Information Engineering, University of Florence, Florence, Italy; Department of Information Engineering and Mathematics, University of Siena, Siena; Department of Information Engineering, Electrical Engineering and Applied Mathematics, University of Salerno, Fisciano, Italy",IEEE Geoscience and Remote Sensing Letters,4-Dec-17,2017,14,12,2255,2259,"In this letter, we show that pansharpening of visible/near-infrared (VNIR) bands takes advantage from a correction of the path-radiance term introduced by the atmosphere during the fusion process. This holds whenever the fusion mechanism emulates the radiative transfer model ruling the acquisition of the Earth's surface from space, that is, for methods exploiting a contrast-based injection model of spatial details extracted from the panchromatic (Pan) image into the interpolated multispectral (MS) bands. Such methods are high-pass modulation (HPM), Brovey transform, synthetic variable ratio (SVR), University of New Brunswick pansharp, smoothing filter-based intensity modulation, and spectral distortion minimization. The path radiance should be estimated and subtracted from each band before the product by Pan is accomplished and added back after. Both empirical and model-based estimation techniques of MS path radiances are compared within the framework of optimized SVR and HPM algorithms. Simulations carried out on QuickBird and IKONOS data highlight that haze correction of MS before fusion is always beneficial, especially on vegetated areas and in terms of spectral quality.",1558-0571,,10.1109/LGRS.2017.2761021,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8091124,Haze;image fusion;multispectral (MS) pansharpening;path radiance;radiative transfer model;remote sensing,Atmospheric modeling;Spatial resolution;Atmospheric measurements;Terrestrial atmosphere;Earth;Context modeling;Atmospheric waves,geophysical image processing;geophysical signal processing;geophysical techniques;image fusion;image resolution;radiative transfer;regression analysis;remote sensing,haze correction;multispectral pansharpening;visible/near-infrared bands;VNIR;path-radiance term;fusion process;fusion mechanism;radiative transfer model;Earth's surface;contrast-based injection model;spatial details;panchromatic image;interpolated multispectral bands;synthetic variable ratio;New Brunswick pansharp;intensity modulation;spectral distortion minimization;path radiance;empirical model-based estimation techniques;MS path radiances;optimized SVR;HPM algorithms,,8,1,18,,31-Oct-17,,,IEEE,IEEE Journals
Augmented audio reality: telepresence/VR hybrid acoustic environments,M. Cohen; S. Aoki; N. Koizumi,"Human Interface Lab., Aizu Univ., Fukushima, Japan; NA; NA",Proceedings of 1993 2nd IEEE International Workshop on Robot and Human Communication,6-Aug-02,1993,,,361,364,"Augmented audio reality consists of hybrid presentations in which computer-generated sounds are overlayed on top of more directly acquired audio signals. We are exploring the alignability of binaural signals with artificially spatialized sources, synthesized by convolving monaural signals with left/right pairs of directional transfer functions. We use MAW (multidimensional audio windows), a NeXT-based system, as a binaural directional mixing console. Since the rearrangement of a dynamic map is used to dynamically select transfer functions, a user may specify the virtual location of a sound source, throwing the source into perceptual space, using exocentric graphical control to drive egocentric auditory display. As a concept demonstration, we muted a telephone, and then used MAW to spatialize a ringing signal at its location, putting the sonic image of the phone into the office environment. By juxtaposing and mixing 'real' and 'synthetic' audio transmissions, we are exploring the relationship between acoustic telepresence and VR presentations: telepresence manifests as the actual configuration of sources in a sound field, as perceivable by a dummyhead; VR is the perception yielded by filtering of virtual sources with respect to virtual sinks. We have conducted an experiment testing the usefulness of such a hybrid.<>",,0-7803-1407-7,10.1109/ROMAN.1993.367692,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=367692,,Virtual reality;Humans;Acoustic testing;Telephony;Layout;Signal synthesis;Transfer functions;Robots;Switches;Laboratories,virtual reality;audio-visual systems;telecontrol,augmented audio reality;VR hybrid acoustic environments;computer-generated sounds;binaural signal alignability;convolving monaural signals;left/right pairs;directional transfer functions;multidimensional audio windows;MAW;NeXT-based system;binaural directional mixing console;transfer function dynamic selection;virtual location;exocentric graphical control;egocentric auditory display;acoustic telepresence;virtual reality,,15,3,12,,6-Aug-02,,,IEEE,IEEE Conferences
A Model for Sensorimotor Affordances in Virtual Reality Environments,U. Meyer; S. Draheim; K. von Luck,"CSTI, Hamburg University of Applied Sciences, Hamburg, Germany; CSTI, Hamburg University of Applied Sciences, Hamburg, Germany; CSTI, Hamburg University of Applied Sciences, Hamburg, Germany",2019 11th International Conference on Virtual Worlds and Games for Serious Applications (VS-Games),14-Oct-19,2019,,,1,4,"Study results on virtual reality (VR) environment properties and their impact on presence have been contradictory. And due to the media specificity of VR, which includes place illusion, rules for environment design cannot directly be transferred from 3D computer games or stereoscopic film to VR. This study develops a model for VR environments based on Mel Slater's observation that place illusion in VR is caused by the use of sensorimotor contingencies (SMC). It defines properties of the environment which provide action possibilities for SMC as sensorimotor affordances (SMA). SMC and SMA form a bidirectional feedback loop of perception. This model helps to clarify former contradictory study results on VR environments, and also provides the basis for a framework of preceptual design rules for VR environments.",2474-0489,978-1-7281-4540-2,10.1109/VS-Games.2019.8864514,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8864514,Virtual reality;virtual environment;illusion;sensorimotor contingencies;affordances;perceptual design,Robot sensing systems;Optical sensors;Optical feedback;Real-time systems;Media;Rendering (computer graphics);Optical imaging,social aspects of automation;virtual reality,sensorimotor affordances;virtual reality environments;place illusion;sensorimotor contingencies;VR media specificity;sensory distortion,,,,20,,14-Oct-19,,,IEEE,IEEE Conferences
Design of a dynamic positioning system for a moored floating platform using QFT robust control,R. Mu√±oz-Mansilla; J. Aranda; J. M. D√≠az; D. Chaos; A. J. Reinoso,"Department of Computer Science and Automatic Control, National Distance Education University (UNED), Madrid, Spain; Department of Computer Science and Automatic Control, National Distance Education University (UNED), Madrid, Spain; Department of Computer Science and Automatic Control, National Distance Education University (UNED), Madrid, Spain; Department of Computer Science and Automatic Control, National Distance Education University (UNED), Madrid, Spain; Department of Telematic Systems and Computing, URJC, Madrid, Spain",2012 7th IEEE Conference on Industrial Electronics and Applications (ICIEA),24-Nov-12,2012,,,763,768,"This paper describes the design of a dynamic positioning system for a moored floating platform by using robust control techniques, particularly Quantitative Feedback Theory (QFT). The goal is to minimize the drift resulting from the wave action by appropriate thrusters control. The model of the platform is a SIMO (single-input multiple-output) system, therefore an interesting question is that the plant has less degree of freedom for actuation and is difficult to control. The control problem of the underactuated system is solved by an iterative multi-stage sequential procedure. Simulation results are presented to demonstrate that the control achieves efficiently the dynamic positioning system. Therefore robust techniques based on QFT methodology constitute attractive alternatives in the application of positioning control of an underactuated marine system.",2158-2297,978-1-4577-2119-9,10.1109/ICIEA.2012.6360827,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360827,dynamic positioning system;underactuated system;robust control;multivariable control;floating platform,Transfer functions;Stability analysis;Control systems;Force;Robust control;Aerodynamics;Equations,feedback;iterative methods;marine control;position control;robust control;vehicle dynamics,dynamic positioning system;moored floating platform;QFT robust control techniques;quantitative feedback theory;drift minimization;thrusters control;SIMO system;single-input multiple-output system;underactuated marine system;iterative multistage sequential procedure;marine control problem,,,,29,,24-Nov-12,,,IEEE,IEEE Conferences
Synchronisation Between Real and Virtual-World Devices in a VR-IoT Environment,A. A. Simiscuka; G. Muntean,"Dublin City University, School of Electronic Engineering, Ireland; Dublin City University, School of Electronic Engineering, Ireland",2018 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB),16-Aug-18,2018,,,1,5,"Virtual Reality (VR) can be used for many applications in diverse fields such as engineering, gaming, healthcare, education, etc. Internet of Things (IoT) devices, including CCTV monitoring cameras and smart watches, support diverse services including providing sensor data, intelligence in appliances and multimedia. This paper proposes and describes VRITESS, a novel VR-IoT environment synchronisation scheme which facilitates a seamless user experience for IoT devices through use of VR, and synchronised representation of IoT devices in the virtual world. Certain IoT devices, which are located in extreme environments or are not straightforward in terms of operation for many users, can be manipulated in a simpler way in a virtual environment. A synchronisation mechanism keeps the real devices up-to-date, according to actions and events that happened in the virtual world and vice-versa: actions applied on the real devices are transferred to the virtual world. The proposed solution is tested in a real-life testbed developed in the Performance Engineering Laboratory at Dublin City University, Ireland, with the Oculus Rift and several IoT devices.",2155-5052,978-1-5386-4729-5,10.1109/BMSB.2018.8436742,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8436742,multimedia internet of things;virtual reality (VR);three-dimensional visualisation;user quality of experience,Synchronization;Urban areas;Virtual environments;Internet of Things;Monitoring;Quality of experience,closed circuit television;Internet of Things;synchronisation;virtual reality,Virtual Reality;CCTV monitoring cameras;synchronised representation;virtual world;virtual environment;synchronisation mechanism;Internet of Things devices;IoT devices;virtual-world devices;real-world devices;VR-IoT environment synchronisation scheme;smart watches;diverse service support;sensor data;VRITESS,,6,,27,,16-Aug-18,,,IEEE,IEEE Conferences
Yaw Rate and Sideslip Angle Control Through Single Input Single Output Direct Yaw Moment Control,B. Lenzo; M. Zanchetta; A. Sorniotti; P. Gruber; W. De Nijs,"Centre for Automotive Engineering, University of Surrey, Guildford, U.K.; Centre for Automotive Engineering, University of Surrey, Guildford, U.K.; Centre for Automotive Engineering, University of Surrey, Guildford, U.K.; Centre for Automotive Engineering, University of Surrey, Guildford, U.K.; Flanders Make, Lommel, Belgium",IEEE Transactions on Control Systems Technology,17-Dec-20,2021,29,1,124,139,"Electric vehicles with independently controlled drivetrains allow torque vectoring, which enhances active safety and handling qualities. This article proposes an approach for the concurrent control of yaw rate and sideslip angle based on a single-input single-output (SISO) yaw rate controller. With the SISO formulation, the reference yaw rate is first defined according to the vehicle handling requirements and is then corrected based on the actual sideslip angle. The sideslip angle contribution guarantees a prompt corrective action in critical situations such as incipient vehicle oversteer during limit cornering in low tire-road friction conditions. A design methodology in the frequency domain is discussed, including stability analysis based on the theory of switched linear systems. The performance of the control structure is assessed via: 1) phase-plane plots obtained with a nonlinear vehicle model; 2) simulations with an experimentally validated model, including multiple feedback control structures; and 3) experimental tests on an electric vehicle demonstrator along step steer maneuvers with purposely induced and controlled vehicle drift. Results show that the SISO controller allows constraining the sideslip angle within the predetermined thresholds and yields tire-road friction adaptation with all the considered feedback controllers.",1558-0865,,10.1109/TCST.2019.2949539,European Union‚Äôs FP7 Programme (iCOMPOSE Project); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8981891,Controlled drift;electric vehicle;experimental tests;sideslip angle control;tire-road friction coefficient;torque vectoring (TV);yaw rate control,Friction;Stability analysis;TV;Torque;Transfer functions;Mathematical model;Wheels,control system synthesis;electric vehicles;feedback;friction;road safety;road vehicles;single-input single-output systems (control);stability;steering systems;switching systems (control);tyres;vehicle dynamics,single input single output direct yaw moment control;electric vehicles;concurrent control;single-input single-output yaw rate controller;vehicle handling requirements;incipient vehicle oversteer;low tire-road friction conditions;nonlinear vehicle model;multiple feedback control structures;vehicle drift;SISO controller;sideslip angle control;stability analysis;phase-plane plots;switched linear systems,,8,,52,CCBY,4-Feb-20,,,IEEE,IEEE Journals
A novel prototype architecture for equipment tele-control and simulation,Y. M. Wang; G. Z. Zhao; H. L. Yin,"Faculty of Management and Economics, Kunming University of Science & Technology, 650093, China; Faculty of Management and Economics, Kunming University of Science & Technology, 650093, China; School of Computer Science and Information Technology, Yunnan Normal University, Kunming 650092, China",Proceedings of the 10th World Congress on Intelligent Control and Automation,24-Nov-12,2012,,,633,637,"Due to the working hazardous or other conditions, such as tele-medical, tele-embodiment, operations should be executed with a fully remote control and monitoring. So, tele-control and reality simulation are crucial in these environments. However, there exists a lack of an effective system architecture that integrates remote condition monitoring and control of automated equipment; that give much consideration about data transfer time delay via TCP/IP data package. This paper presented a novel prototype architecture for tele-control and reality simulation, which can guarantee the non-distortion-transfer of control information and reduce the action time difference between local simulated virtual equipment and remote real equipment, couple the remote control and virtual reality together. In order to demonstrate and validate the effectiveness of the novel architecture, a 3 DOF Fischertechnik industry robot remote operation and monitoring system have been developed. Experimental results are encouraging and demonstrate a promising application in any other relevant environment.",,978-1-4673-1398-8,10.1109/WCICA.2012.6357956,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6357956,Remote control;Control framework;Virtual equipment;Reality simulation,Monitoring;IP networks;Delay effects;Solid modeling;Service robots;Control systems,condition monitoring;control engineering computing;digital simulation;industrial robots;telerobotics;transport protocols;virtual reality,equipment telecontrol;remote control;system architecture;remote condition monitoring;automated equipment control;data transfer time delay;TCP-IP data package;nondistortion-transfer;virtual reality;3 DOF Fischertechnik industry robot remote operation,,1,,11,,24-Nov-12,,,IEEE,IEEE Conferences
Nonlinear control methods supported by learning function based on neural networks,T. Fujiwara; S. Marionneau,"Mitsubishi Heavy Ind. Ltd., Hyogo, Japan; Mitsubishi Heavy Ind. Ltd., Hyogo, Japan","Proceedings of the 1992 International Conference on Industrial Electronics, Control, Instrumentation, and Automation",6-Aug-02,1992,,,1089,1093 vol.2,"Two compensators are proposed which are effective for difficult-to-control objects having a nonlinear drift and a performance drift. For the two types of compensator a nonlinear model can be incorporated as a nonlinear action and learning functions with a neural network can be added for performance drift action. One of them is a feedforward compensator called the inverse system method, which is a method producing inverse characteristics in feedback circuits while directly introducing the nonlinear characteristics of the process into a compensator. The other is a feedback loop compensator called the K/s method. The K/s method is described. The effectiveness of the proposed method has been checked with simulation calculations.<>",,0-7803-0582-5,10.1109/IECON.1992.254460,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=254460,,Neural networks;Transfer functions;Control systems;Nonlinear control systems;Feedback loop;Open loop systems;Feedback circuits;Error correction;Signal processing;Systems engineering and theory,compensation;feedback;feedforward neural nets;learning (artificial intelligence);nonlinear control systems,nonlinear control methods;learning function;neural networks;compensators;difficult-to-control objects;nonlinear drift;performance drift;feedforward compensator;inverse system method;feedback circuits;feedback loop compensator;K/s method,,,,2,,6-Aug-02,,,IEEE,IEEE Conferences
Local and Remote Cooperation With Virtual and Robotic Agents: A P300 BCI Study in Healthy and People Living With Spinal Cord Injury,E. Tidoni; M. Abu-Alqumsan; D. Leonardis; C. Kapeller; G. Fusco; C. Guger; C. Hinterm√ºller; A. Peer; A. Frisoli; F. Tecchia; M. Bergamasco; S. M. Aglioti,"Department of Psychology, University of Rome ‚ÄúLa Sapienza‚Äù, Rome, Italy; Chair of Automatic Control Engineering, Technical University of Munich, TUM, Munich, Germany; Percro Laboratory, Scuola Superiore Sant‚ÄôAnna, Pisa, Italy; Guger Technologies OG, Graz, Austria; Department of Psychology, University of Rome ‚ÄúLa Sapienza‚Äù, Rome, Italy; Guger Technologies OG, Graz, Austria; Guger Technologies OG, Graz, Austria; Bristol Robotics Laboratory, University of the West of England, Bristol, Bristol, U.K.; Percro Laboratory, Scuola Superiore Sant‚ÄôAnna, Pisa, Italy; Percro Laboratory, Scuola Superiore Sant‚ÄôAnna, Pisa, Italy; Percro Laboratory, Scuola Superiore Sant‚ÄôAnna, Pisa, Italy; Department of Psychology, University of Rome ‚ÄúLa Sapienza‚Äù, Rome, Italy",IEEE Transactions on Neural Systems and Rehabilitation Engineering,6-Sep-17,2017,25,9,1622,1632,"The development of technological applications that allow people to control and embody external devices within social interaction settings represents a major goal for current and future brain-computer interface (BCI) systems. Prior research has suggested that embodied systems may ameliorate BCI end-user's experience and accuracy in controlling external devices. Along these lines, we developed an immersive P300-based BCI application with a head-mounted display for virtual-local and robotic-remote social interactions and explored in a group of healthy participants the role of proprioceptive feedback in the control of a virtual surrogate (Study 1). Moreover, we compared the performance of a small group of people with spinal cord injury (SCI) to a control group of healthy subjects during virtual and robotic social interactions (Study 2), where both groups received a proprioceptive stimulation. Our attempt to combine immersive environments, BCI technologies and neuroscience of body ownership suggests that providing realistic multisensory feedback still represents a challenge. Results have shown that healthy and people living with SCI used the BCI within the immersive scenarios with good levels of performance (as indexed by task accuracy, optimizations calls and Information Transfer Rate) and perceived control of the surrogates. Proprioceptive feedback did not contribute to alter performance measures and body ownership sensations. Further studies are necessary to test whether sensorimotor experience represents an opportunity to improve the use of future embodied BCI applications.",1558-0210,,10.1109/TNSRE.2016.2626391,EU Information and Communication Technologies Grant (VERE project); Italian Ministry of Health to SMA; BIAL Foundation (2014/150); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7797151,Body illusions - tendon vibration;brain‚Äìcomputer interface (BCI) P300;spinal cord injury;teleoperation;virtual reality,Visualization;Electroencephalography;Games;Robot sensing systems;Tendons;IEEE members,brain-computer interfaces;injuries;medical robotics;neurophysiology,body ownership sensations;information transfer rate;BCI technologies;virtual surrogate control;proprioceptive feedback;robotic-remote social interactions;virtual-local social interactions;immersive P300-based BCI application;BCI end-user experience;brain-computer interface;spinal cord injury,"Adult;Brain-Computer Interfaces;Event-Related Potentials, P300;Female;Humans;Imagination;Male;Man-Machine Systems;Movement;Reproducibility of Results;Robotics;Sensitivity and Specificity;Spinal Cord Injuries;Task Performance and Analysis;User-Computer Interface;Young Adult",6,,59,,23-Dec-16,,,IEEE,IEEE Journals
Interface Design of a Human-Robot Interaction System for Dual-Manipulators Teleoperation Based on Virtual Reality*,F. Bian; R. Li; L. Zhao; Y. Liu; P. Liang,"The State Key Lab of Robotics and System, Harbin Institute of Technology, Nangang, Harbin, China; The State Key Lab of Robotics and System, Harbin Institute of Technology, Nangang, Harbin, China; The State Key Lab of Robotics and System, Harbin Institute of Technology, Nangang, Harbin, China; Quanzhou HIT Institute of Engineering and Technology, Fengze, Quanzhou, China; Quanzhou HIT Institute of Engineering and Technology, Fengze, Quanzhou, China",2018 IEEE International Conference on Information and Automation (ICIA),26-Aug-19,2018,,,1361,1366,"This paper presents a human-robot interaction interface for dual-manipulators teleoperation based on virtual reality. Using this method, the human operator is able to control the robot at a distance to complete complicated tasks in unstructured environment. Virtual reality technology is integrated into the system to provide the first person perspective of the robot to the operator. Based on the three-dimensional coordinates of shoulder, elbow, wrist and hand captured by Kinect, a geometric model of the human arm is built. Then a geometric vector method is proposed to calculate the joint angles of human upper limbs which are translated into movement commands for a robot. To access the performance of our proposed human-robot interaction interface, teleoperation experiments are conducted on the Baxter robot, illustrating the effectiveness and feasibility of our proposed method.",,978-1-5386-8069-8,10.1109/ICInfA.2018.8812457,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812457,Human-Robot Interaction;Virtual reality;Motion transfer;Teleoperation,Three-dimensional displays;Robot sensing systems;Visualization;Robot kinematics;Head,control engineering computing;human-robot interaction;manipulators;telerobotics;vectors;virtual reality,interface design;human-robot interaction system;dual-manipulators teleoperation;human-robot interaction interface;human operator;virtual reality technology;human arm;geometric vector method;human upper limbs;Baxter robot,,,,16,,26-Aug-19,,,IEEE,IEEE Conferences
Supporting User Interfaces in Ubiquitous Virtual Reality,B. H. Thomas,"Wearable Comput. Lab., Univ. of South AustraliaUniversity of South Australia, SA, Australia",2009 International Symposium on Ubiquitous Virtual Reality,4-Sep-09,2009,,,15,18,"Ubiquitous virtual reality focuses on the widespread access of digital information to the user with the fusion and extension of a number of computer science disciplines. This paper will focus on ways users can conveniently and easily transfer between these different modes of interacting with digital information. Each of these domains has a particular display and interaction technologies that current support their form of information presentation. In additional these domains have software and metaphor support for their user interfaces. This paper will focus on methodologies to perform a number of tasks: 1) transitions between different presentations of information, 2) unifying technologies to better bring together these domains, and 3) articulate the important aspects of interactions within a ubiquitous virtual reality system. This paper will explore a number of possible technologies, such as input devices, clipboard technologies, and software frameworks. The paper will also highlight areas that need future exploration and possible pitfalls to avoid.",,978-1-4244-4437-3,10.1109/ISUVR.2009.16,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232246,User Interface;Ubiquitous Virtual Reality;Ubiquitous Computing,User interfaces;Virtual reality;Wearable computers;Augmented reality;Pervasive computing;Computer science;Computer displays;Ubiquitous computing;Haptic interfaces;Mobile computing,ubiquitous computing;user interfaces;virtual reality,ubiquitous virtual reality system;user interface;digital information interaction;software framework;input device;clipboard technology;information presentation;computer science discipline,,,,15,,4-Sep-09,,,IEEE,IEEE Conferences
Audio-visual attractors for capturing attention to the screens when walking in CAVE systems,F. Grani; S. Serafin; F. Argelaguet; V. Gouranton; M. Badawi; R. Gaugne; A. Lecuyer,"Aalborg University Copenhagen; Aalborg University Copenhagen; Inria-IRISA, Rennes; Inria-IRISA, Rennes; Inria-IRISA, Rennes; Inria-IRISA, Rennes; Inria-IRISA, Rennes",2014 IEEE VR Workshop: Sonic Interaction in Virtual Environments (SIVE),15-Jan-15,2014,,,3,6,"In four-sided CAVE-like VR systems, the absence of the rear wall has been shown to decrease the level of immersion and can introduce breaks in presence. In this paper it is investigated to which extent user's attention can be driven by visual and auditory stimuli in a four-sided CAVE-like system. An experiment was conducted in order to analyze how user attention is diverted while physically walking in a virtual environment, when audio and/or visual attractors are present. The foursided CAVE used in the experiment allowed to walk up to 9m in straight line. An additional key feature in the experiment is the fact that auditory feedback was delivered through binaural audio rendering techniques via non-personalized head related transfer functions (HRTFs). The audio rendering was dependent on the user's head position and orientation, enabling localized sound rendering. The experiment analyzed how different ""attractors"" (audio and/or visual, static or dynamic) modify the user's attention. The results of the conducted experiment show that audio-visual attractors are the most efficient attractors in order to keep the user's attention toward the inside of the CAVE. The knowledge gathered in the experiment can provide guidelines to the design of virtual attractors in order to keep the attention of the user and avoid the ""missing wall"".",,978-1-4799-5781-1,10.1109/SIVE.2014.7006282,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006282,,Visualization;Legged locomotion;Virtual environments;Rendering (computer graphics);Navigation;Analysis of variance,audio user interfaces;audio-visual systems;rendering (computer graphics);transfer functions;virtual reality,four-sided CAVE-like VR systems;auditory stimuli;visual stimuli;user attention;virtual environments;auditory feedback;binaural audio rendering techniques;nonpersonalized head related transfer functions;user head position;user head orientation;localized sound rendering;audio-visual attractors;attention capturing;screens,,3,,12,,15-Jan-15,,,IEEE,IEEE Conferences
A Publish/Subscribe based correlative matching method for multi-domain virtual environment,L. Liu; W. Wu; H. Chen,"School of Computer Science and Information Engineering, Beijing Technology and Business University, 100048, China; State Key Laboratory of Virtual Reality Technology, Beihang University, Beijing 100083, China; School of Computer Science and Information Engineering, Beijing Technology and Business University, 100048, China",2011 IEEE International Symposium on VR Innovation,29-Apr-11,2011,,,169,174,"The multi-domain virtual environment is an important research area of the distributed virtual reality. However, frequent interaction, great quantity of messages and the discrepant need of each individual simulation domain resulted in numerous redundant messages. In this paper, we propose a Publish/Subscribe based correlative matching method for multi-domain virtual environment. This method focus on data filtering of domains' gateways in addition to the DDM scheme. The paper introduces the correlative matching algorithm, the binary representation and the matching method which based on publish/subscribe relationship. Analysis and experiments show that this new solution effectively reduces the redundant data transferring among gateways, thus greatly enhances the performance of the virtual environment, and that the cost of matching method is relative small in multi-domain virtual environment application.",,978-1-4577-0054-5,10.1109/ISVRI.2011.5759625,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5759625,Publish/subscribe;matching method;multi-domain,Logic gates;Virtual environment;Bandwidth;Filtering;Local area networks;Wide area networks;Servers,middleware;virtual reality,correlative matching method;multidomain virtual environment;distributed virtual reality;data filtering;correlative matching algorithm,,,,10,,29-Apr-11,,,IEEE,IEEE Conferences
A framework for a multi-sensory VR effect system with motional display,Byounghyun Yoo; Moohyun Cha; Soonhung Han,"Dept. of Mech. Eng., Korea Adv. Inst. of Sci. & Technol., Daejeon, South Korea; Dept. of Mech. Eng., Korea Adv. Inst. of Sci. & Technol., Daejeon, South Korea; Dept. of Mech. Eng., Korea Adv. Inst. of Sci. & Technol., Daejeon, South Korea",2005 International Conference on Cyberworlds (CW'05),6-Feb-06,2005,,,8 pp.,244,"Virtual reality simulators have been developed as tools for the transfer of knowledge and education. Concurrently, the demand for exhibition systems of science education and cultural experiences has also increased. Existing VR (virtual reality) simulators, which are based on the calculation of dynamics equations, cannot easily be adapted to changes in simulation content. In order to transfer knowledge and maintain interest through educational applications, an experiential system that has multi-sensory effects as well as motion effects is needed. The authors proposed a method for motion generation that is tailored to riding systems and multi-sensory VR effects. In this study, both sense of motion, which is generated from movement of the viewpoint of the visual image, and motion effects, which are prepared in advance, are blended to realize motion simulation by the proposed method. Motion effects can easily be added by interaction between the user and the riding system. Various sensory cues are also implemented to the riding system",,0-7695-2378-1,10.1109/CW.2005.5,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1587539,,Virtual reality;Displays;Cultural differences;Vehicle dynamics;Vehicles;Libraries;Equations;Aerodynamics;Aerospace materials;Aerospace simulation,computer aided instruction;virtual reality,virtual reality simulators;knowledge transfer;science education;multisensory effects;visual image;motion simulation;user interaction,,,1,17,,6-Feb-06,,,IEEE,IEEE Conferences
A Virtual Assembly Design Environment,S. Jayaram; Yong Wang; U. Jayaram; K. Lyons; P. Hart,"Dept. of Mech. & Mater. Eng., Washington State Univ., Pullman, WA, USA; NA; NA; NA; NA",Proceedings IEEE Virtual Reality (Cat. No. 99CB36316),6-Aug-02,1999,,,172,179,"The Virtual Assembly Design Environment (VADE) is a virtual reality (VR) based engineering application which allows engineers to evaluate, analyze, and plan the assembly of mechanical systems. This system focuses on utilizing an immersive virtual environment tightly coupled with commercial computer aided design (CAD) systems. Salient features of VADE include: data integration (two-way) with a parametric CAD system; realistic interaction of the user with parts in the virtual environment; creation of valued design information in the virtual environment; reverse data transfer of design information back to the CAD system; significant interactivity in the virtual environment; collision detection; and physically-based modeling. This paper describes the functionality and applications of VADE. A discussion of the limitations of virtual assembly and a comparison with automated assembly planning systems are presented. Experiments conducted using real-world engineering models are also described.",1087-8270,0-7695-0093-5,10.1109/VR.1999.756948,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=756948,,Virtual reality;Design automation;Design engineering;Virtual environment;Process planning;Integrated circuit modeling;Power engineering and energy;NIST;Assembly systems;Manufacturing systems,virtual reality;user interfaces;CAD;mechanical engineering computing;assembly planning,Virtual Assembly Design Environment;VADE;virtual reality;engineering application;mechanical systems;immersive virtual environment;computer aided design;CAD;data integration;user interaction;data transfer;collision detection;physically-based modeling;assembly planning systems;experiments,,29,4,17,,6-Aug-02,,,IEEE,IEEE Conferences
Human-Robot Assembly: Methodical Design and Assessment of an Immersive Virtual Environment for Real-World Significance,J. H√∂cherl; A. Adam; T. Schlegl; B. Wrede,"OTH Regensburg,Regensburg Robotics Research Unit,Regensburg,Germany; OTH Regensburg,RRRU,Regensburg,Germany; OTH Regensburg,RRRU,Regensburg,Germany; OTH Regensburg,RRRU,Regensburg,Germany",2020 25th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA),5-Oct-20,2020,1,,549,556,"Virtual reality is a powerful tool for industrial applications. The article at hand addresses designers of industrial virtual environments. It summarizes key aspects to design immersive and coherent virtual environments. Furthermore, relevant influencing factors for a high quality virtual environment and tools to quantify this quality are presented. So far, a methodology to design, evaluate, and transfer knowledge from virtual environments into reality has been missing and is of high value for industrial applications. The proposed methodical approach includes the steps application analysis, technology selection and integration, design of virtual environment, evaluation of simulator quality, as well as discussion of the real-world validity. The method is shown on the example of a virtual human-robot working cell used to analyze the human perception of robot behavior during mutual assembly processes. The quality of the virtual environment is evaluated to be adequate for those purposes and the transfer of knowledge gained in virtuality on a corresponding real-world application is discussed. To the best of our knowing a system like the presented one, including full-body tracking, finger tracking, a virtual avatar and a head-mounted display has not been used for industrial use cases and human-robot cooperation before.",1946-0759,978-1-7281-8956-7,10.1109/ETFA46521.2020.9212039,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9212039,virtual reality;human-robot cooperation;system design;fidelity;industrial applications;assembly;immersive and coherent virtual environment;knowledge transfer;simulator quality;real-world validity,,avatars;helmet mounted displays;human-robot interaction;robotic assembly,immersive virtual environment;virtual reality;industrial applications;industrial virtual environments;coherent virtual environments;high quality virtual environment;human-robot working cell;virtual avatar;human-robot cooperation;human-robot assembly,,,,35,,5-Oct-20,,,IEEE,IEEE Conferences
3D Sound Rendering in a Virtual Environment to Evaluate Pedestrian Street Crossing Decisions at a Roundabout,H. Wu; D. H. Ashmead; H. Adams; B. Bodenheimer,"Vanderbilt University, USA; Vanderbilt University, USA; Vanderbilt University, USA; Vanderbilt University, USA",2018 IEEE 4th VR Workshop on Sonic Interactions for Virtual Environments (SIVE),16-Dec-18,2018,,,1,6,"Crossing streets is a potentially hazardous activity for pedestrians, and it is made more hazardous when the complexity of the intersection increases beyond a simple linear bisection, as it does in the case of a roundabout. We are interested in how pedestrians make decisions about when to cross at such intersections. Simulating these intersections in immersive virtual reality provides a safe and effective way to do this. In this context, we present a traffic simulation designed to assess how pedestrians make dynamic gap affordance judgments related to crossing the street when supplied with spatialized sound cues. Our system uses positional information to generate generic head-related transfer functions (HRTFs) for spatializing audio sources. In this paper we evaluate the utility of using spatialized sound for these gap crossing judgments. In addition, we evaluate our simulation against varying levels of visual degradation to better understand how those with visual deficits might rely on their auditory senses. Our results indicate that spatialized sound enhances the experience of the virtual traffic simulation; its effects on gap crossing behavior are more subtle.",,978-1-5386-5713-3,10.1109/SIVE.2018.8577195,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8577195,Virtual reality;spatialized sound;gap affordance;traffic simulation;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism‚ÄîVirtal Reality;J.4 [Computer Applications]: Social and Behavioral Sciences‚ÄîPsychology,Virtual environments;Solid modeling;Three-dimensional displays;Visualization;Biological system modeling;Acoustics;Automobiles,acoustic signal processing;audio signal processing;digital simulation;pedestrians;rendering (computer graphics);solid modelling;traffic engineering computing;transfer functions;virtual reality,virtual reality;head-related transfer functions;pedestrian street crossing decisions;HRTF;audio sources;gap crossing behavior;virtual traffic simulation;roundabout;virtual environment;3d sound rendering,,,,50,,16-Dec-18,,,IEEE,IEEE Conferences
Development of A Virtual Environment to Realize Human-Machine Interaction of Forklift Operation,J. Y. Chew; K. Okayama; T. Okuma; M. Kawamoto; H. Onda; N. Kato,"National Institute of Advanced Industrial Science and Technology,Japan; National Institute of Advanced Industrial Science and Technology,Japan; National Institute of Advanced Industrial Science and Technology,Japan; National Institute of Advanced Industrial Science and Technology,Japan; National Institute of Advanced Industrial Science and Technology,Japan; National Institute of Advanced Industrial Science and Technology,Japan",2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA),16-Dec-19,2019,,,112,118,"This study presents an experimental concept to develop realistic Human-Machine Interaction (HMI) for a Virtual Environment (VE) and a novel evaluation methodology of such system. Such evaluation is motivated by the need to facilitate transfer of model/knowledge from VE to the Real Environment (RE), where it is crucial for the VE to trigger similar user behavior as in the RE. This paper discusses the application of such concept to evaluate interactions of forklift operation in the VE. First, a Virtual Reality (VR) forklift simulator is developed using motion capture and 3D reconstruction methods to mimic HMI of the real forklift operation. Then, the Dynamic Time Warping (DTW) algorithm is used for temporal evaluation of operation behaviors in VE and RE. Results of DTW (i.e. distance and correlation) are used as objective measures to evaluate fidelity of VE during forklift operations on the simulator. Results suggest the proposed forklift simulator triggers operation behavior which is similar (highly correlated) to that of real forklift operation. The contributions of this paper are (a) the novel VR forklift simulator system to realize interactions of real forklift in the VE, and (b) the proposed objective measures for temporal evaluation of the fidelity of VE.",,978-1-7281-3118-4,10.1109/RITAPP.2019.8932837,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932837,,Visualization;Task analysis;Three-dimensional displays;Resists;Image reconstruction;Tracking;Man-machine systems,fork lift trucks;human computer interaction;man-machine systems;virtual reality,operation behaviors;temporal evaluation;virtual environment;human-machine interaction;evaluation methodology;Virtual Reality forklift simulator;forklift simulator;forklift simulator;VR forklift;Real Environment;motion capture;3D reconstruction methods;real forklift operation;Dynamic Time Warping,,,,26,,16-Dec-19,,,IEEE,IEEE Conferences
Perceptual Study of Near-Field Binaural Audio Rendering in Six-Degrees-of-Freedom Virtual Reality,O. S. Rummukainen; S. J. Schlecht; T. Robotham; A. Plinge; E. A. P. Habets,"International Audio Laboratories Erlangen, A joint institution of the Friedrich-Alexander-University Erlangen-N√ºrnberg (FAU), Fraunhofer Institute for Integrated Circuits (IIS), Germany; International Audio Laboratories Erlangen, A joint institution of the Friedrich-Alexander-University Erlangen-N√ºrnberg (FAU), Fraunhofer Institute for Integrated Circuits (IIS), Germany; International Audio Laboratories Erlangen, A joint institution of the Friedrich-Alexander-University Erlangen-N√ºrnberg (FAU), Fraunhofer Institute for Integrated Circuits (IIS), Germany; International Audio Laboratories Erlangen, A joint institution of the Friedrich-Alexander-University Erlangen-N√ºrnberg (FAU), Fraunhofer Institute for Integrated Circuits (IIS), Germany; International Audio Laboratories Erlangen, A joint institution of the Friedrich-Alexander-University Erlangen-N√ºrnberg (FAU), Fraunhofer Institute for Integrated Circuits (IIS), Germany",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,448,454,"Auditory localization cues in the near-field are significantly different than in the far-field. The near-field region is within an arm's length of the listener allowing to integrate proprioceptive cues to determine the location of an object in space. This perceptual study compares three non-individualized methods to apply head-related transfer functions (HRTFs) in six-degrees-of-freedom near-field audio rendering, namely, far-field measured HRTFs, multi-distance measured HRTFs, and spherical-model-based HRTFs with near-field extrapolation. To set our findings in context, we provide a real-world hand-held audio source for comparison along with a distance-invariant condition. Two modes of interaction are compared in an audio-visual virtual reality: one allowing the participant to move the audio object dynamically and the other with a stationary audio object but a freely moving listener.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8798177,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798177,Human-centered computing‚ÄîHuman computer interaction (HCI)‚ÄîInteraction paradigms‚ÄîVirtual Reality;Human-centered computing‚ÄîHuman computer interaction (HCI)‚ÄîInteraction paradigms‚ÄîMixed / augmented reality;Human-centered computing‚ÄîHuman computer interaction (HCI)‚ÄîHCI design and evaluation methods‚ÄîUser studies,Rendering (computer graphics);Loudspeakers;Virtual reality;Visualization;Solid modeling;Engines;Acoustic measurements,acoustic signal processing;audio signal processing;hearing;human computer interaction;virtual reality,near-field binaural audio rendering;six-degrees-of-freedom virtual reality;auditory localization cues;proprioceptive cues;head-related transfer functions;six-degrees-of-freedom near-field audio rendering;spherical-model-based HRTFs;near-field extrapolation;audio-visual virtual reality;handheld audio source;human computer interaction;binaural localization cues,,,,23,,15-Aug-19,,,IEEE,IEEE Conferences
Methods of Efficiency Enhancement of Network Interaction in Distributed Systems of Virtual Reality,V. Y. Kharitonov,Moscow power engineering institute,2nd International Conference on Dependability of Computer Systems (DepCoS-RELCOMEX '07),16-Jul-07,2007,,,305,308,"In this paper the main problems taking place when organizing consistent network interaction in distributed systems of a virtual reality are considered. In particular, the physical limitations influencing reliability of data exchanges between users are considered, and their analytical estimation is given. Then an overview of modern methods that allow to overcome these limitations is provided, such as dead reckoning. Finally, the new adaptive dead reckoning method is proposed to reduce data exchanges between clients considerably while saving desirable state prediction accuracy of corresponded objects. Moreover this method allows to lower the reliability requirements for data transfer in a network using less reliable, but faster and more efficient protocols, such as UDP.",,0-7695-2850-3,10.1109/DEPCOS-RELCOMEX.2007.31,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4272923,,Virtual reality;Delay;Bandwidth;Virtual environment;Coherence;Computer network reliability;Dead reckoning;Workstations;Size measurement;Time measurement,computer network reliability;virtual reality,network interaction enhancement;distributed systems;virtual reality;dead reckoning;data transfer;UDP,,2,,5,,16-Jul-07,,,IEEE,IEEE Conferences
Tangible interaction for conceptual architectural design,J. M. S. Dias; P. Santos; N. Diniz; L. Monteiro; R. Silvestre; R. Bastos,"ADETTI/UNIDE, Lisbon, Portugal; ADETTI/UNIDE, Lisbon, Portugal; ADETTI/UNIDE, Lisbon, Portugal; ADETTI/UNIDE, Lisbon, Portugal; ADETTI/UNIDE, Lisbon, Portugal; ADETTI/UNIDE, Lisbon, Portugal","The First IEEE International Workshop Agumented Reality Toolkit,",6-Jan-03,2002,,,9 pp.,,"This work reports and experiments a tangible mixed reality system for architectural design usage scenarios, such as conceptual design, client brief or architectural design education. The system provides the means for an architect to intuitively interact with an augmented version of a real scale model, in normal working settings, where he can observe 3D virtual objects registered to the real ones. Intuitive tangible interfaces, implemented with paddles, are used to aid design and editing tasks in the mixed environment. By means of paddle gesturing recognition, it is possible to activate a menu, browse and choose menu options or pick, move, rotate and scale 3D virtual objects, within the scale model working area. To transport the user from augmented reality to a fully virtual environment (supporting real-time scene navigation, while in VR mode) and back, paddle gesturing recognition is also used. Complex architectural designs, described in the VRML 97 data format, can be imported into our system, which provides a platform, for testing now design concepts while seamlessly transporting the architect in a truly mixed reality environment: from reality (RE) to augmented reality (AR) and then through augmented virtuality (AV), towards a full virtual environment (VE), and back.",,0-7803-7680-3,10.1109/ART.2002.1106951,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1106951,,Virtual reality;Testing;Design automation;Augmented reality;Cameras;Layout;Programmable logic arrays;Process design;Shape;Visualization,augmented reality;architectural CAD;gesture recognition;virtual reality languages,conceptual architectural design;tangible interaction;tangible mixed reality system;client brief;architectural design education;real scale model;3D virtual objects;intuitive tangible interfaces;editing;paddle gesture recognition;menu;virtual environment;VRML 97 data format,,3,5,13,,6-Jan-03,,,IEEE,IEEE Conferences
The avatar navigation of distributed virtual environment by using multiview client,ManKyu Sung; ChanJong Park,"Human Comput. Interaction Dept., Syst. Eng. Res. Inst., Taejun, South Korea; NA",Proceedings. 3rd Asia Pacific Computer Human Interaction (Cat. No.98EX110),6-Aug-02,1998,,,108,113,"The multi participant VR system can more enhance the sense of reality than existing single user VR systems. But, we should be careful when designing the system, since the current Internet using TCP/IP cannot afford to deliver such a massive amount of information required for the real time constraint of a VR system. We introduce distributed network structure and protocols for multiple user virtual space navigation and interaction through their avatars. This network structure is composed of heterogeneous multi servers, multiview clients and protocols. The multiview client can give proper information to the avatar when navigating the distributed virtual environment. And, for minimizing traffic on the network, we designed the VSTP-the Virtual Space Transfer Protocol to meet real time constraints. The avatars have nine behaviors and recognize the state of each other by using the pre-defined VSTP protocol.",,0-8186-8347-3,10.1109/APCHI.1998.704167,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=704167,,Avatars;Navigation;Virtual environment;Protocols;Virtual reality;Internet;TCPIP;Real time systems;Network servers;Telecommunication traffic,virtual reality;multi-access systems;real-time systems;transport protocols;user interfaces;client-server systems;interactive systems;human factors,avatar navigation;distributed virtual environment;multiview client;multi participant VR system;single user VR system;Internet;TCP/IP;real time constraint;VR system;distributed network structure;protocols;multiple user virtual space navigation;network structure;heterogeneous multi servers;Virtual Space Transfer Protocol;VSTP protocol,,,7,10,,6-Aug-02,,,IEEE,IEEE Conferences
Rock or Roll ‚Äì Locomotion Techniques with a Handheld Spherical Device in Virtual Reality,D. Englmeier; F. Fan; A. Butz,"LMU Munich,Munich,Germany; LMU Munich,Munich,Germany; LMU Munich,Munich,Germany",2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),14-Dec-20,2020,,,618,626,"We investigate the use of a handheld spherical object as a controller for locomotion in VR. Rotating the object controls avatar movement in two different ways: As a zero order controller, it is continuously rotated to the target position as if rolling a ball on the floor. As a first order controller, it is tilted like a joystick to determine the direction and speed of movement. We describe how our prototype was built from low-cost commercially available hardware and discuss our design decisions. Then we evaluate both locomotion techniques in a user study (N=20) and compare them to established methods using handheld VR controllers. Our prototype matched and in some cases outperformed these methods regarding task time and accuracy. All results were obtained without any usage instructions, indicating easy learnability. Some of our insights may transfer to interaction with other naturally shaped objects in VR experiences.",1554-7868,978-1-7281-8508-8,10.1109/ISMAR50242.2020.00089,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284676,Human-centered computing;Human computer interaction (HCI);Interaction devices;Haptic devices;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality,Avatars;Prototypes;Rocks;Hardware;Task analysis;Floors;Augmented reality,avatars;human computer interaction;interactive devices,design decisions;locomotion techniques;handheld VR controllers;naturally shaped objects;VR experiences;handheld spherical device;virtual reality;handheld spherical object;avatar movement;zero order controller,,,,48,,14-Dec-20,,,IEEE,IEEE Conferences
Increasing the effective egocentric field of view with proprioceptive and tactile feedback,Ungyeon Yang; G. Jounghyun Kim,"Virtual Reality Div., Electr. & Telecom. Res. Inst., Daejeon, South Korea; NA",IEEE Virtual Reality 2004,12-Jul-04,2004,,,27,34,"Multimodality often exhibits synergistic effects: each modality compliments and compensates for other modalities in transferring coherent, unambiguous, and enriched information for higher interaction efficiency and improved sense of presence. In this paper, we explore one such phenomenon: a positive interaction among the geometric field of view, proprioceptive interaction, and tactile feedback. We hypothesize that, with proprioceptive interaction and tactile feedback, the geometric field of view and thus visibility can be increased such that it is larger than the physical field of view, without causing a significant distortion in the user's distance perception. This, in turn, would further help operation of the overall multimodal interaction scheme as the user is more likely to receive the multimodal feedback simultaneously. We tested our hypothesis with an experiment to measure the user's change in distance perception according to different values of egocentric geometric field of view and feedback conditions. Our experimental results have shown that, when coupled with physical interaction, the GFOV could be increased by up to 170 percent of the physical field of view without introducing significant distortion in distance perception. Second, when tactile feedback was introduced, in addition to visual and proprioceptive cues, the GFOV could be increased by up to 200 percent. The results offer a useful guideline for effectively utilizing of modality compensation and building multimodal interfaces for close range spatial tasks in virtual environments. In addition, it demonstrates one way to overcome the shortcomings of the narrow (physical) fields of views of most contemporary HMDs.",1087-8270,0-7803-8415-6,10.1109/VR.2004.1310052,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310052,,Feedback;Virtual reality;Space technology;Layout;Telecommunications;Computer science;Testing;Distortion measurement;Guidelines;Virtual environment,virtual reality;image motion analysis;helmet mounted displays;distortion;haptic interfaces,tactile feedback;geometric field of view;proprioceptive interaction;multimodal interaction;multimodal feedback;physical interaction;GFOV;proprioceptive cues;modality compensation;multimodal interfaces;spatial tasks;virtual environments;HMDs,,2,,33,,12-Jul-04,,,IEEE,IEEE Conferences
Research of inter-domain data filtering method for distributed interactive simulation,L. Li; C. Hongqian; T. Li,"School of Computer Science and Information Engineering, Beijing Technology and Business, University, Beijing 100048; School of Computer Science and Information Engineering, Beijing Technology and Business, University, Beijing 100048; School of Computer Science and Information Engineering, Beijing Technology and Business, University, Beijing 100048","2010 International Conference on Audio, Language and Image Processing",10-Jan-11,2010,,,1451,1456,"The distributed interactive simulation of multidomain is an important research area of the distributed virtual reality. However, frequent interaction, great quantity of messages and the discrepant need of each individual simulation domain resulted in numerous redundant messages. Filtering out the redundant data and relieving the transfer loads become a pressing necessity. We analysis the principle of data filtering of HLA standard and introduce a data filtering algorithm based on publish/subscribe. Utilized the data locality feature of distributed interaction simulation, this algorithm can be used in multi-domain either. The experiment shows that the method we introduced provides reliable data filtering performance with incurred incremental costs on purchasing information endurable by our system. In addition, the data filtering matching efficiency is well.",,978-1-4244-5858-5,10.1109/ICALIP.2010.5684393,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5684393,,Filtering;Logic gates;Subscriptions;Data models;Bandwidth;Distributed databases;Wide area networks,digital simulation;message passing;middleware;virtual reality,inter-domain data filtering method;distributed interactive simulation;distributed virtual reality;HLA standard;publish-subscribe;distributed interaction simulation,,2,,8,,10-Jan-11,,,IEEE,IEEE Conferences
Virtual reality based rehabilitation system for Parkinson and multiple sclerosis patients,M. M. Kƒ±lƒ±c; O. C. Muratlƒ±; C. Catal,"Istanbul K√ºlt√ºr University, Department of Computer Engineering, Bakƒ±rk√∂y, ƒ∞stanbul, 34156; Istanbul K√ºlt√ºr University, Department of Computer Engineering, Bakƒ±rk√∂y, ƒ∞stanbul, 34156; Istanbul K√ºlt√ºr University, Department of Computer Engineering, Bakƒ±rk√∂y, ƒ∞stanbul, 34156",2017 International Conference on Computer Science and Engineering (UBMK),2-Nov-17,2017,,,328,331,"The aim of this study is to present a virtual reality based rehabilitation system for Parkinson and Multiple Sclerosis (MS) patients. In this study, physical rehabilitation software has been developed using Virtual Reality (VR) technology. The VR environment was used to find a unique solution to the problems of balance, tremor and movement coordination that MS and Parkinson patients suffer from. Virtual reality environment was designed and implemented using UNITY 3D game engine. The generated virtual environment was supported by Kinect, delivered to the virtual reality viewer of Google Cardboard with third party software, and this whole system provided the virtual reality environment. The interaction of the patients with the virtual environment helped these patients to tackle with their problems. The movements in the joint area of the patient were detected using the Microsoft Kinect human-machine interface. Kinect transferred user movements to the computer based on the serial communication. This prototype system will be deployed into a rehabilitation center in Turkey for in-depth analysis and experiments.",,978-1-5386-0930-9,10.1109/UBMK.2017.8093401,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8093401,Virtual Reality;Software Systems;Health Informatics;Biomedical Systems;Human-Computer Interface;Unity for Virtual Reality,Games;Multiple sclerosis;Fatigue;Sensors;Virtual environments,computer games;diseases;human computer interaction;medical computing;patient rehabilitation;virtual reality,virtual reality viewer;virtual reality based rehabilitation system;Parkinson;multiple sclerosis patients;physical rehabilitation software;VR environment;movement coordination;MS patients;tremor problem;balance problem;UNITY 3D game engine;third party software;Microsoft Kinect human-machine interface;serial communication,,1,,32,,2-Nov-17,,,IEEE,IEEE Conferences
Virtual Reality Integrated Multi-Depth-Camera-System for Real-Time Telepresence and Telemanipulation in Caregiving,C. F. -v. B√∂hlen; A. Brinkmann; S. M√§vers; S. Hellmers; A. Hein,"Carl von Ossietzky University,Assistive Systems&Medical Technologies,Oldenburg,Germany; Carl von Ossietzky University,Assistive Systems&Medical Technologies,Oldenburg,Germany; Carl von Ossietzky University,Assistive Systems&Medical Technologies,Oldenburg,Germany; Carl von Ossietzky University,Assistive Systems&Medical Technologies,Oldenburg,Germany; Carl von Ossietzky University,Assistive Systems&Medical Technologies,Oldenburg,Germany",2020 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),15-Jan-21,2020,,,294,297,"Telepresence and telemanipulation robotics are suitable solutions to relieve humans from direct health risks and repetitive or unhealthy work. Through demographic changes in western countries and the COVID-19 pandemic, this relief is also considered for healthcare workers, especially caregivers, as the demands for them rises. The requirements are intuitively usable telerobotic and telepresence systems for remote assistance, to cut the high physical strain in manual patient transfers and the reduction of contact with infected patients. To ensure this, key technologies like 3D imaging and perception systems are essential. In this work, we present a novel, lightweight telepresence and telemanipulation system, specialized for caregiving. It allows an operator, wearing a virtual reality headset, to immerse into a sensor system captured scene on a distant location in real-time, with low latency of 250 ms and up to 30 fps refresh rate. Extensive measurement shows that 97.1% of the relevant point cloud data is below 1 cm error and 99.5 % is below 1.6 cm, making the system suitable for the application.",,978-1-7281-7463-1,10.1109/AIVR50618.2020.00059,Ministry of Education; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9319102,sensor systems and applications;virtual reality;computer networks,Three-dimensional displays;Robot sensing systems;Robots;Headphones;Virtual reality;Medical services;Solid modeling,cameras;diseases;epidemics;haptic interfaces;health care;human-robot interaction;image capture;medical computing;medical robotics;real-time systems;robot vision;telemedicine;telerobotics;virtual reality,demographic changes;western countries;COVID-19 pandemic;healthcare workers;caregivers;telepresence systems;remote assistance;high physical strain;manual patient transfers;infected patients;perception systems;telemanipulation system;caregiving;virtual reality headset;sensor system captured scene;real-time telepresence;telemanipulation robotics;direct health risks;repetitive work;unhealthy work;virtual reality integrated multidepth-camera-system,,,,26,,15-Jan-21,,,IEEE,IEEE Conferences
Post-Biological Hypersurfacing: Embodied Mixed Reality Data Transfer,J. Stadon,"Dept. of Art, Curtin Univ., Perth, WA, Australia",2011 International Conference on Cyberworlds,17-Nov-11,2011,,,264,268,"This paper focuses on the (d)evolving interface between cyber worlds and the real world, what Giannachi has called the hyper surface. This fusion of real and representation, linking cyber and real worlds constitutes mixed reality interaction as experienced by humans in the physical world, their avatars, agents, and virtual humans. Current mixed reality XML RPC (Remote Procedure Call) interfaces and real-time data transfer enhance the experience of the hyper surface for the audience beyond any previous virtual media types, such as, hypertext, HTML, VRML, virtual reality, etc. Previous research in mixed reality and interactive workspaces that use the concept of a bridge for data transfer have largely inspired this research and I aim to continue the development of new knowledge in this field by critically applying cultural discourse in order to develop a theory regarding the impact of such systems on the notion of post biological identity.",,978-1-4577-1453-5,10.1109/CW.2011.41,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6079377,virtual humans and avatars;human-computer interaction;social networking;networked collaborations;cyberworlds,Humans;DNA;Educational institutions;Cultural differences;Avatars;Collaboration,avatars;computer graphics;human computer interaction,post-biological hypersurfacing;mixed reality data transfer;cyber world;avatar;agent;virtual human;mixed reality XML RPC interface;remote procedure call interface,,,,12,,17-Nov-11,,,IEEE,IEEE Conferences
"What User Interface to Use for Virtual Reality? 2D, 3D or Speech‚ÄìA User Study",Y. Wei√ü; D. Hepperle; A. Sie√ü; M. W√∂lfel,"Fac. of Math., Ludwig Maximilian Univ., Munich, Germany; Fac. of Comput. Sci. & Bus. Inf. Syst., Karlsruhe Univ. of Appl. Sci., Karlsruhe, Germany; Fac. of Comput. Sci. & Bus. Inf. Syst., Karlsruhe Univ. of Appl. Sci., Karlsruhe, Germany; Fac. of Comput. Sci. & Bus. Inf. Syst., Karlsruhe Univ. of Appl. Sci., Karlsruhe, Germany",2018 International Conference on Cyberworlds (CW),27-Dec-18,2018,,,50,57,"In virtual reality different demands on the user interface have to be addressed than on classic screen applications. That's why established strategies from other digital media cannot be transferred unreflected and at least adaptation is required. So one of the leading questions is: which form of interface is preferable for virtual reality? Are 2D interfaces-that are mostly used in combination with mouse or touch interactions- the means of choice, although they do not use the medium's full capabilities? What about 3D interfaces that can be naturally integrated into the virtual space? And last but not least: are speech interfaces, the fastest and most natural form of human interaction/communication, which have recently established themselves in other areas (e.g. digital assistants), ready to conquer the world of virtual reality? To answer these question this work compares these three approaches based on a quantitative user study and highlights advantages and disadvantages of the respective interfaces for virtual reality applications.",,978-1-5386-7315-7,10.1109/CW.2018.00021,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8590016,virtual reality;comparison of user interfaces;input modalities;2D interface;3D interface;Speech interface,Three-dimensional displays;Two dimensional displays;User interfaces;Speech recognition;Image color analysis;Virtual reality;Task analysis,user interfaces;virtual reality,virtual space;speech interfaces;quantitative user study;virtual reality applications;user interface;classic screen applications;digital media,,1,,17,,27-Dec-18,,,IEEE,IEEE Conferences
Investigating Body Transfer Illusion from Human to Monkey Body,T. Javorsk√Ω; F. ≈†kola; S. Sylaiou; J. Martins; F. Liarokapis,"HCILab Masaryk University, Brno, Czech Republic; HCILab Masaryk University, Brno, Czech Republic; School of Social Sciences, Hellenic Open University, Patra, Greece; Faculty of Sciences and Technology, Universidade Tova de Lisboa, Lisbon, Portugal; HCILab Masaryk University, Brno, Czech Republic",2018 International Conference on Intelligent Systems (IS),9-May-19,2018,,,549,556,"This paper presents a virtual reality study examining the magnitude of embodiment into a human and nonhuman avatar. It examines the user experience of inhabiting the body of animals in immersive virtual environments. Participants embodied in a human-like virtual avatar experienced body transfer illusion into a body of a monkey. The experiment consisted of two variants. In the first variant, participants did not have the ability to control the hands inside the Monkey avatar, they were instructed to just look over the scene from their fixed point of view. In the second variant, the ability to move arms and hands of the Monkey avatar was enabled, and this fact was articulated to the test subjects. Results suggest that the body transfer illusion is indeed possible. The study also indicates that the actual shape or visual representation of the body matters less than the amount and diversity of stimuli, and possibilities of controlling the avatar's body. Results of this study can be leveraged in the design of e-learning, health-care, and affective computing platforms, where amplification of the human-oriented design using malleable virtual avatars can bring additional feedback channel to the users.",1541-1672,978-1-5386-7097-2,10.1109/IS.2018.8710499,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8710499,virtual reality;body transfer illusion;sensors,Hafnium;Erbium;Hidden Markov models,avatars;human computer interaction;user interfaces,virtual reality study;human avatar;nonhuman avatar;user experience;immersive virtual environments;human-oriented design;malleable virtual avatars;monkey body;human body;human-like virtual avatar experienced body transfer illusion;visual representation;monkey avatar,,2,,41,,9-May-19,,,IEEE,IEEE Conferences
Spatial sound rendering for dynamic virtual environments,B. Cowan; B. Kapralos,"Faculty of Business and Information Technology, University of Ontario Institute of Technology, Oshawa, Canada; Faculty of Business and Information Technology, University of Ontario Institute of Technology, Oshawa, Canada",2013 18th International Conference on Digital Signal Processing (DSP),10-Oct-13,2013,,,1,6,"We present the details of a virtual sound rendering engine (VSRE) that is being developed for virtual environments and serious games. The VSRE incorporates innovative graphics processing unit-based methods to allow for the approximation of acoustical occlusion/diffraction and reverberation effects at interactive rates. In addition, the VSRE includes a GPU-based method that performs the one-dimensional convolution allowing for the incorporation of head-related transfer functions also at interactive rates. The VSRE is being developed as a research tool for examining multi-modal (audio-visual) interactions through the simple manipulation of the acoustic environment and audio parameters (sound quality), that will, through a series of human-based experiments, allow for the testing of the effect of varying these parameters may have on immersion, engagement, and visual fidelity perception within a virtual environment. Finally, we also provide a running time comparison of several one-dimensional convolution implementations.",2165-3577,978-1-4673-5807-1,10.1109/ICDSP.2013.6622815,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6622815,spatial sound;3D sound;graphics processing unit (GPU);virtual environment;serious games,Graphics processing units;Convolution;Rendering (computer graphics);Virtual environments;Games;Reverberation;Reflection,acoustic signal processing;audio signal processing;convolution;graphics processing units;virtual reality,one-dimensional convolution;visual fidelity perception;audio parameter;acoustic environment;audio-visual interaction;multimodal interaction;head related transfer function;one dimensional convolution;GPU based method;reverberation effect;diffraction effect;acoustical occlusion;graphic processing unit based method;serious game;VSRE;virtual sound rendering engine;dynamic virtual environment;spatial sound rendering,,,,23,,10-Oct-13,,,IEEE,IEEE Conferences
Movement Patterns and Trajectories in Three-Dimensional Software Visualization,S. Marcel; K. Rainer; M. Rudel,University of Bremen; University of Bremen; University of Bremen,2019 19th International Working Conference on Source Code Analysis and Manipulation (SCAM),12-Dec-19,2019,,,163,174,"Software visualization is a growing field of research, in which developers are assisted in understanding and analyzing complex applications by mapping different aspects of a software system onto visual attributes. Under the assumption that virtual reality, due to the higher degree of immersion, may enhance user experience, researchers have begun to port existing visualization techniques to this environment. Oftentimes, layout algorithms and user interaction methods are more or less transferred one-to-one, though little is known about the effect of virtual reality in visual analytics and program comprehension. Moreover, little research on the behavior of developers in different three-dimensional visualization environments has been done yet. This paper extends the results of a previous controlled experiment, in which the EvoStreets visualization technique was compared in different two-and three-dimensional environments. In the original experiment, we could not find evidence that any of the environments, namely, 2D, 2.5D, and virtual reality, effects the time required to find an answer or the correctness of the given answer. However, we found indications that movement patterns differ between the 2.5D and the virtual reality environments. For this paper, we analyzed and refined the movement trajectories that have been recorded in the previous experiment. We found significant differences for some of the tasks that had to be solved by the participants. In particular, we found evidence that the path length, average speed, and occupied volume differ. Though we could find significant correlations between these metrics and correctness, we found indications that there is a correlation with time, which, in turn, differs significantly between the 2.5D and the VR environments for many tasks. These findings may have implications on the design of visualizations, interactions, and recommendation systems for these different environments.",2470-6892,978-1-7281-4937-0,10.1109/SCAM.2019.00027,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930890,Software Visualization;2.5D Environment;Virtual Reality Environment;Movement patterns;Trajectories,Conferences,data visualisation;software engineering;virtual reality,three-dimensional software visualization;complex applications;software system;visual attributes;user experience;layout algorithms;user interaction methods;visual analytics;three-dimensional visualization environments;EvoStreets visualization technique;movement patterns;virtual reality environments;movement trajectories;VR environments;2.5D environments,,1,,59,,12-Dec-19,,,IEEE,IEEE Conferences
Importance of binaural cues of depth in low-resolution audio-visual 3D scene reproductions,D. Salvati; C. Drioli; F. Fontana; G. L. Foresti,"Department of Mathematics, Computer Science and Physics, University of Udine, Italy; Department of Mathematics, Computer Science and Physics, University of Udine, Italy; Department of Mathematics, Computer Science and Physics, University of Udine, Italy; Department of Mathematics, Computer Science and Physics, University of Udine, Italy",2018 IEEE 4th VR Workshop on Sonic Interactions for Virtual Environments (SIVE),16-Dec-18,2018,,,1,6,The following topics are dealt with: acoustic signal processing; virtual reality; audio signal processing; hearing; music; transfer functions; headphones; architectural acoustics; rendering (computer graphics); human computer interaction.,,978-1-5386-5713-3,10.1109/SIVE.2018.8577121,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8577121,3D Sound;Stereoscopic 3D Video;Depth Perception;Stereo Dipole;Low-Resolution,Three-dimensional displays;Visualization;Stereo image processing;Loudspeakers;Ear;Games;Virtual environments,acoustic signal processing;audio signal processing;hearing;music;virtual reality,acoustic signal processing;virtual reality;audio signal processing;hearing;music;transfer functions;headphones;architectural acoustics;rendering (computer graphics);human computer interaction,,,,28,,16-Dec-18,,,IEEE,IEEE Conferences
Immersive Group-to-Group Telepresence,S. Beck; A. Kunert; A. Kulik; B. Froehlich,Virtual Reality Systems Group at Bauhaus-Universit√É¬§t Weimar; Virtual Reality Systems Group at Bauhaus-Universit√§t Weimar; Virtual Reality Systems Group at Bauhaus-Universit√§t Weimar; Virtual Reality Systems Group at Bauhaus-Universit√§t Weimar,IEEE Transactions on Visualization and Computer Graphics,13-Mar-13,2013,19,4,616,625,"We present a novel immersive telepresence system that allows distributed groups of users to meet in a shared virtual 3D world. Our approach is based on two coupled projection-based multi-user setups, each providing multiple users with perspectively correct stereoscopic images. At each site the users and their local interaction space are continuously captured using a cluster of registered depth and color cameras. The captured 3D information is transferred to the respective other location, where the remote participants are virtually reconstructed. We explore the use of these virtual user representations in various interaction scenarios in which local and remote users are face-to-face, side-by-side or decoupled. Initial experiments with distributed user groups indicate the mutual understanding of pointing and tracing gestures independent of whether they were performed by local or remote participants. Our users were excited about the new possibilities of jointly exploring a virtual city, where they relied on a world-in-miniature metaphor for mutual awareness of their respective locations.",1941-0506,,10.1109/TVCG.2013.33,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479190,Multi-user virtual reality;telepresence;3D capture.,Calibration;Cameras;Servers;Streaming media;Image reconstruction;Image color analysis;Virtual reality,image colour analysis;image sensors;solid modelling;stereo image processing;virtual reality,immersive group-to-group telepresence;shared virtual 3D world;coupled projection-based multiuser setups;stereoscopic images;local interaction space;color cameras;registered depth cameras;captured 3D information;virtual user representations;virtual city;world-in-miniature metaphor,"Computer Graphics;Computer Simulation;Group Processes;Humans;Imaging, Three-Dimensional;Models, Biological;Social Behavior;Telecommunications;User-Computer Interface",98,,47,,13-Mar-13,,,IEEE,IEEE Journals
How EvoStreets Are Observed in Three-Dimensional and Virtual Reality Environments,M. Steinbeck; R. Koschke; M. O. R√ºdel,"University of Bremen,Germany; University of Bremen,Germany; University of Bremen,Germany","2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)",2-Apr-20,2020,,,332,343,"When analyzing software systems, a large amount of data accumulates. In order to assist developers in the preparation, evaluation, and understanding of findings, different visualization techniques have been developed. Due to recent progress in immersive virtual reality, existing visualization tools were ported to this environment. However, three-dimensional and virtual reality environments have different advantages and disadvantages, and by transferring concepts, such as layout algorithms and user interaction mechanisms, more or less one-to-one, the characteristics of these environments are neglected. In order to develop techniques adapting to the circumstance of a particular environment, more research in this field is necessary. In previously conducted case studies, we compared EvoStreets deployed in three different environments: 2D, 2.5D, and virtual reality. We found evidence that movement patterns-path length, average speed, and occupied volume-differ significantly between the 2.5D and virtual reality environments for some of the tasks that had to be solved by 34 participants in a controlled experiment. In this paper, we analyze the results of this experiment in more details, to study if not only movement is affected by these environments, but also the way how EvoStreets are observed. Although we could not find enough evidence that the number of viewpoints and their duration differ significantly, we found indications that in virtual reality viewpoints are located closer to the EvoStreets and that the distance between viewpoints is shorter. Based on our previous results and the findings of this paper, we present visualization and user interaction concepts specific to the kind of environment.",1534-5351,978-1-7281-5143-4,10.1109/SANER48275.2020.9054802,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054802,,,program visualisation;virtual reality,movement patterns;visualization tools;virtual reality environments;three-dimensional environments;user interaction;EvoStreets;immersive virtual reality;visualization techniques,,,,43,,2-Apr-20,,,IEEE,IEEE Conferences
Interactions Between Threat and Executive Control in a Virtual Reality Stroop Task,T. D. Parsons; C. G. Courtney,"University of North Texas, Denton, TX; University of Southern California, Los Angeles 501, CA",IEEE Transactions on Affective Computing,27-Feb-18,2018,9,1,66,75,"Understanding the ways in which persons rapidly transfer attention between tasks while still retaining ability to perform these tasks is an important area of study. Everyday activities commonly come in the form of emotional distractors. A recently developed Virtual Reality Stroop Task (VRST) allows for assessing neurocognitive and psychophysiological responding while traveling through simulated safe and ambush desert environments as Stroop stimuli appear on the windshield. We evaluated differences in psychophysiological response patterns associated with completion of an affective task alone versus completion of an affective task that also included a Stroop task. The VRST elicited increased heart rate, respiration rate, skin conductance level, and number of spontaneous fluctuations in electrodermal activity. Increased cognitive workload was found to be associated with the more cognitively challenging Stroop conditions which led to an increase in response level. This expands on previous findings and indicates that allocating attention away from the environment and toward Stroop stimuli likely requires greater inhibitory control. This is corroborated by behavioral findings from previous investigations with the VRST. The VRST revealed that the increased difficulty found in tasks like the Stroop interference task directly evoke autonomic changes in psychophysiological arousal beyond the threatening stimuli themselves.",1949-3045,,10.1109/TAFFC.2016.2569086,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7473917,Affective computing;psychology;arousal classification;affect recognition;virtual reality;Stroop task,Hidden Markov models;Skin;Automotive components;Heart rate;Atmospheric measurements;Particle measurements;Virtual reality,cognition;neurophysiology;psychology;skin;virtual reality,heart rate;respiration rate;skin conductance level;electrodermal activity;Stroop conditions;response level;Stroop stimuli;VRST;Stroop interference task;executive control;emotional distractors;neurocognitive responding;psychophysiological responding;simulated safe desert environments;ambush desert environments;psychophysiological response patterns;affective task;cognitive workload;inhibitory control;Virtual Reality Stroop Task,,1,,79,,19-May-16,,,IEEE,IEEE Journals
Arch-Explore: A natural user interface for immersive architectural walkthroughs,G. Bruder; F. Steinicke; K. H. Hinrichs,"Visualization and Computer Graphics (VisCG) Research Group, Department of Computer Science, University of M√ºnster, Einsteinstr. 62, 48149, Germany; Visualization and Computer Graphics (VisCG) Research Group, Department of Computer Science, University of M√ºnster, Einsteinstr. 62, 48149, Germany; Visualization and Computer Graphics (VisCG) Research Group, Department of Computer Science, University of M√ºnster, Einsteinstr. 62, 48149, Germany",2009 IEEE Symposium on 3D User Interfaces,7-Apr-09,2009,,,75,82,"In this paper we propose the Arch-Explore user interface, which supports natural exploration of architectural 3D models at different scales in a real walking virtual reality (VR) environment such as head-mounted display (HMD) or CAVE setups. We discuss in detail how user movements can be transferred to the virtual world to enable walking through virtual indoor environments. To overcome the limited interaction space in small VR laboratory setups, we have implemented redirected walking techniques to support natural exploration of comparably large-scale virtual models. Furthermore, the concept of virtual portals provides a means to cover long distances intuitively within architectural models. We describe the software and hardware setup and discuss benefits of Arch-Explore.",,978-1-4244-3965-2,10.1109/3DUI.2009.4811208,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811208,3D user interfaces;virtual environments;locomotion;architectural walkthroughs;redirected walking;passive haptic feedback,User interfaces;Legged locomotion;Virtual reality;Computer graphics;Indoor environments;Laboratories;Hardware;Virtual environment;Haptic interfaces;Feedback,helmet mounted displays;solid modelling;user interfaces;virtual reality,immersive architectural walkthroughs;Arch-Explore user interface;natural exploration;architectural 3D models;virtual reality environment;head-mounted display;CAVE setups;virtual indoor environments;VR laboratory setups;virtual models;virtual portals;architectural models,,52,,34,,7-Apr-09,,,IEEE,IEEE Conferences
Modeling an AGV based facility logistics system to measure and visualize performance availability in a VR environment,K. Eilers; J. Rossmann,"RIF Institute for Research and Transfer, Joseph-von-Fraunhofer-Strasse 20, 44227 Dortmund, GERMANY; Institute for Man-Machine Interaction, RWTH Aachen, Ahornstrasse 55, 52074, GERMANY",Proceedings of the Winter Simulation Conference 2014,26-Jan-15,2014,,,367,375,"Performance availability is an approach to rate the performance of material flow systems. Since the data necessary to determine the performance availability can only be obtained by observing the system in operation, planning towards a certain performance availability is a challenging task. In this paper, we present an approach to model an AGV (Automated Guided Vehicle) based logistics facility to ultimately measure and visualize the performance availability of the system within VR environments. We employed 3-D laser scans to create a visual representation of the facility and modelled the mechanical components using the simulation system's kinematic mechanisms. An interface to the real system's control architecture makes it possible to incorporate real world data and scenarios. Data not readily visible or not visible at all such as vehicle health, waiting times, and running times is surveyed and presented in a comprehensive VR environment for evaluating overall system performance and performance availability.",1558-4305,978-1-4799-7486-3,10.1109/WSC.2014.7019903,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7019903,,Availability;Logistics;Vehicles;Three-dimensional displays;Floors;Data models;Real-time systems,automatic guided vehicles;robot kinematics;virtual reality,AGV based facility logistics system;VR environment;material flow system;automated guided vehicle;3D laser scans;kinematic mechanism,,3,,19,,26-Jan-15,,,IEEE,IEEE Conferences
Qualitative analysis of a multimodal interface system using speech/gesture,M. Z. Baig; M. Kavakli,"Virtual and Interactive Simulations of Reality (VISOR) Research Group, Department of Computing, Faculty of Science and Engineering Macquarie University, Sydney, Australia; Virtual and Interactive Simulations of Reality (VISOR) Research Group, Department of Computing, Faculty of Science and Engineering Macquarie University, Sydney, Australia",2018 13th IEEE Conference on Industrial Electronics and Applications (ICIEA),28-Jun-18,2018,,,2811,2816,"In this paper, we present an upgraded version of the 3D modelling system, De-SIGN v3 [1]. The system uses speech and gesture recognition technology to collect information from the user in real-time. These inputs are then transferred to the main program to carry out required 3D object creation and manipulation operations. The aim of the system is to analyse the designer behaviour and quality of interaction, in a virtual reality environment. The system has the basic functionality for 3D object modelling. The users have performed two sets of experiments. In the first experiment, the participants had to draw 3D objects using keyboard and mouse. In the second experiment, speech and gesture inputs have been used for 3D modelling. The evaluation has been done with the help of questionnaires and task completion ratings. The results showed that with speech, it is easy to draw the objects but sometimes system detects the numbers incorrectly. With gestures, it is difficult to stabilize the hand at one position. The completion rate was above 90% with the upgraded system but the precision is low depending on participants.",2158-2297,978-1-5386-3758-6,10.1109/ICIEA.2018.8398188,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8398188,Speech;Gesture;MMIS;3D Modelling;CAD;Object Manipulation,Three-dimensional displays;Speech recognition;Cameras;Sensors;Solid modeling;Task analysis;Human computer interaction,gesture recognition;solid modelling;speech recognition;speech-based user interfaces;virtual reality,multimodal interface system;3D modelling system;manipulation operations;virtual reality environment;3D object modelling;speech recognition;De-SIGN v3;gesture recognition;3D object creation;designer behaviour,,2,,28,,28-Jun-18,,,IEEE,IEEE Conferences
Construction of virtual 3D life-like human hand for real-time human-computer interaction,S. Ren; H. Wu; Y. Wan,"Institute for Signals and Information Processing, Lanzhou University, China; Institute for Signals and Information Processing, Lanzhou University, China; Institute for Signals and Information Processing, Lanzhou University, China",2015 Seventh International Conference on Advanced Computational Intelligence (ICACI),13-Aug-15,2015,,,345,350,"Virtual hand plays an important role in many human-computer interaction applications. However, modeling a life-like 3D virtual hand is not a trivial task, especially the creation of flexible skin textures. In this paper, we propose a new method to execute texture mapping for the 3D virtual hand model automatically and apply it for human-computer interaction in real-time. Specifically, We first adjust the palm image using the mirror of the dorsal image. Then color transfer is performed for the palm image to ensure its similar color as the dorsal image. Finally interpolation is used to further adjust the direct texture mapping considering the virtual seams in fingers and thumb side. The proposed method is very efficient and experimental results show that the generated virtual hand model is more realistic than conventional virtual hands and can yield a stronger sense of immersion in the virtual world.",,978-1-4799-7259-3,10.1109/ICACI.2015.7184727,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7184727,,Computational modeling;Thumb;Indexes;Joints,human computer interaction;interpolation;solid modelling;virtual reality,virtual 3D life like human hand;real-time human-computer interaction;flexible skin textures;texture mapping;3D virtual hand model;palm image;dorsal image;interpolation;virtual seams;virtual world,,,,23,,13-Aug-15,,,IEEE,IEEE Conferences
Research on key technology of machining simulation based on Web,T. Yu; W. Liang; P. Guan; W. Wang,"School of Mechanical Engineering and Automation, Northeastern University, Shenyang, P.R. China; School of Mechanical Engineering and Automation, Northeastern University, Shenyang, P.R. China; School of Mechanical Engineering and Automation, Northeastern University, Shenyang, P.R. China; School of Mechanical Engineering and Automation, Northeastern University, Shenyang, P.R. China",2010 IEEE International Conference on Industrial Technology,27-May-10,2010,,,1071,1076,"According to the single release form of product information on the network in machine manufacturing enterprises and the high price of the conventional NC simulation software, a machining simulation system based on Web is developed in this paper. Making use of the superiority of Java and JavaScript on Web and the interaction of VRML technology, 3D browsing, virtual assembly and machining simulation are realized on the network. Based on the authenticity and real-time of virtual reality, a network distributed virtual simulation system is designed. This method of NC machining simulation is not dependent on the expensive CAD/CAM software, and for the size of the system files is small, it can be transferred on the network conveniently. Using the browser with the plug as the client, the system has free installation, authenticity, interaction, low cost, portability, low requirements for the client, etc.",,978-1-4244-5697-0,10.1109/ICIT.2010.5472567,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5472567,,Machining;Java;Pulp manufacturing;Virtual manufacturing;Assembly;Real time systems;Virtual reality;Design automation;Computer aided manufacturing;CADCAM,CAD/CAM;Internet;Java;machining;numerical control;virtual reality,World Wide Web;product information;machine manufacturing enterprises;NC simulation software;JavaScript;VRML technology;3D browsing;virtual assembly;virtual reality;network distributed virtual simulation system;NC machining simulation;CAD/CAM software,,,,8,,27-May-10,,,IEEE,IEEE Conferences
Binocular Phase-Coded Visual Stimuli for SSVEP-Based BCI,I. Kramberger; Z. kaƒçiƒç; G. Donaj,"Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, Slovenia; Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, Slovenia; Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, Slovenia",IEEE Access,22-Apr-19,2019,7,,48912,48922,"This paper presents a method of binocular visual stimulation for brain-computer interfaces (BCIs) based on steady-state visual evoked potentials (SSVEPs) using phase-coded symbols. The proposed method's emphasis is on a binocular phase-coded visual stimulus, which is based on the phase differences between the left- and right-eye stimuli, and a symbol detection and recognition procedure based on SSVEP response of the left and right occipital lobes of the user's scalp, where the SSVEP response is obtained as electroencephalography (EEG) signaling. The symbols are coded as phase differences and maintain the same frequency of the sine wave-modulated light provided to the user's left and right eyes as a binocular visual stimulation. Based on this method, a basic system setup is presented to explore the possibilities of binocular phase-coded visual stimuli for virtual or augmented reality applications, where the binocular visual stimulation was achieved by the specially designed head-mounted displays. Multiple visually coded targets are realized as eight different phase-coded binocular symbols and further evaluated as a random sequence of single targets, thus representing the situations in virtual or augmented reality, where multiple visually coded targets are present but not visualized to the user simultaneously within the same field of view. The offline results obtained from ten healthy subjects revealed that an average symbol recognition accuracy of 90.63% and an information transfer rate (ITR) of 70.55 bits/min were achieved for a symbol stimulation time of 2 s. The results of this paper demonstrate the feasibility of using binocular visual stimuli for SSVEP-based BCIs, where reasonable ITR is achieved using single-frequency binocular phase-coded symbols. The proposed method indicates the possibility of combining it with 3D wearable visualization technologies, such as binocular head-mounted displays (HMDs), in order to improve the intuitiveness of the interaction with more immersive user experience using BCI modalities.",2169-3536,,10.1109/ACCESS.2019.2910737,Javna Agencija za Raziskovalno Dejavnost RS; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8688386,Brain computer interfaces;brain stimulation;electroencephalography;data acquisition;human computer interaction;phase measurement;steady state visually evoked potential;three-dimensional displays;visualization;virtual reality;wearable sensors,Visualization;Electroencephalography;Encoding;Frequency modulation;Light emitting diodes;Liquid crystal displays;Phase measurement,augmented reality;brain-computer interfaces;electroencephalography;eye;helmet mounted displays;medical signal detection;medical signal processing;neurophysiology;visual evoked potentials,right-eye stimuli;symbol detection;recognition procedure;SSVEP response;phase differences;binocular visual stimulation;binocular phase-coded visual stimuli;multiple visually coded targets;symbol stimulation time;SSVEP-based BCIs;single-frequency binocular phase-coded symbols;3D wearable visualization technologies;binocular head-mounted displays;left- eye stimuli;brain-computer interfaces;steady-state visual evoked potentials;electroencephalography signaling;sine wave-modulated light;augmented reality applications;virtual reality applications;symbol recognition accuracy;information transfer rate;time 2.0 s,,,,38,,11-Apr-19,,,IEEE,IEEE Journals
Recalibration of Perceived Distance in Virtual Environments Occurs Rapidly and Transfers Asymmetrically Across Scale,J. W. Kelly; W. W. Hammel; Z. D. Siegel; L. A. Sjolund,Iowa State University; Iowa State University; Iowa State University; Iowa State University,IEEE Transactions on Visualization and Computer Graphics,24-Mar-14,2014,20,4,588,595,"Distance in immersive virtual reality is commonly underperceived relative to intended distance, causing virtual environments to appear smaller than they actually are. However, a brief period of interaction by walking through the virtual environment with visual feedback can cause dramatic improvement in perceived distance. The goal of the current project was to determine how quickly improvement occurs as a result of walking interaction (Experiment 1) and whether improvement is specific to the distances experienced during interaction, or whether improvement transfers across scales of space (Experiment 2). The results show that five interaction trials resulted in a large improvement in perceived distance, and that subsequent walking interactions showed continued but diminished improvement. Furthermore, interaction with near objects (1-2 m) improved distance perception for near but not far (4-5 m) objects, whereas interaction with far objects broadly improved distance perception for both near and far objects. These results have practical implications for ameliorating distance underperception in immersive virtual reality, as well as theoretical implications for distinguishing between theories of how walking interaction influences perceived distance.",1941-0506,,10.1109/TVCG.2014.36,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6777445,Distance perception; virtual reality; recalibration,Legged locomotion;Virtual environments;Visualization;Educational institutions;Atmospheric measurements;Particle measurements,calibration;distance measurement;virtual reality,perceived distance recalibration;virtual environments;visual feedback;walking interaction;distance perception;immersive virtual reality,,29,,53,,24-Mar-14,,,IEEE,IEEE Journals
A Physics-based Virtual Reality Environment to Quantify Functional Performance of Upper-limb Prostheses,K. Odette; Q. Fu,"Modeling and Simulation Program at University of Central Florida, Orlando, FL, 32827; NeuroMechanical Systems Laboratory, Mechanical and Aerospace Engineering, Biionix (Bionic Materials, Implants & Interfaces) Cluster, University of Central Florida, Orlando, FL, 32827",2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),7-Oct-19,2019,,,3807,3810,"Usability of upper-limb prostheses remains to be a challenge due to the complexity of hand-object interactions in activities of daily living. Functional evaluation is critical for the optimization of prosthesis performance during device design and parameter tuning phase. Therefore, we implemented a low-cost physics-based virtual reality environment (VRE) capable of simulating wide range of object grasping and manipulation tasks to enable human-in-the-loop optimization. Importantly, our novel VRE can assess user performance quantitatively using movement kinematics and interaction forces. We present a preliminary experiment to validate our VRE. Four able-bodied subjects performed object transfer tasks with a simulated myoelectric one DoF soft-synergy prosthetic hand, while wearing braces to restrain different levels of wrist motion. We found that the task completion time was similar across conditions, however limited wrist pronation led to more shoulder compensatory motion whereas challenging object orientation caused more torso compensatory motion.",1558-4615,978-1-5386-1311-5,10.1109/EMBC.2019.8857850,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8857850,,,biomechanics;electromyography;medical signal processing;prosthetics;virtual reality,parameter tuning phase;object grasping;human-in-the-loop optimization;interaction forces;simulated myoelectric one DoF soft-synergy prosthetic hand;object orientation;quantify functional performance;upper-limb prostheses;hand-object interactions;daily living;low-cost physics-based virtual reality environment;torso compensatory motion,Activities of Daily Living;Artificial Limbs;Biomechanical Phenomena;Humans;Physical Functional Performance;Physics;Prosthesis Design;Upper Extremity;Virtual Reality,,,25,,7-Oct-19,,,IEEE,IEEE Conferences
Extending Telepresence Technology as a Middle Stage between Humans to AI Robots Transition in the Workplace of the Future.,D. Cymbalak; F. Jakab; Z. Szalay; J. Turn≈à; E. Bilsk√Ω,"Slovak Centre of Scientific and Technical Information,Ko≈°ice,Slovakia; University Science Park TECHNICOM,Technical University of Ko≈°ice,Ko≈°ice,Slovakia; University of Pre≈°ov in Pre≈°ov,Faculty of Management; Slovak Centre of Scientific andTechnical Information,Bratislava,Slovakia; Slovak Centre of Scientific and Technical Information,Ko≈°ice,Slovakia",2019 17th International Conference on Emerging eLearning Technologies and Applications (ICETA),19-Mar-20,2019,,,133,138,"This paper introduces the concept of extending the telepresence technology (TP) in the way of physical interactions. Related work in the field was based on four years operation of National telepresence infrastructure to support research, development and technology transfer in Slovakia (NTI), where the need of extended collaborative features was identified. In our research we described a new way of human remote-control interfaces working with telepresence technology based on VR and hand or body sensors. At the other hand we proposed the telepresence endpoint's extensions design inspired by robotics elements such as robotic arms or humanoid robotic shells with face projection. The extended telepresence communication protocols were introduced. Multiple use case scenarios of extended telepresence technology were described in the way which will lead to the new approached in research in the field. Paper should be considered as a summary introduction to the problematics of extending the telepresence technology and each proposed concept will be described in more details in separate following manuscripts.",,978-1-7281-4967-7,10.1109/ICETA48886.2019.9040029,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9040029,Telepresence;Robots;Collaboration;Videoconferencing;Artificial Intelligence,,control engineering computing;humanoid robots;mobile robots;telecontrol;telerobotics;virtual reality,AI robots transition;technology transfer;extended collaborative features;human remote-control interfaces;telepresence endpoint;extended telepresence communication protocols;extended telepresence technology;national telepresence infrastructure,,1,,11,,19-Mar-20,,,IEEE,IEEE Conferences
"Robot self-preservation and adaptation to user preferences in game play, a preliminary study",√Å. Castro-Gonz√°lez; F. Amirabdollahian; D. Polani; M. Malfaz; M. A. Salichs,"RoboticsLab at the Carlos III University of Madrid, 28911, Legan√©s, Madrid, Spain; Adaptive Systems Research Group at the University of Hertfordshire, Hat-field, United Kingdom; Adaptive Systems Research Group at the University of Hertfordshire, Hat-field, United Kingdom; RoboticsLab at the Carlos III University of Madrid, 28911, Legan√©s, Madrid, Spain; RoboticsLab at the Carlos III University of Madrid, 28911, Legan√©s, Madrid, Spain",2011 IEEE International Conference on Robotics and Biomimetics,12-Apr-12,2011,,,2491,2498,"It is expected that in a near future, personal robots will be endowed with enough autonomy to function and live in an individual's home. This is while commercial robots are designed with default configuration and factory settings which may often be different to an individual's operating preferences. This paper presents how reinforcement learning is applied and utilised towards personalisation of a robot's behaviour. Two-level reinforcement learning has been implemented: first level is in charge of energy autonomy, i.e. how to survive, and second level is involved in adapting robot's behaviour to user's preferences. In both levels Q-learning algorithm has been applied. First level actions have been learnt in a simulated environment and then the results have been transferred to the real robot. Second level has been fully implemented in the real robot and learnt by human-robot interaction. Finally, experiments showing the performance of the system are presented.",,978-1-4577-2138-0,10.1109/ROBIO.2011.6181679,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6181679,,Robots;Batteries;Learning;Humans;Machine learning;Machine learning algorithms;Games,human-robot interaction;learning (artificial intelligence),robot self-preservation;user preferences adaptation;game play;personal robots;commercial robots;reinforcement learning;robot behaviour personalisation;Q-learning algorithm;human-robot interaction,,4,,28,,12-Apr-12,,,IEEE,IEEE Conferences
PATCH: Pump-Actuated Thermal Compression Haptics,D. T. Goetz; D. K. Owusu-Antwi; H. Culbertson,"The Ohio State University,Department of Mechanical and Aerospace Engineering,Columbus,OH,USA,43210; Massachusetts Institute of Technology,Department of Physics,Cambridge,MA,USA,02139; University of Southern California,Departments of Computer Science and Aerospace and Mechanical Engineering,Los Angeles,CA,USA,90089",2020 IEEE Haptics Symposium (HAPTICS),7-May-20,2020,,,643,649,"Haptics in virtual reality has become increasingly important for improving realism and immersiveness. However, matching the complexity of real-world tactile interactions is a challenging problem due to the complexity of our sense of touch. Motivated by the recognition that multi-modal haptic feedback is needed to fully recreate human touch, we created PATCH, a Pump-Actuated Thermal Compression Haptic device for presenting simultaneous thermal and compression cues. The system uses water of varying temperature to provide compression cues and transfer heat to or from the user's skin. The wearable component of the system is constructed solely of soft, flexible components. When compared to an established, unimodal, pressure-based haptic device, the PATCH system was found to perform similarly in terms of recognition and saliency, but it was rated more favorably in terms of wearability. The PATCH device can display temperatures ranging from 17¬∞ C to 42¬∞ C, fitting the desired temperatures with an R2 = 0.75, and can display pulsed cues at a rate of 0.22 Hz. The success of our PATCH system can serve to inform the development of the next generation of multi-modal haptic devices.",2324-7355,978-1-7281-0234-4,10.1109/HAPTICS45997.2020.ras.HAP20.32.c4048ec3,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9086319,,,force feedback;haptic interfaces;touch (physiological);virtual reality,virtual reality;multimodal haptic feedback;human touch;compression cues;PATCH system;PATCH device;pump-actuated thermal compression haptic device;thermal cues;pressure-based haptic device;frequency 0.22 Hz;temperature 17.0 degC to 42.0 degC,,,,25,,7-May-20,,,IEEE,IEEE Conferences
A video game design based on Emotiv Neuroheadset,R. Raju; C. Yang; C. Li; A. Cangelosi,"Center for Robotics and Neural Systems, Plymouth University, UK; Zienkiewicz Centre for Computational Engineering, Swansea University, SA1 8EN, UK; Center for Robotics and Neural Systems, Plymouth University, UK; Center for Robotics and Neural Systems, Plymouth University, UK",2016 International Conference on Advanced Robotics and Mechatronics (ICARM),27-Oct-16,2016,,,14,19,"This paper presents our work on the development of a video maze game in Android system, and a new method to play the game using gyroscope and electromyography (EMG) signals obtained by a wireless Emotiv Neuroheadset. The TeamViewer software is used to share the computer screen and to transfer the data to an Android device, and the Emotiv EPOC headset is used to detect the intension of the user who is playing the game. The cursor position is controlled using information from the gyroscope embeded in the headset. The clicks are generated through the users blinking action based on the expressive suite data acquired from Emotiv headset signal data. A program called Neuro Mousecontrol is used to act as a tool for controlling gyroscope movements and clicking actions together. Extensive tests have demonstrated the effectiveness of the developed system.",,978-1-5090-3364-5,10.1109/ICARM.2016.7606887,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7606887,,Games;Muscles;Software;Electrodes;Androids;Humanoid robots;Headphones,Android (operating system);brain-computer interfaces;computer games;electromyography;gyroscopes;human computer interaction,video maze game design;Android system;gyroscope;electromyography;EMG signals;wireless Emotiv Neuroheadset;TeamViewer software;Emotiv EPOC headset;cursor position control;Neuro Mousecontrol,,1,,18,,27-Oct-16,,,IEEE,IEEE Conferences
Mediated perception and action in human robotic embodiment,M. Bergamasco,"PERCRO, Scuola Superiore Sant'Anna, Pisa, Italy",19th International Symposium in Robot and Human Interactive Communication,11-Oct-10,2010,,,1,1,"Research on Robotics and Artificial Intelligence presently interprets the interaction between human and robotic subjects through a set of mediated controls who engage almost all human senses. The underlying communication requires the establishment of a set of interaction metaphors in order to allow a natural type of control. The most common of these metaphors is the kinematic copy of human gestures. During the last ten years incredible progresses in cognitive science, psychology, neuroscience, physiology and neurophysiology have been achieved. The knowledge about the relationship between the ‚Äúperception and sensori-motion mechanisms‚Äù and the brain has never been so advanced. One of the major outcomes is in the fact that it is possible to correlate brain neuronal activities to corresponding perception and motion, and, at the same time, it is possible to record these activities through the use of innovative devices. The combined adoption of these results does allow dissolving the physical constraints that act as a boundary during the interaction and control of robots and virtual environment entities. A new generation of brain and body (computer) interfaces (BBCI) will allow direct transfer of user intention and the realization of remote sensing. In such a way it will be possible to achieve the interactive communication with a robot without the requirement to physically perform any action. Virtual and robotic bodies can be controlled and moved even in absence of a correspondent motion of the controlling subject. The robots is moved only by thoughts while the robot perception is transferred directly to the humans through worn interfaces (Head mounted displays, skin and body stimulators,...). This lecture addresses the path from teleoperation and virtual environment interaction toward new methods to recreate the illusion of surrogating our own bodies in different entities (being robotic or virtual) and investigates how the relevant perception-action loops will be affected.",1944-9437,978-1-4244-7990-0,10.1109/ROMAN.2010.5598757,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5598757,,,brain-computer interfaces;human-robot interaction;interactive systems;telerobotics,human robotic embodiment;robotics;artificial intelligence;interaction metaphors;sensori-motion mechanisms;perception mechanisms;brain neuronal activities;virtual environment;brain and body interfaces;user intention;interactive communication,,,,,,11-Oct-10,,,IEEE,IEEE Conferences
Efficient HRTF-based Spatial Audio for Area and Volumetric Sources,C. Schissler; A. Nicholls; R. Mehra,Oculus & Facebook and UNC Chapel Hill; Oculus & Facebook; Oculus & Facebook,IEEE Transactions on Visualization and Computer Graphics,14-Mar-16,2016,22,4,1356,1366,"We present a novel spatial audio rendering technique to handle sound sources that can be represented by either an area or a volume in VR environments. As opposed to point-sampled sound sources, our approach projects the area-volumetric source to the spherical domain centered at the listener and represents this projection area compactly using the spherical harmonic (SH) basis functions. By representing the head-related transfer function (HRTF) in the same basis, we demonstrate that spatial audio which corresponds to an area-volumetric source can be efficiently computed as a dot product of the SH coefficients of the projection area and the HRTF. This results in an efficient technique whose computational complexity and memory requirements are independent of the complexity of the sound source. Our approach can support dynamic area-volumetric sound sources at interactive rates. We evaluate the performance of our technique in large complex VR environments and demonstrate significant improvement over the naive point-sampling technique. We also present results of a user evaluation, conducted to quantify the subjective preference of the user for our approach over the point-sampling approach in VR environments.",1941-0506,,10.1109/TVCG.2016.2518134,Oculus & Facebook; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7383327,Spatial audio;HRTF;area sources;volumetric sources;spherical harmonics;Spatial audio;HRTF;area sources;volumetric sources;spherical harmonics,Ear;Harmonic analysis;Rendering (computer graphics);Three-dimensional displays;Virtual environments;Transfer functions,audio signal processing;rendering (computer graphics);virtual reality,HRTF;spatial audio rendering technique;VR environments;point sampled sound sources;area-volumetric source;spherical harmonic;head related transfer function;spatial audio;computational complexity;memory requirements;sound source complexity;interactive rates;virtual reality,,34,1,38,,14-Jan-16,,,IEEE,IEEE Journals
Multi-DOFs motion platform based on spherical wheels for unmanned systems,S. Lee; S. Park; H. Son,"Department of Mechanical and Nuclear Engineering, UNIST, Ulsan, Korea; Department of Mechanical and Nuclear Engineering, UNIST, Ulsan, Korea; Department of Mechanical and Nuclear Engineering, UNIST, Ulsan, Korea",2016 13th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI),7-Nov-16,2016,,,35,37,"This paper presents to develop a multi-degree of freedom motion platform utilizing spherical wheels for unmanned systems. Recently, as rapidly developing unmanned robotic systems, it increases demands to control the systems by operators remotely and precisely, in particular for unmanned vehicles. Various multi-degree of freedoms (DOFs) motion control platforms have been utilized to transfer realistic motion to remote operators as they are on board by providing virtual reality. However, existing motion platforms have limits in motion realization and the number of DOFs due to mechanical linkages and actuating mechanism. In this paper, a new concept and design of 6 DOFs motion platform, capable of controlling 3 DOFs rotation and 3 DOFs translation motion is developed and feasibility and performance of motion control are practically demonstrated using an open-loop control. The performance shows the design of the motion platform sucessfully control rotation and translation motion independently and thus effectively control the unmanned systems.",,978-1-5090-0821-6,10.1109/URAI.2016.7734015,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7734015,Multi-DOFs motion platform;remote control;spherical wheel actuator;unmanned systems,Random access memory;Motion measurement;Time measurement;Aircraft;Robots,mobile robots;motion control;open loop systems;remotely operated vehicles;robot dynamics;robot kinematics;virtual reality;wheels,open-loop control;3 DOF translation motion control;3 DOF rotation control;actuating mechanism;mechanical linkages;motion realization;virtual reality;multi degree-of-freedom motion control platform;unmanned robotic systems;spherical wheels;multi DOF motion control platform,,1,,4,,7-Nov-16,,,IEEE,IEEE Conferences
Temporary made permanent: Turning temporary exhibitions into fixed memories,G. Morlando; L. Lamera; G. Guidi,"Dept. INDACO, Politecnico di Milano, Milan, Italy; Dept. INDACO, Politecnico di Milano, Milan, Italy; Dept. of Mechanical Engineering, Politecnico di Milano, Milan, Italy",2012 18th International Conference on Virtual Systems and Multimedia,3-Dec-12,2012,,,19,24,"The museum institution deals with the study, the storage and the fruition of cultural heritage. To fulfill these functions the museum uses, as well as the opinion of experts, even the most modern technologies. In this article we present some cases in which the use of digital and virtual reality effectively contributes to increase the knowledge on cultural heritage. In the last years there have been many studies to allow cultural heritage to be preserved with great care, ensuring the memory for scholars but also for future generations. The methods for storing a cultural object are widely studied, but the best techniques to preserve different forms of heritage like temporary or intangible items, are still under discussion. In particular this article refers to the possibility of keeping track of the information contained in a temporary exhibition project, that by its nature exists for a limited amount of time before being finally destroyed or transferred. With the use of standard tools like photogrammetry and three-dimensional modeling we try to define a process in order to turn the temporary into permanent, both for archiving purposes or for allowing the public to access the temporary installation once the physical object has been dismounted.",,978-1-4673-2563-9,10.1109/VSMM.2012.6365902,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365902,Temporary exhibition;temporary installation;Museum;Photogrammetry;3D Modeling,Cultural differences;Solid modeling;Image reconstruction;Lighting;Art;Rendering (computer graphics);Catalogs,exhibitions;history;information retrieval systems;museums;virtual reality,temporary exhibition project;fixed memories;museum institution;cultural heritage;digital reality;virtual reality;cultural object;photogrammetry;three-dimensional modeling;archiving purpose;physical object,,,,10,,3-Dec-12,,,IEEE,IEEE Conferences
Compressing Head-Related Transfer Function databases by Eigen decomposition,C. Ar√©valo; J. Villegas,"University of Aizu,Computer Arts Lab.,Aizu-Wakamatsu,Japan; University of Aizu,Computer Arts Lab.,Aizu-Wakamatsu,Japan",2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP),16-Dec-20,2020,,,1,6,"A method to reduce the memory footprint of Head- Related Transfer Functions (HRTFs) is introduced. Based on an Eigen decomposition of HRTFs, the proposed method is capable of reducing a database comprising 6,344 measurements from 36.30 MB to 2.41MB (about a 15:1 compression ratio). Synthetic HRTFs in the compressed database were set to have less than 1dB spectral distortion between 0.1 and 16 kHz. The differences between the compressed measurements with those in the original database do not seem to translate into degradation of perceptual location accuracy. The high degree of compression obtained with this method allows the inclusion of interpolated HRTFs in databases for easing the real-time audio spatialization in Virtual Reality (VR).",2473-3628,978-1-7281-9320-5,10.1109/MMSP48831.2020.9287134,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9287134,Eigen decomposition;audio spatialization;Virtual Reality (VR);HRIR databases;data compression,Transfer functions;Virtual reality;Multimedia databases;Distortion;Spatial databases;Real-time systems;Distortion measurement,acoustic signal processing;audio coding;data compression;interpolation;transfer functions;virtual reality,original database;Eigen decomposition;memory footprint;database comprising;compression ratio;synthetic HRTFs;compressed database;1dB spectral distortion;compressed measurements;head-related transfer function databases;interpolated HRTF;noise figure 1.0 dB;frequency 0.1 kHz to 16.0 kHz;memory size 2.41 MByte to 36.3 MByte,,,,27,,16-Dec-20,,,IEEE,IEEE Conferences
A Low-Spec Extendable GPU-Based Audio Library,C. Nelson; B. C. W√ºnsche,"Department of Computer Science, Boston University, Boston, MA; Department of Computer Science, University of Auckland, Auckland, New Zealand",2018 International Conference on Image and Vision Computing New Zealand (IVCNZ),7-Feb-19,2018,,,1,5,"Sound is an essential entity for creating realistic immersive virtual environments in applications such as computer games, health psychology, and scientific visualisation. Current multimedia libraries offer many tools for processing and synthesising sound but are usually executed on the CPU and/or suffer from vendor lock-in. In this paper we present a novel low-spec GPU implementation of an audio library. Preliminary studies suggest that the implementation improves speed by an order of magnitude compared to a CPU implementation. Furthermore a GPU-based implementation frees valuable resources on the CPU for other applications and it is ideal for applications where sounds and graphics are integrated and hence can be both executed on the GPU without requiring expensive data transfer between main memory and the graphics card.",2151-2205,978-1-7281-0125-5,10.1109/IVCNZ.2018.8634764,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8634764,audio libraries;graphics hardware;sound rendering;music synthesis;audio analysis;GPGPU,Graphics processing units;Graphics;Libraries;Games;Hardware;Pipelines;Music,graphics processing units;virtual reality,scientific visualisation;low-spec extendable GPU-based audio library;immersive virtual environments;low-spec GPU implementation,,,,26,,7-Feb-19,,,IEEE,IEEE Conferences
Using augmented reality virtual assistants to teach the traditional leather tanning process,G. Ma√ß√£es; W. Pimenta; E. Carvalho,"CCG - Centro de Computa√ß√£o, Gr√°fica, Guimar√£es, Portugal; CCG - Centro de Computa√ß√£o, Gr√°fica, Guimar√£es, Portugal; CCG - Centro de Computa√ß√£o, Gr√°fica, Guimar√£es, Portugal",6th Iberian Conference on Information Systems and Technologies (CISTI 2011),4-Aug-11,2011,,,1,7,"The leather tanning process carries a high cultural value in Guimar√£es city. In some areas of Portugal, most of the society and its history are somehow interlaced with the history of the leather and all the associated processes of its production. There is a great lack of a ‚Äúvivid‚Äù memory about the leather tanning process and its social implications. References to it in Guimar√£es city can be reduced to text and poor quality pictures. On the other hand, it is important to transmit to future generations the valuable role of the leather tanning in the local culture. At this point, the use of augmented reality techniques can help to illustrate interactively, expressively and with a compelling degree of immersion how this process used to be done, and help to preserve its memory. This project consisted in the development and implementation of an augmented reality application to young audiences that illustrates the ancient leather tanning process step-by-step. The resulting visualizations offer an impressive education experience that help to transfer a significant culture value of the Guimar√£es city.",2166-0735,978-989-96247-5-7,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5974179,Augmented reality;multimedia learning;cultural heritage,Augmented reality;Visualization;Animation;Computers;Cameras;Three dimensional displays;Pipelines,augmented reality;leather industry;production engineering computing;tanning,augmented reality virtual assistant;leather tanning process;poor quality pictures;augmented reality application;visualization,,,,,,4-Aug-11,,,IEEE,IEEE Conferences