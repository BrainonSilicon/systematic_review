Document Title,Authors,Author Affiliations,Publication Title,Date Added To Xplore,Publication Year,Volume,Issue,Start Page,End Page,Abstract,ISSN,ISBNs,DOI,Funding Information,PDF Link,Author Keywords,IEEE Terms,INSPEC Controlled Terms,INSPEC Non-Controlled Terms,Mesh_Terms,Article Citation Count,Patent Citation Count,Reference Count,License,Online Date,Issue Date,Meeting Date,Publisher,Document Identifier
An innovative ADHD assessment system using virtual reality,S. Yeh; C. Tsai; Y. Fan; P. Liu; A. Rizzo,"Department of Computer Science & Information Engineering, National Central University, Taiwan; Department of Psychiatry, Neurological Institute, Veterans General Hospital, Taiwan; Department of Computer Science & Information Engineering, National Central University, Taiwan; Department of Computer Science & Information Engineering, National Central University, Taiwan; Institute for Creative Technologies, University of Southern California, USA",2012 IEEE-EMBS Conference on Biomedical Engineering and Sciences,15-Apr-13,2012,,,78,83,"Attention Deficit Hyperactivity Disorder (ADHD) has a prevalence of about 5% and may cause inferiority complex, personality disorders, interpersonal impediment, and even anti-social behaviors in affected children if not treated early. In the past, the diagnosis of ADHD patients mainly depended on paper tests or behavior scales. However, such tests are usually time-consuming and their application suffers from constraints of external conditions in terms of test content and test type. Through the application of VR technology including head mounted display(HMD), game technology and sensors, this study develops and constructs an interactive panoramic virtual classroom scenario in which a blackboard embedded with listening test, CPT test, executive test, and visual memory test specially designed for attention and executive functions is incorporated; moreover, this study also develops a new assessment & diagnosis system based on children's performance, behavior & reaction in the above-mentioned four tests through an enormous and systematic design of a battery of visual & auditory distractions of different intensity levels, durations, and sequence. The system developed in this study is used to carry out a pilot trial on healthy volunteers and its functionalities are confirmed by the test results.",,978-1-4673-1666-8,10.1109/IECBES.2012.6498026,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6498026,ADHD;virtual reality;executive function;memory,,computer aided instruction;handicapped aids;helmet mounted displays;medical computing;medical disorders;virtual reality,innovative ADHD assessment system;virtual reality;attention deficit hyperactivity disorder;inferiority complex;personality disorder;interpersonal impediment;antisocial behavior;VR technology;head mounted display;HMD;game technology;sensor;interactive panoramic virtual classroom;listening test;CPT test;executive test;visual memory test;diagnosis system;children performance;visual distraction;auditory distraction;intensity level,,8,,10,,15-Apr-13,,,IEEE,IEEE Conferences
Spatial Memory Rehabilitation in Virtual Reality ‚Äì Extending findings from Epilepsy Patients to the General Population,S. Maidenbaum; A. Patel; E. Stein; J. Jacobs,"Columbia University,Biomedical Engineering,NY,USA; Columbia University,Biomedical Engineering,NY,USA; Columbia University,Biomedical Engineering,NY,USA; Columbia University,Biomedical Engineering,NY,USA",2019 International Conference on Virtual Rehabilitation (ICVR),13-Feb-20,2019,,,1,7,"Spatial memory is a critical function. Without it, we cannot understand our environment, situate ourselves within it, or remember where items are located. Most research on the neural basis of spatial memory is conducted either with invasive brain recordings from animals or with non-invasive imaging in humans. An emerging way to link these areas is by studying rare invasive recordings from the human brain, which can be obtained from epilepsy patients who have electrodes surgically implanted for seizure mapping. In recent years this invasive method has expanded our understanding of how the human brain represents space and has also suggested methods for modulating and potentially rehabilitating memory. However, it is unclear whether these results from epilepsy patients generalize to the non-epileptic population, and from testing in hospital rooms to more immersive and comfortable setups. Here, groups of epilepsy patients (n=69) and healthy participants (n=17) performed the same virtual spatial memory task, enabling us to compare their spatial memory performance. Moreover, we compared spatial memory performance between a standard computer screen versus a head-mounted display. We found that the spatial memory performance of epilepsy patients performing our task in a hospital was similar to that of matched healthy participants performing the task in the lab. Furthermore, actual spatial memory performance was similar on the group level irrespective of the interface used, despite the fact that subjects reported higher immersion with the head mounted display. By showing consistent spatial memory performance with a single paradigm across epilepsy patients and healthy participants, as well as with the use of different display modalities, our results provide a baseline for evaluating findings regarding the neural basis of spatial memory and neuromodulation for rehabilitation. More broadly, these results demonstrate that findings from neurosurgical patients are comparable to the wider population.",2331-9569,978-1-7281-1285-5,10.1109/ICVR46560.2019.8994573,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994573,Spatial memory;Memory Rehabilitation;Epilepsy;Virtual Reality;Immersive,Task analysis;Epilepsy;Sociology;Statistics;Electrodes;Hospitals;Standards,brain;electroencephalography;medical disorders;medical signal processing;neurophysiology;virtual reality,human brain;epilepsy patients;modulating memory;virtual spatial memory task;actual spatial memory performance;spatial memory performance;spatial memory rehabilitation;invasive brain recordings;noninvasive imaging,,,,43,,13-Feb-20,,,IEEE,IEEE Conferences
An innovative virtual reality system for mild cognitive impairment: Diagnosis and evaluation,S. Yeh; Y. Chen; C. Tsai; A. Rizzo,"Computer Science and Information Engineering Dept., National Central University, Taiwan; Computer Science and Information Engineering Dept., National Central University, Taiwan; Taipei Veterans General Hospital, Taiwan; Institute for Creative Technologies, University of Southern California, USA",2012 IEEE-EMBS Conference on Biomedical Engineering and Sciences,15-Apr-13,2012,,,23,27,"In advanced countries throughout the world, the population of Alzheimer's Disease(AD) patients has been gradually increasing with the aging of the society. As a result, it has become an important research topic how to diagnose AD early and give necessary treatment and training to AD patients, especially those with mild cognitive impairment(MCI), whose executive functions such as response inhibition, cognitive flexibility, attention switching and planning may display evident disorder and impairment. Unlike traditional paper tests and subjective assessments by the patient's relatives, this study adopts virtual reality(VR) technology to develop a novel diagnosis & assessment system, which uses head mounted display(HMD), game technology and sensors to generate an interactive and panoramic scenario-a virtual convenience store-for assessment of executive functions and memory. A variety of tasks of multi-layered difficulty-level hierarchy, such as memorizing a shopping list, looking for certain goods, and checking out, has been designed for customized and adaptive assessment, training, and treatment of MD. In the meantime, the study also records test-takers' performance data (including path and central-vision movement) in the process of all tasks for the development of a novel diagnosis & assessment method. Moreover, test-takers' technology acceptance is measured for assessing the elderly's subjective perception of new technology and discussing the topic of human-machine interaction. In the study, tests on 2 healthy adults have been completed, the system's functionality has been preliminarily verified, and test-takers' subjective perception of the system has been investigated.",,978-1-4673-1666-8,10.1109/IECBES.2012.6498023,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6498023,virtual realit;mild cognitive impairment;Alzheimer's Disease;executive function,,computer games;diseases;helmet mounted displays;patient diagnosis;patient treatment;sensors;virtual reality,innovative virtual reality system;mild cognitive impairment;Alzheimer disease patient;AD diagnosis;AD patient treatment;AD patient training;MCI;response inhibition;cognitive flexibility;attention switching;planning;VR;head mounted display;HMD;game technology;sensors;virtual convenience store;multilayered difficulty-level hierarchy;test-taker performance data;path movement;central-vision movement;test-taker technology acceptance;elderly subjective perception;human-machine interaction;system functionality;test-taker subjective perception,,7,,7,,15-Apr-13,,,IEEE,IEEE Conferences
Genesys: A Virtual Reality scene builder,J. D. O. De Leon; R. P. Tavas; R. A. Aranzanso; R. O. Atienza,"Ubiquitous Computing Laboratory, Electrical and Electronics Engineering Institute, University of the Philippines Diliman, Quezon City, Philippines; Ubiquitous Computing Laboratory, Electrical and Electronics Engineering Institute, University of the Philippines Diliman, Quezon City, Philippines; Ubiquitous Computing Laboratory, Electrical and Electronics Engineering Institute, University of the Philippines Diliman, Quezon City, Philippines; Ubiquitous Computing Laboratory, Electrical and Electronics Engineering Institute, University of the Philippines Diliman, Quezon City, Philippines",2016 IEEE Region 10 Conference (TENCON),9-Feb-17,2016,,,3708,3711,"Virtual Reality (VR) is a computer technology which simulates real world environments and a user's interactions within it. Current trends in VR, however, are focused on the gaming industry with limited work on VR creation tools. Thus, we propose a VR application that allows users to create 3-dimensional scenes in virtual reality named Genesys. Scenes created are viewed with the use of VR head mounted displays which provide the user with a more immersive work environment compared to traditional 2D monitors. Interactions within this workspace are done through motion controllers that allow users to manipulate with objects and spawn more from an online repository. Scenes created can be shared to the Genesys community of artists, creators and users through an online website. This feature widens the project's applications in education, business, and entertainment as a world builder and presentation tool. To measure the effectiveness of the application, a scene composition test was conducted at the end of the experiment. The results showed that Genesys is generally easy to use for people with limited experience in VR. However, improvements can still be made on the object manipulation controls such as rotation and scaling.",2159-3450,978-1-5090-2597-8,10.1109/TENCON.2016.7848751,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7848751,,Virtual reality;Games;Three-dimensional displays;Engines;Industries;Google;Software,helmet mounted displays;human computer interaction;user interfaces;virtual reality,Genesys;virtual reality scene builder;computer technology;VR creation tools;user interactions;gaming industry;three-dimensional scenes;VR head mounted displays;immersive work environment;motion controllers;online Web site;scene composition test;object manipulation controls,,1,,17,,9-Feb-17,,,IEEE,IEEE Conferences
Continuous automatic calibration for optical see-through displays,K. R. Moser; Y. Itoh; J. E. Swan,Mississippi State University; Technical University of Munich; Mississippi State University,2015 IEEE Virtual Reality (VR),27-Aug-15,2015,,,241,242,"The current advent of consumer level optical see-through (OST) head-mounted displays (HMD's) has greatly broadened the accessibility of Augmented Reality (AR) to not only researchers but also the general public as well. This increased user base heightens the need for robust automatic calibration mechanisms suited for nontechnical users. We are developing a fully automated calibration system for two stereo OST HMD's, a consumer level and prototype model, based on the recently introduced interaction free display calibration (INDICA) method. Our current efforts are also focused on the development of an evaluation process to assess the performance of the system during use by non-expert subjects.",2375-5334,978-1-4799-1727-3,10.1109/VR.2015.7223385,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223385,Calibration;OST HMD;Augmented Reality,Calibration;Cameras;Hardware;Augmented reality;Robustness;Prototypes;Head,augmented reality;helmet mounted displays,continuous automatic calibration system;consumer level optical see-through head-mounted displays;augmented reality;robust automatic calibration mechanisms;interaction free display calibration method;INDICA method,,1,,6,,27-Aug-15,,,IEEE,IEEE Conferences
Evaluating Multiple Levels of an Interaction Fidelity Continuum on Performance and Learning in Near-Field Training Simulations,A. Bhargava; J. W. Bertrand; A. K. Gramopadhye; K. C. Madathil; S. V. Babu,Clemson University; Clemson University; Clemson University; Clemson University; Clemson University,IEEE Transactions on Visualization and Computer Graphics,13-Mar-18,2018,24,4,1418,1427,"With costs of head-mounted displays (HMDs) and tracking technology decreasing rapidly, various virtual reality applications are being widely adopted for education and training. Hardware advancements have enabled replication of real-world interactions in virtual environments to a large extent, paving the way for commercial grade applications that provide a safe and risk-free training environment at a fraction of the cost. But this also mandates the need to develop more intrinsic interaction techniques and to empirically evaluate them in a more comprehensive manner. Although there exists a body of previous research that examines the benefits of selected levels of interaction fidelity on performance, few studies have investigated the constituent components of fidelity in a Interaction Fidelity Continuum (IFC) with several system instances and their respective effects on performance and learning in the context of a real-world skills training application. Our work describes a large between-subjects investigation conducted over several years that utilizes bimanual interaction metaphors at six discrete levels of interaction fidelity to teach basic precision metrology concepts in a near-field spatial interaction task in VR. A combined analysis performed on the data compares and contrasts the six different conditions and their overall effects on performance and learning outcomes, eliciting patterns in the results between the discrete application points on the IFC. With respect to some performance variables, results indicate that simpler restrictive interaction metaphors and highest fidelity metaphors perform better than medium fidelity interaction metaphors. In light of these results, a set of general guidelines are created for developers of spatial interaction metaphors in immersive virtual environments for precise fine-motor skills training simulations.",1941-0506,,10.1109/TVCG.2018.2794639,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260967,Bimanual Interaction;Interaction Fidelity;Empirical Evaluation;Educational Virtual Reality,Training;Aerospace electronics;Solid modeling;Metrology;Mice;Virtual environments,computer based training;helmet mounted displays;virtual reality,Interaction Fidelity Continuum;near-field training simulations;virtual reality applications;education;real-world interactions;safe risk-free training environment;intrinsic interaction techniques;near-field spatial interaction task;learning outcomes;discrete application points;performance variables;medium fidelity interaction metaphors;spatial interaction metaphors;immersive virtual environments;fine-motor skills training simulations;bimanual interaction metaphors;restrictive interaction metaphors;head-mounted displays;tracking technology,Adolescent;Adult;Cognition;Female;High Fidelity Simulation Training;Humans;Male;Surveys and Questionnaires;Task Performance and Analysis;User-Computer Interface;Virtual Reality;Young Adult,1,,33,Traditional,17-Jan-18,,,IEEE,IEEE Journals
A novel menu interaction method using head-mounted display for smartphone-based virtual reality,C. Sheng; L. Jiang; B. Tang; X. Tang,"College of Electronic Science and Engineering, NUDT, Changsha 410073, China; College of Electronic Science and Engineering, NUDT, Changsha 410073, China; College of Electronic Science and Engineering, NUDT, Changsha 410073, China; College of Electronic Science and Engineering, NUDT, Changsha 410073, China",2017 Progress In Electromagnetics Research Symposium - Spring (PIERS),18-Jan-18,2017,,,2384,2388,"The menu interaction design method for smartphone-based VR is currently one of the most popular research domains. The existing menu interaction method can be generally divided into two categories: the interaction devices based method and ray selection based method. However, both of them have some inevitable defects, which lead to bad user experience. In this paper, a novel interaction method is proposed, combining the advantages of the ray selection technology and HMD technology. And a smartphone-based VR application demonstration named ‚ÄúTarget Arena‚Äù is developed. In addition, the user experience is evaluated by conducting a survey on several aspects of the demonstration system such as portability, controllability, comfort degree, and overall user experience. Experimental results show that the menu interaction method proposed in the paper performs better than other existing methods.",,978-1-5090-6269-0,10.1109/PIERS.2017.8262151,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8262151,,Resists;Games;Virtual environments;Head;Smart phones;Electromagnetics;Springs,helmet mounted displays;interactive devices;smart phones;user interfaces;virtual reality,head-mounted display;smartphone-based virtual reality;menu interaction design method;existing menu interaction method;interaction devices;ray selection based method;ray selection technology;smartphone-based VR application demonstration,,,,4,,18-Jan-18,,,IEEE,IEEE Conferences
Brain Activity in Virtual Reality: Assessing Signal Quality of High-Resolution EEG While Using Head-Mounted Displays,S. Hertweck; D. Weber; H. Alwanni; F. Unruh; M. Fischbach; M. E. Latoschik; T. Ball,"Translational Neurotechnology Lab, University Medical Center Freiburg; Translational Neurotechnology Lab, University Medical Center Freiburg; Translational Neurotechnology Lab, University Medical Center Freiburg; Human-Computer Interaction Lab, University of Wuerzburg; Human-Computer Interaction Lab, University of Wuerzburg; Human-Computer Interaction Lab, University of Wuerzburg; Translational Neurotechnology Lab, University Medical Center Freiburg",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,970,971,"Biometric measures such as the electroencephalogram (EEG) promise to become viable alternatives to subjective questionnaire ratings for the evaluation of psychophysical effects associated with Virtual Reality (VR) systems, as they provide objective and continuous measurements without breaking the exposure. The extent to which the EEG signal can be disturbed by the presence of VR systems, however, has been barely investigated. This study outlines how to evaluate the compatibility of a given EEG-VR setup on the example of two commercial head-mounted displays (HMDs), the Oculus Rift and the HTC Vive Pro. We use a novel experimental protocol to compare the spectral composition between conditions with and without an HMD present during an eyes-open vs. eyes-closed task. We found general artifacts at the line hum of 50 Hz, and additional HMD refresh rate artifacts (90 Hz) for the Oculus rift exclusively. Frequency components typically most interesting to non-invasive EEG research and applications , however, remained largely unaffected. We observed similar topographies of visually-induced modulation of alpha band power for both HMD conditions in all subjects. Hence, the study introduces a necessary validation test for HMDs in combination with EEG and further promotes EEG as a potential biometric measurement method for psychophysical effects in VR systems.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8798369,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798369,,Electroencephalography;Frequency measurement;Resists;Electrodes;Virtual reality;Task analysis;Physiology,electroencephalography;helmet mounted displays;medical signal processing;neurophysiology;virtual reality,signal quality;addHMD refresh rate artifacts;biometric measurement method;EEG-VR setup;head-mounted displays;HTC Vive Pro;Oculus Rift;EEG signal;Virtual Reality systems;electroencephalogram;high-resolution EEG;brain activity;spectral composition;frequency 50.0 Hz;frequency 90.0 Hz,,1,,9,,15-Aug-19,,,IEEE,IEEE Conferences
BlenderVR: Open-source framework for interactive and immersive VR,B. F. G. Katz; D. Q. Felinto; D. Touraine; D. Poirier-Quinot; P. Bourdot,"LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France; LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France; LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France; LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France; LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France",2015 IEEE Virtual Reality (VR),27-Aug-15,2015,,,203,204,"BlenderVR is an open-source project framework for interactive and immersive applications based on an extension of the Blender Game Engine to Virtual Reality applications. BlenderVR is a generalization of the BlenderCAVE project, accounting for alternate platforms (e.g., HMD, video-walls). The goal is to provide a flexible and easy to use framework for the creation of VR applications for various platforms, making use of the existing power of the BGE's graphics rendering and physics engine. Compatible with 3 major Operating Systems, BlenderVR has been developed by VR researchers with support from the Blender Community. BlenderVR currently handles multi-screen/multi-user tracked stereoscopic rendering through efficient low-level master/slave synchronization process with multimodal interactions via OSC and VRPN protocols.",2375-5334,978-1-4799-1727-3,10.1109/VR.2015.7223366,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223366,"H.5.1 [Multimedia Information Systems]: Artificial, augmented, and virtual realities;I.3.2 [Graphics Systems]: Distributed/network graphics",Rendering (computer graphics);Synchronization;Virtual reality;Engines;Games;Navigation,protocols;public domain software;rendering (computer graphics);synchronisation;virtual reality,BlenderVR;virtual reality;open-source framework;interactive application;immersive application;Blender game engine;graphics rendering;physics engine;synchronization process;OSC protocol;VRPN protocol,,5,,8,,27-Aug-15,,,IEEE,IEEE Conferences
Estimating the motion-to-photon latency in head mounted displays,J. Zhao; R. S. Allison; M. Vinnikov; S. Jennings,"Department of Electrical Engineering and Computer Science, York University, Canada; Department of Electrical Engineering and Computer Science, York University, Canada; Flight Research Laboratory, National Research Council, Canada; Flight Research Laboratory, National Research Council, Canada",2017 IEEE Virtual Reality (VR),6-Apr-17,2017,,,313,314,"We present a method for estimating the Motion-to-Photon (End-to-End) latency of head mounted displays (HMDs). The specific HMD evaluated in our study was the Oculus Rift DK2, but the procedure is general. We mounted the HMD on a pendulum to introduce damped sinusoidal motion to the HMD during the pendulum swing. The latency was estimated by calculating the phase shift between the captured signals of the physical motion of the HMD and a motion-dependent gradient stimulus rendered on the display. We used the proposed method to estimate both rotational and translational Motion-to-Photon latencies of the Oculus Rift DK2.",2375-5334,978-1-5090-6647-6,10.1109/VR.2017.7892302,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892302,Motion-to-Photon Latency;End-to-End Latency;Head-Mounted Displays,Resists;Potentiometers;Photodiodes;Virtual reality;Cameras;Estimation;Frequency-domain analysis,helmet mounted displays;human computer interaction;virtual reality,head mounted displays;HMD;Oculus Rift DK2;pendulum;damped sinusoidal motion;phase shift;motion-dependent gradient stimulus;translational motion-to-photon latencies;rotational motion-to-photon latencies;virtual reality,,18,,6,,6-Apr-17,,,IEEE,IEEE Conferences
Simple augmented reality system for 3D ultrasonic image by see-through HMD and single camera and marker combination,S. Tano; K. Suzuki; K. Miki; N. Watanabe; M. Iwata; T. Hashiyama; J. Ichino; K. Nakayama,"University of Electro-Communications, Chofu-shi, Tokyo, 182-8585 JAPAN; University of Electro-Communications, Chofu-shi, Tokyo, 182-8585 JAPAN; Showa General Hospital, Kodaira-shi, Tokyo, 187-8510 JAPAN; University of Electro-Communications, Chofu-shi, Tokyo, 182-8585 JAPAN; Tokyo Metropolitan College of Industrial Technology, Shinagawa-ku, 140-0011, JAPAN; University of Electro-Communications, Chofu-shi, Tokyo, 182-8585 JAPAN; University of Electro-Communications, Chofu-shi, Tokyo, 182-8585 JAPAN; University of Electro-Communications, Chofu-shi, Tokyo, 182-8585 JAPAN",Proceedings of 2012 IEEE-EMBS International Conference on Biomedical and Health Informatics,7-Jun-12,2012,,,464,467,"Thanks to the rapid progress of ICT, significant progress has been made in both the ‚Äúgeneration‚Äù and ‚Äúdisplay‚Äù of the advanced medical information. However, serious problems still remain in both the ‚Äúgeneration‚Äù and ‚Äúdisplay‚Äù. Therefore, we propose a simple augmented reality system that can display an ultrasonic image of exactly the same plane in the body of the patient that a doctor is looking at. The key idea is to utilize the fact that an ultrasonic probe moves inside the doctor's field of view and within the accessible range of the arm in order to simplify the augmented reality system. The prototype has been developed using only a see-through HMD and single camera and marker combination. Three simple interaction methods compensate for the limitations in 3D position sensing. We worked with a medical doctor to test the prototype system and found it to be effective.",2168-2208,978-1-4577-2177-9,10.1109/BHI.2012.6211617,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6211617,,,augmented reality;biomedical ultrasonics;cameras;helmet mounted displays;medical image processing;medical information systems,augmented reality system;3D ultrasonic image;see-through HMD;ICT;medical information display;medical information generation;ultrasonic probe;interaction methods;3D position sensing;medical doctor;single camera-marker combination;information and communication technology;head mounted display,,2,,12,,7-Jun-12,,,IEEE,IEEE Conferences
NASA Telexploration Project demo,J. Norris; S. Davidoff,NASA Jet Propulsion Laboratory; NASA Jet Propulsion Laboratory,2014 IEEE Virtual Reality (VR),24-Apr-14,2014,,,183,184,"NASA's Telexploration Project seeks to make us better explorers by building immersive environments that feel like we are really there. The Mission Operations Innovation Office and its Operations Laboratory at the NASA Jet Propulsion Laboratory (JPL) founded the Telexploration Project, and is researching how immersive visualization and natural human-robot interaction can enable mission scientists, engineers, and the general public to interact with NASA spacecraft and alien environments in a more effective way. These efforts have been accelerated through partnerships with many different companies, especially in the video game industry. These demos will exhibit some of the progress made at NASA and its commercial partnerships by allowing attendees to experience Mars data acquired from NASA spacecraft in a head mounted display using several rendering and interaction techniques.",2375-5334,978-1-4799-2871-2,10.1109/VR.2014.6802112,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802112,virtual reality;space exploration;robotics,NASA;Mars;Laboratories;Propulsion;Robots;Three-dimensional displays;Space vehicles,astronomy computing;data visualisation;helmet mounted displays;human-robot interaction;Mars;rendering (computer graphics);virtual reality,NASA Telexploration Project demo;immersive environment;Mission Operations Innovation Office;Operations Laboratory;NASA Jet Propulsion Laboratory;NASA JPL;immersive visualization;natural human-robot interaction;mission science;mission engineering;NASA spacecraft;alien environment;Mars data;head mounted display;rendering technique;interaction technique,,3,,,,24-Apr-14,,,IEEE,IEEE Conferences
Interactive Modeling of Trees using VR Devices,Z. Liu; C. Shen; Z. Li; T. Weng; O. Deussen; Z. Cheng; D. Wang,"Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",2019 International Conference on Virtual Reality and Visualization (ICVRV),6-Oct-20,2019,,,69,75,"Conventional interactive 3D tree modeling systems are generally based on 2D input devices, and it's not convenient to generate desired 3D tree shape from 2D inputs due to the complexity of 3D tree structures. In this paper, we present a system for modeling trees interactively using a 3D gesture-based VR platform. The system contains a head-mounted display (HMD) and a 6-DOF motion controller for interaction. We propose an improved procedural modeling method to generate trees faster for VR platform. Using the 6-DOF motion controller, users can manipulate tree structures by a set of 3D interactive operations, including geometric editing using 3D gestures, sketching, brushing and silhouette-guided growth. Our interactions are more flexible and convenient than using traditional 2D input devices, e.g., we allow the user to simultaneously rotate and translate parts of a tree using a 3D gesture.",2375-141X,978-1-7281-4752-9,10.1109/ICVRV47840.2019.00020,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9212896,Human-centered computing-Human computer interaction (HCI)-Interaction paradigms-Virtual reality;Computing methodologies-Computer graphics-Shape modeling,Three-dimensional displays;Vegetation;Solid modeling;Two dimensional displays;Computational modeling;Input devices;Skeleton,geometry;gesture recognition;helmet mounted displays;interactive systems;solid modelling;virtual reality,interactive modeling;VR devices;tree structures;3D gesture-based VR platform;head-mounted display;3D interactive operations;2D input devices;interactive 3D tree modeling systems;geometric editing,,,,25,,6-Oct-20,,,IEEE,IEEE Conferences
A Gas Turbine Virtual Reality Application Migration to Mixed Reality: Development Experience,H. Sulaiman; A. M. Yusof; N. Ibrahim; R. A. Latif,"Universiti Tenaga Nasional,Department of Informatics,Malaysia; Universiti Tenaga Nasional,Department of Informatics,Malaysia; Universiti Tenaga Nasional,Institute of Informatics and Computing in Energy,Malaysia; Universiti Tenaga Nasional,Department of Informatics,Malaysia",2020 IEEE Graphics and Multimedia (GAME),15-Jan-21,2020,,,19,24,"This paper discusses several technical issues and difficulties faced while converting a Gas Turbine Virtual Reality (VR) application to a Mixed Reality (MR) application. Direct conversion from a VR to MR is feasible. However, it is found that several techniques or methods employed in VR are ineffective in MR. This is due to the Head Mounted Device used in the MR application allows users to see the real world while visualising computer-generated image, whereby the same function is not applicable in VR. Among the functions in VR which are not compatible with MR are teleporting and interaction. These issues were discovered during a prototype testing of the MR system. Based on the observation, it is found that in an MR system, the view inside HMD is overcrowded when a virtual background is visible along with the actual background. In addition to that, in an MR system, users prefer to physically walk towards the virtual object rather than teleporting using a controller. The discussion is not only highlighting the problem faced but also the solutions. In general, the objective of this paper is to share the technical issues experienced during the development process. It is expected that this knowledge can be helpful to future researchers or developers.",,978-1-7281-9244-4,10.1109/GAME50158.2020.9315123,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9315123,Virtual Reality (VR);Mixed Reality (MR);teleportation;interaction,Virtual reality;Turbines;Three-dimensional displays;Real-time systems;Solids;Navigation;Mixed reality,data visualisation;gas turbines;helmet mounted displays;mechanical engineering computing;mobile computing;virtual reality;wearable computers,mixed reality application;head mounted device;virtual background;gas turbine virtual reality application;computer generated image visualisation;VR device;mobile devices,,,,10,,15-Jan-21,,,IEEE,IEEE Conferences
Validation of the MR Simulation Approach for Evaluating the Effects of Immersion on Visual Analysis of Volume Data,B. Laha; D. A. Bowman; J. D. Schiffbauer,"Center for Human-Computer Interaction and the Department of Computer Science, Virginia Tech; Center for Human-Computer Interaction and the Department of Computer Science, Virginia Tech; Department of Geological Sciences, University of Missouri, Columbia, MO",IEEE Transactions on Visualization and Computer Graphics,13-Mar-13,2013,19,4,529,538,"In our research agenda to study the effects of immersion (level of fidelity) on various tasks in virtual reality (VR) systems, we have found that the most generalizable findings come not from direct comparisons of different technologies, but from controlled simulations of those technologies. We call this the mixed reality (MR) simulation approach. However, the validity of MR simulation, especially when different simulator platforms are used, can be questioned. In this paper, we report the results of an experiment examining the effects of field of regard (FOR) and head tracking on the analysis of volume visualized micro-CT datasets, and compare them with those from a previous study. The original study used a CAVE-like display as the MR simulator platform, while the present study used a high-end head-mounted display (HMD). Out of the 24 combinations of system characteristics and tasks tested on the two platforms, we found that the results produced by the two different MR simulators were similar in 20 cases. However, only one of the significant effects found in the original experiment for quantitative tasks was reproduced in the present study. Our observations provide evidence both for and against the validity of MR simulation, and give insight into the differences caused by different MR simulator platforms. The present experiment also examined new conditions not present in the original study, and produced new significant results, which confirm and extend previous existing knowledge on the effects of FOR and head tracking. We provide design guidelines for choosing display systems that can improve the effectiveness of volume visualization applications.",1941-0506,,10.1109/TVCG.2013.43,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479179,MR simulator;immersion;micro-CT;volume visualization;virtual reality;3D visualization;HMD;virtual environments.,Virtual reality;Visualization;Mice;Solid modeling;Head;Training;Computational modeling,data analysis;data visualisation;digital simulation;helmet mounted displays;virtual reality,MR simulation approach;immersion effects;visual volume data analysis;virtual reality systems;VR;mixed reality simulation approach;field of regard;FOR;head tracking;volume visualized microCT datasets;CAVE-like display;MR simulator platform;high-end head-mounted display;HMD;display systems;volume visualization applications,"Adolescent;Adult;Computer Graphics;Cues;Equipment Design;Equipment Failure Analysis;Female;Humans;Imaging, Three-Dimensional;Imaging, Three-Dimensional;Male;Task Performance and Analysis;Tomography, X-Ray Computed;User-Computer Interface;Visual Perception;Young Adult",15,,31,,13-Mar-13,,,IEEE,IEEE Journals
VR Dodge-ball: Application of Real-time Gesture Detection from Wearables to ExerGaming,S. Ishii; M. Luimula; A. Yokokubo; G. Lopez,"Aoyama Gakuin University 5-10-1 Fuchinobe,Chuo-ku, Sagamihara-shi, Kanagawa,Japan; Turku University of Applied Sciences Joukahaisenkatu 3C,Turku,Finland,20520; Aoyama Gakuin University 5-10-1 Fuchinobe,Chuo-ku, Sagamihara-shi, Kanagawa,Japan; Aoyama Gakuin University 5-10-1 Fuchinobe,Chuo-ku, Sagamihara-shi, Kanagawa,Japan",2020 11th IEEE International Conference on Cognitive Infocommunications (CogInfoCom),2-Nov-20,2020,,,81,82,"Wearable technologies are applied to various areas nowadays, including health care and physical training. In previous work, we developed ExerSense, an algorithm to segment, classify, and count different predefined motions in real-time using correlation of acceleration. Using ExerSense, we developed a Virtual Reality (VR) Dodge-ball game. A watch-like wearable device is mounted to the right wrist and connected wireless to a head-mounted display (HMD). ExerSense enables to recognize real-time ball throwing gesture. Dodging opponent's ball in 3-Dimensional virtual space is detected using the sensors embedded in the HMD. We found that wearable devices have an advantage for virtual exergames against the camera-based approaches: there is no space and place limitation. Additionally, the study shows that exergames could be implemented with only general usage devices.",2380-7350,978-1-7281-8213-1,10.1109/CogInfoCom50765.2020.9237824,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237824,,Wrist;Wireless communication;Wireless sensor networks;Wearable computers;Resists;Virtual reality;Real-time systems,computer games;gesture recognition;helmet mounted displays;human computer interaction;mobile computing;motion sensors;pattern classification;real-time systems;sensor fusion;virtual reality;wearable computers,health care;physical training;ExerSense;motion segmentation;head mounted display;wearable devices;virtual exergames;3-dimensional virtual space;virtual reality dodge ball game;real time gesture detection;VR Dodge ball;motion classification;gesture recognition;embedded sensors,,,,8,,2-Nov-20,,,IEEE,IEEE Conferences
Robust optical see-through head-mounted display calibration: Taking anisotropic nature of user interaction errors into account,E. Azimi; L. Qian; P. Kazanzides; N. Navab,"Johns Hopkins Univ., USA; Johns Hopkins Univ., USA; Johns Hopkins Univ., USA; Johns Hopkins Univ., USA, TU M√ºnchen, Germany",2017 IEEE Virtual Reality (VR),6-Apr-17,2017,,,219,220,"Uncertainty in measurement of point correspondences negatively affects the accuracy and precision in the calibration of head-mounted displays (HMD). In general, the distribution of alignment errors for optical see-through calibration are not isotropic, and one can estimate its distribution based on interaction requirements of a given calibration process and the user's measurable head motion and hand-eye coordination characteristics. Current calibration methods, however, mostly utilize the Direct Linear Transformation (DLT) method which minimizes Euclidean distances for HMD projection matrix estimation, disregarding the anisotropicity in the alignment errors. We utilize the error covariance in order to take the anisotropic nature of error distribution into account. The main hypothesis of this study is that using Mahalonobis distance within the nonlinear optimization can improve the accuracy of the HMD calibration. The simulation results indicate that our new method outperforms the standard DLT method both in accuracy and precision, and is more robust against user alignment errors. To the best of our knowledge, this is the first time that anisotropic noise has been accommodated in the optical see-through HMD calibration.",2375-5334,978-1-5090-6647-6,10.1109/VR.2017.7892255,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892255,augmented reality;HMD;calibration;error propagation;Mahalonobis distance,Calibration;Resists;Robustness;Adaptive optics;Nonlinear optics;Standards;Uncertainty,augmented reality;calibration;helmet mounted displays;matrix algebra;nonlinear programming;user interfaces,robust optical see-through head-mounted display calibration;user interaction errors;augmented reality;point correspondence measurement;alignment error distribution;user measurable head motion;hand-eye coordination characteristics;direct linear transformation method;Euclidean distances;HMD projection matrix estimation;alignment error anisotropicity;error covariance;Mahalonobis distance;nonlinear optimization;standard DLT method;anisotropic noise,,5,,4,,6-Apr-17,,,IEEE,IEEE Conferences
A Non-Stationary Office Desk Substitution for Desk-Based and HMD-Projected Virtual Reality,D. Zielasko; B. Weyers; T. W. Kuhlen,"Visual Computing Institute, RWTH Aachen University, JARA-HPC, Aachen, Germany; University of Trier, Germany; Visual Computing Institute, RWTH Aachen University, JARA-HPC, Aachen, Germany",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,1884,1889,"The ongoing migration of HMDs to the consumer market also allows the integration of immersive environments into analysis workflows that are often bound to an (office) desk. However, a critical factor when considering VR solutions for professional applications is the prevention of cybersickness. In the given scenario the user is usually seated and the surrounding real world environment is very dominant, where the most dominant part is maybe the desk itself. Including this desk in the virtual environment could serve as a resting frame and thus reduce cybersickness next to a lot of further possibilities. In this work, we evaluate the feasibility of a substitution like this in the context of a visual data analysis task involving travel, and measure the impact on cybersickness as well as the general task performance and presence. In the conducted user study ( n=52), surprisingly, and partially in contradiction to existing work, we found no significant differences for those core measures between the control condition without a virtual table and the condition containing a virtual table. However, the results also support the inclusion of a virtual table in desk-based use cases.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8797837,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797837,Human-centered concepts [Human computer interaction (HCI)]: Interaction paradigms‚ÄîVirtual reality;Human-centered concepts [Human computer interaction (HCI)]: Visualization‚ÄîEmpirical studies in visualization,Task analysis;Data analysis;Virtual environments;Data visualization;Visualization;Three-dimensional displays,data analysis;helmet mounted displays;user interfaces;virtual reality,nonstationary office desk substitution;HMD-projected virtual reality;consumer market;VR solutions;professional applications;cybersickness;virtual environment;visual data analysis task;virtual table;desk-based use cases,,1,,32,,15-Aug-19,,,IEEE,IEEE Conferences
An intelligent and modular sensing system for Augmented Reality application,M. F. Alam; S. Katsikas; S. Hadjiefthymiades,"Pervasive Computing Research, Dept. of Informatics and Telecommunications, National Kapodistrain University of Athens, Greece; Research and Development Electronics, Informatics and Telecommunications, Prisma Electronics SA, Athens, Greece; Pervasive Computing Research, Dept. of Informatics and Telecommunications, National Kapodistrian University of Athens, Greece",2015 9th International Conference on Sensing Technology (ICST),24-Mar-16,2015,,,850,855,"The scientific objective of this paper is to describe an innovative architecture of modular form in sensing and supervision system. In our study, a maintenance work at ATLAS detector in Large Hadron Collider at European Organization for Nuclear Research (CERN), Geneva, Switzerland has been considered. The research challenges lie in the development of real-time data-transmission, instantaneous analysis of data coming from different inputs, local intelligences in low power embedded system, interaction with augmented reality in multiple on-site users, complex interfaces, and portability. The proposed architecture is allocated with modular form. The prototype of this modular device is named a PSS (Personnel Supervision System) module. The hardware of the modular system includes with many sensor modules, cameras, IMU (Inertial Measurement Unit) sensors, processors, Wi-Fi module, laser, LED light plus its associated software. The mobile PSS module is responsible for local data processing for various sensors, image processing, 3D pose estimation, audio data acquisition, visualization and wireless interfaced devices. The advantage of modular concept is that it can work independently or together. The Head Mounted Display (HMD) includes HW and SW to communicate the augmented reality content to the user and to display visual information on a worker's field of view (FOV). The module serves as a supervision post, providing sensor data, video and audio stream to the supervisor. It stores data and provide the means for the supervisor to easily communicate and instruct the worker. It decides, selects and serves the AR (Augmented) content on multiple PTUs, automatically or with minor supervisor intervention. The development of this system to be compatible with a wearable use in a highly challenging environment presents an excellent opportunity to integrate today's leading technical knowledge in a product which can become accessible to industry and general public. This study is a part of the EDUSAFE project, a Marie Curie ITN project focusing on research into the use of Virtual and Augmented Reality (VR/AR) during planned and emergency maintenance in extreme environments.",2156-8073,978-1-4799-6314-0,10.1109/ICSensT.2015.7438515,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7438515,Modular system;Sensors;Augmented Reality;Supervision,Temperature sensors;Program processors;Pins;Augmented reality;Cameras,augmented reality;helmet mounted displays;intelligent sensors,intelligent sensing system;modular sensing system;augmented reality application;head mounted display;personnel supervision system module,,,,26,,24-Mar-16,,,IEEE,IEEE Conferences
Estimating Gaze Depth Using Multi-Layer Perceptron,Y. Lee; C. Shin; A. Plopski; Y. Itoh; T. Piumsomboon; A. Dey; G. Lee; S. Kim; M. Billinghurst,"Empathic Comput. Lab., Univ. of South Australia, Adelaide, SA, Australia; VR/AR Res. Center, KETI, South Korea; Interactive Media Design Lab., NAIST, Japan; Interactive Media Lab., Keio Univ., Yokohama, Japan; Empathic Comput. Lab., Univ. of South Australia, Adelaide, SA, Australia; Empathic Comput. Lab., Univ. of South Australia, Adelaide, SA, Australia; Empathic Comput. Lab., Univ. of South Australia, Adelaide, SA, Australia; Empathic Comput. Lab., Univ. of South Australia, Adelaide, SA, Australia; Empathic Comput. Lab., Univ. of South Australia, Adelaide, SA, Australia",2017 International Symposium on Ubiquitous Virtual Reality (ISUVR),24-Jul-17,2017,,,26,29,"In this paper we describe a new method for determining gaze depth in a head mounted eye-tracker. Eye-trackers are being incorporated into head mounted displays (HMDs), and eye-gaze is being used for interaction in Virtual and Augmented Reality. For some interaction methods, it is important to accurately measure the x-and y-direction of the eye-gaze and especially the focal depth information. Generally, eye tracking technology has a high accuracy in x-and y-directions, but not in depth. We used a binocular gaze tracker with two eye cameras, and the gaze vector was input to an MLP neural network for training and estimation. For the performance evaluation, data was obtained from 13 people gazing at fixed points at distances from 1m to 5m. The gaze classification into fixed distances produced an average classification error of nearly 10%, and an average error distance of 0.42m. This is sufficient for some Augmented Reality applications, but more research is needed to provide an estimate of a user's gaze moving in continuous space.",,978-1-5386-3091-4,10.1109/ISUVR.2017.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7988648,Eye-gaze;3D gaze;Machine Learning;Augmented Reality;Head-mounted display,Three-dimensional displays;Meters;Cameras;Training;Error analysis;Resists;Calibration,augmented reality;cameras;gaze tracking;helmet mounted displays;image classification;learning (artificial intelligence);multilayer perceptrons,gaze depth;head mounted eye-tracker;head mounted displays;virtual reality;augmented reality;focal depth information;eye tracking technology;binocular gaze tracker;eye cameras;gaze vector;MLP neural network;training;performance evaluation;gaze classification;fixed distances;fixed points;average classification error;gaze depth estimation;multilayer perceptron,,4,,23,,24-Jul-17,,,IEEE,IEEE Conferences
An In-Depth Exploration of the Effect of 2D/3D Views and Controller Types on First Person Shooter Games in Virtual Reality,D. Monteiro; H. -N. Liang; J. Wang; H. Chen; N. Baghaei,Xi‚Äôan Jiaotong-Liverpool University; Xi‚Äôan Jiaotong-Liverpool University; Xi‚Äôan Jiaotong-Liverpool University; Xi‚Äôan Jiaotong-Liverpool University; Massey University,2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),14-Dec-20,2020,,,713,724,"The amount of interest in Virtual Reality (VR) research has significantly increased over the past few years, both in academia and industry. The release of commercial VR Head-Mounted Displays (HMDs) has been a major contributing factor. However, there is still much to be learned, especially how views and input techniques, as well as their interaction, affect the VR experience. There is little work done on First-Person Shooter (FPS) games in VR, and those few studies have focused on a single aspect of VR FPS. They either focused on the view, e.g., comparing VR to a typical 2D display or on the controller types. To the best of our knowledge, there are no studies investigating variations of 2D/3D views in HMDs, controller types, and their interactions. As such, it is challenging to distinguish findings related to the controller type from those related to the view. If a study does not control for the input method and finds that 2D displays lead to higher performance than VR, we cannot generalize the results because of the confounding variables. To understand their interaction, we propose to analyze in more depth, whether it is the view (2D vs. 3D) or the way it is controlled that gives the platforms their respective advantages. To study the effects of the 2D/3D views, we created a 2D visual technique, PlaneFrame, that was applied inside the VR headset. Our results show that the controller type can have a significant positive impact on performance, immersion, and simulator sickness when associated with a 2D view. They further our understanding of the interactions that controllers and views have and demonstrate that comparisons are highly dependent on how both factors go together. Further, through a series of three experiments, we developed a technique that can lead to a substantial performance, a good level of immersion, and can minimize the level of simulator sickness.",1554-7868,978-1-7281-8508-8,10.1109/ISMAR50242.2020.00102,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284718,Virtual Reality;2D/3D Views;Controller types;First Person Shooter;Gaming;Head-Mounted Displays,Performance evaluation;Visualization;Three-dimensional displays;Two dimensional displays;Keyboards;Games;Turning,computer games;data visualisation;helmet mounted displays;virtual reality,virtual reality;input techniques;VR experience;VR FPS;typical 2D display;controller type;2D visual technique;VR headset;first person shooter games;commercial VR head-mounted displays;2D-3D views;PlaneFrame,,,,54,,14-Dec-20,,,IEEE,IEEE Conferences
The temporal limits of agency for reaching movements in augmented virtuality,G. Bernal; P. Maes; O. A. Kannape,"MIT Media Lab, Massachusetts Institute of Technology, Cambridge, USA; MIT Media Lab, Massachusetts Institute of Technology, Cambridge, USA; School of Psychology, University of Central Lancashire, Preston, UK","2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",9-Feb-17,2016,,,2896,2899,"The sense of agency (SoA) describes the feeling of being the author and in control of one's movements. It is closely linked to automated aspects of sensorimotor control and understood to depend on one's ability to monitor the details of one's movements. As such SoA has been argued to be a critical component of self-awareness in general and contribute to presence in virtual reality environments in particular. A common approach to investigating SoA is to ask participants to perform goal-directed movements and introducing spatial or temporal visuomotor mismatches in the feedback. Feedback movements are traditionally either switched with someone else's movements using a 2D video-feed or modified by providing abstracted feedback about one's actions on a computer screen. The aim of the current study was to quantify conscious monitoring and the SoA for ecologically valid, three dimensional feedback of the participants' actual limb and movements. This was achieved by displaying an Infra-Red (IR) feed of the participants' upper limbs in an augmented virtuality environment (AVE) using a head-mounted display (HMD). Movements could be fed back in real-time (46ms system delay) or with an experimental delay of up to 570ms. As hypothesized, participant's SoA decreased with increasing temporal visuomotor mismatches (p<;.001), replicating previous findings and extending them to AVEs. In-line with this literature, we report temporal limits of 222¬±60ms (50% psychometric threshold) in N=28 participants. Our results demonstrate the validity of the experimental platform by replicating studies in SoA both qualitatively and quantitatively. We discuss our findings in relation to the use of virtual and mixed reality in research and implications for neurorehabilitation therapies.",,978-1-5090-1897-0,10.1109/SMC.2016.7844679,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7844679,augmented virtuality;sense of agency;presence;sensory integration;movement feedback;motion capture,Delays;Visualization;Feeds;Real-time systems;Training;Conferences;Cybernetics,augmented reality;helmet mounted displays;human computer interaction,temporal agency limits;SoA;sense of agency;infrared feed;IR feed;augmented virtuality environment;head-mounted display;temporal visuomotor mismatches;mixed reality;HMD;AVE,,1,,19,,9-Feb-17,,,IEEE,IEEE Conferences
Assessing Knowledge Retention of an Immersive Serious Game vs. a Traditional Education Method in Aviation Safety,L. Chittaro; F. Buttussi,"Department of Mathematics and Computer Science, Human-Computer Interaction Lab, Italy; Department of Mathematics and Computer Science, Human-Computer Interaction Lab, Italy",IEEE Transactions on Visualization and Computer Graphics,23-Mar-15,2015,21,4,529,538,"Thanks to the increasing availability of consumer head-mounted displays, educational applications of immersive VR could now reach to the general public, especially if they include gaming elements (immersive serious games). Safety education of citizens could be a particularly promising domain for immersive serious games, because people tend not to pay attention to and benefit from current safety materials. In this paper, we propose an HMD-based immersive game for educating passengers about aviation safety that allows players to experience a serious aircraft emergency with the goal of surviving it. We compare the proposed approach to a traditional aviation safety education method (the safety card) used by airlines. Unlike most studies of VR for safety knowledge acquisition, we do not focus only on assessing learning immediately after the experience but we extend our attention to knowledge retention over a longer time span. This is a fundamental requirement, because people need to retain safety procedures in order to apply them when faced with danger. A knowledge test administered before, immediately after and one week after the experimental condition showed that the immersive serious game was superior to the safety card. Moreover, subjective as well as physiological measurements employed in the study showed that the immersive serious game was more engaging and fear-arousing than the safety card, a factor that can contribute to explain the obtained superior retention, as we discuss in the paper.",1941-0506,,10.1109/TVCG.2015.2391853,Federal Aviation Administration (FAA); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7014255,Immersive VR;serious games;user evaluation;knowledge retention;physiological measurements;aviation safety;Immersive VR;serious games;user evaluation;knowledge retention;physiological measurements;aviation safety,Games;Safety;Aircraft;Education;Materials;Avatars;Engines,avionics;computer aided instruction;computer games;helmet mounted displays;virtual reality,knowledge retention;consumer head-mounted displays;educational applications;immersive VR;gaming elements;immersive serious games;safety materials;HMD-based immersive game;aircraft emergency;aviation safety education method;airlines;safety knowledge acquisition;safety procedures;knowledge test;safety card;physiological measurements;superior retention,"Accidents, Aviation;Aviation;Computer Graphics;Humans;User-Computer Interface;Video Games",99,,59,,19-Jan-15,,,IEEE,IEEE Journals
Airborne navigation with onboard InfraRed Sensors,G. Colombi; A. Ondini; L. Fortunato; G. Balzarotti,"Skyward IPT - Selex Galileo, Viale Europa snc 20014 Nerviano (MI) - Italy; Skyward IPT - Selex Galileo, Viale Europa snc 20014 Nerviano (MI) - Italy; Skyward IPT - Selex Galileo, Viale Europa snc 20014 Nerviano (MI) - Italy; Skyward IPT - Selex Galileo, Viale Europa snc 20014 Nerviano (MI) - Italy",2012 13th International Workshop on Cellular Nanoscale Networks and their Applications,18-Oct-12,2012,,,1,6,"Infrared Sensors are widely used nowadays on Aircrafts (rotary and fixed wing) to help pilot's activities. The infrared information of the surrounding area are used mainly for two different purposes: Navigation and Search & Track-While-Scan. Navigation functions, commonly identified with the name of Imaging Modes, are devoted to aid pilots in conjunction with advanced human machine interfaces such as Head Up Display (HUD) and Helmet Mounted Display (HMD). The availability of IR images generated from airborne opto-electronics equipment can support the pilot during navigation in adverse weather conditions, providing important information about external threats (i.e. obstacles), otherwise not detectable by human eye. Search & Track-While-Scan, is a functionality related to surveillance. It includes combination of automatic detection and tracking functions within a wide search volume. These features are typically executed in automatic way and generate the position of possible threats present in the flight path. In general Search & Track-While-Scan outputs are not displayed together with the IR image because the main purpose is to provide the estimated positions of the detected targets; nevertheless, if the Imaging Modes and Tracking capabilities are operated simultaneously in an integrated framework, the overall scenario representation can be improved and the situation awareness increased. This paper will focus on the airborne navigation by means of Infrared Sensors by considering the benefits but also possible limits and areas of improvements.",2165-0152,978-1-4673-0289-0,10.1109/CNNA.2012.6331477,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6331477,,Sensors;Head;Humans;Image sensors;Navigation;Visualization;Magnetic heads,aircraft displays;aircraft navigation;human computer interaction;infrared imaging;object detection;optoelectronic devices;target tracking,airborne navigation;onboard infrared sensors;infrared information;navigation functions;imaging modes;human machine interfaces;IR images;airborne optoelectronics equipment;aircraft pilot;adverse weather conditions;external threats;search & track-while-scan;automatic detection;automatic tracking;threat position generation;flight path;target detection,,2,,7,,18-Oct-12,,,IEEE,IEEE Conferences
An Exoskeleton Type 4-DOF Force Feedback Device Using Magnetorheological Fluid Clutches and Artificial Muscles,Y. Onozuka; R. Suzuki; Y. Yamada; T. Nakamura; C. University,"Faculty of Science and Engineering, Department of Precision Mechanics, Chuo University, 1-13-27 Kasuga, Bunkyo-ku, Tokyo, 112-8551, Japan; Faculty of Science and Engineering, Department of Precision Mechanics, Chuo University, 1-13-27 Kasuga, Bunkyo-ku, Tokyo, 112-8551, Japan; Faculty of Science and Engineering, Department of Precision Mechanics, Chuo University, 1-13-27 Kasuga, Bunkyo-ku, Tokyo, 112-8551, Japan; Faculty of Science and Engineering, Department of Precision Mechanics, Chuo University, 1-13-27 Kasuga, Bunkyo-ku, Tokyo, 112-8551, Japan; Faculty of Science and Engineering, Department of Precision Mechanics, Chuo University, 1-13-27 Kasuga, Bunkyo-ku, Tokyo, 112-8551, Japan",2018 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM),2-Sep-18,2018,,,869,874,"Recently, virtual reality (VR) technology has been developed using a head mounted displays (HMD). Users can recognize virtual objects easily in a VR space. However, users cannot obtain haptic perception, such as operating actual objects. There are force feedback devices that can render its perception. General devices are desktop types which restrict the range of motion (ROM) of operators, whereas exoskeleton types achieve ROM like a human. Many force feedback devices using motors and decelerators lead to a loss of backdrivability and can harm the operator by active force. Therefore, we developed an exoskeleton type four degrees of freedom (DOF) force feedback device for the upper limb with magnetorheological fluid clutches and artificial muscles that are backdrivable and safe actuators; we confirmed that the proposed device can render an elastic force.",2159-6255,978-1-5386-1854-7,10.1109/AIM.2018.8452696,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8452696,,Muscles;Force;Force feedback;Torque;Wires;Elasticity;Rendering (computer graphics),clutches;electroactive polymer actuators;force feedback;magnetorheology;pneumatic actuators;virtual reality;wearable robots,virtual reality technology;head mounted displays;upper limb;pneumatic artificial muscles;virtual objects;exoskeleton type 4-DOF force feedback device;elastic force;artificial muscles;magnetorheological fluid clutches;exoskeleton types,,2,,13,,2-Sep-18,,,IEEE,IEEE Conferences
Experience with head-mounted virtual reality (HMD-VR) predicts transfer of HMD-VR motor skills,J. M. Juliano; D. Saldana; A. Schmiesing; S. Liew,"University of Southern California (USC),Neuroscience Graduate Program,Los Angeles,CA,USA; University of Southern California,Chan Division of Occupational,Los Angeles,CA,USA; University of Southern California,Chan Division of Occupational,Los Angeles,CA,USA; University of Southern California,Chan Division of Occupational,Los Angeles,CA,USA",2019 International Conference on Virtual Rehabilitation (ICVR),13-Feb-20,2019,,,1,2,"Immersive, head-mounted virtual reality (HMD-VR) has the potential to be a useful tool for motor rehabilitation. However, when developing tools for rehabilitation, it is essential to design interventions that will be most effective for generalizing to the real world. Therefore, it is important to understand what factors facilitate transfer from HMD-VR to non-HMD-VR environments. Here we used a well-established test of skilled motor learning, the Sequential Visual Isometric Pinch Task (SVIPT), to train healthy individuals in an HMD-VR environment. We examined whether learned motor skills transferred to a more conventional (non-HMD-VR) environment and what factors facilitated transfer. Our results suggest that on average, learned motor skills from this task transfer from an immersive virtual environment to a conventional environment; however, some individuals did not transfer the learned motor skills. We then examined individual differences between those that did show transfer and those that did not. We found that individuals who had previous exposure to HMD-VR were more likely to transfer their learned motor skills than those who did not. Individual differences in previous exposure to HMD-VR environments prior to training may serve as a predictor to whether learned motor skills will transfer out of HMD-VR.",2331-9569,978-1-7281-1285-5,10.1109/ICVR46560.2019.8994345,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994345,head-mounted virtual reality;skilled motor learning;transfer,,biomechanics;helmet mounted displays;learning (artificial intelligence);patient rehabilitation;virtual reality,HMD-VR environment;learned motor skills;head-mounted virtual reality;HMD-VR motor skills;motor rehabilitation;nonHMD-VR environments;skilled motor learning;immersive virtual environment,,,,9,,13-Feb-20,,,IEEE,IEEE Conferences
Enactive Approach to Assess Perceived Speed Error during Walking and Running in Virtual Reality,T. Perrin; H. A. Kerherv√©; C. Faure; A. Sorel; B. Bideau; R. Kulpa,"Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France; Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France; Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France; Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France; Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France; Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),15-Aug-19,2019,,,622,629,"The recent development of virtual reality (VR) devices such as head mounted displays (HMDs) increases opportunities for applications at the confluence of physical activity and gaming. Recently, the fields of sport and fitness have turned to VR, including for locomotor activities, to enhance motor and energetic resources, as well as motivation and adherence. For example, VR can provide visual feedbacks during treadmill running, thereby reducing monotony and increasing the feeling of movement and engagement with the activity. However, the relevance of using VR tools during locomotion depends on the ability of these systems to provide natural immersive feelings, specifically a coherent perception of speed. The objective of this study is to estimate the error between actual and perceived locomotor speed in VE using an enactive approach, i.e. allowing an active control of the environment. Sixteen healthy individuals participated in the experiment, which consisted in walking and running on a motorized treadmill at speeds ranging from 3 to 11 km/h with 0.5 km/h increments, in a randomized order while wearing a HMD device (HTC Vive) displaying a virtual racetrack. Participants were instructed to match VE speed with what they perceived was their ac-tuallocomotion speed (LS), using a handheld Vive controller. They were able to modify the optic flow speed (OFS) with a 0.02 km/h increment/decrement accuracy. An optic flow multiplier (OFM) was computed based on the error between OFS and LS. It represents the gain that exists between the visually perceived speed and the real locomotion speed experienced by participants for each trial. For all conditions, the average of OFM was 1.00¬±.25 to best match LS. This finding is at odds with previous works reporting an underestimation of speed perception in VR. It could be explained by the use of an enactive approach allowing an active and accurate matching of visually and proprioceptively perceived speeds by participants. But above all, our study showed that the perception of speed in VR is strongly individual, with some participants always overestimating and others constantly underestimating. Therefore, a general OFM should not be used to correct speed in VE to ensure congruence in speed perception, and we propose the use of individual models as recommendations for setting up locomotion-based VR applications.",2642-5254,978-1-7281-1377-7,10.1109/VR.2019.8798209,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798209,Virtual reality;speed perception assessment;running in virtual environment;enaction;physical activity in VR,Legged locomotion;Adaptive optics;Resists;Optical feedback;Virtual environments;Visualization,gait analysis;helmet mounted displays;human factors;mechanoception;virtual reality,speed perception;visually perceived speeds;proprioceptively perceived speeds;locomotion-based VR applications;virtual reality devices;physical activity;locomotor activities;visual feedbacks;VR tools;natural immersive feelings;actual perceived locomotor speed;motorized treadmill;HMD device;virtual racetrack;VE speed;handheld Vive controller;optic flow speed;optic flow multiplier;visually perceived speed;locomotion speed;perceived speed error;velocity 0.5 km/h;velocity 0.02 km/h;velocity 3.0 km/h to 11.0 km/h,,,,35,,15-Aug-19,,,IEEE,IEEE Conferences
Elucidating Factors that can Facilitate Veridical Spatial Perception in Immersive Virtual Environments,W. B. Thompson; J. E. Swan; D. Proffitt; J. K. Kearney; V. Interrante; W. B. Thompson; J. E. Swan; D. Proffitt; J. K. Kearney; V. Interrante,"NA; NA; NA; NA; Minnesota Univ., MN; NA; NA; NA; NA; Minnesota Univ., MN",2007 IEEE Virtual Reality Conference,23-Apr-07,2007,,,11,18,"Enabling veridical spatial perception in immersive virtual environments (IVEs) is an important yet elusive goal, as even the factors implicated in the often-reported phenomenon of apparent distance compression in HMD-based IVEs have yet to be satisfactorily elucidated. In recent experiments (Interrante et al., 2006), we have found that participants appear less prone to significantly underestimate egocentric distances in HMD-based IVEs, relative to in the real world, in the special case that they unambiguously know, through first-hand observation, that the presented virtual environment is a high fidelity 3D model of their concurrently occupied real environment. We had hypothesized that this increased veridicality might be due to participants having a stronger sensation of 'presence' in the IVE under these conditions of co-location, which state of mind leads them to act on their visual input in the IVE similarly as they would in the real world (the presence hypothesis). However, alternative hypotheses are also possible. Primary among these is the visual calibration hypothesis: participants could be relying on metric information gleaned from their exposure to the real environment to calibrate their judgments of sizes and distances in the matched virtual environment. It is important to disambiguate between the presence and visual calibration hypotheses because they suggest different directions for efforts to facilitate veridical distance perception in general (non-co-located) IVEs. In this paper, we present the results of an experiment that seeks novel insight into this question. Using a mixed within- and between-subjects design, we compare participants' relative ability to accurately estimate egocentric distances in three different virtual environment models: one that is an identical match to the occupied real environment; one in which each of the walls in our virtual room model has been surreptitiously moved ~10% inward towards the center of the room; and one in which each of the walls has been surreptitiously moved ~10% outwards from the center of the room. If the visual calibration hypothesis holds, then we should expect to see a degradation in the accuracy of peoples' distance judgments in the surreptitiously modified models, manifested as an underestimation of distances when the IVE is actually larger than the real room and as an overestimation of distances when the IVE is smaller. However, what we found is that distances were significantly underestimated in the virtual environment relative to in the real world in each of the surreptitiously modified room environments, while remaining reasonably accurate (consistent with our previous findings) in the case of the faithfully size-matched room environment. In a post-test survey, participants in each of the three room size conditions reported equivalent subjective levels of presence and did not indicate any overt awareness of the room size manipulation",2375-5334,1-4244-0905-5,10.1109/VR.2007.352458,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4161000,egocentric distance perception;immersive virtual environments,Virtual environment;Calibration;Computer graphics;Displays;Computer science;Computer architecture;Degradation;Chromium;Virtual reality;USA Councils,augmented reality;computer graphics;visual perception,spatial perception;immersive virtual environments;human perception;3D spatial relationships;augmented reality;optical-motor information;ocular-motor information,,19,,13,,23-Apr-07,,,IEEE,IEEE Conferences
xR-EgoPose: Egocentric 3D Human Pose From an HMD Camera,D. Tome; P. Peluse; L. Agapito; H. Badino,UCL; Facebook; University College London; Facebook,2019 IEEE/CVF International Conference on Computer Vision (ICCV),27-Feb-20,2019,,,7727,7737,"We present a new solution to egocentric 3D body pose estimation from monocular images captured from a downward looking fish-eye camera installed on the rim of a head mounted virtual reality device. This unusual viewpoint, just 2 cm away from the user's face, leads to images with unique visual appearance, characterized by severe self-occlusions and strong perspective distortions that result in a drastic difference in resolution between lower and upper body. Our contribution is two-fold. Firstly, we propose a new encoder-decoder architecture with a novel dual branch decoder designed specifically to account for the varying uncertainty in the 2D joint locations. Our quantitative evaluation, both on synthetic and real-world datasets, shows that our strategy leads to substantial improvements in accuracy over state of the art egocentric pose estimation approaches. Our second contribution is a new large-scale photorealistic synthetic dataset - xR-EgoPose - offering 383K frames of high quality renderings ofpeople with a diversity of skin tones, body shapes, clothing, in a variety of backgrounds and lighting conditions, performing a range of actions. Our experiments show that the high variability in our new synthetic training corpus leads to good generalization to real world footage and to state of the art results on real world datasets with ground truth. Moreover, an evaluation on the Human3.6M benchmark shows that the performance of our method is on par with top performing approaches on the more classic problem of 3D human pose from a third person viewpoint.",2380-7504,978-1-7281-4803-8,10.1109/ICCV.2019.00782,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010983,,Three-dimensional displays;Cameras;Pose estimation;Two dimensional displays;Training;Resists;Uncertainty,cameras;helmet mounted displays;image capture;image motion analysis;image sensors;pose estimation;realistic images;rendering (computer graphics);solid modelling;video signal processing;virtual reality,xR-EgoPose;HMD camera;monocular images;fish-eye camera;unique visual appearance;encoder-decoder architecture;2D joint locations;large-scale photorealistic synthetic dataset;high quality renderings;head mounted virtual reality device;dual branch decoder design;egocentric 3D human body pose estimation,,3,,61,,27-Feb-20,,,IEEE,IEEE Conferences
A virtual reality-based multiplayer game using fine-grained localization,T. D. Schepper; B. Braem; S. Latre,"Department of Mathematics and Computer Science, University of Antwerp - iMinds, Belgium; Department of Mathematics and Computer Science, University of Antwerp - iMinds, Belgium; Department of Mathematics and Computer Science, University of Antwerp - iMinds, Belgium",2015 Global Information Infrastructure and Networking Symposium (GIIS),10-Dec-15,2015,,,1,6,"The popularity and availability of Head Mounted Displays (HMDs) has known an increase over the past few years. In general those devices need to be connected to a computer to function properly. Moreover, applications that project images on such an HMD respond typically only to user inputs like mouse and keyboard actions and head movement. In this paper we go a step further by proposing a framework in which the movements of a person are translated into actions in a virtual world. This allows a user to walk around freely while wearing an HMD, increasing the reality of the virtual experience. We will focus in detail on the challenges related to the localization of the user and discuss different options like existing wireless localization technologies, Bluetooth Low Energy (BLE) and an object recognition algorithm. The latter is used in the final solution. Furthermore, we present an experimental and mobile setup to use an HMD in a portable manner. Our solution is demonstrated through a multiplayer game, in which two players compete against each other to capture a flag.",,978-1-4673-7707-2,10.1109/GIIS.2015.7347176,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7347176,Virtual Reality;Multiplayer Game;Oculus Rift;Wireless Localization;Object Tracking,Wireless communication;Cameras;Mobile communication;Histograms;Games;Head;Computers,Bluetooth;computer games;helmet mounted displays;mobile computing;object recognition;portable computers;virtual reality,virtual reality-based multiplayer game;fine-grained localization;head mounted displays;HMD;project images;keyboard actions;mouse actions;head movement;virtual world;virtual experience;wireless localization technologies;Bluetooth Low Energy;BLE;object recognition algorithm;multiplayer game,,3,,23,,10-Dec-15,,,IEEE,IEEE Conferences
Virtual Eye: A sensor based mobile viewer to aid collaborative decision making in virtual environments,W. Ranaweera; R. Wickramarachchi; S. Jabbar; M. Weerasinghe; N. Gunathilake; C. Keppitiyagama; D. Sandaruwan; P. Samarasinghe,"School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka",International Conference on Advances in ICT for Emerging Regions (ICTer2012),31-Jan-13,2012,,,56,61,"Current virtual simulation techniques often include multi-user interactivity in virtual environments that can be controlled in real time. Such simulation techniques are mostly employed in virtual military training sessions and in real time gaming experiences, where users have to make more strategic decisions by analyzing the information they receive, in response to the actions of the other users in the same virtual environment. Generally, in the real world, collaborative decision making takes place when a team of people work together to control the behaviour of a single object which cannot be handled alone by an individual. A ship with its crew can be held as an example. When applying this scenario into virtually simulated environments, multiple users have to involve in representing a single object in the virtual world. These users need to obtain sufficient information about the activities in the environment that will contribute to the collaborative decision making process. Out of many sources, visual information is the most reliable source the users tend to depend on. The use of traditional static displays to obtain visual information limits the capability of providing a rich set of information about the 3D environment. Head Mounted Displays address these limitations while introducing several new problems. On the otherhand, our work is focused on exploring how smart devices can be employed by a collaboratively working team of users to obtain visual information to the level beyond which a static display provides, thus aiding the process of decision making. To serve the above purpose, we propose a solution, ‚ÄúVirtual Eye‚Äù, which uses a smart mobile device with the ability to view the visual output of the virtual world and the ability to control that view according to user's orientation changes and movements with the use of its inbuilt sensors.",,978-1-4673-5530-8,10.1109/ICTer.2012.6422831,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6422831,Virtual reality;collaborative decision making;mobile;sensors;streaming,Educational institutions;Mobile communication;Visualization;Servers;Communication channels;Optical reflection;Optical sensors,computer games;decision making;digital simulation;mobile computing;sensors;virtual reality,virtual eye;sensor based mobile viewer;aid collaborative decision making;virtual environments;virtual simulation techniques;multiuser interactivity;virtual military training sessions;virtual world;collaborative decision making process;visual information;head mounted displays;static display,,1,,13,,31-Jan-13,,,IEEE,IEEE Conferences
Toed-in vs Parallel Displays in Video See-Through Head-Mounted Displays for Close-Up View,N. Cattari; F. Cutolo; R. D‚Äôamato; U. Fontana; V. Ferrari,"Department of Translational Research and New Technologies in Medicine and Surgery, EndoCAS Centre, University of Pisa, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy; Department of Translational Research and New Technologies in Medicine and Surgery, EndoCAS Centre, University of Pisa, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy",IEEE Access,8-Nov-19,2019,7,,159698,159711,"In non-orthostereoscopic video see-through (VST) head-mounted displays (HMDs), the perception of the three-dimensional space is negatively altered by geometrical aberrations, which may lead to perceptual errors, problems of hand-eye coordination, and discomfort for the user. Parallax-free VST HMDs have been proposed, yet their embodiments are generally difficult to create. The present study investigates the guidelines for the development of non-orthostereoscopic VST HMDs capable of providing perceptually coherent augmentations for close-up views, hence specifically devoted to guide high-precision manual tasks. Our underlying rationale is that, under VST view, a perspective-preserving conversion of the camera frames is sufficient to restore the natural perception of the relative depths around a pre-defined working distance in non-orthostereoscopic VST HMDs. This perspective conversion needs to account for the geometry of the visor and the working distance. A simulation platform was designed to compare the on-image displacements between the direct view of the world and the perspective-corrected VST view, considering three different geometrical arrangements of cameras and displays. A user study with a custom-made VST HMD was then conducted to evaluate quantitatively and qualitatively which of the three configurations was the most effective in mitigating the impact of the geometrical aberrations around the reference distance. The results of the simulations and of the user study both proved that, in non-orthostereoscopic VST HMDs, display convergence can be prevented, as the perspective conversion of the camera frames is sufficient to restore the correct stereoscopic perception by the user in the peripersonal space.",2169-3536,,10.1109/ACCESS.2019.2950877,HORIZON2020 Project VOSTARS; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8888173,Head-mounted display;stereoscopic displays;augmented reality;video see-through displays;orthoscopic view;optical aberrations,Optical distortion;Cameras;Optical imaging;Nonlinear optics;Adaptive optics;Optical sensors;Resists,aberrations;augmented reality;cameras;helmet mounted displays;stereo image processing;three-dimensional displays;video cameras;visual perception,display convergence;custom-made VST HMD;cameras;perspective-corrected VST view;direct view;perspective conversion;camera frames;perspective-preserving conversion;high-precision manual tasks;perceptually coherent augmentations;nonorthostereoscopic VST HMDs capable;parallax-free VST HMDs;hand-eye coordination;perceptual errors;geometrical aberrations;nonorthostereoscopic video;toed-in vs parallel displays,,4,,41,CCBY,31-Oct-19,,,IEEE,IEEE Journals
HySAR: Hybrid Material Rendering by an Optical See-Through Head-Mounted Display with Spatial Augmented Reality Projection,T. Hamasaki; Y. Itoh; Y. Hiroi; D. Iwai; M. Sugimoto,Keio University; Tokyo Institue of TechnologyRIKENKeio University; Keio University; Osaka University; Keio University,IEEE Transactions on Visualization and Computer Graphics,13-Mar-18,2018,24,4,1457,1466,"Spatial augmented reality (SAR) pursues realism in rendering materials and objects. To advance this goal, we propose a hybrid SAR (HySAR) that combines a projector with optical see-through head-mounted displays (OST-HMD). In an ordinary SAR scenario with co-located viewers, the viewers perceive the same virtual material on physical surfaces. In general, the material consists of two components: a view-independent (VI) component such as diffuse reflection, and a view-dependent (VD) component such as specular reflection. The VI component is static over viewpoints, whereas the VD should change for each viewpoint even if a projector can simulate only one viewpoint at one time. In HySAR, a projector only renders the static VI components. In addition, the OST-HMD renders the dynamic VD components according to the viewer's current viewpoint. Unlike conventional SAR, the HySAR concept theoretically allows an unlimited number of co-located viewers to see the correct material over different viewpoints. Furthermore, the combination enhances the total dynamic range, the maximum intensity, and the resolution of perceived materials. With proof-of-concept systems, we demonstrate HySAR both qualitatively and quantitatively with real objects. First, we demonstrate HySAR by rendering synthetic material properties on a real object from different viewpoints. Our quantitative evaluation shows that our system increases the dynamic range by 2.24 times and the maximum intensity by 2.12 times compared to an ordinary SAR system. Second, we replicate the material properties of a real object by SAR and HySAR, and show that HySAR outperforms SAR in rendering VD specular components.",1941-0506,,10.1109/TVCG.2018.2793659,JSPS; JST CREST; JST PRESTO; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260968,Optical see-through displays;hybrid material rendering;spatial augmented reality,Augmented realtiy;Head-mounted displays;Rendering (computer graphics);Optical reflection;Adaptive optics,augmented reality;helmet mounted displays;rendering (computer graphics),optical see-through head-mounted display;VD specular components;static VI components;view-dependent component;view-independent component;virtual material;hybrid SAR;spatial augmented reality projection;hybrid material rendering,,1,,37,Traditional,17-Jan-18,,,IEEE,IEEE Journals
An analysis of eye-tracking data in foveated ray tracing,T. Roth; M. Weier; A. Hinkenjann; Y. Li; P. Slusallek,"Bonn-Rhein-Sieg University of Applied Sciences and Brunel University London; Bonn-Rhein-Sieg University of Applied Sciences and Saarland University; Bonn-Rhein-Sieg University of Applied Sciences; Brunel University London; Saarland University, Intel Visual Computing Institute and German Research Center for Artificial Intelligence (DFKI)",2016 IEEE Second Workshop on Eye Tracking and Visualization (ETVIS),16-Feb-17,2016,,,69,73,"We present an analysis of eye tracking data produced during a quality-focused user study of our own foveated ray tracing method. Generally, foveated rendering serves the purpose of adapting actual rendering methods to a user's gaze. This leads to performance improvements which also allow for the use of methods like ray tracing, which would be computationally too expensive otherwise, in fields like virtual reality (VR), where high rendering performance is important to achieve immersion, or fields like scientific and information visualization, where large amounts of data may hinder real-time rendering capabilities. We provide an overview of our rendering system itself as well as information about the data we collected during the user study, based on fixation tasks to be fulfilled during flights through virtual scenes displayed on a head-mounted display (HMD). We analyze the tracking data regarding its precision and take a closer look at the accuracy achieved by participants when focusing the fixation targets. This information is then put into context with the quality ratings given by the users, leading to a surprising relation between fixation accuracy and quality ratings.",,978-1-5090-4731-4,10.1109/ETVIS.2016.7851170,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7851170,,Rendering (computer graphics);Visualization;Ray tracing;Target tracking;Electronic mail;Tunneling;Focusing,data analysis;data visualisation;gaze tracking;helmet mounted displays;ray tracing;rendering (computer graphics);virtual reality,eye-tracking data analysis;foveated ray tracing method;foveated rendering;actual rendering methods;virtual reality;scientific visualization;information visualization;real-time rendering capabilities;fixation tasks;virtual scenes;head-mounted display;HMD;quality ratings,,5,,17,,16-Feb-17,,,IEEE,IEEE Conferences
On Benchmarking Iris Recognition within a Head-mounted Display for AR/VR Applications,F. Boutros; N. Damer; K. Raja; R. Ramachandra; F. Kirchbuchner; A. Kuijper,"Mathematical and Applied Visual Computing, TU Darmstadt,Darmstadt,Germany; Mathematical and Applied Visual Computing, TU Darmstadt,Darmstadt,Germany; Norwegian Biometrics Laboratory, NTNU,Gjovik,Norway; Norwegian Biometrics Laboratory, NTNU,Gjovik,Norway; Mathematical and Applied Visual Computing, TU Darmstadt,Darmstadt,Germany; Mathematical and Applied Visual Computing, TU Darmstadt,Darmstadt,Germany",2020 IEEE International Joint Conference on Biometrics (IJCB),6-Jan-21,2020,,,1,10,"Augmented and virtual reality is being deployed in different fields of applications. Such applications might involve accessing or processing critical and sensitive information, which requires strict and continuous access control. Given that Head-Mounted Displays (HMD) developed for such applications commonly contains internal cameras for gaze tracking purposes, we evaluate the suitability of such setup for verifying the users through iris recognition. In this work, we first evaluate a set of iris recognition algorithms suitable for HMD devices by investigating three well-established handcrafted feature extraction approaches, and to complement it, we also present the analysis using four deep learning models. While taking into consideration the minimalistic hardware requirements of stand-alone HMD, we employ and adapt a recently developed miniature segmentation model (EyeMMS) for segmenting the iris. Further, to account for non-ideal and non-collaborative capture of iris, we define a new iris quality metric that we termed as Iris Mask Ratio (IMR) to quantify the iris recognition performance. Motivated by the performance of iris recognition, we also propose the continuous authentication of users in a non-collaborative capture setting in HMD. Through the experiments on a publicly available OpenEDS dataset, we show that performance with EER = 5% can be achieved using deep learning methods in a general setting, along with high accuracy for continuous user authentication.",2474-9699,978-1-7281-9186-7,10.1109/IJCB48548.2020.9304919,"German Federal Ministry of Education and Research and the Hessen State Ministry for Higher Education, Research; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9304919,,Iris recognition;Resists;Feature extraction;Image segmentation;Cameras;Pupils;Authentication,authorisation;biometrics (access control);feature extraction;helmet mounted displays;image recognition;iris recognition;learning (artificial intelligence);virtual reality,recently developed miniature segmentation model;minimalistic hardware requirements;deep learning models;HMD devices;iris recognition algorithms;gaze tracking purposes;internal cameras;Head-Mounted Displays;continuous access control;strict access control;sensitive information;critical information;virtual reality;augmented reality;Head-mounted display;benchmarking Iris recognition;continuous user authentication;noncollaborative capture setting;iris recognition performance;Iris Mask Ratio;iris quality,,,,50,,6-Jan-21,,,IEEE,IEEE Conferences
Delay Compensation for a Telepresence System With 3D 360 Degree Vision Based on Deep Head Motion Prediction and Dynamic FoV Adaptation,T. Aykut; M. Karimi; C. Burgmair; A. Finkenzeller; C. Bachhuber; E. Steinbach,"Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany",IEEE Robotics and Automation Letters,31-Aug-18,2018,3,4,4343,4350,"The usability of telepresence applications is strongly affected by the communication delay between the user and the remote system. Special attention needs to be paid in case the distant scene is experienced by means of a Head Mounted Display. A high motion-to-photon latency, which describes the time needed to fully reflect the user's motion on the display, results in a poor feeling of presence. Further consequences involve unbearable motion sickness, indisposition, and termination of the telepresence session in the worst case. In this letter, we present our low-cost MAVI telepresence system, which is equipped with a stereoscopic 360¬∞ vision system and high-payload manipulation capabilities. Special emphasis is placed on the stereoscopic vision system and its delay compensation. More specifically, we propose velocity-based dynamic field-of-view adaptation techniques to decrease the emergence of simulator sickness and to improve the achievable level of delay compensation. The proposed delay compensation approach relies on deep learning to predict the prospective head motion. We use our previously described head motion dataset for training, validation, and testing. To prove the general validity of our approach, we perform cross validation with another independent dataset. We use both qualitative measures and subjective experiments for evaluation. Our results show that the proposed approach is able to achieve mean compensation rates of around 99.9% for latencies between 0.1 and 0.5 s.",2377-3766,,10.1109/LRA.2018.2864359,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8429079,3D vision;telepresence;virtual reality;remote reality;omnidirectional vision,Deep learning;Visualization;Delays;Telepresence;Virtual reality;Stereo image processing,compensation;delays;haptic interfaces;helmet mounted displays;learning (artificial intelligence);optical tracking;stereo image processing;three-dimensional displays;virtual reality;visual perception,field-of-view adaptation techniques;delay compensation approach;prospective head motion;mean compensation rates;dynamic FoV adaptation;telepresence applications;communication delay;remote system;Head Mounted Display;unbearable motion sickness;telepresence session;low-cost MAVI telepresence system;stereoscopic 360¬∞ vision system;high-payload manipulation capabilities;head motion dataset;3D 360 degree vision;velocity-based dynamic field-of-view adaptation techniques;high motion-to-photon latency;deep head motion prediction;simulator sickness;deep learning,,2,,29,,8-Aug-18,,,IEEE,IEEE Journals
The Introduction of a Novel Virtual Reality Training System for Gynecology Learning and Its User Experience Research,C. Chang; S. Yeh; M. Li; E. Yao,"School of Journalism, Fudan University, Shanghai, China; School of Information Science and Technology, Fudan University, Shanghai, China; Department of Psychology, Fudan University, Shanghai, China; Iforeal Intelligent Technology, Shanghai, China",IEEE Access,11-Apr-19,2019,7,,43637,43653,"The researchers of this study designed a new virtual reality (VR)-assisted training system, IFOREAL, for gynecology students at their university and introduced it to potential trainees. Two versions of IFOREAL, each employing different devices, were developed. The consumer version uses a traditional LCD display and computer mouse, whereas the professional version utilizes a head-mounted display (HMD) and joystick controller for the virtual learning. Trainees watched simulated videos and interacted with the system to accomplish tasks. IFOREAL consists of several major learning modules of gynecology. This study used the normal spontaneous delivery module to research user experience and perceptions of the IFOREAL VR training system. The results suggested that most of the trainees' user experiences and perceptions of IFOREAL, using both the types of VR-assisted technology, were positively reported. Trainees who used the consumer version of IFOREAL perceived a stronger internal control, whereas trainees using the professional version perceived a better sense of virtual presence. Overall, trainees perceived the usefulness of the IFOREAL system which predicted their future intention to use the system and other similar VR-assisted training systems for learning. Furthermore, whether the virtual content of IFOREAL grabbed the trainees' attention predicted their future intenon to use professional devices of HMD/joysck for learning other subjects. The gender difference was also explored in the study. Generally speaking, female trainees gave better evaluations of IFOREAL compared to their male counterparts. They perceived a better internal control while using the consumer version than the professional version. Male trainees believed that the gadgets used in the professional version provided a better virtual presence and met their expectation of a virtual experience better. This study suggested that different versions of IFOREAL could serve trainees' different needs. Technology developers and trainers should tailor the application of different VR devices to assist with the training/learning in accordance with different conditions/trainees.",2169-3536,,10.1109/ACCESS.2019.2905143,"Iforreal Intelligent Technology (Shanghai) Co., Ltd.; Fudan University; Xijia Great Education Technology Co., Ltd.; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8667417,Virtual reality;training/learning system;immersive and interactive design;user experience;acceptance and adoption of systems,Training;Gynecology;Visualization;Fetus;Standards;Videos;Pregnancy,biomedical education;computer based training;gynaecology;helmet mounted displays;interactive devices;medical computing;virtual reality,novel virtual reality training system;gynecology learning;user experience research;virtual reality-assisted training system;potential trainees;consumer version;computer mouse;professional version utilizes;joystick controller;virtual learning;research user experience;IFOREAL VR training system;VR-assisted technology;virtual presence;IFOREAL system;similar VR-assisted training systems;virtual content;female trainees;male trainees;virtual experience;VR devices,,7,,48,,14-Mar-19,,,IEEE,IEEE Journals
Serious Virtual Reality Game for Isometric Eye Training of Strabismic Patients,J. H. Kim; S. Hee Oh,"Gachon University,Republic of Korea; Gachon University,Republic of Korea",2020 International Conference on Information and Communication Technology Convergence (ICTC),21-Dec-20,2020,,,468,473,"Along with the development of IT technology, the healthcare industry is growing by converging with IT technology, and studies on various fusion medical clinical trials using virtual reality technology, which have been particularly noticeable after the 4th industrial revolution, are actively progressing. In particular, there is a trend of active research on strabismus treatment in combination with virtual reality technology at home and abroad. In this paper, through collaboration with an ophthalmologist, we developed 3 types of mini-game contents that can be used to train strabismus patients in virtual reality space by wearing an HMD, and we study how to control prism diopter value to obtain strabismus training effect in general virtual reality games.",2162-1233,978-1-7281-6758-9,10.1109/ICTC49870.2020.9289585,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9289585,VR;VR Contents;Ophthalmology;Strabismus;Rehabilitation,Training;Solid modeling;Virtual reality;Games;Clinical trials;Stability analysis;Usability,gaze tracking;medical image processing;patient treatment;serious games (computing);virtual reality;vision defects,industrial revolution;mini-game contents;strabismus patients;serious virtual reality game;isometric eye training;health care industry;fusion medical clinical trials;prism diopter value;ophthalmologist;IT technology,,,,12,,21-Dec-20,,,IEEE,IEEE Conferences
The Effect of 360-Degree Video Authentic Materials on EFL Learners' Listening Comprehension,S. Ji; K. Li; L. Zou,Hankou University; Wuhan University; Hankou University,"2019 International Joint Conference on Information, Media and Engineering (IJCIME)",16-Apr-20,2019,,,288,293,"Although the increased use of authentic materials in listening comprehension teaching has become general practice, it is crucial to find out whether or not the new technology-supported authentic material could be beneficial to English as a Foreign Language (EFL) learners' listening comprehension. The present study examined the effect of authentic material presentation modes (the traditional presentation mode versus virtual reality mode) on EFL learners' English listening comprehension and cognitive load. Subjects were 53 English major sophomores of a university in Wuhan. The control group received the common traditional video playback (the traditional presentation mode) and the experimental group were provided material on Head-Mounted Display (HMD) by 360-degree video playback (the virtual reality mode). The same authentic video material-360-degree video journalism was used in the two groups. The results demonstrated that the EFL learners who watched 360-degree video journalism encountered higher cognitive load and did not outperform in English listening comprehension test than those who watched the material in traditional presentation mode. Pedagogical implications for English listening teaching were provided at the end of the study.",,978-1-7281-5586-9,10.1109/IJCIME49369.2019.00065,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9066355,English listening comprehension;cognitive load;360-degree video journalism;EFL learners,Visualization;Education;Resists;Virtual reality;Vocabulary;Media;Head-mounted displays,cognition;computer aided instruction;educational institutions;helmet mounted displays;linguistics;multimedia systems;teaching;video signal processing;virtual reality,English as a foreign language learners;authentic material presentation modes;virtual reality mode;360-degree video playback;authentic video material-360-degree video journalism;English listening comprehension test;English listening teaching;360-degree video authentic materials;comprehension teaching;technology-supported authentic material;head-mounted display;university;cognitive load;EFL learners English listening comprehension,,,,36,,16-Apr-20,,,IEEE,IEEE Conferences
"gPhysics‚ÄîUsing Smart Glasses for Head-Centered, Context-Aware Learning in Physics Experiments",J. Kuhn; P. Lukowicz; M. Hirth; A. Poxrucker; J. Weppner; J. Younas,"Physics Education Research Group, Department of Physics, University of Kaiserslautern, Kaiserslautern, Germany; German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; Physics Education Research Group, Department of Physics, University of Kaiserslautern, Kaiserslautern, Germany; German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany",IEEE Transactions on Learning Technologies,14-Dec-16,2016,9,4,304,317,"Smart Glasses such as Google Glass are mobile computers combining classical Head-Mounted Displays (HMD) with several sensors. Therefore, contact-free, sensor-based experiments can be linked with relating, near-eye presented multiple representations. We will present a first approach on how Smart Glasses can be used as an experimental tool for head-centered, context-aware, wearable-technology-enhanced, and inquiry-based learning in physics education. Therefore, we developed an app that is based on the Google Glass platform and designed to perform educational physical experiments on the topic of acoustics. Its initial application is intended for high-school students whose task is to study the relationship between the frequency of the sound generated by hitting a glass of water and the amount of water in the glass. The core idea is to have Google Glass automatically measure both the water fill level with the camera and the sound frequency with the microphone, and incrementally generate a fill level/frequency graph in the HMD. We designed an educational setting and studied its effect on cognitive and affective variables with an intervention-control-group design. While the intervention group analyzed the fill level/frequency relationship with the Google Glass platform, control group 1 worked on the phenomenon using the same platform implemented on a tablet PC. Control group 2 analyzed the phenomenon using a tablet PC with a typical mobile-based education platform. We used a two-way ANCOVA to study learning outcome, wondering, curiosity, cognitive load, and experimentation time as dependent variables of 46 high-school eighth-graders together with group membership and gender influence as independent variables. While the positive effects of using Google Glass as a mobile lab on wondering and curiosity as well as a positive trend for experimentation time were detected, no differences were analyzed for learning achievement. Although students have a higher cognitive load when working with Google Glass compared to other devices, the cognitive load level is very low in general.",1939-1382,,10.1109/TLT.2016.2554115,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7452644,Wearable computers;physics education;student experiments;acoustic measurements;wearable sensors;image recognition,Smart devices;Google;Sensors;Wearable computing;Mobile computers;Glasses,cameras;computer aided instruction;helmet mounted displays;microphones;mobile computing;notebook computers;physics computing;physics education;student experiments;wearable computers,fill level/frequency relationship;tablet PC;mobile-based education platform;two-way ANCOVA;learning outcome;wondering;curiosity;cognitive load;experimentation time;high-school eighth-graders;group membership;gender influence;mobile lab;intervention-control-group design;affective variables;cognitive variables;educational setting;fill level/frequency graph;microphone;camera;water fill level;sound frequency;high-school students;educational physical experiments;Google Glass platform;physics education;inquiry-based learning;wearable-technology-enhanced learning;sensor-based experiments;contact-free experiments;HMD;classical head-mounted displays;mobile computers;context-aware learning;head-centered learning;smart glasses;gPhysics,,23,,55,,14-Apr-16,,,IEEE,IEEE Journals
‚ÄúWoodlands‚Äù - a Virtual Reality Serious Game Supporting Learning of Practical Road Safety Skills,K. Szczurowski; M. Smith,"Department of Informatics, Institute of Technology Blanchardstown, Dublin, Ireland; Department of Informatics, Institute of Technology Blanchardstown, Dublin, Ireland","2018 IEEE Games, Entertainment, Media Conference (GEM)",1-Nov-18,2018,,,1,9,"In developed societies road safety skills are taught early and often practiced under the supervision of a parent, providing children with a combination of theoretical and practical knowledge. At some point children will attempt to cross a road unsupervised, at that point in time their safety depends on the effectiveness of their road safety education. To date, various attempts to supplement road safety education with technology were made. Most common approach focus on addressing declarative knowledge, by delivering road safety theory in an engaging fashion. Apart from expanding on text based resources to include instructional videos and animations, some stakeholders (e.g.: Irish Road Safety Authority) attempt to take advantage of game-based learning [1]. However, despite the high capacity for interaction being common in Virtual Environments, available game-based solutions to road safety education are currently limited to delivering and assessing declarative knowledge. With recent advancements in the field of Virtual Reality (VR) Head Mounted Displays, procedural knowledge might also be addressed in Virtual Environments. This paper describes the design and development process of a computer-supported learning system that attempts to address psycho-motor skills involved in crossing a road safely, changing learners' attitude towards road safety best practices, and enabling independent practice of transferable skills. By implementing game-based learning principles and following best practice for serious game design (such as making educational components essential to successful game-play, or instructional scaffolding) we hope to make it not only more effective, but also engaging, allowing us to rely on learners' intrinsic motivation [2], to increase their independent practice time and provide them with feedback that will help to condition safe behaviour and increase retention. Presence in Virtual Reality might evoke responses to Virtual Environment as if it was real (RAIR) [3] and enable learners to truly experience learning scenarios. In consequence leading to formation of autobiographical memories constructed from multisensory input, which should result in an increased knowledge retention and transfer [4].",,978-1-5386-6304-2,10.1109/GEM.2018.8516493,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516493,Virtual Reality;VR;Road Safety;Serious Game;Experiential Learning;Game-Based Learning;Virtual Environment,Games;Road safety;Virtual environments;Training,computer aided instruction;helmet mounted displays;road safety;serious games (computing);virtual reality,road safety education;declarative knowledge;road safety theory;road safety best practices;serious game design;virtual reality serious game;virtual environment;virtual reality head mounted displays;Woodlands;game-based learning,,4,,34,,1-Nov-18,,,IEEE,IEEE Conferences
The effects of presentation method and simulation fidelity on psychomotor education in a bimanual metrology training simulation,J. Bertrand; A. Bhargava; K. C. Madathil; A. Gramopadhye; S. V. Babu,"Clemson University, USA; Clemson University, USA; Clemson University, USA; Clemson University, USA; Clemson University, USA",2017 IEEE Symposium on 3D User Interfaces (3DUI),6-Apr-17,2017,,,59,68,"In this study, we empirically evaluated the effects of presentation method and simulation fidelity on task performance and psychomotor skills acquisition in an immersive bimanual simulation towards precision metrology education. In a 2 √ó 2 experiment design, we investigated a large-screen immersive display (LSID) with a head-mounted display (HMD), and the presence versus absence of gravity. Advantages of the HMD include interacting with the simulation in a more natural manner as compared to using a large-screen immersive display due to the similarities between the interactions afforded in the virtual compared to the real-world task. Suspending the laws of physics may have an effect on usability and in turn could affect learning outcomes. Our dependent variables consisted of a pre and post cognition questionnaire, quantitative performance measures, perceived workload and system usefulness, and a psychomotor assessment to measure to what extent transfer of learning took place from the virtual to the real world. Results indicate that the HMD condition was preferable to the immersive display in several metrics while the no-gravity condition resulted in users adopting strategies that were not advantageous for task performance.",,978-1-5090-6716-9,10.1109/3DUI.2017.7893318,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7893318,"H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems‚ÄîArtificial, augmented, and virtual realities",Solid modeling;Training;Aerospace electronics;Resists;Metrology;Visualization;Gravity,computer based training;digital simulation;helmet mounted displays;measurement;virtual reality,presentation method;simulation fidelity;psychomotor education;bimanual metrology training simulation;psychomotor skill acquisition;immersive bimanual simulation;precision metrology education;large-screen immersive display;LSID;head-mounted display;HMD;no-gravity condition,,3,,36,,6-Apr-17,,,IEEE,IEEE Conferences
Cognitive psychology and human factors engineering of virtual reality,A. K. T. Ng,"The University of Hong Kong, Hong Kong, China",2017 IEEE Virtual Reality (VR),6-Apr-17,2017,,,407,408,"This position paper summarizes the author's research interest in Cognitive Psychology and Human-Computer Interaction in the imseCAVE, a CAVE-like system in the University of Hong Kong. Several areas of interest were explored while finding the thesis topic for the Ph.D. research. They include a perception research on distance estimation with proposed error correction mechanism, neurofeedback meditation with EEG in VR and the effect with audio and video, the study of training transfer in VR training, the comparison and research of cybersickness between HMD and the imseCAVE, and comparing VR gaming in TV, HMD, and the imseCAVE by performance, activity level and time perception. With a broad interest, the exact direction is still in the search and requires future exploration.",2375-5334,978-1-5090-6647-6,10.1109/VR.2017.7892349,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892349,Virtual environment;cognitive psychology;HCI,Training;Psychology;Resists;Virtual reality;Human factors;Ergonomics;Human computer interaction,cognition;human factors;virtual reality,cognitive psychology;human factors engineering;virtual reality;CAVE-like system;error correction mechanism;neurofeedback meditation;EEG;VR;imseCAVE;distance estimation,,,,13,,6-Apr-17,,,IEEE,IEEE Conferences
Comparing HMD-Based and Paper-Based Training,S. Werrlich; A. Daniel; A. Ginger; P. Nguyen; G. Notni,"BMW Group, Munich, Germany; BMW Group, Munich, Germany; BMW Group, Munich, Germany; BMW Group, Munich, Germany; Tech. Univ. Ilmenau, Ilmenau, Germany",2018 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),17-Jan-19,2018,,,134,142,"Collaborative Systems are in daily use by millions of people promising to improve everyone's life. Smartphones, smartwatches and tablets are everyday objects and life without these unimaginable. New assistive systems such as head-mounted displays (HMDs) are becoming increasingly important for various domains, especially for the industrial domain, because they claim to improve the efficiency and quality of procedural tasks. A range of scientific laboratory studies already demonstrated the potential of augmented reality (AR) technologies especially for training tasks. However, most researches are limited in terms of inadequate task complexity, measured variables and lacking comparisons. In this paper, we want to close this gap by introducing a novel multimodal HMD-based training application and compare it to paper-based learning for manual assembly tasks. We perform a user study with 30 participants measuring the training transfer of an engine assembly training task, the user satisfaction and perceived workload during the experiment. Established questionnaires such as the system usability scale (SUS), the user experience questionnaire (UEQ) and the Nasa Task Load Index (NASA-TLX) are used for the assessment. Results indicate significant differences between both learning approaches. Participants perform significantly faster and significantly worse using paper-based instructions. Furthermore, all trainees preferred HMD-based learning for future assembly trainings which was scientifically proven by the UEQ.",1554-7868,978-1-5386-7459-8,10.1109/ISMAR.2018.00046,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613759,Augmented Reality;Evaluation;Head Mounted Displays;Training,Task analysis;Training;Engines;Software;Resists;Atmospheric measurements;Particle measurements,augmented reality;computer based training;groupware;helmet mounted displays;human computer interaction;human factors;user interfaces;virtual reality,paper-based training;Collaborative Systems;smartwatches;head-mounted displays;industrial domain;scientific laboratory studies;augmented reality;training tasks;inadequate task complexity;training transfer;engine assembly training task;user satisfaction;system usability scale;user experience questionnaire;Nasa Task Load Index;paper-based instructions;assistive systems;multimodal HMD-based learning,,5,,28,,17-Jan-19,,,IEEE,IEEE Conferences
Increasing the effective egocentric field of view with proprioceptive and tactile feedback,Ungyeon Yang; G. Jounghyun Kim,"Virtual Reality Div., Electr. & Telecom. Res. Inst., Daejeon, South Korea; NA",IEEE Virtual Reality 2004,12-Jul-04,2004,,,27,34,"Multimodality often exhibits synergistic effects: each modality compliments and compensates for other modalities in transferring coherent, unambiguous, and enriched information for higher interaction efficiency and improved sense of presence. In this paper, we explore one such phenomenon: a positive interaction among the geometric field of view, proprioceptive interaction, and tactile feedback. We hypothesize that, with proprioceptive interaction and tactile feedback, the geometric field of view and thus visibility can be increased such that it is larger than the physical field of view, without causing a significant distortion in the user's distance perception. This, in turn, would further help operation of the overall multimodal interaction scheme as the user is more likely to receive the multimodal feedback simultaneously. We tested our hypothesis with an experiment to measure the user's change in distance perception according to different values of egocentric geometric field of view and feedback conditions. Our experimental results have shown that, when coupled with physical interaction, the GFOV could be increased by up to 170 percent of the physical field of view without introducing significant distortion in distance perception. Second, when tactile feedback was introduced, in addition to visual and proprioceptive cues, the GFOV could be increased by up to 200 percent. The results offer a useful guideline for effectively utilizing of modality compensation and building multimodal interfaces for close range spatial tasks in virtual environments. In addition, it demonstrates one way to overcome the shortcomings of the narrow (physical) fields of views of most contemporary HMDs.",1087-8270,0-7803-8415-6,10.1109/VR.2004.1310052,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1310052,,Feedback;Virtual reality;Space technology;Layout;Telecommunications;Computer science;Testing;Distortion measurement;Guidelines;Virtual environment,virtual reality;image motion analysis;helmet mounted displays;distortion;haptic interfaces,tactile feedback;geometric field of view;proprioceptive interaction;multimodal interaction;multimodal feedback;physical interaction;GFOV;proprioceptive cues;modality compensation;multimodal interfaces;spatial tasks;virtual environments;HMDs,,2,,33,,12-Jul-04,,,IEEE,IEEE Conferences
A virtual environment for learning to pilot remotely operated vehicles,N. J. Pioch; B. Roberts; D. Zeltzer,"BBN Corp., Cambridge, MA, USA; NA; NA",Proceedings. International Conference on Virtual Systems and MultiMedia VSMM '97 (Cat. No.97TB100182),6-Aug-02,1997,,,218,226,"Remotely operated vehicles (ROVs) are used extensively for underwater searching and salvage, inspection, surveying, scientific exploration and mine countermeasures. ROV pilots must learn to rely on limited data from video and sonar displays and a few other positional indicators to maintain a sense of their vehicle, its tether and its surroundings. Pilot training typically occurs on-the-job, where equipment is placed at risk, controlled learning situations are hard to create, and time for instruction is minimal. The TRANSoM (TRAiNing for remote Sensing and Manipulation) project is developing a training environment that combines two emerging technologies to overcome these limitations. A virtual environment (VE) simulates the ROV and its surroundings, and also has instructional enhancements such as external views of the ROV, directional cues and alternate modes of interaction with the vehicle, e.g. a head-tracked head-mounted display (HMD). An intelligent tutoring system (ITS) monitors student pilot behavior and offers verbal and graphical feedback, a mission review and a performance assessment. Near-transfer experiments comparing the utility of different artificial viewpoints have been completed, with full transfer experiments involving a real ROV to follow.",,0-8186-8150-0,10.1109/VSMM.1997.622350,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=622350,,Virtual environment;Remotely operated vehicles;Inspection;Sonar equipment;On the job training;Remote sensing;Intelligent systems;Artificial intelligence;Computer displays;Feedback,marine systems;virtual reality;intelligent tutoring systems;telecontrol;computer based training;control engineering computing,virtual environment;remotely operated vehicle simulation;pilot training;underwater vehicles;video displays;sonar displays;positional indicators;TRANSoM project;remote sensing;remote manipulation;instructional enhancements;external views;directional cues;interaction modes;head-tracked head-mounted display;intelligent tutoring system;student pilot behavior monitoring;verbal feedback;graphical feedback;mission review;performance assessment;near-transfer experiments;artificial viewpoints,,5,,15,,6-Aug-02,,,IEEE,IEEE Conferences
A Cross-Platform Classroom Training Simulator: Interaction Design and EvaluationA Cross-Platform Classroom Training Simulator: Interaction Design and Evaluation,A. Delamarre; C. Lisetti; C. Buche,"Florida International University,VISAGE Lab, SCIS,Miami,USA; Florida International University,VISAGE Lab, SCIS,Miami,USA; LAB-STICC CNRS, ENIB,Brest,France",2020 International Conference on Cyberworlds (CW),30-Oct-20,2020,,,86,93,"Virtual training environments experienced with different immersive technologies can accommodate users' preferences, proficiency, and platform availability. Whereas research comparing the effects of immersive technologies can provide important insights about their impact on users' experience (e.g. engagement, transfer of learning), current studies do not address how to design the user interface (UI) to ensure sound comparisons across platforms. For effective comparisons, however, the UI designs must be adapted for the platform used to provide comparable usability. In this article we describe our UI design methodology for the development of an effective and usable virtual classroom training simulator built for three technologies: (1) desktop; (2) Head-Mounted Display (HMD); and (3) Cave Automatic Virtual Environment (CAVE). Usability and other user experience factors were evaluated for each platform with concurrent think-aloud protocol and semi-structured interviews indicating that all three UIs were easy to use and to learn. We discuss insights for future development of cross-platform VTEs.",2642-3596,978-1-7281-6497-7,10.1109/CW49994.2020.00020,Florida International University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240533,Immersive Virtual Environment;Virtual Reality;Human Computer Interaction;User Study;Design,Training;Virtual environments;Resists;User interfaces;User experience;Usability;Interviews,computer based training;computer simulation;helmet mounted displays;user interfaces;virtual reality,interaction design;virtual training environments;platform availability;user interface;UI designs;comparable usability;UI design;usable virtual classroom training simulator;user experience factors;cross-platform VTEs;classroom training simulator;immersive technologies;cross-platform classroom training simulator;desktop;head-mounted display;cave automatic virtual environment,,,,24,,30-Oct-20,,,IEEE,IEEE Conferences
Arch-Explore: A natural user interface for immersive architectural walkthroughs,G. Bruder; F. Steinicke; K. H. Hinrichs,"Visualization and Computer Graphics (VisCG) Research Group, Department of Computer Science, University of M√ºnster, Einsteinstr. 62, 48149, Germany; Visualization and Computer Graphics (VisCG) Research Group, Department of Computer Science, University of M√ºnster, Einsteinstr. 62, 48149, Germany; Visualization and Computer Graphics (VisCG) Research Group, Department of Computer Science, University of M√ºnster, Einsteinstr. 62, 48149, Germany",2009 IEEE Symposium on 3D User Interfaces,7-Apr-09,2009,,,75,82,"In this paper we propose the Arch-Explore user interface, which supports natural exploration of architectural 3D models at different scales in a real walking virtual reality (VR) environment such as head-mounted display (HMD) or CAVE setups. We discuss in detail how user movements can be transferred to the virtual world to enable walking through virtual indoor environments. To overcome the limited interaction space in small VR laboratory setups, we have implemented redirected walking techniques to support natural exploration of comparably large-scale virtual models. Furthermore, the concept of virtual portals provides a means to cover long distances intuitively within architectural models. We describe the software and hardware setup and discuss benefits of Arch-Explore.",,978-1-4244-3965-2,10.1109/3DUI.2009.4811208,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811208,3D user interfaces;virtual environments;locomotion;architectural walkthroughs;redirected walking;passive haptic feedback,User interfaces;Legged locomotion;Virtual reality;Computer graphics;Indoor environments;Laboratories;Hardware;Virtual environment;Haptic interfaces;Feedback,helmet mounted displays;solid modelling;user interfaces;virtual reality,immersive architectural walkthroughs;Arch-Explore user interface;natural exploration;architectural 3D models;virtual reality environment;head-mounted display;CAVE setups;virtual indoor environments;VR laboratory setups;virtual models;virtual portals;architectural models,,52,,34,,7-Apr-09,,,IEEE,IEEE Conferences
Binocular Phase-Coded Visual Stimuli for SSVEP-Based BCI,I. Kramberger; Z. kaƒçiƒç; G. Donaj,"Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, Slovenia; Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, Slovenia; Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, Slovenia",IEEE Access,22-Apr-19,2019,7,,48912,48922,"This paper presents a method of binocular visual stimulation for brain-computer interfaces (BCIs) based on steady-state visual evoked potentials (SSVEPs) using phase-coded symbols. The proposed method's emphasis is on a binocular phase-coded visual stimulus, which is based on the phase differences between the left- and right-eye stimuli, and a symbol detection and recognition procedure based on SSVEP response of the left and right occipital lobes of the user's scalp, where the SSVEP response is obtained as electroencephalography (EEG) signaling. The symbols are coded as phase differences and maintain the same frequency of the sine wave-modulated light provided to the user's left and right eyes as a binocular visual stimulation. Based on this method, a basic system setup is presented to explore the possibilities of binocular phase-coded visual stimuli for virtual or augmented reality applications, where the binocular visual stimulation was achieved by the specially designed head-mounted displays. Multiple visually coded targets are realized as eight different phase-coded binocular symbols and further evaluated as a random sequence of single targets, thus representing the situations in virtual or augmented reality, where multiple visually coded targets are present but not visualized to the user simultaneously within the same field of view. The offline results obtained from ten healthy subjects revealed that an average symbol recognition accuracy of 90.63% and an information transfer rate (ITR) of 70.55 bits/min were achieved for a symbol stimulation time of 2 s. The results of this paper demonstrate the feasibility of using binocular visual stimuli for SSVEP-based BCIs, where reasonable ITR is achieved using single-frequency binocular phase-coded symbols. The proposed method indicates the possibility of combining it with 3D wearable visualization technologies, such as binocular head-mounted displays (HMDs), in order to improve the intuitiveness of the interaction with more immersive user experience using BCI modalities.",2169-3536,,10.1109/ACCESS.2019.2910737,Javna Agencija za Raziskovalno Dejavnost RS; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8688386,Brain computer interfaces;brain stimulation;electroencephalography;data acquisition;human computer interaction;phase measurement;steady state visually evoked potential;three-dimensional displays;visualization;virtual reality;wearable sensors,Visualization;Electroencephalography;Encoding;Frequency modulation;Light emitting diodes;Liquid crystal displays;Phase measurement,augmented reality;brain-computer interfaces;electroencephalography;eye;helmet mounted displays;medical signal detection;medical signal processing;neurophysiology;visual evoked potentials,right-eye stimuli;symbol detection;recognition procedure;SSVEP response;phase differences;binocular visual stimulation;binocular phase-coded visual stimuli;multiple visually coded targets;symbol stimulation time;SSVEP-based BCIs;single-frequency binocular phase-coded symbols;3D wearable visualization technologies;binocular head-mounted displays;left- eye stimuli;brain-computer interfaces;steady-state visual evoked potentials;electroencephalography signaling;sine wave-modulated light;augmented reality applications;virtual reality applications;symbol recognition accuracy;information transfer rate;time 2.0 s,,,,38,,11-Apr-19,,,IEEE,IEEE Journals
Augmented-Reality-Based Visualization of Navigation Data of Mobile Robots on the Microsoft Hololens - Possibilities and Limitations,L. K√§stner; J. Lambrecht,"Technical University of Berlin,Chair Industry Grade Networks and Clouds Department,Berlin,Germany; Technical University of Berlin,Chair Industry Grade Networks and Clouds Department,Berlin,Germany","2019 IEEE International Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM)",19-May-20,2019,,,344,349,"The demand for mobile robots has rapidly increased in recent years due to the flexibility and high variety of application fields comparing to static robots. To deal with complex tasks such as navigation, they work with high amounts of different sensor data making it difficult to operate with for non-experts. To enhance user understanding and human robot interaction, we propose an approach to visualize the navigation stack within a cutting edge 3D Augmented Reality device -the Microsoft Hololens. Therefore, relevant navigation stack data including laser scan, environment map and path planing data are visualized in 3D within the head mounted device. Based on that prototype, we evaluate the Hololens in terms of computational capabilities and limitations for dealing with huge amount of real-time data. Results show that the Hololens is capable of a proper visualization of huge amounts of sensor data. We demonstrate a proper visualization of navigation stack data in 3D within the Hololens. However, there are limitations when transferring and displaying different kinds of data simultaneously.",2326-8239,978-1-7281-3458-1,10.1109/CIS-RAM47153.2019.9095836,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9095836,,Data visualization;Robot sensing systems;Robot kinematics;Navigation;Three-dimensional displays;Mobile robots,augmented reality;control engineering computing;data visualisation;human-robot interaction;mobile robots;path planning,navigation data;mobile robots;Microsoft Hololens;high variety;static robots;sensor data;user understanding;human robot interaction;environment map;path planing data;real-time data;Augmented-Reality-based visualization;relevant navigation stack data;laser scan;cutting edge 3D augmented reality device,,2,,26,,19-May-20,,,IEEE,IEEE Conferences
Mediated perception and action in human robotic embodiment,M. Bergamasco,"PERCRO, Scuola Superiore Sant'Anna, Pisa, Italy",19th International Symposium in Robot and Human Interactive Communication,11-Oct-10,2010,,,1,1,"Research on Robotics and Artificial Intelligence presently interprets the interaction between human and robotic subjects through a set of mediated controls who engage almost all human senses. The underlying communication requires the establishment of a set of interaction metaphors in order to allow a natural type of control. The most common of these metaphors is the kinematic copy of human gestures. During the last ten years incredible progresses in cognitive science, psychology, neuroscience, physiology and neurophysiology have been achieved. The knowledge about the relationship between the ‚Äúperception and sensori-motion mechanisms‚Äù and the brain has never been so advanced. One of the major outcomes is in the fact that it is possible to correlate brain neuronal activities to corresponding perception and motion, and, at the same time, it is possible to record these activities through the use of innovative devices. The combined adoption of these results does allow dissolving the physical constraints that act as a boundary during the interaction and control of robots and virtual environment entities. A new generation of brain and body (computer) interfaces (BBCI) will allow direct transfer of user intention and the realization of remote sensing. In such a way it will be possible to achieve the interactive communication with a robot without the requirement to physically perform any action. Virtual and robotic bodies can be controlled and moved even in absence of a correspondent motion of the controlling subject. The robots is moved only by thoughts while the robot perception is transferred directly to the humans through worn interfaces (Head mounted displays, skin and body stimulators,...). This lecture addresses the path from teleoperation and virtual environment interaction toward new methods to recreate the illusion of surrogating our own bodies in different entities (being robotic or virtual) and investigates how the relevant perception-action loops will be affected.",1944-9437,978-1-4244-7990-0,10.1109/ROMAN.2010.5598757,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5598757,,,brain-computer interfaces;human-robot interaction;interactive systems;telerobotics,human robotic embodiment;robotics;artificial intelligence;interaction metaphors;sensori-motion mechanisms;perception mechanisms;brain neuronal activities;virtual environment;brain and body interfaces;user intention;interactive communication,,,,,,11-Oct-10,,,IEEE,IEEE Conferences
Transfer of a skilled motor learning task between virtual and conventional environments,J. Anglin; D. Saldana; A. Schmiesing; S. Liew,"University of Southern California, Los Angeles, California, United States of America; University of Southern California, Los Angeles, California, United States of America; University of Southern California, Los Angeles, California, United States of America; University of Southern California, Los Angeles, California, United States of America",2017 IEEE Virtual Reality (VR),6-Apr-17,2017,,,401,402,"Immersive, head-mounted virtual reality (HMD-VR) can be a potentially useful tool for motor rehabilitation. However, it is unclear whether the motor skills learned in HMD-VR transfer to the non-virtual world and vice-versa. Here we used a well-established test of skilled motor learning, the Sequential Visual Isometric Pinch Task (SVIPT), to train individuals in either an HMD-VR or conventional training (CT) environment. Participants were then tested in both environments. Our results show that participants who train in the CT environment have an improvement in motor performance when they transfer to the HMD-VR environment. In contrast, participants who train in the HMD-VR environment show a decrease in skill level when transferring to the CT environment. This has implications for how training in HMD-VR and CT may affect performance in different environments.",2375-5334,978-1-5090-6647-6,10.1109/VR.2017.7892346,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892346,Virtual reality;skilled motor learning;transfer,Training;Logic gates;Virtual reality;Computed tomography;Electroencephalography;Visualization;Indexes,medical computing;patient rehabilitation;virtual reality,skilled motor learning task;virtual environments;head-mounted virtual reality;HMD-VR;motor rehabilitation;sequential visual isometric pinch task;SVIPT;conventional training environment;CT environment,,8,,4,,6-Apr-17,,,IEEE,IEEE Conferences