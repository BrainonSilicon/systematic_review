"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Force-Driven Traffic Simulation for a Future Connected Autonomous Vehicle-Enabled Smart Transportation System","Y. Zhang; G. Zhang; R. Fierro; Y. Yang","University of New Mexico, Albuquerque, NM, USA; University of Hawaii at Manoa, Honolulu, HI, USA; University of New Mexico, Albuquerque, NM, USA; University of New Mexico, Albuquerque, NM, USA","IEEE Transactions on Intelligent Transportation Systems","29 Jun 2018","2018","19","7","2221","2233","Recent technology advances significantly push forward the development and the deployment of the concept of smart, such as smart community and smart city. Smart transportation is one of the core components in modern urbanization processes. Under this context, the connected autonomous vehicle (CAV) system presents a promising solution towards the enhanced traffic safety and mobility through state-of-the-art wireless communications and autonomous driving techniques. Being capable of collecting and transmitting real-time vehicle-specific, location-specific, and area-wide traffic information, it is believed that CAV-enabled transportation systems will revolutionize the existing understanding of network-wide traffic operations and reestablish traffic flow theory. This paper develops a new continuum dynamics model for the future CAV-enabled traffic system, realized by encapsulating mutually-coupled vehicle interactions using virtual internal and external forces. Leveraging Newton's second law of motion, our model naturally preserves the traffic volume and automatically handles both the longitudinal and lateral traffic operations due to its 2-D nature, which sets us apart from the existing macroscopic traffic flow models. Our model can also be rolled back to handle the conventional traffic of human drivers, and the experiment shows that the model describes real-world traffic behavior well. Therefore, we consider the proposed model a complement and generalization of the existing traffic theory. We also develop a smoothed particle hydrodynamics-based numerical simulation and an interactive traffic visualization framework. By posing user-specified external constraints, our system allows users to visually understand the impact of different traffic operations interactively.","1558-0016","","10.1109/TITS.2017.2787141","National Science Foundation; Nvidia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8340226","Smart transportation;connected vehicle;autonomous vehicle;traffic flow model;visualization;SPH;particle system;numerical solution","Numerical models;Computational modeling;Smart transportation;Autonomous vehicles;Vehicle dynamics;Acceleration;Mathematical model","data visualisation;digital simulation;intelligent transportation systems;interactive systems;road safety;road traffic;road vehicles;traffic information systems","network-wide traffic operations;continuum dynamics model;mutually-coupled vehicle interactions;virtual internal forces;traffic volume;longitudinal traffic operations;lateral traffic operations;interactive traffic visualization framework;smart transportation system;connected autonomous vehicle system;wireless communications;autonomous driving techniques;traffic flow theory;traffic operations;traffic safety;CAV-enabled traffic system;virtual external forces;smoothed particle hydrodynamics-based numerical simulation;force-driven traffic simulation;CAV-enabled transportation systems","","9","","72","","17 Apr 2018","","","IEEE","IEEE Journals"
"Computer modeling of interaction of gas discharge plasma with solid dielectric barriers","Y. V. Serdyuk; S. M. Gubanski","Chalmers Univ. of Technol., Gothenburg, Sweden; Chalmers Univ. of Technol., Gothenburg, Sweden","IEEE Transactions on Dielectrics and Electrical Insulation","26 Sep 2005","2005","12","4","725","735","A computer model describing charge transfer in a system consisting of two parallel-plate metallic electrodes covered with solid dielectric barriers immersed in gas medium is proposed. The material of the barriers is supposed to be a non-ideal insulator whose properties correspond to polyethylene and air is considered as a gas phase. The model is based on continuity equations for fluxes of charge carriers and accounts for their drift and diffusion and also for different sources of their generation and losses in different media. The continuity equations are coupled with Poisson's equation for computing electric fields affected by temporal and spatial variations of space charges in the system. Results of the computer simulations are obtained for the case when the applied field in the gas exceeds its breakdown threshold, i.e. charge transfer in the gas phase takes place in the form of an electrical discharge (electron avalanche and streamer). Evolution of generated discharge plasma is analyzed taking into account conditions on gas-solid interfaces and in the bulk of the solid dielectric barriers.","1558-4135","","10.1109/TDEI.2005.1511098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1511098","","Solid modeling;Discharges;Poisson equations;Charge transfer;Plasma properties;Plasma materials processing;Concurrent computing;Electrodes;Dielectric materials;Dielectrics and electrical insulation","avalanche breakdown;discharges (electric);plasma-wall interactions;space charge;plasma;electrodes;polyethylene insulation;air insulation;Poisson equation;digital simulation;charge injection","gas discharge plasma;solid dielectric barrier;charge transfer;parallel-plate metallic electrode;nonideal insulator;polyethylene;continuity equation;charge carrier;drift;diffusion;Poissons equation;electric fields;spatial variation;temporal variations;space charge;computer simulation;breakdown threshold;electrical discharge;electron avalanche;streamer propagation;gas-solid interface;charge injection;charge transport","","35","","21","","26 Sep 2005","","","IEEE","IEEE Journals"
"Navigation Aids in Collaborative Virtual Environments: Comparison of 3DML, Audio, Textual, Arrows-Casting","S. Khalid; S. Ullah; N. Ali; A. Alam; I. Rabbi; I. U. Rehman; M. Azhar","Department of Computer Science and IT, University of Malakand, Chakdara, Pakistan; Department of Computer Science and IT, University of Malakand, Chakdara, Pakistan; Department of Computer Science and IT, University of Malakand, Chakdara, Pakistan; Department of Computer Science and IT, University of Malakand, Chakdara, Pakistan; Department of Computer Science, University of Science and Technology Bannu, Bannu, Pakistan; Department of Computer Science and IT, University of Malakand, Chakdara, Pakistan; Department of Computer Science and IT, University of Malakand, Chakdara, Pakistan","IEEE Access","30 Oct 2019","2019","7","","152979","152989","For Collaborative Virtual Environments (CVEs), many interaction techniques are developed. Depending on the purpose of the collaborative work, techniques of interaction and manipulation change from one application to another. There is no general, good and efficient solution for all the collaborative systems. In addition, people in CVEs also use communication channels to share task goals, task decomposition and task progress. Therefore, awareness and communication are usually considered as important instruments to complete collaborative task. In this paper we present a comparative study of user performance with assembly task across four different guidance navigation aids i.e. 3-Dimensional Map-Liner (3DML), Audio, Textual and Arrows-Casting. Dijkstra's algorithm is used for shortest path selection while making the assembly task in CVEs. We conducted experiments on different college students to check the performance of the students. We reported the results of a precise experiments containing of 24 virtual teams of 48 individual students. Overall results showed that students performed task faster using the arrows while they were slow with audio support in navigation.","2169-3536","","10.1109/ACCESS.2019.2948285","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8876589","Virtual reality (VR);collaborative virtual environments;building navigation;map based navigation;Dijkstra’s algorithms;path planning","Navigation;Task analysis;Collaboration;Visualization;Virtual environments;Three-dimensional displays;Computer science","computer aided instruction;groupware;team working;virtual reality","collaborative virtual environments;3DML;CVE;interaction techniques;collaborative work;manipulation change;collaborative systems;communication channels;task goals;task decomposition;collaborative task;assembly task;virtual teams;guidance navigation aids;arrows-casting;3-dimensional map-liner;Dijkstra algorithm;college students","","","","44","CCBY","21 Oct 2019","","","IEEE","IEEE Journals"
"Framework for haptic interaction with virtual avatars","P. Evrard; F. Keith; J. Chardonnet; A. Kheddar","AIST/CNRS Joint Japanese-French Robotics Laboratory, Tsukuba, Japan; AIST/CNRS Joint Japanese-French Robotics Laboratory, Tsukuba, Japan; AIST/CNRS Joint Japanese-French Robotics Laboratory, Tsukuba, Japan; AIST/CNRS Joint Japanese-French Robotics Laboratory, Tsukuba, Japan","RO-MAN 2008 - The 17th IEEE International Symposium on Robot and Human Interactive Communication","15 Aug 2008","2008","","","15","20","In this paper we present an integrative frame work centered on haptic interaction with virtual avatars. This framework is devised for general prototyping and collaborative scenario studies with haptic feedback. First we present the software architecture of the framework and give details on some of its components. Then we show how this framework can be used to derive in a short time a virtual reality simulation. In this simulation, a user directly interacts with a virtual avatar to collaboratively manipulate a virtual object, with haptic feedback and using fast dynamics computation and constraint based methods with friction.","1944-9437","978-1-4244-2212-8","10.1109/ROMAN.2008.4600636","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4600636","","Robots","avatars;feedback;haptic interfaces;software architecture","haptic interaction;virtual avatars;general prototyping;collaborative scenario;haptic feedback;software architecture;virtual reality simulation;virtual object","","8","","12","","15 Aug 2008","","","IEEE","IEEE Conferences"
"Humanoid Audio–Visual Avatar With Emotive Text-to-Speech Synthesis","H. Tang; Y. Fu; J. Tu; M. Hasegawa-Johnson; T. S. Huang","Beckman Inst. for Adv. Sci. & Technol., Univ. of Illinois at Urbana-Champaign, Urbana, IL; Beckman Inst. for Adv. Sci. & Technol., Univ. of Illinois at Urbana-Champaign, Urbana, IL; Beckman Inst. for Adv. Sci. & Technol., Univ. of Illinois at Urbana-Champaign, Urbana, IL; Beckman Inst. for Adv. Sci. & Technol., Univ. of Illinois at Urbana-Champaign, Urbana, IL; Beckman Inst. for Adv. Sci. & Technol., Univ. of Illinois at Urbana-Champaign, Urbana, IL","IEEE Transactions on Multimedia","24 Oct 2008","2008","10","6","969","981","Emotive audio-visual avatars are virtual computer agents which have the potential of improving the quality of human-machine interaction and human-human communication significantly. However, the understanding of human communication has not yet advanced to the point where it is possible to make realistic avatars that demonstrate interactions with natural-sounding emotive speech and realistic-looking emotional facial expressions. In this paper, We propose the various technical approaches of a novel multimodal framework leading to a text-driven emotive audio-visual avatar. Our primary work is focused on emotive speech synthesis, realistic emotional facial expression animation, and the co-articulation between speech gestures (i.e., lip movements) and facial expressions. A general framework of emotive text-to-speech (TTS) synthesis using a diphone synthesizer is designed and integrated into a generic 3-D avatar face model. Under the guidance of this framework, we therefore developed a realistic 3-D avatar prototype. A rule-based emotive TTS synthesis system module based on the Festival-MBROLA architecture has been designed to demonstrate the effectiveness of the framework design. Subjective listening experiments were carried out to evaluate the expressiveness of the synthetic talking avatar.","1941-0077","","10.1109/TMM.2008.2001355","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637888","Audio–visual avatar;emotive speech synthesis;human–computer interaction;multimodal system;3–D face modeling and animation;TTS","Avatars;Speech synthesis;Facial animation;Humans;Face;Government;Man machine systems;Synthesizers;Prototypes;Intelligent agent","avatars;computer animation;human computer interaction;speech synthesis;virtual reality","humanoid audio-visual avatar;emotive text-to-speech synthesis;virtual computer agents;human-machine interaction;human-human communication;natural-sounding emotive speech;generic 3-D avatar face model","","16","4","36","","3 Oct 2008","","","IEEE","IEEE Journals"
"SEMAS: A new simulation module for AC drive systems","A. Ba-Razzouk; K. Debebe; T. Rafesthain; V. Rajagopalan","Groupe de Recherche en Électronique Industrielle (G.R.É.I.), Université du Québec à Trois-Rivières, C.P. 500, Trois-Rivières, Qué. G9A 5H7; Groupe de Recherche en Électronique Industrielle (G.R.É.I.), Université du Québec à Trois-Rivières, C.P. 500, Trois-Rivières, Qué. G9A 5H7; Groupe de Recherche en Électronique Industrielle (G.R.É.I.), Université du Québec à Trois-Rivières, C.P. 500, Trois-Rivières, Qué. G9A 5H7; Groupe de Recherche en Électronique Industrielle (G.R.É.I.), Université du Québec à Trois-Rivières, C.P. 500, Trois-Rivières, Qué. G9A 5H7","Canadian Journal of Electrical and Computer Engineering","13 Sep 2013","1993","18","4","181","189","The paper presents an adaptation of the general-purpose SIMNON software for the study of alternating-current drives. With the objective of designing and dimensioning converter-AC machine-regulator systems, a simulation module named SEMAS is constructed in modular form using SIMNON. This software package shows great capabilities in terms of computing power, optimization, robustness of the algorithms and graphical interaction. Asynchronous and synchronous machine models implemented in SEMAS are presented. The different methods for modelling static converters and switches, with the particularities of each, are also presented. The results show evidence of a good agreement between simulations and experiments.","0840-8688","","10.1109/CJECE.1993.6593945","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6593945","","Gold;Stators;Commutation;Rotors;Adaptation models;Computational modeling;EMTP","AC machines;digital simulation;electric drives;electric machine analysis computing;power convertors;software packages;switches","simulation module;AC drive systems;SEMAS;general-purpose SIMNON software;alternating-current drives;dimensioning;converter-AC machine-regulator systems;design;software package;computing power;optimization;robustness;algorithms;graphical interaction;synchronous machine models;asynchronous machine models;static converters;switches","","2","","","","13 Sep 2013","","","IEEE","IEEE Journals"
"Lessons from Digital Puppetry: Updating a Design Framework for a Perceptual User Interface","J. Ferguson","Fac. of Sci. & Technol., Univ. of Westminster, London, UK","2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing","28 Dec 2015","2015","","","1590","1595","While digital puppeteering is largely used just to augment full body motion capture in digital production, its technology and traditional concepts could inform a more naturalized multi-modal human computer interaction than is currently used with the new perceptual systems such as Kinect. Emerging immersive social media networks with their fully live virtual or augmented environments and largely inexperienced users would benefit the most from this strategy. This paper intends to define digital puppeteering as it is currently understood, and summarize its broad shortcomings based on expert evaluation. Based on this evaluation it will suggest updates and experiments using current perceptual technology and concepts in cognitive processing for existing human computer interaction taxonomy. This updated framework may be more intuitive and suitable in developing extensions to an emerging perceptual user interface for the general public.","","978-1-5090-0154-5","10.1109/CIT/IUCC/DASC/PICOM.2015.239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363285","digital puppeteering;perceptual user interface;motion capture;cognitive;multi-modal;immersive;social media","Software;Animation;Production;Sensors;Hardware;User interfaces;Motion segmentation","augmented reality;human computer interaction;image motion analysis;image sensors;social networking (online);user interfaces","digital puppetry;design framework;perceptual user interface;digital puppeteering;full body motion capture;digital production;naturalized multimodal human computer interaction;Kinect;immersive social media networks;fully live virtual environments;augmented environments;cognitive processing;human computer interaction taxonomy","","","","22","","28 Dec 2015","","","IEEE","IEEE Conferences"
"Development and validation of a general vehicle dynamics simulation (NUCARS)","F. B. Blader; J. A. Elkins; N. G. Wilson; P. E. Klauser","Transangle, Concord, MA, USA; NA; NA; NA","Proceedings., Technical Papers Presented at the IEEE/ASME Joint Railroad Conference","6 Aug 2002","1989","","","39","46","NUCARS (New and Untried Car Analytic Regime Simulation) is a general-purpose program for modeling rail vehicle transient and steady-state response. NUCARS models the interaction of an arbitrary number of rigid or flexible bodies joined by suspension-element-type connections. Means are provided for varying the number and identity of the degrees of freedom chosen for each body. The potential choices include all translational and rotational body degrees of freedom and the first flexible modes (for all bodies, excluding the wheelsets) in twist and in vertical and lateral bending. All connections must be assigned a stiffness and/or damping characteristic. Rigid connections are given large stiffnesses. The representation of connection location and of forces through the connections is chosen to minimize the program memory required. NUCARS is coded in Fortran 77 for use on IBM-compatible personal computers. Three vehicle dynamics applications are presented, including results of validation testing with a lightweight, two-axle, intermodal car.","","","10.1109/RRCON.1989.77279","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=77279","","Vehicle dynamics;Analytical models;Rails;Vehicles;Transient analysis;Steady-state;Damping;Microcomputers;Application software;Testing","digital simulation;railways;transients","IBM-compatible personal computers;Fortran 77;New and Untried Car Analytic Regime Simulation;NUCARS;rail vehicle steady state response modeling;rail vehicle transient response modeling","","6","","12","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Video game experience and basic robotic skills","A. Tanaka; R. Smith; C. Hughes","The Nicholson Center, Florida Hospital, Celebration, US; The Nicholson Center, Florida Hospital, Celebration, US; Department of Computer Science, The University of Central Florida, Orlando, US","2016 IEEE International Conference on Serious Games and Applications for Health (SeGAH)","10 Oct 2016","2016","","","1","6","Virtual reality simulators have emerged as valuable tools for standardized and objective robotic surgery skill training and assessments. In recent years the idea of using video game technology in surgical education for laparoscopy has also been explored, however few have attempted to make a connection between video game experience and robotic surgical skills. Thus, the current study aims to examine the performance of video gamers in a virtual reality robotic surgery simulator. Furthermore, the video gamers' performance was compared to that of medical students, expert robotic surgeons, and “laypeople.” The purpose of this study is to demonstrate that video gamers acquire perceptual and psychomotor skills through video game play, similar to those used by robotic surgeons. Subjects completed a demographic questionnaire and performed three computer-based perceptual tests: a Flanker compatibility task, a subsidizing task, and a Multiple Object Tracking test. Participants then performed two warm-up exercises and eight trials of two core exercises on a robotic surgery simulator. After completing all trials, participants completed a post-questionnaire regarding their experience with the system. Expert video gamers (n=40), medical students (n=24), laypeople (n=42) and expert robotic surgeons (n=16) were recruited. Medical students and gamers were significantly faster than experts in the Flanker Task. The experts were significantly slower than the all other groups in the subsidizing task. Experts scored significantly higher, were significantly more efficient, and were significantly faster than laypeople, medical students, and gamers in the first trial of Ring & Rail 1 and Suture Sponge. In trial eight of the simulation exercises, the experts performed significantly better than most groups in all of the metrics. Contrary to prior literature in laparoscopy, this study was unable to validate enhanced abilities of video gamers in a robotic surgery simulator. This study does further demonstrate that the transfer of skills developed through video game play is relevant to the surgical technique. This may be due to the differences of the systems and how the users interact within them. In a society where video games have become an integral past time, it is important to determine the role that video games play in the perceptual and psychomotor development of users. These findings can be generalized to domains outside of medicine that utilize robotic and computer-controlled systems, speaking to the scope of the gamers' abilities and pointing to the capacity within these systems.","","978-1-5090-2210-6","10.1109/SeGAH.2016.7586262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586262","","Surgery;Robots;Measurement;Games;Training;Rails;Cameras","biomedical education;computer aided instruction;computer games;educational robots;human-robot interaction;medical computing;medical robotics;surgery;virtual reality","video game experience;basic robotic skills;virtual reality robotic surgery simulator;standardized robotic surgery skill training;objective robotic surgery skill training;standardized robotic surgery skill assessment;objective robotic surgery skill assessment;surgical education;laparoscopy;video game technology;perceptual skill acquisition;psychomotor skill acquisition;computer-based perceptual tests;flanker compatibility task;subsidizing task;multiple object tracking test;computer-controlled systems","","1","","17","","10 Oct 2016","","","IEEE","IEEE Conferences"
"You'll be Great: Virtual Agent-based Cognitive Restructuring to Reduce Public Speaking Anxiety","E. Kimani; T. Bickmore; H. Trinh; P. Pedrelli","Khoury College of Computer Sciences, Northeastern University,Boston,Massachusetts,USA; Khoury College of Computer Sciences, Northeastern University,Boston,Massachusetts,USA; Khoury College of Computer Sciences, Northeastern University,Boston,Massachusetts,USA; Massachusetts General Hospital,Boston,Massachusetts,USA","2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)","9 Dec 2019","2019","","","641","647","Public speaking is an essential task for success in many careers, yet fear of public speaking makes this an undesirable activity for most people and negatively affects the quality of many presentations. Cognitive behavioral therapy is an effective tool for helping people overcome social anxieties disorders, including public speaking anxiety. However, most people do not engage in this therapy for public speaking anxiety, due to time constraints and other barriers. We present a virtual coach that uses cognitive behavioral therapy techniques to help presenters restructure irrational thoughts associated with public speaking anxiety. The design of the virtual coach was informed by an analysis of a corpus of cognitive restructuring examples generated by a clinical psychologist. In a between-subjects experiment comparing the virtual coach to a control condition, the virtual coach was shown to be significantly better at reducing thoughts associated with speech anxiety and improving a presentation experience for speakers.","2156-8111","978-1-7281-3888-6","10.1109/ACII.2019.8925438","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8925438","embodied conversational agents;intelligent interactions;virtual agents;cognitive behavioral therapy;natural language generation;public speaking anxiety","Public speaking;Medical treatment;Employee welfare;Task analysis;Psychology;Natural languages;Physiology","cognition;patient treatment;psychology;speech recognition;virtual reality","speech anxiety;clinical psychologist;virtual agent-based cognitive restructuring;cognitive behavioral therapy techniques;virtual coach;public speaking anxiety;social anxieties disorders","","","","37","","9 Dec 2019","","","IEEE","IEEE Conferences"
"A Space Efficient Clustered Visualization of Large Graphs","M. L. Huang; Q. V. Nguyen","University of Technology, Australia; University of Technology, Australia","Fourth International Conference on Image and Graphics (ICIG 2007)","4 Sep 2007","2007","","","920","927","This paper proposes a new technique for visualizing large graphs of several ten thousands of vertices and edges. To achieve the graph abstraction, a hierarchical clustered graph is extracted from a general large graph based on the community structures which are discovered in the graph. An enclosure geometrical partitioning algorithm is then applied to achieve the space optimization. For graph drawing, we technically use the combination of a spring-embbeder algorithm and circular drawings that archives the goal of optimization of display space and aesthetical niceness. We also discuss an associated interaction mechanism accompanied with the layout solution. Our interaction not only allows users to navigate hierarchically up and down through the entire clustered graph, but also provides a way to navigate multiple clusters concurrently. Animation is also implemented to preserve users' mental maps during the interaction.","","978-0-7695-2929-5","10.1109/ICIG.2007.10","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4297211","","Visualization;Large screen displays;Navigation;Clustering algorithms;Partitioning algorithms;Space technology;Data mining;Large-scale systems;World Wide Web;Graphics","data visualisation;graph theory;human computer interaction;optimisation;pattern clustering;user interfaces","enclosure geometrical partitioning algorithm;space optimization;graph drawing;user interaction;computer animation;hierarchical clustered graph visualization;human computer interaction","","7","1","22","","4 Sep 2007","","","IEEE","IEEE Conferences"
"Robust dynamic hand gesture recognition system with sparse steric haar-like feature for human robot interaction","C. Liu; Y. Chen; L. Fu","Department of Computer Science and Information Engineering, National Taiwan University, Taiwan, ROC; Department of Computer Science and Information Engineering, National Taiwan University, Taiwan, ROC; Department of Computer Science and Information Engineering, National Taiwan University, Taiwan, ROC","2016 55th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE)","21 Nov 2016","2016","","","148","153","Hand gesture is an effective and natural way for human-robot interaction (HRI). This paper presents a robust dynamic hand gesture recognition system with a RGB-D sensor. In order to automatically recognize hand gesture from color and depth sequences, where noise and occlusion are common problems, we extract steric Haar-like features to robustly represent the complicated spatial information of the hand. A novel feature selection approach, which takes the advantage of class separability measure, is employed to effectively ferret out the most discriminative features. We also use sparse coding method to encode these features so that it is less prone to over-fitting even when only limited amount of training data are available. Generally speaking, spare Steric Haar-like (SSH) features are efficient to compute by using the self-padding integral volume, in addition to the advantage of robustness to noise and occlusion. These crucial features significantly improve the performance of tracking and classification. Experiments with a public dynamic hand gesture dataset and a self-built hand gesture dataset show the superiority of the proposed system compared with the state-of-the-art approaches.","","978-4-907764-50-0","10.1109/SICE.2016.7749213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7749213","Human Interfaces;Robotic and Automation Systems;Virtual Reality Systems","Feature extraction;Three-dimensional displays;Gesture recognition;Robustness;Data mining;Thumb","feature selection;gesture recognition;Haar transforms;human-robot interaction","robust dynamic hand gesture recognition system;sparse steric Haar-like feature;human robot interaction;novel feature selection approach;sparse coding method;self-padding integral volume;RGB-D sensor;class separability measure","","2","","33","","21 Nov 2016","","","IEEE","IEEE Conferences"
"Graphical simulation and high-level control of humanoid robots","J. J. Kuffner; S. Kagami; M. Inaba; H. Inoue","Dept. of Mechano-Inf., Tokyo Univ., Japan; NA; NA; NA","Proceedings. 2000 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2000) (Cat. No.00CH37113)","6 Aug 2002","2000","3","","1943","1948 vol.3","Physically-based simulation software is commonly used for developing and testing low-level robot control algorithms. In order to facilitate the development and evaluation of higher-level robot behaviors, broader-based simulations are needed. Examples include software for simulating 3D vision, motion planning for obstacle avoidance, and integrating vision and planning. In addition to modeling the general interaction between the robot and its environment, the software can be used as a graphical user interface for directly controlling or interacting with a robot operating in the real world. This paper describes our current efforts toward building a large-scale software simulation framework for the development and testing of high-level behaviors for humanoid robots. We view this as a potential useful tool for the visualization and development of robotic systems, as well as an interactive, task-level programming interface for robots.","","0-7803-6348-5","10.1109/IROS.2000.895255","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=895255","","Robot control;Humanoid robots;Software testing;Computational modeling;Robot sensing systems;Orbital robotics;Motion planning;Computer architecture;Legged locomotion;Visualization","legged locomotion;digital simulation;engineering graphics;robot vision;collision avoidance;graphical user interfaces;robot programming;interactive programming","graphical simulation;high-level control;humanoid robots;simulation software;low-level robot control algorithms;broader-based simulations;3D vision;motion planning;obstacle avoidance;graphical user interface;GUI;large-scale software simulation framework;robotic system visualization;robotic system development;interactive task-level programming interface","","9","","18","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Hybrid multi-agent system simulations: Cognitive and social agents","A. Caballero; J. Botía","Universidad Católica San Antonio, Guadalupe, Murcia 30107; Universidad de Murcia, Espinardo, Murcia 30100","2012 Federated Conference on Computer Science and Information Systems (FedCSIS)","20 Nov 2012","2012","","","1231","1238","Simulating social and cognitive agent abilities is a very important aspect of agent-based computing. Multi-Agent Based Social Simulations (MABSS) could benefit from incorporating cognitive behaviours. A hybrid simulating approach, considering social and cognitive abilities, provides a more realistic basis for modelling agents and their social interactions. But, how social and cognitive behaviours could be supported simultaneously in MABSS? Is it always advantageous using cognitive capabilities into social simulations? This paper offers a set of general considerations about how cognitive capabilities could be integrated into social multi-agent simulations. It points out the most relevant cognitive requirements of social simulations of a great amount of real scenarios where some agents could carry out cognitive processing while others (a great majority) behave in reactive way. The suitability of several alternatives for integrating social and cognitive capabilities of agents are discussed. The paper also offers several efficiency related arguments and recommendations for using one of the three considered approaches.","","978-83-60810-48-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6354371","","Cognition;Computational modeling;Computer architecture;Programming;Planning;Process control;Multiagent systems","cognitive systems;digital simulation;multi-agent systems","hybrid multiagent system simulations;social agent abilities;cognitive agent abilities;agent-based computing;multiagent based social simulations;MABSS;cognitive behaviours;agent modelling;social interactions;social behaviours;social simulations","","","","24","","20 Nov 2012","","","IEEE","IEEE Conferences"
"Real-time photometric registration from arbitrary geometry","L. Gruber; T. Richter-Trummer; D. Schmalstieg","Graz University of Technology, Austria; Graz University of Technology, Austria; Graz University of Technology, Austria","2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","7 Jan 2013","2012","","","119","128","Visually coherent rendering for augmented reality is concerned with seamlessly blending the virtual world and the real world in real-time. One challenge in achieving this is the correct handling of lighting. We are interested in applying real-world light to virtual objects, and compute the interaction of light between virtual and real. This implies the measurement of the real-world lighting, also known as photometric registration. So far, photometric registration has mainly been done through capturing images with artificial light probes, such as mirror balls or planar markers, or by using high dynamic range cameras with fish-eye lenses. In this paper, we present a novel non-invasive system, using arbitrary scene geometry as a light probe for photometric registration, and a general AR rendering pipeline supporting real-time global illumination techniques. Based on state of the art real-time geometric reconstruction, we show how to robustly extract data for photometric registration to compute a realistic representation of the real-world diffuse lighting. Our approach estimates the light from observations of the reconstructed model and is based on spherical harmonics, enabling plausible illumination such as soft shadows, in a mixed virtual-real rendering pipeline.","","978-1-4673-4662-7","10.1109/ISMAR.2012.6402548","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402548","H.5.1 [Information Interfaces and Presentation]: Artificial, augmented,Virtual Realities—;I.4.8 [Image Processing and Computer Vision]: Photometric registration—3D Reconstruction;I.3.3 [Computer Graphics]: Image Generation—Spherical Harmonics","Lighting;Rendering (computer graphics);Estimation;Geometry;Cameras;Mathematical model;Real-time systems","augmented reality;cameras;image registration;rendering (computer graphics)","real time photometric registration;visually coherent rendering;augmented reality;virtual world;artificial light probes;mirror balls;planar markers;dynamic range cameras;fish eye lenses;noninvasive system;arbitrary scene geometry;real time global illumination;real time geometric reconstruction;realistic representation;real world diffuse lighting;reconstructed model;spherical harmonics;mixed virtual real rendering pipeline","","48","6","20","","7 Jan 2013","","","IEEE","IEEE Conferences"
"Hybrid agent-based simulation for analyzing the National Airspace System","Seungman Lee; A. Pritchett; D. Goldsman","Sch. of Ind. & Syst. Eng., Georgia Inst. of Technol., Atlanta, GA, USA; NA; NA","20th DASC. 20th Digital Avionics Systems Conference (Cat. No.01CH37219)","6 Aug 2002","2001","2","","6E1/1","6E1/10 vol.2","Hybrid agent-based simulation is required to provide a mechanism for analyzing large-scale complex systems, such as the National Airspace System (NAS), more accurately and completely. The dynamic behavior of many large-scale complex systems is, in general, hybrid in nature and thus can be best described by a combination of discrete-event and continuous-time models, and their interactions. Correspondingly, hybrid agent-based simulation capable of incorporating different types of models, such as continuous-time and discrete-event models, provides an accurate means of evaluating the reliability and performance of large, complex systems. However, in order to serve as a valuable design and analysis tool, a number of important issues must be addressed. This paper outlines issues in the development of hybrid agent-based simulation architectures capable of providing a scaleable mechanism for simulating the NAS. In particular, an object-oriented approach to hybrid agent-based simulation is described. In addition, methods of improving computational efficiency of updating the simulation are described and compared.","","0-7803-7034-1","10.1109/DASC.2001.964178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=964178","","Analytical models;Computational modeling;Predictive models;Large-scale systems;Discrete event simulation;Aircraft navigation;Computer architecture;Aerospace control;Communication system control;Control systems","air traffic control;software agents;aerospace control;digital simulation;large-scale systems;aerospace computing;synchronisation;software architecture","hybrid agent-based simulation;large-scale complex systems;National Airspace System;dynamic behavior;continuous-time models;discreteevent models;reliability;performance;resynchronization","","","","19","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Limb-vector paralleling: A general approach to translate postures from human to humanoid robots","Z. Bao; S. Chen; C. Tung; R. Y. Tara; H. Fabroyir; W. Teng","Networked Robotics Laboratory, Dept. of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan; Networked Robotics Laboratory, Dept. of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan; Networked Robotics Laboratory, Dept. of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan; Networked Robotics Laboratory, Dept. of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan; Networked Robotics Laboratory, Dept. of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan; Networked Robotics Laboratory, Dept. of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan","2014 International Conference on Advanced Robotics and Intelligent Systems (ARIS)","7 Aug 2014","2014","","","51","55","Developing intuitive interface to control humanoid robots with high degrees-of-freedom (DOF) in real-time remains as an essential issue. Since most humanoid robots have at least sixteen DOF, achieving real-time performance in controlling humanoid robot posture is hard to accomplish. This paper proposes a method to calculate joint angles of humanoid robots according to human's joint locations tracked by a motion capture system. The objective is to make the humanoid robot imitating human posture in real-time. Our proposed method requires a human motion capture system that could provide at least thirteen 3D joint positions: a pair of arm (shoulder, elbow, hand), a pair of leg (hip, knee, ankle), and a torso. Every joint that interconnects two limbs has to have two DOF. Our proposed method is implemented on RoboBuilder humanoid robot. The experimental results show that the robot can imitate human posture in real-time correctly. Moreover, the results verify that the proposed method is applicable to different type of humanoid robots using WeBots simulation software.","","978-1-4799-5846-7","10.1109/ARIS.2014.6871491","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6871491","","Joints;Humanoid robots;Vectors;Conferences;Real-time systems;Kinematics","humanoid robots;human-robot interaction;motion control","limb-vector paralleling;human-humanoid robot posture translation;humanoid robot posture control;human joint location tracking;human motion capture system;RoboBuilder humanoid robot;WeBots simulation software","","","","16","","7 Aug 2014","","","IEEE","IEEE Conferences"
"Design, development and testing of cooperative avionics algorithms in low-cost research and development simulation environment","A. Plutov; A. Pinsky","Israel Aircraft Ind. Ltd., Ben Gurion, Israel; NA","Proceedings of the IEEE 1998 National Aerospace and Electronics Conference. NAECON 1998. Celebrating 50 Years (Cat. No.98CH36185)","6 Aug 2002","1998","","","361","366","This paper investigates design, development and testing of new cooperative avionics algorithms (CAAs) in low-cost research and development (R&D) simulation environment These CAAs may be later implemented in avionics systems. Interaction of cooperative avionics algorithms in a complex systems requires off-line simulations at various development stages to achieve a reasonable estimation of system behavior with new CAAs. The R&D stage of CAAs in general does not require use of visual systems and pilot-in-the-loop, thus enabling possible use of low-cost simulator, which at the same time should be modular and easy-in-use. After developing and testing these CAA's in low-cost simulated environment, it is possible to transfer the models to other, more complicated systems with visual aids and pilot-in-the-loop for further development. In this paper use of low-cost simulator is shown on examples of Data Link (DL) and Sensor Fusion (SF) algorithms' development.","0547-3578","0-7803-4449-9","10.1109/NAECON.1998.710137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=710137","","Algorithm design and analysis;Testing;Aerospace electronics;Costs;Computer aided analysis;Research and development;Aircraft;Sensor fusion;Sensor systems;Resource management","avionics;aerospace computing;digital simulation;aerospace simulation;sensor fusion","cooperative avionics algorithms;simulation environment;off-line simulation;pilot-in-the-loop;data link;sensor fusion","","","","2","","6 Aug 2002","","","IEEE","IEEE Conferences"
"The Study of Model for Two-Handed Pointing Tasks in Pen + Touch Interfaces","J. Yin; W. Xu; L. Pi","Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Kunming, China; Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Kunming, China; Faculty of Information Engineering and Automation, Kunming University of Science and Technology, Kunming, China","IEEE Access","10 Mar 2021","2021","9","","38087","38096","In pen + touch interfaces, two-handed pointing tasks are quite basic. We focus on two-handed pointing tasks on a stationary touchable tablet under asynchronous conditions, in which another target will not appear until one target is touched and dwelled. Fitts' law cannot accurately model such pointing tasks based on the results of our pilot study. This paper seeks to establish an ergonomics model for bimanual pointing tasks under asynchronous interaction. We designed and implemented three experiments with bimanual pointing tasks varying the target widths and distances. A series of bimanual pointing tasks with ten different IDs (Index of Difficulty) were carried out by 18 participants. The movement time (MT) and errors were collected and analyzed. Through experiments, we found that the index of difficulty of pointing tasks has a significant impact on MT (F9,170 = 6.276, p <; 0.001). Our proposed model achieves a fit of R2 = 0.973, while the Fitts' law model only achieves a fit of R2 = 0.623. The experimental results show that our model has a strong effectiveness and applicability for bimanual pointing tasks in pen + touch interfaces.","2169-3536","","10.1109/ACCESS.2021.3063882","National Natural Science Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9369395","Bimanual interaction;pen + touch;pointing tasks;human ergonomics model","Task analysis;Ergonomics;Thumb;Solid modeling;Performance evaluation;Mobile handsets;Computational modeling","haptic interfaces;human computer interaction;interactive devices;notebook computers;touch sensitive screens","bimanual pointing tasks;two-handed pointing tasks;pen + touch interfaces;stationary touchable tablet;ergonomics model;asynchronous interaction;IDs;index of difficulty;movement time;MT;Fitts law","","","","40","CCBY","4 Mar 2021","","","IEEE","IEEE Journals"
"Designing user interfaces for different user groups: A three-way teleconference system for doctors, patients and assistants using a Remote Medical robot","G. Stollnberger; M. Giuliani; N. Mirnig; M. Tscheligi; K. Arent; B. Kreczmer; F. Grzeszczak; D. Szczesniak-Stanczyk; R. Zarczuk; A. Wysokinski","Center for Human-Computer Interaction, Department of Computer Sciences, University of Salzburg, Austria; Center for Human-Computer Interaction, Department of Computer Sciences, University of Salzburg, Austria; Center for Human-Computer Interaction, Department of Computer Sciences, University of Salzburg, Austria; Center for Human-Computer Interaction, Department of Computer Sciences, University of Salzburg, Austria; Cybernetics and Robotics, Wroclaw University of Technology, Poland; Cybernetics and Robotics, Wroclaw University of Technology, Poland; Cybernetics and Robotics, Wroclaw University of Technology, Poland; Department of Cardiology, Medical University of Lublin, Poland; Department of Cardiology, Medical University of Lublin, Poland; Department of Cardiology, Medical University of Lublin, Poland","2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","17 Nov 2016","2016","","","612","617","We present the design for a three-way medical teleconference system for communication between a doctor, a patient, and an assistant. The system includes individual doctor-patient and doctor-assistant communication channels, as well as the capability of starting and stopping communication channels separately. The initial system design is based on results of a user requirement analysis. To evaluate the design, we conducted two user studies in which doctors, assistants, and patients used our teleconference system in a simulated examination scenario. The study results show that the general usability of our system was rated as good. However, doctors, patients, and assistants reported that they would like to receive better visualisation of the connection status for the communication channels and the system status of the robot in general. Based on these results, we present an updated design for the teleconference system. We also provide best practices which can help designers of medical teleconference systems.","1944-9437","978-1-5090-3929-6","10.1109/ROMAN.2016.7745181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745181","","Medical services;Robots;Medical diagnostic imaging;Graphical user interfaces;Communication channels;Interviews","biomedical communication;control engineering computing;medical robotics;teleconferencing;user interfaces","user interfaces;user groups;three-way teleconference system;remote medical robot;doctors;patients;three-way medical teleconference system;doctor-patient communication channels;doctor-assistant communication channels;user requirement analysis;simulated examination scenario;connection status","","3","","23","","17 Nov 2016","","","IEEE","IEEE Conferences"
"Simulation of human-oriented production systems considering workers' cooperation","Y. Okuda; Y. Nakamura; M. Kishi; N. Ishikawa; M. Hitomi","Mechatronics Res. Center, SANYO Electr. Co. Ltd., Osaka, Japan; NA; NA; NA; NA","8th IEEE International Workshop on Robot and Human Interaction. RO-MAN '99 (Cat. No.99TH8483)","6 Aug 2002","1999","","","381","386","The needs of customers with regard to manufactured products are likely to continue becoming more diverse. One way to handle the diverse requirements of individual customers is configuration to order (CTO) and the only way to make this a reality is to shift to extremely diverse, small-lot manufacturing. In the general shift from mass production to highly diverse, small-lot production, human-oriented production processes such as U-lines and manufacturing cells have been utilized to increasing effect. This success is due to using human abilities such as ""cooperation"" to give the production process a great deal of flexibility. In order to bring to reality the extremely diverse, small-lot manufacturing systems that can make configuration to order a reality it is desirable to construct human-oriented production processes that are both worker-friendly and make good use of the workers' abilities. For that reason, there is a demand for ways of quantitatively evaluating cooperation and other human factors in the manufacturing process. The present research has modeled the cooperative behavior of autonomous people in a human oriented production process, applied the cooperation model to production simulation, and evaluated it.","","0-7803-5841-4","10.1109/ROMAN.1999.900370","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=900370","","Production systems;Productivity;Virtual manufacturing;Process design;Human factors;Computational modeling;Assembly systems;Flow production systems;Mass production;Production facilities","human factors;flexible manufacturing systems;digital simulation","human-oriented production systems;workers' cooperation;configuration to order;extremely diverse small-lot manufacturing;human-oriented production processes;U-lines;manufacturing cells;manufacturing process;production simulation;autonomous people","","2","","4","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Cleansed PHAT GCC based sound source localization","S. Lee; Y. Park; Y. Park","Department of Mechanical Engineering, KAIST, Deajeon, Korea; Department of Mechanical Engineering, KAIST, Deajeon, Korea; Department of Mechanical Engineering, KAIST, Deajeon, Korea","ICCAS 2010","17 Dec 2010","2010","","","2051","2054","Sound source localization (SSL) is one of the important techniques used in various engineering fields such as monitoring and surveillance system, and so on. When SSL is utilized in robot auditory system, it is essential for Human-Robot Interaction (HRI) in that robot can recognize its working environment and what direction a speaker is locating. Generalized cross correlation (GCC) function has been frequently used for SSL due to its fast computation and less requirement of high system resources. Artificial ear which is the robot auditory hardware we are dealing with consists of 2 microphones and a single pinna structure. This is locating on the both sides of robot head where free field condition can't be applicable due to reflected wave caused by robot platform such as robot shoulder, etc. This paper has focused on modification of spatially mapped GCC function, which was proposed by B. Kwon, for application into artificial ear structure. We proposed cleansed PHAT GCC function for use in spatially mapped GCC method. Cleansed PHAT GCC function combines cleansing method and conventional PHAT GCC function for eliminating reflected wave which causes free field condition break down. Simulation results using proposed cleansed PHAT GCC function showed that 93% SSL performance is obtainable when a single sound source exists.","","978-89-93215-02-1","10.1109/ICCAS.2010.5670119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5670119","Sound Source Localization;Cleansed PHAT GCC;Robot Artificial Ear;Spatially Mapped GCC","Robots;Microphones;Azimuth;Microwave integrated circuits;Ear;Correlation;Estimation","acoustic generators;acoustic signal detection;acoustic signal processing;correlation methods;human-robot interaction","sound source localization;monitoring system;surveillance system;robot auditory system;human-robot interaction;generalized cross correlation;PHAT GCC function;artificial ear structure;cleansing method","","","","11","","17 Dec 2010","","","IEEE","IEEE Conferences"
"Next-generation of virtual personal assistants (Microsoft Cortana, Apple Siri, Amazon Alexa and Google Home)","V. Këpuska; G. Bohouta","Electrical & Computer Engineering Department, Florida Institute of Technology, Melbourne, FL, USA; Electrical & Computer Engineering Department, Florida Institute of Technology, Melbourne, FL, USA","2018 IEEE 8th Annual Computing and Communication Workshop and Conference (CCWC)","26 Feb 2018","2018","","","99","103","One of the goals of Artificial intelligence (AI) is the realization of natural dialogue between humans and machines. in recent years, the dialogue systems, also known as interactive conversational systems are the fastest growing area in AI. Many companies have used the dialogue systems technology to establish various kinds of Virtual Personal Assistants(VPAs) based on their applications and areas, such as Microsoft's Cortana, Apple's Siri, Amazon Alexa, Google Assistant, and Facebook's M. However, in this proposal, we have used the multi-modal dialogue systems which process two or more combined user input modes, such as speech, image, video, touch, manual gestures, gaze, and head and body movement in order to design the Next-Generation of VPAs model. The new model of VPAs will be used to increase the interaction between humans and the machines by using different technologies, such as gesture recognition, image/video recognition, speech recognition, the vast dialogue and conversational knowledge base, and the general knowledge base. Moreover, the new VPAs system can be used in other different areas of applications, including education assistance, medical assistance, robotics and vehicles, disabilities systems, home automation, and security access control.","","978-1-5386-4649-6","10.1109/CCWC.2018.8301638","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8301638","Virtual Personal Assistants;Multi-modal Dialogue Systems;Gesture Recognition;Image Recognition;Image Recognition","Data models;Analytical models;Speech recognition;Speech;Knowledge based systems;Google;Cloud computing","artificial intelligence;computer aided instruction;handicapped aids;human computer interaction;interactive systems;knowledge based systems;social networking (online);virtual reality","Microsoft Cortana;Apple Siri;Amazon Alexa;Google home;Artificial intelligence;natural dialogue;interactive conversational systems;AI;Microsoft's Cortana;Apple's Siri;Google Assistant;multimodal dialogue systems;combined user input modes;manual gestures;body movement;conversational knowledge base;general knowledge base;education assistance;medical assistance;disabilities systems;home automation;virtual personal assistants;VPA model","","26","","13","","26 Feb 2018","","","IEEE","IEEE Conferences"
"Agents, believability and embodiment in advanced learning environments. Introduction to a panel discussion","A. Nijholt","Twente Univ., Enschede, Netherlands","Proceedings IEEE International Conference on Advanced Learning Technologies","7 Aug 2002","2001","","","457","459","On the World Wide Web we see a growing number of general HCI interfaces, interfaces to educational or entertainment systems, interfaces to professional environments, etc., where an animated face, a cartoon character or a human-like virtual agent has the task to assist the user, to engage the user into a conversation or to educate the user. What can be said say about the effects a human-like agent has on a student's performance? We discuss agents, their intelligence, embodiment and interaction modalities. In particular, we introduce viewpoints and questions about roles embodied agents can play in educational environments.","","0-7695-1013-2","10.1109/ICALT.2001.943978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=943978","","Intelligent agent;Intelligent systems;Animation;Virtual reality;Human computer interaction;Face;Web pages;Avatars;Computer interfaces;Software agents","intelligent tutoring systems;teaching;information resources;software agents;computer animation;human factors;interactive systems;user interfaces","advanced learning environments;World Wide Web;HCI interfaces;entertainment systems;professional environments;animated face;cartoon character;human-like virtual agent;student performance;interaction modalities;embodied agents;educational environments","","5","","13","","7 Aug 2002","","","IEEE","IEEE Conferences"
"Guidelines for speech interactions between pilot and cognitive assistant","S. Estes; J. Helleberg; K. Long; M. Pollack; M. Quezada","The MITRE Corporation McLean, VA 22102; The MITRE Corporation McLean, VA 22102; The MITRE Corporation McLean, VA 22102; The MITRE Corporation McLean, VA 22102; The MITRE Corporation McLean, VA 22102","2018 Integrated Communications, Navigation, Surveillance Conference (ICNS)","14 Jun 2018","2018","","","3H2-1","3H2-10","Over the last three years, the MITRE Corporation has been developing a cognitive assistant concept for pilots called Digital Copilot. Digital Copilot reduces pilot workload and increases safety by offloading pilot tasks, increasing task efficiency, and inferring pilot intent to provide the right information at the right time. As with many existing cognitive assistants (e.g., Amazon's Alexa or Apple's Siri), speech, both as a device input and output, is a major component of the interface. In this paper, we will introduce the Digital Copilot concept, discuss the challenges of speech-based interfaces in the cockpit, and suggest ten principals for the design of speech-based interfaces gleaned from literature review, flight testing, and simulator studies of Digital Copilot with General Aviation pilots.","","978-1-5386-5679-2","10.1109/ICNSURV.2018.8384875","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8384875","","Aircraft;Airports;Air traffic control;Speech recognition;Task analysis;Meteorology;Visualization","aerospace computing;aerospace simulation;aircraft displays;cognitive systems;speech recognition;user interfaces","speech interactions;general aviation pilots;MITRE corporation;cognitive assistant;digital copilot;cockpit;speech-based interfaces design;flight testing;simulator studies;Amazon's Alexa;Apple's Siri","","","","24","","14 Jun 2018","","","IEEE","IEEE Conferences"
"Motion control of a virtual humanoid that can perform real physical interactions with a human","K. Nagasaka; A. Miyamoto; M. Nagano; H. Shirado; T. Fukushima; M. Fujita","Department of Intelligent Systems Research Laboratory, System Technologies Laboratories, Sony Corporation, 5-1-12 Kitashinagawa Shinagawa-ku, Tokyo, 141-0001 Japan; Department of Intelligent Systems Research Laboratory, System Technologies Laboratories, Sony Corporation, 5-1-12 Kitashinagawa Shinagawa-ku, Tokyo, 141-0001 Japan; Department of Intelligent Systems Research Laboratory, System Technologies Laboratories, Sony Corporation, 5-1-12 Kitashinagawa Shinagawa-ku, Tokyo, 141-0001 Japan; Department of Intelligent Systems Research Laboratory, System Technologies Laboratories, Sony Corporation, 5-1-12 Kitashinagawa Shinagawa-ku, Tokyo, 141-0001 Japan; Department of Intelligent Systems Research Laboratory, System Technologies Laboratories, Sony Corporation, 5-1-12 Kitashinagawa Shinagawa-ku, Tokyo, 141-0001 Japan; Department of Intelligent Systems Research Laboratory, System Technologies Laboratories, Sony Corporation, 5-1-12 Kitashinagawa Shinagawa-ku, Tokyo, 141-0001 Japan","2008 IEEE/RSJ International Conference on Intelligent Robots and Systems","14 Oct 2008","2008","","","2303","2310","This paper proposes a multi-objective, highly generalized and efficient control framework for a virtual character performing various physical interactions in a dynamically simulated world. The framework comprises 1) a generalized inverse dynamics that determines joint forces satisfying multiple objectives considering priorities, unactuated joints and inequality constraints about contacts, 2) a generalized stabilizer available in various contact situations based on the long-term momentum stabilization and 3) a motion primitive network for realizing composite motions by modularizing and interconnecting motion functions. By applying the proposed framework, various interactions with a virtual humanoid, such as basic reflections and carrying objects, are realized in real time with a tactile sensation through the two-armed multi-fingered haptic device we developed.","2153-0866","978-1-4244-2057-5","10.1109/IROS.2008.4650680","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4650680","","Force;Acceleration;Joints;Jacobian matrices;Physics;Indexes;Dynamics","haptic interfaces;humanoid robots;manipulator dynamics;mobile robots;motion control;virtual reality","virtual humanoid motion control;real physical interaction;generalized inverse dynamics;unactuated joints force;long-term momentum stabilization;two-armed multifingered haptic device;tactile sensation","","2","1","30","","14 Oct 2008","","","IEEE","IEEE Conferences"
"Intuitive volume rendering on mobile devices","Y. Xin; H. Wong","Faculty of Information Technology, Macau University of Science and Technology, China; Faculty of Information Technology, Macau University of Science and Technology, China","2016 9th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)","16 Feb 2017","2016","","","696","701","Nowadays, mobile devices, virtual reality and augment reality technologies are developing faster and faster. With a variety of equipments, people are no longer only using PC to handle tasks. Some traditional system frameworks are migrating to these new technology areas, and direct volume rendering is one of them. In this paper, we propose a real-time and intuitive volume data exploration framework on mobile devices. Our framework introduces a direct-touch transfer function design method that is able for the user to pick voxels directly on a volume rendered image. With one-pass shader, user interaction and volume rendering can be handled efficiently in real-time. The user only needs to learn a few related knowledge to explore a volume data and get its rendered image. As a result, the time cost of transfer function design for direct volume rendering is significantly reduced. Our framework is implemented with OpenGL ES 3.0 and GLSL shader. Experimental results show the advantages of our framework. Researchers, and even general users, can easily obtain volume rendered images of volume data.","","978-1-5090-3710-0","10.1109/CISP-BMEI.2016.7852799","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7852799","Direct volume rendering;mobile devices;transfer function design;volume data;direct touch;user interface design","Transfer functions;Rendering (computer graphics);Mobile handsets;Histograms;Image color analysis;Two dimensional displays","augmented reality;mobile computing;rendering (computer graphics);transfer functions","mobile devices;virtual reality;augment reality;real-time intuitive volume data exploration;intuitive volume rendering;direct-touch transfer function design;one-pass shader;user interaction;OpenGL ES 3.0;GLSL shader","","","","13","","16 Feb 2017","","","IEEE","IEEE Conferences"
"A Novel Multimedia Interactive System for Public Show and Presentations","M. Gaudina; S. Schiappacasse; L. Lagomarsino; E. Bellanti; G. Vercelli","Dept. of Inf., Bioeng., Robot., & Syst. Eng., Univ. of Genoa, Genoa, Italy; Dept. of Inf., Bioeng., Robot., & Syst. Eng., Univ. of Genoa, Genoa, Italy; Circle Garage Start-up Innovativa S.R.L., Genoa, Italy; Dept. of Inf., Bioeng., Robot., & Syst. Eng., Univ. of Genoa, Genoa, Italy; Dept. of Inf., Bioeng., Robot., & Syst. Eng., Univ. of Genoa, Genoa, Italy","2014 Eighth International Conference on Complex, Intelligent and Software Intensive Systems","2 Oct 2014","2014","","","543","546","Holographic interactivity is nowadays a promising research topic within HCI field, mainly due to recent technological improvements. Moreover, low-cost off-the shelf components are widely availables, with respect to the last century situation for traditional human-machine interaction paradigms. The way of displaying information and data communication are now much more robust and solid than in the past, allowing better user experiences (Ux) than before in terms of presence and immersion. The paper presents a novel interaction system based on holographic and multi-touch technologies well suited for shows and interactive talks. The performer/presenter operates behind a vertical touch enabled transparent holographic panel where multimedia contents are projected and directly manipulated. This type of communication is much more cogent and immersive than any other, since both the presenter and the public interact facing each other with the possibility of focusing their attention on the same interspersed interactive elements. Furthermore, the system relies on a web based cross-platform framework allowing both proximal and remote interaction and visualization on smartphones, tablets and internet enabled devices in general. Preliminary interviews have underlined the goodness of this new interaction paradigm suggesting that this could be a strong base of a much larger platform for many and different uses.","","978-1-4799-4325-8","10.1109/CISIS.2014.79","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6915571","","Three-dimensional displays;Software;Tactile sensors;Business;Multimedia communication;Internet","computer aided instruction;human computer interaction;Internet;multimedia systems;touch sensitive screens","multimedia interactive system;public show;public presentation;holographic interactivity;HCI field;human computer interface;user experience;multitouch technology;holographic technology;vertical touch enabled transparent holographic panel;multimedia contents;Web based cross-platform framework;proximal interaction;remote interaction","","1","","16","","2 Oct 2014","","","IEEE","IEEE Conferences"
"Medical data analysis based on Nao robot: An automated approach towards robotic real-time interaction with human body","M. S. Sharif; M. H. Alsibai","School of Architecture, Computing and Engineering, UEL, E16 2RD, London, UK; School of Architecture, Computing and Engineering, UEL, E16 2RD, London, UK","2017 7th IEEE International Conference on Control System, Computing and Engineering (ICCSCE)","8 Feb 2018","2017","","","91","96","There is a significant increase of strokes, heart diseases and premature death, people need more than ever to be aware of their vital signs such as blood pressure, heart beats, cholesterol level etc. Monitoring and analysing this medical data can help increase the awareness of the risk factor of heart disease. However, there is a huge pressure on medical staff and general practitioners (GPs), therefore this research proposes a medical data analysis based on Nao robots to meet these needs and it will serve as an automated approach towards a robotics real-time interaction with the human body. The proposed research offers a new way to allow users to understand the meaning of their vital signs using a human robot interaction. The developed system has been tested on publicly available data and simulated data. It can predict the future risk of heart disease based on some data attributes. Based on the risk prediction, it can feedback the result and the required lifestyle changes to avoid any related risk.","","978-1-5386-3897-2","10.1109/ICCSCE.2017.8284386","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8284386","Medical Data Analysis;Artificial Intelligence;Robotic;Neural Network;Internet of Things;Lifestyle","Robots;Diseases;Blood pressure;Medical diagnostic imaging;Heart;Biomedical monitoring;Diabetes","cardiology;data analysis;diseases;human-robot interaction;medical information systems;medical robotics;patient monitoring;risk management","risk factor;heart disease;medical data analysis;Nao robot;automated approach;robotics real-time interaction;human body;vital signs;human robot interaction;data attributes","","","","36","","8 Feb 2018","","","IEEE","IEEE Conferences"
"Intelligent Objects to Facilitate Human Participation in Virtual Institutions","I. Rodriguez; A. Puig; M. Esteva; C. Sierra; A. Bogdanovych; S. Simoff","Appl. Math. Dept., Univ. of Barcelona, Barcelona; Appl. Math. Dept., Univ. of Barcelona, Barcelona; Artificial Intell. Res. Inst., Barcelona; Artificial Intell. Res. Inst., Barcelona; Sch. of Comput. & Math., Univ. of Western Sydney, Sydney, NSW; Sch. of Comput. & Math., Univ. of Western Sydney, Sydney, NSW","2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","6 Jan 2009","2008","1","","196","199","Our research combines electronic institutions and 3D virtual worlds for the construction of virtual institutions which are virtual worlds with normative regulation of interactions. That is, a virtual world where participants actions have to comply with predefined institutional rules. In this context, the actions a participant may perform depend on the institutional rules and the current execution state. We propose to include iObjects, intelligent objects, as entities having both visualization properties and decision mechanisms in the virtual institution. They are a new key element to improve users participation in virtual institutions. We situate them in a middleware infrastructure in order to be independent of 3D virtual world platform and to provide a general solution in which participants could be connected from different immersive environment platforms.","","978-0-7695-3496-1","10.1109/WIIAT.2008.320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740448","virtual environments;normative multiagent systems;virtual institutions;intelligent objects","Humans;Intelligent agent;Visualization;Artificial intelligence;Avatars;Mathematics;Software agents;Multiagent systems;Mechanical factors;Middleware","data visualisation;human computer interaction;middleware;multi-agent systems;virtual reality","intelligent objects;human participation;virtual institutions;electronic institutions;3D virtual worlds;iObjects;visualization property;middleware infrastructure","","2","","11","","6 Jan 2009","","","IEEE","IEEE Conferences"
"Power-optimized stiffness and nonlinear position control of an actuator with Variable Torsion Stiffness","P. Beckerle; J. Wojtusch; J. Schuy; B. Strah; S. Rinderknecht; O. v. Stryk","Institute for Mechatronic Systems, Department of Mechanical Engineering, Technische Universität Darmstadt, Germany; Simulation, Systems Optimization, and Robotics Group, Department of Computer Science, Technische Universität Darmstadt, Germany; Institute for Mechatronic Systems, Department of Mechanical Engineering, Technische Universität Darmstadt, Germany; Institute for Mechatronic Systems, Department of Mechanical Engineering, Technische Universität Darmstadt, Germany; Institute for Mechatronic Systems, Department of Mechanical Engineering, Technische Universität Darmstadt, Germany; Simulation, Systems Optimization, and Robotics Group, Department of Computer Science, Technische Universität Darmstadt, Germany","2013 IEEE/ASME International Conference on Advanced Intelligent Mechatronics","22 Aug 2013","2013","","","387","392","Introducing compliant actuation to robotic joints is an approach to ensure safety in closer human-machine interaction. Further, the possibility to adjust stiffness can be beneficial considering energy storage and the power consumption required to track certain trajectories. The subject of this paper is the stiffness and position control of the Variable Torsion Stiffness (VTS) actuator for application in compliant robotic joints. For the realization of a variable rotational stiffness, the active length of a torsional elastic element in serial configuration between drive and link is adjusted in VTS. After the deduction of an extended drive train model, this paper gives an advanced power analysis clarifying power-optimal settings from previous basic models and identifying additional settings that allow for a more versatile operation. Based on these results that can be generalized to other variable elastic actuator concepts, an optimized strategy for setting stiffness is determined considering the whole system dynamics including natural frequencies as well as antiresonance effects. For position control of VTS in a prototypical implementation, a nonlinear position controller is designed by means of feedback linearization. Although the system is modified significantly by changing drive train stiffness, the stiffness adaptation of the controller ensures the required tracking performance.","2159-6255","978-1-4673-5320-5","10.1109/AIM.2013.6584122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6584122","","Robots","actuators;compliant mechanisms;control system synthesis;couplings;drives;elasticity;energy storage;feedback;human-robot interaction;linearisation techniques;nonlinear control systems;position control;power consumption;torsion;trajectory control","power-optimized stiffness;nonlinear position control;variable torsion stiffness actuator;compliant actuation;robotic joints;human-machine interaction;energy storage;power consumption;trajectory tracking;stiffness control;VTS actuator;compliant robotic joints;variable rotational stiffness;torsional elastic element;serial configuration;extended drive train model;advanced power analysis;power-optimal settings;natural frequencies;antiresonance effects;VTS position control;nonlinear position controller;feedback linearization;stiffness adaptation","","14","","16","","22 Aug 2013","","","IEEE","IEEE Conferences"
"Weighted Hybrid Admittance-Impedance Control with Human Intention Based Stiffness Estimation for Human-Robot Interaction","H. Kim; J. Kwon; Y. Oh; B. J. You; W. Yang","Kwangwoon University, Seoul, Republic of Korea; Kwangwoon University, Seoul, Republic of Korea; Korea Institute of Science and Technology (KIST), Seoul, Republic of Korea; Korea Institute of Science and Technology (KIST), Seoul, Republic of Korea; Kwangwoon University, Seoul, Republic of Korea","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","6 Jan 2019","2018","","","1","6","In a human-robot interaction (HRI) device that performs physical collaboration operations in constant contact with the user, admittance control and impedance control are generally used. Since the two controllers exhibit opposite performances depending on the stiffness condition, controllers capable of dealing with various magnitudes of stiffness are required. As such, this study proposes hybrid control that adjusts the control distribution ratios of admittance control and impedance control based on the operating frequency analysis to react to the user intention and various stiffness conditions in real time. The proposed controller algorithm exhibited lower overshoot than impedance control in the step input response simulation, faster response speed compared to admittance control in the response simulation for 0-5 Hz input frequencies, and the smallest vibration magnitude and number of vibrations in the case of a virtual wall collision, resulting in improved performance compared to existing control methods.","2153-0866","978-1-5386-8094-0","10.1109/IROS.2018.8594435","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8594435","","Impedance;Admittance;Force;Manipulators;Stability analysis;Mathematical model","biomechanics;control engineering computing;elastic constants;haptic interfaces;human-robot interaction;manipulator dynamics;vibrations","human intention based stiffness estimation;HRI device;frequency analysis;input response simulation;vibration magnitude;virtual wall collision;control distribution ratios;physical collaboration operations;human-robot interaction device;weighted hybrid admittance-impedance control","","","","16","","6 Jan 2019","","","IEEE","IEEE Conferences"
"A constraint-based god-object method for haptic display","C. B. Zilles; J. K. Salisbury","Dept. of Mech. Eng., MIT, Cambridge, MA, USA; Dept. of Mech. Eng., MIT, Cambridge, MA, USA","Proceedings 1995 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human Robot Interaction and Cooperative Robots","6 Aug 2002","1995","3","","146","151 vol.3","Haptic display is the process of applying forces to a human ""observer"" giving the sensation of touching and interacting with real physical objects. Touch is unique among the senses because it allows simultaneous exploration and manipulation of an environment. A haptic display system has three main components. The first is the haptic interface, or display device, generally some type of electro-mechanical system able to exert controllable forces on the user with one or more degrees of freedom. The second is the object model-a mathematical representation of the object containing its shape and other properties related to the way it feels. The third component, the haptic rendering algorithm, joins the first two components to compute, in real time, the model-based forces to give the user the sensation of touching the simulated objects. This paper focuses on a new haptic rendering algorithm for generating convincing interaction forces for objects modeled as rigid polyhedra. We create a virtual model of the haptic interface, called the god-object, which conforms to the virtual environment. The haptic interface can then be servo-ed to this virtual model. This algorithm is extensible to other functional descriptions and lays the groundwork for displaying not only shape information, but surface properties such as friction and compliance.","","0-8186-7108-4","10.1109/IROS.1995.525876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=525876","","Haptic interfaces;Displays;Shape;Humans;Force control;Control systems;Mathematical model;Computational modeling;Rendering (computer graphics);Virtual environment","virtual reality;interactive devices","constraint-based god-object method;haptic display;haptic interface;electro-mechanical system;controllable forces;haptic rendering algorithm;rigid polyhedra","","395","88","8","","6 Aug 2002","","","IEEE","IEEE Conferences"
"The effects of compensation for scatter, lead X-rays and high-energy contamination on lesion detectability and activity estimation in Ga-67 imaging","G. El Fakhri; S. C. Moore; P. Maksud; M. F. Kijewski","Dept. of Radiol., Brigham & Women's Hosp., Boston, MA, USA; Dept. of Radiol., Brigham & Women's Hosp., Boston, MA, USA; NA; NA","2002 IEEE Nuclear Science Symposium Conference Record","27 Oct 2003","2002","3","","1784","1786 vol.3","Compton scatter, lead X-rays and high-energy contamination are major factors affecting image quality in Ga-67 imaging. Scattered photons detected in one photopeak can originate from photons emitted in the same photopeak, as well as from higher energy photons which interacted in the collimator and crystal and lost energy. Furthermore, lead X-rays can be detected in the main energy photopeak (93 keV). We have previously developed two energy-based methods, based on artificial neural networks (ANN) and on a generalized spectral fitting approach (GS), to compensate for scatter, high-energy contamination and lead X-rays in Ga-67 imaging. The aim of the present study is to evaluate under realistic conditions the impact of these phenomena and their compensation on lesion detection and estimation tasks in Ga-67 imaging. ANN and GS were compared on the basis of performance of a three-channel Hotelling observer (CHO), which incorporated internal noise, in detecting the presence of a sphere of unknown size on an anatomic background, as well as on the basis of estimation of lesion activity. Spherical lesions ranging from 2 to 6 cm in diameter, located at several sites in an anthropomorphic torso phantom, were simulated using a Monte Carlo program that modeled all photon interactions in the patient as well as in the collimator and the detector for all decays between 91 and 888 keV. One hundred noise realizations were generated from cacti very low noise simulated projection. Scatter worsened both the CHO signal-to-noise ratio (SNR) and the estimation accuracy. On average, the presence of scatter led to a 12% reduction in CHO SNR. Correcting for scatter further diminished CHO SNR but to a lesser extent with ANN (5% reduction compared to WIN) than with GS (12%). Both scatter corrections improved performance in activity estimation compared to WIN. ANN yielded better precision (1.8 vs 4%) but greater bias (5.1 vs 3.6%) than did GS.","","0-7803-7636-6","10.1109/NSSMIC.2002.1239668","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1239668","","X-ray scattering;Contamination;Lesions;X-ray detection;X-ray detectors;Optical imaging;Electromagnetic scattering;Particle scattering;Artificial neural networks;Photonic crystals","single photon emission computed tomography;neural nets;Compton effect;Monte Carlo methods;spectral analysis;electron device noise;medical image processing;phantoms;physiological models;digital simulation;X-ray scattering","Compton scatter;Pb X-rays;lesion activity estimation;lesion detectability;high-energy contamination;image quality;/sup 67/Ga SPECT imaging;scattered photons;photopeak;collimator;lesion detection tasks;lesion estimation tasks;artificial neural networks;generalized spectral fitting;performance;three-channel Hotelling observer signal-to-noise ratio;estimation accuracy;scatter corrections;internal noise;sphere;anatomic background;spherical lesions;anthropomorphic torso phantom;Monte Carlo program;photon interactions;patient;detector;noise realizations;very low noise simulated projection;2 to 6 cm;Ga","","","","6","","27 Oct 2003","","","IEEE","IEEE Conferences"
"Optimal Modality Selection for Cooperative Human–Robot Task Completion","M. G. Jacob; J. P. Wachs","School of Industrial Engineering, Purdue University, West Lafayette, IN, USA; School of Industrial Engineering, Purdue University, West Lafayette, IN, USA","IEEE Transactions on Cybernetics","20 May 2017","2016","46","12","3388","3400","Human-robot cooperation in complex environments must be fast, accurate, and resilient. This requires efficient communication channels where robots need to assimilate information using a plethora of verbal and nonverbal modalities such as hand gestures, speech, and gaze. However, even though hybrid human-robot communication frameworks and multimodal communication have been studied, a systematic methodology for designing multimodal interfaces does not exist. This paper addresses the gap by proposing a novel methodology to generate multimodal lexicons which maximizes multiple performance metrics over a wide range of communication modalities (i.e., lexicons). The metrics are obtained through a mixture of simulation and real-world experiments. The methodology is tested in a surgical setting where a robot cooperates with a surgeon to complete a mock abdominal incision and closure task by delivering surgical instruments. Experimental results show that predicted optimal lexicons significantly outperform predicted suboptimal lexicons (p <; 0.05) in all metrics validating the predictability of the methodology. The methodology is validated in two scenarios (with and without modeling the risk of a human-robot collision) and the differences in the lexicons are analyzed.","2168-2275","","10.1109/TCYB.2015.2506985","NPRP from the Qatar National Research Fund (a member of the Qatar Foundation); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7366577","Human–robot interaction (HRI);multimodal systems;Pareto optimization","Measurement;Speech;Robots;Computational modeling;Speech recognition;Cybernetics;Surgery","cooperative systems;human-robot interaction;medical robotics;Pareto optimisation;surgery","optimal modality selection;cooperative human-robot task completion;human-robot cooperation;multimodal lexicon generation;surgical setting;Pareto optimization","Algorithms;Computer Simulation;Cybernetics;Fixation, Ocular;General Surgery;Gestures;Humans;Robotics;Task Performance and Analysis;User-Computer Interface","1","","47","","25 Dec 2015","","","IEEE","IEEE Journals"
"Proof of Concept of an Assistive Robotic Arm Control Using Artificial Stereovision and Eye-Tracking","Y. -S. L. -K. Cio; M. Raison; C. Leblond Ménard; S. Achiche","Mechanical Engineering Department, Polytechnique de Montréal, Montréal, Canada; Mechanical Engineering Department, Polytechnique de Montréal, Montréal, Canada; Mechanical Engineering Department, Polytechnique de Montréal, Montréal, Canada; Mechanical Engineering Department, Polytechnique de Montréal, Montréal, Canada","IEEE Transactions on Neural Systems and Rehabilitation Engineering","10 Dec 2019","2019","27","12","2344","2352","Assistive robotic arms have become popular to help users with upper limb disabilities achieve autonomy in their daily tasks, such as drinking and grasping objects in general. Usually, these robotic arms are controlled with an adapted joystick. Joysticks are user-friendly when it comes to a general approach to an object. However, they are not as intuitive when having to accurately approach an object, especially when obstacles are present. Alternatively, the combined use of artificial stereovision and eye-tracking seems to be a promising solution, as the user's vision is usually dissociated from their upper limb disability. Hence, the objective of this study was to develop a proof of concept for the control of an assistive robotic arm using a low-cost combination of stereovision and eye-tracking. Using the developed control system, a typically developed person was able to control the robotic arm successfully reaching and grasping an object for 92% of the trials without obstacles with an average time of 13.8 seconds. Then, another set of trials with one obstacle had a success rate of 91% with an average time of 17.3 seconds. Finally, the last set of trials with two obstacles had a success rate of 98% with an average time of 18.4 seconds. Furthermore, the cost of an eye-tracker and stereovision remains below 400$.","1558-0210","","10.1109/TNSRE.2019.2950619","Natural Sciences and Engineering Research Council of Canada; Fonds de Recherche du Québec - Nature et Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887462","Collision avoidance;human-robot interaction;path planning;rehabilitation robotics;stereo vision","Manipulators;Robot sensing systems;Cameras;Rehabilitation robotics;Control systems;Human computer interaction","computer vision;control engineering computing;handicapped aids;human computer interaction;interactive devices;manipulators;medical robotics;mobile robots;stereo image processing","user-friendly;joystick;grasping objects;drinking;upper limb disability;eye-tracking;artificial stereovision;assistive robotic arm control","Adult;Artificial Limbs;Calibration;Computer Simulation;Costs and Cost Analysis;Depth Perception;Disabled Persons;Eye Movements;Humans;Male;Psychomotor Performance;Rehabilitation;Robotics;Self-Help Devices;Software;Upper Extremity;User-Computer Interface","","","62","IEEE","30 Oct 2019","","","IEEE","IEEE Journals"
"VATPA: a simulation environment for message-passing concurrent systems","H. Liu; M. T. Nyeu; D. Y. Y. Yun; W. Lin","Dept. of Electr. Eng., Hawaii Univ., Honolulu, HI, USA; Dept. of Electr. Eng., Hawaii Univ., Honolulu, HI, USA; Dept. of Electr. Eng., Hawaii Univ., Honolulu, HI, USA; Dept. of Electr. Eng., Hawaii Univ., Honolulu, HI, USA","[1992] Proceedings. The Sixteenth Annual International Computer Software and Applications Conference","6 Aug 2002","1992","","","326","331","The authors present an animation tool for visualizing the complex, dynamic behavior of parallel algorithms. The key idea behind this tool design is to abstract run-time activities and turn them into graphical representations that move and vary in location, size, and color. With proper abstractions, it establishes a technical foundation for monitoring, analyzing, and improving complex parallel algorithms. It represents animated views in an informative and coherent manner. There are two unique attributes that distinguish the animation tool from others: (1) it provides a general simulation environment for analyzing parallel algorithms with arbitrary program structures and sizes; and (2) it allows the visualization for computation status of parallel processes and their run-time interactions.<>","","0-8186-3000-0","10.1109/CMPSAC.1992.217583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=217583","","Animation;Parallel algorithms;Visualization;Algorithm design and analysis;Graphics;Computational modeling;Displays;Discrete event simulation;Runtime;Workstations","computer animation;data visualisation;digital simulation;message passing;parallel algorithms","VATPA;simulation environment;message-passing concurrent systems;animation tool;parallel algorithms;run-time activities;graphical representations;visualization;run-time interactions","","","","11","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Toolbox for exploration of energy-efficient event processors for human-computer interaction","T. Rzayev; D. H. Albonesi; F. Guimbretière; R. Manohar; J. Kihm","Computer Systems Laboratory, Cornell University, Ithaca, NY, USA; Computer Systems Laboratory, Cornell University, Ithaca, NY, USA; 2Information Science Department, Cornell University, Ithaca, NY, USA; 3Computer Systems Laboratory, Yale University, New Haven, CT, USA; 2Information Science Department, Cornell University, Ithaca, NY, USA","2017 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)","13 Jul 2017","2017","","","173","184","The advent of high speed input sensor and display technologies and the drive for faster interactive response suggests that human-computer interaction (HCI) task processing deadlines of a few milliseconds or less may be required in future handheld devices. At the same time, users will expect the same, if not better, battery life than today's devices under these more stringent response requirements. In this paper, we present a toolbox for exploring the design space of HCI event processors. We first describe the simulation platform for interactive environments that runs mobile user interface code with inputs recorded from human users. We validate it against a hardware platform from prior work. Given system-level constraints on latency, we demonstrate how this toolbox can be used to design a custom heterogeneous event processor that maximizes battery life. We show that our toolbox can pick design points that are 1.5-2.5× more energy-efficient than general-purpose big. LITTLE architectures.","","978-1-5386-3890-3","10.1109/ISPASS.2017.7975289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7975289","","Human computer interaction;Keyboards;Hardware;Time factors;Multicore processing","human computer interaction;microprocessor chips","energy efficient event processors;human-computer interaction;input sensor;display technologies;interactive response;handheld devices;battery life;HCI event processors;interactive environments;mobile user interface code;hardware platform","","","","19","","13 Jul 2017","","","IEEE","IEEE Conferences"
"System Design and Experimental Method of an Integrated Power Market Simulation System","K. Tan; H. Chen; S. Qu; Z. Jing; D. Hua",NA; NA; NA; NA; NA,"2011 Asia-Pacific Power and Energy Engineering Conference","11 Apr 2011","2011","","","1","5","Many challenging and new issues arise in China's power market process. In this paper the general and specific characteristics of power market research are analyzed and an integrated simulation system (IPMSS) based on experimental economics (EE) and agent-based computational economics (ACE) is designed. Further works include proposing a hybrid experimental method of experimenter and agent, and carrying out with different power market models configured under three experimental approaches. The IPMSS applies a hybrid mode of B/S and C/S with three layers: Client program/Web browser, application server and database server, which has a robust architecture of data communication and simulation interaction. There are three roles administrator, trainer and trainee, and all experimental process are strictly controlled. The real power market operation scenario is vividly reproduced by the flexible setting of experimental parameters and the visual experimental results. At last a regional power system is taken as an example to verify the feasibility and validity of the proposed simulation system.","2157-4847","978-1-4244-6255-1","10.1109/APPEEC.2011.5748688","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5748688","","Power markets;Computational modeling;Adaptation model;Biological system modeling;Analytical models;Humans","online front-ends;power engineering computing;power markets;user interfaces","integrated power market simulation system;China power market process;integrated simulation system;experimental economics;agent-based computational economics;hybrid experimental method;B-S;C-S;client program-Web browser;application server;database server;data communication;simulation interaction;regional power system;system design","","","","16","","11 Apr 2011","","","IEEE","IEEE Conferences"
"Towards Immersive Learning in Object-Oriented Paradigm: A Preliminary Study","F. Fernandes; C. Werner",IF Sudeste MG; COPPE/UFRJ,"2019 21st Symposium on Virtual and Augmented Reality (SVR)","5 Dec 2019","2019","","","59","68","Object-Oriented Paradigm Teaching is mandatory in the curriculum of the courses of the Computing area. Students are taught fundamental concepts about this paradigm, such as class, object, encapsulation, polymorphism, generalization and composition. One of the major challenges of Software Engineering is to teach complex and abstract concepts in a short time, with examples or simple projects done in academic environments. Virtual Reality has demonstrated advantages applied to Education, providing immersive experiences and new ways of visualization and interaction. However, this technology has not been extensively explored in Software Engineering. In this sense, this paper aims to present a disruptive method of teaching and learning support on fundamentals in object orientation paradigm based on Immersive Learning, called OO Game VR. In addition, an initial heuristic evaluation was performed with 6 subjects in order to identify usability problems. Despite problems found related to support learning, navigation and orientation, the natural expression of action and clear entry and exit points, the subjects were able to perform all the tasks, showing indications that the application has the potential to support teaching of OOP teaching through Immersive Learning. In future works, the usability problems will be fixed and specific methods will be applied for measuring influence immersion on learning outcomes.","","978-1-7281-5434-3","10.1109/SVR.2019.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8921030","immersive learning;object-oriented paradigm;software engineering education;virtual reality","Education;Games;Software engineering;Usability;Avatars;Monitoring","computer aided instruction;computer science education;educational courses;human factors;object-oriented methods;object-oriented programming;software engineering;teaching;virtual reality","complex concepts;abstract concepts;immersive experiences;learning support;object orientation paradigm;usability problems;navigation;OOP teaching;influence immersion;learning outcomes;Immersive Learning;Software Engineering;fundamental concepts;Object-Oriented Paradigm Teaching","","","","22","","5 Dec 2019","","","IEEE","IEEE Conferences"
"A preliminary analysis of analysis window size and voting size with a time delay for a robust real-time sEMG pattern recognition","M. Kim; J. Lee; H. Ko; K. Kim","Interaction& Robotics Research Center, Korea Institute of Science and Technology, 39-1 Hawolgok-dong, Seoul, 136-791, Korea; Interaction& Robotics Research Center, Korea Institute of Science and Technology, 39-1 Hawolgok-dong, Seoul, 136-791, Korea; HCI& Robotics, University of Science and Technology, 217 Gajeong-ro, Daejeon, Korea; Interaction& Robotics Research Center, Korea Institute of Science and Technology, 39-1 Hawolgok-dong, Seoul, 136-791, Korea","2014 11th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)","12 Mar 2015","2014","","","121","126","Myo-electric signals have been widely used in human-machine interfaces because these biosignal directly reflect human intentions to robots. The major difficulty of applying these biosignal in a pattern recognition system in real time is that they are unstable and vary in time. This instability occurs outside of the steady state of the signal, at the beginning and the ending of the motions. For real-time application users, the errors at the beginning of motion can lower the credibility of a pattern recognition system. In this sense, precise classification is the most significant factor for the system; thus the classification accuracy has higher priority compared to other factors. Generally, a trade-off relationship between the time delay of control commands and the classification accuracy has been known for sEMG users. Since parameters for signal processing can alter the sensitivity(time delay and accuracy) of the system, this study investigates limitations of a pattern recognition system due to transient-state errors. In particular, the performance of the system is analysed with respect to the analysis window size and the voting size of classification. Through an off-line simulation, we propose useful guidelines for the analysis window size and voting size in myoelectric signals for real-time applications.","","978-1-4799-5333-2","10.1109/URAI.2014.7057411","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057411","sEMG signal;real-time pattern recognition;optimal parameters and time delay","Accuracy;Delay effects;Real-time systems;Pattern recognition;Transient analysis;Feature extraction;Electrodes","biology computing;delays;electromyography;human-robot interaction;pattern recognition","analysis window size;voting size;time delay;robust real-time sEMG pattern recognition system;human-machine interfaces;biosignal;human intentions;robots;instability;precise classification;sEMG users;signal processing;transient-state errors;offline simulation;myoelectric signals;real-time applications","","3","","14","","12 Mar 2015","","","IEEE","IEEE Conferences"
"Non-rigid surface detection for gestural interaction with applicable surfaces","A. Ziegler; S. Belongie","Department of Computer Science and Engineering, University of California, San Diego, USA; Department of Computer Science and Engineering, University of California, San Diego, USA","2012 IEEE Workshop on the Applications of Computer Vision (WACV)","5 Mar 2012","2012","","","73","80","In this work we present a novel application of non-rigid surface detection to enable gestural interaction with applicable surfaces. This method can add interactivity to traditionally passive media such as books, newspapers, restaurant menus, or anything else printed on paper. We allow a user to interact with these surfaces in a natural manner and present basic gestures based on pointing and touching. This technique was developed as part of an ongoing effort to create an assisted reading device for the visually impaired. However, it is suited to general applications and can be used as a practical mechanism for interaction with screen-less wearable devices. Our key contributions are a unique application of non-rigid surface detection, a basic gesturing paradigm, and a proof of concept system.","1550-5790","978-1-4673-0234-0","10.1109/WACV.2012.6163029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6163029","","Shape;Visualization;Media;Thumb;Minimization;Cameras;Vectors","gesture recognition;handicapped aids;interactive systems","nonrigid surface detection;gestural interaction;applicable surfaces;books;newspapers;restaurant menus;pointing gestures;touching gestures;visually impaired;assisted reading device;screen-less wearable devices interaction","","","1","25","","5 Mar 2012","","","IEEE","IEEE Conferences"
"SMART-P: rigorous three-dimensional process simulator on a supercomputer","S. Odanaka; H. Umimoto; M. Wakabayashi; H. Esaki","Matsushita Electr. Ind. Co., Ltd., Osaka, Japan; Matsushita Electr. Ind. Co., Ltd., Osaka, Japan; Matsushita Electr. Ind. Co., Ltd., Osaka, Japan; Matsushita Electr. Ind. Co., Ltd., Osaka, Japan","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","6 Aug 2002","1988","7","6","675","683","A description is given of a three-dimensional process simulator, named SMART-P, that is based on the finite-difference approach to the supercomputer FACOM VP-100. To simulate the impurity redistribution and nonplanar structure in the Si/SiO/sub 2/ system, this simulator contains a three-dimensional oxidation model, an interaction model of impurities, a numerical model of interstitial-assisted oxidation-enhanced diffusion, and other process models. The numerical process modeling in the Si/SiO/sub 2/ system is described. The three-dimensional process modeling CAD (computer-aided design) has been realized by using efficient numerical algorithms based on the generalized coordinate transformation method. The capabilities of this simulator have been demonstrated in applications relating to both local oxidation of silicon (LOCOS) and trench-isolated 0.5 mu m MOSFET structures.<>","1937-4151","","10.1109/43.3207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=3207","","Impurities;Computational modeling;Oxidation;Numerical models;Design automation;Finite difference methods;Supercomputers;Application software;Silicon;MOSFET circuits","circuit CAD;digital simulation;integrated circuit technology;oxidation","size 0.5 mu m;three-dimensional process simulator;supercomputer;SMART-P;finite-difference approach;FACOM VP-100;impurity redistribution;nonplanar structure;three-dimensional oxidation model;interaction model;numerical model;interstitial-assisted oxidation-enhanced diffusion;CAD;generalized coordinate transformation method;local oxidation;trench-isolated;MOSFET structures;Si-SiO/sub 2/","","40","1","27","","6 Aug 2002","","","IEEE","IEEE Journals"
"UnityMol: interactive and ludic visual manipulation of coarse-grained RNA and other biomolecules","S. Doutreligne; C. Gageat; T. Cragnolini; A. Taly; S. Pasquali; P. Derreumaux; M. Baaden","Lab. de Biochimie Theorique, CNRS UPR9080, Univ. Paris Diderot, Sorbonne Paris Cite, 13 rue Pierre et Marie Curie, 75005, Paris, France; Lab. de Biochimie Theorique, CNRS UPR9080, Univ. Paris Diderot, Sorbonne Paris Cite, 13 rue Pierre et Marie Curie, 75005, Paris, France; Lab. de Biochimie Theorique, CNRS UPR9080, Univ. Paris Diderot, Sorbonne Paris Cite, 13 rue Pierre et Marie Curie, 75005, Paris, France; Lab. de Biochimie Theorique, CNRS UPR9080, Univ. Paris Diderot, Sorbonne Paris Cite, 13 rue Pierre et Marie Curie, 75005, Paris, France; Lab. de Biochimie Theorique, CNRS UPR9080, Univ. Paris Diderot, Sorbonne Paris Cite, 13 rue Pierre et Marie Curie, 75005, Paris, France; Lab. de Biochimie Theorique, CNRS UPR9080, Univ. Paris Diderot, Sorbonne Paris Cite, 13 rue Pierre et Marie Curie, 75005, Paris, France; Lab. de Biochimie Theorique, CNRS UPR9080, Univ. Paris Diderot, Sorbonne Paris Cite, 13 rue Pierre et Marie Curie, 75005, Paris, France","2015 IEEE 1st International Workshop on Virtual and Augmented Reality for Molecular Science (VARMS@IEEEVR)","9 Jul 2015","2015","","","1","6","We present a general software architecture to carry out interactive molecular simulations in a game engine environment. Our implementation is based on the UnityMol framework and the HireRNA physics engine. With UnityMol, we pursue the goal to create an interactive virtual laboratory enabling researchers in biology to visualize biomolecular systems, run simulations and interact with physical models and data. Similarly, UnityMol enables game designers to build scientifically accurate molecular scenarios. We discuss four case studies, from simulation setup via immersive experiments, force-induced unfolding of RNA to teaching and collaborative research applications. Visual effects enrich the dynamic and immersive aspects. We combine an appealing visual feedback with a set of analysis features to extract information about properties of the fascinating biomolecular systems under study. Access to various input devices enables a natural interaction with the simulation.","","978-1-4673-6926-8","10.1109/VARMS.2015.7151718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7151718","I.6.6 [Simulation and Modeling]-Simulation Output Analysis;J.3 [Computer Applications]: Life and Medical Sciences-Biology and Genetics","Biological system modeling;Solid modeling;RNA;Computational modeling;Games;Engines;Force","data visualisation;interactive systems;molecular biophysics;RNA;software architecture;teaching","Ludic visual manipulation;interactive visual manipulation;coarse-grained RNA;software architecture;interactive molecular simulations;game engine environment;UnityMol framework;HireRNA physics engine;interactive virtual laboratory;biomolecular systems;physical models;game designers;collaborative research applications;visual effects;visual feedback;feature extraction;information extraction","","3","","14","","9 Jul 2015","","","IEEE","IEEE Conferences"
"Generalized Hebbian algorithm for wearable sensor rotation estimation","V. Joukov; J. F. Lin; D. Kulić",NA; NA; NA,"2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","14 Dec 2017","2017","","","2248","2253","Inertial measurement units (IMUs) enable human motion measurement in any environment, which can be useful for human robot interaction, exoskeletons, and active prosthetics. This paper proposes an approach for estimating the orientation between a wearable IMU sensor and the body frame of the wearer using a simple and fast calibration procedure. The proposed approach uses the generalized Hebbian algorithm to incrementally estimate the axis aligned with gravity using acceleration measurements obtained during a static pose, and the axis perpendicular to the saggital plane using gyro measurements obtained during sagittal plane movements. An automated convergence criterion based on the sensor measurement variance is used. The proposed approach is tested in simulation and with human movement and demonstrates excellent and fast calibration performance.","2153-0866","978-1-5386-2682-5","10.1109/IROS.2017.8206045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8206045","","Accelerometers;Transmission line matrix methods;Gyroscopes;Convergence;Robot sensing systems;Principal component analysis;Estimation","acceleration measurement;accelerometers;body sensor networks;calibration;gyroscopes;Hebbian learning;human-robot interaction;inertial systems;motion measurement;pose estimation;rotation measurement;sensor fusion","generalized Hebbian algorithm;wearable sensor rotation estimation;inertial measurement units;human motion measurement;human robot interaction;active prosthetics;wearable IMU sensor;body frame;calibration procedure;acceleration measurements;gyro measurements;sagittal plane movements;sensor measurement variance;human movement;calibration performance;exoskeletons;axis estimation;static pose;automated convergence criterion","","","","22","","14 Dec 2017","","","IEEE","IEEE Conferences"
"Multi-contact representation for a force-reflecting manipulating simulator: preliminary experiments","T. Kotoku; K. Komoriya; K. Tanie","Robotics Dept., AIST-MITI, Ibaraki, Japan; Robotics Dept., AIST-MITI, Ibaraki, Japan; Robotics Dept., AIST-MITI, Ibaraki, Japan","Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'94)","6 Aug 2002","1994","1","","725","730 vol.1","This paper presents an algorithm for estimating the interaction forces between model objects contacting at multiple points. The authors' previous work addressed the interaction forces that arise between two convex polyhedra, and the development of an efficient algorithm for detecting the interaction and for estimating the interaction forces. To deal with the general case of multiple contacts, the authors consider the non-convex objects as a set of convex polyhedral parts. The problem of calculating the interaction forces with multiple contacts can be divided into multiple problems involving the calculation of the interaction forces arising between two convex objects making a single contact. By implementing this algorithm on a parallel processing system, the authors constructed a real-time operating simulator. Preliminary experiments, involving the placement of a cube in a corner, were performed to evaluate the effectiveness of the system.<>","","0-7803-1933-8","10.1109/IROS.1994.407353","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=407353","","Orbital robotics;Haptic interfaces;Graphics;Delay effects;Electronic mail;Object detection;Educational robots;Education;Predictive models;Force control","telerobotics;manipulators;real-time systems;digital simulation;parallel processing","multi-contact representation;force-reflecting manipulating simulator;interaction forces;nonconvex objects;convex polyhedral parts;parallel processing system;real-time operating simulator","","5","","18","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Impedance control approach vs. adaptive nonlinear design in simulated push-button haptic interface","B. Allotta; V. Colla; G. Bioli; F. Conticelli","Scula Superiore Sant'Anna, Pisa, Italy; NA; NA; NA","8th IEEE International Workshop on Robot and Human Interaction. RO-MAN '99 (Cat. No.99TH8483)","6 Aug 2002","1999","","","279","284","General purpose haptic interfaces are receiving increasing attention, because they can simulate different kinds of interaction between user and virtual objects/environments. The paper describes the control of a special-purpose haptic interface devoted to simulating the behavior of a push button, with the aim of performing user tests on different geometries and designs. The control task is to provide a reaction to the external solicitation as similar as possible to that of real buttons.","","0-7803-5841-4","10.1109/ROMAN.1999.900353","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=900353","","Impedance;Programmable control;Adaptive control;Haptic interfaces;Hardware;Force sensors;Force measurement;Springs;Testing;Geometry","haptic interfaces;force control;adaptive control;nonlinear control systems;virtual reality","impedance control approach;adaptive nonlinear design;simulated push-button haptic interface;virtual objects;virtual environments;user tests;control task","","","","8","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Real-time multi-objective hand posture/gesture recognition by using distance classifiers and finite state machine for virtual mouse operations","A. Aksaç; O. Öztürk; T. Özyer","Computer Engineering Department, TOBB University of Economics & Technology, Ankara, Turkey; Computer Engineering Department, TOBB University of Economics & Technology, Ankara, Turkey; Computer Engineering Department, TOBB University of Economics & Technology, Ankara, Turkey","2011 7th International Conference on Electrical and Electronics Engineering (ELECO)","26 Jan 2012","2011","","","II-457","II-461","Cameras that are connected to computers record sequence of digital images of human hand in order to interpret human posture/gesture. Human hand posture/gesture recognition has been utilized for providing virtual reality mechanism and it is still an ongoing research in human-computer interaction (HCI) community. Virtual reality can be operated on a particular program but it will be more effective if the entire system can be controlled for the sake of generality. Another direction is the applicability of virtual reality in real time. In this paper, we have developed a virtual mouse system that can recognize the pre-defined mouse movements in real time regardless of the context. Our real time hand recognition system is three fold. 1) skin detection, 2) feature extraction and 3) recognition. For recognition, various features with their own objectives are constructed from hand postures and compared according to the similarity measures and the best-matched posture is used as a mouse action to control the cursor of the computer.","","978-6-0501-0090-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6140225","","Thumb;Mice;Pattern recognition;Feature extraction;Skin;Image color analysis","feature extraction;finite state machines;gesture recognition;human computer interaction;image classification;image sequences;object detection;virtual reality","hand posture recognition;gesture recognition;distance classifier;finite state machine;virtual mouse operation;human computer interaction;virtual reality mechanism;skin detection;feature extraction;digital image sequence;best-matched posture","","","","23","","26 Jan 2012","","","IEEE","IEEE Conferences"
"Learning an Action-Conditional Model for Haptic Texture Generation","N. Heravi; W. Yuan; A. M. Okamura; J. Bohg","Stanford University,Department of Mechanical Engineering; Carnegie Mellon University,Robotics Institute; Stanford University,Department of Mechanical Engineering; Stanford University,Department of Computer Science","2020 IEEE International Conference on Robotics and Automation (ICRA)","15 Sep 2020","2020","","","11088","11095","Rich haptic sensory feedback in response to user interactions is desirable for an effective, immersive virtual reality or teleoperation system. However, this feedback depends on material properties and user interactions in a complex, non-linear manner. Therefore, it is challenging to model the mapping from material and user interactions to haptic feedback in a way that generalizes over many variations of the user's input. Current methodologies are typically conditioned on user interactions, but require a separate model for each material. In this paper, we present a learned action-conditional model that uses data from a vision-based tactile sensor (GelSight) and user's action as input. This model predicts an induced acceleration that could be used to provide haptic vibration feedback to a user. We trained our proposed model on a publicly available dataset (Penn Haptic Texture Toolkit) that we augmented with GelSight measurements of the different materials. We show that a unified model over all materials outperforms previous methods and generalizes to new actions and new instances of the material categories in the dataset.","2577-087X","978-1-7281-7395-5","10.1109/ICRA40945.2020.9197447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197447","","Haptic interfaces;Autoregressive processes;Force;Acceleration;Predictive models;Solid modeling;Discrete Fourier transforms","feedback;haptic interfaces;human-robot interaction;image texture;learning (artificial intelligence);mobile robots;robot vision;tactile sensors;telerobotics;virtual reality","Haptic Texture generation;haptic sensory feedback;user interactions;immersive virtual reality;material properties;haptic vibration feedback;Penn Haptic Texture Toolkit;action-conditional model learning;GelSight measurements;teleoperation system;autonomous robot;GelSight image texture","","","","33","","15 Sep 2020","","","IEEE","IEEE Conferences"
"High-Fidelity Yet Fast Dynamic Models of Wheeled Mobile Robots","N. Seegmiller; A. Kelly","Southwest Research Institute, San Antonio, TX, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA","IEEE Transactions on Robotics","19 May 2017","2016","32","3","614","625","Advances in hardware design have made wheeled mobile robots (WMRs) exceptionally mobile. To fully exploit this mobility, we present a novel dynamic model formulation for use in WMR planning, control, and estimation systems. The formulation is high fidelity, general, modular, and fast. It builds on our prior work on recursive methods for 3-D kinematics derivation and constrained motion prediction using differential algebraic equations. It is stable, even for large integration steps, and can enforce realistic nonlinear models of wheel-terrain interaction. Simulation tests show our dynamic models to be more functional, stable, and efficient than common alternatives. Simulations can run over 1K × faster than real time on an ordinary PC. Experimental results on multiple platforms and terrain types show that, once calibrated, our models predict motion accurately. To facilitate their use, we have released open-source MATLAB and C++ libraries implementing our modeling/simulation methods.","1941-0468","","10.1109/TRO.2016.2546310","U.S. Government; National Science Foundation Graduate Research Fellowship; Army Research Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7471489","Dynamics;kinematics;model identification;wheeled mobile robots;wheel slip;wheel–terrain interaction;Dynamics;kinematics;model identification;wheeled mobile robots;wheel slip;wheel–terrain interaction","Kinematics;Vehicle dynamics;Computational modeling;Dynamics;Mathematical model;Wheels;Numerical models","C++ language;differential algebraic equations;digital simulation;mobile robots;nonlinear systems;robot dynamics;robot kinematics;solid modelling;wheels","high-fidelity yet fast dynamic models;wheeled mobile robots;dynamic model formulation;WMR planning;WMR control;WMR estimation systems;recursive methods;3D kinematics derivation;constrained motion prediction;differential algebraic equations;realistic nonlinear models;wheel-terrain interaction;simulation tests;open-source MATLAB;C++ libraries","","16","","51","","18 May 2016","","","IEEE","IEEE Journals"
"Eye-MMS: Miniature Multi-Scale Segmentation Network of Key Eye-Regions in Embedded Applications","F. Boutros; N. Damer; F. Kirchbuchner; A. Kuijper","Fraunhofer Institute for Computer Graphics Research IGD, Germany and Technische Universität Darmstadt, Germany; Fraunhofer Institute for Computer Graphics Research IGD, Germany and Technische Universität Darmstadt, Germany; Fraunhofer Institute for Computer Graphics Research IGD, Germany and Technische Universität Darmstadt, Germany; Fraunhofer Institute for Computer Graphics Research IGD, Germany and Technische Universität Darmstadt, Germany","2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)","5 Mar 2020","2019","","","3665","3670","Segmentation of the iris or sclera is an essential processing block in ocular biometric systems. However, human-computer interaction, as in VR/AR applications, requires multiple region segmentation to enable smoother interaction and eye-tracking. Such application does not only demand highly accurate and generalizable segmentation, it requires such segmentation model to be appropriate for the limited computational power of embedded systems. This puts strict limits on the size of the deployed deep learning models. This work presents a miniature multi-scale segmentation network consisting of inter-connected convolutional modules. We present a baseline multi-scale segmentation network and modify it to reduce its parameters by more than 80 times, while reducing its accuracy by less than 3%, resulting in our Eye-MMS model containing only 80k parameters. This work is developed on the OpenEDS database and is conducted in preparation for the OpenEDS Semantic Segmentation Challenge.","2473-9944","978-1-7281-5023-9","10.1109/ICCVW.2019.00452","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022048","Semantic segmentation;Biometrics;Eye segmentation;Embedded biometrics","Image segmentation;Iris recognition;Databases;Solid modeling;Semantics;Image resolution;Computational modeling","augmented reality;biometrics (access control);embedded systems;eye;gaze tracking;human computer interaction;image segmentation;learning (artificial intelligence);neural nets","miniature multiscale segmentation network;eye regions;embedded applications;ocular biometric systems;human-computer interaction;multiple region segmentation;eye-tracking;embedded systems;deep learning;baseline multiscale segmentation network;Eye-MMS model;OpenEDS Semantic Segmentation Challenge;OpenEDS database;AR application;VR application","","8","","26","","5 Mar 2020","","","IEEE","IEEE Conferences"
"Adaptive Neural Network-based Perception and Awareness of Teleoperation Systems in Human-Machine Interactions","P. M. Kebria; D. Nahavandi; A. Khosravi; S. Nahavandi; F. Bello","Deakin University,Institute for Intelligent Systems Research and Innovation (IISRI),Waurn Ponds,VIC,Australia,3216; Deakin University,Institute for Intelligent Systems Research and Innovation (IISRI),Waurn Ponds,VIC,Australia,3216; Deakin University,Institute for Intelligent Systems Research and Innovation (IISRI),Waurn Ponds,VIC,Australia,3216; Deakin University,Institute for Intelligent Systems Research and Innovation (IISRI),Waurn Ponds,VIC,Australia,3216; Centre for Engagement and Simulation Science, Imperial College, Chelsea and Westminster Hospital,London,UK","2020 IEEE International Conference on Human-Machine Systems (ICHMS)","30 Sep 2020","2020","","","1","6","This paper addresses the problem of perception and awareness of teleoperation systems in the presence of human collaboratives/objects in the workspace. Although the term teleoperation generally refers to operations being executed remotely, in many applications, like telemedicine, there exist human beings in the remote workspace. Hence, it is critically important that the teleoperator system to operate safely enough in the presence of human kinds in the workspace. In this paper, we propose a perception and awareness scheme for a teleoperation system that prevents the teleoperator from imposing extreme and unwanted forces/movements. To achieve this goal, we train a neural network to estimate and predict the motion and force commands from the human operator. Furthermore, we develop an adaptive algorithm for fine-tuning network parameters for robustness purposes. Theoretically proven, stability and performance of the proposed scheme is comparatively evaluated in comprehensive simulations.","","978-1-7281-5871-6","10.1109/ICHMS49158.2020.9209437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9209437","","Force;Neural networks;Teleoperators;Adaptive algorithms;Reliability;Training","human computer interaction;learning (artificial intelligence);man-machine systems;neural nets;telemedicine","fine-tuning network parameters;human operator;neural network;awareness scheme;human kinds;teleoperator system;remote workspace;term teleoperation;human-machine interactions;teleoperation system","","","","27","","30 Sep 2020","","","IEEE","IEEE Conferences"
"Driver Behaviour Prediction for Motion Simulators Using Changepoint Segmentation","M. Hossny; S. Mohamed; S. Nahavandi","Centre for Intell. Syst. Res., Deakin Univ., Melbourne, VIC, Australia; Centre for Intell. Syst. Res., Deakin Univ., Melbourne, VIC, Australia; Centre for Intell. Syst. Res., Deakin Univ., Melbourne, VIC, Australia","2015 IEEE International Conference on Systems, Man, and Cybernetics","14 Jan 2016","2015","","","457","462","Driving phenomenon is a repetitive process, that permits sequential learning under identifying the proper change periods. Sequential filtering is widely used for tracking and prediction of state dynamics. However, it suffers at abrupt changes, which cause sudden incremental prediction error. We provide a sequential filtering approach using online Bayesian detection of change points to decrease prediction error generally, and specifically at abrupt changes. The approach learns from optimally detected segments for identifying driving behaviour. Change points detection is done by the Pruned Exact Linear Time algorithm. Computational cost of our approach is bounded by the cost of the implemented sequential filter. This computational performance is suitable to the online nature of motion simulator's delay reduction. The approach was tested on a simulated driving scenario using Vortex by CM Labs. The state dimensions are simulated 2D space coordinates, and velocity. Particle filter was used for online sequential filtering. Prediction results show that change-point detection improves the quality of state estimation compared to traditional sequential filters, and is more suitable for predicting behavioural activities.","","978-1-4799-8697-2","10.1109/SMC.2015.91","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379223","Human Machine Interaction;Driver Behaviour Prediction;Particle Filter;Changepoint Approach","Vehicles;Hidden Markov models;Head;Tracking;Vehicle dynamics;Dynamics;Training","Bayes methods;behavioural sciences computing;digital simulation;learning (artificial intelligence);particle filtering (numerical methods);state estimation","driver behaviour prediction;motion simulators;changepoint segmentation;repetitive process;sequential learning;sequential filtering;state dynamic prediction;state dynamic tracking;sequential filtering approach;online Bayesian changepoint detection;prediction error;driving phenomenon;driving behaviour;pruned exact linear time algorithm;motion simulator delay reduction;computational performance;Vortex;CM Labs;particle filter;state estimation;behavioural activity prediction","","3","","16","","14 Jan 2016","","","IEEE","IEEE Conferences"
"Fun learning Stagecast Creator: an exercise in minimalism and collaboration","C. Seals; M. B. Rosson; J. M. Carroll; T. Lewis; L. Colson","Center for Human-Comput. Interaction, Virginia Tech, Blacksburg, VA, USA; Center for Human-Comput. Interaction, Virginia Tech, Blacksburg, VA, USA; Center for Human-Comput. Interaction, Virginia Tech, Blacksburg, VA, USA; Center for Human-Comput. Interaction, Virginia Tech, Blacksburg, VA, USA; Center for Human-Comput. Interaction, Virginia Tech, Blacksburg, VA, USA","Proceedings IEEE 2002 Symposia on Human Centric Computing Languages and Environments","10 Dec 2002","2002","","","177","186","We are attempting to create a cross-generational learning community who will work together to design, construct, and discuss simulations of community topics. The simulations are built with Stagecast Creator, a state-of-the art visual programming environment. As part of this larger project, we have developed minimalist training materials for middle school students. This paper reports a formative evaluation of these training materials, in which groups of students worked together on two related tutorial modules. In general the students were successful in their work with Creator, needing little aid from the experimenters, and showing evidence of enjoyment. Our aim is to develop materials that will attract participation and enable students to spend their free time and play with this environment, and as a by-product of having fun, learn more about visual programming.","","0-7695-1644-0","10.1109/HCC.2002.1046370","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1046370","","Collaboration;Educational institutions;Seals;Humans;Art;Electrical capacitance tomography;Read only memory;Web sites;Resource management","visual programming;programming environments;computer aided instruction","cross-generational learning community;community topics simulations;state-of-the art visual programming environment;Stagecast Creator;training materials;tutorial modules","","9","","13","","10 Dec 2002","","","IEEE","IEEE Conferences"
"Visual interpretation of hand gestures for human-computer interaction: a review","V. I. Pavlovic; R. Sharma; T. S. Huang","Dept. of Electr. & Comput. Eng., Illinois Univ., Urbana, IL, USA; NA; NA","IEEE Transactions on Pattern Analysis and Machine Intelligence","6 Aug 2002","1997","19","7","677","695","The use of hand gestures provides an attractive alternative to cumbersome interface devices for human-computer interaction (HCI). In particular, visual interpretation of hand gestures can help in achieving the ease and naturalness desired for HCI. This has motivated a very active research area concerned with computer vision-based analysis and interpretation of hand gestures. We survey the literature on visual interpretation of hand gestures in the context of its role in HCI. This discussion is organized on the basis of the method used for modeling, analyzing, and recognizing gestures. Important differences in the gesture interpretation approaches arise depending on whether a 3D model of the human hand or an image appearance model of the human hand is used. 3D hand models offer a way of more elaborate modeling of hand gestures but lead to computational hurdles that have not been overcome given the real-time requirements of HCI. Appearance-based models lead to computationally efficient ""purposive"" approaches that work well under constrained situations but seem to lack the generality desirable for HCI. We also discuss implemented gestural systems as well as other potential applications of vision-based gesture recognition. Although the current progress is encouraging, further theoretical as well as computational advances are needed before gestures can be widely used for HCI. We discuss directions of future research in gesture recognition, including its integration with other natural modes of human-computer interaction.","1939-3539","","10.1109/34.598226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=598226","","Human computer interaction;Computer displays;Computational modeling;Virtual reality;Computer vision;Potential well;Tracking;Motion analysis;Communications technology;Keyboards","user interfaces;image recognition;motion estimation;reviews","human-computer interaction;HCI;hand gestures;visual interpretation;real-time requirements;computationally efficient purposive approaches;vision-based gesture recognition","","1032","426","105","","6 Aug 2002","","","IEEE","IEEE Journals"
"Origami, folding paper over the Web","N. Kishi; Y. Fujii","Dept. of Math. & Comput. Sci., Tsuda Coll., Tokyo, Japan; NA","Proceedings. 3rd Asia Pacific Computer Human Interaction (Cat. No.98EX110)","6 Aug 2002","1998","","","337","342","Origami, paperfolding, is a traditional Japanese art of folding paper into representation of 3-D figures. In general, it is quite difficult to learn origami from 2-D images such as diagrams and videos, because it requires inference of 3-D models from 2-D images. We are developing a system for folding origami over the Web, by designing a model of an origami folding process and by implementing a client-server system. Our system consists of three parts: the origami editor, origami server and origami browser. The origami editor enables the user to create and edit origami projects, which are sequences of origami states and folding methods. The origami server receives the input data from the editor and generates a VRML 2.0 data stream, which represents a transition between two origami states. The VRML 2.0 data stream is then displayed by the origami browser, or a VRML 2.0 browser, as a 3-D origami figure in motion.","","0-8186-8347-3","10.1109/APCHI.1998.704454","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=704454","","Videos;Books;Read only memory;Educational institutions;Art;Shape;Mathematics;Computer science;Client-server systems;Electrical capacitance tomography","computer animation;solid modelling;user interfaces;Internet;client-server systems;virtual reality","origami editor;paperfolding;Japanese art;3D figure representation;2D images;diagrams;World Wide Web;client-server system;origami server;origami browser;VRML;animation","","2","","4","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Benchmarking Touchscreen Biometrics for Mobile Authentication","J. Fierrez; A. Pozo; M. Martinez-Diaz; J. Galbally; A. Morales","Universidad Autonoma de Madrid, Madrid, Spain; Universidad Autonoma de Madrid, Madrid, Spain; Universidad Autonoma de Madrid, Madrid, Spain; European Commission, DG Joint Research Centre, Ispra, Italy; Universidad Autonoma de Madrid, Madrid, Spain","IEEE Transactions on Information Forensics and Security","21 May 2018","2018","13","11","2720","2733","We study user interaction with touchscreens based on swipe gestures for personal authentication. This approach has been analyzed only recently in the last few years in a series of disconnected and limited works. We summarize those recent efforts and then compare them to three new systems (based on support vector machine and Gaussian mixture model using selected features from the literature) exploiting independent processing of the swipes according to their orientation. For the analysis, four public databases consisting of touch data obtained from gestures sliding one finger on the screen are used. We first analyze the contents of the databases, observing various behavioral patterns, e.g., horizontal swipes are faster than vertical independently of the device orientation. We then explore an intra-session scenario, where users are enrolled and authenticated within the same day, and an inter-session one, where enrollment and test are performed on different days. The resulting benchmarks and processed data are made public, allowing the reproducibility of the key results obtained based on the provided score files and scripts. In addition to the remarkable performance, thanks to the proposed orientation-based conditional processing, the results show various new insights into the distinctiveness of swipe interaction, e.g., some gestures hold more user-discriminant information, data from landscape orientation is more stable, and horizontal gestures are more discriminative in general than vertical ones.","1556-6021","","10.1109/TIFS.2018.2833042","Cecabank, the Project CogniMetrics; Imperial College London; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353868","Active authentication;biometrics;smartphone;touchscreen;human computer interaction","Authentication;Support vector machines;Biometrics (access control);Benchmark testing;Databases;Task analysis;Neural networks","biometrics (access control);Gaussian processes;gesture recognition;human computer interaction;support vector machines;touch sensitive screens","touchscreen biometrics;mobile authentication;user interaction;touchscreens;swipe gestures;personal authentication;support vector machine;Gaussian mixture model;public databases;touch data;processed data;user-discriminant information;orientation based conditional processing;landscape orientation data","","19","","36","","3 May 2018","","","IEEE","IEEE Journals"
"Super resolving texture mapping from multiple view images for 3D model construction","H. Saito","Dept. of Inf. & Comput. Sci., Keio Univ., Yokohama, Japan","Smc 2000 conference proceedings. 2000 ieee international conference on systems, man and cybernetics. 'cybernetics evolving to systems, humans, organizations, and their complex interactions' (cat. no.0","6 Aug 2002","2000","2","","1418","1421 vol.2","There are wide varieties of applications of 3D modeling from real images, which can generate virtual view images by rendering the input images on to a 3D shape model. Because the virtual viewpoint is not generally at the same point, the synthesized image in a virtual view does not have sufficient resolution. To improve this resolution problem, we propose a method for improving the rendered texture resolution. For each vertex of the 3D shape model, the position of the vertex is adjusted to improve the texture of the neighboring triangle patches. For the improvement, the position of the vertex is adjusted by comparing the observation (input image) with the projected image of the model texture. By repeating the visit to every vertex, not only can a super-resolved texture be obtained but also a more accurate 3D patch model. By performing experiments using synthesized multiple-view images of 51 calibrated cameras around the object scene and a real VTR image sequence, it is demonstrated that the proposed method can successfully provide a super-resolved texture image with an improved 3D shape model.","1062-922X","0-7803-6583-6","10.1109/ICSMC.2000.886053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=886053","","Image resolution;Shape;Rendering (computer graphics);Predictive models;Pixel;Application software;Image generation;Cameras;Video recording;Image sequences","stereo image processing;image resolution;image texture;virtual reality;rendering (computer graphics);video cameras;image sequences;calibration","texture mapping;multi-view images;3D model construction;virtual view images;rendering;3D shape model;virtual viewpoint;synthesised image;image resolution;rendered texture resolution;vertex position adjustment;triangle patches;projected image;repeated vertex visits;super-resolved texture;3D patch model;calibrated cameras;VTR image sequence","","2","2","11","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Rehabilitation Game Model for Personalised Exercise","D. Holmes; D. Charles; P. Morrow; S. McClean; S. McDonough","Comput. Sci. Res. Inst., Univ. of Ulster, Newtownabbey, UK; Comput. Sci. Res. Inst., Univ. of Ulster, Newtownabbey, UK; Comput. Sci. Res. Inst., Univ. of Ulster, Newtownabbey, UK; Comput. Sci. Res. Inst., Univ. of Ulster, Newtownabbey, UK; Comput. Sci. Res. Inst., Univ. of Ulster, Newtownabbey, UK","2015 International Conference on Interactive Technologies and Games","8 Feb 2016","2015","","","41","48","Existing literature has shown that games and virtual reality can help motivate people thus keeping them engaged for longer. Nonetheless, in most approaches the design of games or virtual reality for rehabilitation purposes tend to apply a basic motivational approach that focuses on the general population of game players. Recent research shows that individuals can be motivated quite differently and so it may be important to consider each individual's motivational characteristics within the context of rehabilitation to ensure continued engagement. In this paper we present the Rehabilitation Game Model (RGM), which can be used as a basis for evaluating existing systems and for designing new interactive rehabilitation systems that are more personalised and engaging. Initial evaluation of existing rehabilitation games and comparison with commercial games using the RGM indicate a potential over emphasis on achievement based reward systems in rehabilitation game design compared to other reward systems.","","978-1-4673-7874-1","10.1109/iTAG.2015.11","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7399488","rehabilitation;game design;gamification;motivation;user types","Games;Ontologies;Psychology;Solid modeling;Virtual reality;Context;Systematics","computer games;health care;human computer interaction;patient rehabilitation;virtual reality","rehabilitation game model;personalised exercise;virtual reality;interactive rehabilitation systems;gamification;motivational characteristics","","4","","30","","8 Feb 2016","","","IEEE","IEEE Conferences"
"Human-automation Interaction Strategies for Life Science Applications: Implications and Future Research","D. B. Kaber; N. Stoll; K. Thurow","Member, IEEE, Industrial & Systems Engineering Department, North Carolina State University (NCSU), Raleigh, NC 27695 USA. phone: 919-515-3086; fax: 919-515-5281; e-mail: dbkaber@ncsu.edu; Center for Life Science Automation, University of Rostock, Rostock, 18119 DE. email: norbert.stoll@celisca.de; Center for Life Science Automation, University of Rostock, Rostock, 18119 DE. email: kerstin.thurow@celisca.de","2007 IEEE International Conference on Automation Science and Engineering","8 Oct 2007","2007","","","615","620","The objective of this research was to identify current and future approaches to the design of highly automated systems for life science processes involving humans in control loops in applications such as high-throughput compound screening and high-performance analytical chemistry. (In some advanced applications, screening of biochemical reactions and analytics are performed together.) The identified approaches were classified according to existing theories of human-centered automation, which provided a basis for projecting human performance implications, including error recovery capability. We provide background on the life sciences domain and established theories of types and levels of automation in complex human-machine systems. We describe specific forms of robotic and automated technologies used in life science applications and the general design of high-throughput screening and analytical systems to accommodate particular process configurations. Some example classifications of life science automation (LSA) schemes are presented by referring to a taxonomy of levels of automation from the literature. Finally, we identify the need for future empirical research on human performance consequences of LSA and remedial measures, including enhanced supervisory control interface design.","2161-8089","978-1-4244-1153-5","10.1109/COASE.2007.4341856","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4341856","","Robotics and automation;Humans;Biochemical analysis;Performance analysis;Automatic control;Control systems;Chemistry;Design automation;Error correction;Man machine systems","biology computing;human computer interaction","human-automation Interaction;high-throughput compound screening;high-performance analytical chemistry;error recovery;complex human-machine systems;life science automation schemes;taxonomy;supervisory control interface","","7","","14","","8 Oct 2007","","","IEEE","IEEE Conferences"
"Which do you feel comfortable, interview by a real doctor or by a virtual doctor? A comparative study of responses to inquiries with various psychological intensities, for the development of the Hyper Hospital","A. Yoshida; Y. Hagita; K. Yamazaki; T. Yamaguchi","Dept. of Inf. Technol., Kyoto Inst. of Technol., Japan; Dept. of Inf. Technol., Kyoto Inst. of Technol., Japan; NA; NA","Proceedings of 1993 2nd IEEE International Workshop on Robot and Human Communication","6 Aug 2002","1993","","","370","374","The ""Hyper Hospital"" is a novel medical care system which will be constructed on an electronic information network. The human interface of the Hyper Hospital based on the modern virtual reality technology is expected to maximally enhance patients' ability of healing illness by computer-supported online visual consultations. In order to investigate the effects and features of online visual consultations in the Hyper Hospital, we conducted an experiment to clarify the influence of electronic interviews on the talking behavior of interviewees in the similar context to real doctor-patient interactions. Four types of distant-confrontation interviews were presented to voluntary subjects and their verbal and nonverbal responses were analyzed from the human ethological viewpoints. In the media-mediated interviews both the latency and the duration of interviewees' utterances in answering questions increased compared with those of live face to face interviews. These results suggest that the interviewee became more verbose or talkative in the mediated interviews, but his psychological tension was generally augmented.<>","","0-7803-1407-7","10.1109/ROMAN.1993.367690","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=367690","","Hospitals;Humans;Psychology;Virtual reality;Information technology;Modems;Computer interfaces;Delay;Medical simulation;Medical services","medical computing;virtual reality;human factors;information networks","virtual doctor;psychological intensities;Hyper Hospital;electronic information network;virtual reality;computer-supported online visual consultations;verbosity;talkativeness;psychological tension","","1","","15","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Multi-Hand Direct Manipulation of Complex Constrained Virtual Objects","J. Kim; M. Jeon; J. Park","Korea Institute of Science and Technology, Hwarangro 14 gil 5,Center for Intelligent and Interactive Robotics,Seongbuk-Gu,Korea,02792; KAIST,Robotics Program,Korea; Korea Institute of Science and Technology, Hwarangro 14 gil 5,Center for Intelligent and Interactive Robotics,Seongbuk-Gu,Korea,02792","2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","28 Jan 2020","2019","","","3235","3240","We present a method to manipulate virtual objects which are constrained complexly and reconfigurable as if they would exist in a real world by using multiple hands simultaneously. A complexly constrained, and reconfigurable object, such as a Rubik's cube, is hard to describe its physical motion constraints, mainly because they are determined by the grasping situation and dynamically changeable. Rather than describing the physical motion constraints in a general form, we more focus on the multiple hand interaction of a complex object. A complex object is divided into multiple subparts which are grasped by each hand, and the constraints between the subparts are optimized for inducing natural and continuous movement. For this, we propose a dynamically adjustable data structure for representing object parts grasped by multiple hands, and an optimization-based pose estimation of the constrained subparts along with their grasped hands. The experiments show that human subjects can manipulate a complexly constrained object such as a Rubik's cube without any difficulty as if it exists in the real-world.","2153-0866","978-1-7281-4004-9","10.1109/IROS40897.2019.8968088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8968088","","","data structures;human computer interaction;optimisation;pose estimation;virtual reality","multihand direct manipulation;constrained virtual objects;optimization-based pose estimation;grasped hands;data structure;multiple subparts;multiple hand interaction;physical motion constraints;Rubik's cube;reconfigurable object","","","","16","","28 Jan 2020","","","IEEE","IEEE Conferences"
"ReMod3D: A high-performance simulator for autonomous, self-reconfigurable robots","T. Collins; N. O. Ranasinghe; W. Shen","Information Sciences Institute, The University of Southern California, Los Angeles, U.S.A.; Information Sciences Institute, The University of Southern California, Los Angeles, U.S.A.; Information Sciences Institute, The University of Southern California, Los Angeles, U.S.A.","2013 IEEE/RSJ International Conference on Intelligent Robots and Systems","2 Jan 2014","2013","","","4281","4287","Three-dimensional, physics-based simulators are important to the field of self-reconfigurable robotics because they allow researchers to approximate the physical interactions and autonomous behaviors of large numbers of modules in a low-cost, safe, and highly-controlled manner. This paper presents a novel, high-performance, general-purpose simulator for autonomous, self-reconfigurable robots called ReMod3D (RM3D) that overcomes the speed and scalability limitations of existing self-reconfigurable simulators while, at the same time, allowing for realistic module structures, complex environments, and high physical simulation fidelity. While most existing self-reconfigurable simulators view modules as actuated physical bodies with programmable controllers, RM3D views them as embodied agents, defined not only by their physical bodies (links, joints, docks, sensors, actuators) but also by their minds (actions, percepts, behaviors, world models) and the noise inherent in the interaction between sensors, actuators, and the environment. RM3D also simulates inter-module dock connection breakage, something novel for self-reconfigurable robot simulators. Additionally, we present experimental evidence showing that this novel architecture makes RM3D well-suited to locomotion, manipulation, reconfiguration, and embodied intelligence research.","2153-0866","978-1-4673-6358-7","10.1109/IROS.2013.6696970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6696970","","Robots;Physics;Sensors;Engines;Joints;Scalability;Actuators","digital simulation;programmable controllers;self-adjusting systems;telerobotics","ReMod3D;high-performance simulator;self-reconfigurable robots;autonomous robots;physics-based simulators;three-dimensional simulators;realistic module structures;complex environments;high physical simulation fidelity;programmable controllers;embodied agents;intermodule dock connection breakage;self-reconfigurable robot simulators","","2","","22","","2 Jan 2014","","","IEEE","IEEE Conferences"
"Development of Hardware-in-Loop Simulation Platform for Collaborative Robots Based on LinuxCNC and V-rep","L. Tongtong; Y. Tao; Y. Zelin; L. Shuxuan; L. Jianming","Beijing Institute of Precision Mechanical and Electrical Control Equipment, Beijing, China; Beijing Institute of Precision Mechanical and Electrical Control Equipment, Beijing, China; Beijing Institute of Precision Mechanical and Electrical Control Equipment, Beijing, China; Beijing Institute of Precision Mechanical and Electrical Control Equipment, Beijing, China; Beijing Institute of Precision Mechanical and Electrical Control Equipment, Beijing, China","2018 IEEE International Conference on Mechatronics and Automation (ICMA)","7 Oct 2018","2018","","","1323","1328","Cooperative robots are currently the leading research and development direction of the robotics industry. Developing robotic systems often requires a combination of software and hardware. However, due to its complexity, making a real robot itself proposes great challenges to developers. This article describes a hardware-in-the-loop simulation control development platform based on Linux CNC and V-rep simulation software. In the real-time Linux system, we build a general-purpose, modular cooperative robot control system; and we establish a robot model in the V-rep. Data communication between them can be achieved through data interaction module. Thanks to the modularity of the control system, developers are free to add algorithmic modules. In this paper, a six-degree-of-freedom lightweight robotic arm model is taken as an example to serve as a virtual controlled object of the above cooperative robot control system. Afterwards, this paper establishes the forward and inverse kinematics algorithm and dynamics algorithm of the robot separately, and verifies the validity of this hardware-in-loop simulation development platform.","2152-744X","978-1-5386-6075-1","10.1109/ICMA.2018.8484611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8484611","Cooperative robots;Hardware in loop simulation;Kinematics and Dynamics Modelling","Service robots;Hardware;Robot control;Kinematics;Task analysis;Software","computerised numerical control;control engineering computing;digital simulation;Linux;mobile robots;multi-robot systems;robot dynamics;robot kinematics","LinuxCNC;robotics industry;hardware-in-the-loop simulation control development platform;V-rep simulation software;six-degree-of-freedom lightweight robotic arm model;virtual controlled object;Linux system;inverse kinematics algorithm;dynamics algorithm;cooperative robot control system","","","","13","","7 Oct 2018","","","IEEE","IEEE Conferences"
"Computationally efficient techniques for data-driven haptic rendering","R. Hover; M. Di Luca; G. Szekely; M. Harders","Computer Vision Lab - ETH Zurich, Sternwartstr. 7, CH-8092, Switzerland; Max Planck Institute for Biological Cybernetics, Spemannstr. 41, D-72076 Tübingen, Germany; Computer Vision Lab - ETH Zurich, Sternwartstr. 7, CH-8092, Switzerland; Computer Vision Lab - ETH Zurich, Sternwartstr. 7, CH-8092, Switzerland","World Haptics 2009 - Third Joint EuroHaptics conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems","3 Apr 2009","2009","","","39","44","Data-driven haptic rendering requires processing of raw recorded signals, which leads to high computational effort for large datasets. To achieve real-time performance, one possibility is to reduce the parameter space of the employed interpolation technique, which generally decreases the accuracy in the rendering. In this paper, we propose a method for guiding this parameter reduction to maintain high accuracy with respect to the just noticeable difference for forces. To this end, we performed a user study to estimate this perception threshold. The threshold is used to assess the final error in the rendered forces as well as for the parameter reduction process. Comparison with measured data from real object interactions confirms the accuracy of our method and highlights the reduced computational effort.","","978-1-4244-3858-7","10.1109/WHC.2009.4810814","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810814","Virtual Reality;Haptic Rendering;Deformable Models","Haptic interfaces;Interpolation;Deformable models;Computer vision;Rendering (computer graphics);Force sensors;Sensor systems;Biology computing;Computer interfaces;Force feedback","interpolation;rendering (computer graphics);virtual reality","data-driven haptic rendering;interpolation technique;parameter reduction process","","8","","20","","3 Apr 2009","","","IEEE","IEEE Conferences"
"A general purpose suite for Grid resources exploitation","A. Fella; E. Luppi; M. Manzali; L. Tomassetti","Istituto Nazionale di Fisica Nucleare in Pisa (INFNPisa), Largo P. Corvo 3, I-56100, Italy; University of Ferrara and INFN, via Saragat, 1, I-44122, Italy; INFN-Ferrara, via Saragat, 1, I-44122, Italy; University of Ferrara and INFN, via Saragat, 1, I-44122, Italy","2011 IEEE Nuclear Science Symposium Conference Record","20 Feb 2012","2011","","","99","103","We present a general-purpose software framework, which allows different multi-disciplinary communities to take advantage of a distributed computational infrastructure. The ultimate goal is to provide organizations that need to exploit resources with CPU-intensive loose-parallel tasks with a software service capable to offer a user-friendly, standard and highly customizable access to the Grid. The software suite we developed has been designed specifically for organizations that cannot afford the adoption costs of more specialized and complex frameworks, developed in High Energy Physics (HEP) environment, but that still require an easy-to-use interface to the Grid. Our framework heavily relies on a bookkeeping database, storing both application-specific and infrastructure meta-data, which is tightly coupled with a web-based user-interface. The first makes available to the users information on the execution status of jobs and their specific meaning and parameters, and contributes in orchestrating the submission mechanism. The latter provides job submission management, bookkeeping database interactions, basic monitoring functionality and eLog system. Multi-site submissions based on user-defined requests and fine grain parametric submission interfaces are available. The structure of framework services follow a centralized design: job management service and bookkeeping database are hosted in a European Grid Infrastructure (EGI) site. Jobs executed into remote sites transfer their output to predefined target site repository and update the bookkeeping database. In addition, the framework requires a proper configuration of the remote Grid sites on which the jobs will run. Results from a large production of Monte Carlo simulated events submitted to 15 Grid sites are reported, and a comparison in terms of features, scopes, and targets, with a broad spectrum of general-purpose solutions in the same field of application is presented as well.","1082-3654","978-1-4673-0120-6","10.1109/NSSMIC.2011.6154459","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6154459","","Internet;Europe;Information services;Electronic publishing;Chemistry","grid computing;high energy physics instrumentation computing;human computer interaction;Internet;Monte Carlo methods;resource allocation;user interfaces","general-purpose software suite framework;multidisciplinary community;grid resource exploitation;bookkeeping database interaction;CPU-intensive loose-parallel task;job submission management;Web-based user-interface;European grid infrastructure site;high energy physics environment;complex framework;infrastructure metadata;eLog system;basic monitoring functionality;multisite submission mechanism;application-specific metadata;target site repository;Monte Carlo simulated event","","","","40","","20 Feb 2012","","","IEEE","IEEE Conferences"
"Crack pattern simulation based on 3D surface cellular automaton","S. Gobron; N. Chiba","Iwate Univ., Morioka, Japan; NA","Proceedings Computer Graphics International 2000","6 Aug 2002","2000","","","153","162","Describes a method for modeling the propagation of cracks on any 3D surface. Taking a previous cellular automata model of the authors (1999) as the basis, this method allows just about any type of cracks on any type of triangulated 3D object. Our model's main advantage is that it proposes a semi-physical solution, making it at the same time user-controllable and easily extendable. After summarizing works in the literature, we make a brief and simple description of what cracks are physically, and how they are generated. Based on this idea, we detail our model of crack propagation. We first introduce the general development of cracks. We then propose an original model of spectrum stress. This is followed by a description of the mutual interaction between cracks and stresses. Finally, a set of graphical examples, together with their respective parameters, concludes this paper.","","0-7695-0643-7","10.1109/CGI.2000.852330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=852330","","Surface cracks;Automata;Deformable models;Character generation;Surface texture;Computational modeling;Stress;Computer simulation;Animation;Automatic control","crazing;fracture;digital simulation;physics computing;computer graphics;cellular automata;crack-edge stress field analysis","crack pattern simulation;3D surface cellular automaton;triangulated 3D object;semi-physical solution;user-controllable model;extendable model;crack generation;crack propagation;spectrum stress;crack-stress interaction;computer graphics;parameters","","","","33","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Measurement system of α β surface radioactive contamination based on Virtual Training","Hui Weihua; Huang Changqiang; Ding Dali","The Engineering Institute, Air Force Engineering University, Xi'an 710038, China; The Engineering Institute, Air Force Engineering University, Xi'an 710038, China; The Engineering Institute, Air Force Engineering University, Xi'an 710038, China","IEEE 2011 10th International Conference on Electronic Measurement & Instruments","10 Oct 2011","2011","2","","90","93","A Virtual Training System of α β surface radioactive contamination measurement is constructed based on Virtual Reality. Firstly, 3-d geometric models about radioactive environment, radioactive environment of surface device, α β detector, surface contamination instrument are constructed, the general radioactive law based on face radioactive source is presented. These models are driving in general program platform using human-computer interaction technology. Furthermore, there are several functions about database sharing, fault diagnosis, examining evaluation and on-time help which realize the whole system virtual training. Program show this training system avoid “nuclear fear” psychology and improve staff's training effect.","","978-1-4244-8161-3","10.1109/ICEMI.2011.6037772","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6037772","virtual training;radioactivity;α ray;β ray;radiation field","Pollution measurement;Training;Surface contamination;Solid modeling;Instruments;Software","nuclear power stations;radioactivity measurement;surface contamination;virtual reality","measurement system;surface radioactive contamination;virtual training;virtual reality;3D geometric models;radioactive environment;surface contamination instrument;human-computer interaction technology;database sharing;fault diagnosis","","","","4","","10 Oct 2011","","","IEEE","IEEE Conferences"
"Repurposing Visual Input Modalities for Blind Users: A Case Study of Word Processors","H. -N. Lee; V. Ashok; I. V. Ramakrishnan","Stony Brook University,Department of Computer Science,Stony Brook,NY,USA; Old Dominion University,Department of Computer Science,Norfolk,VA,USA; Stony Brook University,Department of Computer Science,Stony Brook,NY,USA","2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","14 Dec 2020","2020","","","2714","2721","Visual `point-and-click' interaction artifacts such as mouse and touchpad are tangible input modalities, which are essential for sighted users to conveniently interact with computer applications. In contrast, blind users are unable to leverage these visual input modalities and are thus limited while interacting with computers using a sequentially narrating screen-reader assistive technology that is coupled to keyboards. As a consequence, blind users generally require significantly more time and effort to do even simple application tasks (e.g., applying a style to text in a word processor) using only keyboard, compared to their sighted peers who can effortlessly accomplish the same tasks using a point-and-click mouse. This paper explores the idea of repurposing visual input modalities for non-visual interaction so that blind users too can draw the benefits of simple and efficient access from these modalities. Specifically, with word processing applications as the representative case study, we designed and developed NVMouse as a concrete manifestation of this repurposing idea, in which the spatially distributed word-processor controls are mapped to a virtual hierarchical `Feature Menu' that is easily traversable non-visually using simple scroll and click input actions. Furthermore, NVMouse enhances the efficiency of accessing frequently-used application commands by leveraging a data-driven prediction model that can determine what commands the user will most likely access next, given the current `local' screen-reader context in the document. A user study with 14 blind participants comparing keyboard-based screen readers with NVMouse, showed that the latter significantly reduced both the task-completion times and user effort (i.e., number of user actions) for different word-processing activities.","2577-1655","978-1-7281-8526-2","10.1109/SMC42975.2020.9283015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283015","Accessibility;assistive technology;screen reader;visual impairment;word processing","Productivity;Visualization;Keyboards;Predictive models;Mice;Task analysis;Text processing","data visualisation;handicapped aids;interactive devices;keyboards;user interfaces","click input actions;user actions;visual input modalities;blind users;word processor;tangible input modalities;sighted users;computer applications;sequentially narrating screen-reader assistive technology;simple application tasks;nonvisual interaction;word processing applications;spatially distributed word-processor controls;simple scroll;point-and-click mouse;point-and-click interaction artifacts;keyboard-based screen readers;blind participants","","","","20","","14 Dec 2020","","","IEEE","IEEE Conferences"
"Extending haptic augmented reality: Modulating stiffness during two-point squeezing","S. Jeon; M. Harders","Computer Vision Laboratory, ETH Zurich, Switzerland; Computer Vision Laboratory, ETH Zurich, Switzerland","2012 IEEE Haptics Symposium (HAPTICS)","16 Apr 2012","2012","","","141","146","This paper is concerned with haptic augmented reality, which allows us to merge virtual haptic stimuli into the real haptic environment. Considering the modulation of real haptic properties as a key functionality, we previously focused on modulating stiffness of a real fixed object constrained at one contact point. In this paper we generalize the approach by enabling a user to grasp, lift, and manipulate an object via two interaction points. Modulated stiffness can be explored by squeezing an object. To this end, two haptic interfaces equipped with force sensors are employed to render the additional virtual forces of the augmentation at the two interaction points. We introduce the required extended algorithms and evaluate the performance in a pilot user study. A longer term goal of our work is the development of a training environment for tumor palpation.","2324-7355","978-1-4673-0809-0","10.1109/HAPTIC.2012.6183782","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6183782","","Haptic interfaces;Force;Modulation;Rendering (computer graphics);Vectors;Visualization;Hardware","augmented reality;elasticity;haptic interfaces;modulation","haptic augmented reality;stiffness modulation;two-point squeezing;virtual haptic stimuli;real haptic environment;real haptic properties;object manipulation;modulated stiffness;haptic interfaces;force sensors;virtual forces;training environment;tumor palpation","","7","","18","","16 Apr 2012","","","IEEE","IEEE Conferences"
"A Gesture Learning Interface for Simulated Robot Path Shaping With a Human Teacher","P. M. Yanik; J. Manganelli; J. Merino; A. L. Threatt; J. O. Brooks; K. E. Green; I. D. Walker","Department of Engineering and Technology, Western Carolina University, Cullowhee, NC, USA; School of Architecture at Clemson University, Clemson, SC, USA; Department of Electrical and Computer Engineering, Clemson University, Clemson, SC, USA; School of Architecture at Clemson University, Clemson, SC, USA; Department of Psychology, Clemson University, Clemson, USA; School of Architecture at Clemson University, Clemson, SC, USA; Department of Electrical and Computer Engineering, Clemson University, Clemson, SC, USA","IEEE Transactions on Human-Machine Systems","20 May 2017","2014","44","1","41","54","Recognition of human gestures is an active area of research integral for the development of intuitive human-machine interfaces for ubiquitous computing and assistive robotics. In particular, such systems are key to effective environmental designs that facilitate aging in place. Typically, gesture recognition takes the form of template matching in which the human participant is expected to emulate a choreographed motion as prescribed by the researchers. A corresponding robotic action is then a one-to-one mapping of the template classification to a library of distinct responses. In this paper, we explore a recognition scheme based on the growing neural gas (GNG) algorithm that places no initial constraints on the user to perform gestures in a specific way. Motion descriptors extracted from sequential skeletal depth data are clustered by GNG and mapped directly to a robotic response that is refined through reinforcement learning. A simple good/bad reward signal is provided by the user. This paper presents results that show that the topology-preserving quality of GNG allows generalization between gestured commands. Experimental results using an automated reward are presented that compare learning results involving single nodes versus results involving the influence of node neighborhoods. Although separability of input data influences the speed of learning convergence for a given neighborhood radius, it is shown that learning progresses toward emulation of an associative memory that maps input gesture to desired action.","2168-2305","","10.1109/TSMC.2013.2291714","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6687233","Gesture recognition;human-robot interaction;machine learning;robots","Robot sensing systems;Gesture recognition;Neural networks;Hidden Markov models;Topology","gesture recognition;human-robot interaction;image classification;neurocontrollers;path planning;robot vision;robots","gesture learning interface;simulated robot path shaping;human teacher;human gesture recognition;intuitive human-machine interfaces;ubiquitous computing;assistive robotics;template matching;one-to-one mapping;choreographed motion emulation;template classification;GNG algorithm;growing neural gas;motion descriptors;sequential skeletal depth data;reinforcement learning;good-bad reward signal;topology-preserving quality;generalization;node neighborhoods;input data separability;associative memory","","23","","75","","18 Dec 2013","","","IEEE","IEEE Journals"
"A generic framework for an interface tutor agent within a virtual collaborative learning environment","B. -. Marin; A. Hunger; S. Werner; S. Meila; C. Schuetz","Inst. of Multimedia & Software Eng., Duisburd Univ., Duisburg, Germany; Inst. of Multimedia & Software Eng., Duisburd Univ., Duisburg, Germany; Inst. of Multimedia & Software Eng., Duisburd Univ., Duisburg, Germany; Inst. of Multimedia & Software Eng., Duisburd Univ., Duisburg, Germany; Inst. of Multimedia & Software Eng., Duisburd Univ., Duisburg, Germany","IEEE International Conference on Advanced Learning Technologies, 2004. Proceedings.","22 Nov 2004","2004","","","31","35","Interface agents are a branch of the general research field of software agents which exist as a primary point of contact between human and computer. This paper aims at showing how to integrate an interface tutor (pedagogical) agent in a virtual collaborative learning environment in order to help students in the process of learning and the benefits from this human-computer interaction.","","0-7695-2181-9","10.1109/ICALT.2004.1357369","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1357369","","Collaborative work;Software engineering;Humans;Application software;Animation;Software agents;Computer interfaces;Intelligent agent;Virtual environment;Virtual groups","intelligent tutoring systems;software agents;user interfaces;human computer interaction;groupware;teaching","interface tutor agent;virtual collaborative learning environment;software agents;human-computer contact;pedagogical agent;student learning;human-computer interaction","","6","","14","","22 Nov 2004","","","IEEE","IEEE Conferences"
"Six-degree-of-freedom haptic rendering using translational and generalized penetration depth computation","Y. Li; M. Tang; S. Zhang; Y. J. Kim",Computer Science and Engineering Ewha Womans University; Computer Science and Engineering Ewha Womans University; Computer Science and Technology Zhejiang University; Computer Science and Engineering Ewha Womans University,"2013 World Haptics Conference (WHC)","27 Jun 2013","2013","","","289","294","We present six-degree-of-freedom (6DoF) haptic rendering algorithms using translational (PDt) and generalized penetration depth (PDg). Our rendering algorithm can handle any type of object/object haptic interaction using penalty-based response and makes no assumption about the underlying geometry and topology. Moreover, our rendering algorithm can effectively deal with multiple contacts. Our penetration depth algorithms for PDt and PDg are based on a contact-space projection technique combined with iterative, local optimization on the contact-space. We circumvent the local minima problem, imposed by the local optimization, using motion coherence present in the haptic simulation. Our experimental results show that our methods can produce high-fidelity force feedback for general polygonal models consisting of tens of thousands of triangles at near-haptic rates, and are successfully integrated into an off-the-shelf 6DoF haptic device. We also discuss the benefits of using different formulations of penetration depth in the context of 6DoF haptics.","","978-1-4799-0088-6","10.1109/WHC.2013.6548423","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6548423","","Haptic interfaces;Rendering (computer graphics);Handheld computers;Probes;Computational modeling;Torque;Force","force feedback;geometry;haptic interfaces;iterative methods;optimisation;rendering (computer graphics);solid modelling;topology","six-degree-of-freedom haptic rendering;translational depth computation;generalized penetration depth computation;6DoF haptic rendering algorithms;translational penetration depth;object interaction;object haptic interaction;penalty-based response;geometry;topology;penetration depth algorithms;contact-space projection technique;iterative technique;local optimization technique;contact-space technique;local minima problem;motion coherence;haptic simulation;high-fidelity force feedback;general polygonal models;near-haptic rates;off-the-shelf 6DoF haptic device;6DoF haptics","","2","","31","","27 Jun 2013","","","IEEE","IEEE Conferences"
"MyVision AIR: An augmented interactive reality book mobile application","H. Al-Ali; M. W. Bazzaza; M. J. Zemerly; J. W. P. Ng","Dept. Electrical and Computer Engineering, Khalifa University of Science, Technology and Research, Abu Dhabi, UAE; Dept. Electrical and Computer Engineering, Khalifa University of Science, Technology and Research, Abu Dhabi, UAE; Dept. Electrical and Computer Engineering, Khalifa University of Science, Technology and Research, Abu Dhabi, UAE; Etisalat BT Innovation Center (EBTIC) BT Innovate and Design, Abu Dhabi, UAE","2016 IEEE Global Engineering Education Conference (EDUCON)","23 May 2016","2016","","","741","745","This paper presents an Augmented Interactive Reality book (AIR) application, aimed to enhance the reading experience of adult-learners by incorporating Augmented Reality (AR) technology to improve the interaction of normal books. Various features and characteristics of Augmented Reality (AR) were applied to the chosen book, ""My Vision"" written by H.H. Sheikh Mohammed Bin Rashid Al Maktoum, Vice-President and Prime Minister of the UAE and Ruler of Dubai. The project is a joint-collaboration between Etisalat British Telecommunication Innovation Center (EBTIC) and Khalifa University, as part of the iCampus project on ""Smart Learning-Edutainment"". The project has received a number of positive feedbacks from the field study conducted with the general public, and has also been presented to H.H. Sheikh Mohammed Bin Rashid Al Maktoum - Ruler of Dubai, H.H. Sheikh Saif Bin Zayed Al Nahyan - Deputy Prime Minister and Minister of Interior, and several others.","2165-9567","978-1-4673-8633-3","10.1109/EDUCON.2016.7474634","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7474634","","Augmented reality;Three-dimensional displays;Solid modeling;Cameras;Software;Animation;Creativity","augmented reality;computer science education","MyVision AIR;augmented interactive reality book mobile application;AIR application;Etisalat British Telecommunication Innovation Center;EBTIC;Khalifa University;iCampus project;Smart Learning-Edutainment","","1","","13","","23 May 2016","","","IEEE","IEEE Conferences"
"Efficient model learning for dialog management","F. Doshi; N. Roy","CSAIL MIT, 32 Vassar Street, Cambridge, MA 02139, USA; CSAIL MIT, 32 Vassar Street, Cambridge, MA 02139, USA","2007 2nd ACM/IEEE International Conference on Human-Robot Interaction (HRI)","30 Jul 2012","2007","","","65","72","Intelligent planning algorithms such as the Partially Observable Markov Decision Process (POMDP) have succeeded in dialog management applications [10, 11, 12] because they are robust to the inherent uncertainty of human interaction. Like all dialog planning systems, however, POMDPs require an accurate model of the user (e.g., what the user might say or want). POMDPs are generally specified using a large probabilistic model with many parameters. These parameters are difficult to specify from domain knowledge, and gathering enough data to estimate the parameters accurately a priori is expensive. In this paper, we take a Bayesian approach to learning the user model simultaneously with dialog manager policy. At the heart of our approach is an efficient incremental update algorithm that allows the dialog manager to replan just long enough to improve the current dialog policy given data from recent interactions. The update process has a relatively small computational cost, preventing long delays in the interaction. We are able to demonstrate a robust dialog manager that learns from interaction data, out-performing a hand-coded model in simulation and in a robotic wheelchair application.","2167-2148","978-1-59593-617-2","10.1145/1228716.1228726","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6251718","Human-robot interaction;decision-making under uncertainty;model learning","Robots;Convergence;Abstracts;Face;Pragmatics;History;Planning","Bayes methods;human-robot interaction;interactive systems;learning (artificial intelligence);Markov processes;wheelchairs","model learning;intelligent planning algorithms;partially observable Markov decision process;POMDP;dialog management applications;human interaction uncertainty;probabilistic model;Bayesian approach;dialog manager policy;incremental update algorithm;robust dialog manager;robotic wheelchair application","","7","","12","","30 Jul 2012","","","IEEE","IEEE Conferences"
"Evaluation of the Application of Smart Glasses for Decentralized Control Systems in Logistics","T. Kirks; J. Jost; T. Uhlott; J. Püth; M. Jakobs","Fraunhofer Institute for Material Flow and Logistics,Department Automation and Embedded Systems,Dortmund,Germany,44227; Fraunhofer Institute for Material Flow and Logistics,Department Automation and Embedded Systems,Dortmund,Germany,44227; Fraunhofer Institute for Material Flow and Logistics,Department Automation and Embedded Systems,Dortmund,Germany,44227; Fraunhofer Institute for Material Flow and Logistics,Department Automation and Embedded Systems,Dortmund,Germany,44227; Fraunhofer Institute for Material Flow and Logistics,Department Automation and Embedded Systems,Dortmund,Germany,44227","2019 IEEE Intelligent Transportation Systems Conference (ITSC)","28 Nov 2019","2019","","","4470","4476","The approach of this paper is to investigate the application of smart glasses for human-robot interaction for scenarios like warehouse logistics, transportation systems and logistics in general. Following various research questions we conduct an experiment with multiple tests to gather information on the accuracy of localization with the Microsoft HoloLens and the feasibility of its application. The tests can also be taken into account when testing other wearables for the same purpose. An adequate accuracy enables the human worker to be integrated in decentralized control systems better and build teams of the diverse entities in human-robot interaction and cooperation.","","978-1-5386-7024-8","10.1109/ITSC.2019.8917159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917159","","Robots;Logistics;Navigation;Tracking;Human-robot interaction;Decentralized control;Multi-agent systems","augmented reality;decentralised control;human-robot interaction;logistics;production engineering computing","human worker;decentralized control systems;human-robot interaction;smart glasses;warehouse logistics;transportation systems;Microsoft HoloLens","","","","20","","28 Nov 2019","","","IEEE","IEEE Conferences"
"A Multi-rate Control Approach to Haptic Interaction in Multi-user Virtual Environments","M. Fotoohi; S. Sirouspour; D. Capson","Department of Electrical and Computer Engineering, McMaster University, Hamilton, Ontario L8S 4K1, Canada; Department of Electrical and Computer Engineering, McMaster University, Hamilton, Ontario L8S 4K1, Canada. Email: sirouspour@ece.mcmaster.ca; Department of Electrical and Computer Engineering, McMaster University, Hamilton, Ontario L8S 4K1, Canada","Proceedings 2007 IEEE International Conference on Robotics and Automation","21 May 2007","2007","","","99","104","High-fidelity haptic interaction in multi-user environments over general Ethernet-based local area networks (LAN) and metropolitan area networks (MAN) can be challenging but has promising applications. Under typical network traffic conditions, the 1kHz real-time control rate suggested in the literature for stable haptic simulation is well above that achievable by conventional network protocols such as the UDP and TCP/IP. To overcome this limitation, a decentralized multi-rate control approach is proposed in which local force-feedback loops are executed at higher rates than data packet transmission between the user workstations. Mathematical models for stability and performance analysis of such multi-rate haptic control systems are presented. Analytical and experimental results demonstrate improved performance and stability for the distributed control architecture when compared with a centralized controller.","1050-4729","1-4244-0601-3","10.1109/ROBOT.2007.363771","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4209076","Haptic Interfce Control;Cooperative Haptics;Collaborative Haptics;Multi-user Haptics;Collaborative Virtual Environments;Multi-rate Control Systems","Haptic interfaces;Virtual environment;Local area networks;Force control;Stability analysis;Performance analysis;Metropolitan area networks;Communication system traffic control;Traffic control;Protocols","data communication;force feedback;groupware;haptic interfaces;local area networks;metropolitan area networks;stability;telecommunication traffic","multiuser virtual environments;high-fidelity haptic interaction;Ethernet-based local area networks;metropolitan area networks;network traffic;haptic simulation;network protocols;force feedback;data packet transmission;stability;multirate haptic control system;distributed control;collaborative haptics","","3","","12","","21 May 2007","","","IEEE","IEEE Conferences"
"Recognizing Human Emotional State Based on the 2D-FrFT and FLDA","L. Qi; E. Chen; X. Mu; L. Guan; S. Zhang; L. Gao","Inf. Eng. Sch., Zhengzhou Univ., Zhengzhou, China; Inf. Eng. Sch., Zhengzhou Univ., Zhengzhou, China; Inf. Eng. Sch., Zhengzhou Univ., Zhengzhou, China; Dept. of Electr. & Comput. Eng., Ryerson Univ. Toronto, Toronto, ON, Canada; Inf. Eng. Sch., Zhengzhou Univ., Zhengzhou, China; Inf. Eng. Sch., Zhengzhou Univ., Zhengzhou, China","2009 2nd International Congress on Image and Signal Processing","30 Oct 2009","2009","","","1","4","Computer recognition of human emotional states is an important component for efficient human-computer interaction. In this paper we explore an approach for recognition of human emotion from the visual information. We perform feature selection by using the two dimensions fractional Fourier transform. As a generalization of Fourier transform, the two dimensions fractional Fourier transform (2D-FrFT) contains simultaneity the time-frequency information of the signal, and is considered as a new tool for time-frequency analysis, especially in the area of image recognition. In this paper we use the amplitude of the 2D-FrFT of an image as the feature of the images to train the FLDA multiclassifier for human emotion recognition. Simulation result shows that this method of the features extraction and classifier has high recognition rate.","","978-1-4244-4129-7","10.1109/CISP.2009.5304269","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5304269","","Emotion recognition;Fourier transforms;Feature extraction;Time frequency analysis;Human computer interaction;Data mining;Optical filters;Signal analysis;Image recognition;Computational modeling","emotion recognition;feature extraction;Fourier transforms;human computer interaction;time-frequency analysis","human emotional state recognition;2D FrFT;computer recognition;human computer interaction;visual information;fractional Fourier transform;time-frequency analysis;image recognition;FLDA multiclassifier;feature extraction;Fisher linear discriminant analysis","","7","","8","","30 Oct 2009","","","IEEE","IEEE Conferences"
"A Six Degree-of-Freedom God-Object Method for Haptic Display of Rigid Bodies with Surface Properties","M. Ortega; S. Redon; S. Coquillart","Rhone-Alpes Res. Unit, INRIA, Saint Ismier; NA; NA","IEEE Transactions on Visualization and Computer Graphics","4 Sep 2007","2007","13","3","458","469","This paper describes a generalization of the god-object method for haptic interaction between rigid bodies. Our approach separates the computation of the motion of the six degree-of-freedom god-object from the computation of the force applied to the user. The motion of the god-object is computed using continuous collision detection and constraint-based quasi-statics, which enables high-quality haptic interaction between contacting rigid bodies. The force applied to the user is computed using a novel constraint-based quasi-static approach, which allows us to suppress force artifacts typically found in previous methods. The constraint-based force applied to the user, which handles any number of simultaneous contact points, is computed within a few microseconds, while the update of the configuration of the rigid god-object is performed within a few milliseconds for rigid bodies containing up to tens of thousands of triangles. Our approach has been successfully tested on complex benchmarks. Our results show that the separation into asynchronous processes allows us to satisfy the different update rates required by the haptic and visual displays. Force shading and textures can be added and enlarge the range of haptic perception of a virtual environment. This paper is an extension of M. Ortega et al., [2006]","1941-0506","","10.1109/TVCG.2007.1028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4297687","Haptics;god-object;six degrees of freedom;rigid bodies;constraint-based quasi-statics.","Haptic interfaces;Displays;Virtual environment;Computational modeling;Motion detection;Benchmark testing;Humans;Design automation;Computer aided manufacturing;CADCAM","computational geometry;display devices;haptic interfaces;rendering (computer graphics);virtual reality","six degree-of-freedom god-object method;haptic display;rigid body;surface properties;haptic interaction;collision detection;constraint-based quasistatics;visual displays;haptic perception;virtual environment;haptic rendering methods","","78","6","36","","4 Sep 2007","","","IEEE","IEEE Journals"
"Package and chip-level EMI/EMC structure design, modeling and simulation","E. Diaz-Alvarez; J. P. Krusius","Sch. of Electr. Eng., Cornell Univ., Ithaca, NY, USA; NA","1999 Proceedings. 49th Electronic Components and Technology Conference (Cat. No.99CH36299)","6 Aug 2002","1999","","","873","878","Electromagnetic interference (EMI) and electromagnetic compatibility (EMC) issues are generally managed on the subsystem level in today's electronic systems. With the introduction of compact mixed signal assemblies and mixed signal integrated circuits (IC), EMI/EMC problems have to be solved on the package or chip levels in the near future. Sources, and conductive and radiative interaction mechanisms for representative packages and IC's are quantified in this paper. Package-to-substrate, chip-to-package, and chip partition-to-partition feedthroughs are identified as one of the key issue. 3D electromagnetic radiative finite element simulations for EMI coupling for representative feedthrough structures are presented. Structures for managing package and chip level EMI/EMC are proposed.","0569-5503","0-7803-5231-9","10.1109/ECTC.1999.776285","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=776285","","Electromagnetic interference;Electromagnetic compatibility;Integrated circuit packaging;Electronics packaging;Electromagnetic coupling;Electromagnetic compatibility and interference;Assembly;Mixed analog digital integrated circuits;Electromagnetic radiation;Finite element methods","electromagnetic interference;electromagnetic compatibility;packaging;finite element analysis;digital simulation;electromagnetic shielding","package-level EMI/EMC structure design;chip-level EMI/EMC structure design;modeling;simulation;electromagnetic interference;electromagnetic compatibility;compact mixed signal assemblies;mixed signal integrated circuits;conductive interaction mechanisms;radiative interaction mechanisms;package-to-substrate feedthroughs;chip-to-package feedthroughs;chip partition-to-partition feedthroughs;3D EM radiative finite element simulations;EMI coupling;feedthrough structures","","8","1","3","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Virtual Character Animation Based on Affordable Motion Capture and Reconfigurable Tangible Interfaces","F. Lamberti; G. Paravati; V. Gatteschi; A. Cannavò; P. Montuschi","Dipartimento di Automatica e Informatica of Politecnico di Torino, Corso Duca degli Abruzzi 24, Torino, Italy; Dipartimento di Automatica e Informatica of Politecnico di Torino, Corso Duca degli Abruzzi 24, Torino, Italy; Dipartimento di Automatica e Informatica of Politecnico di Torino, Corso Duca degli Abruzzi 24, Torino, Italy; Dipartimento di Automatica e Informatica of Politecnico di Torino, Corso Duca degli Abruzzi 24, Torino, Italy; Dipartimento di Automatica e Informatica of Politecnico di Torino, Corso Duca degli Abruzzi 24, Torino, Italy","IEEE Transactions on Visualization and Computer Graphics","27 Mar 2018","2018","24","5","1742","1755","Software for computer animation is generally characterized by a steep learning curve, due to the entanglement of both sophisticated techniques and interaction methods required to control 3D geometries. This paper proposes a tool designed to support computer animation production processes by leveraging the affordances offered by articulated tangible user interfaces and motion capture retargeting solutions. To this aim, orientations of an instrumented prop are recorded together with animator's motion in the 3D space and used to quickly pose characters in the virtual environment. High-level functionalities of the animation software are made accessible via a speech interface, thus letting the user control the animation pipeline via voice commands while focusing on his or her hands and body motion. The proposed solution exploits both off-the-shelf hardware components (like the Lego Mindstorms EV3 bricks and the Microsoft Kinect, used for building the tangible device and tracking animator's skeleton) and free open-source software (like the Blender animation tool), thus representing an interesting solution also for beginners approaching the world of digital animation for the first time. Experimental results in different usage scenarios show the benefits offered by the designed interaction strategy with respect to a mouse & keyboard-based interface both for expert and non-expert users.","1941-0506","","10.1109/TVCG.2017.2690433","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7891591","Tangible user interfaces;natural user interfaces;motion capture;human-machine interaction;computer animation","Animation;Tracking;Three-dimensional displays;Instruments;Production;User interfaces;Mice","computer animation;human computer interaction;public domain software;user interfaces","animation pipeline;body motion;tangible device;open-source software;digital animation;virtual character animation;steep learning curve;interaction methods;computer animation production processes;articulated tangible user interfaces;motion capture retargeting solutions;virtual environment;high-level functionalities;animation software;speech interface;hands motion;interaction strategy","","4","","50","","3 Apr 2017","","","IEEE","IEEE Journals"
"A cyber-physical power system test bed for intrusion detection systems","U. Adhikari; T. H. Morris; S. Pan","Dept. of Electrical and Computer Engineering, Mississippi State University, Mississippi State, MS 39762; Dept. of Electrical and Computer Engineering, Mississippi State University, Mississippi State, MS 39762; Dept. of Electrical and Computer Engineering, Mississippi State University, Mississippi State, MS 39762","2014 IEEE PES General Meeting | Conference & Exposition","30 Oct 2014","2014","","","1","5","The rapid advancement of technology used in operation, monitoring, and control introduces several threats against power system. Cyber-physical power system vulnerabilities are increasing and the consequences of attack can be catastrophic. Understanding power system phenomena and attacks is vital to identifying and detecting such events. Researchers require a suitable power system test bed that can provide a platform for simulation of power system events and attacks. An essential part of such a test bed is the ability to provide software and hardware interaction to mimic real world scenarios. This paper presents a test bed for the development of an intrusion detection system (IDS) for power systems. The test bed consists of a power system modeled on a real time digital simulator (RTDS), a data collection and processing engine, and a MATLAB/RSCAD parameter calculation engine. This test bed provides a platform for hardware in the loop (HIL) simulation, power system attacks, and generates data sets required by cyber security researchers. Coordinated distance protection and overcurrent protection schemes are implemented on the IEEE 9 bus system and a 3-generator 4 bus system [11]. Fault, contingency and cyber-attack scenarios have been developed for both power systems. Selected relevant simulation results are presented.","1932-5517","978-1-4799-6415-4","10.1109/PESGM.2014.6939262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6939262","attacks;contingencies;data;faults;IDS;power system;test bed","Relays;Circuit faults;Power system stability;Phasor measurement units;Power transmission lines;Generators","digital simulation;IEEE standards;overcurrent protection;power engineering computing;power system control;power system faults;power system measurement;power system protection;power system security","cyber-physical power system;intrusion detection system;power system. operation;power system monitoring;power system control;power system attack simulation;software and hardware interaction;IDS;real time digital simulator;RTDS;data collection;data processing engine;hardware in the loop simulation;HIL simulation;overcurrent protection schemes;IEEE 9 bus system;3-generator 4 bus system;power systems. Fault","","8","","18","","30 Oct 2014","","","IEEE","IEEE Conferences"
"Codevelopmental Learning Between Human and Humanoid Robot Using a Dynamic Neural-Network Model","J. Tani; R. Nishimoto; J. Namikawa; M. Ito","RIKEN Brain Sci. Inst., Wako; RIKEN Brain Sci. Inst., Wako; RIKEN Brain Sci. Inst., Wako; NA","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","16 Jan 2008","2008","38","1","43","59","This paper examines characteristics of interactive learning between human tutors and a robot having a dynamic neural-network model, which is inspired by human parietal cortex functions. A humanoid robot, with a recurrent neural network that has a hierarchical structure, learns to manipulate objects. Robots learn tasks in repeated self-trials with the assistance of human interaction, which provides physical guidance until the tasks are mastered and learning is consolidated within the neural networks. Experimental results and the analyses showed the following: 1) codevelopmental shaping of task behaviors stems from interactions between the robot and a tutor; 2) dynamic structures for articulating and sequencing of behavior primitives are self-organized in the hierarchically organized network; and 3) such structures can afford both generalization and context dependency in generating skilled behaviors.","1941-0492","","10.1109/TSMCB.2007.907738","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4378437","Compositionality;continuous-time recurrent neural network (CTRNN);development learning;humanoid robot;Compositionality;continuous-time recurrent neural network (CTRNN);development learning;humanoid robot","Humanoid robots;Robot kinematics;Brain modeling;Orbital robotics;Indium tin oxide;Human robot interaction;Recurrent neural networks;Circuits;Robot sensing systems;Supervised learning","human computer interaction;humanoid robots;interactive systems;learning (artificial intelligence);recurrent neural nets;task analysis","codevelopmental interactive learning;human-humanoid robot;dynamic recurrent neural-network model;human tutors;human parietal cortex function;human interaction;task learning","Artificial Intelligence;Biomimetics;Biomimetics;Computer Simulation;Cybernetics;Humans;Man-Machine Systems;Models, Theoretical;Neural Networks (Computer);Robotics;Robotics;User-Computer Interface","34","","51","","16 Jan 2008","","","IEEE","IEEE Journals"
"Archeovirtual 2011: An evaluation approach to virtual museums","S. Pescarin; A. Pagano; M. Wallergård; W. Hupperetz; C. Ray","Virtual Heritage Laboratory, CNR ITABC, Rome, Italy; University of Lugano, Switzerland; Lund University, Sweden; Allard Pierson Museum, University of Amsterdam Netherlands; Allard Pierson Museum, University of Amsterdam, Netherlands","2012 18th International Conference on Virtual Systems and Multimedia","3 Dec 2012","2012","","","25","32","November 2011 saw the opening of the exhibition “Archeovirtual” organized by CNR ITABC - Virtual Heritage Lab - and V-MusT Network of Excellence, in Paestum, Italy, under the general direction of BMTA1. The event, that was part of a wider European project focus on virtual museums, turned to be a great opportunity to show many different projects, applications and installations about Virtual Reality and Cultural Heritage. The four-days exhibition was an occasion to get in touch with the newest experiences with virtual reconstructions, 3D models, interactive environments, augmented reality and mobile solutions for cultural contents; at the same time, it was an opportunity for organizers to directly face the audience's impact towards projects. That because of the necessity to investigate more on social and behavioral aspects in order to positively affect the learning benefits of public. So doing, we could build in the future applications much more tailored on the final costumers, closer to their abilities and necessities. During the show four types of investigative tools were employed to evaluate the general visitor's behavior and the effectiveness of interfaces, to understand their expectations and experiences, and to obtain a reference grid of values to test if users' experience fit with organizers' ones. The first outcomes revealed that audience's impact toward interactive applications seems depending on the capability of technology to be “invisible” otherwise technology has to assure a wide range of possibilities in content accesses. In definitive, virtual museums need to have an always more integrated approach between cultural contents, interfaces and social and behavioral studies.","","978-1-4673-2563-9","10.1109/VSMM.2012.6365903","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365903","virtual museum;social and behavioral investigation;information interface;interaction;sensory immersion","Usability;Cultural differences;Face;Educational institutions;Europe;Interviews;User interfaces","history;interactive systems;museums;solid modelling;virtual reality","Archeovirtual 2011;virtual museums;CNR ITABC;Virtual Heritage Lab;European project;virtual reality;cultural heritage;virtual reconstructions;3D models;interactive environments;augmented reality;mobile solutions;cultural contents;reference grid;interactive applications","","14","","10","","3 Dec 2012","","","IEEE","IEEE Conferences"
"Development and evaluation of a mobile AR assisted learning system for English learning","M. Hsieh","Fortune Institute of Technology, No. 288, Chihshiue Rd., Daliao District, Kaohsiung City 83158, Taiwan","2016 International Conference on Applied System Innovation (ICASI)","11 Aug 2016","2016","","","1","4","Increasing researches have indicated that digital media learning materials are emerged to education in recent years. Multimedia learning environments have offered new ways for learners to interact with various educational resources. Some studies have mentioned that the AR technologies should better employment in learning environments. This paper presents AR-based technologies to develop and evaluate a mobile English learning system. The learning content was based on English prepositions. The multimedia formats included text, image, movie, and interaction. Furthermore, this paper utilizes questionnaire and observation, to explore the system acceptance and learning behavior of students learning. The results found that the mobile AR English learning system could enhance students' attention and affect their learning behaviors. Students generally accepted the mobile AR English assisted learning environment.","","978-1-4673-9888-6","10.1109/ICASI.2016.7539743","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539743","augmented reality;augmented reality learning environment;English learning;user acceptance","Decision support systems;Conferences;Computers;Urban areas;Encoding;Education;Information technology","augmented reality;computer aided instruction;ergonomics;linguistics;multimedia systems","digital media learning materials;educational resources;AR-based technologies;English prepositions;multimedia learning environments;multimedia formats;student attention;learning behaviors;mobile AR assisted English learning system","","","","18","","11 Aug 2016","","","IEEE","IEEE Conferences"
"Robot Action Planning by Commonsense Knowledge in Human-Robot Collaborative Tasks","C. J. Conti; A. S. Varde; W. Wang","Montclair State University,Deparment of Computer Science,Montclair,NJ,USA; Montclair State University,Deparment of Computer Science,Montclair,NJ,USA; Montclair State University,Deparment of Computer Science,Montclair,NJ,USA","2020 IEEE International IOT, Electronics and Mechatronics Conference (IEMTRONICS)","8 Oct 2020","2020","","","1","7","Robotics and artificial intelligence (AI) span the broad realm of mechatronics in general. Humans and robots can collaborate with each other to enhance various tasks, e.g. in the vehicle industry. Facets of AI such as commonsense knowledge can play a significant role here. In this paper, we propose an approach for human-robot collaboration such that it leverages commonsense knowledge to develop models for the simulation of assembly tasks in real-world applications. We consider modeling based on relevant attributes, e.g. weight and stability of parts. The proposed approach thereby entails human-robot interaction, mathematical modeling, both semantics and pragmatics in commonsense knowledge, as well as challenges specific to the application domain. We describe our approach, focusing on the mathematical modeling, and conduct our experimental evaluation using simulation tasks. Experimental results indicate that the proposed approach yields better outcomes than humans or robots working alone, which is in line with other such claims in the field of human-robot collaboration. This work sets the stage for real robot applications based on the results of our simulation tasks.","","978-1-7281-9615-2","10.1109/IEMTRONICS51293.2020.9216410","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9216410","artificial intelligence;commonsense knowledge;robotics;human-robot interaction;mathematical modeling;simulation studies","Collaboration;Task analysis;Service robots;Mathematical model;Knowledge based systems;Robotic assembly","artificial intelligence;human-robot interaction;mobile robots;motion control;path planning;robotic assembly","robot action planning;commonsense knowledge;human-robot collaboration;assembly tasks;human robot interaction;mathematical modeling;simulation tasks;artificial intelligence;robot movement","","2","","16","","8 Oct 2020","","","IEEE","IEEE Conferences"
"Enhancing Parking Simulations Using Peer-Designed Agents","M. Chalamish; D. Sarne; R. Lin","Department of Computer Science, Ashkelon Academic College, Ashkelon, Israel; Department of Computer Science, Bar-Ilan University, Ramat-Gan, Israel; Department of Computer Science, Bar-Ilan University, Ramat-Gan, Israel","IEEE Transactions on Intelligent Transportation Systems","25 Feb 2013","2013","14","1","492","498","In this paper, we investigate the usefulness of peer-designed agents (PDAs) as a turn-key technology for enhancing parking simulations. The use of PDAs improves the system's ability to capture the dynamics of the interaction between individuals in the system, each theoretically exhibiting a different strategic behavior. Furthermore, since people in general are inherently rational and computation bounded, simulating this domain becomes even more challenging. The advantage of PDAs in this context lies in their ability to reliably simulate a large pool of human individuals with diverse strategies and goals. We demonstrate the efficacy of the proposed method by developing a large-scale simulation system for the parking space search domain, which plays an important role in urban transport systems. The system is based on 34 different parking search strategies. Most of these strategies are substantially different from synthetic strategies that are used in prior literature. A quantitative analysis of the PDAs indicates that they reliably capture their designers' real-life strategies. Finally, we demonstrate the usefulness of PDA-based parking space search simulation by utilizing it to evaluate four different information technologies that are of increasing use in recent years.","1558-0016","","10.1109/TITS.2012.2210545","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6275492","Experimentation;multiagent systems;parking simulations;peer-designed agents (PDAs)","Personal digital assistants;Computational modeling;Legged locomotion;Reliability;Search problems;Vehicles","digital simulation;multi-agent systems;road traffic;traffic engineering computing","enhancing parking simulations;peer designed agents;PDA;turn key technology;strategic behavior;human individuals;parking space search domain;urban transport systems","","6","","14","","20 Aug 2012","","","IEEE","IEEE Journals"
"A comprehensive case study of the impact of multicast routing protocols on mobile health care training systems","A. Zarrad; A. R. Mahlous","Department of computer science and Information Systems Prince Sultan University Riyadh, Saudi Arabia; Department of computer science and Information Systems Prince Sultan University Riyadh, Saudi Arabia","The Third International Conference on e-Technologies and Networks for Development (ICeND2014)","18 Dec 2014","2014","","","70","74","Nowadays, Health Care Training-based System (HCTS) is a vital component in the education and training of health care in 3D Virtual Environment (VE). The practice of HCTS continues to grow at rapid pace throughout all of the healthcare disciplines, however research in this field still in its early stage. Increasingly, decision makers and developer look forward to offer more sophisticated, much larger, and more complex HCTS to serve the desired outcome and improve the quality and safety of patient care. Due to the rapidly increasing usage of personal mobile devices and the need of executing HCTS applications in environments that have no previous network infrastructure available, Mobile Health Care Training-based System (MHCTS) is an expected future trend. In such systems, medical staff will share and collaborate in a 3D virtual environment through their mobile devices in an ad-hoc network (MANET) in order to accomplish specific missions' typically surgical emergency room. Users are organized into various groups (Radiologists, Maternity departments, and General surgery etc.), and need to be managed by a multicast scheme to save network bandwidth and offer immersive sense. MHCTS are sensitive to networking issues, since interactive 3D graphics requires additional load due to the use of mobile devices. Therefore, we need to emphasize on the importance and the improvement of multicast techniques for the effectiveness of MHCTS and the management of collaborative group interaction. Research so far has devoted little attention to the network communication protocols design of such systems which is crucial to preserve the sense of immersion for participating users. In this paper, we investigate the effect of multicast routing protocol in advancing the field of Health care Training-based System to the benefit of patient's safety, and health care professional. A comprehensive analysis about various ad-hoc multicast routing protocols is proposed. The selection key factors for the right protocol for MHCTS applications were safety and robustness. To the best of our knowledge, this work will be the first initiative involving systematic literature reviews to identify a research gate for the use of multicast protocol in health care simulation learning community.","","978-1-4799-3166-8","10.1109/ICeND.2014.6991355","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6991355","Ad-hoc;Multicast Protocol;Health care training system;3D Virtual Environment","Routing;Routing protocols;Medical services;Virtual environments;Peer-to-peer computing;Multicast protocols","biomedical communication;computer based training;mobile ad hoc networks;mobile computing;multicast protocols;routing protocols;virtual reality","multicast routing protocols;mobile health care training systems;MHCTS;3D virtual environment;VE;mobile ad-hoc network;MANET","","","","21","","18 Dec 2014","","","IEEE","IEEE Conferences"
"Velocity Estimation Algorithms for Audio-Haptic Simulations Involving Stick-Slip","S. Sinclair; M. M. Wanderley; V. Hayward","Institut des Systèmes Intelligents et de Robotique, UPMC University Paris 06, Paris, France; Input Devices and Music Interaction Laboratory (IDMIL) at McGill University, Montréal, QC, Canada; Institut des Systèmes Intelligents et de Robotique, UPMC University Paris 06, Paris, France","IEEE Transactions on Haptics","19 May 2017","2014","7","4","533","544","With real-time models of friction that take velocity as input, accuracy depends in great part on adequately estimating velocity from position measurements. This process can be sensitive to noise, especially at high sampling rates. In audio-haptic acoustic simulations, often characterized by friction-induced, relaxation-type stick-slip oscillations, this gives a gritty, dry haptic feel and a raspy, unnatural sound. Numerous techniques have been proposed, but each depend on tuning parameters so that they may offer a good trade-off between delay and noise rejection. In an effort to compare fairly, each of thirteen methods considered in the present study was automatically optimized and evaluated; finally a subset of these were compared subjectively. Results suggest that no one method is ideal for all gain levels, though the best general performance was found by using a sliding-mode differentiator as input to a Kalman integrator. An additional conclusion is that estimators do not approach the quality available in physical velocity transduction, and therefore such sensors should be considered in haptic device design.","2329-4051","","10.1109/TOH.2014.2346505","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6874521","Haptics;friction;velocity estimation","Noise measurement;Real-time systems;Haptic interfaces;Accelerometers;Velocity","audio signal processing;estimation theory;haptic interfaces;sampling methods;stick-slip","velocity estimation algorithm;audio-haptic simulation;real-time models of friction;position measurement;sampling rate;audio-haptic acoustic simulation;friction-induced oscillation;relaxation-type stick-slip oscillation;tuning parameter;delay rejection;noise rejection;sliding-mode differentiator;Kalman integrator;physical velocity transduction;haptic device design","Acoustics;Algorithms;Computer Simulation;Equipment Design;Friction;Human Engineering;Models, Theoretical;Sound","3","","28","","8 Aug 2014","","","IEEE","IEEE Journals"
"L2 stability of haptic systems with projection-based force reflection","I. G. Polushin; M. Z. Hasan","Department of Electrical and Computer Engineering, Western University, London, Canada; Department of Electrical and Computer Engineering, Western University, London, Canada","IEEE Transactions on Haptics","17 Sep 2014","2014","7","3","405","410","The problem of stability of haptic interaction with virtual objects is addressed, where the force reflection is implemented using the projection-based principle. A stability condition is derived that generalizes some previously known results to the case of projection-based force reflection. It demonstrates that, in this case, an additional design parameter is brought in that allows to increase the admissible stiffness of the virtual wall and decrease the update rate without changing the damping of the haptic device. A passivity based interpretation of the result is given in terms of interconnection of generalized passive systems where the excess of passivity of haptic device compensates the shortage of passivity of the virtual wall. In particular, it is shown that the projection-based force reflection allows to arbitrarily increase the excess of passivity of the haptic device without changing its physical damping.","2329-4051","","10.1109/TOH.2014.2305437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6736085","Haptic interfaces;stability;passivity","Haptic interfaces;Force;Damping;Stability criteria;Virtual environments;Equations","haptic interfaces;virtual reality","L2-stability;haptic systems;projection-based force reflection;haptic interaction stability problem;virtual objects;stability condition;design parameter;virtual wall admissible stiffness;update rate;haptic device damping;passivity based interpretation;generalized passive system interconnection","Algorithms;Biomechanical Phenomena;Robotics","1","","26","","10 Feb 2014","","","IEEE","IEEE Journals"
"Givs: Fine-Grained Gesture Control for Mobile Devices in Driving Environments","L. Jiang; M. Xia; X. Liu; F. Bai","School of Computer Science, McGill University, Montreal, Canada; School of Computer Science, McGill University, Montreal, Canada; School of Computer Science, McGill University, Montreal, Canada; General Motors Global R&D, Detroit, MI, USA","IEEE Access","17 Mar 2020","2020","8","","49229","49243","New media and communication technologies like mobile devices are nowadays widely used everywhere for providing rich functionalities and highly personalized services. However, using such a device in a driving environment is still very inconvenient and unsafe to be controlled by the driver. The touchscreen operations are one major obstacle since multi-touchscreen is optimized for hand-held usage scenarios. To overcome this limitation, we propose to replace some most used touch operations with gesture controls for mobile devices in a driving environment. Gesture control is simple, more flexible and requires less eye focus, which makes it more suitable for in-vehicle usages. In this paper, we design Givs, a fully functional gesture control system for mobile devices in a driving environment. Givs leverages the latest motion sensing technology to enable ubiquitous and driving-friendly gestures. Compared to other off-the-shelf gesture recognition solutions, Givs is optimized for in-vehicle use cases and is designed to overcome various limitations caused by real driving conditions, including bumpy road conditions, significant noise introduced by car vibration and technical limitations of motion sensors. Our extensive in-vehicle tests and participant experience experiments demonstrate that Givs well assists users in accomplishing various types of tasks and support human-machine interaction in driving environments such as personal vehicle and public transport, with high accuracy and fast responsiveness, while promoting drivnig convenience and safety.","2169-3536","","10.1109/ACCESS.2020.2971849","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8984325","Human-machine interaction;smart sensing;mobile computing;driving safety","Sensors;Motion detection;Mobile handsets;Delays;Hardware;Automobiles;Tracking","gesture recognition;human computer interaction;mobile computing;road vehicles;touch sensitive screens;traffic engineering computing","fine-grained gesture control;mobile devices;driving environment;hand-held usage scenarios;fully functional gesture control system;driving-friendly gestures;off-the-shelf gesture recognition solutions;driving conditions;Givs","","1","","40","CCBY","5 Feb 2020","","","IEEE","IEEE Journals"
"A theoretical approach to human-robot interaction based on the bipolar man framework","F. Amigoni; V. Schiaffonati; M. Somalvico","Dipt. di Elettronica e Informazione, Politecnico di Milano, Italy; Dipt. di Elettronica e Informazione, Politecnico di Milano, Italy; Dipt. di Elettronica e Informazione, Politecnico di Milano, Italy","Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication","10 Dec 2002","2002","","","183","188","The consideration of a general theoretical scenario accounting for the relationships between humans and robots may enhance the design and the development of human-robot interfaces. By starting from peculiar examples, the aim of this paper is to present an abstract framework that accounts for the current tendencies within the field of human-robots interaction. This framework is based on a precise ""philosophical"" position expressed by the concept of bipolar man, which has an impact on both the analysis and the design of human-robot interfaces.","","0-7803-7545-9","10.1109/ROMAN.2002.1045619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1045619","","Human robot interaction;Modems;Electronic mail;Man machine systems;Proposals;Taxonomy;Manipulators;Senior citizens;Communication channels","robots;user interfaces","human-robot interaction;bipolar man framework;human-robot interface analysis;human-robot interface design","","1","","15","","10 Dec 2002","","","IEEE","IEEE Conferences"
"Mechanisms of neural reorganization in chronic stroke subjects after virtual reality training","S. Saleh; H. Bagce; Q. Qiu; G. Fluet; A. Merians; S. Adamovich; E. Tunik","New Jersey Institute of Technology Newark, NJ 07102 USA; School of Health Related Professions and the school of Biomedical Sciences at the University of Medicine and Dentistry, Newark, 07107; New Jersey Institute of Technology Newark, NJ 07102 USA; School of Health Related Professions at the University of Medicine and Dentistry, Newark, 07107; School of Health Related Professions at the University of Medicine and Dentistry, Newark, 07107; New Jersey Institute of Technology Newark, NJ 07102 USA; School of Health Related Professions and the school of Biomedical Sciences at the University of Medicine and Dentistry, Newark, 07107","2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society","1 Dec 2011","2011","","","8118","8121","This study investigates patterns of brain reorganization in chronic stroke subjects after two weeks of robot-assisted arm and hand training in virtual reality (VR). Four subjects were studied with event-related fMRI while doing simple paretic hand finger movements before (double baseline) and after training. Bilateral hand movements were recorded and used to provide real-time feedback to subjects during scanning to eliminate performance confounds on fMRI results. The kinematic parameters of each movement were also used in the general linear model with the BOLD signal to investigate training-induced changes in neuromotor coupling. Univariate analysis showed an increase in BOLD signal in the ipsilesional hemisphere in two subjects and a decrease in activity in the other two subjects. Seed voxel based functional connectivity analysis revealed an increase in connectivity between ipsilesional motor cortex and bilateral sensorimotor cortex during finger movements in all four subjects. Hemispheric laterality index values showed a tendency to decrease reflecting a reduction in the over-dominance of the contralesional hemisphere. The study is novel in terms of 1) tracking finger movement during a motor task in the scanner, 2) monitoring motor performance during the experiment and 3) giving online visual feedback of subjects' movement. This pilot study introduces a novel approach to study neural plasticity by combining measures of regional intensity, interregional interactions (using functional connectivity analysis and hemispheric laterality index), and modulation in the strength of neuromotor coupling.","1558-4615","978-1-4577-1589-1","10.1109/IEMBS.2011.6092002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6092002","","Training;Robot sensing systems;Thumb;Angular velocity;Kinematics;Couplings","biomechanics;biomedical MRI;brain;diseases;medical image processing;medical robotics;neurophysiology;virtual reality","neural reorganization;chronic stroke;virtual reality training;brain reorganization;robot-assisted arm;hand training;event-related fMRI;paretic hand finger movements;bilateral hand movements;real-time feedback;BOLD signal;univariate analysis;functional connectivity analysis;ipsilesional motor cortex;bilateral sensorimotor cortex;tracking finger movement;online visual feedback;neural plasticity;hemispheric laterality index;neuromotor coupling","Aged;Chronic Disease;Female;Functional Laterality;Humans;Male;Middle Aged;Nerve Net;Nervous System;Oxygen;Robotics;Stroke;Stroke;Task Performance and Analysis;User-Computer Interface","9","","20","","1 Dec 2011","","","IEEE","IEEE Conferences"
"Computing optimal forces for generalised kinesthetic feedback on the human hand during virtual grasping and manipulation","C. Tzafestas; P. Coiffet","CNRS, Velizy, France; NA","Proceedings of International Conference on Robotics and Automation","6 Aug 2002","1997","1","","118","123 vol.1","This paper focuses on the problem of force-feedback for the human-operator hand when manipulating virtual objects. We propose a method for the computation of feedback-forces that have to be applied on each individual phalanx and finger of the human hand in order to display pertinent, kinesthetic information about static or dynamic characteristics of objects present in the virtual scene. External forces and moments of the manipulated virtual objects heave to be mapped on the contact-forces space of the virtual grasp. The method is based on the solution of a nonlinear programming problem, formulated by performing a static analysis of a general, multiple contact points virtual grasp. A methodology for modelling interactions within a virtual environment, and performing realistic grasping and manipulation, is also presented.","","0-7803-3612-7","10.1109/ROBOT.1997.620025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=620025","","Force feedback;Humans;Grasping;Virtual reality;Haptic interfaces;Fingers;Layout;Performance analysis;Intelligent robots;Computer displays","nonlinear programming;virtual reality;feedback;manipulators;telerobotics;solid modelling","optimal forces;generalised kinesthetic feedback;human hand;virtual grasping;virtual manipulation;virtual objects;phalanx;finger;dynamic characteristics;static characteristics;virtual scene;nonlinear programming;static analysis;virtual grasp","","5","","16","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Computer-enhanced route and survey spatial knowledge assessment in clinical neuropsychology","F. Morganti; A. Gaggioli; L. Strambi; M. L. Rusconi; G. Riva","Appl. Technol. for Neuro-Psychol. Lab, Ist. Auxologico Italiano, Milan; Appl. Technol. for Neuro-Psychol. Lab, Ist. Auxologico Italiano, Milan; Appl. Technol. for Neuro-Psychol. Lab, Ist. Auxologico Italiano, Milan; NA; NA","2006 International Workshop on Virtual Rehabilitation","9 Oct 2006","2006","","","110","115","In the field of clinical neuropsychology, topographical disorientation represents one of the main consequences of brain injury. Different methodological approaches and different tools have been used in the assessment of brain-injured patient's navigational abilities. These procedures include auto-evaluation questionnaires, evaluation of general cognitive level, mental rotation tasks or specifically suited visual-spatial tasks. All these methodologies have shown a moderate correlation between the results of these kinds of evaluation and the navigational ability impairment observed in everyday contexts. Meanwhile, the evaluation of patient's spatial orientation out of laboratory setting appears to be an unprofitable opportunity for clinicians. Thus the problem in designing an effective assessment tool is still open. A promising approach could be to integrate classical evaluation tools with computer-based interactive ones, such as virtual reality. According to this framework, we propose a combination of classical and virtual reality-based assessment, in which perceptive, memory and attentional functions (that combined each other are considered the hub for spatial orientation ability) will be evaluated with standardized neuropsychological tests and a more situated computer-based tools will allow the assessment of spatial orientation during the interaction with complex environments. Strictly linked with ""paper and pencil"" spatial disorientation neuropsychological evaluation, we propose two 3D virtual reality tools based on Wisc-R Maze subtest and road map test, customized to match interactive evaluation requirements. The first will provide the possibility to evaluate human ability of finding the best route to achieve a target goal while immersed in an empty environment. The second can be used to evaluate the ability in creating relationships between various points of the environment and in inferring, through the reasoning process, high-level spatial organization knowledge. By providing the possibility to track user's spatial behaviours, a virtual reality-based evaluation allows an effective and objective record of all the experimental variables. It also avoids the intervention of the experimenter, which may interfere with the actions of the agent-explorer. The main hypothesis of our research is that the integration of virtual reality-based tools with traditional evaluation methods will improve the evaluation of topographical disorientation in brain-injured patients","2331-9569","1-4244-0280-8","10.1109/IWVR.2006.1707537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1707537","","Humans;Virtual reality;Navigation;Brain injuries;Dementia;Lesions;Laboratories;Space exploration;Vehicles;Patient monitoring","brain;medical diagnostic computing;navigation;patient diagnosis;psychology;virtual reality","computer-enhanced route knowledge assessment;spatial knowledge assessment;clinical neuropsychology;topographical disorientation;brain injury;patient navigational abilities;cognitive level evaluation;mental rotation;visual-spatial tasks;navigational ability impairment;spatial orientation;3D virtual reality tools;Wisc-R Maze subtest;road map test;interactive evaluation;spatial behaviour","","1","","40","","9 Oct 2006","","","IEEE","IEEE Conferences"
"Scalable dynamical systems for multi-agent steering and simulation","S. Goldenstein; M. Karavelas; D. Metaxas; L. Guibas; A. Goswami","Pennsylvania Univ., Philadelphia, PA, USA; NA; NA; NA; NA","Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164)","9 Jul 2003","2001","4","","3973","3980 vol.4","We present a methodology for agent modeling that is scalable and efficient. It is based on the integration of nonlinear dynamical systems and kinetic data structures. The method consists of three-layers that model steering, flocking, and crowding agent behaviors among moving and static obstacles in 2 and 3D. The first layer, the local layer is based on the the use of nonlinear dynamical systems theory and models low level behaviors, it is fast and efficient, and does not depend on the total number of agents in the environment. The use of dynamical systems allows the use of continuous numerical parameters with which we can modify the interaction of each agent with the environment. This creates controllable distinctive behaviors. The second layer, a global environment layer consists of a specifically designed kinetic data structure to track efficiently the immediate environment of each agent and know which obstacles/agents are near or visible to the given agent. This layer reduces the complexity in the local layer. In the third layer, a global planning layer, the problem of target tracking is generalized in a way that allows navigation in maze-like terrains, avoidance of local minima and cooperation between agents. We implement this layer based on two approaches that are suitable for different applications. One is to track the closest single moving or static target. The second is to use a pre-specified vector field. This vector can be generated automatically (with harmonic functions, for example) or based on user input to achieve the desired output. We demonstrate the power of the approach through a series of experiments simulating single/multiple agents and crowds moving towards moving/static targets in complex environments.","1050-4729","0-7803-6576-3","10.1109/ROBOT.2001.933237","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=933237","","Data structures;Kinetic theory;Target tracking;Autonomous agents;Differential equations;Computational modeling;Computer simulation;Application software;Navigation;Virtual environment","nonlinear dynamical systems;data structures;multi-robot systems;multi-agent systems;path planning;digital simulation;mobile robots","scalable dynamical systems;multi-agent steering;kinetic data structures;static obstacles;moving obstacles;crowding agent behavior;flocking agent behavior;low level behaviors;controllable distinctive behaviors;global planning layer;target tracking;navigation;maze-like terrains;complex environments","","3","4","36","","9 Jul 2003","","","IEEE","IEEE Conferences"
"Modeling train control systems with Petri nets-a functional reference-architecture","M. M. Z. Horste; E. Schnieder","Inst. for Control & Autom. Eng., Tech. Univ. Braunschweig, Germany; NA","Smc 2000 conference proceedings. 2000 ieee international conference on systems, man and cybernetics. 'cybernetics evolving to systems, humans, organizations, and their complex interactions' (cat. no.0","6 Aug 2002","2000","4","","3081","3086 vol.4","Control systems for guided traffic primarily have the task to ensure safe but efficient operation. This paper shows an approach to model such systems in two general steps: the analysis of existing systems to define the functional units and the construction of the train control system. To reach the goal of the train control system specific functions are used which can be classified in functions for protection, supervision of operation and optimization. These functions are modeled as abstract functional blocks, independent from the implementation of a specific train control system. By means of these building blocks existing or new train control systems can be modeled, simulated and analyzed. The method presented is a part of the framework BASYSNET which is founded on Petri nets as means of description.","1062-922X","0-7803-6583-6","10.1109/ICSMC.2000.884471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=884471","","Control system synthesis;Petri nets;Control systems;Automatic control;Protection;Automation;Traffic control;Accidents;Rail transportation;Electrical equipment industry","locomotives;traffic control;digital simulation;Petri nets;rail traffic;control system analysis computing","train control systems modeling;Petri nets;functional reference-architecture;safety;supervision;optimization;BASYSNET framework;simulation","","2","","13","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Design of CRBRE for double-agent convoying simulation stage","M. Katoh","Department of Mechanical Engineering, Faculty of Engineering, Osaka Institute of Technology, Japan","2009 ICCAS-SICE","13 Nov 2009","2009","","","4272","4277","This paper details the design concept and process of an application-specific case rule-based reasoning engine (CRBRE) for double-agent convoying, although it has a frame that has generality. The design was accomplished using the plan, design, check and change (PDCC) design cycle. The engine has a 3-cycle configuration of perception step from agents, environment and their interaction; action step to them; and transform step from perception to action (PTA-cycle). Many applications such as multi-agent and multi-object systems with triggers will be possible to achieve.","","978-4-907764-34-0","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5332797","Case-based reasoning;Artificial intelligence;Agent;Convoying","Engines;Genetic programming;Collaboration;Artificial intelligence;Remotely operated vehicles;Road vehicles;Vehicle driving;Mobile robots;Intelligent robots;Mechanical engineering","case-based reasoning;digital simulation;multi-agent systems","double-agent convoying simulation stage;application-specific case rule-based reasoning engine;multiagent system;multiobject systems","","1","","11","","13 Nov 2009","","","IEEE","IEEE Conferences"
"Can Darwinian Virtual Objects Behave Well if Left Alone?","D. Harrison; E. Chng","Sch. of Art & Design, Univ. of Wolverhampton, Wolverhampton, UK; NA","2012 International Conference on Cyberworlds","25 Oct 2012","2012","","","290","295","The artist and principal author has been creating art works in multimedia through the semantic association of ideas into concepts, as a means of exploring the efficacy of hypermedia for a conceptual art practice. This is particularly evident in the developments apparent in the ongoing 'Deconstructing Duchamp' project, where 'flocking' behaviours have been applied to Duchampian digitised items to observe the familial relations within, and key to his work, at play. Following this project, a second work 'Shift-Life' has proceeded to further develop the idea of allotting animal-like behaviours to electronic data items giving them the appearance of possessing a basic intelligence. By then observing their response to our physical interactions we can glean a clearer understanding, from their inter-relationships, of a complex conceptual framework. While Marcel Duchamp offered the art world one of the most complex and formative pieces of art ever, initiating the shift of values from aesthetics to idea, Charles Darwin developed the theory of evolution, the 'big' idea of survivability through adaptation. Shift-Life was created as part of the national Darwin 200 project for the international bicentenary in 2009. It is a complex system of virtual life-forms struggling to survive in an environment made volatile through human interaction. Central to this installation work is the artificial life ecosystem as a self-sustaining, self-reproducing equilibrium of creatures and plants living in it. The general behaviour of each organism was more sophisticated than for the Duchampian creatures in that they were equipped for survival strategies and the reproduction of progenies. An exposition of the Shift-Life program is therefore presented followed by reflection on both projects and future directions for this collaborative research where potential emergent behaviours are concerned.","","978-1-4673-2736-7","10.1109/CW.2012.49","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6337436","Duchamp;Darwin;associative media;behaviours;mixed-reality;artificial life;agent-based modelling","Art;Glass;Ecosystems;Organisms;Toxicology;Vegetation","art;multimedia computing;reliability;virtual reality","Darwinian virtual objects;multimedia;conceptual art practice;Deconstructing Duchamp project;Duchampian digitised items;familial relations;second work Shift-Life;animal-like behaviours;electronic data items;physical interactions;complex conceptual framework;formative pieces;complex pieces;survivability through adaptation;international bicentenary;complex system;virtual life-forms;human interaction;self-sustaining;artificial life ecosystem;Duchampian creatures;collaborative research;emergent behaviours","","","","9","","25 Oct 2012","","","IEEE","IEEE Conferences"
"A case study of Jawi Editor in the XO-laptop simulated environment","K. Ismail; R. J. Raja Yusof; N. Jomhari","Faculty of Computer Science & Information Technology, University of Malaya, Malaysia; Faculty of Computer Science & Information Technology, University of Malaya, Malaysia; Faculty of Computer Science & Information Technology, University of Malaya, Malaysia","2010 International Conference on User Science and Engineering (i-USEr)","22 Feb 2011","2010","","","21","25","Jawi script is an important Malay heritage that has been in general, replaced by the Roman script. From a dominant writing in Malay world, the usage of Jawi is confined mostly in Islamic religious context nowadays. As an initiative to encourage the learning of Jawi, this research proposed a Jawi Editor running on the XO-laptop which considered as a new technology used in education, this technology introduced by One Laptop per Child (OLPC) organization. OLPC concerned of giving a laptop for every child in the developing countries to encourage them in education. XO-laptop allows collaboration and cooperation between teacher and students and between students themselves by working in groups. In this new technology of education the XO-laptop plays a main role of transferring the teacher and students roles in the class from the traditional way to the computerize technology. The aim of this research is to develop and contribute a Jawi Editor in the XO-laptop simulated environment to help the Jawi teachers and students in classes, to compile several development guidelines of Jawi-like systems in the XO-laptop simulated environment and to conduct a case study of teacher-student interaction using the Jawi Editor in the XO-laptop simulated environment.","","978-1-4244-9049-3","10.1109/IUSER.2010.5716716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5716716","Jawi;OLPC;XO-laptop;CSCW","Portable computers;Educational institutions;Writing;Collaboration;Measurement;Manuals","computer aided instruction;groupware;laptop computers","Jawi Editor;XO laptop simulated environment;Jawi script;Malay heritage;Roman script;one laptop per child organization;teacher student interaction","","1","","5","","22 Feb 2011","","","IEEE","IEEE Conferences"
