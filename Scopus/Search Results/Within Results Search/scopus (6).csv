Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Document Type,Publication Stage,Open Access,Source,EID
"McFadyen J., Nolan C., Pinocy E., Buteri D., Baumann O.","56538356500;38062062000;57222272594;57222268325;16244152500;","Doorways do not always cause forgetting: a multimodal investigation",2021,"BMC Psychology","9","1", 41,"","",,,"10.1186/s40359-021-00536-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102100800&doi=10.1186%2fs40359-021-00536-3&partnerID=40&md5=9f140ab2136e8568de112de8d6470025","Queensland Brain Institute, University of Queensland, Brisbane, QLD  4072, Australia; Max Planck UCL Centre for Computational Psychiatry and Ageing Research, University College London, London, United Kingdom; School of Psychology and Interdisciplinary Centre for the Artificial Mind, Bond University, Robina, QLD  4226, Australia","McFadyen, J., Queensland Brain Institute, University of Queensland, Brisbane, QLD  4072, Australia, Max Planck UCL Centre for Computational Psychiatry and Ageing Research, University College London, London, United Kingdom; Nolan, C., Queensland Brain Institute, University of Queensland, Brisbane, QLD  4072, Australia; Pinocy, E., School of Psychology and Interdisciplinary Centre for the Artificial Mind, Bond University, Robina, QLD  4226, Australia; Buteri, D., School of Psychology and Interdisciplinary Centre for the Artificial Mind, Bond University, Robina, QLD  4226, Australia; Baumann, O., School of Psychology and Interdisciplinary Centre for the Artificial Mind, Bond University, Robina, QLD  4226, Australia","Background: The ‘doorway effect’, or ‘location updating effect’, claims that we tend to forget items of recent significance immediately after crossing a boundary. Previous research suggests that such a forgetting effect occurs both at physical boundaries (e.g., moving from one room to another via a door) and metaphysical boundaries (e.g., imagining traversing a doorway, or even when moving from one desktop window to another on a computer). Here, we aimed to conceptually replicate this effect using virtual and physical environments. Methods: Across four experiments, we measured participants’ hit and false alarm rates to memory probes for items recently encountered either in the same or previous room. Experiments 1 and 2 used highly immersive virtual reality without and with working memory load (Experiments 1 and 2, respectively). Experiment 3 used passive video watching and Experiment 4 used active real-life movement. Data analysis was conducted using frequentist as well as Bayesian inference statistics. Results: Across this series of experiments, we observed no significant effect of doorways on forgetting. In Experiment 2, however, signal detection was impaired when participants responded to probes after moving through doorways, such that false alarm rates were increased for mismatched recognition probes. Thus, under working memory load, memory was more susceptible to interference after moving through doorways. Conclusions: This study presents evidence that is inconsistent with the location updating effect as it has previously been reported. Our findings call into question the generalisability and robustness of this effect to slight paradigm alterations and, indeed, what factors contributed to the effect observed in previous studies. © 2021, The Author(s).","Doorway effect; Event boundary; Memory; Spatial navigation","Bayes theorem; environment; human; recall; short term memory; Bayes Theorem; Environment; Humans; Memory, Short-Term; Mental Recall",Article,"Final","",Scopus,2-s2.0-85102100800
"Baceviciute S., Terkildsen T., Makransky G.","55441702500;57205338475;50361371800;","Remediating learning from non-immersive to immersive media: Using EEG to investigate the effects of environmental embeddedness on reading in Virtual Reality",2021,"Computers and Education","164",, 104122,"","",,,"10.1016/j.compedu.2020.104122","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100105880&doi=10.1016%2fj.compedu.2020.104122&partnerID=40&md5=0e064f3f47964fe4caef507e98daa3ff","University of Copenhagen, Department of Psychology, Denmark","Baceviciute, S., University of Copenhagen, Department of Psychology, Denmark; Terkildsen, T., University of Copenhagen, Department of Psychology, Denmark; Makransky, G., University of Copenhagen, Department of Psychology, Denmark","Virtual Reality (VR) has the potential to enrich education but little is known about how unique affordances of immersive technology might influence leaning and cognition. This study investigates one particular affordance of VR, namely environmental embeddedness, which enables learners to be situated in simulated or imagined settings that contextualize their learning. A sample of 51 university students were administered written learning material in a between-subjects design study, wherein one group read text about sarcoma cancer on a physical pamphlet in the real world, and the other group read identical text on a virtual pamphlet embedded in an immersive VR environment which resembled a hospital room. The study combined advanced EEG measurement techniques, learning tests, and cognitive load measures to compare conditions. Results show that the VR group performed significantly better on a knowledge transfer post-test. However, reading in VR was found to be more cognitively effortful and less time-efficient. Findings suggest the significance of environmental embeddedness for learning, and provide important considerations for the design of educational VR environments, as we remediate learning content from non-immersive to immersive media. © 2021 Elsevier Ltd","EEG; Embeddedness; Learning; Remediation; Virtual reality environments","E-learning; Knowledge management; Remediation; Cognitive loads; Immersive media; Immersive technologies; Knowledge transfer; Learning contents; Learning materials; Measurement techniques; University students; Virtual reality",Article,"Final","",Scopus,2-s2.0-85100105880
"Monteiro P., Melo M., Valente A., Vasconcelos-Raposo J., Bessa M.","57201131572;7102354924;7102410111;36070012200;14031038800;","Delivering Critical Stimuli for Decision Making in VR Training: Evaluation Study of a Firefighter Training Scenario",2021,"IEEE Transactions on Human-Machine Systems","51","2", 9247430,"65","74",,,"10.1109/THMS.2020.3030746","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103091552&doi=10.1109%2fTHMS.2020.3030746&partnerID=40&md5=2ab0568260ec97afacd284c5f8dae21d","Inesc Tec, Porto, 4200-465, Portugal; Universidade de Trás-os-Montes e Alto Douro, Vila Real, 5000-801, Portugal","Monteiro, P., Inesc Tec, Porto, 4200-465, Portugal; Melo, M., Inesc Tec, Porto, 4200-465, Portugal; Valente, A., Inesc Tec, Porto, 4200-465, Portugal, Universidade de Trás-os-Montes e Alto Douro, Vila Real, 5000-801, Portugal; Vasconcelos-Raposo, J., Inesc Tec, Porto, 4200-465, Portugal, Universidade de Trás-os-Montes e Alto Douro, Vila Real, 5000-801, Portugal; Bessa, M., Inesc Tec, Porto, 4200-465, Portugal, Universidade de Trás-os-Montes e Alto Douro, Vila Real, 5000-801, Portugal","The goal for a virtual reality (VR) training system is to enable trainees to acquire all the knowledge they need to perform effectively in a real environment. Such a system should provide an experience so authentic that no further real-world training is necessary, meaning that it is sufficient to train in VR. We evaluate the impact of a haptic thermal stimulus, which is of paramount importance to decision making, on trainees performance and knowledge acquisition. A thermal device was created to deliver the stimulus. As a proof of concept, a procedure from firefighter training is selected, in which sensing the temperature of a door with one's hand is essential. The sample consisted of 48 subjects divided among three experimental scenarios: one in which a virtual thermometer is used (visual stimulus), another in which the temperature is felt with the hand (thermal stimulus) and a third in which both methods are used (visual + thermal stimuli). For the performance evaluation, we measured the total time taken, the numbers of correctly executed procedures and identified neutral planes, the deviation from the target height, and the responses to a knowledge transfer questionnaire. Presence, cybersickness, and usability are measured to evaluate the impact of the haptic thermal stimulus. Considering the thermal stimulus condition as the baseline, we conclude that the significantly different results in the performance among the conditions indicate that the better performance in the visual-only condition is not representative of the real-life performance. Consequently, VR training applications need to deliver the correct stimuli for decision making. © 2013 IEEE.","Firefighters; haptic cues; multisensory displays; thermal; training; virtual reality (VR)","Fire extinguishers; Knowledge acquisition; Knowledge management; Virtual reality; Evaluation study; Knowledge transfer; Proof of concept; Real environments; Real-life performance; Training applications; Training scenario; Training Systems; Decision making",Article,"Final","",Scopus,2-s2.0-85103091552
"Araiza-Alba P., Keane T., Chen W.S., Kaufman J.","57191667278;55582336900;57188973057;7403022831;","Immersive virtual reality as a tool to learn problem-solving skills",2021,"Computers and Education","164",, 104121,"","",,,"10.1016/j.compedu.2020.104121","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099353627&doi=10.1016%2fj.compedu.2020.104121&partnerID=40&md5=82079d081459ac2caf3cea01c4ad7087","Swinburne University of Technology, PO Box 218, Hawthorn, Victoria, Australia","Araiza-Alba, P., Swinburne University of Technology, PO Box 218, Hawthorn, Victoria, Australia; Keane, T., Swinburne University of Technology, PO Box 218, Hawthorn, Victoria, Australia; Chen, W.S., Swinburne University of Technology, PO Box 218, Hawthorn, Victoria, Australia; Kaufman, J., Swinburne University of Technology, PO Box 218, Hawthorn, Victoria, Australia","Immersive virtual reality (IVR) technology has demonstrated positive educational outcomes related to its use and is gaining traction in educational and training settings; IVR is expected to have widespread adoption within the classroom in the upcoming years. However, the educational potential of IVR with children has not been thoroughly investigated, especially as a tool for problem-solving skills. Therefore, this study was designed to answer the following questions: (1) Is IVR a useful tool to learn and practice problem-solving skills? More specifically, do children using IVR solve a game better than those using a tablet application or a board game? (2) Does IVR provide a more engaging experience for children to practice problem-solving skills than on a tablet or a board game? (3) Do problem-solving skills learned with IVR technology transfer to real-life (physical game)? Children (n = 120) aged 7–9.9 years were randomly assigned to a problem-solving game in one of three conditions: board game, tablet, or IVR. The results showed that, overall, the percentage of children who completed the problem-solving game was higher in the IVR condition (77.5%), compared with those in the tablet (32.5%) or board game (30%) conditions. We also found that the interest and enjoyment scores of participants using IVR were significantly higher than participants in the other two conditions, and that the children in the IVR condition were able to learn how to solve the problem and transfer their learning to the physical game. IVR is a technology capable of engaging interest and motivating the user, as well as having the potential to assist in cognitive processing and knowledge transfer. © 2021 Elsevier Ltd","21st century abilities; Elementary education; Games; Problem-solving skills; Virtual reality","Knowledge management; Technology transfer; Transfer learning; Board games; Cognitive processing; Educational potential; Immersive virtual reality; Knowledge transfer; Physical games; Problem solving skills; Tablet applications; Virtual reality",Article,"Final","",Scopus,2-s2.0-85099353627
"Ozcinar C., İmamoğlu N., Wang W., Smolic A.","57211460523;38061650600;57213601132;57204958271;","Delivery of omnidirectional video using saliency prediction and optimal bitrate allocation",2021,"Signal, Image and Video Processing","15","3",,"493","500",,,"10.1007/s11760-020-01769-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090784192&doi=10.1007%2fs11760-020-01769-2&partnerID=40&md5=09390fc7a72cc1d7c7f88d20468860a9","V-SENSE, Trinity College Dublin, Dublin, Ireland; Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology, Tokyo, Japan","Ozcinar, C., V-SENSE, Trinity College Dublin, Dublin, Ireland; İmamoğlu, N., Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; Wang, W., Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; Smolic, A., V-SENSE, Trinity College Dublin, Dublin, Ireland","In this work, we propose and investigate a user-centric framework for the delivery of omnidirectional video (ODV) on VR systems by taking advantage of visual attention (saliency) models for bitrate allocation module. For this purpose, we formulate a new bitrate allocation algorithm that takes saliency map and nonlinear sphere-to-plane mapping into account for each ODV and solve the formulated problem using linear integer programming. For visual attention models, we use both image- and video-based saliency prediction results; moreover, we explore two types of attention model approaches: (i) salient object detection with transfer learning using pre-trained networks, (ii) saliency prediction with supervised networks trained on eye-fixation dataset. Experimental evaluations on saliency integration of models are discussed with interesting findings on transfer learning and supervised saliency approaches. © 2020, Springer-Verlag London Ltd., part of Springer Nature.","360 ∘ Video streaming; Attention-based bitrate allocation; Saliency maps with transfer learning and supervision","Behavioral research; Forecasting; Integer programming; Object detection; Transfer learning; Bit-rate allocation; Experimental evaluation; Formulated problems; Linear integer programming; Salient object detection; Supervised network; Visual Attention; Visual attention model; Learning systems",Article,"Final","",Scopus,2-s2.0-85090784192
"Cheng M., Anderson M., Levac D.E.","57222585846;57222586805;25937323900;","Performance Variability During Motor Learning of a New Balance Task in a Non-immersive Virtual Environment in Children With Hemiplegic Cerebral Palsy and Typically Developing Peers",2021,"Frontiers in Neurology","12",, 623200,"","",,,"10.3389/fneur.2021.623200","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103329101&doi=10.3389%2ffneur.2021.623200&partnerID=40&md5=dabc59fc0853ed3646ac10dc4f0d0d8f","Rehabilitation Games and Virtual Reality Laboratory, Department of Physical Therapy, Movement and Rehabilitation Sciences, Northeastern University, Boston, MA, United States; Department of Biology, Macalester College, St. Paul, MN, United States","Cheng, M., Rehabilitation Games and Virtual Reality Laboratory, Department of Physical Therapy, Movement and Rehabilitation Sciences, Northeastern University, Boston, MA, United States; Anderson, M., Department of Biology, Macalester College, St. Paul, MN, United States; Levac, D.E., Rehabilitation Games and Virtual Reality Laboratory, Department of Physical Therapy, Movement and Rehabilitation Sciences, Northeastern University, Boston, MA, United States","Background: Motor impairments contribute to performance variability in children with cerebral palsy (CP) during motor skill learning. Non-immersive virtual environments (VEs) are popular interventions to promote motor learning in children with hemiplegic CP. Greater understanding of performance variability as compared to typically developing (TD) peers during motor learning in VEs may inform clinical decisions about practice dose and challenge progression. Purpose: (1) To quantify within-child (i.e., across different timepoints) and between-child (i.e., between children at the same timepoint) variability in motor skill acquisition, retention and transfer in a non-immersive VE in children with CP as compared to TD children; and (2) To explore the relationship between the amount of within-child variability during skill acquisition and learning outcomes. Methods: Secondary data analysis of 2 studies in which 13 children with hemiplegic CP and 67 TD children aged 7–14 years undertook repeated trials of a novel standing postural control task in acquisition, retention and transfer sessions. Changes in performance across trials and sessions in children with CP as compared to TD children and between younger (7–10 years) and older (11–14 years) children were assessed using mixed effects models. Raw scores were converted to z-scores to meet model distributional assumptions. Performance variability was quantified as the standard deviation of z-scores. Results: TD children outperformed children with CP and older children outperformed younger children at each session. Older children with CP had the least between-child variability in acquisition and the most in retention, while older TD children demonstrated the opposite pattern. Younger children with CP had consistently high between-child variability, with no difference between sessions. Within-child variability was highest in younger children, regardless of group. Within-child variability was more pronounced in TD children as compared to children with CP. The relationship between the amount of within-child variability in performance and performance outcome at acquisition, retention and transfer sessions was task-specific, with a positive correlation for 1 study and a negative correlation in the other. Conclusions: Findings, though preliminary and limited by small sample size, can inform subsequent research to explore VE-specific causes of performance variability, including differing movement execution requirements and individual characteristics such as motivation, attention and visuospatial abilities. © Copyright © 2021 Cheng, Anderson and Levac.","cerebral palsy; children; motor learning; variability; virtual environment; virtual reality",,Article,"Final","",Scopus,2-s2.0-85103329101
"Boller B., Ouellet É., Belleville S.","54402456500;55567624500;7003289069;","Using Virtual Reality to Assess and Promote Transfer of Memory Training in Older Adults With Memory Complaints: A Randomized Controlled Trial",2021,"Frontiers in Psychology","12",, 627242,"","",,,"10.3389/fpsyg.2021.627242","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103339822&doi=10.3389%2ffpsyg.2021.627242&partnerID=40&md5=cc313318f3471c64a1312494f31a565a","Department of Psychology, Université du Québec à Trois-Rivières, Trois-Rivières, QC, Canada; Research Centre, Institut Universitaire de Gériatrie de Montréal, Montréal, QC, Canada; Department of Psychology, Université de Montréal, Montréal, QC, Canada","Boller, B., Department of Psychology, Université du Québec à Trois-Rivières, Trois-Rivières, QC, Canada, Research Centre, Institut Universitaire de Gériatrie de Montréal, Montréal, QC, Canada; Ouellet, É., Research Centre, Institut Universitaire de Gériatrie de Montréal, Montréal, QC, Canada, Department of Psychology, Université de Montréal, Montréal, QC, Canada; Belleville, S., Research Centre, Institut Universitaire de Gériatrie de Montréal, Montréal, QC, Canada, Department of Psychology, Université de Montréal, Montréal, QC, Canada","In this proof-of-concept study, we assessed the potential for immersive virtual reality (VR) to measure transfer following strategic memory training, and whether efficacy and transfer are increased when training is complemented by practice in an immersive virtual environment. Forty older adults with subjective memory complaints were trained with the method of loci. They were randomized to either a condition where they practiced the strategy in VR (n = 20) or a control condition where they were familiarized with VR using a non-memory task (n = 20). Training efficacy was measured with word recall, and transfer of the training benefit was measured with a recall task completed in two VR tasks (primary outcomes) as well as a self-report memory questionnaire (secondary outcomes). Testing was administered before (PRE), midway (POST 3), and after (POST 6) training. Participants improved their scores on word recall. Regarding transfer measures, participants improved their performance in the two VR recall tasks but not on the self-report memory questionnaire. No significant group effect was observed. Improvement was found when comparing PRE to POST 3 with no further improvement at POST 6. Thus, strategic memory training improved the memory of seniors with memory complaints on word recall and a transfer task relying on a VR scenario that resembles real-life. However, no evidence supporting an increase in transfer effects was found when enriching training with VR memory exercises. © Copyright © 2021 Boller, Ouellet and Belleville.","aging; cognitive training; episodic memory; memory complaint; randomized controlled trial; virtual reality",,Article,"Final","",Scopus,2-s2.0-85103339822
"Liubogoshchev M., Korneev E., Khorov E.","57200496493;57222333639;34869950000;","Everest: Bitrate adaptation for cloud VR",2021,"Electronics (Switzerland)","10","6", 678,"1","17",,,"10.3390/electronics10060678","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102367580&doi=10.3390%2felectronics10060678&partnerID=40&md5=b8109a2394052392181695bfc8233c23","Kharkevich Institute for Information Transmission Problems of the Russian Academy of Sciences, Moscow, 127051, Russian Federation; Moscow Institute of Physics and Technology, Moscow, 141701, Russian Federation","Liubogoshchev, M., Kharkevich Institute for Information Transmission Problems of the Russian Academy of Sciences, Moscow, 127051, Russian Federation, Moscow Institute of Physics and Technology, Moscow, 141701, Russian Federation; Korneev, E., Kharkevich Institute for Information Transmission Problems of the Russian Academy of Sciences, Moscow, 127051, Russian Federation, Moscow Institute of Physics and Technology, Moscow, 141701, Russian Federation; Khorov, E., Kharkevich Institute for Information Transmission Problems of the Russian Academy of Sciences, Moscow, 127051, Russian Federation, Moscow Institute of Physics and Technology, Moscow, 141701, Russian Federation","Cloud Virtual Reality (VR) technology is expected to promote VR by providing a higher Quality of Experience (QoE) and energy efficiency at lower prices for the consumer. In cloud VR, the virtual environment is rendered on the remote server and transmitted to the headset as a video stream. To guarantee real-time experience, networks need to transfer huge amounts of data with much stricter delays than imposed by the state-of-the-art live video streaming applications. To reduce the burden imposed on the networks, cloud VR applications shall adequately react to the changing network conditions, including the wireless channel fluctuations and highly variable user activity. For that, they need to adjust the quality of the video stream adaptively. This paper studies video quality adaptation for cloud VR and improves the QoE for cloud VR users. It develops a distributed, i.e., with no assistance from the network, bitrate adaptation algorithm for cloud VR, called the Enhanced VR bitrate Estimator (EVeREst). The algorithm aims to optimize the average bitrate of cloud VR video flows subject to video frame delay and loss constraints. For that, the algorithm estimates both the current network load and the delay experienced by separate frames. It anticipates the changes in the users’ activity and limits the bitrate accordingly, which helps prevent excess interruptions of the playback. With simulations, the paper shows that the developed algorithm significantly improves the QoE for the end-users compared to the state-of-the-art adaptation algorithms developed for MPEG DASH live streaming, e.g., BOLA. Unlike these algorithms, the developed algorithm satisfies the frame loss requirements of multiple VR sessions and increases the network goodput by up to 10 times. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Bitrate adaptation; Cloud VR; Quality of experience; Real-time adaptive video; Video traffic; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85102367580
"Kourtesis P., Collina S., Doumas L.A.A., MacPherson S.E.","57210959726;35309731500;12345301900;57212061035;","Validation of the Virtual Reality Everyday Assessment Lab (VR-EAL): An Immersive Virtual Reality Neuropsychological Battery with Enhanced Ecological Validity",2021,"Journal of the International Neuropsychological Society","27","2",,"181","196",,2,"10.1017/S1355617720000764","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095727298&doi=10.1017%2fS1355617720000764&partnerID=40&md5=682a1271572f8544a09deaa59f15dad1","Human Cognitive Neuroscience, Department of Psychology, University of Edinburgh, Edinburgh, United Kingdom; Department of Psychology, University of Edinburgh, Edinburgh, United Kingdom; Lab of Experimental Psychology, Suor Orsola Benincasa University of Naples, Naples, Italy; Interdepartmental Centre for Planning and Research Scienza Nuova, Suor Orsola Benincasa University of Naples, Naples, Italy","Kourtesis, P., Human Cognitive Neuroscience, Department of Psychology, University of Edinburgh, Edinburgh, United Kingdom, Department of Psychology, University of Edinburgh, Edinburgh, United Kingdom, Lab of Experimental Psychology, Suor Orsola Benincasa University of Naples, Naples, Italy, Interdepartmental Centre for Planning and Research Scienza Nuova, Suor Orsola Benincasa University of Naples, Naples, Italy; Collina, S., Lab of Experimental Psychology, Suor Orsola Benincasa University of Naples, Naples, Italy, Interdepartmental Centre for Planning and Research Scienza Nuova, Suor Orsola Benincasa University of Naples, Naples, Italy; Doumas, L.A.A., Department of Psychology, University of Edinburgh, Edinburgh, United Kingdom; MacPherson, S.E., Human Cognitive Neuroscience, Department of Psychology, University of Edinburgh, Edinburgh, United Kingdom, Department of Psychology, University of Edinburgh, Edinburgh, United Kingdom","The assessment of cognitive functions such as prospective memory, episodic memory, attention, and executive functions benefits from an ecologically valid approach to better understand how performance outcomes generalize to everyday life. Immersive virtual reality (VR) is considered capable of simulating real-life situations to enhance ecological validity. The present study attempted to validate the Virtual Reality Everyday Assessment Lab (VR-EAL), an immersive VR neuropsychological battery, against an extensive paper-and-pencil neuropsychological battery. Methods: Forty-one participants (21 females) were recruited: 18 gamers and 23 non-gamers who attended both an immersive VR and a paper-and-pencil testing session. Bayesian Pearson's correlation analyses were conducted to assess construct and convergent validity of the VR-EAL. Bayesian t-tests were performed to compare VR and paper-and-pencil testing in terms of administration time, similarity to real-life tasks (i.e., ecological validity), and pleasantness. Results: VR-EAL scores were significantly correlated with their equivalent scores on the paper-and-pencil tests. The participants' reports indicated that the VR-EAL tasks were significantly more ecologically valid and pleasant than the paper-and-pencil neuropsychological battery. The VR-EAL battery also had a shorter administration time. Conclusion: The VR-EAL appears as an effective neuropsychological tool for the assessment of everyday cognitive functions, which has enhanced ecological validity, a highly pleasant testing experience, and does not induce cybersickness. © 2020 INS. Published by Cambridge University Press.","Attention; Episodic memory; Everyday functioning; Executive function; Prospective memory; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85095727298
"Parong J., Mayer R.E.","56520185200;7403065717;","Cognitive and affective processes for learning science in immersive virtual reality",2021,"Journal of Computer Assisted Learning","37","1",,"226","241",,3,"10.1111/jcal.12482","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089751070&doi=10.1111%2fjcal.12482&partnerID=40&md5=8ad3aa7f4645bc62203c9c281872a614","Department of Psychological and Brain Sciences, University of California, Santa Barbara, Santa Barbara, CA, United States; Department of Psychology, University of Wisconsin–Madison, Madison, WI, United States","Parong, J., Department of Psychological and Brain Sciences, University of California, Santa Barbara, Santa Barbara, CA, United States, Department of Psychology, University of Wisconsin–Madison, Madison, WI, United States; Mayer, R.E., Department of Psychological and Brain Sciences, University of California, Santa Barbara, Santa Barbara, CA, United States","As immersive virtual reality (IVR) systems proliferate in classrooms, it is important to understand how they affect learning outcomes and the underlying affective and cognitive processes that may cause these outcomes. Proponents argue that IVR could improve learning by increasing positive affective and cognitive processing, thereby supporting improved performance on tests of learning outcome, whereas opponents of IVR contend that it could hurt learning by increasing distraction, thereby disrupting cognitive learning processes and leading to poorer learning outcomes. In a media comparison study, students viewed a biology lesson either as an interactive animated journey in IVR or as a slideshow on a desktop monitor. Those who viewed the IVR lesson performed significantly worse on transfer tests, reported higher emotional arousal, reported more extraneous cognitive load and showed less engagement based on EEG measures than those who viewed the slideshow lesson, with or without practice questions added to the lessons. Mediational analyses showed that the lower retention scores for the IVR lesson were related to an increase in self-reported extraneous cognitive load and emotional arousal. These results support the notion that immersive environments create high affective and cognitive distraction, which leads to poorer learning outcomes than desktop environments. © 2020 John Wiley & Sons Ltd","affective processing; cognitive processing; multimedia; science learning; virtual reality",,Article,"Final","",Scopus,2-s2.0-85089751070
"Andersen M.S., Makransky G.","57219054225;50361371800;","The validation and further development of a multidimensional cognitive load scale for virtual environments",2021,"Journal of Computer Assisted Learning","37","1",,"183","196",,1,"10.1111/jcal.12478","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091135125&doi=10.1111%2fjcal.12478&partnerID=40&md5=fbc81a5bc502b80ab67a1c386b9e62a8","Department of Psychology, University of Copenhagen, Copenhagen, Denmark","Andersen, M.S., Department of Psychology, University of Copenhagen, Copenhagen, Denmark; Makransky, G., Department of Psychology, University of Copenhagen, Copenhagen, Denmark","Measuring cognitive load is important in virtual learning environments (VLE). Thus, valid and reliable measures of cognitive load are important to support instructional design in VLE. Through three studies, we investigated the validity and reliability of Leppink's Cognitive Load Scale (CLS) and developed the extraneous cognitive load (EL) dimension into three sub-scales relevant for VLE: EL instructions, EL interaction, and EL environment. We investigated the validity of the measures using the Partial Credit Model (PCM), Confirmatory Factor Analysis (CFA), and correlations with retention tests. Study 1 (n = 73) investigated the adapted version of the CLS. Study 2 describes the development and validation of the Multidimensional Cognitive Load Scale for Virtual Environments (MCLSVE), with 140 students in higher education. Study 3 tested the generalizability of the results with 121 higher education students in a more complicated VLE. The results provide initial evidence for the validity and reliability of the MCLSVE. © 2020 John Wiley & Sons Ltd","cognitive load; confirmatory factor analysis; item response theory; virtual reality; virtual simulations",,Article,"Final","",Scopus,2-s2.0-85091135125
"Wilf M., Cerra Cheraka M., Jeanneret M., Ott R., Perrin H., Crottaz-Herbette S., Serino A.","36515832500;57222264361;57221090466;57221094468;57221091485;57202925776;23390163100;","Combined virtual reality and haptic robotics induce space and movement invariant sensorimotor adaptation",2021,"Neuropsychologia","150",, 107692,"","",,,"10.1016/j.neuropsychologia.2020.107692","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098145308&doi=10.1016%2fj.neuropsychologia.2020.107692&partnerID=40&md5=1d5ecc00fd2c0fe69faadad48c343573","MySpace Lab, Department of Clinical Neurosciences, Lausanne University Hospital (CHUV), Lausanne, Switzerland; MindMaze SA, Chemin de Roseneck 5, Lausanne, 1006, Switzerland; Neuropsychology and Neurorehabilitation Service, Lausanne University Hospital (CHUV), Lausanne, Switzerland","Wilf, M., MySpace Lab, Department of Clinical Neurosciences, Lausanne University Hospital (CHUV), Lausanne, Switzerland; Cerra Cheraka, M., MindMaze SA, Chemin de Roseneck 5, Lausanne, 1006, Switzerland; Jeanneret, M., MindMaze SA, Chemin de Roseneck 5, Lausanne, 1006, Switzerland; Ott, R., MindMaze SA, Chemin de Roseneck 5, Lausanne, 1006, Switzerland; Perrin, H., MySpace Lab, Department of Clinical Neurosciences, Lausanne University Hospital (CHUV), Lausanne, Switzerland; Crottaz-Herbette, S., Neuropsychology and Neurorehabilitation Service, Lausanne University Hospital (CHUV), Lausanne, Switzerland; Serino, A., MySpace Lab, Department of Clinical Neurosciences, Lausanne University Hospital (CHUV), Lausanne, Switzerland, MindMaze SA, Chemin de Roseneck 5, Lausanne, 1006, Switzerland","Prism adaptation is a method for studying visuomotor plasticity in healthy individuals, as well as for rehabilitating patients suffering spatial neglect. We developed a new set-up based on virtual-reality (VR) and haptic-robotics allowing us to induce sensorimotor adaptation and to reproduce the effect of prism adaptation in a more ecologically valid, yet experimentally controlled context. Participants were exposed to an immersive VR environment while controlling a virtual hand via a robotic-haptic device to reach virtual objects. During training, a rotational shift was induced between the position of the participant's real hand and that of the virtual hand in order to trigger sensorimotor recalibration. The use of VR and haptic-robotics allowed us to simulate and test multiple components of sensorimotor adaptation: training either peripersonal or extrapersonal space and testing generalization for the non-trained sector of space, and using active versus robot-guided reaching movements. Results from 60 neurologically intact participants show that participants exposed to the virtual shift were able to quickly adapt their reaching movements to aim correctly at the target objects. When the shift was removed, participants showed a systematic deviation of their movements during open-loop tasks in the direction opposite to that of the shift, which generalized to un-trained portions of space and occurred also when their movements were robotically-guided during the adaptation. Interestingly, follow-up questionnaires revealed that when the adaptation training was robotically-guided, participants were largely unaware of the mismatch between their hand and the virtual hand's position. The stability of the aftereffects, despite the changing experimental parameters, suggests that the induced sensory-motor adaptation does not rely on low-level processing of sensory stimuli during the training, but taps into high-level representations of space. Importantly, the flexibility of the trained space and the option of robotically-guided movements open novel possibilities of fine-tuning the training to patients’ level of spatial and motor impairment, thus possibly resulting in a better outcome. © 2020 The Author(s)","Far space; Guided movement; Haptic robot; Hemispatial neglect; Passive movement; Prism adaptation; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85098145308
"Harris D.J., Hardcastle K.J., Wilson M.R., Vine S.J.","57192429891;57221862684;55574207642;36811509000;","Assessing the learning and transfer of gaze behaviours in immersive virtual reality",2021,"Virtual Reality",,,,"","",,,"10.1007/s10055-021-00501-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100476971&doi=10.1007%2fs10055-021-00501-w&partnerID=40&md5=ad4779acdc2d1563f331327866d64c86","School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom; Counter Terrorism Protective Security Operations, Metropolitan Police Service, Lambeth HQ, London, SE1 7LP, United Kingdom","Harris, D.J., School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom; Hardcastle, K.J., Counter Terrorism Protective Security Operations, Metropolitan Police Service, Lambeth HQ, London, SE1 7LP, United Kingdom; Wilson, M.R., School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom; Vine, S.J., School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom","Virtual reality (VR) has clear potential for improving simulation training in many industries. Yet, methods for testing the fidelity, validity and training efficacy of VR environments are, in general, lagging behind their adoption. There is limited understanding of how readily skills learned in VR will transfer, and what features of training design will facilitate effective transfer. Two potentially important elements are the psychological fidelity of the environment, and the stimulus correspondence with the transfer context. In this study, we examined the effectiveness of VR for training police room searching procedures, and assessed the corresponding development of perceptual-cognitive skill through eye-tracking indices of search efficiency. Participants (n = 54) were assigned to a VR rule-learning and search training task (FTG), a search only training task (SG) or a no-practice control group (CG). Both FTG and SG developed more efficient search behaviours during the training task, as indexed by increases in saccade size and reductions in search rate. The FTG performed marginally better than the CG on a novel VR transfer test, but no better than the SG. More efficient gaze behaviours learned during training were not, however, evident during the transfer test. These findings demonstrate how VR can be used to develop perceptual-cognitive skills, but also highlight the challenges of achieving transfer of training. © 2021, The Author(s).","Fidelity; Police; Policing; Training; Validity; VR","E-learning; Eye tracking; Cognitive skill; Gaze behaviours; Immersive virtual reality; Search behaviours; Search efficiency; Simulation training; Training design; Transfer of trainings; Virtual reality",Article,"Article in Press","",Scopus,2-s2.0-85100476971
"Le Noury P., Buszard T., Reid M., Farrow D.","57219051674;55605085300;15136884800;7006613807;","Examining the representativeness of a virtual reality environment for simulation of tennis performance",2021,"Journal of Sports Sciences","39","4",,"412","420",,,"10.1080/02640414.2020.1823618","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091186202&doi=10.1080%2f02640414.2020.1823618&partnerID=40&md5=96877292c3a8a59e66088616130cba45","Institute of Health and Sport, Victoria University, Melbourne, Australia; Game Insight Group, Tennis Australia, Perth, Australia","Le Noury, P., Institute of Health and Sport, Victoria University, Melbourne, Australia; Buszard, T., Institute of Health and Sport, Victoria University, Melbourne, Australia; Reid, M., Game Insight Group, Tennis Australia, Perth, Australia; Farrow, D., Institute of Health and Sport, Victoria University, Melbourne, Australia","There has been a growing interest in using virtual reality (VR) for training perceptual-cognitive skill in sport. For VR training to effectively simulate real-world tennis performance, it must recreate the contextual information and movement behaviours present in the real-world environment. It is therefore critical to assess the representativeness of VR prior to implementing skill training interventions. We constructed a VR tennis environment designed for training perceptual-cognitive skill, with the aim of assessing its representativeness and validating its use. Participants movement behaviours were compared when playing tennis in VR and real-world environments. When performing groundstrokes, participants frequently used the same stance in VR as they did in the real-world condition. Participants experienced a high sense of presence in VR, evident through the factors of spatial presence, engagement and ecological validity being high, with minimal negative effects found. We conclude that Tennis VR is sufficiently representative of real-world tennis. Our discussion focuses on the opportunity for training perceptual-cognitive skill and the potential for skill transfer. © 2020 Informa UK Limited, trading as Taylor & Francis Group.","artificial intelligence; interactive training; perception action coupling; Skill","adult; article; artificial intelligence; ecological validity; female; human; human experiment; male; perception; simulation training; skill; standing; tennis; virtual reality",Article,"Final","",Scopus,2-s2.0-85091186202
"Harvey C., Selmanović E., O’Connor J., Chahin M.","48761392600;35218206600;57197835447;57204813574;","A comparison between expert and beginner learning for motor skill development in a virtual reality serious game",2021,"Visual Computer","37","1",,"3","17",,1,"10.1007/s00371-019-01702-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067692541&doi=10.1007%2fs00371-019-01702-w&partnerID=40&md5=bc2d985815aa255af972888f2dbf8fff","Birmingham City University, West Midlands, B4 7XG, United Kingdom; University of Sarajevo, Zmaja od Bosne 35, B&H, Sarajevo, Bosnia and Herzegovina","Harvey, C., Birmingham City University, West Midlands, B4 7XG, United Kingdom; Selmanović, E., University of Sarajevo, Zmaja od Bosne 35, B&H, Sarajevo, Bosnia and Herzegovina; O’Connor, J., Birmingham City University, West Midlands, B4 7XG, United Kingdom; Chahin, M., University of Sarajevo, Zmaja od Bosne 35, B&H, Sarajevo, Bosnia and Herzegovina","In order to be used for skill development and skill maintenance, virtual environments require accurate simulation of the physical phenomena involved in the process of the task being trained. The accuracy needs to be conveyed in a multimodal fashion with varying parameterisations still being quantified, and these are a function of task, prior knowledge, sensory efficacy and human perception. Virtual reality (VR) has been integrated from a didactic perspective in many serious games and shown to be effective in the pedological process. This paper interrogates whether didactic processes introduced into a VR serious game, by taking advantage of augmented virtuality to modify game attributes, can be effective for both beginners and experts to a task. The task in question is subjective performance in a clay pigeon shooting simulation. The investigation covers whether modified game attributes influence skill and learning in a complex motor task and also investigates whether this process is applicable to experts as well as beginners to the task. VR offers designers and developers of serious games the ability to provide information in the virtual world in a fashion that is impossible in the real world. This introduces the question of whether this is effective and transfers skill adoption into the real world and also if a-priori knowledge influences the practical nature of this information in the pedagogic process. Analysis is conducted via a between-subjects repeated measure ANOVA using a 2 × 2 factorial design to address these questions. The results show that the different training provided affects the performance in this task (N= 57). The skill improvement is still evidenced in repeated measures when information and guidance is removed. This effect does not exist under a control condition. Additionally, we separate by an expert and non-expert group to deduce if a-priori knowledge influences the effect of the presented information, it is shown that it does not. © 2019, The Author(s).","Learning; Serious game; Training; Virtual reality","E-learning; Personnel training; Sensory perception; Virtual reality; Augmented virtualities; Human perception; Learning; Physical phenomena; Priori knowledge; Repeated measures; Skill development; Subjective performance; Serious games",Article,"Final","",Scopus,2-s2.0-85067692541
"Latif S., Tarner H., Beck F.","57204297580;57221051233;25824730200;","Talking Realities: Audio Guides in Virtual Reality Visualizations",2021,"IEEE Computer Graphics and Applications",,,,"","",,,"10.1109/MCG.2021.3058129","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100836573&doi=10.1109%2fMCG.2021.3058129&partnerID=40&md5=e2bd14a4b2ae9156580f43d0da0207de","ICB, University of Duisburg-Essen - Campus Essen, 119884 Essen, NRW, Germany, 45127 (e-mail: shahid.latif@uni-due.de); ICB, University of Duisburg-Essen - Campus Essen, 119884 Essen, NRW, Germany, (e-mail: hagen.tarner@paluno.uni-due.de); ICB, Universitat Duisburg-Essen - Campus Essen, 119884 Essen, NRW, Germany, 45127 (e-mail: fabian.beck@paluno.uni-due.de)","Latif, S., ICB, University of Duisburg-Essen - Campus Essen, 119884 Essen, NRW, Germany, 45127 (e-mail: shahid.latif@uni-due.de); Tarner, H., ICB, University of Duisburg-Essen - Campus Essen, 119884 Essen, NRW, Germany, (e-mail: hagen.tarner@paluno.uni-due.de); Beck, F., ICB, Universitat Duisburg-Essen - Campus Essen, 119884 Essen, NRW, Germany, 45127 (e-mail: fabian.beck@paluno.uni-due.de)","Building upon the ideas of storytelling and explorable explanations, we introduce Talking Realities, a concept for producing data-driven interactive narratives in virtual reality. It combines an audio narrative with an immersive visualization to communicate analysis results. The narrative is automatically produced using template-based natural language generation and adapts to data and user interactions. The synchronized animation of visual elements in accordance with the audio connects the two representations. In addition, we discuss various modes of explanation ranging from fully guided tours to free exploration of the data. We demonstrate the applicability of our concept by developing a virtual reality visualization for air traffic data. Furthermore, generalizability is exhibited by sketching mock-ups for two more application scenarios in the context of information and scientific visualization. IEEE","Data analysis; Data visualization; Speech synthesis; Synchronization; Two dimensional displays; Virtual reality; Visualization","Natural language processing systems; Virtual reality; Visualization; Application scenario; Immersive visualization; Information and scientific visualization; Interactive narrative; Natural language generation; Reality visualization; User interaction; Visual elements; Data visualization",Article,"Article in Press","",Scopus,2-s2.0-85100836573
"Kondo Y., Fukuhara K., Suda Y., Higuchi T.","57219251978;52163401400;57219255977;55702546800;","Training older adults with virtual reality use to improve collision-avoidance behavior when walking through an aperture",2021,"Archives of Gerontology and Geriatrics","92",, 104265,"","",,,"10.1016/j.archger.2020.104265","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091915778&doi=10.1016%2fj.archger.2020.104265&partnerID=40&md5=e8bc2b9c29fa499658d23b268614d2bb","Department of Health Promotion Science, Tokyo Metropolitan University, Tokyo, Japan; Department of Physical Rehabilitation, National Center Hospital, National Center of Neurology and Psychiatry, Tokyo, Japan","Kondo, Y., Department of Health Promotion Science, Tokyo Metropolitan University, Tokyo, Japan, Department of Physical Rehabilitation, National Center Hospital, National Center of Neurology and Psychiatry, Tokyo, Japan; Fukuhara, K., Department of Health Promotion Science, Tokyo Metropolitan University, Tokyo, Japan; Suda, Y., Department of Health Promotion Science, Tokyo Metropolitan University, Tokyo, Japan; Higuchi, T., Department of Health Promotion Science, Tokyo Metropolitan University, Tokyo, Japan","Many older adults perform collision-avoidance behavior either insufficiently (i.e., frequent collision) or inefficiently (i.e., exaggerated behavior to ensure collision-avoidance). The present study examined whether a training system using virtual reality (VR) simulation enhanced older adults’ collision-avoidance behavior in response to a VR image of an aperture during real walking. Twenty-five (n = 13 intervention group and n = 12 control group) older individuals participated. During training, a VR image of walking through an aperture was projected onto a large screen. Participants in the intervention group tried to avoid virtual collision with the minimum body rotation required to walk on the spot through a variety of narrow apertures. Participants in the control group remained without body rotation while walking on the spot through a wide aperture. A comparison between pre-test and post-test performances in the real environment indicated that after the training, significantly smaller body rotation angles were observed in the intervention group. This suggests that the training led participants to modify their behavior to try to move efficiently during real walking. However, although not significant, collision rates also tended to be greater, suggesting that, at least for some participants, the modification required to avoid collision was too difficult. Transfer of the learned behavior using the VR environment to real walking is discussed. © 2020 Elsevier B.V.","Cautious strategy; Obstacle avoidance; Stepping in place; Virtual reality; Walking","aged; article; avoidance behavior; clinical article; controlled study; female; human; human experiment; male; rotation; task performance; virtual reality; walking; avoidance behavior; walking; Aged; Avoidance Learning; Humans; Virtual Reality; Walking",Article,"Final","",Scopus,2-s2.0-85091915778
"Sakib M.N., Chaspari T., Behzadan A.H.","57213424763;55351228300;15073914400;","Physiological Data Models to Understand the Effectiveness of Drone Operation Training in Immersive Virtual Reality",2021,"Journal of Computing in Civil Engineering","35","1", 04020053,"","",,,"10.1061/(ASCE)CP.1943-5487.0000941","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095978574&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000941&partnerID=40&md5=e4034444de1c6b70a770491142771400","Dept. of Multidisciplinary Engineering, Texas A and M Univ., 3127 TAMU, College Station, TX  77843, United States; Dept. of Computer Science and Engineering, Texas A and M Univ., 3127 TAMU, College Station, TX  77843, United States; Dept. of Construction Science, Texas A and M Univ., 3137 TAMU, College Station, TX  77843, United States","Sakib, M.N., Dept. of Multidisciplinary Engineering, Texas A and M Univ., 3127 TAMU, College Station, TX  77843, United States; Chaspari, T., Dept. of Computer Science and Engineering, Texas A and M Univ., 3127 TAMU, College Station, TX  77843, United States; Behzadan, A.H., Dept. of Construction Science, Texas A and M Univ., 3137 TAMU, College Station, TX  77843, United States","Data collection using unmanned aerial vehicles (UAVs) in construction and heavy civil projects is subject to compliance with strict operational rules and safety regulations. Both the US Federal Aviation Administration (FAA) and the European Union Aviation Safety Agency (EASA) require drone operators to keep the drone in sight and avoid flying near people or other objects. From the perspective of the operator, remaining in standing or sitting position while always looking up to monitor the drone movements can cause awkward body postures, stress, and fatigue. Coupled with the mental load resulting from delegated tasks, this could potentially put the drone mission, people, and property at risk. This research investigates the reliability of using the drone operator's physiological indexes and self-assessments to predict performance, mental workload (MWL), and stress in immersive virtual reality training and outdoor deployment. A user study was carried out to collect physiological data using wearable devices and design general population and group-specific prediction models. Results show that in 83% of cases, these models can predict performance, MWL, and stress levels accurately or within one level. This paper contributes to the core body of knowledge by providing a scalable approach to objectively quantifying performance, MWL, and stress that can be used to design adaptive training systems for drone operators. Personalized models of physiological signals are presented as reliable indexes to describing the outcome of interest. Scalability is achieved through the application of generalizable machine learning models that learn the interdependencies between physiological and self-assessment inputs and their association with corresponding outcomes. © 2020 American Society of Civil Engineers.","Human performance; Machine learning (ML); Mental workload; Physiological signals; Unmanned aerial vehicle (UAV); Virtual reality (VR); Wearable technology","Adaptive systems; Antennas; Automobile bodies; Data acquisition; Drones; E-learning; Forecasting; Personnel training; Physiology; Population statistics; Predictive analytics; Safety engineering; Virtual reality; Adaptive training system; General population; Immersive virtual reality; Machine learning models; Personalized model; Physiological indices; Physiological signals; Us federal aviation administrations; Physiological models",Article,"Final","",Scopus,2-s2.0-85095978574
"Clay C.J., Schmitz B.A., Balakrishnan B., Hopfenblatt J.P., Evans A., Kahng S.","55362551400;57201501225;25931981700;57193741502;57221685293;21635542200;","Feasibility of virtual reality behavior skills training for preservice clinicians",2021,"Journal of Applied Behavior Analysis",,,,"","",,,"10.1002/jaba.809","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099796240&doi=10.1002%2fjaba.809&partnerID=40&md5=66587b6483c39392f35899c20e1b6efc","The University of Missouri, United States; The Thompson Center for Autism and Neurodevelopmental Disorders, United States; Rutgers University, United States","Clay, C.J., The University of Missouri, United States, The Thompson Center for Autism and Neurodevelopmental Disorders, United States; Schmitz, B.A., The University of Missouri, United States, The Thompson Center for Autism and Neurodevelopmental Disorders, United States; Balakrishnan, B., The University of Missouri, United States; Hopfenblatt, J.P., The University of Missouri, United States; Evans, A., The University of Missouri, United States; Kahng, S., Rutgers University, United States","Effective training procedures include behavioral skills training (BST), which involves providing written and verbal instructions, modeling of the skill, rehearsal of the skill, and feedback on the performance. This training typically involves in vivo experience in which trainees and students are exposed to risks such as proximity to infectious disease, behavioral issues such as aggression, and errors in teaching performance. Conducting BST in a virtual reality (VR) context involving virtual individuals with problem behavior may be an effective means of mitigating these risks. The purpose of this study was to examine the feasibility of training students to conduct functional communication training (FCT) in a VR environment using BST. We trained 13 preservice college students to implement FCT for attention and escape functions. We found VR BST was effective at increasing correct steps performed of FCT to mastery criterion levels with all participants. Future researchers should examine generalization and maintenance of VR BST. © 2021 Society for the Experimental Analysis of Behavior","behavioral skills training; functional communication training; virtual reality; virtual teaching; virtual training",,Article,"Article in Press","",Scopus,2-s2.0-85099796240
"Kittel A., Larkin P., Elsworthy N., Spittle M.","57189646376;55764354400;54917109200;16425117500;","Transfer of 360° virtual reality and match broadcast video-based tests to on-field decision-making",2021,"Science and Medicine in Football","5","1",,"79","86",,,"10.1080/24733938.2020.1802506","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088971174&doi=10.1080%2f24733938.2020.1802506&partnerID=40&md5=520e42b047599e9f94af9f1ec8cacd05","Institute for Health and Sport, Victoria University, Australia; Maribyrnong Sports Academy, Melbourne, Australia; School of Health, Medical and Applied Sciences, Central Queensland University, Rockhampton, Australia","Kittel, A., Institute for Health and Sport, Victoria University, Australia; Larkin, P., Institute for Health and Sport, Victoria University, Australia, Maribyrnong Sports Academy, Melbourne, Australia; Elsworthy, N., School of Health, Medical and Applied Sciences, Central Queensland University, Rockhampton, Australia; Spittle, M., Institute for Health and Sport, Victoria University, Australia","This study aimed to assess the level of transfer of two reliable and valid video modes to in-game decision-making performance. Two video-based tests of 25 clips each (360°VR and match broadcast vision) assessed off-field decision-making accuracy in elite Australian football umpires (n=21). Game performance was assessed across four games for each participant, classified into two groups based on this measure; “highly skilled” or ‘skilled’. Decision-making was assessed for correct, missed and unwarranted decisions in video-based tests and in-game assessments. Independent t-tests analysed differences between highly skilled and skilled in-game decision-makers for each test. Correlations also compared experience and in-game with video-based test decision-making performance. For both video-based tests, there were no significant differences between highly skilled and skilled in-game decision-makers, nor any significant correlations. Officials who made less unwarranted decisions in-game (highly skilled) made significantly less unwarranted decisions in the match broadcast test. There was a significant correlation between experience and 360°VR correct decision-making. Neither video-based test had the sensitivity to discriminate between elite officials, potentially due to the third-person perspective (match broadcast task) or sub-elite players presented (360°VR). Optimising the representativeness of off-field tasks through including similar constraints to performance environments is an important consideration for researchers and practitioners. © 2020 Informa UK Limited, trading as Taylor & Francis Group.","decision making; immersive video; officials; transfer; video-based test; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85088971174
"Zhu Y., Zhai G., Min X., Zhou J.","57189598758;15847120000;56030205300;55938080200;","Learning a Deep Agent to Predict Head Movement in 360-Degree Images",2021,"ACM Transactions on Multimedia Computing, Communications and Applications","16","4", 3410455,"","",,,"10.1145/3410455","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100305639&doi=10.1145%2f3410455&partnerID=40&md5=50236f32dd2ed174b5431f405e66566a","Shanghai Jiao Tong University, Shanghai, China; University of Macau, Macau","Zhu, Y., Shanghai Jiao Tong University, Shanghai, China; Zhai, G., Shanghai Jiao Tong University, Shanghai, China; Min, X., Shanghai Jiao Tong University, Shanghai, China; Zhou, J., University of Macau, Macau","Virtual reality adequately stimulates senses to trick users into accepting the virtual environment. To create a sense of immersion, high-resolution images are required to satisfy human visual system, and low latency is essential for smooth operations, which put great demands on data processing and transmission. Actually, when exploring in the virtual environment, viewers only perceive the content in the current field of view. Therefore, if we can predict the head movements that are important behaviors of viewers, more processing resources can be allocated to the active field of view. In this article, we propose a model to predict the trajectory of head movement. Deep reinforcement learning is employed to mimic the decision making. In our framework, to characterize each state, features for viewport images are extracted by convolutional neural networks. In addition, the spherical coordinate maps and visited maps are generated for each viewport image, which facilitate the multiple dimensions of the state information by considering the impact of historical head movement and position information. To ensure the accurate simulation of visual behaviors during the watching of panoramas, we stipulate that the model imitates the behaviors of human demonstrators. To allow the model to generalize to more conditions, the intrinsic motivation is employed to guide the agent's action toward reducing uncertainty, which can enhance robustness during the exploration. The experimental results demonstrate the effectiveness of the proposed stepwise head movement predictor. © 2020 ACM.","360 degree; deep reinforcement learning (DRL); head movement prediction; omnidirectional; panoramic; saliency; VR","Behavioral research; Convolutional neural networks; Data handling; Decision making; Forecasting; Image processing; Reinforcement learning; Data processing and transmission; High resolution image; Human Visual System; Intrinsic motivation; Multiple dimensions; Position information; Processing resources; Spherical coordinates; Deep learning",Article,"Final","",Scopus,2-s2.0-85100305639
"Solini H.M., Bhargava A., Pagano C.C.","57203975019;57194158382;7005950745;","The effects of testing environment, experimental design, and ankle loading on calibration to perturbed optic flow during locomotion",2021,"Attention, Perception, and Psychophysics","83","1",,"497","511",,,"10.3758/s13414-020-02200-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096534879&doi=10.3758%2fs13414-020-02200-1&partnerID=40&md5=33cc438a34f94a9f543f1f1b7c1aaedc","Department of Psychology, Clemson University, 418 Brackett Hall, Clemson, SC, United States; Key Lime Interactive, LLC, Brooklyn, NY, United States","Solini, H.M., Department of Psychology, Clemson University, 418 Brackett Hall, Clemson, SC, United States; Bhargava, A., Key Lime Interactive, LLC, Brooklyn, NY, United States; Pagano, C.C., Department of Psychology, Clemson University, 418 Brackett Hall, Clemson, SC, United States","Calibration is the process by which the execution of actions becomes scaled to the (changing) relationship between environmental features and the actor’s action capabilities. Though much research has investigated how individuals calibrate to perturbed optic flow, it remains unclear how different experimental factors contribute to the magnitude of calibration transfer. In the present study, we assessed how testing environment (Experiment 1), an adapted pretest-calibration-posttest design (Experiment 2), and bilateral ankle loading (Experiment 3) affected the magnitude of calibration to perturbed optic flow. We found that calibration transferred analogously to real-world and virtual environments. Although the magnitude of calibration transfer found here was greater than that reported by previous researchers, it was evident that calibration occurred rapidly and quickly plateaued, further supporting the claim that calibration is often incomplete despite continued calibration trials. We also saw an asymmetry in calibration magnitude, which may be due to a lack of appropriate perceptual-motor scaling prior to calibration. The implications of these findings for the assessment of distance perception and calibration in real-world and virtual environments are discussed. © 2020, The Psychonomic Society, Inc.","Adaptation and after effects; Goal-directed movements; Perception and action","ankle; calibration; human; locomotion; methodology; optic flow; Ankle; Calibration; Humans; Locomotion; Optic Flow; Research Design",Article,"Final","",Scopus,2-s2.0-85096534879
"Liu P., Li C., Xiao C., Zhang Z., Ma J., Gao J., Shao P., Valerio I., Pawlik T.M., Ding C., Yilmaz A., Xu R.","57109570400;57208301188;57194183923;56452276600;57217084915;57212121943;56085690300;14623552900;7006249269;57214826251;57219084145;56984933900;","A Wearable Augmented Reality Navigation System for Surgical Telementoring Based on Microsoft HoloLens",2021,"Annals of Biomedical Engineering","49","1",,"287","298",,,"10.1007/s10439-020-02538-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086131311&doi=10.1007%2fs10439-020-02538-5&partnerID=40&md5=e3b5799ca3ae72fb69fe834a82a5b7e1","Department of Precision Machinery and Instrumentation, University of Science and Technology of China, Hefei, Anhui, China; Department of Biomedical Engineering, The Ohio State University, Columbus, United States; Photogrammetric Computer Vision Laboratory, The Ohio State University, Columbus, United States; Department of Surgery, The Ohio State University, Columbus, United States; Department of Rehabilitation Medicine, The Second Hospital of Anhui Medical University, Hefei, Anhui, China","Liu, P., Department of Precision Machinery and Instrumentation, University of Science and Technology of China, Hefei, Anhui, China; Li, C., Department of Precision Machinery and Instrumentation, University of Science and Technology of China, Hefei, Anhui, China, Department of Biomedical Engineering, The Ohio State University, Columbus, United States; Xiao, C., Photogrammetric Computer Vision Laboratory, The Ohio State University, Columbus, United States; Zhang, Z., Department of Precision Machinery and Instrumentation, University of Science and Technology of China, Hefei, Anhui, China, Department of Biomedical Engineering, The Ohio State University, Columbus, United States; Ma, J., Department of Precision Machinery and Instrumentation, University of Science and Technology of China, Hefei, Anhui, China; Gao, J., Department of Precision Machinery and Instrumentation, University of Science and Technology of China, Hefei, Anhui, China; Shao, P., Department of Precision Machinery and Instrumentation, University of Science and Technology of China, Hefei, Anhui, China; Valerio, I., Department of Surgery, The Ohio State University, Columbus, United States; Pawlik, T.M., Department of Surgery, The Ohio State University, Columbus, United States; Ding, C., Department of Rehabilitation Medicine, The Second Hospital of Anhui Medical University, Hefei, Anhui, China; Yilmaz, A., Photogrammetric Computer Vision Laboratory, The Ohio State University, Columbus, United States; Xu, R., Department of Precision Machinery and Instrumentation, University of Science and Technology of China, Hefei, Anhui, China, Department of Biomedical Engineering, The Ohio State University, Columbus, United States","This paper reports a new type of augmented reality (AR) system that integrates a Microsoft HoloLens device with a three-dimensional (3D) point tracking module for medical training and telementored surgery. In this system, a stereo camera is used to track the 3D position of a scalpel and transfer its coordinates wirelessly to a HoloLens device. In the scenario of surgical training, a virtual surgical scene with pre-recorded surgical annotations is superimposed with the actual surgical scene so that the surgical trainee is able to operate following virtual instructions. In the scenario of telementored surgery, the virtual surgical scene is co-registered with the actual surgical scene so that the virtual scalpel remotely mentored by an experienced surgeon provides the AR guidance for the inexperienced on-site operator. The performance characteristics of the proposed AR telementoring system are verified by benchtop experiments. The clinical applicability of the proposed system in telementored skin grafting surgery and fasciotomy is validated in a New Zealand rabbit model. Our benchtop and in vivo experiments demonstrate the potential to improve surgical performance and reduce healthcare disparities in remote areas with limited resources. © 2020, Biomedical Engineering Society.","Augment reality surgical navigation; Medical training; Microsoft HoloLens; Surgical telementoring","Augmented reality; E-learning; Navigation systems; Stereo image processing; Wearable computers; Augmented reality systems; In-vivo experiments; Medical training; New Zealand rabbits; Performance characteristics; Stereo cameras; Surgical training; Threedimensional (3-d); Transplantation (surgical); adult; animal experiment; animal tissue; Article; controlled study; fasciotomy; female; health care disparity; human; human tissue; image recording; in vivo study; medical education; medical student; New Zealand rabbit; nonhuman; priority journal; skin transplantation; surgeon; surgical training; telecommunication; virtual reality",Article,"Final","",Scopus,2-s2.0-85086131311
"Lau K.W., Lee P.Y.","57211282004;36835177400;","Using virtual reality for professional training practices: exploring the factors of applying stereoscopic 3D technologies in knowledge transfer",2021,"Virtual Reality",,,,"","",,,"10.1007/s10055-021-00504-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101077739&doi=10.1007%2fs10055-021-00504-7&partnerID=40&md5=8289cf3850d93bac91546d72ef249966","The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong","Lau, K.W., The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong; Lee, P.Y., The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong","Current research has constantly highlighted the significance of developing a learning culture with a robust knowledge sharing and transfer process in knowledge-based societies. The emergence of stereoscopic 3D virtual technologies provides organizations with an opportunity to develop immersive and virtual professional training practices for employees’ transformative learning. This research gathered data from a survey of 326 respondents to investigate employees’ virtual learning experiences in a virtual learning environment (VLE). The results show that a successful VLE model could possibly enhance employees’ learning motivation, process and satisfaction. The empirical evidence of this research suggests that there are three key components of framework for actual implementation; they are (1) the careful selection of VLE; (2) the appropriate design of pedagogical strategies; and (3) the effective use of virtual stimuli which involves the factors of the stereoscopic 3D visualization, telepresence and multisensory interactions. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd. part of Springer Nature.","Knowledge transfer; Learning science; Professional training; Stereoscopic 3D technology; Virtual reality","Computer aided instruction; E-learning; Knowledge based systems; Knowledge management; Personnel training; Stereo image processing; Surveys; Three dimensional computer graphics; Visual communication; Knowledge-based society; Multisensory interaction; Pedagogical strategies; Professional training; Stereoscopic 3-d technologies; Stereoscopic 3D visualization; Transformative learning; Virtual learning environments; Virtual reality",Article,"Article in Press","",Scopus,2-s2.0-85101077739
"Nguyen-Vo T., Riecke B.E., Stuerzlinger W., Pham D.-M., Kruijff E.","57021750000;6603396361;55902405400;57203971039;15022738100;","NaviBoard and NaviChair: Limited Translation Combined with Full Rotation for Efficient Virtual Locomotion",2021,"IEEE Transactions on Visualization and Computer Graphics","27","1", 8809840,"165","177",,2,"10.1109/TVCG.2019.2935730","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096885584&doi=10.1109%2fTVCG.2019.2935730&partnerID=40&md5=85d46ecc0f5cefd72f65aac054e1267c","School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC  V5A 1S6, Canada; Institute of Visual Computing, Bonn-Rhein-Sieg University of Applied Sciences, Sankt Augustin, 53757, Germany","Nguyen-Vo, T., School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC  V5A 1S6, Canada; Riecke, B.E., School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC  V5A 1S6, Canada; Stuerzlinger, W., School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC  V5A 1S6, Canada; Pham, D.-M., School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC  V5A 1S6, Canada; Kruijff, E., Institute of Visual Computing, Bonn-Rhein-Sieg University of Applied Sciences, Sankt Augustin, 53757, Germany","Walking has always been considered as the gold standard for navigation in Virtual Reality research. Though full rotation is no longer a technical challenge, physical translation is still restricted through limited tracked areas. While rotational information has been shown to be important, the benefit of the translational component is still unclear with mixed results in previous work. To address this gap, we conducted a mixed-method experiment to compare four levels of translational cues and control: none (using the trackpad of the HTC Vive controller to translate), upper-body leaning (sitting on a 'NaviChair', leaning the upper-body to locomote), whole-body leaning/stepping (standing on a platform called NaviBoard, leaning the whole body or stepping one foot off the center to navigate), and full translation (physically walking). Results showed that translational cues and control had significant effects on various measures including task performance, task load, and simulator sickness. While participants performed significantly worse when they used a controller with no embodied translational cues, there was no significant difference between the NaviChair, NaviBoard, and actual walking. These results suggest that translational body-based motion cues and control from a low-cost leaning/stepping interface might provide enough sensory information for supporting spatial updating, spatial awareness, and efficient locomotion in VR, although future work will need to investigate how these results might or might not generalize to other tasks and scenarios. © 1995-2012 IEEE.","Adaptive control; cognitive informatics; human computer interaction; human factors; user interface; virtual reality","Computer graphics; Software engineering; Efficient locomotion; Sensory information; Simulator sickness; Spatial awareness; Spatial updating; Technical challenges; Translational component; Virtual locomotion; Controllers",Article,"Final","",Scopus,2-s2.0-85096885584
"Guarda A.F.R., Rodrigues N.M.M., Pereira F.","56337122500;7006052345;7201690397;","Constant Size Point Cloud Clustering: A Compact, Non-Overlapping Solution",2021,"IEEE Transactions on Multimedia","23",, 9000649,"77","91",,,"10.1109/TMM.2020.2974325","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098157333&doi=10.1109%2fTMM.2020.2974325&partnerID=40&md5=88082449ccfda4fb0d35d8f41da0bd7a","Instituto Superior Tecnico, Universidade de Lisboa, Instituto de Telecomunicacoes, Lisbon, Portugal; ESTG, Instituto Politecnico de Leiria, Instituto de Telecomunicacoes, Leiria, Portugal","Guarda, A.F.R., Instituto Superior Tecnico, Universidade de Lisboa, Instituto de Telecomunicacoes, Lisbon, Portugal; Rodrigues, N.M.M., ESTG, Instituto Politecnico de Leiria, Instituto de Telecomunicacoes, Leiria, Portugal; Pereira, F., Instituto Superior Tecnico, Universidade de Lisboa, Instituto de Telecomunicacoes, Lisbon, Portugal","Point clouds have recently become a popular 3D representation model for many application domains, notably virtual and augmented reality. Since point cloud data is often very large, processing a point cloud may require that it be segmented into smaller clusters. For example, the input to deep learning-based methods like auto-encoders should be constant size point cloud clusters, which are ideally compact and non-overlapping. However, given the unorganized nature of point clouds, defining the specific data segments to code is not always trivial. This paper proposes a point cloud clustering algorithm which targets five main goals: i) clusters with a constant number of points; ii) compact clusters, i.e., with low dispersion; iii) non-overlapping clusters, i.e., not intersecting each other; iv) ability to scale with the number of points; and v) low complexity. After appropriate initialization, the proposed algorithm transfers points between neighboring clusters as a propagation wave, filling or emptying clusters until they achieve the same size. The proposed algorithm is unique since there is no other point cloud clustering method available in the literature offering the same clustering features for large point clouds at such low complexity. © 1999-2012 IEEE.","compactness; constant size; non-overlapping; Point cloud; point cloud clustering","3D modeling; Augmented reality; Deep learning; Learning systems; Three dimensional computer graphics; 3d representations; Clustering feature; Clustering methods; Learning-based methods; Low dispersions; Overlapping clusters; Point cloud data; Virtual and augmented reality; Clustering algorithms",Article,"Final","",Scopus,2-s2.0-85098157333
"Feng Y., Duives D., Daamen W., Hoogendoorn S.","57216936136;55630559900;6602658905;6701778851;","Data collection methods for studying pedestrian behaviour: A systematic review",2021,"Building and Environment","187",, 107329,"","",,1,"10.1016/j.buildenv.2020.107329","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095426073&doi=10.1016%2fj.buildenv.2020.107329&partnerID=40&md5=cdba405c4d43abf884b7f43d557c614d","Department of Transport & Planning, Delft University of Technology, Stevinweg 1, Delft, 2628 CN, Netherlands","Feng, Y., Department of Transport & Planning, Delft University of Technology, Stevinweg 1, Delft, 2628 CN, Netherlands; Duives, D., Department of Transport & Planning, Delft University of Technology, Stevinweg 1, Delft, 2628 CN, Netherlands; Daamen, W., Department of Transport & Planning, Delft University of Technology, Stevinweg 1, Delft, 2628 CN, Netherlands; Hoogendoorn, S., Department of Transport & Planning, Delft University of Technology, Stevinweg 1, Delft, 2628 CN, Netherlands","Collecting pedestrian behaviour data is vital to understand pedestrian behaviour. This systematic review of 145 studies aims to determine the capability of contemporary data collection methods in collecting different pedestrian behavioural data, identify research gaps and discuss the possibilities of using new technologies to study pedestrian behaviour. The review finds that there is an imbalance in the number of studies that feature various aspects of pedestrian behaviour, most importantly (1) pedestrian behaviour in large complex scenarios, and (2) pedestrian behaviour during new types of high-risk situations. Additionally, three issues are identified regarding current pedestrian behaviour studies, namely (3) little comprehensive data sets featuring multi-dimensional behaviour data simultaneously, (4) generalizability of most collected data sets is limited, and (5) costs of pedestrian behaviour experiments are relatively high. A set of new technologies offers opportunities to overcome some of these limitations. This review identifies three types of technologies that can become a valuable addition to pedestrian behaviour research methods, namely (1) applying VR experiments to study pedestrian behaviour in the environments that are difficult or cannot be mimicked in real-life, repeat experiments to determine the impact of factors on pedestrian behaviour and collect more accurate behavioural data to understand the decision-making process of pedestrian behaviour deeply, (2) applying large-scale crowd monitoring to study pedestrian movements in large complex environments and incident situations, and (3) utilising the Internet of Things to track pedestrian movements at various locations that are difficult to investigate at the moment. © 2020 The Authors","Crowd; Data collection method; IoT; Literature review; Pedestrian behaviour; Virtual reality","Data acquisition; Risk perception; Complex environments; Data collection method; Decision making process; High-risk situations; Multi dimensional; Pedestrian movement; Research gaps; Systematic Review; Behavioral research; decision making; Internet; literature review; pedestrian; travel behavior; virtual reality",Article,"Final","",Scopus,2-s2.0-85095426073
"Labib A., Alinier G.","57202192355;6506887966;","Transport and Retrieval on Extracorporeal Membrane Oxygenation (ECMO): Setup and Activities of an Immersive Transport and Retrieval on ECMO Workshop",2021,"Journal of Cardiothoracic and Vascular Anesthesia",,,,"","",,,"10.1053/j.jvca.2020.11.069","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099134136&doi=10.1053%2fj.jvca.2020.11.069&partnerID=40&md5=c0d042ee01ddc9d7818aa10bbd45881e","Medical Intensive Care Unit, Hamad General Hospital, Hamad Medical Corporation, Doha, Qatar; Weill Cornell Medicine – Qatar, Doha, Qatar; Hamad Medical Corporation Ambulance Service, Medical City, Doha, Qatar; School of Health and Social Work, University of Hertfordshire, Hatfield, Hertfordshire, United Kingdom; Northumbria University, Newcastle upon Tyne, United Kingdom","Labib, A., Medical Intensive Care Unit, Hamad General Hospital, Hamad Medical Corporation, Doha, Qatar, Weill Cornell Medicine – Qatar, Doha, Qatar; Alinier, G., Hamad Medical Corporation Ambulance Service, Medical City, Doha, Qatar, School of Health and Social Work, University of Hertfordshire, Hatfield, Hertfordshire, United Kingdom, Northumbria University, Newcastle upon Tyne, United Kingdom","Extracorporeal life support and extracorporeal membrane oxygenation (ECMO) are widely used for acute severe refractory cardiac and respiratory failure. An increasing number of patients are treated with ECMO worldwide. This can be attributed to technical and technologic advancements, easier access to modern equipment, and more regular and accessible training opportunities for practitioners to maintain current skills and develop new ones. Typically, ECMO is provided at tertiary or regional centers that often are university- affiliated. In a significant number of patients, ECMO may be initiated at a peripheral hospital before they are transported to a tertiary facility by a specialized multiprofessional ECMO team. The transport phase is, however, fraught with challenges and untoward events are not uncommon during ECMO transportation, so a robust education and training program is critical to ensure patient safety and optimum outcome. This article describes the authors’ experience of developing and running a simulation-based ECMO Transport and Retrieval workshop, with multiple immersive scenarios and opportunities for participants to familiarize themselves with the process and the ambulance equipment and environment. Preparation is a key element to successfully run scenarios that are technically challenging to facilitate due to the environment and equipment involved. To date, 136 multidisciplinary ECMO providers have attended the workshop and no incidents have been reported by the authors’ teams during actual transfers and retrieval missions with patients on ECMO. © 2020 The Authors","ECMO; high-fidelity; immersive; retrieval; simulation; transport; workshop",,Conference Paper,"Article in Press","",Scopus,2-s2.0-85099134136
"Ösp Egilsdottir H., Heyn L.G., Brembo E.A., Byermoen K.R., Moen A., Eide H.","57221478468;37123970300;57170877500;57220864359;7003535544;6701792808;","Configuration of mobile learning tools to support basic physical assessment in nursing education: Longitudinal participatory design approach",2021,"JMIR mHealth and uHealth","9","1", e22633,"","",,,"10.2196/22633","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099248397&doi=10.2196%2f22633&partnerID=40&md5=361834d50166a4b23ffa1a2c913b3f70","Science Centre Health and Technology, Faculty of Health and Social Sciences, University of South-Eastern Norway, Drammen, Norway; Institute for Health and Society, Faculty of Medicine, University of Oslo, Oslo, Norway","Ösp Egilsdottir, H., Science Centre Health and Technology, Faculty of Health and Social Sciences, University of South-Eastern Norway, Drammen, Norway; Heyn, L.G., Science Centre Health and Technology, Faculty of Health and Social Sciences, University of South-Eastern Norway, Drammen, Norway; Brembo, E.A., Science Centre Health and Technology, Faculty of Health and Social Sciences, University of South-Eastern Norway, Drammen, Norway; Byermoen, K.R., Science Centre Health and Technology, Faculty of Health and Social Sciences, University of South-Eastern Norway, Drammen, Norway; Moen, A., Institute for Health and Society, Faculty of Medicine, University of Oslo, Oslo, Norway; Eide, H., Science Centre Health and Technology, Faculty of Health and Social Sciences, University of South-Eastern Norway, Drammen, Norway","Background: As many students in higher education are skilled users of mobile technology, mobile learning (mLearning) can be a promising educational strategy to enhance their learning experience. mLearning might also be well suited for nursing students as they navigate between multiple learning contexts in their educational curriculum. As an educational strategy, mLearning may also reduce challenges caused by the theory-practice gap in nursing by supporting skills and knowledge transfer between the university and clinical settings. As the introduction of basic physical assessment skills (B-PASs) into Norwegian bachelor's degree education in nursing occurred quite recently, there is a lack of competence in supervision and teaching in both university and clinical settings. As such, mLearning appears to be a good strategy to support student B-PAS learning and knowledge transfer across learning contexts. Objective: This study aims to explore and elicit the perspectives of students regarding the way in which a selection of digital learning resources supports B-PAS learning and application in clinical rotation, which of the selected digital learning resources are beneficial to include in a suite of mLearning tools, and how the selected digital learning resources could support the transfer of skills and knowledge from the academic to clinical context. Methods: We used a longitudinal participatory design approach to co-design a suite of mLearning tools. The co-design processes took place in several workshops (WSs) over a period of 3 months: 2 WSs with first-year students (n=6), 3 WSs with second-year students (n=6), and 3 WSs with third-year students (n=8). The students evaluated several digital learning resources in both academic and clinical contexts. The digital learning resources included digital simulation with virtual patients, massive open online courses, and multimedia learning material. In the co-design WS, the potential and benefits of these digital learning resources for the learning and application of B-PASs were explored. Results: The students reported that the digital learning resources stimulated learning in 7 different ways. They also emphasized the importance of including all selected and tested digital learning resources. Moreover, students supported the inclusion of additional learning material, such as multiple-choice tests and written assignments, aimed at providing feedback and contributing to knowledge development. Conclusions: The co-design processes and collaboration with the nursing students provided insight into how a suite of mLearning tools may support the learning and application of B-PASs and human bioscience knowledge in clinical rotation. From the students' perspective, one of the strengths of the suite of mLearning tools was the range of content, as this met a broader range of student learning preferences regarding learning B-PASs. The suite of mLearning tools contributes to and supports skills training and knowledge transfer between multiple learning contexts. © H Ösp Egilsdottir, Lena Günterberg Heyn, Espen Andreas Brembo, Kirsten Røland Byermoen, Anne Moen, Hilde Eide","Clinical; Clinical competence; Computer simulation; Education; Education; Learning; Mobile application; Mobile phone; Nursing; Nursing; Nursing skills; Physical examination; Students","adult; education; female; human; learning; male; Norway; nursing education; nursing student; procedures; psychology; Adult; Education, Nursing; Educational Measurement; Female; Humans; Learning; Male; Norway; Students, Nursing",Article,"Final","",Scopus,2-s2.0-85099248397
"Silva R.D.O.S., Pereira A.M., Araújo D.C.S.A.D., Rocha K.S.S., Serafini M.R., de Lyra Jr D.P.","57221873948;57203542041;57194724668;56608912300;36667281100;57221867525;","Effect of Digital Serious Games Related to Patient Care in Pharmacy Education: A Systematic Review",2021,"Simulation and Gaming",,,,"","",,,"10.1177/1046878120988895","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100515582&doi=10.1177%2f1046878120988895&partnerID=40&md5=34113488d55b14f9fd99dbeddb4cea8d","Laboratory of Teaching and Research in Social Pharmacy (LEPFS), Department of Pharmacy, Federal University of Sergipe, São Cristóvão, SE, Brazil; Department of Pharmacy, Federal University of Sergipe, São Cristóvão, SE, Brazil","Silva, R.D.O.S., Laboratory of Teaching and Research in Social Pharmacy (LEPFS), Department of Pharmacy, Federal University of Sergipe, São Cristóvão, SE, Brazil; Pereira, A.M., Laboratory of Teaching and Research in Social Pharmacy (LEPFS), Department of Pharmacy, Federal University of Sergipe, São Cristóvão, SE, Brazil; Araújo, D.C.S.A.D., Laboratory of Teaching and Research in Social Pharmacy (LEPFS), Department of Pharmacy, Federal University of Sergipe, São Cristóvão, SE, Brazil; Rocha, K.S.S., Laboratory of Teaching and Research in Social Pharmacy (LEPFS), Department of Pharmacy, Federal University of Sergipe, São Cristóvão, SE, Brazil; Serafini, M.R., Department of Pharmacy, Federal University of Sergipe, São Cristóvão, SE, Brazil; de Lyra Jr, D.P., Laboratory of Teaching and Research in Social Pharmacy (LEPFS), Department of Pharmacy, Federal University of Sergipe, São Cristóvão, SE, Brazil","Background. In recent years, the use of digital serious games in the education of healthcare students and professionals has been frequent. However, there are no high-level evidence studies focused on the effect of this tool in the development of patient care-related competencies in pharmacy education. Aim. To assess the effect of digital serious games on learning about patient care in pharmacy education. Methods. The Cochrane Library, ERIC, Embase, IPA, LILACS, PubMed, Scopus, and Web of Science databases were reviewed to identify relevant studies published up to October 2, 2018. Standardized and non-standardized terms including “games,” “serious games,” “pharmacy education,” “pharmacists,” and “pharmacy students” were used as search terms. The quality of the studies was assessed using validated tools. Results and Discussion. Of the 1,521 studies reviewed, seven met the eligibility criteria. Three studies were performed in the United States (42.85%). The most-frequent design studies were randomized controlled studies (n = 3; 42.85%). The number of participants ranged between 6 and 354. In most cases, game scenarios were based on simulations in which users performed the role of the pharmacist (n = 5; 71.42%). The predominant primary outcome was attitudes (n = 5; 71.42%) related to patient care. Only one study (14.27%) demonstrated significant improvements in the assessed primary outcomes. The methodology of the included studies lacked robustness. Conclusion. The effect of learning technological tools on patient care-related competencies was not significant in most of the included studies. Future studies must provide high-quality, integrated-manner evidence on the effect of digital serious games in pharmacy education (knowledge, skills, and attitudes) to facilitate the transfer of learning to real-life scenarios and changes in organizational practices. © 2021 SAGE Publications.","active learning < simulation/gaming; education; educational games < simulation/gaming; learning < objective",,Article,"Article in Press","",Scopus,2-s2.0-85100515582
"Torres Calderon W., Roberts D., Golparvar-Fard M.","57219900490;57202510851;34868104300;","Synthesizing Pose Sequences from 3D Assets for Vision-Based Activity Analysis",2021,"Journal of Computing in Civil Engineering","35","1", 937,"","",,,"10.1061/(ASCE)CP.1943-5487.0000937","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095970460&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000937&partnerID=40&md5=7f2d77939f7e91927fbaa9ebd445ca60","Dept. of Civil and Environmental Engineering, Univ. of Illinois at Urbana-Champaign, Urbana, IL  61801, United States; Dept. of Computer Science, Univ. of Illinois at Urbana-Champaign, Urbana, IL  61801, United States; Dept. of Civil and Environmental Engineering and Computer Science, Univ. of Illinois at Urbana-Champaign, Urbana, IL  61801, United States","Torres Calderon, W., Dept. of Civil and Environmental Engineering, Univ. of Illinois at Urbana-Champaign, Urbana, IL  61801, United States; Roberts, D., Dept. of Computer Science, Univ. of Illinois at Urbana-Champaign, Urbana, IL  61801, United States; Golparvar-Fard, M., Dept. of Civil and Environmental Engineering and Computer Science, Univ. of Illinois at Urbana-Champaign, Urbana, IL  61801, United States","In recent years, computer vision algorithms have shown to effectively leverage visual data from jobsites for video-based activity analysis of construction equipment. However, earthmoving operations are restricted to site work and surrounding terrain, and the presence of other structures, particularly in urban areas, limits the number of viewpoints from which operations can be recorded. These considerations lower the degree of intra-activity and interactivity category variability to which said algorithms are exposed, hindering their potential for generalizing effectively to new jobsites. Secondly, training computer vision algorithms is also typically reliant on large quantities of hand-annotated ground truth. These annotations are burdensome to obtain and can offset the cost-effectiveness incurred from automating activity analysis. The main contribution of this paper is a means of inexpensively generating synthetic data to improve the capabilities of vision-based activity analysis methods based on virtual, kinematically articulated three-dimensional (3D) models of construction equipment. The authors introduce an automated synthetic data generation method that outputs a two-dimensional (2D) pose corresponding to simulated excavator operations that vary according to camera position with respect to the excavator and activity length and behavior. The presented method is validated by training a deep learning-based method on the synthesized 2D pose sequences and testing on pose sequences corresponding to real-world excavator operations, achieving 75% precision and 71% recall. This exceeds the 66% precision and 65% recall obtained when training and testing the deep learning-based method on the real-world data via cross-validation. Limited access to reliable amounts of real-world data incentivizes using synthetically generated data for training vision-based activity analysis algorithms. © 2020 American Society of Civil Engineers.",,"Computer vision; Cost effectiveness; Deep learning; Excavation; Excavators; Information analysis; Learning systems; Urban growth; Computer vision algorithms; Earthmoving operations; Learning-based methods; Pose corresponding; Synthetic data generations; Three-dimensional (3D) model; Training and testing; Two Dimensional (2 D); Construction equipment",Article,"Final","",Scopus,2-s2.0-85095970460
"Oersen C., Wyngaard R., Nkabinde L.","57221596259;57221596876;57221601784;","An Immersive Mobile Application for Improved Learning and Virtual Tour Experience: A Nature Reserve Perspective",2020,"2020 ITU Kaleidoscope: Industry-Driven Digital Transformation, ITU K 2020",,, 9303226,"","",,,"10.23919/ITUK50268.2020.9303226","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099583078&doi=10.23919%2fITUK50268.2020.9303226&partnerID=40&md5=17906af01ebf766c8b42fe89141e2a35","University of Western Cape, South Africa","Oersen, C., University of Western Cape, South Africa; Wyngaard, R., University of Western Cape, South Africa; Nkabinde, L., University of Western Cape, South Africa","The purpose of this study was to develop an immersive virtual reality application for the University of Western Cape's nature reserve in South Africa. For this focus on a nature reserve project, the project team was requested to build a self-guided tour capable of achieving knowledge transfer, and which has aesthetic pleasure. The study was informed by the peculiar challenge of the nature reserve and existing literature to identify gaps that may occur in the body of knowledge. The scrum project methodology was used to manage the life cycle of the project. The application was successfully built within the given time frame and the client's feedback was overwhelmingly positive. © 2020 ITU.","4IR; immersive technology; nature reserve; self-guided tour","E-learning; Knowledge management; Life cycle; Body of knowledge; Immersive virtual reality; Knowledge transfer; Mobile applications; Nature reserves; Project team; South Africa; Virtual tour; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85099583078
"López Ríos O., Lechuga López L.J., Lechuga López G.","6602320190;57219186980;57219186115;","A comprehensive statistical assessment framework to measure the impact of immersive environments on skills of higher education students: a case study",2020,"International Journal on Interactive Design and Manufacturing","14","4",,"1395","1410",,,"10.1007/s12008-020-00698-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091611562&doi=10.1007%2fs12008-020-00698-1&partnerID=40&md5=9ea2c3ee7e6c8f12ca21f48c463182f0","Instituto Tecnológico y de Estudios Superiores de Monterrey, Campus CDMX, Mexico City, CDMX, Mexico; Université de Paris, UFR Informatique, 5 Rue Thomas Mann, Paris, France","López Ríos, O., Instituto Tecnológico y de Estudios Superiores de Monterrey, Campus CDMX, Mexico City, CDMX, Mexico; Lechuga López, L.J., Université de Paris, UFR Informatique, 5 Rue Thomas Mann, Paris, France; Lechuga López, G., Instituto Tecnológico y de Estudios Superiores de Monterrey, Campus CDMX, Mexico City, CDMX, Mexico","Universities are facing the challenge of updating the contents of their current study programs and adopting novel education strategies in order to prepare the next generation of engineers who can adapt to the highly competitive labor market of Industry 4.0. This new industrial era requires skills and competencies in state-of-the-art technologies which are constantly and rapidly evolving. This research presents an alternative approach to the current teaching–learning methodologies, focusing on the use of Virtual Reality (VR) as an educational tool and its contribution towards the upcoming industrial challenges, via what we call interactive education for future engineers (IE). Our IE strategy is supported by interactive simulation using the latest VR technologies, currently being Facebook’s Oculus Rift hardware and software. With this approach, we seek to enhance the “know-how” of our students by training them in the practical skills they will need for the technological innovations of the evolving labor market. Our work has been implemented in engineering courses at Tecnologico de Monterrey in Mexico, aligning with the university’s educational model “TEC21” which aims to increase the students’ self-learning capabilities using interactive teaching and hands-on practical work to develop new abilities and competencies in an expanded variety of domains. So far, our results have shown that the use of IE not only improves the way professors teach, but reinforces skills, competencies, enhances creativity and strongly motivates the students in their daily learning. © 2020, Springer-Verlag France SAS, part of Springer Nature.","Assessment; Competencies; Higher education; Industry 4.0; Interactive education; Virtual Reality","Commerce; Computer software; Education computing; Educational technology; Employment; Industrial research; Learning systems; Technology transfer; Virtual reality; Hardware and software; Higher education students; Industrial challenges; Interactive simulations; Self-learning capability; State-of-the-art technology; Statistical assessment; Technological innovation; Students",Article,"Final","",Scopus,2-s2.0-85091611562
"Lohre R., Bois A.J., Pollock J.W., Lapner P., McIlquham K., Athwal G.S., Goel D.P.","57215864647;55259753500;23980839200;55395887100;57215196711;6603148899;34881653400;","Effectiveness of Immersive Virtual Reality on Orthopedic Surgical Skills and Knowledge Acquisition Among Senior Surgical Residents: A Randomized Clinical Trial",2020,"JAMA network open","3","12",,"e2031217","",,,"10.1001/jamanetworkopen.2020.31217","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099115911&doi=10.1001%2fjamanetworkopen.2020.31217&partnerID=40&md5=9e49c1d4861330739cfc706cc3ef6346","Department of Orthopaedics, University of British Columbia, Vancouver, BC, Canada; Section of Orthopaedic Surgery, Department of Surgery, University of Calgary, Calgary, AB, Canada; Division of Orthopaedic Surgery, Department of Surgery, University of Ottawa, Ottawa, ON, Canada; Roth McFarlane Hand and Upper Limb Center, Western University Schulich School of Medicine and Dentistry, London, ON, Canada; Canadian Shoulder Elbow Society, Canadian Orthopaedic Association, Westmount, QC, Canada","Lohre, R., Department of Orthopaedics, University of British Columbia, Vancouver, BC, Canada; Bois, A.J., Section of Orthopaedic Surgery, Department of Surgery, University of Calgary, Calgary, AB, Canada; Pollock, J.W., Division of Orthopaedic Surgery, Department of Surgery, University of Ottawa, Ottawa, ON, Canada; Lapner, P., Division of Orthopaedic Surgery, Department of Surgery, University of Ottawa, Ottawa, ON, Canada; McIlquham, K., Division of Orthopaedic Surgery, Department of Surgery, University of Ottawa, Ottawa, ON, Canada; Athwal, G.S., Roth McFarlane Hand and Upper Limb Center, Western University Schulich School of Medicine and Dentistry, London, ON, Canada, Canadian Shoulder Elbow Society, Canadian Orthopaedic Association, Westmount, QC, Canada; Goel, D.P., Department of Orthopaedics, University of British Columbia, Vancouver, BC, Canada","Importance: Video learning prior to surgery is common practice for trainees and surgeons, and immersive virtual reality (IVR) simulators are of increasing interest for surgical training. The training effectiveness of IVR compared with video training in complex skill acquisition should be studied. Objectives: To evaluate whether IVR improves learning effectiveness for surgical trainees and to validate a VR rating scale through correlation to real-world performance. Design, Setting, and Participants: This block randomized, intervention-controlled clinical trial included senior (ie, postgraduate year 4 and 5) orthopedic surgery residents from multiple institutions in Canada during a single training course. An intention-to-treat analysis was performed. Data were collected from January 30 to February 1, 2020. Intervention: An IVR training platform providing a case-based module for reverse shoulder arthroplasty (RSA) for advanced rotator cuff tear arthropathy. Participants were permitted to repeat the module indefinitely. Main Outcomes and Measures: The primary outcome measure was a validated performance metric for both the intervention and control groups (Objective Structured Assessment of Technical Skills [OSATS]). Secondary measures included transfer of training (ToT), transfer effectiveness ratio (TER), and cost-effectiveness (CER) ratios of IVR training compared with control. Additional secondary measures included IVR performance metrics measured on a novel rating scale compared with real-world performance. Results: A total of 18 senior surgical residents participated; 9 (50%) were randomized to the IVR group and 9 (50%) to the control group. Participant demographic characteristics were not different for age (mean [SD] age: IVR group, 31.1 [2.8] years; control group, 31.0 [2.7] years), gender (IVR group, 8 [89%] men; control group, 6 [67%] men), surgical experience (mean [SD] experience with RSA: IVR group, 3.3 [0.9]; control group, 3.2 [0.4]), or prior simulator use (had experience: IVR group 6 [67%]; control group, 4 [44%]). The IVR group completed training 387% faster considering a single repetition (mean [SD] time for IVR group: 4.1 [2.5] minutes; mean [SD] time for control group: 16.1 [2.6] minutes; difference, 12.0 minutes; 95% CI, 8.8-14.0 minutes; P < .001). The IVR group had significantly better mean (SD) OSATS scores than the control group (15.9 [2.5] vs 9.4 [3.2]; difference, 6.9; 95% CI, 3.3-9.7; P < .001). The IVR group also demonstrated higher mean (SD) verbal questioning scores (4.1 [1.0] vs 2.2 [1.7]; difference, 1.9; 95% CI, 0.1-3.3; P = .03). The IVR score (ie, Precision Score) had a strong correlation to real-world OSATS scores (r = 0.74) and final implant position (r = 0.73). The ToT was 59.4%, based on the OSATS score. The TER was 0.79, and the system was 34 times more cost-effective than control, based on CER. Conclusions and Relevance: In this study, surgical training with IVR demonstrated superior learning efficiency, knowledge, and skill transfer. The TER of 0.79 substituted for 47.4 minutes of operating room time when IVR was used for 60 minutes. Trial Registration: ClinicalTrials.gov Identifier: NCT04404010.",,"adult; Canada; clinical competence; controlled study; education; female; human; male; medical education; orthopedic surgeon; orthopedic surgery; procedures; randomized controlled trial; simulation training; virtual reality; Adult; Canada; Clinical Competence; Female; Humans; Internship and Residency; Male; Orthopedic Procedures; Orthopedic Surgeons; Simulation Training; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85099115911
"Nykänen M., Puro V., Tiikkaja M., Kannisto H., Lantto E., Simpura F., Uusitalo J., Lukander K., Räsänen T., Heikkilä T., Teperi A.-M.","57204180566;57193531916;51864912400;57210474667;57210417159;57210464151;57210465141;34976891300;7004111153;57219873265;36239398300;","Implementing and evaluating novel safety training methods for construction sector workers: Results of a randomized controlled trial",2020,"Journal of Safety Research","75",,,"205","221",,,"10.1016/j.jsr.2020.09.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095819636&doi=10.1016%2fj.jsr.2020.09.015&partnerID=40&md5=0f5de273bf90f1503b0331cdfff7f1e1","Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland","Nykänen, M., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Puro, V., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Tiikkaja, M., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Kannisto, H., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Lantto, E., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Simpura, F., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Uusitalo, J., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Lukander, K., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Räsänen, T., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Heikkilä, T., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Teperi, A.-M., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland","Introduction: The construction industry is regarded as one of the most unsafe occupational fields worldwide. Despite general agreement that safety training is an important factor in preventing accidents in the construction sector, more studies are needed to identify effective training methods. To address the current research gap, this study evaluated the impact of novel, participatory safety training methods on construction workers’ safety competencies. Specifically, we assessed the efficacy of an immersive virtual reality (VR)-based safety training program and a participatory human factors safety training program (HFST) in construction industry workplaces. Method: In 2019, 119 construction sector workers from eight workplaces participated in a randomized controlled trial conducted in Finland. All the study participants were assessed using questionnaires at baseline, immediately after the intervention and at one-month follow-up. We applied generalized linear mixed modeling for statistical analysis. Results: Compared to lecture-based safety training, VR-based safety training showed a stronger impact on safety motivation, self-efficacy and safety-related outcome expectancies. In addition, the construction sector workers who participated in the VR-based safety training showed a greater increase in self-reported safety performance at one-month follow-up. Contrary to our study hypotheses, we found no significant differences between the study outcomes in terms of study participants in the HFST training condition and the comparison condition without HFST training. Conclusion: Our study indicates that VR technology as a safety training tool has potential to increase safety competencies and foster motivational change in terms of the safety performance of construction sector workers. In the future, the efficacy of participatory human factors safety training should be studied further using a version that targets both managerial and employee levels and is implemented in a longer format. Practical implications: Safety training in virtual reality provides a promising alternative to passive learning methods. Its motivating effect complements other safety training activities. © 2020","Human factors safety training; Safety locus of control; Safety motivation; Safety self-efficacy; Virtual reality","Accident prevention; Construction industry; Curricula; Human engineering; Learning systems; Motivation; Occupational risks; Safety factor; Surveys; Virtual reality; Construction sectors; Construction workers; Generalized linear mixed models; Immersive virtual reality; Randomized controlled trial; Safety performance; Safety training program; Training conditions; Personnel training; adult; article; building industry; comparative effectiveness; construction worker; controlled study; drug safety; employee; expectancy; female; Finland; follow up; human; human experiment; learning; locus of control; male; motivation; outcome assessment; questionnaire; randomized controlled trial; self concept; training; virtual reality; workplace",Article,"Final","",Scopus,2-s2.0-85095819636
"Rauscher M., Humpe A., Brehm L.","57212102453;57191606409;57125859600;","Virtual reality in tourism: Is it 'Real' enough?",2020,"Academica Turistica","13","2",,"127","138",,,"10.26493/2335-4194.13.127-138","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099795988&doi=10.26493%2f2335-4194.13.127-138&partnerID=40&md5=f6a3055e8dfcd660b228e8aa2e759ef2","Munich University of Applied Sciences, Germany","Rauscher, M., Munich University of Applied Sciences, Germany; Humpe, A., Munich University of Applied Sciences, Germany; Brehm, L., Munich University of Applied Sciences, Germany","Virtual Reality Technology is increasingly becoming popular in the tourism sector. So far, the most researched application is the marketing of destinations. In contrast, the technology has also been mentioned as a means to limit or reduce the number of tourists at a specific sight or destination. In this respect vr is considered as a substitute for the actual trip. This paper addresses this issue by looking at the possibility to apply vr-technology to transfer the real-life experience into the digital world. In a qualitative research framework, visitor behaviour and experience are investigated when encountering vr sights in order to better understand items driving technology adoption. Structured content analysis is applied for data analysis where coding follows an adjusted Unified Theory of Acceptance and Use of Technology model. For interpretation purposes a pure qualitative framework was chosen. We find that enjoyment is an important driver for vr technology acceptance, whereas facilitating conditions and outcome expectations seem to be obstacles for it. Perceived usefulness is evaluated controversially. While the technology is not acknowledged as a substitute for a regular holiday trip, especially for travellers who take pleasure in active holidays or appreciate social interaction, it was recognised as an alternative for special occasions such as brief getaways from everyday life or short city trips. Overall, when appropriately implemented the technology might not only be useful to decrease visitor concentration in touristic hotspots or to decrease negative aspects associated with frequent travel but could further be applied to sites where visitors do not engage physically because sites are too distant, expensive, inhospitable, unsafe or fragile. © 2020 University of Primorska. All rights reserved.","Technology adoption; Tourism; Travel substitute; Utaut; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85099795988
"Brickler D., Teather R.J., Duchowski A.T., Babu S.V.","57063224300;24588246800;6701824388;9039004700;","A fitts’ law evaluation of visuo-haptic fidelity and sensory mismatch on user performance in a near-field disc transfer task in virtual reality",2020,"ACM Transactions on Applied Perception","17","4", 15,"","",,,"10.1145/3419986","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098327645&doi=10.1145%2f3419986&partnerID=40&md5=405cfd1df7d08411fef108bce167fcb8","Clemson University, School of Computing, 100 McAdams Hall, Clemson, SC  29634, United States; Carleton University, School of Information Technology, 230 Azrieli Pavilion, 1125 Colonel By Drive, Ottawa, ON  K1S 5B6, Canada","Brickler, D., Clemson University, School of Computing, 100 McAdams Hall, Clemson, SC  29634, United States; Teather, R.J., Carleton University, School of Information Technology, 230 Azrieli Pavilion, 1125 Colonel By Drive, Ottawa, ON  K1S 5B6, Canada; Duchowski, A.T., Clemson University, School of Computing, 100 McAdams Hall, Clemson, SC  29634, United States; Babu, S.V., Clemson University, School of Computing, 100 McAdams Hall, Clemson, SC  29634, United States","The trade-off between speed and accuracy in precision tasks is important to evaluate during user interaction with input devices. When different sensory cues are added or altered in such interactions, those cues have an effect on this trade-off, and thus, they affect overall user performance. For instance, adding cues like haptic feedback and stereoscopic viewing will result in more realistic user interaction, thus improving performance in these tasks. Also, adding a noticeable disparity between physical and virtual movements creates a mismatch between visual and proprioceptive systems, which generally has a negative effect on performance. In this study, we investigate the effects of haptic feedback, stereoscopic viewing, and visuo-proprioceptive mismatch on how quickly and accurately users complete a virtual pick-and-place task using the PHANToM OMNI. Through this experiment, we find that in the movement phase of a ring transfer, movement time and user performance are affected by haptic feedback and visuo-proprioceptive mismatch, and the main effects of stereoscopic viewing appears to be limited to the more precise step when the ring is around the target peg. © 2020 Association for Computing Machinery.","Fitts’ law; Haptics; Near-field virtual reality; Stereo","Economic and social effects; Stereo image processing; Haptic feedbacks; Improving performance; Law evaluation; Movement time; Pick and place; Stereoscopic viewing; User interaction; User performance; Virtual reality",Article,"Final","",Scopus,2-s2.0-85098327645
"Kruthik H.M., Prabhu G.K., Mukund S., Meena P., Nagar S.V.","57222258361;57222260776;57222254177;56469220800;57210112222;","Content Development for study of Mechanical and Electrical behavioural aspects of Three Phase Induction Machine on a 3D platform",2020,"IEEE Region 10 Humanitarian Technology Conference, R10-HTC","2020-December",, 9357009,"","",,,"10.1109/R10-HTC49770.2020.9357009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102081593&doi=10.1109%2fR10-HTC49770.2020.9357009&partnerID=40&md5=b71f609aa3a79142d520b93d4b28a648","Mechanical Engineering, B.M.S. College of Engineering, Bengaluru, India; Electrical and Electronics Engineering, B.M.S. College of Engineering, Bengaluru, India","Kruthik, H.M., Mechanical Engineering, B.M.S. College of Engineering, Bengaluru, India; Prabhu, G.K., Electrical and Electronics Engineering, B.M.S. College of Engineering, Bengaluru, India; Mukund, S., Mechanical Engineering, B.M.S. College of Engineering, Bengaluru, India; Meena, P., Electrical and Electronics Engineering, B.M.S. College of Engineering, Bengaluru, India; Nagar, S.V., Mechanical Engineering, B.M.S. College of Engineering, Bengaluru, India","In the current scenario of transformations in Engineering Education that involves the seamless integration of engineering disciplines, a cohesive approach of learning the mechanical and electrical aspects provides a holistic insight into the behavior of machines. This provides an immersive experience to the learner bridging the gap that hitherto exists in the understanding of abstract concepts. This paper presents the attempt in creating a 3-Dimensional environment with a machine and its various parts for viewing and manipulation of certain parameters for the learner. The focus is on enhancing the user experience for a 3-phase squirrel cage induction motor. Physical modeling, systems engineering, thermal simulations, and detailed physical review for the machine were made using 3DEXPERIENCE software. The motor prototype with fine details is developed by Computer-Aided Drafting. The industry-based V model is used to perform systems engineering. Kinematics is modeled giving an interactive simulation to obtain the electrical characteristics. Heat transfer in the motor is also visualized considering the losses generated in different parts of the machine. The results are encouraging and seem to provide a self-learning platform for the learner to try out. This work has far-reaching effects of extension into a component level understanding and application of behavior modeling to various systems leading to an effective virtual lab setup for the learner community. © 2020 IEEE.","Engineering Education; Immersive Learning; Systems Engineering; Thermal Simulation","Asynchronous machinery; Engineering education; Heat transfer; Squirrel cage motors; Systems engineering; Thermal Engineering; Turing machines; User experience; Computer aided drafting; Electrical characteristic; Engineering disciplines; Interactive simulations; Mechanical and electrical; Seamless integration; Squirrel cage induction motor; Three-phase induction machine; Learning systems",Conference Paper,"Final","",Scopus,2-s2.0-85102081593
"Hung S.C.-W., Ho A.Y.-N., Lai I.H.-W., Lee C.S.-W., Pong A.S.-K., Lai F.H.-Y.","57221111354;57221089186;57221107135;57221082203;57221100232;7202559750;","Meta-analysis on the effectiveness of virtual reality cognitive training (Vrct) and computer-based cognitive training (CBCT) for individuals with mild cognitive impairment (MCI)",2020,"Electronics (Switzerland)","9","12", 2185,"1","21",,,"10.3390/electronics9122185","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098193324&doi=10.3390%2felectronics9122185&partnerID=40&md5=1d7fc323c9ec04670313ebe5df17497b","Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hung Hom, Hong Kong","Hung, S.C.-W., Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hung Hom, Hong Kong; Ho, A.Y.-N., Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hung Hom, Hong Kong; Lai, I.H.-W., Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hung Hom, Hong Kong; Lee, C.S.-W., Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hung Hom, Hong Kong; Pong, A.S.-K., Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hung Hom, Hong Kong; Lai, F.H.-Y., Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hung Hom, Hong Kong","This meta-analysis aims to assess the effectiveness of virtual reality cognitive training (VRCT) and conventional computer-based cognitive training (CBCT) in five specific cognitive domains (i.e., global cognitive function (GCF), memory (Mem), executive function (EF), language (Lang) and visuospatial skills (VS)) of individuals with mild cognitive impairment. A total of 320 studies were yielded from five electronic databases. Eighteen randomized controlled trials met the PRISMA criteria, with 10 related to VRCT and 8 related to CBCT. A random-effect model was used in determining the main effect of cognitive training in five specific cognitive domains. VRCT provided the largest effect size on VS and Lang while the smallest on EF. CBCT provided the largest effect size on Mem and Lang while the smallest on EF. VRCT and CBCT generate an opposite effect on VS. VRCT outweighs CBCT in treatment effectiveness of GCF, EF, Lang and VS. More immersive and interactive experiences in VRCT may help individuals with MCI better engage in real-life experiences, which supports skill generalization and reduces external distractions. CBCT tends to improve Mem but no definite conclusions can be made. Further investigation with more stringent research design and specific protocol are required to reach consensus about the optimum intervention regime. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Cognitive training; Computer; Meta-analysis; Mild cognitive impairment; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85098193324
"Knierim P., Kiss F., Rauh M., Schmidt A.","55536806700;57194275301;57220211863;57204719065;","Tangibility is Overrated: Comparing Learning Experiences of Physical Setups and their Virtual Equivalent in Augmented Reality",2020,"ACM International Conference Proceeding Series",,,,"299","305",,1,"10.1145/3428361.3428379","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097281134&doi=10.1145%2f3428361.3428379&partnerID=40&md5=f2a3600f9efb5b510bc9846efe9c88ee","Lmu Munich, Germany; University of Stuttgart, Germany","Knierim, P., Lmu Munich, Germany; Kiss, F., University of Stuttgart, Germany; Rauh, M., Lmu Munich, Germany; Schmidt, A., Lmu Munich, Germany","Augmented Reality (AR) is gaining increasing importance in science, education, and entertainment. A fundamental characteristic of AR is blending the virtual and physical world into a coherent environment. In this paper, we examine the effect of substituting the physical components of lab experiments with tangible replicas and virtual representations. We conducted a user study with thirty participants who carried out the experiment in three different abstraction levels (original lab equipment, non-functional tangible props, virtual representation). We compared the users' performance regarding setup time, experienced workload, quality of measurements, and concept comprehension of the learning task. We found no effect on comprehension but significant differences in setup time and quality of measures. The results indicate that substitution reduces the experiment setup duration without affecting knowledge transfer. These results help to shape future AR learning environments, and we offer insights for creating complex mixed reality learning materials. © 2020 ACM.","Amplified Perception; Augmented Reality; Learning; Mixed Reality; Physical Substitution; Physics Lab Experiment; Thermal Vision","Augmented reality; Blending; Computer aided instruction; E-learning; Knowledge management; Abstraction level; Experiment set-up; Fundamental characteristics; Knowledge transfer; Learning environments; Learning experiences; Physical components; Virtual representations; Mixed reality",Conference Paper,"Final","",Scopus,2-s2.0-85097281134
"Saghafian M., Laumann K., Akhtar R.S., Skogstad M.R.","57220037198;6602490074;57220035991;57215534124;","The Evaluation of Virtual Reality Fire Extinguisher Training",2020,"Frontiers in Psychology","11",, 593466,"","",,,"10.3389/fpsyg.2020.593466","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096573932&doi=10.3389%2ffpsyg.2020.593466&partnerID=40&md5=fca9427d1ab4d858a5e268f33309576e","Department of Psychology, Faculty of Social and Educational Sciences, Norwegian University of Science and Technology, Trondheim, Norway","Saghafian, M., Department of Psychology, Faculty of Social and Educational Sciences, Norwegian University of Science and Technology, Trondheim, Norway; Laumann, K., Department of Psychology, Faculty of Social and Educational Sciences, Norwegian University of Science and Technology, Trondheim, Norway; Akhtar, R.S., Department of Psychology, Faculty of Social and Educational Sciences, Norwegian University of Science and Technology, Trondheim, Norway; Skogstad, M.R., Department of Psychology, Faculty of Social and Educational Sciences, Norwegian University of Science and Technology, Trondheim, Norway","The aim of this research was to explore trainees’ perceptions and evaluation of Virtual Reality fire extinguisher training. Virtual Reality technology is being adopted by many industries for various purposes including safety training for safety critical industries. The future direction of Virtual Reality training requires an understanding of trainees’ evaluation of it; this fact motivated this research. Data were collected from 85 participants using a questionnaire after the training. Observation notes were taken to provide a better understanding of the context. Qualitative research with a thematic analysis was used to analyze the data. The results of this analysis revealed that the most salient themes reflect on issues surrounding the realism of the Virtual Reality simulation, namely different emotional and bodily experiences during the training, while the benefits of the training (health, safety, environmental advantages, efficiency and convenience, repeatability and variety of scenarios) make it a good supplement. Nevertheless, improved realism is needed to make it more effective and enhance transfer and acceptance. This study encourages the consideration of important matters (such as realism and emotions) when using Virtual Reality for fire training. It also describes the positive perceptions of this type of training (repeatability of training, safety and environmental concerns). © Copyright © 2020 Saghafian, Laumann, Akhtar and Skogstad.","convenience; fire extinguisher training; realism; safety; virtual reality",,Article,"Final","",Scopus,2-s2.0-85096573932
"Ticala R., Ciupe A., Meza S., Orza B.","57221596383;57105700600;24829838400;24503681900;","Augmenting Learning through VR Storytelling",2020,"2020 14th International Symposium on Electronics and Telecommunications, ISETC 2020 - Conference Proceedings",,, 9301040,"","",,,"10.1109/ISETC50328.2020.9301040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099607360&doi=10.1109%2fISETC50328.2020.9301040&partnerID=40&md5=3d616e9bbba1803ae2f7470ab54f8174","Technical University of Cluj-Napoca, Multimedia Systems and Applications Laboratory, Cluj-Napoca, Romania","Ticala, R., Technical University of Cluj-Napoca, Multimedia Systems and Applications Laboratory, Cluj-Napoca, Romania; Ciupe, A., Technical University of Cluj-Napoca, Multimedia Systems and Applications Laboratory, Cluj-Napoca, Romania; Meza, S., Technical University of Cluj-Napoca, Multimedia Systems and Applications Laboratory, Cluj-Napoca, Romania; Orza, B., Technical University of Cluj-Napoca, Multimedia Systems and Applications Laboratory, Cluj-Napoca, Romania","This paper presents a narrative instructional model as an interaction framework in a Virtual Reality environment. Virtual Reality solutions provide the means to present a storytelling scenario through visual interactive models. The proposed implementation consists of a VR prototype developed to assist kindergarten and primary school pupils, in assimilating knowledge about different types of musical instruments, while developing a sense of practice-based interaction. The application is structured on three levels; each level is represented by an element of nature (water, earth and air), corresponding to the know-how complexity: water or level 0 which reflects an elementary level of intrinsic knowledge; towards the air environment that reflects the level of cumulative knowledge that will be reached by the end of the game. Knowledge is assimilated by interacting with elements in the virtual environment and by following the annotated guidelines. © 2020 IEEE.","animated characters; musical instruments; primary and kindergarten education; progressive knowledge; storytelling; virtual reality","Technology transfer; Air environment; Elementary levels; Instructional model; Interaction framework; Interactive models; Primary schools; Virtual-reality environment; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85099607360
"Sykownik P., Emmerich K., Masuch M.","57201134642;55376829000;6603274877;","Like in the good old times, but virtual - A case for simulating co-located multiplayer games in VR",2020,"CHI PLAY 2020 - Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play",,,,"379","383",,,"10.1145/3383668.3419885","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096774619&doi=10.1145%2f3383668.3419885&partnerID=40&md5=c45fe5c4daa7b0f98c34fdf17c296cc9","University Duisburg-Essen, Duisburg, Germany","Sykownik, P., University Duisburg-Essen, Duisburg, Germany; Emmerich, K., University Duisburg-Essen, Duisburg, Germany; Masuch, M., University Duisburg-Essen, Duisburg, Germany","In this paper, we present ongoing work on simulating the social setting of co-located multiplayer games in virtual reality (VR), to transfer the rich sociability associated with physical co-location to online gaming. We developed a VR application that allows two physically remote users to play games together on a virtual couch. Based on our initial experience in two small user tests, we assume that the VR version induces a social experience similar to the co-located gameplay. We will test this assumption in subsequent user studies. We also outline the theoretical and methodological relevance of VR-simulated couch-coop multiplayer games for researchers and practitioners. © 2020 ACM.","Co-located gaming; Multiplayer games; Online gaming; Social presence; Virtual reality","Interactive computer systems; User experience; Co-located; Colocations; Multiplayer games; On-line gaming; Remote users; Social settings; User study; VR applications; Human computer interaction",Conference Paper,"Final","",Scopus,2-s2.0-85096774619
"Doolani S., Owens L., Wessels C., Makedon F.","57219947037;57209983843;57219945746;57207521629;","Vis: An immersive virtual storytelling system for vocational training",2020,"Applied Sciences (Switzerland)","10","22", 8143,"1","15",,,"10.3390/app10228143","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096219073&doi=10.3390%2fapp10228143&partnerID=40&md5=49a6239c0b68d52f1173532bcf8a09c5","Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX  76019, United States","Doolani, S., Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX  76019, United States; Owens, L., Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX  76019, United States; Wessels, C., Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX  76019, United States; Makedon, F., Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX  76019, United States","Storytelling has been established as a proven method to effectively communicate and assist in knowledge transfer. In recent years, there has been growing interest in improving the training and learning domain by using advanced technology such as Virtual Reality (VR). However, a gap exists between storytelling and VR, and it is as yet unclear how they can be combined to form an effective system that not only maintains the level of engagement and immersion provided by VR technology but also provides the core strengths of storytelling. In this paper, we present vIS, a Vocational Immersive Storytelling system, which bridges the gap between storytelling and VR. vIS focuses on vocational training, in which users are trained on how to use a mechanical micrometer by employing a creative fictional story embedded inside a virtual manufacturing plant’s workplace. For the evaluation, a two-phase user study with 30 participants was conducted to measure the system’s effectiveness and improvements in long-term training, as well as to examine user experience against traditional methods of training—2D videos and textual manuals. The results indicate that the user’s ability to retain their training after seven days was nearly equal for vIS and the 2D video-based technique and was considerably higher than the text-based technique. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Storytelling; Usability testing; Virtual reality; Vocational training",,Article,"Final","",Scopus,2-s2.0-85096219073
"Monteiro D., Liang H.-N., Wang J., Chen H., Baghaei N.","57144011000;8636386200;57207048907;57221155309;14020983900;","An In-Depth Exploration of the Effect of 2D/3D Views and Controller Types on First Person Shooter Games in Virtual Reality",2020,"Proceedings - 2020 IEEE International Symposium on Mixed and Augmented Reality, ISMAR 2020",,, 9284718,"713","724",,,"10.1109/ISMAR50242.2020.00102","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099294395&doi=10.1109%2fISMAR50242.2020.00102&partnerID=40&md5=9a9ee4dfccc97f04f5650a4b63a6eea1","Xi'an Jiaotong-Liverpool University, China; Massey University, New Zealand","Monteiro, D., Xi'an Jiaotong-Liverpool University, China; Liang, H.-N., Xi'an Jiaotong-Liverpool University, China; Wang, J., Xi'an Jiaotong-Liverpool University, China; Chen, H., Xi'an Jiaotong-Liverpool University, China; Baghaei, N., Massey University, New Zealand","The amount of interest in Virtual Reality (VR) research has significantly increased over the past few years, both in academia and industry. The release of commercial VR Head-Mounted Displays (HMDs) has been a major contributing factor. However, there is still much to be learned, especially how views and input techniques, as well as their interaction, affect the VR experience. There is little work done on First-Person Shooter (FPS) games in VR, and those few studies have focused on a single aspect of VR FPS. They either focused on the view, e.g., comparing VR to a typical 2D display or on the controller types. To the best of our knowledge, there are no studies investigating variations of 2D/3D views in HMDs, controller types, and their interactions. As such, it is challenging to distinguish findings related to the controller type from those related to the view. If a study does not control for the input method and finds that 2D displays lead to higher performance than VR, we cannot generalize the results because of the confounding variables. To understand their interaction, we propose to analyze in more depth, whether it is the view (2D vs. 3D) or the way it is controlled that gives the platforms their respective advantages. To study the effects of the 2D/3D views, we created a 2D visual technique, PlaneFrame, that was applied inside the VR headset. Our results show that the controller type can have a significant positive impact on performance, immersion, and simulator sickness when associated with a 2D view. They further our understanding of the interactions that controllers and views have and demonstrate that comparisons are highly dependent on how both factors go together. Further, through a series of three experiments, we developed a technique that can lead to a substantial performance, a good level of immersion, and can minimize the level of simulator sickness. © 2020 IEEE.","2D/3D Views; Controller types; First Person Shooter; Gaming; Head-Mounted Displays; Virtual Reality","Augmented reality; Controllers; Diseases; Helmet mounted displays; Contributing factor; First person shooter games; Head mounted displays; Input methods; Input techniques; Simulator sickness; Visual techniques; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85099294395
"Barsom E.Z., Duijm R.D., Dusseljee-Peute L.W.P., Landman-van der Boom E.B., van Lieshout E.J., Jaspers M.W., Schijven M.P.","57140782000;57209450976;57206834659;57218800815;57218802771;7005754901;6602492995;","Cardiopulmonary resuscitation training for high school students using an immersive 360-degree virtual reality environment",2020,"British Journal of Educational Technology","51","6",,"2050","2062",,1,"10.1111/bjet.13025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090308641&doi=10.1111%2fbjet.13025&partnerID=40&md5=f346cbaaca0fa9416060f7e3d520cd22","Public Health research institute, Department of Medical Informatics of the Amsterdam UMC, Netherlands; Amsterdam UMC, Netherlands","Barsom, E.Z.; Duijm, R.D.; Dusseljee-Peute, L.W.P., Public Health research institute, Department of Medical Informatics of the Amsterdam UMC, Netherlands; Landman-van der Boom, E.B.; van Lieshout, E.J.; Jaspers, M.W., Amsterdam UMC, Netherlands; Schijven, M.P., Amsterdam UMC, Netherlands","Cardiopulmonary resuscitation (CPR) is a lifesaving emergency procedure. To increase survival rates, it is recommended to increase the number of high school students who know how to perform CPR. We have developed an immersive “Virtual Reality (VR) Resuscitation Training” to train the theoretical knowledge of CPR in which trainees must save the life of the patient in a virtual environment. This paper presents a randomized controlled study with a pre-posttest design to explore whether a VR enhanced curriculum improves high school students’ theoretical CPR knowledge. Forty students without previous CPR experience in the past year were randomly assigned to either the VR group or the standard group. The VR group had a significant higher increase of correct answers in comparison with the Standard group. More importantly, the gain in score on taking the correct sequence of CPR steps was significant favouring the VR-enhanced protocol over the Standard protocol. Therefore, the use of a VR training for CPR training appears to be an effective learning method for non-medical students and may be of great value skilling high school students in becoming adequate CPR providers. © 2020 British Educational Research Association","Cardiopulmonary resuscitation; immersive environment; medical education; virtual reality","E-learning; Learning systems; Resuscitation; Students; Technology transfer; Cardiopulmonary resuscitation; Effective learning; Emergency procedures; High school students; Medical students; Standard groups; Standard protocols; Virtual-reality environment; Virtual reality",Article,"Final","",Scopus,2-s2.0-85090308641
"Klingenberg S., Jørgensen M.L.M., Dandanell G., Skriver K., Mottelson A., Makransky G.","57214077924;56015706700;6603030047;6701521625;57191531178;50361371800;","Investigating the effect of teaching as a generative learning strategy when learning through desktop and immersive VR: A media and methods experiment",2020,"British Journal of Educational Technology","51","6",,"2115","2138",,3,"10.1111/bjet.13029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091609462&doi=10.1111%2fbjet.13029&partnerID=40&md5=c050635d4c8cd7c89671a2651c5559af","Virtual Learning Lab at the Department of Psychology at the University of Copenhagen, United States; Department of Biology at the University of Copenhagen, United States; Department of Psychology at the University of Copenhagen, United States","Klingenberg, S., Virtual Learning Lab at the Department of Psychology at the University of Copenhagen, United States; Jørgensen, M.L.M., Department of Biology at the University of Copenhagen, United States; Dandanell, G., Department of Biology at the University of Copenhagen, United States; Skriver, K., Department of Biology at the University of Copenhagen, United States; Mottelson, A., Virtual Learning Lab at the Department of Psychology at the University of Copenhagen, United States; Makransky, G., Department of Psychology at the University of Copenhagen, United States","Immersive virtual reality (IVR) simulations for education have been found to increase affective outcomes compared to traditional media, but the effects on learning are mixed. As reflection has previously shown to enhance learning in traditional media, we investigated the efficacy of appropriate reflection exercises for IVR. In a 2 × 2 mixed-methods experiment, 89 (61 female) undergraduate biochemistry students learned about the electron transport chain through desktop virtual reality (DVR) and IVR (media conditions). Approximately, half of each group engaged in a subsequent generative learning strategy (GLS) of teaching in pairs (method conditions). A significant interaction between media and methods illustrated that the GLS of teaching significantly improved transfer (d = 1.26), retention (d = 0.60) and self-efficacy (d = 0.82) when learning through IVR, but not DVR. In the second part of the study, students switched media conditions and the experiment was repeated. This time, significant main effects favoring the IVR group on the outcomes of intrinsic motivation (d = 0.16), perceived enjoyment (d = 0.94) and presence (d = 1.29) were observed, indicating that students preferred IVR after having experienced both media conditions. The results support the view that methods enable media that affect learning and that the GLS of teaching is specifically relevant for IVR. © 2020 British Educational Research Association","biochemistry education; generative learning strategies; head-mounted displays; immersive virtual reality; learning; media versus methods","Electron transport properties; Students; Virtual reality; Desktop virtual reality; Electron transport chain; Enhance learning; Immersive virtual reality; Intrinsic motivation; Learning strategy; Perceived enjoyment; Self efficacy; Learning systems",Article,"Final","",Scopus,2-s2.0-85091609462
"Englmeier D., Fan F., Butz A.","57194090648;57221494100;55150450600;","Rock or Roll - Locomotion Techniques with a Handheld Spherical Device in Virtual Reality",2020,"Proceedings - 2020 IEEE International Symposium on Mixed and Augmented Reality, ISMAR 2020",,, 9284676,"618","626",,1,"10.1109/ISMAR50242.2020.00089","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099291639&doi=10.1109%2fISMAR50242.2020.00089&partnerID=40&md5=2f5568c3878ae3680a3168bbb39af3dc","Lmu Munich, Munich, Germany","Englmeier, D., Lmu Munich, Munich, Germany; Fan, F., Lmu Munich, Munich, Germany; Butz, A., Lmu Munich, Munich, Germany","We investigate the use of a handheld spherical object as a controller for locomotion in VR. Rotating the object controls avatar movement in two different ways: As a zero order controller, it is continuously rotated to the target position as if rolling a ball on the floor. As a first order controller, it is tilted like a joystick to determine the direction and speed of movement. We describe how our prototype was built from low-cost commercially available hardware and discuss our design decisions. Then we evaluate both locomotion techniques in a user study (N=20) and compare them to established methods using handheld VR controllers. Our prototype matched and in some cases outperformed these methods regarding task time and accuracy. All results were obtained without any usage instructions, indicating easy learnability. Some of our insights may transfer to interaction with other naturally shaped objects in VR experiences. © 2020 IEEE.","Haptic devices; Human computer interaction (HCI); Human computer interaction (HCI); Human-centered computing; Human-centered computing; Interaction devices; Interaction paradigms; Virtual reality","Augmented reality; Costs; Virtual reality; Design decisions; First-order controller; Learnability; Locomotion technique; Spherical objects; Target position; User study; Zero order; Controllers",Conference Paper,"Final","",Scopus,2-s2.0-85099291639
"Souza V., Maciel A., Nedel L., Kopper R., Loges K., Schlemmer E.","57210972319;24329619800;8702986800;15022552000;57221603592;26424749700;","The Effect of Virtual Reality on Knowledge Transfer and Retention in Collaborative Group-Based Learning for Neuroanatomy Students",2020,"Proceedings - 2020 22nd Symposium on Virtual and Augmented Reality, SVR 2020",,, 9262701,"92","101",,,"10.1109/SVR51698.2020.00028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099538628&doi=10.1109%2fSVR51698.2020.00028&partnerID=40&md5=999be8e2249e7c159986b5ddaf469af4","Institute of Informatics (INF), Federal University of Rio Grande Do sul (UFRGS), Porto Alegre, Brazil; University of North Carolina at Greensboro (UNCG), Department of Computer Science, Greensboro, United States; University of Vale Do Rio Dos Sinos (UNISINOS), São Leopoldo, Brazil","Souza, V., Institute of Informatics (INF), Federal University of Rio Grande Do sul (UFRGS), Porto Alegre, Brazil; Maciel, A., Institute of Informatics (INF), Federal University of Rio Grande Do sul (UFRGS), Porto Alegre, Brazil; Nedel, L., Institute of Informatics (INF), Federal University of Rio Grande Do sul (UFRGS), Porto Alegre, Brazil; Kopper, R., University of North Carolina at Greensboro (UNCG), Department of Computer Science, Greensboro, United States; Loges, K., University of Vale Do Rio Dos Sinos (UNISINOS), São Leopoldo, Brazil; Schlemmer, E., University of Vale Do Rio Dos Sinos (UNISINOS), São Leopoldo, Brazil","There are many uses for virtual reality (VR) in education, and there is a consensus about its contribution in the teaching and learning processes. However, the majority of the studies assess the effectiveness of an individual learning in VR, and there is a need to explore more on the effects of VR using different levels of immersion and collaboration. This paper presents an experiment to investigate knowledge transfer in a group-based learning game. We introduce a VR serious game to support teaching and learning processes in neuroanatomy health education. A between-subjects experiment was conducted with 23 students to jointly assess learning, knowledge retention, and sense of presence. As a control condition, grouped students assembled a physical model of the human brain, while in the experimental condition, a virtual brain was assembled. In each group, one participant assembled the brain, while the others observed and verbally collaborated in a group-based learning strategy. Results shown high mean scores in the virtual condition. When comparing the knowledge test performance before and immediately after the experiment, we found significant difference only for the virtual condition. The same can be observed for retention. Because of the promising results achieved and motivated by the need of more engaging new tools for remote learning - fully used in quarantine conditions, such as the current one because of the Covid-19 pandemic - we conducted a pilot user study to evaluate the learning effect of a remote version of our collaborative VR game. © 2020 IEEE.","Presence; User Evaluation; Virtual Reality","Augmented reality; E-learning; Education computing; Knowledge management; Serious games; Teaching; Virtual reality; Collaborative groups; Experimental conditions; Individual learning; Knowledge retention; Knowledge transfer; Learning strategy; Sense of presences; Teaching and learning; Students",Conference Paper,"Final","",Scopus,2-s2.0-85099538628
"Martin N., Mathieu N., Pallamin N., Ragot M., Diverrez J.-M.","57188745225;57221495248;13405769400;57073515600;56928312300;","Virtual reality sickness detection: An approach based on physiological signals and machine learning",2020,"Proceedings - 2020 IEEE International Symposium on Mixed and Augmented Reality, ISMAR 2020",,, 9284654,"387","399",,,"10.1109/ISMAR50242.2020.00065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099321186&doi=10.1109%2fISMAR50242.2020.00065&partnerID=40&md5=eef96cc31598451773f458ec1c3fa5c9","Irt B<com, Cesson-Sevigne, France; Ubisoft, Montreuil, France","Martin, N., Irt B<com, Cesson-Sevigne, France; Mathieu, N., Ubisoft, Montreuil, France; Pallamin, N., Irt B<com, Cesson-Sevigne, France; Ragot, M., Irt B<com, Cesson-Sevigne, France; Diverrez, J.-M., Irt B<com, Cesson-Sevigne, France","Virtual Reality (VR) is spreading to the general public but still has a major issue: VR sickness. To take it into consideration and minimize its occurrence, evaluation methods are required. The current methods are mainly based on subjective measurements and therefore have several drawbacks (e.g., non-continuous, intrusive). Physiological signals combined with Machine Learning (ML) methods seem an interesting approach to go beyond these limits. In this paper, we present a large-scale experimentation (103 participants) where physiological data (cardiac and electrodermal activities) and subjective data (perceived VR sickness) were gathered during 30-minute VR video game sessions. Using ML methods, models were trained to predict VR sickness level (based on the physiological data labeled with the subjective data). Results showed an explained variance up to 75% (in a regression approach) and an accuracy up to 91% (in a classification approach). Despite generalization issues, this method seems promising and valuable for a real time, automatic and continuous evaluation of VR sickness, based on physiological signals and ML models. © 2020 IEEE.","Ergonomics; H.1.2 [Models and principles]: User/Machine Systems; Human factors; I.3.6 [Computer graphics]: Methodology and Techniques","Augmented reality; Diseases; E-learning; Machine learning; Physiology; Virtual reality; Classification approach; Electrodermal activity; Evaluation methods; General publics; Large-scale experimentations; Physiological data; Physiological signals; Subjective measurements; Physiological models",Conference Paper,"Final","",Scopus,2-s2.0-85099321186
"Lampen E., Lehwald J., Pfeiffer T.","57209683199;57202847650;14027435500;","Virtual Humans in AR: Evaluation of Presentation Concepts in an Industrial Assistance Use Case",2020,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,,,"","",,,"10.1145/3385956.3418974","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095834964&doi=10.1145%2f3385956.3418974&partnerID=40&md5=6990b67981dda33559c0b31456034299","EvoBus GmbH, Neu-Ulm, Germany; Faculty of Technology, University of Applied Sciences Emden/Leer, Emden, Germany","Lampen, E., EvoBus GmbH, Neu-Ulm, Germany; Lehwald, J., EvoBus GmbH, Neu-Ulm, Germany; Pfeiffer, T., Faculty of Technology, University of Applied Sciences Emden/Leer, Emden, Germany","Embedding virtual humans in educational settings enables the transfer of the approved concepts of learning by observation and imitation of experts to extended reality scenarios. Whilst various presentation concepts of virtual humans for learning have been investigated in sports and rehabilitation, little is known regarding industrial use cases. In prior work on manual assembly, Lampen et al. [21] show that three-dimensional (3D) registered virtual humans can provide assistance as effective as state-of-the-art HMD-based AR approaches. We extend this work by conducting a comparative user study (N=30) to verify implementation costs of assistive behavior features and 3D registration. The results reveal that the basic concept of a 3D registered virtual human is limited and comparable to a two-dimensional screen aligned presentation. However, by incorporating additional assistive behaviors, the 3D assistance concept is enhanced and shows significant advantages in terms of cognitive savings and reduced errors. Thus, it can be concluded, that this presentation concept is valuable in situations where time is less crucial, e.g. in learning scenarios or during complex tasks. © 2020 ACM.","Augmented Reality; Expert-Based Learning; Virtual Human","E-learning; Educational settings; Implementation cost; Industrial use case; Learning by observation; Learning scenarios; Sports and rehabilitations; State of the art; Threedimensional (3-d); Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85095834964
"David E., Beitner J., Võ M.L.-H.","57202111778;57203870149;9634349400;","Effects of transient loss of vision on head and eye movements during visual search in a virtual environment",2020,"Brain Sciences","10","11", 841,"1","26",,,"10.3390/brainsci10110841","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095995234&doi=10.3390%2fbrainsci10110841&partnerID=40&md5=2ba85748a2dc9beeeb7a622d24f7ff47","Scene Grammar Lab, Department of Psychology, Johann Wolfgang-Goethe-Universität, Theodor-W.-Adorno-Platz 6, Frankfurt, 60323, Germany","David, E., Scene Grammar Lab, Department of Psychology, Johann Wolfgang-Goethe-Universität, Theodor-W.-Adorno-Platz 6, Frankfurt, 60323, Germany; Beitner, J., Scene Grammar Lab, Department of Psychology, Johann Wolfgang-Goethe-Universität, Theodor-W.-Adorno-Platz 6, Frankfurt, 60323, Germany; Võ, M.L.-H., Scene Grammar Lab, Department of Psychology, Johann Wolfgang-Goethe-Universität, Theodor-W.-Adorno-Platz 6, Frankfurt, 60323, Germany","Central and peripheral fields of view extract information of different quality and serve different roles during visual tasks. Past research has studied this dichotomy on-screen in conditions remote from natural situations where the scene would be omnidirectional and the entire field of view could be of use. In this study, we had participants looking for objects in simulated everyday rooms in virtual reality. By implementing a gaze-contingent protocol we masked central or peripheral vision (masks of 6 deg. of radius) during trials. We analyzed the impact of vision loss on visuo-motor variables related to fixation (duration) and saccades (amplitude and relative directions). An important novelty is that we segregated eye, head and the general gaze movements in our analyses. Additionally, we studied these measures after separating trials into two search phases (scanning and verification). Our results generally replicate past on-screen literature and teach about the role of eye and head movements. We showed that the scanning phase is dominated by short fixations and long saccades to explore, and the verification phase by long fixations and short saccades to analyze. One finding indicates that eye movements are strongly driven by visual stimulation, while head movements serve a higher behavioral goal of exploring omnidirectional scenes. Moreover, losing central vision has a smaller impact than reported on-screen, hinting at the importance of peripheral scene processing for visual search with an extended field of view. Our findings provide more information concerning how knowledge gathered on-screen may transfer to more natural conditions, and attest to the experimental usefulness of eye tracking in virtual reality. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Gaze-contingent protocol; Virtual reality; Visual attention; Visual field loss; Visual search",,Article,"Final","",Scopus,2-s2.0-85095995234
"Petersen G.B., Klingenberg S., Mayer R.E., Makransky G.","57205735672;57214077924;7403065717;50361371800;","The virtual field trip: Investigating how to optimize immersive virtual learning in climate change education",2020,"British Journal of Educational Technology","51","6",,"2098","2114",,6,"10.1111/bjet.12991","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087505916&doi=10.1111%2fbjet.12991&partnerID=40&md5=95f409f7b19bb124fd571c95d712bfb7","Department of Psychology, University of Copenhagen, Denmark; University of Copenhagen, Denmark; University of California, Santa Barbara, United States; Department of Psychology at the University of Copenhagen, Denmark","Petersen, G.B., Department of Psychology, University of Copenhagen, Denmark; Klingenberg, S., University of Copenhagen, Denmark; Mayer, R.E., University of California, Santa Barbara, United States; Makransky, G., Department of Psychology at the University of Copenhagen, Denmark","Immersive Virtual Reality (IVR) is being used for educational virtual field trips (VFTs) involving scenarios that may be too difficult, dangerous or expensive to experience in real life. We implemented an immersive VFT within the investigation phase of an inquiry-based learning (IBL) climate change intervention. Students investigated the consequences of climate change by virtually traveling to Greenland and exploring albedo and greenhouse effects first hand. A total of 102 seventh and eighth grade students were randomly assigned to one of two instructional conditions: (1) narrated pretraining followed by IVR exploration or (2) the same narrated training material integrated within the IVR exploration. Students in both conditions showed significant increases in declarative knowledge, self-efficacy, interest, STEM intentions, outcome expectations and intentions to change behavior from the pre- to post-assessment. However, there was a significant difference between conditions favoring the pretraining group on a transfer test consisting of an oral presentation to a fictitious UN panel. The findings suggest that educators can choose to present important prerequisite learning content before or during a VFT. However, adding pretraining may lead to better transfer test performance, presumably because it helps reduce cognitive load while learning in IVR. © 2020 British Educational Research Association",,"Climate change; Students; Virtual reality; Declarative knowledge; Immersive virtual reality; Inquiry based learning (IBL); Learning contents; Oral presentations; Training material; Virtual field trips; Virtual learning; E-learning",Article,"Final","",Scopus,2-s2.0-85087505916
"Pletz C., Zinn B.","57218546432;36770118100;","Evaluation of an immersive virtual learning environment for operator training in mechanical and plant engineering using video analysis",2020,"British Journal of Educational Technology","51","6",,"2159","2179",,1,"10.1111/bjet.13024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089538860&doi=10.1111%2fbjet.13024&partnerID=40&md5=f0549fc6714395b5221f74594500ae9d","Department of Vocational Education focused on Teaching Technology (BPT) at the, University of Stuttgart, Germany; Department of Vocational Education focused on Teaching Technology (BPT), University of Stuttgart, Germany","Pletz, C., Department of Vocational Education focused on Teaching Technology (BPT) at the, University of Stuttgart, Germany; Zinn, B., Department of Vocational Education focused on Teaching Technology (BPT), University of Stuttgart, Germany","A structural evaluation is imperative for developing an effective virtual learning environment. Understanding the extent to which content that has been learned virtually can be applied practically holds particular importance. A group of persons from the technical field of mechanical and plant engineering (N = 13) participated in a virtual operator training for a case application of additive manufacturing. To evaluate the virtual learning environment the participants answered quantitative questionnaires and were asked to apply what they had learned virtually to the real machine. Both the virtual training and testing phase on the real machine were recorded by video (800 minutes in total). The category system resulting from a structured qualitative video analysis with a total of 568 codes contains design-, instruction- and interaction-related optimisation potentials for further development of the virtual learning sequence. Mistakes, difficulties and other anomalies during the application on the real machine provide further revision options. The study uses video data for the first time to derive optimisation potentials and to investigate the learning transfer of virtually learned action knowledge to the real-world activity. © 2020 The Authors. British Journal of Educational Technology published by John Wiley & Sons Ltd on behalf of British Educational Research Association",,"Computer aided instruction; Engineering education; Learning systems; Personnel training; Surveys; Virtual reality; Learning Transfer; Operator training; Plant engineering; Real-world activities; Structural evaluation; Virtual learning; Virtual learning environments; Virtual operators; E-learning",Article,"Final","",Scopus,2-s2.0-85089538860
"Armstrong M., Tsuchiya K., Liang F., Kunze K., Pai Y.S.","57219866273;57194083287;57191504624;21743317500;56267209600;","Multiplex Vision: Understanding Information Transfer and F-Formation with Extended 2-Way FOV",2020,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,,,"","",,,"10.1145/3385956.3418954","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095814394&doi=10.1145%2f3385956.3418954&partnerID=40&md5=89c416380a230628f82185e756df2444","Keio University, Graduate School of Media Design, Tokyo, Japan; INNOCC Ignition Point Inc., Tokyo, Japan; University of Auckland, Auckland, New Zealand","Armstrong, M., Keio University, Graduate School of Media Design, Tokyo, Japan; Tsuchiya, K., Keio University, Graduate School of Media Design, Tokyo, Japan; Liang, F., INNOCC Ignition Point Inc., Tokyo, Japan; Kunze, K., Keio University, Graduate School of Media Design, Tokyo, Japan; Pai, Y.S., University of Auckland, Auckland, New Zealand","Research in sociology shows that effective conversation relates to people's spatial and orientational relationship, namely the proxemics (distance, eye contact, synchrony) and the F-formation (orientation and arrangement). In this work, we introduce novel conversational paradigms that effects conventional F-formation by introducing the concept of multi-directional conversation. Multiplex Vision is a head-mounted device capable of providing a 360° field-of-view (FOV) and facilitating multi-user interaction multi-directionally, thereby providing novel methods on how people can interact with each other. We propose 3 possible new forms of interactions from our prototype: one-to-one, one-to-many, and many-to-many. To facilitate them, we manipulate 2 key variables, which are the viewing parameter and the display parameter. To gather feedback for our system, we conducted a study to understand information transfer between various modes, as well as a user study on how different proposed paradigms effect conversation. Finally, we discuss present and future use cases that can benefit from our system. © 2020 ACM.","360 field-of-view; conversation; F-formation; vision augmentation","Sociology; Display parameters; Field of views; Information transfers; Key variables; Multi-user interaction; Novel methods; Orientational relationship; Viewing parameters; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85095814394
"Schwarz S., Regal G., Kempf M., Schatz R.","56785127800;55848939000;57204063955;35609979600;","Learning Success in Immersive Virtual Reality Training Environments: Practical Evidence from Automotive Assembly",2020,"ACM International Conference Proceeding Series",,,,"","",,,"10.1145/3419249.3420182","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095803774&doi=10.1145%2f3419249.3420182&partnerID=40&md5=eeef469f019ee50a6111f03a2664300c","Austrian Institute of Technology GmbH, Vienna, Austria; Innovation.rocks GmbH, Vienna, Austria","Schwarz, S., Austrian Institute of Technology GmbH, Vienna, Austria; Regal, G., Austrian Institute of Technology GmbH, Vienna, Austria; Kempf, M., Innovation.rocks GmbH, Vienna, Austria; Schatz, R., Austrian Institute of Technology GmbH, Vienna, Austria","Learning success in assembly training using immersive virtual reality technologies depends on multiple factors ranging from quality levels of process and technical documentation, visual 3D rendering quality, maturity of didactic concepts to individual differences and attitudes of workers and trainers. In this paper, we present the results of a field study conducted in an automotive factory to evaluate an immersive virtual reality training environment (VTE). Set up under real training conditions, the VTE was operated by trainers to train novice assembly line workers on a specific task: the assembly of a vehicle center console. Using a between-subject design we compare training performance in terms of skill transfer and retention between workers being trained in the VTE to workers who had been trained conventionally on the physical car. Our results suggest positive transfer of the acquired procedures from the VTE to physical assembly and even performance improvements over time. We discuss learning success in the VTE in contrast to user experience feedback and the implemented sequence steps for mounting assembly parts, based on comprehensive behavioral data. Finally, reflections on trainer feedback lead the way to implications for the adaption of didactic strategies and operational procedures towards increasing overall effectiveness of VTE-supported assembly training. © 2020 ACM.","Automotive Assembly; Learning Transfer; Trainers.; Training; Virtual Reality; Workers","E-learning; Human computer interaction; Three dimensional computer graphics; User experience; Assembly-line workers; Automotive assemblies; Experience feedback; Immersive virtual reality; Individual Differences; Operational procedures; Overall effectiveness; Technical documentations; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85095803774
"Reidy L., Chan D., Nduka C., Gunes H.","57219692602;7402215873;6701344479;7005067251;","Facial Electromyography-based Adaptive Virtual Reality Gaming for Cognitive Training",2020,"ICMI 2020 - Proceedings of the 2020 International Conference on Multimodal Interaction",,,,"174","183",,,"10.1145/3382507.3418845","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096675924&doi=10.1145%2f3382507.3418845&partnerID=40&md5=90924d4272dc8c02fa5721a1381ffeac","University of Cambridge, Cambridge, United Kingdom; University College London, London, United Kingdom; Emteq Ltd, United Kingdom","Reidy, L., University of Cambridge, Cambridge, United Kingdom; Chan, D., University College London, London, United Kingdom; Nduka, C., Emteq Ltd, United Kingdom; Gunes, H., University of Cambridge, Cambridge, United Kingdom","Cognitive training has shown promising results for delivering improvements in human cognition related to attention, problem solving, reading comprehension and information retrieval. However, two frequently cited problems in cognitive training literature are a lack of user engagement with the training programme, and a failure of developed skills to generalise to daily life. This paper introduces a new cognitive training (CT) paradigm designed to address these two limitations by combining the benefits of gamification, virtual reality (VR), and affective adaptation in the development of an engaging, ecologically valid, CT task. Additionally, it incorporates facial electromyography (EMG) as a means of determining user affect while engaged in the CT task. This information is then utilised to dynamically adjust the game's difficulty in real-time as users play, with the aim of leading them into a state of flow. Affect recognition rates of 64.1% and 76.2%, for valence and arousal respectively, were achieved by classifying a DWT-Haar approximation of the input signal using kNN. The affect-aware VR cognitive training intervention was then evaluated with a control group of older adults. The results obtained substantiate the notion that adaptation techniques can lead to greater feelings of competence and a more appropriate challenge of the user's skills. © 2020 Owner/Author.","adaptive gaming; affective computing; cognitive training; facial electromyography; virtual reality","E-learning; Interactive computer systems; Virtual addresses; Adaptation techniques; Affect recognition; Cognitive training; Facial electromyographies; Human cognition; Reading comprehension; Training programmes; User engagement; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85096675924
"McIntosh J., Zajac H.D., Stefan A.N., Bergström J., Hornbæk K.","57188763518;57220116799;57220115883;57210962041;6602385484;","Iteratively adapting avatars using task-integrated optimisation",2020,"UIST 2020 - Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology",,, 3415832,"709","721",,,"10.1145/3379337.3415832","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096968994&doi=10.1145%2f3379337.3415832&partnerID=40&md5=335c57f6515e33f2e0a9ad2ad2c2a6ad","University of Copenhagen, Copenhagen, Denmark","McIntosh, J., University of Copenhagen, Copenhagen, Denmark; Zajac, H.D., University of Copenhagen, Copenhagen, Denmark; Stefan, A.N., University of Copenhagen, Copenhagen, Denmark; Bergström, J., University of Copenhagen, Copenhagen, Denmark; Hornbæk, K., University of Copenhagen, Copenhagen, Denmark","Virtual Reality allows users to embody avatars that do not match their real bodies. Earlier work has selected changes to the avatar arbitrarily and it therefore remains unclear how to change avatars to improve users' performance. We propose a systematic approach for iteratively adapting the avatar to perform better for a given task based on users' performance. The approach is evaluated in a target selection task, where the forearms of the avatar are scaled to improve performance. A comparison between the optimised and real arm lengths shows a significant reduction in average tapping time by 18.7%, for forearms multiplied in length by 5.6. Additionally, with the adapted avatar, participants moved their real body and arms significantly less, and subjective measures show reduced physical demand and frustration. In a second study, we modify finger lengths for a linear tapping task to achieve a better performing avatar, which demonstrates the generalisability of the approach. © 2020 ACM.","Avatar adaptation; Optimisation; Virtual reality","Iterative methods; Arm lengths; Improve performance; Optimisations; Physical demand; Tapping time; Target selection; Task-based; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-85096968994
"Du J., Yu F.R., Lu G., Wang J., Jiang J., Chu X.","57188706756;57213980384;7403460635;13613533800;57198571713;8536386700;","MEC-Assisted Immersive VR Video Streaming over Terahertz Wireless Networks: A Deep Reinforcement Learning Approach",2020,"IEEE Internet of Things Journal","7","10", 9120235,"9517","9529",,10,"10.1109/JIOT.2020.3003449","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092709939&doi=10.1109%2fJIOT.2020.3003449&partnerID=40&md5=9d415f1ee32084295aa918f217856727","Shaanxi Key Laboratory of Information Communication Network and Security, School of Communications and Information Engineering, Xi'an University of Posts and Telecommunications, Xi'an, 710121, China; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON  K1S 5B6, Canada; Department of Electronic and Electrical Engineering, University of Sheffield, Sheffield, S1 3JD, United Kingdom","Du, J., Shaanxi Key Laboratory of Information Communication Network and Security, School of Communications and Information Engineering, Xi'an University of Posts and Telecommunications, Xi'an, 710121, China; Yu, F.R., Department of Systems and Computer Engineering, Carleton University, Ottawa, ON  K1S 5B6, Canada; Lu, G., Shaanxi Key Laboratory of Information Communication Network and Security, School of Communications and Information Engineering, Xi'an University of Posts and Telecommunications, Xi'an, 710121, China; Wang, J., Shaanxi Key Laboratory of Information Communication Network and Security, School of Communications and Information Engineering, Xi'an University of Posts and Telecommunications, Xi'an, 710121, China; Jiang, J., Shaanxi Key Laboratory of Information Communication Network and Security, School of Communications and Information Engineering, Xi'an University of Posts and Telecommunications, Xi'an, 710121, China; Chu, X., Department of Electronic and Electrical Engineering, University of Sheffield, Sheffield, S1 3JD, United Kingdom","Immersive virtual reality (VR) video is becoming increasingly popular owing to its enhanced immersive experience. To enjoy ultrahigh resolution immersive VR video with wireless user equipments, such as head-mounted displays (HMDs), ultralow-latency viewport rendering, and data transmission are the core prerequisites, which could not be achieved without a huge bandwidth and superior processing capabilities. Besides, potentially very high energy consumption at the HMD may impede the rapid development of wireless panoramic VR video. Multiaccess edge computing (MEC) has emerged as a promising technology to reduce both the task processing latency and the energy consumption for HMD, while bandwidth-rich terahertz (THz) communication is expected to enable ultrahigh-speed wireless data transmission. In this article, we propose to minimize the long-term energy consumption of a THz wireless access-based MEC system for high quality immersive VR video services support by jointly optimizing the viewport rendering offloading and downlink transmit power control. Considering the time-varying nature of wireless channel conditions, we propose a deep reinforcement learning-based approach to learn the optimal viewport rendering offloading and transmit power control policies and an asynchronous advantage actor-critic (A3C)-based joint optimization algorithm is proposed. The simulation results demonstrate that the proposed algorithm converges fast under different learning rates, and outperforms existing algorithms in terms of minimized energy consumption and maximized reward. © 2014 IEEE.","Asynchronous advantage actor-critic (A3C); computation offloading; deep reinforcement learning (DRL); terahertz (THz) communication; virtual reality (VR)","Bandwidth; Data communication equipment; Data transfer; Deep learning; Energy utilization; Green computing; Helmet mounted displays; Learning algorithms; Power control; Quality control; Reinforcement learning; Rendering (computer graphics); Video streaming; Wave transmission; Wireless networks; Head mounted displays; Immersive virtual reality; Processing capability; Reinforcement learning approach; Terahertz(THz) communications; Transmit power control; Wireless channel condition; Wireless data transmission; Virtual reality",Article,"Final","",Scopus,2-s2.0-85092709939
"Zhang X.","57222575025;","The Construction of Realistic Environment of Deep Learning Based on Virtual Reality",2020,"Proceedings - 2020 International Conference on Computers, Information Processing and Advanced Education, CIPAE 2020",,, 9373657,"186","190",,,"10.1109/CIPAE51077.2020.00056","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103299812&doi=10.1109%2fCIPAE51077.2020.00056&partnerID=40&md5=561124e638c202ca2d8e674d480159f0","Village, Chenjia Town, Chongming District, Shanghai, China","Zhang, X., Village, Chenjia Town, Chongming District, Shanghai, China","Virtual environment created based on virtual reality can promote learners' deep learning experience. It enables learners' immersive exploration and interaction with the real environment. In this way they can have their personalized learning experience and continuous feedback. Virtual reality, which creates an immersive and interactive environment, leads to a better teaching model where students' previous learning pattern is changed. At present, virtual reality technology is becoming increasingly mature, and research on the application of virtual reality in education is drawing more attention from educators. The article analyzes the learning pattern enabled by virtual reality, and I believe that the advantages of virtual reality in the construction of deep learning mainly lie in environment construction, experience design, behavior guidance, and learning transfer. © 2020 IEEE.","deep empathy; deep learning; immersive reaction; virtual reality technology","E-learning; Education computing; Virtual reality; Environment constructions; Experience design; Interactive Environments; Learning experiences; Learning Transfer; Personalized learning; Realistic environments; Virtual reality technology; Deep learning",Conference Paper,"Final","",Scopus,2-s2.0-85103299812
"Cheah C.S.L., Barman S., Vu K.T.T., Jung S.E., Mandalapu V., Masterson T.D., Zuber R.J., Boot L., Gong J.","7007112847;57215324988;57204359659;57215315964;57202788973;56543054000;57215331782;35781520200;55512650400;","Validation of a Virtual Reality Buffet environment to assess food selection processes among emerging adults",2020,"Appetite","153",, 104741,"","",,1,"10.1016/j.appet.2020.104741","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085559744&doi=10.1016%2fj.appet.2020.104741&partnerID=40&md5=7437bcd0f7ff0a777e94e3a78b2df10d","Department of Psychology, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Department of Information Systems, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Department of Nutritional Sciences, The Pennsylvania State University, 110 Chandlee Laboratory, University ParkPA  16802, United States; Imaging Research Center, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States","Cheah, C.S.L., Department of Psychology, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Barman, S., Department of Psychology, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Vu, K.T.T., Department of Psychology, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Jung, S.E., Department of Psychology, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Mandalapu, V., Department of Information Systems, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Masterson, T.D., Department of Nutritional Sciences, The Pennsylvania State University, 110 Chandlee Laboratory, University ParkPA  16802, United States; Zuber, R.J., Imaging Research Center, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Boot, L., Imaging Research Center, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Gong, J., Department of Information Systems, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States","Emerging adulthood is a critical developmental period for examining food- and eating-related behaviors as long-term weight-related behavioral patterns are established. Virtual reality (VR) technology is a promising tool for basic and applied research on eating and food-related processes. Thus, the present study tested the validity and user perceptions of a highly immersive and realistic VR food buffet by: (1) comparing participants' food selections made in the VR buffet and a real-world (RW) food buffet cafeteria one-week apart, and (2) assessing participants' rated perceptions of their VR experience (0–100 scale). Participants comprised an ethnically diverse sample of emerging adults (N = 35, Mage = 20.49, SD = 2.17). Results revealed that participants' food selections in the VR and RW food buffets were significantly and positively correlated in Kcals, grams, carbohydrates, and protein (all p's &lt; 0.05). Moreover, participants perceived that: (a) the VR buffet was natural (M = 70.97, SD = 20.92), (b) their lunch selection in the VR buffet represented a lunch they would select on an average day (M = 84.11, SD = 15.92); and (c) their selection represented a lunch they would select if the same foods were available (M = 91.29, SD = 11.00). Our findings demonstrated the validity and acceptability of our highly immersive and realistic VR buffet for assessing food selection that is generalizable to RW food settings one-week apart without precisely matched foods. The findings of this study support the utility of VR as a validated tool for research on psychological and behavioral food-related processes and training interventions among emerging adults. © 2020 Elsevier Ltd","Emerging adults; Food buffet; Food selection; Virtual reality","adult; Article; controlled study; critical period (psychology); environmental factor; female; food preference; human; human experiment; hunger; male; meal; normal human; nutritional value; perception; portion size; validation process; virtual reality",Article,"Final","",Scopus,2-s2.0-85085559744
"Zhou T., Zhu Q., Du J.","57218949339;57209806243;57219889677;","Intuitive robot teleoperation for civil engineering operations with virtual reality and deep learning scene reconstruction",2020,"Advanced Engineering Informatics","46",, 101170,"","",,,"10.1016/j.aei.2020.101170","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090898690&doi=10.1016%2fj.aei.2020.101170&partnerID=40&md5=908bb4c201303c8747d6ecb275b0542a","Engineering School of Sustainable Infrastructure & Environment, University of Florida, 1949 Stadium Road 454A Weil Hall, Gainesville, FL  32611, United States; Engineering School of Sustainable Infrastructure & Environment, University of Florida, 1949 Stadium Road 460F Weil Hall, Gainesville, FL  32611, United States","Zhou, T., Engineering School of Sustainable Infrastructure & Environment, University of Florida, 1949 Stadium Road 454A Weil Hall, Gainesville, FL  32611, United States; Zhu, Q., Engineering School of Sustainable Infrastructure & Environment, University of Florida, 1949 Stadium Road 454A Weil Hall, Gainesville, FL  32611, United States; Du, J., Engineering School of Sustainable Infrastructure & Environment, University of Florida, 1949 Stadium Road 460F Weil Hall, Gainesville, FL  32611, United States","Robotic teleoperation, i.e., manipulating remote robotic systems at a distance, has gained its popularity in various industrial applications, including construction operations. The key to a successful teleoperation robot system is the delicate design of the human-robot interface that helps strengthen the human operator's situational awareness. Traditional human-robot interface for robotic teleoperation is usually based on imagery data (e.g., video streaming), causing the limited field of view (FOV) and increased cognitive burden for processing additional spatial information. As a result, 3D scene reconstruction methods based on point cloud models captured by scanning technologies (e.g., depth camera and LiDAR) have been explored to provide immersive and intuitive feedback to the human operator. Despite the added benefits of applying reconstructed 3D scenes in telerobotic systems, challenges still present. Most 3D reconstruction methods utilize raw point cloud data due to the difficulty of real-time model rendering. The significant size of point cloud data makes the processing and transfer between robots and human operators difficult and slow. In addition, most reconstructed point cloud models do not contain physical properties such as weight and colliders. A more enriched control mechanism based on physics engine simulations is impossible. This paper presents an intelligent robot teleoperation interface that collects, processes, transfers, and reconstructs the immersive scene model of the workspace in Virtual Reality (VR) and enables intuitive robot controls accordingly. The proposed system, Telerobotic Operation based on Auto-reconstructed Remote Scene (TOARS), utilizes a deep learning algorithm to automatically detect objects in the captured scene, along with their physical properties, based on the point cloud data. The processed information is then transferred to the game engine where rendered virtual objects replace the original point cloud models in the VR environment. TOARS is expected to significantly improve the efficiency of 3D scene reconstruction and situational awareness of human operators in robotic teleoperation. © 2020 Elsevier Ltd","Deep learning; Robot; Scene reconstruction; Teleoperation; Virtual reality","Biofeedback; Cloud computing; Data handling; Deep learning; E-learning; Image reconstruction; Industrial robots; Intelligent robots; Learning algorithms; Machine design; Object detection; Personnel; Physical properties; Remote control; Rendering (computer graphics); Robotics; Social robots; Virtual reality; 3D scene reconstruction; Construction operations; Engineering operation; Human-Robot Interface; Processed information; Robot teleoperation interfaces; Robotic teleoperation; Situational awareness; Three dimensional computer graphics",Article,"Final","",Scopus,2-s2.0-85090898690
"Lécuyer F., Gouranton V., Lamercerie A., Reuzeau A., Caillaud B., Arnaldi B.","57209417146;6506588443;57215823769;56741393700;55605009400;6603383416;","Unveiling the implicit knowledge, one scenario at a time",2020,"Visual Computer","36","10-12",,"1951","1963",,,"10.1007/s00371-020-01904-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087744022&doi=10.1007%2fs00371-020-01904-7&partnerID=40&md5=768db087b10889f5bf375586c542d6d8","INSA Rennes, Univ Rennes, Inria, CNRS, IRISA, Rennes, France; Univ Rennes, Inria, CNRS, IRISA, Rennes, France; IRISA, Univ Rennes, Inria, CNRS, IRISA, Rennes, France","Lécuyer, F., INSA Rennes, Univ Rennes, Inria, CNRS, IRISA, Rennes, France; Gouranton, V., INSA Rennes, Univ Rennes, Inria, CNRS, IRISA, Rennes, France; Lamercerie, A., IRISA, Univ Rennes, Inria, CNRS, IRISA, Rennes, France; Reuzeau, A., INSA Rennes, Univ Rennes, Inria, CNRS, IRISA, Rennes, France; Caillaud, B., Univ Rennes, Inria, CNRS, IRISA, Rennes, France; Arnaldi, B., INSA Rennes, Univ Rennes, Inria, CNRS, IRISA, Rennes, France","When defining virtual reality applications with complex procedures, such as medical operations or mechanical assembly or maintenance procedures, the complexity and the variability of the procedures make the definition of the scenario difficult and time-consuming. Indeed, the variability complicates the definition of the scenario by the experts, and its combinatorics demand a comprehension effort for the developer, which is often out of reach. Additionally, the experts have a hard time explaining the procedures with a sufficient level of details, as they usually forget to mention some actions that are, in fact, important for the application. To ease the creation of scenario, we propose a complete methodology, based on (1) an iterative process composed of: (2) the recording of actions in virtual reality to create sequences of actions and (3) the use of mathematical tools that can generate a complete scenario from a few of those sequences, with (4) graphical visualization of the scenarios and complexity indicators. This process helps the expert to determine the sequences that must be recorded to obtain a scenario with the required variability. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","Authoring; Generalization; Scenario; Virtual reality","Virtual reality; Complexity indicators; Graphical visualization; Implicit knowledge; Iterative process; Maintenance procedures; Mathematical tools; Mechanical assembly; Medical operations; Iterative methods",Article,"Final","",Scopus,2-s2.0-85087744022
"Pinardi D., Ebri L., Belicchi C., Farina A., Binelli M.","57195467991;56770178100;57219547851;7202992441;55354577100;","Direction Specific Analysis of Psychoacoustics Parameters inside Car Cockpit: A Novel Tool for NVH and Sound Quality",2020,"SAE Technical Papers",,"2020",,"","",,,"10.4271/2020-01-1547","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093822780&doi=10.4271%2f2020-01-1547&partnerID=40&md5=c96cd017a73014350d0726971591bd1f","University of Parma, Italy; University of Parma, Ask Industries SpA, Italy","Pinardi, D., University of Parma, Italy; Ebri, L., University of Parma, Ask Industries SpA, Italy; Belicchi, C., University of Parma, Italy; Farina, A., University of Parma, Italy; Binelli, M., University of Parma, Italy","Psychoacoustics parameters are widely employed in automotive field for objective evaluation of Sound Quality (SQ) of vehicle cabins and their components. The standard approach relies on binaural recordings from which numerical values and curves are calculated. In addition, head-locked binaural listening playback can be performed. The Virtual Reality (VR) technology recently started to diffuse also in automotive field, bringing new possibilities for enhanced and immersive listening sessions, thanks to the usage of massive microphone arrays instead of binaural microphones. In this paper, we combine both solutions: the principal SQ parameters are derived from multichannel recordings. This allows computing a map of direction-dependent values of SQ parameters. The acquisition system consists in a spherical microphone array with 32 capsules and a multiple-lens camera for capturing a panoramic equirectangular background image. The audio recording is encoded into High Order Ambisonics (HOA) format for being compared with a classic omnidirectional microphone and into Spatial PCM Sampling (SPS) format for producing 360° equirectangular color maps. The SPS encoding is used to plot over the background image the distribution of SPL values in dB (A) and of the SQ parameters: by adding to them the directional information, it results into a novel 360° diagnostic tool for localizing the most annoying sources. Furthermore, the playback of the HOA soundtrack can be performed both on a loudspeaker rig inside an Ambisonics listening room or on binaural headphones attached to a Head Mounted Display (HMD), benefiting from head-tracking and personalized Head Related Transfer Functions (HRTFs), allowing to make quick subjective evaluations with a degree of realism unattainable with the older static binaural approach. © 2020SAE International. All Rights Reserved.",,"Acoustic noise; Acoustic variables measurement; Helmet mounted displays; Loudspeakers; Microphones; Parameter estimation; Quality control; Virtual reality; Binaural recordings; Directional information; Head mounted displays; Head related transfer function; Multi-channel recording; Objective evaluation; Spherical microphone array; Subjective evaluations; Audio recordings",Conference Paper,"Final","",Scopus,2-s2.0-85093822780
"Tarkkanen K., Lehto A., Oliva D., Somerkoski B., Haavisto T., Luimula M.","25642288100;57208750395;42061986700;56297992300;57219971101;17435411000;","Research study design for teaching and testing fire safety skills with AR and VR Games",2020,"11th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2020 - Proceedings",,, 9237831,"167","172",,,"10.1109/CogInfoCom50765.2020.9237831","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096361007&doi=10.1109%2fCogInfoCom50765.2020.9237831&partnerID=40&md5=44575e2d89999555aca8e9be53dd6969","ICT, Turku University of Applied Sciences, Turku, Finland; RDI Services, Turku University of Applied Sciences, Turku, Finland; University of Turku, Department of Teacher Education, Turku, Finland","Tarkkanen, K., ICT, Turku University of Applied Sciences, Turku, Finland; Lehto, A., RDI Services, Turku University of Applied Sciences, Turku, Finland; Oliva, D., ICT, Turku University of Applied Sciences, Turku, Finland; Somerkoski, B., University of Turku, Department of Teacher Education, Turku, Finland; Haavisto, T., ICT, Turku University of Applied Sciences, Turku, Finland; Luimula, M., ICT, Turku University of Applied Sciences, Turku, Finland","Virtual and augmented reality (VR AR) games can provide innovative methods for teaching and learning important skills relating to fire safety. However, in an emergency context, testing the acquired knowledge and skills, i.e. verifying the learning, can be challenging. In this paper, we ask how the interplay between AR and VR could support learning verification. We describe two standalone games of both types, which interchangeably teach fire safety skills to children and verify their learning results. In particular, we describe the planned learning paths and research study designs for verification studies within and between these games to answer the above question. By operationalizing the two cases, the paper ends in proposing more generalized study design for AR and VR research in a fire safety context. © 2020 IEEE.","Augmented reality; Fire safety; Research design; Serious games; Virtual reality","Augmented reality; Fires; Emergency contexts; Innovative method; Planned learning; Research study design; Study design; Support learning; Teaching and learning; Virtual and augmented reality; Safety testing",Conference Paper,"Final","",Scopus,2-s2.0-85096361007
"Knopp B., Velychko D., Dreibrodt J., Schütz A.C., Endres D.","56307867500;57219361918;57211058203;21743919300;7004010222;","Evaluating Perceptual Predictions based on Movement Primitive Models in VR-and Online-Experiments",2020,"Proceedings - SAP 2020: ACM Symposium on Applied Perception",,, 3407940,"","",,,"10.1145/3385955.3407940","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092379746&doi=10.1145%2f3385955.3407940&partnerID=40&md5=ba08f9fee7a689f63e03698142dba169","Philipps Universität Marburg, Germany; University of Marburg, Germany","Knopp, B., Philipps Universität Marburg, Germany; Velychko, D., Philipps Universität Marburg, Germany; Dreibrodt, J., Philipps Universität Marburg, Germany; Schütz, A.C., Philipps Universität Marburg, Germany; Endres, D., University of Marburg, Germany","We investigate the role of prediction in biological movement perception by comparing different representations of human movement in a virtual reality (VR) and online experiment. Predicting movement enables quick and appropriate action by both humans and artificial agents in many situations, e.g. when the interception of objects is important. We use different predictive movement primitive (MP) models to probe the visual system for the employed prediction mechanism. We hypothesize that MP-models, originally devised to address the degrees-of-freedom (DOF) problem in motor production, might be used for perception as well. In our study we consider object passing movements. Our paradigm is a predictive task, where participants need to discriminate movement continuations generated by MP models from the ground truth of the natural continuation. This experiment was conducted first in VR, and later on continued as online experiment. We found that results transfer from the controlled and immersive VR setting with movements rendered as realistic avatars to a simple and COVID-19 safe online setting with movements rendered as stick figures. In the online setting we further investigate the effect of different occlusion timings. We found that contact events during the movement might provide segmentation points that render the lead-in movement independent of the continuation and thereby make perceptual predictions much harder for subjects. We compare different MP-models by their capability to produce perceptually believable movement continuations and their usefulness to predict this perceptual naturalness. Our research might provide useful insight for application in computer animation, by showing how movements can be continued without violating the expectation of the user. Our results also contribute towards an efficient method of animating avatars by combining simple movements into complex movement sequences. © 2020 Owner/Author.","dynamical movement primitives; dynamical systems; Gaussian process dynamical model; human animation; movement primitives; perception; psychophysics","Animation; Degrees of freedom (mechanics); Forecasting; Virtual reality; Artificial agents; Biological movements; Computer animation; Human movements; Movement primitives; On-line experiments; On-line setting; Prediction mechanisms; Motion estimation",Conference Paper,"Final","",Scopus,2-s2.0-85092379746
"Delamarre A., Lisetti C., Buche C.","57195671754;6602670860;8349259000;","A Cross-Platform Classroom Training Simulator: Interaction Design and EvaluationA Cross-Platform Classroom Training Simulator: Interaction Design and Evaluation",2020,"Proceedings - 2020 International Conference on Cyberworlds, CW 2020",,, 9240533,"86","93",,,"10.1109/CW49994.2020.00020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099535199&doi=10.1109%2fCW49994.2020.00020&partnerID=40&md5=0afab14bfbc31f31c90b991bafa5ee8d","Florida International University, Visage Lab, Scis, Miami, United States; LAB-STICC Cnrs, Enib, Brest, France","Delamarre, A., Florida International University, Visage Lab, Scis, Miami, United States; Lisetti, C., Florida International University, Visage Lab, Scis, Miami, United States; Buche, C., LAB-STICC Cnrs, Enib, Brest, France","Virtual training environments experienced with different immersive technologies can accommodate users' preferences, proficiency, and platform availability. Whereas research comparing the effects of immersive technologies can provide important insights about their impact on users' experience (e.g. engagement, transfer of learning), current studies do not address how to design the user interface (UI) to ensure sound comparisons across platforms. For effective comparisons, however, the UI designs must be adapted for the platform used to provide comparable usability. In this article we describe our UI design methodology for the development of an effective and usable virtual classroom training simulator built for three technologies: (1) desktop; (2) Head-Mounted Display (HMD); and (3) Cave Automatic Virtual Environment (CAVE). Usability and other user experience factors were evaluated for each platform with concurrent think-aloud protocol and semi-structured interviews indicating that all three UIs were easy to use and to learn. We discuss insights for future development of cross-platform VTEs. © 2020 IEEE.","Design; Human Computer Interaction; Immersive Virtual Environment; User Study; Virtual Reality","Availability; Caves; Computer aided instruction; Design; E-learning; Helmet mounted displays; Simulators; Transfer learning; User experience; User interfaces; Cave automatic virtual environments; Head mounted displays; Immersive technologies; Platform availabilities; Semi structured interviews; Think-aloud protocol; Transfer of learning; Virtual training environments; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85099535199
"Houshmand B., Khan N.M.","57219792826;38361516100;","Facial Expression Recognition under Partial Occlusion from Virtual Reality Headsets based on Transfer Learning",2020,"Proceedings - 2020 IEEE 6th International Conference on Multimedia Big Data, BigMM 2020",,, 9232653,"70","75",,,"10.1109/BigMM50055.2020.00020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097241474&doi=10.1109%2fBigMM50055.2020.00020&partnerID=40&md5=b69f6f1256f605345e4e4028c5b57250","Ryerson University Data Science, Toronto, Canada; Ryerson University Electrical and Computer Engineering, Toronto, Canada","Houshmand, B., Ryerson University Data Science, Toronto, Canada; Khan, N.M., Ryerson University Electrical and Computer Engineering, Toronto, Canada","Facial expressions of emotion are a major channel in our daily communications, and it has been subject of intense research in recent years. To automatically infer facial expressions, convolutional neural network based approaches has become widely adopted due to their proven applicability to Facial Expression Recognition (FER) task.On the other hand Virtual Reality (VR) has gained popularity as an immersive multimedia platform, where FER can provide enriched media experiences. However, recognizing facial expression while wearing a head-mounted VR headset is a challenging task due to the upper half of the face being completely occluded. In this paper we attempt to overcome these issues and focus on facial expression recognition in presence of a severe occlusion where the user is wearing a head-mounted display in a VR setting. We propose a geometric model to simulate occlusion resulting from a Samsung Gear VR headset that can be applied to existing FER datasets. Then, we adopt a transfer learning approach, starting from two pretrained networks, namely VGG and ResNet. We further fine-tune the networks on FER+ and RAF-DB datasets. Experimental results show that our approach achieves comparable results to existing methods while training on three modified benchmark datasets that adhere to realistic occlusion resulting from wearing a commodity VR headset. Code for this paper is available at: https://github.com/bita-github/MRP-FER © 2020 IEEE.","Facial expression recognition; Facial occlusion; Transfer learning; VR","Big data; Convolutional neural networks; E-learning; Face recognition; Helmet mounted displays; Transfer learning; Wear of materials; Benchmark datasets; Facial expression recognition; Facial Expressions; Geometric modeling; Head mounted displays; Multimedia platforms; Partial occlusions; Virtual-reality headsets; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85097241474
"Harris D.J., Buckingham G., Wilson M.R., Brookes J., Mushtaq F., Mon-Williams M., Vine S.J.","57192429891;14069958400;55574207642;57197801653;56999078200;7006287402;36811509000;","The effect of a virtual reality environment on gaze behaviour and motor skill learning",2020,"Psychology of Sport and Exercise","50",, 101721,"","",,3,"10.1016/j.psychsport.2020.101721","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086586041&doi=10.1016%2fj.psychsport.2020.101721&partnerID=40&md5=608f65aed21033b6e58a9a8feac30da8","School of Sport and Health Sciences, University of Exeter, Exeter, EX1 2LU, United Kingdom; School of Psychology, University of Leeds, Leeds, LS2 9JZ, United Kingdom; Centre for Immersive Technologies, University of Leeds, Leeds, LS2 9JZ, United Kingdom; Bradford Teaching Hospitals NHS Foundation Trust, Bradford, West Yorkshire, United Kingdom; National Centre for Optics, Vision and Eye Care, University of South-Eastern Norway, Kongsberg, Hasbergs Vei 363616, Norway","Harris, D.J., School of Sport and Health Sciences, University of Exeter, Exeter, EX1 2LU, United Kingdom; Buckingham, G., School of Sport and Health Sciences, University of Exeter, Exeter, EX1 2LU, United Kingdom; Wilson, M.R., School of Sport and Health Sciences, University of Exeter, Exeter, EX1 2LU, United Kingdom; Brookes, J., School of Psychology, University of Leeds, Leeds, LS2 9JZ, United Kingdom; Mushtaq, F., School of Psychology, University of Leeds, Leeds, LS2 9JZ, United Kingdom, Centre for Immersive Technologies, University of Leeds, Leeds, LS2 9JZ, United Kingdom; Mon-Williams, M., School of Psychology, University of Leeds, Leeds, LS2 9JZ, United Kingdom, Centre for Immersive Technologies, University of Leeds, Leeds, LS2 9JZ, United Kingdom, Bradford Teaching Hospitals NHS Foundation Trust, Bradford, West Yorkshire, United Kingdom, National Centre for Optics, Vision and Eye Care, University of South-Eastern Norway, Kongsberg, Hasbergs Vei 363616, Norway; Vine, S.J., School of Sport and Health Sciences, University of Exeter, Exeter, EX1 2LU, United Kingdom","Objective: Virtual reality (VR) systems hold significant potential for training skilled behaviours and are currently receiving intense interest in the sporting domain. They offer both practical and pedagogical benefits, but there are concerns about the effect that perceptual deficiencies in VR systems (e.g. reduced haptic information, and stereoscopic display distortions) may have on learning and performance. ‘Specificity of learning’ theories suggest that VR could be ineffective (or even detrimental) if important differences (e.g. perceptual deficiencies) exist between practice and real task performance conditions. Nevertheless, ‘structural learning’ theories suggest VR could be a useful training tool, despite these deficiencies, because a trainee can still learn the underlying structure of the behaviour. We explored these theoretical predictions using golf putting as an exemplar skill. Method: In Experiment 1 we used a repeated measures design to assess putting accuracy (radial error) and quiet eye duration of expert golfers (n = 18) on real putts before and after 40 VR ‘warm up’ putts. In Experiment 2, novice golfers (n = 40) were assigned to either VR or real-world putting training. Putting accuracy and quiet eye durations were then assessed on a real-world retention test. Results: Both visual guidance (quiet eye) and putting accuracy were disrupted temporarily when moving from VR to real putting (Experiment 1). However, real-world and VR practice produced comparable improvements in putting accuracy in novice golfers (Experiment 2). Conclusion: Overall, the results suggest that: (i) underlying skill structures can be learned in VR and transferred to the real-world; (ii) perceptual deficiencies will place limits on the use of VR. These findings demonstrate the challenges and opportunities for VR as a training tool, and emphasise the need to empirically test the costs and benefits of specific systems before deploying VR training. © 2020 Elsevier Ltd","Quiet eye; Skill acquisition; Sport; Stereoscopic; Transfer; VR","article; clinical article; gaze; golf; human; human experiment; learning; motor performance; prediction; virtual reality; warm up",Article,"Final","",Scopus,2-s2.0-85086586041
"Tychkov A.Y., Grachev A.V., Alimuradov A.K.","36731632400;56982633900;56595170300;","Virtual Reality in Information Transfer",2020,"Proceedings - 2020 International Russian Automation Conference, RusAutoCon 2020",,, 9208101,"826","830",,,"10.1109/RusAutoCon49822.2020.9208101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093936152&doi=10.1109%2fRusAutoCon49822.2020.9208101&partnerID=40&md5=b588ffda22ded34bf60a388b377b648f","Penza State University, Research Institute for Basic and Applied Studies, Penza, Russian Federation; Penza State University, Department of Radioengineering and Radioelectronic Systems, Penza, Russian Federation; Penza State University, Student Research and Production Business Incubator, Penza, Russian Federation","Tychkov, A.Y., Penza State University, Research Institute for Basic and Applied Studies, Penza, Russian Federation; Grachev, A.V., Penza State University, Department of Radioengineering and Radioelectronic Systems, Penza, Russian Federation; Alimuradov, A.K., Penza State University, Student Research and Production Business Incubator, Penza, Russian Federation","The article is devoted to technologies and virtual reality systems as comprehensive solutions for immersion of the user into virtual reality using specialized devices and interfaces. Technologies for wire/wireless transfer of audio-visual and parametric information in virtual reality systems are discussed. The aim of the article is to analyze and summarize advantages and disadvantages of modern facilities for multimedia and parametric information transfer used in virtual reality systems. A search method for research materials in Russian and international journals included in scientific citation databases was used. The paper analyzes the features (advantages and disadvantages) of using virtual reality in conditions of optical information transfer, wireless protocols (WiFi, Bluetooth, Wireless USB, LIDAR, ZigBee), and wire interfaces (Display Port, HDMI, USB) that provide user communication with virtual reality system. Virtual reality forms a new artificial real world transferred to the user via various wire/wireless (WiGig (802.11ad), WiFi 6 (802.11ax), WiHD (802.15.3c), and Display Port 2.0) interfaces, taking into account physiological, physical and psychometric indicators. Modern technical solutions should give impetus to the creation of adaptive virtual reality with a total immersion effect, when the user cannot distinguish a virtual world from real events. © 2020 IEEE.","adaptive virtual reality; tactile interfaces; wireless/wire information transfer","Audio systems; IEEE Standards; Optical communication; Optical radar; System buses; Virtual reality; Wi-Fi; Wire; Wireless local area networks (WLAN); Information transfers; International journals; Optical information; Parametric information; Technical solutions; User communication; Virtual reality system; Wireless protocol; Data communication systems",Conference Paper,"Final","",Scopus,2-s2.0-85093936152
"Catal C., Akbulut A., Tunali B., Ulug E., Ozturk E.","22633325800;25960607500;57211942369;57211949025;57211945039;","Evaluation of augmented reality technology for the design of an evacuation training game",2020,"Virtual Reality","24","3",,"359","368",,2,"10.1007/s10055-019-00410-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075481004&doi=10.1007%2fs10055-019-00410-z&partnerID=40&md5=1f2c3d6562a0c05b9c1b4538db9f7821","Information Technology Group, Wageningen University & Research, Wageningen, Netherlands; Department of Computer Engineering, Istanbul Kultur University, Istanbul, Turkey","Catal, C., Information Technology Group, Wageningen University & Research, Wageningen, Netherlands; Akbulut, A., Department of Computer Engineering, Istanbul Kultur University, Istanbul, Turkey; Tunali, B., Department of Computer Engineering, Istanbul Kultur University, Istanbul, Turkey; Ulug, E., Department of Computer Engineering, Istanbul Kultur University, Istanbul, Turkey; Ozturk, E., Department of Computer Engineering, Istanbul Kultur University, Istanbul, Turkey","Building evacuation training systems and training employees in an organization have a vital role in emergency cases in which people need to know what to do exactly. In every building, procedures, rules, and actions are attractively shown on the walls, but most of the people living in that building are not aware of these procedures and do not have any experience what to do in these dangerous situations. In order to be able to apply these procedures properly in an emergency situation, community members should be trained with the state-of-the-art equipment and technologies, but to do so, up-front investment and development of such a system are necessary. In this study, augmented reality (AR) technology was applied to realize a game-based evacuation training system that implements gamification practices. The architectural plans of a university were used to model the floors and the relevant environment. Employees are trained to learn how to reach the nearest exit location in the event of a fire or earthquake, and also, the system provides the shortest path for the evacuation. In addition to these features, our training game has educational animations about the fire, chemical attack, and earthquake events. A mobile application was implemented to train employees working in the building and inform them to know how to escape in an emergency situation. The technology acceptance model and the related questionnaire form were applied, and the response of 36 participants was analyzed. It was demonstrated that AR and relevant tools provide a flexible environment to develop evacuation systems in a university, our mobile application enabled participants to be trained in a realistic environment, and trainees were highly satisfied with the system. Educational animations were also another benefit for the trainees. © 2019, The Author(s).","Animation; ARKit framework; Augmented reality; Evacuation training system; Game engine; Software; Training; Unity3D","Animation; Augmented reality; Chemical attack; Computer software; Earthquakes; Investments; Mobile computing; Technology transfer; ARKit framework; Augmented reality technology; Game Engine; Realistic environments; State-of-the-art equipments; Technology acceptance model; Training Systems; Unity3d; Personnel training",Article,"Final","",Scopus,2-s2.0-85075481004
"Chen J., Liu C., Chang R., Gui P., Na S.","23090323300;57220998631;57219899921;57212382631;57200312577;","From traditional to vr-based online education platforms: A model of the mechanism influencing user migration",2020,"Information (Switzerland)","11","9", 423,"1","19",,,"10.3390/info11090423","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097974976&doi=10.3390%2finfo11090423&partnerID=40&md5=2014b0cd71a30650376d848607f8a5be","School of Business Administration, Wonkwang University, 460 Iksandae-ro, Iksan, Jeonbuk  54538, South Korea","Chen, J., School of Business Administration, Wonkwang University, 460 Iksandae-ro, Iksan, Jeonbuk  54538, South Korea; Liu, C., School of Business Administration, Wonkwang University, 460 Iksandae-ro, Iksan, Jeonbuk  54538, South Korea; Chang, R., School of Business Administration, Wonkwang University, 460 Iksandae-ro, Iksan, Jeonbuk  54538, South Korea; Gui, P., School of Business Administration, Wonkwang University, 460 Iksandae-ro, Iksan, Jeonbuk  54538, South Korea; Na, S., School of Business Administration, Wonkwang University, 460 Iksandae-ro, Iksan, Jeonbuk  54538, South Korea","VR technology can help create optimal virtual learning spaces. Such spaces offer new visual experiences that break through the limitations of time and space and greatly stimulate people’s imagination and creativity in learning. Currently, the bandwidth required for such spaces limits the large-scale application of virtual reality (VR) technology for this purpose. With the large-scale deployment and application of high-speed networks, however, online education platforms based on VR technology will be better able to meet the diversified and personalized learning needs of learners. To promote the development and popularization of new online education platforms based on VR, the factors influencing the migration of learners from traditional online education platforms to new platforms need to be understood more clearly. A model based on the theory of negative, positive, and anchoring effects can explain learners’ migration behavior in this connection. To this end, a structural equation model based on the PLS variance algorithm was used to analyze data obtained through offline and online questionnaires. It was found that in terms of “negative effects”, the afunction and loyalty associated with traditional online education platforms reduced learners’ willingness to migrate to new platforms based on VR technology. In terms of “positive effects”, the novel interactivity and personalization brought by the new platform increased the willingness of users of traditional platforms to migrate to new platforms. In terms of “anchoring effects”, the system quality and relationship quality of learners’ use of traditional online education platforms, as well as the transfer costs associated with the new platform, generated learners’ risk perception about platform migration. In addition, risk perception not only negatively affects learners’ migration to the new platforms, but also strengthens their cognition of the system quality and relationship quality of the traditional platforms, while reducing their interactive awareness of those platforms. Therefore, by adjusting the psychological component of virtual learning, the online education platforms based on VR technology can create high-quality platforms migrating from traditional platforms. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Migration mechanism; Online education; VR technology","Behavioral research; Electronic assessment; HIgh speed networks; Learning systems; Risk perception; Surveys; Anchoring effects; Large-scale applications; Large-scale deployment; Online questionnaire; Personalized learning; Relationship qualities; Structural equation modeling; Visual experiences; E-learning",Article,"Final","",Scopus,2-s2.0-85097974976
"Lamb R., Etopio E.A.","36634407300;55377820300;","Virtual Reality: a Tool for Preservice Science Teachers to Put Theory into Practice",2020,"Journal of Science Education and Technology","29","4",,"573","585",,1,"10.1007/s10956-020-09837-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086093371&doi=10.1007%2fs10956-020-09837-5&partnerID=40&md5=cd13439157dd46a931e0208a267b9983","Neurocognition Science Laboratory, East Carolina University, Greenville, NC  27858, United States; University at Buffalo, Buffalo, NY, United States","Lamb, R., Neurocognition Science Laboratory, East Carolina University, Greenville, NC  27858, United States; Etopio, E.A., University at Buffalo, Buffalo, NY, United States","The purpose of the present study was to investigate, compare, and characterize interactive VR-based preservice science teacher clinical teaching environments with those of real-life teaching environments. Fifty-four college-aged students were assigned randomly to either real-life conditions or VR conditions. The main effect of the VR condition versus real-life was not statistically significant in terms of the retrospective engagement survey, psychological measures, and composite neuroimaging. This finding suggests that use of VR, in terms of the realism of the environment for the preservice science teachers allowed them to learn from modeled real-life situations for transfer of skills from VR to classroom use. © 2020, Springer Nature B.V.","Methods courses; Professional learning; Science education; Teacher preparation; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85086093371
"Colombo M., Dolhasz A., Harvey C.","57220106721;57193614682;48761392600;","A Computer Vision Inspired Automatic Acoustic Material Tagging System for Virtual Environments",2020,"IEEE Conference on Computatonal Intelligence and Games, CIG","2020-August",, 9231689,"736","739",,,"10.1109/CoG47356.2020.9231689","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096928895&doi=10.1109%2fCoG47356.2020.9231689&partnerID=40&md5=5ddcf3873d31b91b857e59df2851414c","Birmingham City University, Dmt Lab, United Kingdom","Colombo, M., Birmingham City University, Dmt Lab, United Kingdom; Dolhasz, A., Birmingham City University, Dmt Lab, United Kingdom; Harvey, C., Birmingham City University, Dmt Lab, United Kingdom","This paper presents the ongoing work on an approach to material information retrieval in virtual environments (VEs). Our approach uses convolutional neural networks to classify materials by performing semantic segmentation on images captured in the VE. Class maps obtained are then re-projected onto the environment. We use transfer learning and fine-tune a pretrained segmentation model on images captured in our VEs. The geometry and semantic information can then be used to create mappings between objects in the VE and acoustic absorption coefficients. This can then be input for physically-based audio renderers, allowing a significant reduction in manual material tagging. © 2020 IEEE.","acoustic applications; games; machine vision; rendering (computer graphics); semantic networks","Computer vision; Convolutional neural networks; Image segmentation; Semantics; Transfer learning; Acoustic absorption coefficients; Acoustic materials; Material information; Physically based; Segmentation models; Semantic information; Semantic segmentation; Tagging systems; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85096928895
"Lognoul M., Nasello J., Triffaux J.-M.","57192315139;57202678573;6602998181;","Virtual reality exposure therapy for post-traumatic stress disorders, obsessive-compulsive disorders and anxiety disorders: Indications, added value and limitations [La thérapie par exposition en réalité virtuelle pour les états de stress post-traumatiques, les troubles obsessionnels compulsifs et les troubles anxieux: indications, plus-value et limites]",2020,"Encephale","46","4",,"293","300",,1,"10.1016/j.encep.2020.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081206627&doi=10.1016%2fj.encep.2020.01.005&partnerID=40&md5=3a2b5f6da7ce4045868302f24c897585","Psychologie médicale et Psychosomatique, hôpital de jour universitaire “La Clé”, Liège, Belgium; Faculté de médecine, département de psychologie médicale, université de Liège, Liège, Belgium; Faculté de psychologie, département de psychologie clinique, université de Liège, Liège, Belgium","Lognoul, M., Psychologie médicale et Psychosomatique, hôpital de jour universitaire “La Clé”, Liège, Belgium, Faculté de médecine, département de psychologie médicale, université de Liège, Liège, Belgium; Nasello, J., Psychologie médicale et Psychosomatique, hôpital de jour universitaire “La Clé”, Liège, Belgium, Faculté de psychologie, département de psychologie clinique, université de Liège, Liège, Belgium; Triffaux, J.-M., Psychologie médicale et Psychosomatique, hôpital de jour universitaire “La Clé”, Liège, Belgium, Faculté de médecine, département de psychologie médicale, université de Liège, Liège, Belgium","The exposure in cognitive behavioral therapy (CBT) is a well-known intervention, widely investigated in scientific research. Several studies have shown the benefits of this intervention in the treatment of anxiety disorders, obsessive-compulsive disorders (OCD) and post-traumatic stress disorders (PTSD). The different exposure techniques are mainly based on the emotional processing of fear theory and use an emotional stimulation of fear, following by its habituation. However, new approaches have emerged and are based on the inhibitory learning theory. The virtual reality technology allows emotional involvement from patients and represents a complementary approach to the classical modalities of exposure therapy (e.g., mental or in vivo expositions). This modern approach presents specific features that need to be taken into account by the therapist. Firstly, the presence feeling, which is defined as the “be there” feeling. This feeling is dependent on immersive technical features and personality factors. Secondly, virtual reality sickness, similar to motion sickness, represents a limitation that might prejudice a virtual therapy. The main scientific investigations of Virtual Reality Exposure Therapy (VRET) for treating social phobia, specific phobia, PTSD, and panic disorders are encouraging and demonstrate a similar effectiveness between both in vivo and in virtuo exposures. The scarce investigations on generalized anxiety disorders and OCD also suggeste a similar effectiveness between these exposures. However, further scientific investigations are needed to support these preliminary findings. The attrition rates and deteriorating states are similar to classical CBT approaches. Nevertheless, scientific literature presents several limits: 1) much of the research on this topic has interest conflicts (e.g., developers are also authors of a large number of studies); 2) there is a high heterogeneity of materials and virtual environments used; 3) important measures are not always taken into account in scientific research (e.g., the presence feeling); and 4) a massive use of waiting lists as a control measure. Despite these limitations, the VRET have strong silver linings: 1) the easy access to exposure (less limited than standard exposure techniques) and a cost reduction; 2) highly guaranteed security; 3) the anonymization of exposures (i.e., the patients do not risk meeting someone they know during the exposure therapy); 4) the therapist has a greater control of exposures; 5) a standardization of the exposures; 6) a greater involvement in therapy for technophile patients. Virtual exposure also seems to be generally more accepted by patients. © 2020 L'Encéphale, Paris","Anxiety disorders; Cognitive behavioral therapy; Obsessive-compulsive disorder; Post-traumatic stress disorder; Virtual reality","anonymization; anxiety disorder; Article; computer security; cost control; cybersickness; emotion; fear; generalized anxiety disorder; habituation; human; learning theory; obsessive compulsive disorder; panic; personality; phobia; posttraumatic stress disorder; psychotherapist; social phobia; standardization; treatment indication; virtual reality; virtual reality exposure therapy",Article,"Final","",Scopus,2-s2.0-85081206627
"Nie J., Wu B.","57219057682;57213495940;","Investigating the effect of immersive virtual reality and planning on the outcomes of simulation-based learning: A media and method experiment",2020,"Proceedings - IEEE 20th International Conference on Advanced Learning Technologies, ICALT 2020",,, 9155971,"329","332",,,"10.1109/ICALT49669.2020.00106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091147966&doi=10.1109%2fICALT49669.2020.00106&partnerID=40&md5=0cfc6e5a1bd46be168e53bd114e7a60d","East China Normal University, Department of Educational Informational Technology, Shanghai, China","Nie, J., East China Normal University, Department of Educational Informational Technology, Shanghai, China; Wu, B., East China Normal University, Department of Educational Informational Technology, Shanghai, China","The application of the immersive virtual reality (VR) has injected new vitality into educational innovation, but there are also some voices of doubt on its practical learning effects. Considering two aspects of media and instructional methods, the study investigated the effect of immersive virtual reality and planning strategy on simulation-based learning by a 2×2 experimental cross-panel design. The results showed that both of them had a significant main effect, indicating that the immersive VR and planning led to better behavioral transfer performance and immersive VR increased sense of presence and self-efficacy as well. No interaction effect between media and method was found. © 2020 IEEE.","Immersive virtual reality; Planning Strategy; Simulation-based learning; Virtual simulation","E-learning; Learning systems; Educational innovations; Immersive virtual reality; Instructional methods; Interaction effect; Planning strategies; Sense of presences; Simulation-based learning; Transfer performance; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85091147966
"Hensen B., Klamma R.","57203715350;6603333022;","Comparing authoring workflows and learning paths in web mixed reality environments",2020,"Proceedings - IEEE 20th International Conference on Advanced Learning Technologies, ICALT 2020",,, 9155647,"319","321",,,"10.1109/ICALT49669.2020.00102","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091165216&doi=10.1109%2fICALT49669.2020.00102&partnerID=40&md5=40e1befd400cbb1c1d7357c1b5345d55","Rwth Aachen University, Informatik 5, Aachen, Germany","Hensen, B., Rwth Aachen University, Informatik 5, Aachen, Germany; Klamma, R., Rwth Aachen University, Informatik 5, Aachen, Germany","With recent developments in information technology, we can realize learning experiences on the Web and in mixed reality. Many disciplines have profited from this, e.g. anatomy with the possibility to learn with 3D models in both environments. However, designing authoring workflows and learning paths can be different in these environments as the transfer of design ideas can affect the quality of the learning experiences. In this paper, we juxtapose a Web application and a mixed reality application of the same anatomy course. We highlight where differences need to be considered and which modules can be used in both environments, e.g. authentication and gamification. With the practical knowledge presented here, the design of learning experiences on the Web and in mixed reality can be enhanced. To support this, all code is available as open-source software on GitHub. © 2020 IEEE.","Augmented Reality; Gamification; Mixed Reality; Virtual Reality; Web-based Learning; WebXR","Open source software; Open systems; Design ideas; Learning experiences; Learning paths; Mixed-reality environment; WEB application; Work-flows; Mixed reality",Conference Paper,"Final","",Scopus,2-s2.0-85091165216
"Reneker J.C., Pannell W.C., Babl R.M., Zhang Y., Lirette S.T., Adah F., Reneker M.R.","39262154500;57211146202;57208317766;57218229331;55749187700;8383459800;57200071502;","Virtual immersive sensorimotor training (VIST) in collegiate soccer athletes: A quasi-experimental study",2020,"Heliyon","6","7", e04527,"","",,1,"10.1016/j.heliyon.2020.e04527","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088391353&doi=10.1016%2fj.heliyon.2020.e04527&partnerID=40&md5=3e73c054b3c48f8873a4389c75cf734f","Department of Population Health Sciences, School of Population Health, University of Mississippi Medical Center, United States; Department of Physical Therapy, School of Health Related Professions, University of Mississippi Medical Center, United States; Department of Data Science, School of Population Health, University of Mississippi Medical Center, United States; Athletic Department, Mississippi College, United States","Reneker, J.C., Department of Population Health Sciences, School of Population Health, University of Mississippi Medical Center, United States; Pannell, W.C., Department of Physical Therapy, School of Health Related Professions, University of Mississippi Medical Center, United States; Babl, R.M., Department of Physical Therapy, School of Health Related Professions, University of Mississippi Medical Center, United States; Zhang, Y., Department of Data Science, School of Population Health, University of Mississippi Medical Center, United States; Lirette, S.T., Department of Data Science, School of Population Health, University of Mississippi Medical Center, United States; Adah, F., Department of Physical Therapy, School of Health Related Professions, University of Mississippi Medical Center, United States; Reneker, M.R., Athletic Department, Mississippi College, United States","Neuroscience; Exercise; Musculoskeletal system; Neurology; Clinical research; Virtual reality; Sensorimotor control; Sports injury prevention. © 2020 The AuthorsA burgeoning area of innovation in sports is the use of extended realities to provide athletes with novel training environments. Evidence has demonstrated that virtual environments can be useful therapeutic tools with demonstrated positive outcomes. The purpose of this pilot investigation was to determine the effects of virtual immersive sensorimotor training intervention by quantifying 1) the training effect measured via change in performance pre-to post-intervention on the virtual reality exercises, 2) the difference in the in clinical measures of functional sensorimotor control, 3) the injury incidence rate, and 4) on-field performance during soccer competitions. Statistical analyses were used to describe differences between an experimental and a control group. Participants were recruited from the men and women's soccer teams at two universities in the United States. Participants at one university were in the experimental group (n = 78) and received virtual immersive sensorimotor training, consisting of nine novel exercises in headset virtual reality, twice each week for six weeks. Participants at the second university were in the control group (n = 52). The virtual exercises were developed with reference to the rehabilitative principles of neuroplasticity to train various neurologic processes, contributing to overall sensorimotor control. This includes vestibular, visual and oculomotor activities, cervical neuromotor control training, movement coordination, and postural/balance exercises. The results indicate significant positive training effects pre-to post-intervention in seven of the nine training exercises (p ≤ 0.005) and improvement in clinical tests of cervical neuromotor control, balance, and inspection time (p ≤ 0.009) in the experimental group compared to the control. One of the virtual training exercises was positively associated with on-field performance (p = 0.022). No differences in injury rate or overall on-field performance metrics between the experimental and control were detected. This research study provides evidence of training and positive transfer from virtual to real-world environments, supporting the use of these novel virtual exercises to improve measures of sensorimotor control in healthy soccer athletes. © 2020 The Authors","Clinical research; Exercise; Musculoskeletal system; Neurology; Neuroscience; Sensorimotor control; Sports injury prevention; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85088391353
"Eiris R., Jain A., Gheisari M., Wehle A.","57196006104;57216183570;36459705300;55344669000;","Safety immersive storytelling using narrated 360-degree panoramas: A fall hazard training within the electrical trade context",2020,"Safety Science","127",, 104703,"","",,3,"10.1016/j.ssci.2020.104703","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082764482&doi=10.1016%2fj.ssci.2020.104703&partnerID=40&md5=414ed06acb963eaf989a6379e49e6ace","208 Rinker Hall, Rinker School of Construction Management, University of Florida, PO Box 115703, Gainesville, FL  32611-5703, United States; Plaza Construction, 120 NE 27th Street, Miami, FL  33137, United States; 322 Rinker Hall, Rinker School of Construction Management, University of Florida, PO Box 115703, Gainesville, FL  32611-5703, United States","Eiris, R., 208 Rinker Hall, Rinker School of Construction Management, University of Florida, PO Box 115703, Gainesville, FL  32611-5703, United States; Jain, A., Plaza Construction, 120 NE 27th Street, Miami, FL  33137, United States; Gheisari, M., 322 Rinker Hall, Rinker School of Construction Management, University of Florida, PO Box 115703, Gainesville, FL  32611-5703, United States; Wehle, A., 322 Rinker Hall, Rinker School of Construction Management, University of Florida, PO Box 115703, Gainesville, FL  32611-5703, United States","Safety training in the United States construction industry commonly employs classroom-based lecture and storytelling techniques to transfer knowledge to workers and professionals. However, low levels of engagement and low-fidelity representations of the construction jobsites have posed limitations for learners to easily visualize and understand hazard conditions. One emerging technology that has the potential to increase engagement and provide high-fidelity visualizations of construction jobsites is 360-degree panorama virtual environments. This study concentrates on using immersive storytelling within digital 360-degree panoramas to improve hazard recognition and risk perception. A proof-of-concept platform was developed to assess the produced virtual training environment in terms of hazard identification, risk perception, and sense of presence. The platform was conceptualized within the visual and narrative context of electrical trade fall hazards, as this trade often perform complex work at elevated surfaces making them especially susceptible to fall related injuries and fatalities. A between-subject pilot study was conducted with forty construction management student subjects, comparatively evaluating safety immersive storytelling and Occupational Safety and Health Administration (OSHA) trained participants (e.g., OSHA 10-hr, OSHA 30-hr). It was found that no statistical differences are present in the average Hazard Identification Index (HII) scores for both approaches, suggesting that the outcomes of the training techniques are equivalent for the narrow scope of fall hazards evaluated in this study (scissor/aerial lifts, scaffolds, roofs/unprotected edges). Nevertheless, time savings in hazard identification training were found; safety immersive storytelling required 15 min of training in contrast 10 or 30 h of OSHA training. Furthermore, it was detected that subjects assigned more or equal risk to ladders, scaffolds, and scissor/aerial lifts hazards for safety immersive storytelling compared to the OSHA condition. Although the subject risk perception scores demonstrate these trends, a statistical analysis performed showed no significant differences between the two experimental groups. All participants perceived that the immersive experience provided a high sense of presence. Based on the experimental results, it was concluded that safety immersive storytelling provides an analogous outcome to OSHA interventions for the studied fall hazards while reducing the required training time. © 2020 Elsevier Ltd","360-degree panorama; Immersive storytelling; Safety training; Virtual reality","Accident prevention; Commerce; Construction industry; E-learning; Hazardous materials; Hazards; Project management; Risk assessment; Risk perception; Tools; Virtual reality; 360-degree panorama; Construction management; Emerging technologies; Immersive; Occupational safety and health administrations; Safety training; Statistical differences; Virtual training environments; Occupational risks; 360 degree panorama; adult; Article; building industry; construction worker; controlled study; electrical trade; employee attitude; fall hazard training; falling; fatality; female; hazard identification; Hazard Identification Index; human; human experiment; male; methodology; motivation; occupational accident; occupational safety; outcome assessment; photography; pilot study; priority journal; proof of concept; risk assessment; risk perception; scoring system; statistical analysis; story telling; student; training; videorecording; virtual reality; vulnerable population; young adult",Article,"Final","",Scopus,2-s2.0-85082764482
"Andreatta M., Neueder D., Herzog K., Genheimer H., Schiele M.A., Deckert J., Domschke K., Reif A., Wieser M.J., Pauli P.","23967624100;55877547500;57213604493;56902628900;56326699900;55918597000;6505952781;57203053457;11440385900;7003473881;","Generalization of Conditioned Contextual Anxiety and the Modulatory Effects of Anxiety Sensitivity",2020,"Neurotherapeutics","17","3",,"1239","1252",,,"10.1007/s13311-020-00831-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077909175&doi=10.1007%2fs13311-020-00831-8&partnerID=40&md5=d239c54c7c09aea354b5edccb8a6608d","Department of Psychology (Biological Psychology, Clinical Psychology and Psychotherapy), University of Würzburg, Würzburg, Germany; Department of Psychology, Educational Sciences, and Child Studies, Erasmus University Rotterdam, Burg. Oudlaan 50, Rotterdam, 3062 DR, Netherlands; Department of Psychiatry and Psychotherapy, Medical Center – University of Freiburg, Faculty of Medicine, University of Freiburg, Freiburg im Breisgau, Germany; Department of Psychiatry, Psychosomatics, and Psychotherapy, Center of Mental Health, Würzburg, Germany; Center of Mental Health, University of Würzburg, Würzburg, Germany; Department of Psychiatry, Psychosomatic Medicine and Psychotherapy, University Hospital Frankfurt, Frankfurt am Main, Germany","Andreatta, M., Department of Psychology (Biological Psychology, Clinical Psychology and Psychotherapy), University of Würzburg, Würzburg, Germany, Department of Psychology, Educational Sciences, and Child Studies, Erasmus University Rotterdam, Burg. Oudlaan 50, Rotterdam, 3062 DR, Netherlands; Neueder, D., Department of Psychology (Biological Psychology, Clinical Psychology and Psychotherapy), University of Würzburg, Würzburg, Germany; Herzog, K., Department of Psychology (Biological Psychology, Clinical Psychology and Psychotherapy), University of Würzburg, Würzburg, Germany; Genheimer, H., Department of Psychology (Biological Psychology, Clinical Psychology and Psychotherapy), University of Würzburg, Würzburg, Germany; Schiele, M.A., Department of Psychiatry and Psychotherapy, Medical Center – University of Freiburg, Faculty of Medicine, University of Freiburg, Freiburg im Breisgau, Germany; Deckert, J., Department of Psychiatry, Psychosomatics, and Psychotherapy, Center of Mental Health, Würzburg, Germany, Center of Mental Health, University of Würzburg, Würzburg, Germany; Domschke, K., Department of Psychiatry and Psychotherapy, Medical Center – University of Freiburg, Faculty of Medicine, University of Freiburg, Freiburg im Breisgau, Germany, Department of Psychiatry, Psychosomatics, and Psychotherapy, Center of Mental Health, Würzburg, Germany; Reif, A., Department of Psychiatry, Psychosomatic Medicine and Psychotherapy, University Hospital Frankfurt, Frankfurt am Main, Germany; Wieser, M.J., Department of Psychology (Biological Psychology, Clinical Psychology and Psychotherapy), University of Würzburg, Würzburg, Germany, Department of Psychology, Educational Sciences, and Child Studies, Erasmus University Rotterdam, Burg. Oudlaan 50, Rotterdam, 3062 DR, Netherlands; Pauli, P., Department of Psychology (Biological Psychology, Clinical Psychology and Psychotherapy), University of Würzburg, Würzburg, Germany, Center of Mental Health, University of Würzburg, Würzburg, Germany","Anxiety patients overgeneralize fear responses, possibly because they cannot distinguish between cues never been associated with a threat (i.e., safe) and threat-associated cues. However, as contexts and not cues are discussed as the relevant triggers for prolonged anxiety responses characterizing many anxiety disorders, we speculated that it is rather overgeneralization of contextual anxiety, which constitutes a risk factor for anxiety disorders. To this end, we investigated generalization of conditioned contextual anxiety and explored modulatory effects of anxiety sensitivity, a risk factor for anxiety disorders. Fifty-five participants underwent context conditioning in a virtual reality paradigm. On Day 1 (acquisition), participants received unpredictable mildly painful electric stimuli (unconditioned stimulus, US) in one virtual office (anxiety context, CTX+), but never in a second office (safety context, CTX−). Successful acquisition of conditioned anxiety was indicated by aversive ratings and defensive physiological responses (i.e., SCR) to CTX+ vs CTX−. On Day 2 (generalization), participants re-visited both the anxiety and the safety contexts plus three generalization contexts (G-CTX), which were gradually dissimilar to CTX+ (from 75 to 25%). Generalization of conditioned anxiety was evident for ratings, but less clear for physiological responses. The observed dissociation between generalization of verbal and physiological responses suggests that these responses depend on two distinct context representations, likely elemental and contextual representations. Importantly, anxiety sensitivity was positively correlated with the generalization of reported contextual anxiety. Thus, this study demonstrates generalization gradients for conditioned contextual anxiety and that anxiety sensitivity facilitates such generalization processes suggesting the importance of generalization of contextual anxiety for the development of anxiety disorders. © 2020, The Author(s).","Anxiety sensitivity; Context conditioning; Generalization processes; Startle response; Virtual reality","adult; anxiety; anxiety disorder; Anxiety Sensitivity Index; Article; conditioned contextual anxiety; conditioned reflex; electrostimulation; female; generalization (psychology); habituation; human; major clinical study; male; neurophysiology; pain threshold; personality; Positive and Negative Affect Schedule; priority journal; risk factor; startle reflex; virtual reality; white noise",Article,"Final","",Scopus,2-s2.0-85077909175
"Castañé G.G., Calderón Mateos A.","50060943100;57211937827;","Machine learning applied to accelerate energy consumption models in computing simulators",2020,"Simulation Modelling Practice and Theory","102",, 102012,"","",,,"10.1016/j.simpat.2019.102012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075471055&doi=10.1016%2fj.simpat.2019.102012&partnerID=40&md5=d55fbbb9baa10288908c6b755fecdde3","Insight-centre for Data Analytics, Computer Science Department, University College Cork, Cork, Ireland; Computer Science and Engineering Department, Universidad Carlos III de Madrid, Leganés, Spain","Castañé, G.G., Insight-centre for Data Analytics, Computer Science Department, University College Cork, Cork, Ireland; Calderón Mateos, A., Computer Science and Engineering Department, Universidad Carlos III de Madrid, Leganés, Spain","The ever-increasing growth of data centres and fog resources makes difficult for current simulation frameworks to model large computing infrastructures. Therefore, a major trade-off for simulators is the balance between abstraction level of the models, the scalability, and the performance of the executions. In order to balance better these, early forays can be found in the literature in which AI techniques are applied, but either lack of generality or are tailored to specific simulation frameworks. This paper describes the methodology to integrate memoization as a technique of supervised learning into any computing simulators framework. In this process, a bespoke kernel was constructed for the analysis of the energy models used in most well known computing simulators -cloud and fog-, but also to avoid simulation overhead. Finally, a detailed evaluation of energy models and its performance is presented showing the impact of applying supervised learning to computing simulator, showing performance improvements when models are more accurate and computations are dense. © 2019 Elsevier B.V.","Computer simulation; Machine learning; Memoization; Simulation","Computer simulation; Economic and social effects; Energy utilization; Learning systems; Machine learning; Simulators; Supervised learning; Abstraction level; AI techniques; Current simulation; Energy consumption model; Large-computing; Memoization; Simulation; Simulation framework; Green computing",Article,"Final","",Scopus,2-s2.0-85075471055
"Lopez C.E., Ashour O., Cunningham J.D., Tucker C., Lynch P.C.","57193163382;36080456300;57194829435;15833577900;56300591400;","The CLICK approach and its impact on learning introductory probability concepts in an industrial engineering course",2020,"ASEE Annual Conference and Exposition, Conference Proceedings","2020-June",, 1339,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095792991&partnerID=40&md5=2b11cbd2f228cb0f4a897f4e2b19ce26","Lafayette College, United States; Penn State Erie, Behrend College, United States; Carnegie Mellon University, United States; Pennsylvania State University, Behrend College, United States","Lopez, C.E., Lafayette College, United States; Ashour, O., Penn State Erie, Behrend College, United States; Cunningham, J.D., Carnegie Mellon University, United States; Tucker, C., Carnegie Mellon University, United States; Lynch, P.C., Pennsylvania State University, Behrend College, United States","The objective of this work is to present an initial investigation of the impact the Connected Learning and Integrated Course Knowledge (CLICK) approach has had on students' motivation, engineering identity, and learning outcomes. CLICK is an approach that leverages Virtual Reality (VR) technology to provide an integrative learning experience in the Industrial Engineering (IE) curriculum. To achieve this integration, the approach aims to leverage VR learning modules to simulate a variety of systems. The VR learning modules offer an immersive experience and provide the context for real-life applications. The virtual simulated system represents a theme to transfer the system concepts and knowledge across multiple IE courses as well as connect the experience with real-world applications. The CLICK approach has the combined effect of immersion and learning-by-doing benefits. In this work, VR learning modules are developed for a simulated manufacturing system. The modules teach the concepts of measures of location and dispersion, which are used in an introductory probability course within the IE curriculum. This work presents the initial results of comparing the motivation, engineering identity, and knowledge gain between a control and an intervention group (i.e., traditional vs. CLICK teaching groups). The CLICK approach group showed greater motivation compared to a traditional teaching group. However, there were no effects on engineering identity and knowledge gain. Nevertheless, it is hypothesized that the VR learning modules will have a positive impact on the students' motivation, engineering identity, and knowledge gain over the long run and when used across the curriculum. Moreover, IE instructors interested in providing an immersive and integrative learning experience to their students could leverage the VR learning modules developed for this project. © American Society for Engineering Education 2020.",,"Curricula; Learning systems; Manufacture; Motivation; Students; Teaching; Virtual reality; Industrial engineering course; Integrated course; Integrative learning; Learning by doing; Learning modules; Learning outcome; Probability concepts; Real-life applications; Engineering education",Conference Paper,"Final","",Scopus,2-s2.0-85095792991
"Harrington M.C.R.","36836717500;","Virtual dioramas transform natural history museum exhibit halls & gardens to life with immersive AR",2020,"Extended Abstracts - Proceedings of the 2020 ACM Interaction Design and Children Conference, IDC 2020",,,,"276","279",,,"10.1145/3397617.3402036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091986221&doi=10.1145%2f3397617.3402036&partnerID=40&md5=99b27fde8a41e48fbd6d9bc34cabd113","University of Central Florida, United States","Harrington, M.C.R., University of Central Florida, United States","The original motivation and design process of the AR Perpetual Garden App is discussed in detail. Available on Apple iTunes and Google Play Stores, children and parents, teachers and students, may download and learn with it now, thus amplifying the learning impact of immersive experiences even at home. Inspired by the dioramas of the past, both the creation process and their use in museums as interactive, multimodal, knowledge artifacts are discussed and carefully analyzed. This paper may be of interest to researchers and practitioners alike. First, as a way to understand and generalize the critical design factors used and to extend findings into their design research, and second, as an iterative design and development process model, learner-user experience (LUX) design, extensible to other domains. © 2020 Owner/Author.","augmented reality; bioacoustics; data visualization; immersive; informal learning; information fidelity; interactive; multimodal; museums","Exhibitions; User experience; User interfaces; Creation process; Critical design; Design process; Design research; Iterative design; Knowledge artifacts; Museum exhibits; Natural history; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85091986221
"Hartless J.F., Ayer S.K., London J.S., Wu W.","57208328848;55358381000;38561546100;55707471100;","Comparison of Building Design Assessment Behaviors of Novices in Augmented-and Virtual-Reality Environments",2020,"Journal of Architectural Engineering","26","2", 04020002,"","",,2,"10.1061/(ASCE)AE.1943-5568.0000396","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082121907&doi=10.1061%2f%28ASCE%29AE.1943-5568.0000396&partnerID=40&md5=56136f424798e28dea0e25c612fa4a0b","Emerging Technologies BIM Research Group, School of Sustainable Engineering and the Built Environment, Arizona State Univ., 660 S. College Ave., Tempe, AZ  85281, United States; Dept. of Engineering Education, Virginia Tech, 363 Goodwin Hall, 635 Prices Fork Rd., Blacksburg, VA  24061, United States; Lyles College of Engineering, Californian State Univ. Fresno, 2320 E San Ramon Ave., Fresno, CA  93740, United States","Hartless, J.F., Emerging Technologies BIM Research Group, School of Sustainable Engineering and the Built Environment, Arizona State Univ., 660 S. College Ave., Tempe, AZ  85281, United States; Ayer, S.K., Emerging Technologies BIM Research Group, School of Sustainable Engineering and the Built Environment, Arizona State Univ., 660 S. College Ave., Tempe, AZ  85281, United States; London, J.S., Dept. of Engineering Education, Virginia Tech, 363 Goodwin Hall, 635 Prices Fork Rd., Blacksburg, VA  24061, United States; Wu, W., Lyles College of Engineering, Californian State Univ. Fresno, 2320 E San Ramon Ave., Fresno, CA  93740, United States","Design and construction professionals must make well-informed decisions for every project that meets both industry standards and building codes and also the specific needs of building users and clients. In order to make effective decisions, research suggests that explicit knowledge, defined as easily codified and communicated information, and tacit knowledge, considered to be the know-how of completing a task, must be effectively applied. While there is recognition of the need for both forms of knowledge, architecture engineering and construction (AEC) education has historically focused on covering content-related explicit knowledge in the classroom. As a result, students generally develop tacit knowledge over their careers. Due to an aging AEC workforce, there is a need to support tacit knowledge development in the classroom to enable students entering the industry to supplement the collective tacit knowledge that will exit the industry as the current generation of practitioners retires. Therefore, the authors of this paper explore the use of augmented reality (AR) and virtual reality (VR) to provide immersive virtual experiences aimed at replicating the types of scenarios that students might experience in their careers that would require them to apply tacit knowledge. The authors tasked students in construction-related disciplines with assessing a building design and making judgments about how the design should be modified to support an occupant in a wheelchair in both VR and AR. Using two similar models and a counterbalanced research methodology, the authors coded the statements and behaviors of the student participants during this design assessment exercise. The results of this work indicate that both technologies elicited statements that were indicative of explicit knowledge related to the needs of a wheelchair-bound occupant. When AR and VR were found to directly encourage physical exploration in the experience, both led to behaviors that simulated the completion of tasks that might be performed by a wheelchair-bound occupant. These behaviors were frequently followed by comments that were indicative of tacit knowledge. While this type of behavior was observed in both AR and VR, AR seemed to more directly encourage this type of interaction among participants. The contribution of this work is in providing observational evidence to demonstrate how the physical exploration affordances of AR and VR may be able to support experiences that foster the use and development of tacit knowledge related to AEC-related decision-making. © 2020 American Society of Civil Engineers.",,"Architectural design; Augmented reality; Building codes; Construction; Decision making; Education computing; Students; Technology transfer; Virtual reality; Wheelchairs; Architecture engineering; Augmented and virtual realities; Current generation; Design and construction; Design assessments; Explicit knowledge; Industry standards; Research methodologies; Structural design",Article,"Final","",Scopus,2-s2.0-85082121907
"Mogessie M., Wolf S.D., Barbosa M., Jones N., McLaren B.M.","57209507489;56839569300;57219194303;57219201077;25652179400;","Work-in-Progress-A Generalizable Virtual Reality Training and Intelligent Tutor for Additive Manufacturing",2020,"Proceedings of 6th International Conference of the Immersive Learning Research Network, iLRN 2020",,, 9155119,"355","358",,,"10.23919/iLRN47897.2020.9155119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091627468&doi=10.23919%2fiLRN47897.2020.9155119&partnerID=40&md5=34bb3ec1e1c3c639d26419a77d160553","Carnegie Mellon University, Human-Computer Interaction Institute, Pittsburgh, PA, United States; Carnegie Mellon University, Next Manufacturing Center, Pittsburgh, PA, United States","Mogessie, M., Carnegie Mellon University, Human-Computer Interaction Institute, Pittsburgh, PA, United States; Wolf, S.D., Carnegie Mellon University, Next Manufacturing Center, Pittsburgh, PA, United States; Barbosa, M., Carnegie Mellon University, Human-Computer Interaction Institute, Pittsburgh, PA, United States; Jones, N., Carnegie Mellon University, Next Manufacturing Center, Pittsburgh, PA, United States; McLaren, B.M., Carnegie Mellon University, Human-Computer Interaction Institute, Pittsburgh, PA, United States","There is currently significant demand for training in how to use metals additive manufacturing (AM) machines. Such training is important not only for the technicians who run and maintain the machines, but also for engineers and strategic decision makers who need to support AM part fabrication. Furthermore, there are a variety of AM machines, each with different details to be learned and potential hazards to overcome, and it is difficult to train more than a handful of users at one time. To address these challenges, a prototype training system has been developed, the AM Training Tutor, which uses interactive virtual reality (VR) to train users on a specific AM machine-the EOS M290. To make the training technology more widely available and expand its use across a variety of different AM machines, efforts are underway to develop a modularized and generic version of the AM Training Tutor that can be customized with relatively little effort to train users to operate other AM machines. This work-in-progress paper details the progress to-date, challenges and proposed solutions with the aim to demonstrate how standalone VR-based training systems can be redesigned for relatively easy repurposing and generalization. © 2020 Immersive Learning Research Network.","3D printing; additive manufacturing; advanced manufacturing; cognitive tutor; generalized VR; VR-based training; workforce training","3D printers; Additives; Decision making; E-learning; Virtual addresses; Virtual reality; Intelligent tutors; Interactive virtual reality; Potential hazards; Repurposing; Strategic decisions; Training Systems; Virtual reality training; Work in progress; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-85091627468
"Harrington M.C.R.","36836717500;","Connecting User Experience to Learning in an Evaluation of an Immersive, Interactive, Multimodal Augmented Reality Virtual Diorama in a Natural History Museum & the Importance of Story",2020,"Proceedings of 6th International Conference of the Immersive Learning Research Network, iLRN 2020",,, 9155202,"70","78",,1,"10.23919/iLRN47897.2020.9155202","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091628294&doi=10.23919%2fiLRN47897.2020.9155202&partnerID=40&md5=f7fa4d4c17bd27da4a85962abc7a79ac","University of Central Florida, Games and Interactive Media, Orlando, FL, United States","Harrington, M.C.R., University of Central Florida, Games and Interactive Media, Orlando, FL, United States","Reported are the findings of user experience and learning outcomes from a July 2019 study of an immersive, interactive, multimodal augmented reality (AR) application, used in the context of a museum. The AR Perpetual Garden App is unique in creating an immersive multisensory experience of data. It allowed scientifically naïve visitors to walk into a virtual diorama constructed as a data visualization of a springtime woodland understory and interact with multimodal information directly through their senses. The user interface comprised of two different AR data visualization scenarios reinforced with data based ambient bioacoustics, an audio story of the curator's narrative, and interactive access to plant facts. While actual learning and dwell times were the same between the AR app and the control condition, the AR experience received higher ratings on perceived learning. The AR interface design features of ""Story""and ""Plant Info""showed significant correlations with actual learning outcomes, while ""Ease of Use""and ""3D Plants""showed significant correlations with perceived learning. As such, designers and developers of AR apps can generalize these findings to inform future designs. © 2020 Immersive Learning Research Network.","augmented reality; bioacoustics; data visualization; immersive; informal learning; information fidelity; interactive; multimodal; museums; narrative; photorealistic; place illusion; presence; virtual dioramas; virtual reality","Augmented reality; Data visualization; Museums; User experience; User interfaces; Virtual reality; Visualization; Ease-of-use; Future designs; Interface design features; Learning outcome; Multi-modal information; Multisensory; Natural history; Perceived learning; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85091628294
"Eng C.M., Calkosz D.M., Yang S.Y., Williams N.C., Thiessen E.D., Fisher A.V.","57212590978;57219202932;57219198136;57219195594;6602516755;7403451526;","Doctoral Colloquium-Enhancing Brain Plasticity and Cognition Utilizing Immersive Technology and Virtual Reality Contexts for Gameplay",2020,"Proceedings of 6th International Conference of the Immersive Learning Research Network, iLRN 2020",,, 9155120,"395","398",,1,"10.23919/iLRN47897.2020.9155120","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091675073&doi=10.23919%2fiLRN47897.2020.9155120&partnerID=40&md5=e68c98567586bfbe5574b8caacb775bc","Carnegie Mellon University, Department of Psychology, Pittsburgh, United States; Carnegie Mellon University, Computer Science, Pittsburgh, United States; Carnegie Mellon University, Information Systems, Pittsburgh, United States; Carnegie Mellon University Logic and Computation, Pittsburgh, United States","Eng, C.M., Carnegie Mellon University, Department of Psychology, Pittsburgh, United States; Calkosz, D.M., Carnegie Mellon University, Computer Science, Pittsburgh, United States; Yang, S.Y., Carnegie Mellon University, Information Systems, Pittsburgh, United States; Williams, N.C., Carnegie Mellon University Logic and Computation, Pittsburgh, United States; Thiessen, E.D., Carnegie Mellon University, Department of Psychology, Pittsburgh, United States; Fisher, A.V., Carnegie Mellon University, Department of Psychology, Pittsburgh, United States","This work-in-progress paper examines the effects of immersive virtual experiences on cognition and neuroplasticity. Study 1 examined the separate and combined effects of physically active and cognitively demanding immersive gameplay on executive function and associated neural substrates. Results indicated that cognition and neuroplasticity-the building of new brain connections-increase when learning novel skills via active gameplay. Study 2 devised an experimental design to reproduce Study 1 in virtual reality to examine whether the findings of enhanced cognition and neuroplasticity generalize across virtual contexts and development. Incorporating neuroimaging measures into virtual experiences may identify the underlying mechanisms for behavioral changes in learning. © 2020 Immersive Learning Research Network.","executive function; exergames; neuroplasticity","Neuroimaging; Neurophysiology; Behavioral changes; Brain plasticity; Combined effect; Executive function; Immersive technologies; Neural substrates; Virtual contexts; Work in progress; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85091675073
"Johnson D., Damian D., Tzanetakis G.","57214167710;57192297254;6602262192;","Evaluating the effectiveness of mixed reality music instrument learning with the theremin",2020,"Virtual Reality","24","2",,"303","317",,5,"10.1007/s10055-019-00388-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068827721&doi=10.1007%2fs10055-019-00388-8&partnerID=40&md5=7e681b8efa8420e7e54ec8a41f3173ea","University of Victoria, 3800 Finnerty Rd, Victoria, BC  V8P 5C2, Canada","Johnson, D., University of Victoria, 3800 Finnerty Rd, Victoria, BC  V8P 5C2, Canada; Damian, D., University of Victoria, 3800 Finnerty Rd, Victoria, BC  V8P 5C2, Canada; Tzanetakis, G., University of Victoria, 3800 Finnerty Rd, Victoria, BC  V8P 5C2, Canada","Learning music is a challenging process that requires years of practice to master, either with lessons from a professional teacher or through self-teaching. While practicing, students are expected to self-evaluate their performance which may be difficult without timely feedback from a professional. Research into computer-assisted music instrument tutoring (CAMIT) attempts to address this through the use of emerging technologies. In this paper, we study CAMIT for mixed reality (MR) by developing MR:emin, an immersive MR music learning environment for the theremin, an electronic music instrument that is controlled without physical contact. MR:emin integrates a physical theremin with the immersive learning environment. To better understand the effectiveness of such environments, we perform a user study with MR:emin comparing traditional music learning with two virtual learning environments, an immersive one and a non-immersive one. In a between-groups study, 30 participants were trained to play a sequence of notes on the theremin using one of the three training environments. Results of our statistical analysis show that performance error during training is significantly smaller in the immersive MR environment. This does not necessarily lead to improved performance after training; analysis of post-training improvement indicates that immersive training results in the smallest amount of improvement. Participants, however, indicate that the MR:emin environment is more engaging and increases confidence during practice. We discuss potential factors leading to the decrease in learning and provide some environment guidelines to aid in the design of engaging immersive music learning environments. © 2019, Springer-Verlag London Ltd., part of Springer Nature.","Immersive learning environments; Learning transfer; Mixed reality; Music pedagogy; Training","Computer aided instruction; Computer music; Mixed reality; Personnel training; Emerging technologies; Environment guidelines; Immersive learning; Learning environments; Learning Transfer; Music pedagogy; Performance error; Virtual learning environments; E-learning",Article,"Final","",Scopus,2-s2.0-85068827721
"Glaser N.J., Schmidt M.","57194409345;55267409100;","Usage Considerations of 3D Collaborative Virtual Learning Environments to Promote Development and Transfer of Knowledge and Skills for Individuals with Autism",2020,"Technology, Knowledge and Learning","25","2",,"315","322",,1,"10.1007/s10758-018-9369-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049893405&doi=10.1007%2fs10758-018-9369-9&partnerID=40&md5=ec331a7b776d07c1656ee62853c19f21","School of Education, College of Education, Criminal Justice, and Human Services, University of Cincinnati, PO Box 210002, Teachers/Dyer Hall, Cincinnati, OH  45221, United States","Glaser, N.J., School of Education, College of Education, Criminal Justice, and Human Services, University of Cincinnati, PO Box 210002, Teachers/Dyer Hall, Cincinnati, OH  45221, United States; Schmidt, M., School of Education, College of Education, Criminal Justice, and Human Services, University of Cincinnati, PO Box 210002, Teachers/Dyer Hall, Cincinnati, OH  45221, United States","This emerging technology report explores three-dimensional collaborative virtual learning environments (3D CVLEs) as an intervention modality with potential to foster development of knowledge and skills for people with autism spectrum disorder (ASD). Affordances and unique characteristics of 3D CVLEs are detailed and considered from the perspectives of learning, instruction, and assessment. Research suggests that 3D CVLEs can promote acquisition of social and communicative competencies for individuals with ASD in a safe and controllable manner. However, substantial challenges still exist related to overexposure and cybersickness. This report provides an analysis of current trends in the field, along with considerations of relevance and integration challenges with this unique learner population. Implications for further research are discussed. © 2018, Springer Nature B.V.","3D collaborative virtual learning environments; 3D CVLE; Autism interventions; Autism spectrum; Disorder; Technological interventions; Virtual reality","Computer aided instruction; Diseases; Knowledge management; Virtual reality; 3D-CVLE; Autism intervention; Autism spectrum; Collaborative virtual learning environments; Disorder; Technological interventions; E-learning",Article,"Final","",Scopus,2-s2.0-85049893405
"Jacquesson T., Simon E., Dauleac C., Margueron L., Robinson P., Mertens P.","45161264700;14013750500;57201979055;57215599357;57214027278;55974579600;","Stereoscopic three-dimensional visualization: interest for neuroanatomy teaching in medical school",2020,"Surgical and Radiologic Anatomy","42","6",,"719","727",,2,"10.1007/s00276-020-02442-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081412005&doi=10.1007%2fs00276-020-02442-6&partnerID=40&md5=7b6514283ab156eafe2bb873948d86f5","Department of Anatomy, Faculté de médecine Lyon-Est, Université de Lyon, Université Claude Bernard Lyon I, 8 Avenue Rockefeller, Lyon, 69003, France; Skull Base Multi-Disciplinary Unit, Department of Neurosurgery, Neurological Hospital Pierre Wertheimer, Hospices Civils de Lyon, 59 Bd Pinel, Lyon, 69677, France; Department of Clinical Research and Innovation, Hospices Civils de Lyon, Lyon, France; Department of Functional Neurosurgery, Neurological Hospital Pierre Wertheimer, Hospices Civils de Lyon, 59 Bd Pinel, Lyon, 69677, France","Jacquesson, T., Department of Anatomy, Faculté de médecine Lyon-Est, Université de Lyon, Université Claude Bernard Lyon I, 8 Avenue Rockefeller, Lyon, 69003, France, Skull Base Multi-Disciplinary Unit, Department of Neurosurgery, Neurological Hospital Pierre Wertheimer, Hospices Civils de Lyon, 59 Bd Pinel, Lyon, 69677, France; Simon, E., Department of Anatomy, Faculté de médecine Lyon-Est, Université de Lyon, Université Claude Bernard Lyon I, 8 Avenue Rockefeller, Lyon, 69003, France, Department of Functional Neurosurgery, Neurological Hospital Pierre Wertheimer, Hospices Civils de Lyon, 59 Bd Pinel, Lyon, 69677, France; Dauleac, C., Department of Anatomy, Faculté de médecine Lyon-Est, Université de Lyon, Université Claude Bernard Lyon I, 8 Avenue Rockefeller, Lyon, 69003, France; Margueron, L., Department of Anatomy, Faculté de médecine Lyon-Est, Université de Lyon, Université Claude Bernard Lyon I, 8 Avenue Rockefeller, Lyon, 69003, France; Robinson, P., Department of Clinical Research and Innovation, Hospices Civils de Lyon, Lyon, France; Mertens, P., Department of Anatomy, Faculté de médecine Lyon-Est, Université de Lyon, Université Claude Bernard Lyon I, 8 Avenue Rockefeller, Lyon, 69003, France, Department of Functional Neurosurgery, Neurological Hospital Pierre Wertheimer, Hospices Civils de Lyon, 59 Bd Pinel, Lyon, 69677, France","Purpose: The anatomy of both the brain and the skull is particularly difficult to learn and to teach. Since their anatomical structures are numerous and gathered in a complex tridimensional (3D) architecture, classic schematical drawing or photography in two dimensions (2D) has difficulties in providing a clear, simple, and accurate message. Advances in photography and computer sciences have led to develop stereoscopic 3D visualization, firstly for entertainment then for education. In the present study, we report our experience of stereoscopic 3D lecture for neuroanatomy teaching to early medical school students. Methods: High-resolution specific pictures were taken on various specimen dissections in the Anatomy Laboratory of the University of Lyon, France. Selected stereoscopic 3D views were displayed on a large dedicated screen using a doubled video projector. A 2-h stereoscopic neuroanatomy lecture was given by two neuroanatomists to third-year medicine students who wore passive 3D glasses. Setting up lasted 30 min and involved four people. The feedback from students was collected and analyzed. Results: Among the 483 students who have attended the stereoscopic 3D lecture, 195 gave feedback, and all (100%) were satisfied. Among these, 190 (97.5%) reported a better knowledge transfer of brain anatomy and its 3D architecture. Furthermore, 167 (86.1%) students felt it could change their further clinical practice, 179 (91.8%) thought it could enhance their results in forthcoming anatomy examinations, and 150 (76.9%) believed such a 3D lecture might allow them to become better physicians. This 3D anatomy lecture was graded 8.9/10 a mean against 5.9/10 for previous classical 2D lectures. Discussion–conclusion: The stereoscopic 3D teaching of neuroanatomy made medical students enthusiastic involving digital technologies. It could improve their anatomical knowledge and test scores, as well as their clinical competences. Depending on university means and the commitment of teachers, this new tool should be extended to other anatomical fields. However, its setting up requires resources from faculties and its impact on clinical competencies needs to be objectively assessed. © 2020, Springer-Verlag France SAS, part of Springer Nature.","Anatomy; Pedagogy; Stereoscopy; Teaching; Tridimensional","anatomical concepts; Article; brain tissue; clinical competence; clinical practice; dissection; feedback system; human; medical education; medical examination; medical school; medical student; neuroanatomy; personal experience; priority journal; professional knowledge; stereoscopic vision; student satisfaction; teaching; three-dimensional imaging; anatomic model; anatomy and histology; brain; devices; diagnostic imaging; education; France; medical education; neuroanatomy; photography; procedures; questionnaire; skull; teaching; three-dimensional imaging; Brain; Dissection; Education, Medical, Undergraduate; France; Humans; Imaging, Three-Dimensional; Models, Anatomic; Neuroanatomy; Photography; Schools, Medical; Skull; Students, Medical; Surveys and Questionnaires; Teaching",Article,"Final","",Scopus,2-s2.0-85081412005
"Sherman G.D., Türkay S., Moulton S.T., Friedman M.C., Darani N., Daly B., Kayden S.","21834656400;36544543100;23390455500;51161154600;6504200671;57204125112;54386994300;","The generalized sense of power is a psychological resource: Evidence from a disaster response field training exercise",2020,"European Journal of Social Psychology","50","4",,"733","748",,,"10.1002/ejsp.2644","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076930839&doi=10.1002%2fejsp.2644&partnerID=40&md5=a48f2d75a47135554e26d3f729ed0b97","College of Business, State University of New York at Stony Brook, Stony Brook, NY, United States; Harvard Initiative for Learning and Teaching, Harvard University, Cambridge, MA, United States; Harvard Humanitarian Initiative, Harvard University, Cambridge, MA, United States; Harvard Medical School, Boston, MA, United States; Queensland University of Technology, Brisbane, Qld, Australia; Panorama Education, Boston, MA, United States; Wayfair LLC, Boston, MA, United States; 11th Hour Project, Schmidt Family Foundation, Palo Alto, CA, United States; Department of Executive Education, Henry W. Bloch School of Management, University of Missouri-Kansas City, Kansas City, MO, United States","Sherman, G.D., College of Business, State University of New York at Stony Brook, Stony Brook, NY, United States; Türkay, S., Harvard Initiative for Learning and Teaching, Harvard University, Cambridge, MA, United States, Queensland University of Technology, Brisbane, Qld, Australia; Moulton, S.T., Harvard Initiative for Learning and Teaching, Harvard University, Cambridge, MA, United States, Panorama Education, Boston, MA, United States; Friedman, M.C., Harvard Initiative for Learning and Teaching, Harvard University, Cambridge, MA, United States, Wayfair LLC, Boston, MA, United States; Darani, N., Harvard Humanitarian Initiative, Harvard University, Cambridge, MA, United States, 11th Hour Project, Schmidt Family Foundation, Palo Alto, CA, United States; Daly, B., Harvard Humanitarian Initiative, Harvard University, Cambridge, MA, United States, Department of Executive Education, Henry W. Bloch School of Management, University of Missouri-Kansas City, Kansas City, MO, United States; Kayden, S., Harvard Humanitarian Initiative, Harvard University, Cambridge, MA, United States, Harvard Medical School, Boston, MA, United States","We examined whether the generalized sense of power—the belief that one is able to influence others in one's various social relationships—serves as a psychological resource that enables leadership in high-stakes, unfamiliar group challenges, such as emergencies or crises. We studied current and prospective humanitarian aid professionals (N = 180) during a major field training exercise: a three-day, immersive simulated humanitarian crisis. Individuals who entered the simulated crisis with a greater sense of power in their social relationships experienced lower stress (anxiety), behaved more assertively, and left the simulation with a relatively heightened desire to lead, despite not being deemed better leaders by their teammates. Lacking an initial sense of power was associated with experiences (e.g., feeling timid) that undermined the desire to lead. These results suggest that the psychological sense of power is a key leadership resource, without which one may be at risk of self-selecting out of leadership. © 2019 John Wiley & Sons, Ltd.","challenge; motivation; power; psychological resource; stress","adult; anxiety; article; controlled study; disaster; exercise; female; human; leadership; major clinical study; male; motivation; prospective study; simulation; social interaction; stress",Article,"Final","",Scopus,2-s2.0-85076930839
"Tcha-Tokey K., Schmidt C.T., Geslin E., Richir S.","57188737906;14036157300;36168103100;55917685500;","Improving humans enhancing the complex sociological being with the virtual",2020,"ACM International Conference Proceeding Series",,,,"","",,,"10.1145/3396339.3396401","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086142743&doi=10.1145%2f3396339.3396401&partnerID=40&md5=21e5057c9f2f7522f43367755992b898","Polytech Nantes University, Arts et Metiers Institute of Technology, LAMPA, HESAM Université, Change, F-53810, France; Le Mans University and Arts et Metiers, Institute of Technology, LAMPA, HESAM Université, Change, F-53810, France; UCO Laval and Arts et Metiers, Institute of Technology, LAMPA, HESAM Université, Change, F-53810, France; Arts et Metiers Institute of Technology, LAMPA, HESAM Université, Change, F-53810, France","Tcha-Tokey, K., Polytech Nantes University, Arts et Metiers Institute of Technology, LAMPA, HESAM Université, Change, F-53810, France; Schmidt, C.T., Le Mans University and Arts et Metiers, Institute of Technology, LAMPA, HESAM Université, Change, F-53810, France; Geslin, E., UCO Laval and Arts et Metiers, Institute of Technology, LAMPA, HESAM Université, Change, F-53810, France; Richir, S., Arts et Metiers Institute of Technology, LAMPA, HESAM Université, Change, F-53810, France","In this paper, we argue in favour of using an immersive Virtual Environment (VE) in order to improve human capabilities. We develop this idea in order to advance the potential of VEs in enhancing humans. Training with VEs has proven in some cases to be more efficient than training in real world situations in terms of the reduction of time consumption, risk reduction, easily presenting specific simulation realism, all of which improve learning capabilities. The VE would be an environment for extending human capabilities, the goal being to increase experiences. This last affirmation could renew the scope of action for AH research: acquiring new needed capabilities from the virtual world that would be usable in both worlds, real and virtual. © 2020 Association for Computing Machinery.","Augmented human; Complex system; Knowledge transfer; Novel therapeutic discovery; Virtual environment","Human capability; Immersive virtual environments; Learning capabilities; Real world situations; Risk reductions; Time consumption; Virtual worlds; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85086142743
"Streuber S., Saalfeld P., Podulski K., Hüttl F., Huber T., Buggenhagen H., Boedecker C., Preim B., Hansen C.","57220273134;56537022300;57219598585;57214720246;18535462800;6505541978;57216913553;57195333478;55890379200;","Training of patient handover in virtual reality",2020,"Current Directions in Biomedical Engineering","6","1", 20200040,"","",,,"10.1515/cdbme-2020-0040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094109314&doi=10.1515%2fcdbme-2020-0040&partnerID=40&md5=731ca08cb53a069a29a16c9e92962315","Faculty of Computer Science and Research Campus STIMULATE, Otto-von-Guericke University Magdeburg, Magdeburg, Germany; Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Mainz, Germany; Rudolph-Frey-Lernklinik, University Medicine of the Johannes Gutenberg-University Mainz, Mainz, Germany","Streuber, S., Faculty of Computer Science and Research Campus STIMULATE, Otto-von-Guericke University Magdeburg, Magdeburg, Germany; Saalfeld, P., Faculty of Computer Science and Research Campus STIMULATE, Otto-von-Guericke University Magdeburg, Magdeburg, Germany; Podulski, K., Faculty of Computer Science and Research Campus STIMULATE, Otto-von-Guericke University Magdeburg, Magdeburg, Germany; Hüttl, F., Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Mainz, Germany; Huber, T., Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Mainz, Germany; Buggenhagen, H., Rudolph-Frey-Lernklinik, University Medicine of the Johannes Gutenberg-University Mainz, Mainz, Germany; Boedecker, C., Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Mainz, Germany; Preim, B., Faculty of Computer Science and Research Campus STIMULATE, Otto-von-Guericke University Magdeburg, Magdeburg, Germany; Hansen, C., Faculty of Computer Science and Research Campus STIMULATE, Otto-von-Guericke University Magdeburg, Magdeburg, Germany","Patient handover is an important part for information transfer between medical professionals in a clinical setting. Yet, in current medical education, these conversations are only trained sparsely, since they are costly to perform as they take place in offsite courses and are led by experts over several days. Virtual reality (VR)-based training courses could increase the availability of training, by eliminating travel costs and reducing the time-commitment of the teaching experts. This work presents a VR prototype of a multi-user training and examination application for patient handover. To ensure a similar interaction quality to its current real world counterpart, this work used omni-directional video recordings to create a realistic setting and compared different projection methods. A pilot study highlighted distinct use-cases of sphere and mesh projections to visualize the recordings. The results suggest enhanced spatial presence relating to the usage of omni-directional videos in VR-applications. © 2020 Sebastian Streuber et al., published by De Gruyter, Berlin/Boston 2020.","human-computer-interaction; medical training; patient handover; virtual reality",,Article,"Final","",Scopus,2-s2.0-85094109314
"Heravi N., Yuan W., Okamura A.M., Bohg J.","57219438768;57216124044;7103344370;35071071500;","Learning an Action-Conditional Model for Haptic Texture Generation",2020,"Proceedings - IEEE International Conference on Robotics and Automation",,, 9197447,"11088","11095",,,"10.1109/ICRA40945.2020.9197447","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092709202&doi=10.1109%2fICRA40945.2020.9197447&partnerID=40&md5=bab2a2b0b30322aa9c870f170ab86acd","Stanford University, Department of Mechanical Engineering, United States","Heravi, N., Stanford University, Department of Mechanical Engineering, United States; Yuan, W., Stanford University, Department of Mechanical Engineering, United States; Okamura, A.M., Stanford University, Department of Mechanical Engineering, United States; Bohg, J., Stanford University, Department of Mechanical Engineering, United States","Rich haptic sensory feedback in response to user interactions is desirable for an effective, immersive virtual reality or teleoperation system. However, this feedback depends on material properties and user interactions in a complex, non-linear manner. Therefore, it is challenging to model the mapping from material and user interactions to haptic feedback in a way that generalizes over many variations of the user's input. Current methodologies are typically conditioned on user interactions, but require a separate model for each material. In this paper, we present a learned action-conditional model that uses data from a vision-based tactile sensor (GelSight) and user's action as input. This model predicts an induced acceleration that could be used to provide haptic vibration feedback to a user. We trained our proposed model on a publicly available dataset (Penn Haptic Texture Toolkit) that we augmented with GelSight measurements of the different materials. We show that a unified model over all materials outperforms previous methods and generalizes to new actions and new instances of the material categories in the dataset. © 2020 IEEE.",,"Agricultural robots; Robotics; Sensory feedback; Textures; Virtual reality; Conditional models; Haptic feedbacks; Immersive virtual reality; Induced accelerations; Teleoperation systems; Unified Modeling; User interaction; Vibration feedback; Feedback",Conference Paper,"Final","",Scopus,2-s2.0-85092709202
"Leal A.F., Da Silva T.D., Lopes P.B., Bahadori S., De Araújo L.V., Da Costa M.V.B., De Moraes Í.A.P., Marques R.H., Crocetta T.B., De Abreu L.C., Monteiro C.B.D.M.","57204267800;55546962700;57203415815;57192925491;57195720273;57216643925;57195930904;57216644454;54898013000;57192659178;55481862300;","The use of a task through virtual reality in cerebral palsy using two different interaction devices (concrete and abstract) - A cross-sectional randomized study",2020,"Journal of NeuroEngineering and Rehabilitation","17","1", 59,"","",,3,"10.1186/s12984-020-00689-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084169322&doi=10.1186%2fs12984-020-00689-z&partnerID=40&md5=caef0f1dc8abcbee12236b6afe49cad4","Laboratório de Desenho e Escrita Científica, Departamento de Ciências Básicas, Faculdade de Medicina Do ABC, Santo André, SP, Brazil; Departamento de Cardiologia, Escola Paulista de Medicina, Universidade Federal de São Paulo, São Paulo, SP, Brazil; Grupo de Pesquisa e Aplicações Tecnológicas em Reabilitação, Escola de Artes, Ciências e Humanidades - EACH, Universidade de São Paulo, São Paulo, SP, Brazil; Faculdade de Medicina, Universidade Cidade de São Paulo - UNICID, São Paulo, SP, Brazil; Programa de Pós-Graduação em Ciências da Reabilitação, Faculdade de Medicina, Universidade de São Paulo, Rua Cipotânea, 15, São Paulo, SP, CEP: 05360-160, Brazil; Orthopaedic Research Institute, Bournemouth University, Executive Business Centre, Holdenhurst Road, Bournemouth, BH8 8EB, United Kingdom; Programa de Pós-Graduação em Bioengenharia, Universidade Brasil, São Paulo, SP, Brazil; Secretaria de Tecnologia da Informação e Comunicação, Universidade Do Estado de Santa Catarina - UDESC, Florianópolis, SC, Brazil","Leal, A.F., Laboratório de Desenho e Escrita Científica, Departamento de Ciências Básicas, Faculdade de Medicina Do ABC, Santo André, SP, Brazil, Departamento de Cardiologia, Escola Paulista de Medicina, Universidade Federal de São Paulo, São Paulo, SP, Brazil; Da Silva, T.D., Departamento de Cardiologia, Escola Paulista de Medicina, Universidade Federal de São Paulo, São Paulo, SP, Brazil, Grupo de Pesquisa e Aplicações Tecnológicas em Reabilitação, Escola de Artes, Ciências e Humanidades - EACH, Universidade de São Paulo, São Paulo, SP, Brazil, Faculdade de Medicina, Universidade Cidade de São Paulo - UNICID, São Paulo, SP, Brazil, Programa de Pós-Graduação em Ciências da Reabilitação, Faculdade de Medicina, Universidade de São Paulo, Rua Cipotânea, 15, São Paulo, SP, CEP: 05360-160, Brazil; Lopes, P.B., Departamento de Cardiologia, Escola Paulista de Medicina, Universidade Federal de São Paulo, São Paulo, SP, Brazil; Bahadori, S., Orthopaedic Research Institute, Bournemouth University, Executive Business Centre, Holdenhurst Road, Bournemouth, BH8 8EB, United Kingdom; De Araújo, L.V., Grupo de Pesquisa e Aplicações Tecnológicas em Reabilitação, Escola de Artes, Ciências e Humanidades - EACH, Universidade de São Paulo, São Paulo, SP, Brazil; Da Costa, M.V.B., Grupo de Pesquisa e Aplicações Tecnológicas em Reabilitação, Escola de Artes, Ciências e Humanidades - EACH, Universidade de São Paulo, São Paulo, SP, Brazil; De Moraes, Í.A.P., Grupo de Pesquisa e Aplicações Tecnológicas em Reabilitação, Escola de Artes, Ciências e Humanidades - EACH, Universidade de São Paulo, São Paulo, SP, Brazil, Programa de Pós-Graduação em Ciências da Reabilitação, Faculdade de Medicina, Universidade de São Paulo, Rua Cipotânea, 15, São Paulo, SP, CEP: 05360-160, Brazil; Marques, R.H., Programa de Pós-Graduação em Bioengenharia, Universidade Brasil, São Paulo, SP, Brazil; Crocetta, T.B., Grupo de Pesquisa e Aplicações Tecnológicas em Reabilitação, Escola de Artes, Ciências e Humanidades - EACH, Universidade de São Paulo, São Paulo, SP, Brazil, Secretaria de Tecnologia da Informação e Comunicação, Universidade Do Estado de Santa Catarina - UDESC, Florianópolis, SC, Brazil; De Abreu, L.C., Laboratório de Desenho e Escrita Científica, Departamento de Ciências Básicas, Faculdade de Medicina Do ABC, Santo André, SP, Brazil; Monteiro, C.B.D.M., Laboratório de Desenho e Escrita Científica, Departamento de Ciências Básicas, Faculdade de Medicina Do ABC, Santo André, SP, Brazil, Grupo de Pesquisa e Aplicações Tecnológicas em Reabilitação, Escola de Artes, Ciências e Humanidades - EACH, Universidade de São Paulo, São Paulo, SP, Brazil, Programa de Pós-Graduação em Ciências da Reabilitação, Faculdade de Medicina, Universidade de São Paulo, Rua Cipotânea, 15, São Paulo, SP, CEP: 05360-160, Brazil","Background: Cerebral Palsy (CP) is characterised by variable difficulties in muscular action, resulting in inability of the individual to perform functional movement. An option to provide functionality to the individual with CP is the use of computer innovation. The aim of this paper was to verify if there was any performance improvement in a task performed in a virtual environment and if there was transfer to the task performed in the real environment and vice versa in this population. Methods: A computer program was developed comprising a motor task, but with two possibilities of user interaction: a) concrete interface (with physical contact): in which the individual touches the computer screen to finish the task and b) abstract interface (no physical contact): in which the individual performs a hand movement in front of the Kinect device. Participants were split into two groups. The experimental group consisted of 28 individuals with CP within the ages of 6 and 15 years old. The control group included 28 typically developing individuals mirroring the age and sex of the experimental group. Results: Individuals from both groups were able to improve task performance and retain acquired information. The CP group presented worse performance than the control group in all phases of the study. Further findings showed that the CP group presented better performance in the abstract interface than in the concrete interface, whereas, in the control group, the opposite occurred: their best performance was in the concrete. Conclusions: Motor tasks performed by individuals with CP through an interface with a more virtual environment feature (abstract interface: Kinect) provided better performance when compared to an interface with a more real characteristic (concrete interface: Touchscreen). Trial registration: ClinicalTrials.gov Identifier - NCT03352440; Date of registration - November 17, 2017. © 2020 The Author(s).","Cerebral palsy; Learning; Motor activity; Motor skills; Virtual reality exposure therapy","adaptation; adolescent; Article; cerebral palsy; child; clinical article; clinical practice; contact time; controlled study; cross-sectional study; Gross Motor Function Classification System; hand movement; human; motor activity; motor performance; nerve cell plasticity; preschool child; priority journal; proprioception; randomized controlled trial; school child; tactile stimulation; virtual reality; cerebral palsy; computer interface; female; male; pathophysiology; physiology; video game; Adolescent; Cerebral Palsy; Child; Cross-Sectional Studies; Female; Humans; Male; Motor Skills; User-Computer Interface; Video Games; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85084169322
"Brun D., George S., Gouin-Vallerand C.","57193572581;56911617500;24464753700;","Keycube: Text entry evaluation with a cubic device",2020,"Conference on Human Factors in Computing Systems - Proceedings",,, 3382837,"","",,,"10.1145/3334480.3382837","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090240646&doi=10.1145%2f3334480.3382837&partnerID=40&md5=9f979c43b59c70ab8ef51b249597d339","Université TÉLUQ, Montreal, PQ, Canada; Le Mans University, Le Mans, France; Université de Sherbrooke, Sherbrooke, Canada","Brun, D., Université TÉLUQ, Montreal, PQ, Canada; George, S., Le Mans University, Le Mans, France; Gouin-Vallerand, C., Université de Sherbrooke, Sherbrooke, Canada","The keycube is a tangible cubic device including a text entry interface for different apparatuses such as augmented, mixed or virtual reality headsets, as well as smart TVs, desktop computers, laptops, tablets. The keycube comprises 80 keys equally disposed on 5 faces. In this paper we investigate keycube text entry performances and the potential typing skill transfer from traditional keyboard. Using prototype implementations, we conducted a user study comparing different cubic layouts and included a baseline from traditional keyboards. Experiments show that users are able to attain about 19 words per minute within one hundred minutes of practice with a QWERTY-based cubic layout, more than twice the speed of an unknown-based cubic layout with similar error rate, and about 30% of their speed with a traditional keyboard. © 2020 Owner/Author.","Cube; Device; Evaluation; Input speed; Keyboard; Text entry","Human engineering; Personal computers; Error rate; Prototype implementations; Skill transfer; Text entry; User study; Virtual-reality headsets; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85090240646
"Wentzel J., D'Eon G., Vogel D.","57188763196;57219111871;8435582600;","Improving Virtual Reality Ergonomics Through Reach-Bounded Non-Linear Input Amplification",2020,"Conference on Human Factors in Computing Systems - Proceedings",,, 3376687,"","",,4,"10.1145/3313831.3376687","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091311186&doi=10.1145%2f3313831.3376687&partnerID=40&md5=a2a6f22213bc5a2fc765a1f66b3d95ef","University of Waterloo, Waterloo, ON, Canada; Universiy of British Columbia, Vancouver, BC, Canada","Wentzel, J., University of Waterloo, Waterloo, ON, Canada; D'Eon, G., Universiy of British Columbia, Vancouver, BC, Canada; Vogel, D., University of Waterloo, Waterloo, ON, Canada","Input amplification enables easier movement in virtual reality (VR) for users with mobility issues or in confined spaces. However, current techniques either do not focus on maintaining feelings of body ownership, or are not applicable to general VR tasks. We investigate a general purpose non-linear transfer function that keeps the user's reach within reasonable bounds to maintain body ownership. The technique amplifies smaller movements from a user-definable neutral point into the expected larger movements using a configurable Hermite curve. Two experiments evaluate the approach. The first establishes that the technique has comparable performance to the state-of-the-art, increasing physical comfort while maintaining task performance and body ownership. The second explores the characteristics of the technique over a wide range of amplification levels. Using the combined results, design and implementation recommendations are provided with potential applications to related VR transfer functions. © 2020 ACM.","ergonomics; input re-mapping; interaction techniques","Ergonomics; Virtual reality; Confined space; Design and implementations; Hermite curves; Neutral points; Non linear; State of the art; Task performance; Transfer functions",Conference Paper,"Final","",Scopus,2-s2.0-85091311186
"Shah S.H.H., Han K., Lee J.W.","57210145879;56739751100;8948633800;","Real-time application for generating multiple experiences from 360° panoramic video by tracking arbitrary objects and viewer's orientations",2020,"Applied Sciences (Switzerland)","10","7", 2248,"","",,,"10.3390/app10072248","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083571542&doi=10.3390%2fapp10072248&partnerID=40&md5=1e365e082a2f584e3c6a957dc533296e","Department of Software Convergence, Sejong University, 209 Neungdong-ro, Gwangjin-gu, Seoul, 05006, South Korea","Shah, S.H.H., Department of Software Convergence, Sejong University, 209 Neungdong-ro, Gwangjin-gu, Seoul, 05006, South Korea; Han, K., Department of Software Convergence, Sejong University, 209 Neungdong-ro, Gwangjin-gu, Seoul, 05006, South Korea; Lee, J.W., Department of Software Convergence, Sejong University, 209 Neungdong-ro, Gwangjin-gu, Seoul, 05006, South Korea","We propose a novel authoring and viewing system for generating multiple experiences with a single 360° video and eciently transferring these experiences to the user. An immersive video contains much more interesting information within the 360° environment than normal videos. There can be multiple interesting areas within a 360° frame at the same time. Due to the narrow field of view in virtual reality head-mounted displays, a user can only view a limited area of a 360° video. Hence, our system is aimed at generating multiple experiences based on interesting information in different regions of a 360° video and ecient transferring of these experiences to prospective users. The proposed system generates experiences by using two approaches: (1) Recording of the user's experience when the user watches a panoramic video using a virtual reality head-mounted display, and (2) tracking of an arbitrary interesting object in a 360° video selected by the user. For tracking of an arbitrary interesting object, we have developed a pipeline around an existing simple object tracker to adapt it for 360° videos. This tracking algorithm was performed in real time on a CPU with high precision. Moreover, to the best of our knowledge, there is no such existing system that can generate a variety of different experiences from a single 360° video and enable the viewer to watch one 360° visual content from various interesting perspectives in immersive virtual reality. Furthermore, we have provided an adaptive focus assistance technique for ecient transferring of the generated experiences to other users in virtual reality. In this study, technical evaluation of the system along with a detailed user study has been performed to assess the system's application. Findings from evaluation of the system showed that a single 360° multimedia content has the capability of generating multiple experiences and transfers among users. Moreover, sharing of the 360° experiences enabled viewers to watch multiple interesting contents with less effort. © 2020 by the authors.","360° video experiences; object tracking; Authoring system; Experience transfer; Focus assistance; Human-computer interaction (HCI); Virtual reality; Visualization",,Article,"Final","",Scopus,2-s2.0-85083571542
"Pallavicini F., Pepe A.","6701879031;55744410200;","Virtual reality games and the role of body involvement in enhancing positive emotions and decreasing anxiety: Within-subjects pilot study",2020,"JMIR Serious Games","8","2", e15635,"","",,1,"10.2196/15635","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097499071&doi=10.2196%2f15635&partnerID=40&md5=c7fbb876de190177fb7d8f4c6dfacc7b","Department of Human Sciences for Education, University of Milano-Bicocca, Milan, Italy","Pallavicini, F., Department of Human Sciences for Education, University of Milano-Bicocca, Milan, Italy; Pepe, A., Department of Human Sciences for Education, University of Milano-Bicocca, Milan, Italy","Background: In the last few years, the introduction of immersive technologies, especially virtual reality, into the gaming market has dramatically altered the traditional concept of video games. Given the unique features of virtual reality in terms of interaction and its ability to completely immerse the individual into the game, this technology should increase the propensity for video games to effectively elicit positive emotions and decrease negative emotions and anxiety in the players. However, to date, few studies have investigated the ability of virtual reality games to induce positive emotions, and the possible effect of this new type of video game in diminishing negative emotions and anxiety has not yet been tested. Furthermore, given the critical role of body movement in individuals’ well-being and in emotional responses to video games, it seems critical to investigate how body involvement can be exploited to modulate the psychological benefits of virtual reality games in terms of enhancing players’ positive emotions and decreasing negative emotions and anxiety. Objective: This within-subjects study aimed to explore the ability of commercial virtual reality games to induce positive emotions and diminish negative emotions and state anxiety of the players, investigating the effects of the level of body involvement requested by the game (ie, high vs low). Methods: A total of 36 young adults played a low body-involvement (ie, Fruit Ninja VR) and a high body-involvement (ie, Audioshield) video game in virtual reality. The Visual Analogue Scale (VAS) and the State-Trait Anxiety Inventory, Form-Y1 (STAI-Y1) were used to assess positive and negative emotions and state anxiety. Results: Results of the generalized linear model (GLM) for repeated-measures multivariate analysis of variance (MANOVA) revealed a statistically significant increase in the intensity of happiness (P<.001) and surprise (P=.003) and, in parallel, a significant decrease in fear (P=.01) and sadness (P<.001) reported by the users. Regarding the ability to improve anxiety in the players, the results showed a significant decrease in perceived state anxiety after game play, assessed with both the STAI-Y1 (P=.003) and the VAS-anxiety (P=.002). Finally, the results of the GLM MANOVA showed a greater efficacy of the high body-involvement game (ie, Audioshield) compared to the low body-involvement game (ie, Fruit Ninja VR), both for eliciting positive emotions (happiness, P<.001; and surprise, P=.01) and in reducing negative emotions (fear, P=.05; and sadness, P=.05) and state anxiety, as measured by the STAI-Y1 (P=.05). Conclusions: The two main principal findings of this study are as follows: (1) virtual reality video games appear to be effective tools to elicit positive emotions and to decrease negative emotions and state anxiety in individuals and (2) the level of body involvement of the virtual video game has an important effect in determining the ability of the game to improve positive emotions and decrease negative emotions and state anxiety of the players. © 2020 JMIR Publications. All Rights Reserved.","Anxiety; Emotions; Positive emotions; State anxiety; Video games; Virtual reality; Virtual reality gaming",,Article,"Final","",Scopus,2-s2.0-85097499071
"Frøland T.H., Heldal I., Sjøholt G., Ersvær E.","57215113864;6506576998;8668775300;15019082500;","Games on mobiles via web or virtual reality technologies: How to support learning for biomedical laboratory science education",2020,"Information (Switzerland)","11","4", 195,"","",,2,"10.3390/info11040195","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084759701&doi=10.3390%2finfo11040195&partnerID=40&md5=8830595e0bd0b1b9cae5becc371e2b19","Department of Safety, Chemistry and Biomedical Laboratory Sciences, Western Norway University of Applied Sciences, Bergen, 5063, Norway; Department of Computer Science, Electrical Engineering and Mathematical Sciences, Western Norway University of Applied Sciences, Bergen, 5063, Norway","Frøland, T.H., Department of Safety, Chemistry and Biomedical Laboratory Sciences, Western Norway University of Applied Sciences, Bergen, 5063, Norway; Heldal, I., Department of Computer Science, Electrical Engineering and Mathematical Sciences, Western Norway University of Applied Sciences, Bergen, 5063, Norway; Sjøholt, G., Department of Safety, Chemistry and Biomedical Laboratory Sciences, Western Norway University of Applied Sciences, Bergen, 5063, Norway; Ersvær, E., Department of Safety, Chemistry and Biomedical Laboratory Sciences, Western Norway University of Applied Sciences, Bergen, 5063, Norway","Simulations, serious games, and virtual reality (SSG) applications represent promising support for achieving practical proficiency, but it is difficult to know how to introduce them into a new environment. This paper aims to contribute to a better understanding of introducing new SSGs to a non-computer related educational environment-biomedical laboratory science (BLS) education. By following the choice, construction, and evaluation of a gamified app for practicing phlebotomy (StikkApp), not only the usefulness of the application, but also the general needs and possibilities for supporting SSG applications, are discussed. This paper presents the evaluation of StikkApp through an experimental study examining its use on mobile devices, as a web app and by discussing challenges for a corresponding virtual reality app by BLS students and their teachers. This evaluation focused on questions concerning usage scenarios, technologies, and how the design of the app can be aligned to learning goals necessary for education. By discussing these requirements and possibilities for apps and technology support for using SSG apps for BLS students, this paper contributes to a better understanding of using digital support for sustainable education. © 2020 by the authors.","Biomedical engineering; Education; Evaluation of educational games; Game-based learning; Phlebotomy","Serious games; Students; Technology transfer; Virtual reality; Biomedical laboratories; Educational environment; Science education; Support learning; Sustainable educations; Technology support; Usage scenarios; Virtual reality technology; E-learning",Article,"Final","",Scopus,2-s2.0-85084759701
"Dodsworth C., Norman L.J., Thaler L.","57213270944;47962359900;8606415800;","Navigation and perception of spatial layout in virtual echo-acoustic space",2020,"Cognition","197",, 104185,"","",,3,"10.1016/j.cognition.2020.104185","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077751909&doi=10.1016%2fj.cognition.2020.104185&partnerID=40&md5=6731f36e885f7f2bb55119f5c2c7b0a9","Department of Psychology, Durham University, Durham, DH1 3LE, United Kingdom","Dodsworth, C., Department of Psychology, Durham University, Durham, DH1 3LE, United Kingdom; Norman, L.J., Department of Psychology, Durham University, Durham, DH1 3LE, United Kingdom; Thaler, L., Department of Psychology, Durham University, Durham, DH1 3LE, United Kingdom","Successful navigation involves finding the way, planning routes, and avoiding collisions. Whilst previous research has shown that people can navigate using non-visual cues, it is not clear to what degree learned non-visual navigational abilities generalise to ‘new’ environments. Furthermore, the ability to successfully avoid collisions has not been investigated separately from the ability to perceive spatial layout or to orient oneself in space. Here, we address these important questions using a virtual echolocation paradigm in sighted people. Fourteen sighted blindfolded participants completed 20 virtual navigation training sessions over the course of 10 weeks. In separate sessions, before and after training, we also tested their ability to perceive the spatial layout of virtual echo-acoustic space. Furthermore, three blind echolocation experts completed the tasks without training, thus validating our virtual echo-acoustic paradigm. We found that over the course of 10 weeks sighted people became better at navigating, i.e. they reduced collisions and time needed to complete the route, and increased success rates. This also generalised to ‘new’ (i.e. untrained) virtual spaces. In addition, after training, their ability to judge spatial layout was better than before training. The data suggest that participants acquired a ‘true’ sensory driven navigational ability using echo-acoustics. In addition, we show that people not only developed navigational skills related to avoidance of collisions and finding safe passage, but also processes related to spatial perception and orienting. In sum, our results provide strong support for the idea that navigation is a skill which people can achieve via various modalities, here: echolocation. © 2020 The Authors","Audition; Blindness; Learning; Neuroplasticity; Sonar; Training","acoustics; adult; aged; Article; controlled study; depth perception; echolocation; female; human; male; maze test; normal human; priority journal; virtual reality",Article,"Final","",Scopus,2-s2.0-85077751909
"Chen S., Leng Y., Labi S.","57192303170;57210796820;6505891237;","A deep learning algorithm for simulating autonomous driving considering prior knowledge and temporal information",2020,"Computer-Aided Civil and Infrastructure Engineering","35","4",,"305","321",,15,"10.1111/mice.12495","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071427073&doi=10.1111%2fmice.12495&partnerID=40&md5=240f130d92be944e09298feca4a29915","U.S. DOT Center for Connected and Automated Transportation (CCAT), and Lyles School of Civil Engineering, Purdue University, West Lafayette, IN, United States; Weldon School of Biomedical Engineering, Department of Computer Science, and U.S. DOT Center for Connected and Automated Transportation (CCAT), Purdue University, West Lafayette, IN, United States","Chen, S., U.S. DOT Center for Connected and Automated Transportation (CCAT), and Lyles School of Civil Engineering, Purdue University, West Lafayette, IN, United States; Leng, Y., Weldon School of Biomedical Engineering, Department of Computer Science, and U.S. DOT Center for Connected and Automated Transportation (CCAT), Purdue University, West Lafayette, IN, United States; Labi, S., U.S. DOT Center for Connected and Automated Transportation (CCAT), and Lyles School of Civil Engineering, Purdue University, West Lafayette, IN, United States","Autonomous vehicle (AV) stakeholders continue to seek assurance of the safety performance of this new technology through AV testing on in-service roads, AV-dedicated road networks, and AV test tracks. However, recent AV-related fatalities on in-service roads have exacerbated public skepticism and eroded some public trust in the safety of AV operations. Further, test tracks are unable to characterize adequately the real-world driving environment. For this reason, driving simulators continue to serve as an attractive means of AV testing. However, in most AV driving simulators, the AV operation is based on commands external to the vehicle and embedded in the code for the driving environment. To address the simulation shortfalls associated with this approach, this paper develops a deep convolutional neural network–long short-term memory (CNN–LSTM) algorithm for self-driving simulation. This algorithm observes and characterizes the AV's driving environment, and controls the AV movement in the driving simulation. The CNN part extracts features that use transfer learning to introduce human prior knowledge, and the LSTM part uses temporal information to process the extracted features, and incorporates temporal dynamics to predict driving decisions. The AV may also use an external server with a database containing road environment data as an additional source of information. It is acknowledged that different driving simulators differ in their functions and their capabilities to access driving-environment data. Therefore, to make it sufficiently flexible to facilitate replication by other researchers that use driving simulators, the algorithm has been designed and demonstrated using only image data of the driving environment as input. This is because roadway image data are easily and readily accessible from the screen of any driving simulator. The proposed algorithm was tested using the open racing car simulator test track platform and was found to be able to mimic human driving decisions with a high degree of accuracy. © 2019 Computer-Aided Civil and Infrastructure Engineering",,"Automobile drivers; Automobile simulators; Autonomous vehicles; Deep neural networks; Learning algorithms; Roads and streets; Safety testing; Autonomous driving; Convolutional neural network; Driving environment; High degree of accuracy; Open racing car simulators; Real-world drivings; Safety performance; Temporal information; Long short-term memory; accuracy assessment; algorithm; artificial neural network; decision making; numerical model; performance assessment; public transport; stakeholder; transportation development; transportation planning",Article,"Final","",Scopus,2-s2.0-85071427073
"Lohre R., Bois A.J., Athwal G.S., Goel D.P.","57215864647;55259753500;6603148899;34881653400;","Improved Complex Skill Acquisition by Immersive Virtual Reality Training: A Randomized Controlled Trial",2020,"Journal of Bone and Joint Surgery - American Volume","102","6",,"","",,10,"10.2106/JBJS.19.00982","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082147105&doi=10.2106%2fJBJS.19.00982&partnerID=40&md5=4e329e9a54ded568ebd592911773531d","Department of Orthopaedics, University of British Columbia, Vancouver, BC, Canada; Section of Orthopaedic Surgery, Department of Surgery, University of Calgary, Calgary, AB, Canada; Roth McFarlane Hand and Upper Limb Center, Schulich School of Medicine and Dentistry, Western University, London, ON, Canada","Lohre, R., Department of Orthopaedics, University of British Columbia, Vancouver, BC, Canada; Bois, A.J., Section of Orthopaedic Surgery, Department of Surgery, University of Calgary, Calgary, AB, Canada; Athwal, G.S., Roth McFarlane Hand and Upper Limb Center, Schulich School of Medicine and Dentistry, Western University, London, ON, Canada; Goel, D.P., Department of Orthopaedics, University of British Columbia, Vancouver, BC, Canada","Background:There has been limited literature on immersive virtual reality (VR) simulation in orthopaedic education. The purpose of this multicenter, blinded, randomized controlled trial was to determine the validity and efficacy of immersive VR training in orthopaedic resident education.Methods:Nineteen senior orthopaedic residents (resident group) and 7 consultant shoulder arthroplasty surgeons (expert group) participated in the trial comparing immersive VR with traditional learning using a technical journal article as a control. The examined task focused on achieving optimal glenoid exposure. Participants completed demographic questionnaires, knowledge tests, and a glenoid exposure on fresh-frozen cadavers while being examined by blinded shoulder arthroplasty surgeons. Training superiority was determined by the outcome measures of the Objective Structured Assessment of Technical Skills (OSATS) score, a developed laboratory metric, verbal answers, and time to task completion.Results:Immersive VR had greater realism and was superior in teaching glenoid exposure than the control (p = 0.01). The expert group outperformed the resident group on knowledge testing (p = 0.04). The immersive VR group completed the learning activity and knowledge tests significantly faster (p < 0.001) at a mean time (and standard deviation) of 11 ± 3 minutes than the control group at 20 ± 4 minutes, performing 3 to 5 VR repeats for a reduction in learning time of 570%. The immersive VR group completed the glenoid exposure significantly faster (p = 0.04) at a mean time of 14 ± 7 minutes than the control group at 21 ± 6 minutes, with superior OSATS instrument handling scores (p = 0.03). The immersive VR group scored equivalently in surprise verbal scores (p = 0.85) and written knowledge scores (p = 1.0).Conclusions:Immersive VR demonstrated substantially improved translational technical and nontechnical skills acquisition over traditional learning in senior orthopaedic residents. Additionally, the results demonstrate the face, content, construct, and transfer validity for immersive VR.Clinical Relevance:This adequately powered, randomized controlled trial demonstrated how an immersive VR system can efficiently (570%) teach a complex surgical procedure and also demonstrate improved translational skill and knowledge acquisition when compared with a traditional learning method. © 2020 Lippincott Williams and Wilkins. All rights reserved.",,"Article; cadaver; cohort analysis; comparative study; controlled study; demography; glenoid cavity; human; medical expert; multicenter study; Objective Structured Assessment of Technical Skills score; orthopedic specialist; orthopedic surgeon; orthopedics; priority journal; professional knowledge; questionnaire; randomized controlled trial; residency education; scientific literature; scoring system; shoulder arthroplasty; virtual reality; work experience; Canada; clinical competence; clinical trial; education; medical education; procedures; reproducibility; shoulder replacement; simulation training; single blind procedure; Arthroplasty, Replacement, Shoulder; Canada; Clinical Competence; Humans; Internship and Residency; Orthopedics; Reproducibility of Results; Simulation Training; Single-Blind Method; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85082147105
"Logishetty K., Gofton W.T., Rudran B., Beaulé P.E., Cobb J.P.","35574197100;6508101071;57205023949;7003898709;7202728836;","Fully Immersive Virtual Reality for Total Hip Arthroplasty: Objective Measurement of Skills and Transfer of Visuospatial Performance after a Competency-Based Simulation Curriculum",2020,"Journal of Bone and Joint Surgery - American Volume","102","6", e27,"","",,4,"10.2106/JBJS.19.00629","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082148057&doi=10.2106%2fJBJS.19.00629&partnerID=40&md5=ce3c4083d57c9a883f9025c6bef05f48","MSk Lab, Department of Surgery and Cancer, Imperial College, London, United Kingdom; Division of Orthopaedic Surgery, Ottawa Hospital, Ottawa, ON, Canada","Logishetty, K., MSk Lab, Department of Surgery and Cancer, Imperial College, London, United Kingdom; Gofton, W.T., Division of Orthopaedic Surgery, Ottawa Hospital, Ottawa, ON, Canada; Rudran, B., MSk Lab, Department of Surgery and Cancer, Imperial College, London, United Kingdom; Beaulé, P.E., Division of Orthopaedic Surgery, Ottawa Hospital, Ottawa, ON, Canada; Cobb, J.P., MSk Lab, Department of Surgery and Cancer, Imperial College, London, United Kingdom","Background:Fully immersive virtual reality (VR) uses headsets to situate a surgeon in a virtual operating room to perform open surgical procedures. The aims of this study were to determine (1) if a VR curriculum for training residents to perform anterior approach total hip replacement (AA-THR) was feasible, (2) if VR enabled residents' performance to be measured objectively, and (3) if cognitive and motor skills that were learned with use of VR were transferred to the physical world.Methods:The performance of 32 orthopaedic residents (surgical postgraduate years [PGY]-1 through 4) with no prior experience with AA-THR was measured during 5 consecutive VR training and assessment sessions. Outcome measures were related to procedural sequence, efficiency of movement, duration of surgery, and visuospatial precision in acetabular component positioning and femoral neck osteotomy, and were compared with the performance of 4 expert hip surgeons to establish competency-based criteria. Pretraining and post-training assessments on dry bone models were used to assess the transfer of visuospatial skills from VR to the physical world.Results:Residents progressively developed surgical skills in VR on a learning curve through repeated practice, plateauing, on average, after 4 sessions (4.1 ± 0.6 hours); they reached expert VR levels for 9 of 10 metrics (except femoral osteotomy angle). Procedural errors were reduced by 79%, assistive prompts were reduced by 70%, and procedural duration was reduced by 28%. Dominant and nondominant hand movements were reduced by 35% and 36%, respectively, and head movement was reduced by 44%. Femoral osteotomy was performed more accurately, and acetabular implant orientation improved in VR assessments. In the physical world assessments, experts were more accurate than residents prior to simulation, but were matched by residents after simulation for all of the metrics except femoral osteotomy angle. The residents who performed best in VR were the most accurate in the physical world, while 2 residents were unable to achieve competence despite sustained practice.Conclusions:For novice surgeons learning AA-THR skills, fully immersive VR technology can objectively measure progress in the acquisition of surgical skills as measured by procedural sequence, efficiency of movement, and visuospatial accuracy. Skills learned in this environment are transferred to the physical environment. © 2020 Lippincott Williams and Wilkins. All rights reserved.",,"adult; Article; clinical practice; cognition; depth perception; education program; female; femur osteotomy; hand movement; head movement; human; learning curve; male; motor performance; normal human; operation duration; orthopedic surgeon; outcome assessment; postgraduate education; priority journal; professional competence; residency education; resident; simulation; surgical approach; technology; total hip replacement; virtual reality; anatomic model; Canada; clinical competence; curriculum; economics; education; hip replacement; medical education; orthopedics; procedures; psychomotor performance; simulation training; single blind procedure; Adult; Arthroplasty, Replacement, Hip; Canada; Clinical Competence; Competency-Based Education; Female; Humans; Internship and Residency; Learning Curve; Male; Models, Anatomic; Orthopedics; Psychomotor Performance; Simulation Training; Single-Blind Method; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85082148057
"Xiao S., Ye X., Guo Y., Gao B., Long J.","57216950659;57216952687;57214783652;57054714700;36094130900;","Transfer of Coordination Skill to the Unpracticed Hand in Immersive Environments",2020,"Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2020",,, 9089455,"258","265",,,"10.1109/VR46266.2020.1580775954370","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085471846&doi=10.1109%2fVR46266.2020.1580775954370&partnerID=40&md5=e436207a769c58353b6c079248db0c5a","Jinan University, College of Information Science and Technology, Guangzhou, 510640, China","Xiao, S., Jinan University, College of Information Science and Technology, Guangzhou, 510640, China; Ye, X., Jinan University, College of Information Science and Technology, Guangzhou, 510640, China; Guo, Y., Jinan University, College of Information Science and Technology, Guangzhou, 510640, China; Gao, B., Jinan University, College of Information Science and Technology, Guangzhou, 510640, China; Long, J., Jinan University, College of Information Science and Technology, Guangzhou, 510640, China","Physical practice with one hand results in performance gains of the other (un-practiced) hand in a unilateral motor task. Yet how it induces performance gains of interlimb coordination in the bimanual movements between trained limb and the opposite, untrained limb is unclear. The present study designed a game-like interactive system for physical practice, in which an avatar's hands could be controlled itself or by the subject during a bimanual movement task in an immersive virtual reality environment. Participants practiced with the bimanual task by simultaneously drawing non-symmetric three-sided squares (e.g., U and C) to learn limb coordination with the following training strategies: (1) performing and seeing a bimanual task (BH-BH); (2) performing a unimanual task with right hand and seeing a bimanual action (RH-BH); (3) not performing a task but seeing a bimanual action (noH-BH); (4) performing and seeing a unimanual task (RH-RH). We found that the learning performance was better after BH-BH and RH-BH compared with other training strategies. In addition, we examined the effects of virtual hand representations on the learning performance after RH-BH. We found that the performance after training was increased with the realism level of virtual hands. These findings suggest that the proposed approach of RH-BH with realistic virtual hand would result in transfer of coordination skill to the unpracticed hand, which puts forward a new approach for learning and rehabilitation of coordination skill in patients with unilateral motor deficit in immersive environments. © 2020 IEEE.","Avatar hands; bimanual movement; coordination skill; virtual reality","Patient rehabilitation; Transfer learning; User interfaces; Bimanual movement; Co-ordination skills; Immersive environment; Immersive virtual reality; Interactive system; Learning performance; Performance Gain; Training strategy; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85085471846
"Jakl A., Lienhart A.-M., Baumann C., Jalaeefar A., Schlager A., Schoffer L., Bruckner F.","35242591600;57216955058;57216949185;57216948882;57216950067;57205459948;56562723100;","Enlightening Patients with Augmented Reality",2020,"Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2020",,, 9089476,"195","203",,1,"10.1109/VR46266.2020.1581532258804","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085526448&doi=10.1109%2fVR46266.2020.1581532258804&partnerID=40&md5=4538f04908530fbf0229b5588000429e","University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria","Jakl, A., University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria; Lienhart, A.-M., University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria; Baumann, C., University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria; Jalaeefar, A., University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria; Schlager, A., University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria; Schoffer, L., University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria; Bruckner, F., University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria","Enlightening Patients with Augmented Reality (EPAR) enhances patient education with new possibilities offered by Augmented Reality. Medical procedures are becoming increasingly complex and printed information sheets are often hard to understand for patients. EPAR developed an augmented reality prototype that helps patients with strabismus to better understand the processes of examinations and eye surgeries. By means of interactive storytelling, three identified target groups based on user personas were able to adjust the level of information transfer based on their interests. We performed a 2-phase evaluation with a total of 24 test subjects, resulting in a final system usability score of 80.0. For interaction prompts concerning virtual 3D content, visual highlights were considered to be sufficient. Overall, participants thought that an AR system as a complementary tool could lead to a better understanding of medical procedures. © 2020 IEEE.","concepts and paradigms Human-centered computing; Human-centered computing; Interaction design theory; Interface design prototyping Human-centered computing; Mixed / augmented reality Human-centered computing; Usability testing","Augmented reality; User interfaces; Complementary tools; Information sheets; Information transfers; Interactive storytelling; Medical procedures; Patient education; System usability; Target group; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85085526448
"Kalkofen D., Mori S., Ladinig T., Daling L., Abdelrazeq A., Ebner M., Ortega M., Feiel S., Gabl S., Shepel T., Tibbett J., Laine T.H., Hitch M., Drebenstedt C., Moser P.","24822405100;57216934724;57191445046;57207299893;57209209532;56903912500;57216935226;57201155199;57216938368;56418693800;57189056968;57217452784;26027504900;35614644400;7102945424;","Tools for Teaching Mining Students in Virtual Reality based on 360° Video Experiences",2020,"Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VRW 2020",,, 9090430,"455","459",,1,"10.1109/VRW50115.2020.00096","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085391640&doi=10.1109%2fVRW50115.2020.00096&partnerID=40&md5=dae08611357938adaf178d8e5b5c711c","Graz University of Technology, Austria; Montanuniversit at Leoben, Austria; RWTH Aachen University, Germany; Pilot; Tallinn University of Technology, Estonia; TU Bergakademie Freiberg, Germany; Lulea University of Technology, Sweden","Kalkofen, D., Graz University of Technology, Austria; Mori, S., Graz University of Technology, Austria; Ladinig, T., Montanuniversit at Leoben, Austria; Daling, L., RWTH Aachen University, Germany; Abdelrazeq, A., RWTH Aachen University, Germany; Ebner, M., Graz University of Technology, Austria; Ortega, M., Montanuniversit at Leoben, Austria; Feiel, S., Montanuniversit at Leoben, Austria; Gabl, S., Graz University of Technology, Austria; Shepel, T., TU Bergakademie Freiberg, Germany; Tibbett, J., Pilot; Laine, T.H., Lulea University of Technology, Sweden; Hitch, M., Tallinn University of Technology, Estonia; Drebenstedt, C., TU Bergakademie Freiberg, Germany; Moser, P., Montanuniversit at Leoben, Austria","In recent years, Virtual Reality (VR) technology has found their way into higher education. Its power lays in its ability to provide immersive three-dimensional (3D) experiences that help conveying educational content whilst providing rich interaction possibilities. Especially in mining engineering education, VR has high potential to reshape the provided learning content. Field trips, i.e. mine visits, are an integral part of the education and necessary to transfer knowledge to students. However, field trips are time and cost intensive and mines often have tight entry regulations. As a result, the number of field trips is limited. VR-based field trips offer a considerable alternative presupposed they replicate the complex mining environment realistically. In addition, VR mines have the advantage of taking students close to events (e.g. explosions) that are impossible to demonstrate in a real mine. However, generating realistic 3D content for VR still involves complex, and thus time consuming tasks. Therefore, we present the design of a VR Framework for teaching mining students based on 360° video data, its evaluation in three different lectures, and its extension based on the feedback we received from students and teachers from four different universities. © 2020 IEEE.",,"E-learning; Mining engineering; Students; User interfaces; Cost-intensive; Educational contents; Higher education; ITS evaluation; Learning contents; Mining environments; Threedimensional (3-d); Time-consuming tasks; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85085391640
"Gainer S., Eadara S., Haskins J., Huse W., Zhu B., Boyd B., Laird C., Farantatos J.J., Jerald J.","57210917259;57216937631;57210912110;57210916941;57216935372;57210914790;57210912932;57216935098;6507201978;","A Customized Input Device for Simulating the Detection of Hazardous Materials",2020,"Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VRW 2020",,, 9090446,"7","12",,1,"10.1109/VRW50115.2020.0-267","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085388847&doi=10.1109%2fVRW50115.2020.0-267&partnerID=40&md5=39fb1b83ac3d65296b85cb03779968a6","NextGen Interactions","Gainer, S., NextGen Interactions; Eadara, S., NextGen Interactions; Haskins, J., NextGen Interactions; Huse, W., NextGen Interactions; Zhu, B., NextGen Interactions; Boyd, B., NextGen Interactions; Laird, C., NextGen Interactions; Farantatos, J.J., NextGen Interactions; Jerald, J., NextGen Interactions","Although consumer VR controllers work well for gaming and general VR usage, they are not necessarily appropriate for specific professional needs. Instead of attempting to build generalized hand controllers with the goal of satisfying a broad range of users, we built a novel input device for the specific needs of a specific target audience - firefighters. We accomplished this by talking with over 30 firefighters. Their input was in the form of one-on-one discussions, focus groups, questionnaires, and feedback on our work in progress. Based on their input, we 1) identified a specific need - the simulation of detecting hazardous materials, 2) built a physical air monitoring device, that more closely matches firefighters actual air monitoring devices than standard VR controllers, and 3) implemented a hazardous materials scenario that consist of both physical and virtual elements. © 2020 IEEE.","Hardware - Emerging technologies - Emerging interfaces; Human-centered computing - Human computer interaction (HCI) - Interaction devices - Haptic devices; Human-centered computing - Human computer interaction (HCI) - Interaction paradigms - Virtual reality","Air pollution; Controllers; Fire extinguishers; Hazardous materials; Hazards; Knobs; Surveys; User interfaces; Air monitoring; Detection of hazardous materials; Focus groups; Input devices; Target audience; Virtual elements; Work in progress; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85085388847
"Qi K., Borland D., Jackson E., Williams N.L., Minogue J., Peck T.C.","57216932498;12804308600;57216938473;57210919407;12791055300;24329980700;","The Impact of Haptic and Visual Feedback on Teaching",2020,"Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VRW 2020",,, 9090605,"613","614",,,"10.1109/VRW50115.2020.00157","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085368062&doi=10.1109%2fVRW50115.2020.00157&partnerID=40&md5=a4f82288ccdedd80cba8779a856ed759","Davidson College, United States; RENCI, UNC, Chapel Hill, United States; North Carolina State University, United States; University of Maryland, College Park, United States","Qi, K., Davidson College, United States; Borland, D., RENCI, UNC, Chapel Hill, United States; Jackson, E., North Carolina State University, United States; Williams, N.L., University of Maryland, College Park, United States; Minogue, J., North Carolina State University, United States; Peck, T.C., Davidson College, United States","Haptic feedback, an important aspect of learning in virtual reality, has been demonstrated in contexts such as surgical training. However, deploying haptic feedback in other educational practices remains understudied. Haptically-enabled science simulations enable students to experience abstract scientific concepts through concrete and observable lessons in which students can physically experience the concepts being taught through haptic feedback. The present study aims to investigate the effect of an educational simulation on the understanding of basic physics concepts related to buoyancy. Specifically, we hypothesize that a simulation with visual and haptic feedback will improve participant learning transfer. © 2020 IEEE.","Education; Human computer interaction (HCI); Interaction paradigms; Interactive learning environments; Virtual reality","Students; Transfer learning; User interfaces; Visual communication; Educational simulations; Haptic feedbacks; In contexts; Learning Transfer; Surgical training; Visual feedback; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85085368062
"Chirico A., Giovannetti T., Neroni P., Simone S., Gallo L., Galli F., Giancamilli F., Predazzi M., Lucidi F., De Pietro G., Giordano A.","56736363600;6603442366;56449399500;57208625839;24072878600;57216654873;57190075356;57204580043;6603819858;6508247659;57211929456;","Virtual Reality for the Assessment of Everyday Cognitive Functions in Older Adults: An Evaluation of the Virtual Reality Action Test and Two Interaction Devices in a 91-Year-Old Woman",2020,"Frontiers in Psychology","11",, 123,"","",,1,"10.3389/fpsyg.2020.00123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086524265&doi=10.3389%2ffpsyg.2020.00123&partnerID=40&md5=33521c197f288a9b3c08c5978e8e3e06","Department of Psychology of Developmental and Socialization Processes, Sapienza University of Rome, Rome, Italy; Psychology Department, Temple University, Philadelphia, PA, United States; Institute for High Performance Computing and Networking, National Research Council, Naples, Italy; Department of Engineering, Parthenope University of Naples, Naples, Italy; Fondazione Il Melo Onlus, Gallarate, Italy; Sbarro Institute for Cancer Research and Molecular Medicine, Center for Biotechnology, College of Science and Technology, Temple University, Philadelphia, PA, United States; Department of Medical Biotechnologies, University of Siena, Siena, Italy","Chirico, A., Department of Psychology of Developmental and Socialization Processes, Sapienza University of Rome, Rome, Italy; Giovannetti, T., Psychology Department, Temple University, Philadelphia, PA, United States; Neroni, P., Institute for High Performance Computing and Networking, National Research Council, Naples, Italy, Department of Engineering, Parthenope University of Naples, Naples, Italy; Simone, S., Psychology Department, Temple University, Philadelphia, PA, United States; Gallo, L., Institute for High Performance Computing and Networking, National Research Council, Naples, Italy; Galli, F., Department of Psychology of Developmental and Socialization Processes, Sapienza University of Rome, Rome, Italy; Giancamilli, F., Department of Psychology of Developmental and Socialization Processes, Sapienza University of Rome, Rome, Italy; Predazzi, M., Fondazione Il Melo Onlus, Gallarate, Italy; Lucidi, F., Department of Psychology of Developmental and Socialization Processes, Sapienza University of Rome, Rome, Italy; De Pietro, G., Institute for High Performance Computing and Networking, National Research Council, Naples, Italy; Giordano, A., Sbarro Institute for Cancer Research and Molecular Medicine, Center for Biotechnology, College of Science and Technology, Temple University, Philadelphia, PA, United States, Department of Medical Biotechnologies, University of Siena, Siena, Italy","Performance-based functional tests for the evaluation of daily living activities demonstrate strong psychometric properties and solve many of the limitations associated with self- and informant-report questionnaires. Virtual reality (VR) technology, which has gained interest as an effective medium for administering interventions in the context of healthcare, has the potential to minimize the time-demands associated with the administration and scoring of performance-based assessments. To date, efforts to develop VR systems for assessment of everyday function in older adults generally have relied on non-immersive systems. The aim of the present study was to evaluate the feasibility of an immersive VR environment for the assessment of everyday function in older adults. We present a detailed case report of an elderly woman who performed an everyday activity in an immersive VR context (Virtual Reality Action Test) with two different types of interaction devices (controller vs. sensor). VR performance was compared to performance of the same task with real objects outside of the VR system (Real Action Test). Comparisons were made on several dimensions, including (1) quality of task performance (e.g., order of task steps, errors, use and speed of hand movements); (2) subjective impression (e.g., attitudes), and (3) physiological markers of stress. Subjective impressions of performance with the different controllers also were compared for presence, cybersickness, and usability. Results showed that the participant was capable of using controllers and sensors to manipulate objects in a purposeful and goal-directed manner in the immersive VR paradigm. She performed the everyday task similarly across all conditions. She reported no cybersickness and even indicated that interactions in the VR environment were pleasant and relaxing. Thus, immersive VR is a feasible approach for function assessment even with older adults who might have very limited computer experience, no prior VR exposure, average educational experiences, and mild cognitive difficulties. Because of inherent limitations of single case reports (e.g., unknown generalizability, potential practice effects, etc.), group studies are needed to establish the full psychometric properties of the Virtual Reality Action Test. © Copyright © 2020 Chirico, Giovannetti, Neroni, Simone, Gallo, Galli, Giancamilli, Predazzi, Lucidi, De Pietro and Giordano.","activities of daily living; cognitive aging; everyday action; psychometric assessment; virtual reality",,Article,"Final","",Scopus,2-s2.0-85086524265
"de Moraes Í.A.P., Monteiro C.B.D.M., Silva T.D.D., Massetti T., Crocetta T.B., de Menezes L.D.C., Andrade G.P.D.R., Alessandro Hervaldo Nicolai R.E., Dawes H., Coe S., Magalhães F.H.","57195930904;55481862300;55546962700;55546122700;54898013000;57191485293;57211442029;57214918552;7003895377;55901034900;35345153300;","Motor learning and transfer between real and virtual environments in young people with autism spectrum disorder: A prospective randomized cross over controlled trial",2020,"Autism Research","13","2",,"307","319",,6,"10.1002/aur.2208","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073925009&doi=10.1002%2faur.2208&partnerID=40&md5=a7e6539428b6756cf19811f5da50d924","School of Arts, Sciences and Humanities, University of São Paulo, São Paulo, SP, Brazil; Post-Graduate Programme in Rehabilitation Sciences, Faculty of Medicine, University of São Paulo, São Paulo, SP, Brazil; Department of Morphology and Physiology, Faculty of Medicine of ABC, Santo André, SP, Brazil; Integrated Psycho-pedagogical Support Group (GAPI) Special Education School in São Bernardo do Campo, São Paulo, Brazil; Institute of Nursing and Allied Health Research, Oxford Brookes University, Oxford, United Kingdom; Department of Clinical Neurology, University of Oxford, Oxford, United Kingdom","de Moraes, Í.A.P., School of Arts, Sciences and Humanities, University of São Paulo, São Paulo, SP, Brazil, Post-Graduate Programme in Rehabilitation Sciences, Faculty of Medicine, University of São Paulo, São Paulo, SP, Brazil; Monteiro, C.B.D.M., School of Arts, Sciences and Humanities, University of São Paulo, São Paulo, SP, Brazil, Post-Graduate Programme in Rehabilitation Sciences, Faculty of Medicine, University of São Paulo, São Paulo, SP, Brazil; Silva, T.D.D., Post-Graduate Programme in Rehabilitation Sciences, Faculty of Medicine, University of São Paulo, São Paulo, SP, Brazil; Massetti, T., Post-Graduate Programme in Rehabilitation Sciences, Faculty of Medicine, University of São Paulo, São Paulo, SP, Brazil; Crocetta, T.B., Department of Morphology and Physiology, Faculty of Medicine of ABC, Santo André, SP, Brazil; de Menezes, L.D.C., Post-Graduate Programme in Rehabilitation Sciences, Faculty of Medicine, University of São Paulo, São Paulo, SP, Brazil; Andrade, G.P.D.R., Integrated Psycho-pedagogical Support Group (GAPI) Special Education School in São Bernardo do Campo, São Paulo, Brazil; Alessandro Hervaldo Nicolai, R.E., School of Arts, Sciences and Humanities, University of São Paulo, São Paulo, SP, Brazil; Dawes, H., Institute of Nursing and Allied Health Research, Oxford Brookes University, Oxford, United Kingdom, Department of Clinical Neurology, University of Oxford, Oxford, United Kingdom; Coe, S., Department of Clinical Neurology, University of Oxford, Oxford, United Kingdom; Magalhães, F.H., School of Arts, Sciences and Humanities, University of São Paulo, São Paulo, SP, Brazil","Autism spectrum disorder (ASD) is associated with persistent deficits in social communication and social interaction, including impaired multisensory integration, which might negatively impact cognitive and motor skill performance, and hence negatively affect learning of tasks. Considering that tasks in virtual environment may provide an engaging tool as adjuncts to conventional therapies, we set out to compare motor performance between young people with ASD and a typically developing (TD) control group that underwent coincident timing tasks based on Kinect (no physical contact) and on Keyboard (with physical contact) environments. Using a randomized repeated cross-over controlled trial design, 50 young people with ASD and 50 with TD, matched by age and sex were divided into subgroups of 25 people that performed the two first phases of the study (acquisition and retention) on the same device—real or virtual—and then switched to the other device to repeat acquisition and retention phases and finally switched on to a touch screen (transfer phase). Results showed that practice in the virtual task was more difficult (producing more errors), but led to a better performance in the subsequent practice in the real task, with more pronounced improvement in the ASD as compared to the TD group. It can be concluded that the ASD group managed to transfer the practice from a virtual to a real environment, indicating that virtual methods may enhance learning of motor and cognitive skills. A need for further exploration of its effect across a number of tasks and activities is warranted. Autism Res 2020, 13: 307–319. © 2019 International Society for Autism Research, Wiley Periodicals, Inc. Lay Summary: Individuals with autism spectrum disorder are known to have difficulties with learning motor tasks. Considering that performing motor tasks in virtual environment may be an engaging tool as adjuncts to conventional therapies, we aimed to estimate performance in tasks regardless of physical touch. Results showed that participants had more difficulty using the non-touch task; however, virtual training improved performance on the physical (real) task. This result indicates that virtual methods could be a promising therapeutic approach for the ASD population. © 2019 International Society for Autism Research, Wiley Periodicals, Inc.","autistic disorder; developmental disabilities; motor skills; virtual reality","accuracy; adolescent; Article; autism; child; clinical article; controlled study; disease severity; female; gesture; human; male; motor learning; motor performance; priority journal; skill; systematic error; task performance; touch; virtual reality; age; autism; crossover procedure; pathophysiology; physiology; prospective study; psychology; randomized controlled trial; sex factor; Adolescent; Age Factors; Autism Spectrum Disorder; Child; Cross-Over Studies; Female; Humans; Male; Motor Skills; Prospective Studies; Sex Factors; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85073925009
"de Voogd L.D., Murray Y.P.J., Barte R.M., van der Heide A., Fernández G., Doeller C.F., Hermans E.J.","56066508400;57211967009;57190023980;57211968086;7202232893;6507122603;7005960381;","The role of hippocampal spatial representations in contextualization and generalization of fear: Fear memory contextualization",2020,"NeuroImage","206",, 116308,"","",,2,"10.1016/j.neuroimage.2019.116308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075509808&doi=10.1016%2fj.neuroimage.2019.116308&partnerID=40&md5=35c80c49b0b06388b48efad534a880f7","Donders Institute for Brain, Cognition and Behaviour, Radboud University and Radboud University Medical Center, Nijmegen, 6500 HB, Netherlands; Department of Psychology, New York University, New York, NY  10003, United States; Kavli Institute for Systems Neuroscience, Centre for Neural Computation, The Egil and Pauline Braathen and Fred Kavli Centre for Cortical Microcircuits, NTNU, Norwegian University of Science and Technology, Trondheim, Norway; Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany","de Voogd, L.D., Donders Institute for Brain, Cognition and Behaviour, Radboud University and Radboud University Medical Center, Nijmegen, 6500 HB, Netherlands, Department of Psychology, New York University, New York, NY  10003, United States; Murray, Y.P.J., Donders Institute for Brain, Cognition and Behaviour, Radboud University and Radboud University Medical Center, Nijmegen, 6500 HB, Netherlands; Barte, R.M., Donders Institute for Brain, Cognition and Behaviour, Radboud University and Radboud University Medical Center, Nijmegen, 6500 HB, Netherlands; van der Heide, A., Donders Institute for Brain, Cognition and Behaviour, Radboud University and Radboud University Medical Center, Nijmegen, 6500 HB, Netherlands; Fernández, G., Donders Institute for Brain, Cognition and Behaviour, Radboud University and Radboud University Medical Center, Nijmegen, 6500 HB, Netherlands; Doeller, C.F., Kavli Institute for Systems Neuroscience, Centre for Neural Computation, The Egil and Pauline Braathen and Fred Kavli Centre for Cortical Microcircuits, NTNU, Norwegian University of Science and Technology, Trondheim, Norway, Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany; Hermans, E.J., Donders Institute for Brain, Cognition and Behaviour, Radboud University and Radboud University Medical Center, Nijmegen, 6500 HB, Netherlands","Using contextual information to predict aversive events is a critical ability that protects from generalizing fear responses to safe contexts. Animal models have demonstrated the importance of spatial context representations within the hippocampal formation in contextualization of fear learning. The ventromedial prefrontal cortex (vmPFC) is known to play an important role in safety learning, possibly also through the incorporation of context information. However, if contextual representations are related to context-dependent expression of fear memory in humans remains unclear. Twenty-one healthy participants underwent functional MRI combined with a cue-context conditioning paradigm within a self-navigated virtual reality environment. The environment included two buildings (Threat and Safe context), which had distinct features outside but were identical inside. Within each context, participants saw two cues (CS+, CS-). The CS+ was consistently (100% reinforcement rate) paired with an electric shock in the Threat context, but never in the Safe context. The CS- was never paired with a shock. We found robust differential skin conductance responses (SCRs; CS+ ​> ​CS-) in the Threat context, but also within the Safe context, indicating fear generalization. Within the Safe context, vmPFC responses to the CS+ were larger than those in the Threat context. We furthermore found environment-specific representations for the two contexts in the training paradigm (i.e., before conditioning took place) in the hippocampus to be related to fear expression and generalization. Namely, participants with a weak context representation (z-score < 1.65) showed stronger fear generalization compared to participants with a strong context representation (z-score > 1.65). Thus, a weak neural representation strength of spatial context may explain overgeneralization of memory to safe contexts. In addition, our findings demonstrate that context-dependent regulation of fear expression engages ventromedial prefrontal pathways suggesting this involves a similar mechanism that is known to be involved in retrieval of extinction memory. © 2019 Elsevier Inc.","BOLD-fMRI; Contextual conditioning; Hippocampus; Pavlovian fear conditioning; Ventromedial prefrontal cortex (vmPFC); Virtual reality","adult; Article; association; biosafety; brain function; concept formation; conditioning; controlled study; electric shock; environmental factor; fear; female; functional magnetic resonance imaging; hippocampus; human; human experiment; life threat; male; normal human; priority journal; recall; regulatory mechanism; reinforcement; skin conductance; spatial memory; ventromedial prefrontal cortex; virtual reality; conditioned reflex; depth perception; electrodermal response; fear; functional neuroimaging; hippocampus; nuclear magnetic resonance imaging; physiology; prefrontal cortex; spatial behavior; support vector machine; young adult; Adult; Conditioning, Classical; Fear; Female; Functional Neuroimaging; Galvanic Skin Response; Generalization, Psychological; Hippocampus; Humans; Magnetic Resonance Imaging; Male; Prefrontal Cortex; Space Perception; Spatial Behavior; Support Vector Machine; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85075509808
"Kaplan A.D., Cruit J., Endsley M., Beers S.M., Sawyer B.D., Hancock P.A.","57203577853;55957076800;7003719103;57215654078;36025972800;7102723856;","The Effects of Virtual Reality, Augmented Reality, and Mixed Reality as Training Enhancement Methods: A Meta-Analysis",2020,"Human Factors",,,,"","",,12,"10.1177/0018720820904229","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081603757&doi=10.1177%2f0018720820904229&partnerID=40&md5=23181c622324b7e6e21a3cb74deec76b","University of Central Florida, Orlando, United States; SA Technologies, Gold Canyon, AZ, United States; MITRE Corporation, Colorado Springs, CO, United States","Kaplan, A.D., University of Central Florida, Orlando, United States; Cruit, J., University of Central Florida, Orlando, United States; Endsley, M., SA Technologies, Gold Canyon, AZ, United States; Beers, S.M., MITRE Corporation, Colorado Springs, CO, United States; Sawyer, B.D., University of Central Florida, Orlando, United States; Hancock, P.A., University of Central Florida, Orlando, United States","Objective: The objective of this meta-analysis is to explore the presently available, empirical findings on transfer of training from virtual (VR), augmented (AR), and mixed reality (MR) and determine whether such extended reality (XR)-based training is as effective as traditional training methods. Background: MR, VR, and AR have already been used as training tools in a variety of domains. However, the question of whether or not these manipulations are effective for training has not been quantitatively and conclusively answered. Evidence shows that, while extended realities can often be time-saving and cost-saving training mechanisms, their efficacy as training tools has been debated. Method: The current body of literature was examined and all qualifying articles pertaining to transfer of training from MR, VR, and AR were included in the meta-analysis. Effect sizes were calculated to determine the effects that XR-based factors, trainee-based factors, and task-based factors had on performance measures after XR-based training. Results: Results showed that training in XR does not express a different outcome than training in a nonsimulated, control environment. It is equally effective at enhancing performance. Conclusion: Across numerous studies in multiple fields, extended realities are as effective of a training mechanism as the commonly accepted methods. The value of XR then lies in providing training in circumstances, which exclude traditional methods, such as situations when danger or cost may make traditional training impossible. © Copyright 2020, Commonwealth of Australia, as represented by the Department of Defence, Science, and Technology.","immersive environments; meta-analysis; transfer of training; virtual environments","Augmented reality; Mixed reality; Virtual reality; Control environment; Empirical findings; Immersive environment; Meta analysis; Performance measure; Training enhancement; Training methods; Transfer of trainings; E-learning; article; augmented reality; effect size; human; meta analysis; transfer of learning; virtual reality",Article,"Article in Press","",Scopus,2-s2.0-85081603757
"Hejtmanek L., Starrett M., Ferrer E., Ekstrom A.D.","14008461600;56442554600;7101784591;7005951533;","How much of what we learn in virtual reality transfers to real-world navigation?",2020,"Multisensory Research","33","4-5",,"479","503",,1,"10.1163/22134808-20201445","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082813726&doi=10.1163%2f22134808-20201445&partnerID=40&md5=a5f02f4195dd7bc0560e2209286c8f3e","Third Faculty of Medicine, Charles University, Ruská 87, Prague 10, 100 00, Czech Republic; Center for Neuroscience, University of California, Davis, 1 Shields Ave, Davis, CA  95618, United States; Department of Psychology, University of California, Davis, 1 Shields Ave, Davis, CA  95618, United States; Department of Psychology, University of Arizona, 1503 E. University Blvd., Tucson, AZ  85719, United States","Hejtmanek, L., Third Faculty of Medicine, Charles University, Ruská 87, Prague 10, 100 00, Czech Republic, Center for Neuroscience, University of California, Davis, 1 Shields Ave, Davis, CA  95618, United States; Starrett, M., Center for Neuroscience, University of California, Davis, 1 Shields Ave, Davis, CA  95618, United States, Department of Psychology, University of California, Davis, 1 Shields Ave, Davis, CA  95618, United States, Department of Psychology, University of Arizona, 1503 E. University Blvd., Tucson, AZ  85719, United States; Ferrer, E., Department of Psychology, University of California, Davis, 1 Shields Ave, Davis, CA  95618, United States; Ekstrom, A.D., Center for Neuroscience, University of California, Davis, 1 Shields Ave, Davis, CA  95618, United States, Department of Psychology, University of California, Davis, 1 Shields Ave, Davis, CA  95618, United States, Department of Psychology, University of Arizona, 1503 E. University Blvd., Tucson, AZ  85719, United States","Past studies suggest that learning a spatial environment by navigating on a desktop computer can lead to significant acquisition of spatial knowledge, although typically less than navigating in the real world. Exactly how this might differ when learning in immersive virtual interfaces that offer a rich set of multisensory cues remains to be fully explored. In this study, participants learned a campus building environment by navigating (1) the real-world version, (2) an immersive version involving an omnidirectional treadmill and head-mounted display, or (3) a version navigated on a desktop computer with a mouse and a keyboard. Participants first navigated the building in one of the three different interfaces and, afterward, navigated the real-world building to assess information transfer. To determine how well they learned the spatial layout, we measured path length, visitation errors, and pointing errors. Both virtual conditions resulted in significant learning and transfer to the real world, suggesting their efficacy in mimicking some aspects of real-world navigation. Overall, real-world navigation outperformed both immersive and desktop navigation, effects particularly pronounced early in learning. This was also suggested in a second experiment involving transfer from the real world to immersive virtual reality (VR). Analysis of effect sizes of going from virtual conditions to the real world suggested a slight advantage for immersive VR compared to desktop in terms of transfer, although at the cost of increased likelihood of dropout. Our findings suggest that virtual navigation results in significant learning, regardless of the interface, with immersive VR providing some advantage when transferring to the real world. Copyright © 2020 by Koninklijke Brill NV, Leiden, The Netherlands.","Navigation; Proprioception; Spatial cognition; Transfer; Virtual reality","Helmet mounted displays; Mammals; Navigation; Sensory perception; Transfer learning; Head mounted displays; Immersive virtual reality; Information transfers; Spatial cognition; Spatial environments; Transfer; Virtual interfaces; Virtual navigation; Virtual reality",Article,"Final","",Scopus,2-s2.0-85082813726
"Carreon A., Smith S.J., Mosher M., Rao K., Rowland A.","57200799882;8063955600;57219305897;57221021182;56821362700;","A Review of Virtual Reality Intervention Research for Students With Disabilities in K–12 Settings",2020,"Journal of Special Education Technology",,,,"","",,,"10.1177/0162643420962011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092143583&doi=10.1177%2f0162643420962011&partnerID=40&md5=24117c6927194ddf8e5de88897d87620","The University of Kansas, Lawrence, KS, United States; University of Hawaii, Honolulu, HI, United States","Carreon, A., The University of Kansas, Lawrence, KS, United States; Smith, S.J., The University of Kansas, Lawrence, KS, United States; Mosher, M., The University of Kansas, Lawrence, KS, United States; Rao, K., University of Hawaii, Honolulu, HI, United States; Rowland, A., The University of Kansas, Lawrence, KS, United States","Virtual reality (VR) technology has improved in access and availability in the area of K–12 instruction, increasingly being cited for its promise to meet the varied learning needs of individuals with disabilities. This descriptive review of 25 research studies conducted in K–12 settings examined the defining characteristics of immersion levels associated with VR, the purpose and application of the augmented reality intervention, the outcomes associated with the current use of VR, and the possibility of generalization beyond VR. The results of the review reveal that a majority of studies are utilizing nonimmersive screen-based simulations. While still considered under the VR domain, these technologies do not take advantage of the features of semi- and fully immersive VR which make it an appealing intervention for students with disabilities. Based on the results of this review, we provide recommendations to establish a strong research base on emerging VR technology and its use for students with disabilities in the K–12 classroom. © The Author(s) 2020.","assistive technology; instructional technology; literature review; methodologies; mixed reality; mobile devices; technology perspectives; virtual reality",,Article,"Article in Press","",Scopus,2-s2.0-85092143583
"Cristea D.S., Rusu C.C., Mistodie L.R., Ivanov M., Leontin A.","39860898100;18435404300;8531354900;57220005717;57220008357;","Immersive data analytics for enhancing organisational knowledge transfer processes through a custom developed virtual reality framework",2020,"eLearning and Software for Education Conference",,,,"92","100",,,"10.12753/2066-026X-20-097","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096497931&doi=10.12753%2f2066-026X-20-097&partnerID=40&md5=0f6fe1ccb533535691d1258b52874aba","University ‘Dunărea de Jos’, Str. Domnească 47, Galati, Romania; S.C. ALTFACTOR SRL, Str. Domnească 47, Galati, Romania","Cristea, D.S., University ‘Dunărea de Jos’, Str. Domnească 47, Galati, Romania; Rusu, C.C., University ‘Dunărea de Jos’, Str. Domnească 47, Galati, Romania; Mistodie, L.R., University ‘Dunărea de Jos’, Str. Domnească 47, Galati, Romania; Ivanov, M., S.C. ALTFACTOR SRL, Str. Domnească 47, Galati, Romania; Leontin, A., S.C. ALTFACTOR SRL, Str. Domnească 47, Galati, Romania","During the past years, virtual reality (VR) and augmented reality (AR) improved a lot from both accessibility and hardware capabilities perspectives. Currently, this type of software applications is encouraged to be part of various domains. This paper presents how virtual reality technologies can provide a novel, immersive, approach of one of the most used data science tasks, respectively data analytics, that can be used to enhance the effectiveness of the organizational knowledge transfer. Knowledge transfer, a process used in various industries including education, business, social and technology, plays an important role in the overall learning process, introducing new ways of sharing resources and people experience. As a data scientist, it is usually said that about 80% of the time will be used doing EDA (exploratory data analytics scenarios). Our research targeted the enhancement of organizational knowledge transfer processes by using immersive EDA. Our paper emphasizes the fact that VR offers extended possibilities for sustaining data analytics strategies, improving them with a new immersive perspective. Virtual learning environments can be used to build skills and one challenge for virtual reality, when applied in education or training, is to assess Virtual Environments effectiveness. Immersive data analytics can ease the effort of quantifying how effective a specific virtual scenario was for a group of users. The presented study also emphasises on how VR technologies can provide more detailed immersive analytics that can be used in optimizing knowledge transfer and implicitly learning processes, by potentially analysing every move of the learners, assessing the evolution of the user learning/performance, respectively understanding user reaction speed (response times) in various contexts similar to real world scenarios. Also, through immersive analytics, it is possible to determine learners emotional state and their level of attention, being possible to provide a more personalised interactive experience for enhancing learning efficiency. © 2020, National Defence University - Carol I Printing House. All rights reserved.","Data science; E-learning; Immersive data analytics; Knowledge transfer; Virtual reality",,Conference Paper,"Final","",Scopus,2-s2.0-85096497931
"Rothe S., Schmidt A., Montagud M., Buschek D., Hußmann H.","57199996760;57219418508;35868074700;55850134500;23389275800;","Social viewing in cinematic virtual reality: a design space for social movie applications",2020,"Virtual Reality",,,,"","",,1,"10.1007/s10055-020-00472-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092676924&doi=10.1007%2fs10055-020-00472-4&partnerID=40&md5=def8d44ae1a903490a6dd20957473a4d","Institute of Informatics, Ludwig-Maximilians-University Munich, Munich, Germany; Universitat de València & i2CAT Foundation, Valencia, Spain; Research Group HCI + AI, Department of Computer Science, University of Bayreuth, Bayreuth, Germany","Rothe, S., Institute of Informatics, Ludwig-Maximilians-University Munich, Munich, Germany; Schmidt, A., Institute of Informatics, Ludwig-Maximilians-University Munich, Munich, Germany; Montagud, M., Universitat de València & i2CAT Foundation, Valencia, Spain; Buschek, D., Research Group HCI + AI, Department of Computer Science, University of Bayreuth, Bayreuth, Germany; Hußmann, H., Institute of Informatics, Ludwig-Maximilians-University Munich, Munich, Germany","Since watching movies is a social experience for most people, it is important to know how an application should be designed for enabling shared cinematic virtual reality (CVR) experiences via head-mounted displays (HMDs). Viewers can feel isolated when watching omnidirectional movies with HMDs. Even if they are watching the movie simultaneously, they do not automatically see the same field of view, since they can freely choose their viewing direction. Our goal is to explore interaction techniques to efficiently support social viewing and to improve social movie experiences in CVR. Based on the literature review and insights from earlier work, we identify seven challenges that need to be addressed: communication, field-of-view (FoV) awareness, togetherness, accessibility, interaction techniques, synchronization, and multiuser environments. We investigate four aspects (voice chat, sending emotion states, FoV indication, and video chat) to address some of the challenges and report the results of four user studies. Finally, we present and discuss a design space for CVR social movie applications and highlight directions for future work. © 2020, The Author(s).","360° video; Cinematic virtual reality; Interactive TV; Omnidirectional video; Social viewing","Helmet mounted displays; Motion pictures; Technology transfer; Design spaces; Field of views; Head mounted displays; Interaction techniques; Literature reviews; Multiuser environments; User study; Viewing directions; Virtual reality",Article,"Article in Press","",Scopus,2-s2.0-85092676924
"Matsangidou M., Otkhmezuri B., Ang C.S., Avraamides M., Riva G., Gaggioli A., Iosif D., Karekla M.","57196007400;57196009850;15831174100;6506947139;56962750600;6603138127;57219454910;7801543407;","“Now i can see me” designing a multi-user virtual reality remote psychotherapy for body weight and shape concerns",2020,"Human-Computer Interaction",,,,"","",,3,"10.1080/07370024.2020.1788945","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092795269&doi=10.1080%2f07370024.2020.1788945&partnerID=40&md5=67a8f0e1d96c2ded63dded4a70672b50","School of Engineering and Digital Arts, University of Kent, Kent, United Kingdom; Research Center on Interactive Media, Smart systems and Emerging technologies ltd, Nicosia, Cyprus; School of Psychology, University of Cyprus, Nicosia, Cyprus; School of Psychology, Università Cattolica Del Sacro Cuore, Milan, Italy; Applied Technology for Neuro-Psychology Lab, Milan, Italy","Matsangidou, M., School of Engineering and Digital Arts, University of Kent, Kent, United Kingdom, Research Center on Interactive Media, Smart systems and Emerging technologies ltd, Nicosia, Cyprus; Otkhmezuri, B., School of Engineering and Digital Arts, University of Kent, Kent, United Kingdom; Ang, C.S., School of Engineering and Digital Arts, University of Kent, Kent, United Kingdom; Avraamides, M., Research Center on Interactive Media, Smart systems and Emerging technologies ltd, Nicosia, Cyprus, School of Psychology, University of Cyprus, Nicosia, Cyprus; Riva, G., School of Psychology, Università Cattolica Del Sacro Cuore, Milan, Italy, Applied Technology for Neuro-Psychology Lab, Milan, Italy; Gaggioli, A., School of Psychology, Università Cattolica Del Sacro Cuore, Milan, Italy, Applied Technology for Neuro-Psychology Lab, Milan, Italy; Iosif, D., School of Psychology, University of Cyprus, Nicosia, Cyprus; Karekla, M., School of Psychology, University of Cyprus, Nicosia, Cyprus","Recent years have seen a growing research interest towards designing computer-assisted health interventions aiming to improve mental health services. Digital technologies are becoming common methods for diagnosis, therapy, and training. With the advent of lower-cost VR head-mounted-displays (HMDs) and high internet data transfer capacity, there is a new opportunity for applying immersive VR tools to augment existing interventions. This study is among the first to explore the use of a Multi-User Virtual Reality (MUVR) system as a therapeutic medium for participants at high-risk for developing Eating Disorders. This paper demonstrates the positive effect of using MUVR remote psychotherapy to enhance traditional therapeutic practices. The study capitalises on the opportunities which are offered by a MUVR remote psychotherapeutic session to enhance the outcome of Acceptance and Commitment Therapy, Play Therapy and Exposure Therapy for sufferers with body shape and weight concerns. Moreover, the study presents the design opportunities and challenges of such technology, while strengths on the feasibility, and the positive user acceptability of introducing MUVR to facilitate remote psychotherapy. Finally, the appeal of using VR for remote psychotherapy and its observed positive impact on both therapists and participants is discussed. © 2020 The Author(s). Published with license by Taylor & Francis Group, LLC.","Acceptance and Commitment Therapy (ACT); high-risk for eating disorders; Multi-User virtual reality; Play Therapy; Exposure Therapy; remote psychotherapy","Data transfer; Helmet mounted displays; Computer assisted; Digital technologies; Head mounted displays; Health interventions; Mental health services; Research interests; Therapeutic practices; Transfer capacities; Virtual reality",Article,"Article in Press","",Scopus,2-s2.0-85092795269
"Bellalouna F.","18933453600;","New approach for industrial training using virtual reality technology",2020,"Procedia CIRP","93",,,"262","267",,,"10.1016/j.procir.2020.03.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092432354&doi=10.1016%2fj.procir.2020.03.008&partnerID=40&md5=05e8e2f253a68a1c8bc857d201728f9f","University of Applied Sciences Karlsruhe, Moltkestraße 30, Karlsruhe, 76133, Germany","Bellalouna, F., University of Applied Sciences Karlsruhe, Moltkestraße 30, Karlsruhe, 76133, Germany","This paper presents two case studies achieved within industrial cooperation projects between the University of Applied Sciences Karlsruhe and German manufacturers for special appliances. The aim of the case studies is development and implementation of training applications for the use and the handling of special vehicle using the virtual reality technology. Based on the experiences gathered during these cooperation projects the challenges that face the VR introduction in the industrial area is outlined in this paper. Furthermore, a best practice approach on how to transfer CAD to VR data to implement industrial VR application is presented in this contribution. © 2020 The Authors.","CAD data; Cognitive approach; Intuitive approach; Virtual reality; VR data","Automobile manufacture; E-learning; Industrial area; Industrial cooperation; Industrial training; IS development; Training applications; University of applied science; Virtual reality technology; VR applications; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85092432354
"Hoppe A.H., Marek F., De Camp F.V., Stiefelhagen R.","57195069885;57210910641;57194787505;6602180348;","Extending movable surfaces with touch interaction using the virtualtablet: An extended view",2020,"Advances in Science, Technology and Engineering Systems","5","2",,"328","337",,,"10.25046/AJ050243","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087525968&doi=10.25046%2fAJ050243&partnerID=40&md5=df0c63da1836cd541fada857bd9f6d7e","Karlsruhe Institute of Technology (KIT), Institute for Anthropomatics and Robotics (IAR), cv:hci Lab, Karlsruhe, 76131, Germany; Fraunhofer IOSB, Interactive Analysis and Diagnosis (IAD), Karlsruhe, 76131, Germany; Fraunhoferstr. 1, Karlsruhe, 76131, Germany","Hoppe, A.H., Karlsruhe Institute of Technology (KIT), Institute for Anthropomatics and Robotics (IAR), cv:hci Lab, Karlsruhe, 76131, Germany, Fraunhoferstr. 1, Karlsruhe, 76131, Germany; Marek, F., Karlsruhe Institute of Technology (KIT), Institute for Anthropomatics and Robotics (IAR), cv:hci Lab, Karlsruhe, 76131, Germany; De Camp, F.V., Fraunhofer IOSB, Interactive Analysis and Diagnosis (IAD), Karlsruhe, 76131, Germany; Stiefelhagen, R., Karlsruhe Institute of Technology (KIT), Institute for Anthropomatics and Robotics (IAR), cv:hci Lab, Karlsruhe, 76131, Germany","Immersive output and natural input are two core aspects of a virtual reality experience. Current systems are frequently operated by a controller or gesture-based approach. However, these techniques are either very accurate but require an effort to learn, or very natural but miss haptic feedback for optimal precision. We transfer ubiquitous touch interaction with haptic feedback into a virtual environment. To validate the performance of our implementation, we performed a user study with 28 participants. As the results show, the movable and cheap real world object supplies an accurate touch detection that is equal to a laserpointer-based interaction with a controller. Moreover, the virtual tablet can extend the functionality of a real world tablet. Additional information can be displayed in mid-air around the touchable area and the tablet can be turned over to interact with both sides. Therefore, touch interaction in virtual environments allows easy to learn and precise system interaction and can even augment the established touch metaphor with new paradigms. © 2020 ASTES Publishers. All rights reserved.","Haptic feedback; Touch interaction; Virtual environment; Virtual reality; VirtualTablet",,Article,"Final","",Scopus,2-s2.0-85087525968
"Kandi V.R., Brittle P., Castronovo F., Gaedicke C.","57218765879;57218762256;55924007300;14007888200;","Application of a Virtual Reality Educational Game to Improve Design Review Skills",2020,"Construction Research Congress 2020: Project Management and Controls, Materials, and Contracts - Selected Papers from the Construction Research Congress 2020",,,,"545","554",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090229314&partnerID=40&md5=77556dfb26956aa5dbf78beb70671f9f","Construction Management Program, School of Engineering, California State Univ., Hayward, CA, United States","Kandi, V.R., Construction Management Program, School of Engineering, California State Univ., Hayward, CA, United States; Brittle, P., Construction Management Program, School of Engineering, California State Univ., Hayward, CA, United States; Castronovo, F., Construction Management Program, School of Engineering, California State Univ., Hayward, CA, United States; Gaedicke, C., Construction Management Program, School of Engineering, California State Univ., Hayward, CA, United States","Innovative software and technology solutions, such as building information modeling and virtual reality, are increasingly being adopted by the construction industry. One use of this technology is to utilize BIM models to perform design reviews in immersive virtual reality environments. Performing a design review, whether on paper drawings or in VR environments requires essential and strong problem-solving and evaluation skills. The objective of this paper is to support the development and education of such design review skills in undergraduate construction students using virtual reality simulation games. To achieve this objective, 32 undergraduate construction management students were asked to use the design review simulator, an educational virtual reality game designed with the learning objective of teaching design review skills. During the experiment the students were tasked with identifying noticeable design mistakes and writing down these mistakes as they were encountered. There were three basic research questions the authors were seeking to address in this experiment: 1) does playing the simulation game in VR encourage students to identify a higher number of design mistakes than evaluating the design on paper, 2) do design review skills gained from performing the design review in one mode transfer to the other alternate mode, 3) does the order in which the design review methods are implemented affect student improvements in design review skills? Based on the analysis of the results, the authors could conclude that the students gained design review skills. Through the use of the DRS the students found a significant higher number of design mistakes when performing design reviews in virtual reality, in comparison to performing design reviews using physical construction drawings. With study, the authors provide an example of how virtual reality simulation games can be leveraged in the classroom to gain design review skills. In future research, the authors will perform comparative experiments to test if the game supports higher gains in skills with knowledge tests. © 2020 American Society of Civil Engineers.",,"Architectural design; Computer aided software engineering; Construction industry; E-learning; Education computing; Project management; Virtual reality; Building Information Model - BIM; Comparative experiments; Construction drawings; Construction management; Immersive virtual reality; Learning objectives; Technology solutions; Virtual reality simulations; Students",Conference Paper,"Final","",Scopus,2-s2.0-85090229314
"Ojelade A., Paige F.","57203984321;57202021599;","Virtual reality postural training for construction",2020,"Construction Research Congress 2020: Safety, Workforce, and Education - Selected Papers from the Construction Research Congress 2020",,,,"565","573",,,"10.1061/9780784482872.061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096943100&doi=10.1061%2f9780784482872.061&partnerID=40&md5=3f57eb8f400f3d339c7ab720e408cc14","Occupational Ergonomics and Safety, Dept. of Industrial and Systems Engineering, Virginia Tech, Blacksburg, VA, United States; Construction and Engineering Management, Dept. of Civil Engineering, Virginia Tech, Blacksburg, VA, United States","Ojelade, A., Occupational Ergonomics and Safety, Dept. of Industrial and Systems Engineering, Virginia Tech, Blacksburg, VA, United States; Paige, F., Construction and Engineering Management, Dept. of Civil Engineering, Virginia Tech, Blacksburg, VA, United States","Currently, the U.S. construction workforce is aging faster than the next generation is being trained. While an insufficient workforce will cause major issues with the advancement of infrastructure, it also causes less discussed worker health safety hazards. Traditional experiential learning is a major limitation of the construction industry's growth rate due to the non-availability of real environments, time, and training supervisors. Virtual reality (VR) allows for a virtual environment to efficiently mimic dangerous, expensive, and difficult to set up training scenarios. This paper presents an exploration of a virtual approach to training future construction workers. VR environments and a RGB camera based pose estimation pedagogical tool are evaluated for their ability to improve the training process of future construction workers. Study participants will be assessed on their ability to learn, identify, and assess health safety risks, specifically proper lifting and postural techniques associated with construction tasks. Findings of this work in progress will provide quantified learning gains by measuring training time, changes in behavior, and risk assessment ability; and a qualitative understanding of the experience in the virtual environment through participant interviews. Findings from this study transfer to a much-needed digitization of pedagogical approaches for blue collar industries. © 2020 American Society of Civil Engineers.",,"Construction industry; Health hazards; Health risks; Occupational risks; Personnel training; Risk assessment; Virtual reality; Construction workers; Construction workforces; Experiential learning; Pedagogical approach; Pedagogical tools; Postural training; Real environments; Training scenario; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85096943100
"Harris D.J., Buckingham G., Wilson M.R., Brookes J., Mushtaq F., Mon-Williams M., Vine S.J.","57192429891;14069958400;55574207642;57197801653;56999078200;7006287402;36811509000;","Exploring sensorimotor performance and user experience within a virtual reality golf putting simulator",2020,"Virtual Reality",,,,"","",,,"10.1007/s10055-020-00480-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092909275&doi=10.1007%2fs10055-020-00480-4&partnerID=40&md5=c0dd2e10981714f6c085f31365d25818","School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom; School of Psychology, University of Leeds, Leeds, LS2 9JZ, United Kingdom; Centre for Immersive Technologies, University of Leeds, Leeds, LS2 9JZ, United Kingdom; Bradford Teaching Hospitals NHS Foundation Trust, Bradford, West Yorkshire, United Kingdom; National Centre for Optics, Vision and Eye Care, University of South-Eastern Norway, Hasbergs vei 36, Kongsberg, 3616, Norway","Harris, D.J., School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom; Buckingham, G., School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom; Wilson, M.R., School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom; Brookes, J., School of Psychology, University of Leeds, Leeds, LS2 9JZ, United Kingdom; Mushtaq, F., School of Psychology, University of Leeds, Leeds, LS2 9JZ, United Kingdom, Centre for Immersive Technologies, University of Leeds, Leeds, LS2 9JZ, United Kingdom; Mon-Williams, M., School of Psychology, University of Leeds, Leeds, LS2 9JZ, United Kingdom, Centre for Immersive Technologies, University of Leeds, Leeds, LS2 9JZ, United Kingdom, Bradford Teaching Hospitals NHS Foundation Trust, Bradford, West Yorkshire, United Kingdom, National Centre for Optics, Vision and Eye Care, University of South-Eastern Norway, Hasbergs vei 36, Kongsberg, 3616, Norway; Vine, S.J., School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom","In light of recent advances in technology, there has been growing interest in virtual reality (VR) simulations for training purposes in a range of high-performance environments, from sport to nuclear decommissioning. For a VR simulation to elicit effective transfer of training to the real-world, it must provide a sufficient level of validity, that is, it must be representative of the real-world skill. In order to develop the most effective simulations, assessments of validity should be carried out prior to implementing simulations in training. The aim of this work was to test elements of the physical fidelity, psychological fidelity and construct validity of a VR golf putting simulation. Self-report measures of task load and presence in the simulation were taken following real and simulated golf putting to assess psychological and physical fidelity. The performance of novice and expert golfers in the simulation was also compared as an initial test of construct validity. Participants reported a high degree of presence in the simulation, and there was little difference between real and virtual putting in terms of task demands. Experts performed significantly better in the simulation than novices (p =.001, d = 1.23), and there was a significant relationship between performance on the real and virtual tasks (r =.46, p =.004). The results indicated that the simulation exhibited an acceptable degree of construct validity and psychological fidelity. However, some differences between the real and virtual tasks emerged, suggesting further validation work is required. © 2020, The Author(s).","Construct validity; Simulation; Sport; Training; VR","Golf; User experience; Construct validity; Nuclear decommissioning; Real-world; Task demand; Test elements; Training purpose; Transfer of trainings; VR simulation; Virtual reality",Article,"Article in Press","",Scopus,2-s2.0-85092909275
"Zhang L., Weitlauf A.S., Amat A.Z., Swanson A., Warren Z.E., Sarkar N.","55803949700;57191707622;57203133051;53265026200;25032282500;7201361624;","Assessing Social Communication and Collaboration in Autism Spectrum Disorder Using Intelligent Collaborative Virtual Environments",2020,"Journal of Autism and Developmental Disorders","50","1",,"199","211",,4,"10.1007/s10803-019-04246-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074351511&doi=10.1007%2fs10803-019-04246-z&partnerID=40&md5=dac49c257ecb6445127a7b2978757a8c","Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United States; Department of Pediatrics, Vanderbilt University Medical Center, Nashville, United States; Vanderbilt Kennedy Center, Treatment and Research Institute of Autism Spectrum Disorders, Vanderbilt University Medical Center, 230 Appleton Pl., PMB 74, Nashville, TN  37212, United States; Department of Special Education, Vanderbilt University, Nashville, TN, United States; Department of Psychiatry, Vanderbilt University Medical Center, Nashville, TN, United States; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, United States","Zhang, L., Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United States; Weitlauf, A.S., Department of Pediatrics, Vanderbilt University Medical Center, Nashville, United States, Vanderbilt Kennedy Center, Treatment and Research Institute of Autism Spectrum Disorders, Vanderbilt University Medical Center, 230 Appleton Pl., PMB 74, Nashville, TN  37212, United States; Amat, A.Z., Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United States; Swanson, A., Vanderbilt Kennedy Center, Treatment and Research Institute of Autism Spectrum Disorders, Vanderbilt University Medical Center, 230 Appleton Pl., PMB 74, Nashville, TN  37212, United States; Warren, Z.E., Department of Pediatrics, Vanderbilt University Medical Center, Nashville, United States, Vanderbilt Kennedy Center, Treatment and Research Institute of Autism Spectrum Disorders, Vanderbilt University Medical Center, 230 Appleton Pl., PMB 74, Nashville, TN  37212, United States, Department of Special Education, Vanderbilt University, Nashville, TN, United States, Department of Psychiatry, Vanderbilt University Medical Center, Nashville, TN, United States; Sarkar, N., Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United States, Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, United States","Existing literature regarding social communication outcomes of interventions in autism spectrum disorder (ASD) depends upon human raters, with limited generalizability to real world settings. Technological innovation, particularly virtual reality (VR) and collaborative virtual environments (CVE), could offer a replicable, low cost measurement platform when endowed with intelligent agent technology and peer-based interactions. We developed and piloted a novel collaborative virtual environment and intelligent agent (CRETA) for the assessment of social communication and collaboration within system and peer interactions. The system classified user statements with moderate to high accuracies. We found moderate to high agreement in displayed communication and collaboration skills between human–human and human–agent interactions. CRETA offers a promising avenue for future development of autonomous measurement systems for ASD research. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Autism; Collaboration; Communication; Measurement; Technology; Virtual reality","adolescent; Article; autism; automatic speech recognition; clinical article; communication skill; controlled study; DSM-5; feasibility study; female; human; machine learning; male; pilot study; priority journal; social competence; task performance; verbal communication; virtual reality; autism; case control study; interpersonal communication; peer group; psychology; social behavior; Adolescent; Autism Spectrum Disorder; Case-Control Studies; Communication; Female; Humans; Male; Peer Group; Social Behavior; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85074351511
"Bogaerts B., Sels S., Vanlanduit S., Penne R.","57191575116;57193554563;7004271926;6701922997;","Connecting the CoppeliaSim robotics simulator to virtual reality",2020,"SoftwareX","11",, 100426,"","",,,"10.1016/j.softx.2020.100426","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080071825&doi=10.1016%2fj.softx.2020.100426&partnerID=40&md5=031766ad9c44d9d74d77dd43b781e8d1","Faculty of Applied Engineering, University of Antwerp, Antwerp, Belgium","Bogaerts, B., Faculty of Applied Engineering, University of Antwerp, Antwerp, Belgium; Sels, S., Faculty of Applied Engineering, University of Antwerp, Antwerp, Belgium; Vanlanduit, S., Faculty of Applied Engineering, University of Antwerp, Antwerp, Belgium; Penne, R., Faculty of Applied Engineering, University of Antwerp, Antwerp, Belgium","The CoppeliaSim VR Toolbox provides a set of tools to experience CoppeliaSim robot simulation software in Virtual Reality and to return user interactions. Its primary focus is to create a platform that enables the fast prototyping and verification of robotic systems. Moreover, the generality of the toolbox ensures that it can be valuable in other contexts like robotics education, human–robot interaction or reinforcement learning. The software is designed to have a low entry threshold for moderately complex use cases, but can be extended to perform very complex visualizations for more experienced users. © 2020 The Authors","Human–robot interaction; Interface; Prototyping; Robot simulation; Virtual reality","Computer software; Interfaces (materials); Reinforcement learning; Robotics; Software prototyping; Virtual reality; Fast prototyping; Robot interactions; Robot simulation software; Robot simulations; Robotic systems; Robotics education; User interaction; Human robot interaction",Article,"Final","",Scopus,2-s2.0-85080071825
"Eiris R., Gheisari M., Esmaeili B.","57196006104;36459705300;35388139800;","Desktop-based safety training using 360-degree panorama and static virtual reality techniques: A comparative experimental study",2020,"Automation in Construction","109",, 102969,"","",,6,"10.1016/j.autcon.2019.102969","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073757844&doi=10.1016%2fj.autcon.2019.102969&partnerID=40&md5=910f18b71dc4dced51aa43348f942f02","Rinker School of Construction Management, University of Florida, United States; Sid and Reva Dewberry Department of Civil, Environmental, and Infrastructure Engineering, George Mason University, United States","Eiris, R., Rinker School of Construction Management, University of Florida, United States; Gheisari, M., Sid and Reva Dewberry Department of Civil, Environmental, and Infrastructure Engineering, George Mason University, United States; Esmaeili, B., Sid and Reva Dewberry Department of Civil, Environmental, and Infrastructure Engineering, George Mason University, United States","Virtual reality (VR)-based approaches have been used to facilitate safety knowledge transfer and increase hazard awareness by providing safe and controlled experiences of unsafe scenarios in construction safety training applications. However, the long development times and high computational costs associated with existing VR methods have posed significant challenges to using such VR-based safety training platforms. Unlike VR settings that deliver computer-generated reproductions of the environment, 360-degree panorama can create true-to-reality simulations of construction jobsites. This research developed and compared two hazard-identification training platforms based on VR and 360-degree panorama. Construction students and professionals participated in an experiment to determine their perception of realism and evaluate their hazard-identification skills. It was found that students perceived the 360-degree panorama conditions as more realistic than the VR conditions, but professionals perceived no difference between them. Moreover, differences were found in the average hazard identification index (HII) scores for all participants, with higher scores for the VR conditions than for the 360-degree panorama conditions. Finally, it was found that there was an inverse correlation between the presence scores and the average HII scores for the participants in the study. © 2019 Elsevier B.V.","360-degree panorama; Construction safety training; Hazard recognition; Virtual reality","E-learning; Hazardous materials; Knowledge management; Students; Virtual reality; 360-degree panorama; Computational costs; Computer generated; Construction safety; Hazard identification; Inverse correlation; Training platform; Virtual reality techniques; Hazards",Article,"Final","",Scopus,2-s2.0-85073757844
"Ke Y., Liu P., An X., Song X., Ming D.","55760984800;57213603004;57214860474;55814078100;9745824400;","An online SSVEP-BCI system in an optical see-through augmented reality environment",2020,"Journal of Neural Engineering","17","1", 016066,"","",,5,"10.1088/1741-2552/ab4dc6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080070514&doi=10.1088%2f1741-2552%2fab4dc6&partnerID=40&md5=bd56e2fce8c2131522bac0a349d1c469","Academy of Medical Engineering and Translational Medicine, Tianjin International Joint Research Centre for Neural Engineering, Tianjin Key Laboratory of Brain Science and Neural Engineering, Tianjin University, Tianjin, 300072, China; Department of Biomedical Engineering, College of Precision Instrument and Optoelectronics Engineering, Tianjin University, Tianjin, 300072, China","Ke, Y., Academy of Medical Engineering and Translational Medicine, Tianjin International Joint Research Centre for Neural Engineering, Tianjin Key Laboratory of Brain Science and Neural Engineering, Tianjin University, Tianjin, 300072, China; Liu, P., Academy of Medical Engineering and Translational Medicine, Tianjin International Joint Research Centre for Neural Engineering, Tianjin Key Laboratory of Brain Science and Neural Engineering, Tianjin University, Tianjin, 300072, China; An, X., Academy of Medical Engineering and Translational Medicine, Tianjin International Joint Research Centre for Neural Engineering, Tianjin Key Laboratory of Brain Science and Neural Engineering, Tianjin University, Tianjin, 300072, China; Song, X., Academy of Medical Engineering and Translational Medicine, Tianjin International Joint Research Centre for Neural Engineering, Tianjin Key Laboratory of Brain Science and Neural Engineering, Tianjin University, Tianjin, 300072, China; Ming, D., Academy of Medical Engineering and Translational Medicine, Tianjin International Joint Research Centre for Neural Engineering, Tianjin Key Laboratory of Brain Science and Neural Engineering, Tianjin University, Tianjin, 300072, China, Department of Biomedical Engineering, College of Precision Instrument and Optoelectronics Engineering, Tianjin University, Tianjin, 300072, China","Objective. This study aimed to design and evaluate a high-speed online steady-state visually evoked potential (SSVEP)-based brain-computer interface (BCI) in an optical see-through (OST) augmented reality (AR) environment. Approach. An eight-class BCI was designed in an OST-AR headset which is wearable and allows users to see the user interface of the BCI and the device to be controlled in the same view field via the OST head-mounted display. The accuracies, information transfer rates (ITRs), and SSVEP signal characteristics of the AR-BCI were evaluated and compared with a computer screen-based BCI implemented with a laptop in offline and online cue-guided tasks. Then, the performance of the AR-BCI was evaluated in an online robotic arm control task. Main results. The offline results obtained during the cue-guided task performed with the AR-BCI showed maximum averaged ITRs of 65.50 ± 9.86 bits min-1 according to the extended canonical correlation analysis-based target identification method. The online cue-guided task achieved averaged ITRs of 65.03 ± 11.40 bits min-1. The online robotic arm control task achieved averaged ITRs of 45.57 ± 7.40 bits min-1. Compared with the screen-based BCI, some limitations of the AR environment impaired BCI performance and the quality of SSVEP signals. Significance. The results showed the potential for providing a high-performance brain-control interaction method by combining AR and BCI. This study could provide methodological guidelines for developing more wearable BCIs in OST-AR environments and will also encourage more interesting applications involving BCIs and AR techniques. © 2020 IOP Publishing Ltd.","augmented reality; brain-computer interface; electroencephalogram; optical see-through; steady-state visual evoked potential","Augmented reality; Electroencephalography; Helmet mounted displays; Interface states; Robotic arms; Robotics; User interfaces; Wearable computers; Canonical correlation analysis; Head mounted displays; Information transfer rate; Methodological guidelines; Optical see-through; Steady state visual evoked potentials; Steady state visually evoked potentials; Target identification; Brain computer interface; adult; augmented reality; Conference Paper; controlled study; correlation analysis; female; human; human experiment; male; normal human; online system; priority journal; robotics; signal transduction; task performance; visual evoked potential",Conference Paper,"Final","",Scopus,2-s2.0-85080070514
"Prumes M., da Silva T.D., de Oliveira Alberissi C.A., Capelini C.M., Del Ciello de Menezes L., da Rocha J.B.F., Favero F.M., de Mello Monteiro C.B.","55358258900;55546962700;57222091652;57195469943;57222098295;57222101223;36113108600;36952872700;","Motor learning through a non-immersive virtual task in people with limb-girdle muscular dystrophies",2020,"Journal of Human Growth and Development","30","3",,"461","471",,1,"10.7322/jhgd.v30.11115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101350817&doi=10.7322%2fjhgd.v30.11115&partnerID=40&md5=feff79ca53a954d44af79380bd99c3c1","Laboratório de Delineamento de Estudos e Escrita Científica. Centro Universitário Saúde ABC (FMABC), Santo André, SP, Brazil; Departamento de Cardiologia, Escola Paulista de Medicina, Universidade Federal de São Paulo (UNIFESP), São Paulo, SP, Brazil; Faculdade de Medicina, Universidade Cidade de São Paulo (UNICID), São Paulo, SP, Brazil; Programa de Pós-Graduação em Ciências da Reabilitação, Faculdade de Medicina da Universidade de São Paulo, São Paulo, SP, Brazil; Escola de Artes, Ciências e Humanidades (EACH), Universidade de São Paulo (USP), São Paulo, SP, Brazil; Setor de Investigação nas Doenças Neuromusculares, Departamento de Neurologia e Neurocirurgia, Universidade Federal de São Paulo (UNIFESP), São Paulo, SP, Brazil","Prumes, M., Laboratório de Delineamento de Estudos e Escrita Científica. Centro Universitário Saúde ABC (FMABC), Santo André, SP, Brazil; da Silva, T.D., Departamento de Cardiologia, Escola Paulista de Medicina, Universidade Federal de São Paulo (UNIFESP), São Paulo, SP, Brazil, Faculdade de Medicina, Universidade Cidade de São Paulo (UNICID), São Paulo, SP, Brazil, Programa de Pós-Graduação em Ciências da Reabilitação, Faculdade de Medicina da Universidade de São Paulo, São Paulo, SP, Brazil; de Oliveira Alberissi, C.A., Escola de Artes, Ciências e Humanidades (EACH), Universidade de São Paulo (USP), São Paulo, SP, Brazil; Capelini, C.M., Programa de Pós-Graduação em Ciências da Reabilitação, Faculdade de Medicina da Universidade de São Paulo, São Paulo, SP, Brazil; Del Ciello de Menezes, L., Departamento de Cardiologia, Escola Paulista de Medicina, Universidade Federal de São Paulo (UNIFESP), São Paulo, SP, Brazil; da Rocha, J.B.F., Laboratório de Delineamento de Estudos e Escrita Científica. Centro Universitário Saúde ABC (FMABC), Santo André, SP, Brazil; Favero, F.M., Setor de Investigação nas Doenças Neuromusculares, Departamento de Neurologia e Neurocirurgia, Universidade Federal de São Paulo (UNIFESP), São Paulo, SP, Brazil; de Mello Monteiro, C.B., Laboratório de Delineamento de Estudos e Escrita Científica. Centro Universitário Saúde ABC (FMABC), Santo André, SP, Brazil, Programa de Pós-Graduação em Ciências da Reabilitação, Faculdade de Medicina da Universidade de São Paulo, São Paulo, SP, Brazil, Escola de Artes, Ciências e Humanidades (EACH), Universidade de São Paulo (USP), São Paulo, SP, Brazil","Introduction: Limb-girdle muscular dystrophies (LGMDs) are neuromuscular and genetic disorders that progress with weakness and damage of the proximal muscles, developing with loss of functionality. Virtual reality environments are suggested as an effective alternative for performance of daily life activities. However, there is no evidence in the literature on the use of virtual reality in this population. Objective: Assess motor performance through a motor learning protocol in a coincident timing task. Methods: 10 participants with LGMD and 10 healthy individuals were selected and included in the study to perform a non-immersive virtual reality task divided into three phases: acquisition (20 attempts), retention (5 attempts), and transfer (5 attempts, with speed increase). Results: It is observed that the accuracy of movement improves from the beginning to the end of the acquisition (p = 0.01); however, there is a marginal difference between the groups in block A1 (p = 0.089). Regarding the variability of touches, observed by the variable error, both groups improved performance in all phases. Conclusion: Even with lower performance than the control group at the beginning of the practice, individuals with LGMD showed the potential to optimize motor function during the practice of a non-immersive virtual reality activity and were able to match their performance with the control group after a few attempts. © The authors (2020). this article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (http://creativecommons.org/publicdomain/zero/1.0/) applies to the data made available in this article, unless otherwise stated.","Limb-Girdle Muscular Dystrophies; Motor Learning; Muscular Dystrophies; Virtual Reality",,Article,"Final","",Scopus,2-s2.0-85101350817
"Huber B., Gajos K.Z.","57188807714;8375653300;","Conducting online virtual environment experiments with uncompensated, unsupervised samples",2020,"PLoS ONE","15","1", e0227629,"","",,3,"10.1371/journal.pone.0227629","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078713911&doi=10.1371%2fjournal.pone.0227629&partnerID=40&md5=f476cce779c79a329e6e1b8d1b27de70","School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, United States","Huber, B., School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, United States; Gajos, K.Z., School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, United States","Web-based experimentation with uncompensated and unsupervised samples allows for a larger and more diverse sample population, more generalizable results, and faster theory to experiment cycle. Given that participants are unsupervised, it is still unknown whether the data collected in such settings would be of sufficiently high quality to support robust conclusions. Therefore, we investigated the feasibility of conducting such experiments online using virtual environment technologies. We conducted a conceptual replication of two prior experiments that have been conducted in virtual environments. Our results replicate findings previously obtained in conventional laboratory settings. These results hold across different device types of participants (ranging from desktop, through mobile devices to immersive virtual reality headsets), suggesting that experiments can be conducted online with uncompensated samples in virtual environments. © 2020 Huber, Gajos. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"adolescent; adult; aged; Article; behavior assessment; child; community care; feasibility study; female; human; human experiment; laboratory; male; process design; replication study; unsupervised machine learning; virtual reality; web-based intervention; computer; interpersonal communication; middle aged; mobile phone; non-therapeutic research; online system; psychology; spatial orientation; young adult; Adolescent; Adult; Aged; Cell Phone; Child; Computers; Female; Humans; Male; Middle Aged; Negotiating; Nontherapeutic Human Experimentation; Online Systems; Spatial Navigation; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85078713911
"Nuguri S.S., Calyam P., Oruche R., Gulhane A., Valluripally S., Stichter J., He Z.","57197736605;6507285722;57207993528;57207990715;57193485929;6602918053;7403885484;","vSocial: a cloud-based system for social virtual reality learning environment applications in special education",2020,"Multimedia Tools and Applications",,,,"","",,,"10.1007/s11042-020-09051-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085874226&doi=10.1007%2fs11042-020-09051-w&partnerID=40&md5=1dd676b2769f35d92da28167c6e0768d","University of Missouri, Columbia, MO, United States","Nuguri, S.S., University of Missouri, Columbia, MO, United States; Calyam, P., University of Missouri, Columbia, MO, United States; Oruche, R., University of Missouri, Columbia, MO, United States; Gulhane, A., University of Missouri, Columbia, MO, United States; Valluripally, S., University of Missouri, Columbia, MO, United States; Stichter, J., University of Missouri, Columbia, MO, United States; He, Z., University of Missouri, Columbia, MO, United States","Virtual Learning Environments (VLEs) are spaces designed to educate student groups remotely via online platforms. Although traditional VLEs have shown promise in educating students, they offer limited immersion that overall diminishes learning effectiveness. In this paper, we describe vSocial, a cloud-based virtual reality learning environment (VRLE) system that can be deployed over high-speed networks using the High Fidelity “social VR” platform. vSocial provides flexible control of group learning content and compliance with established VLE standards with improved immersive user experience for both instructor(s) and students. For our vSocial development, we build upon the use case of an existing special education VLE viz., iSocial that trains youth with Autism Spectrum Disorder by implementing the Social Competence Intervention (SCI) curriculum. The vSocial can be used to: (a) implement multiple learning modules using wearable VR technologies, (b) integrate cognitive state sensing devices, and (c) organize learning session data securely using web applications hosted on cloud resources. Our experiment results show that the VR mode of content delivery in vSocial better stimulates the generalization of lessons to the real world than non-VR lessons, and provides improved immersion when compared to an equivalent desktop version. Further, usability study results show that users can successfully use the web application features in vSocial for group learning activities with ease-of-use and consistency. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","Intelligent network services; Learning environments; Social virtual reality; Special education; Web applications","Compliance control; Computer aided instruction; HIgh speed networks; Learning systems; Regulatory compliance; Students; User experience; Virtual reality; Wearable technology; Autism spectrum disorders; Learning effectiveness; Learning sessions; Social competences; Special education; Usability studies; Virtual learning environments (VLEs); Virtual reality learning environments; E-learning",Article,"Article in Press","",Scopus,2-s2.0-85085874226
"Balkhoyor A.M., Mir R., Mirghani I., Pike T.W., Sheppard W.E.A., Biyani C.S., Lodge J.P.A., Mon-Williams M.A., Mushtaq F., Manogue M.","57194641763;57201256505;57191096853;56536400200;57219273154;7005861188;7103082442;7006287402;56999078200;6701334811;","Exploring the Presence of Core Skills for Surgical Practice Through Simulation",2020,"Journal of Surgical Education",,,,"","",,,"10.1016/j.jsurg.2020.08.036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092014433&doi=10.1016%2fj.jsurg.2020.08.036&partnerID=40&md5=bf0c0221d8adc89a13261d1e2adb8f83","Department of Preventive Dentistry, Faculty of Dentistry, Umm Al-Qura University, Makkah, Saudi Arabia; School of Dentistry and Psychology, Faculty of Medicine & Health, University of Leeds, Leeds, West Yorkshire, United Kingdom; School of Medicine, Faculty of Medicine & Health, University of Leeds, Leeds, West Yorkshire, United Kingdom; Faculty of Medicine & Health, University of Leeds, St James's University Hospital, Leeds, West Yorkshire, United Kingdom; School of Psychology, Faculty of Medicine & Health, University of Leeds, Leeds, West Yorkshire, United Kingdom; Leeds Teaching Hospitals NHS Trust, Department of Urology, Leeds, West Yorkshire, United Kingdom; HPB and Transplant Unit, St James's University Hospital, Leeds, West Yorkshire, United Kingdom; School of Psychology, Faculty of Medicine & Health, the Centre for Immersive Technologies, University of Leeds, Leeds, West Yorkshire, United Kingdom; School of Dentistry, Faculty of Medicine & Health, University of Leeds, Leeds, West Yorkshire, United Kingdom","Balkhoyor, A.M., Department of Preventive Dentistry, Faculty of Dentistry, Umm Al-Qura University, Makkah, Saudi Arabia, School of Dentistry and Psychology, Faculty of Medicine & Health, University of Leeds, Leeds, West Yorkshire, United Kingdom; Mir, R., School of Medicine, Faculty of Medicine & Health, University of Leeds, Leeds, West Yorkshire, United Kingdom; Mirghani, I., School of Dentistry and Psychology, Faculty of Medicine & Health, University of Leeds, Leeds, West Yorkshire, United Kingdom; Pike, T.W., Faculty of Medicine & Health, University of Leeds, St James's University Hospital, Leeds, West Yorkshire, United Kingdom; Sheppard, W.E.A., School of Psychology, Faculty of Medicine & Health, University of Leeds, Leeds, West Yorkshire, United Kingdom; Biyani, C.S., Leeds Teaching Hospitals NHS Trust, Department of Urology, Leeds, West Yorkshire, United Kingdom; Lodge, J.P.A., HPB and Transplant Unit, St James's University Hospital, Leeds, West Yorkshire, United Kingdom; Mon-Williams, M.A., School of Psychology, Faculty of Medicine & Health, the Centre for Immersive Technologies, University of Leeds, Leeds, West Yorkshire, United Kingdom; Mushtaq, F., School of Psychology, Faculty of Medicine & Health, the Centre for Immersive Technologies, University of Leeds, Leeds, West Yorkshire, United Kingdom; Manogue, M., School of Dentistry, Faculty of Medicine & Health, University of Leeds, Leeds, West Yorkshire, United Kingdom","OBJECTIVE: The ability to simulate procedures in silico has transformed surgical training and practice. Today's simulators, designed for the training of a highly specialized set of procedures, also present a powerful scientific tool for understanding the neural control processes that underpin the learning and application of surgical skills. Here, we examined whether 2 simulators designed for training in 2 different surgical domains could be used to examine the extent to which fundamental sensorimotor skills transcend surgical specialty. DESIGN, SETTING & PARTICIPANTS: We used a high-fidelity virtual reality dental simulator and a laparoscopic box simulator to record the performance of 3 different groups. The groups comprised dentists, laparoscopic surgeons, and psychologists (each group n = 19). RESULTS: The results revealed a specialization of performance, with laparoscopic surgeons showing the highest performance on the laparoscopic box simulator, while dentists demonstrated the highest skill levels on the virtual reality dental simulator. Importantly, we also found that a transfer learning effect, with laparoscopic surgeons and dentists showing superior performance to the psychologists on both tasks. CONCLUSIONS: There are core sensorimotor skills that cut across surgical specialty. We propose that the identification of such fundamental skills could lead to improved training provision prior to specialization. © 2020 Association of Program Directors in Surgery","core surgical skills; learning transfer; sensorimotor; simulation; surgical training",,Article,"Article in Press","",Scopus,2-s2.0-85092014433
"Riemann T., Kreß A., Roth L., Klipfel S., Metternich J., Grell P.","57216947870;57194567019;57216952566;57216945850;6507096724;57216945501;","Agile implementation of virtual reality in learning factories",2020,"Procedia Manufacturing","45",,,"1","6",,5,"10.1016/j.promfg.2020.04.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085522794&doi=10.1016%2fj.promfg.2020.04.029&partnerID=40&md5=7eb2225c75269422795ea229476aa652","Technische Universität Darmstadt, Otto-Berndt-Str. 2, Darmstadt, 64287, Germany","Riemann, T., Technische Universität Darmstadt, Otto-Berndt-Str. 2, Darmstadt, 64287, Germany; Kreß, A., Technische Universität Darmstadt, Otto-Berndt-Str. 2, Darmstadt, 64287, Germany; Roth, L., Technische Universität Darmstadt, Otto-Berndt-Str. 2, Darmstadt, 64287, Germany; Klipfel, S., Technische Universität Darmstadt, Otto-Berndt-Str. 2, Darmstadt, 64287, Germany; Metternich, J., Technische Universität Darmstadt, Otto-Berndt-Str. 2, Darmstadt, 64287, Germany; Grell, P., Technische Universität Darmstadt, Otto-Berndt-Str. 2, Darmstadt, 64287, Germany","The concept of learning factories fulfills current learning theoretical requirements in terms of the situation, process orientation, as well as authenticity. Nevertheless, due to the high complexity of the industrial production environment, it is challenging to transfer learned skills into the operational application situation. With Virtual Reality, training participants have the ability to learn with transfer-oriented action tasks in virtual space directly after the training in physical learning environments. The learning process can be personalized and adapted in the virtual learning environment. Each participant in the training can individually determine elements of the learning situation. For example, the entire learning environment can be adapted to the individual real production environment of the training participant. Through Virtual Reality, new forms of reflection are possible, e.g. recording the learning process. Technical, didactic and organizational requirements were identified by a systematic literature analysis. The research project is based on training courses in the process learning factory “Center for industrial Productivity” (CiP) located at TU Darmstadt. In order to assess and prioritize the requirements, expert surveys were conducted. The surveys are based on the Kano model in order to classify requirements. Must-be quality requirements are implemented in a minimum viable product (MVP). The MVP allows fast learning by testing and experimenting. Based on the agile manifesto, further requirements can be implemented agilely in the virtual environment. © 2020 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0/) Peer-review under responsibility of the scientific committee of the 10th Conference on Learning Factories 2020.","Agile Project Management; Kano Model; Learning Factory; Learning Scenario; Virtual Reality",,Conference Paper,"Final","",Scopus,2-s2.0-85085522794
"Rockstroh C., Blum J., Göritz A.S.","57209661689;57191752660;6603271342;","A mobile VR-based respiratory biofeedback game to foster diaphragmatic breathing",2020,"Virtual Reality",,,,"","",,,"10.1007/s10055-020-00471-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092085540&doi=10.1007%2fs10055-020-00471-5&partnerID=40&md5=1146e157b67d14795bff15e197391f71","Department of Occupational and Consumer Psychology, Albert-Ludwigs-Universität Freiburg, Engelbergerstr. 41, Freiburg, 79106, Germany","Rockstroh, C., Department of Occupational and Consumer Psychology, Albert-Ludwigs-Universität Freiburg, Engelbergerstr. 41, Freiburg, 79106, Germany; Blum, J., Department of Occupational and Consumer Psychology, Albert-Ludwigs-Universität Freiburg, Engelbergerstr. 41, Freiburg, 79106, Germany; Göritz, A.S., Department of Occupational and Consumer Psychology, Albert-Ludwigs-Universität Freiburg, Engelbergerstr. 41, Freiburg, 79106, Germany","Virtual reality (VR) has become popular in mental health research. Several studies have explored the use of VR in the context of biofeedback protocols. In the present paper, we report on the development and evaluation of a VR-based respiratory biofeedback game to foster diaphragmatic breathing. The game integrates respiratory biofeedback, restorative VR and gamification. The game is designed to run on a mobile, all-in-one VR headset. Notably, an integrated VR hand controller is utilized as a sensor to detect respiration-induced movements of the diaphragm. In a longitudinal within-subjects study, we explored the feasibility of the game and tested the effectiveness of six training sessions. Participants reported a pleasant user experience. Moreover, the results show that the brief VR-based breathing training increased perceived breath awareness, improved diaphragmatic breathing, increased relaxation, decreased perceived stress, reduced symptoms of burnout and boosted relaxation-related self-efficacy. Future studies need to address the generalizability and long-term stability of the results, compare the approach with existing treatments and fine-tune the training components. © 2020, The Author(s).","Diaphragmatic breathing; Respiratory biofeedback; Self-efficacy; Serious game; Stress reduction; Virtual reality","Biofeedback; User experience; Long term stability; Mental health; Self efficacy; Training sessions; Virtual reality",Article,"Article in Press","",Scopus,2-s2.0-85092085540
"Lyons K.D., Slaughenhaupt R.M., Mupparaju S.H., Lim J.S., Anderson A.A., Stankovic A.S., Cowan D.R., Fellows A.M., Binsted K.A., Buckey J.C.","57192428122;57221276743;57221276412;57221276972;57221275884;57197902798;57194430574;9939328400;8562364900;7003913960;","Autonomous Psychological Support for Isolation and Confinement",2020,"Aerospace Medicine and Human Performance","91","11",,"876","885",,,"10.3357/AMHP.5705.2020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098675681&doi=10.3357%2fAMHP.5705.2020&partnerID=40&md5=2b74ff07b83a33a189395fcdac791ada","Psychiatry Research, Dartmouth-Hitchcock Medical CenterNH, Lebanon; Space Medicine Innovations Laboratory, Geisel School of Medicine at DartmouthNH, Lebanon; Sidney Kimmel Medical College, Thomas Jefferson University, Philadelphia, PA, United States; Smead Aerospace Engineering Sciences, University of Colorado at Boulder, BoulderCO, United States; Department of Psychiatry, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Information and Computer Sciences University of Hawaii at Manoa, Honolulu, HI, United States","Lyons, K.D., Psychiatry Research, Dartmouth-Hitchcock Medical CenterNH, Lebanon; Slaughenhaupt, R.M., Space Medicine Innovations Laboratory, Geisel School of Medicine at DartmouthNH, Lebanon; Mupparaju, S.H., Sidney Kimmel Medical College, Thomas Jefferson University, Philadelphia, PA, United States; Lim, J.S., Space Medicine Innovations Laboratory, Geisel School of Medicine at DartmouthNH, Lebanon; Anderson, A.A., Smead Aerospace Engineering Sciences, University of Colorado at Boulder, BoulderCO, United States; Stankovic, A.S., Department of Psychiatry, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Cowan, D.R., Space Medicine Innovations Laboratory, Geisel School of Medicine at DartmouthNH, Lebanon; Fellows, A.M., Space Medicine Innovations Laboratory, Geisel School of Medicine at DartmouthNH, Lebanon; Binsted, K.A., Information and Computer Sciences University of Hawaii at Manoa, Honolulu, HI, United States; Buckey, J.C., Space Medicine Innovations Laboratory, Geisel School of Medicine at DartmouthNH, Lebanon","INTRODUCTION: Isolated and confined environments (ICEs), such as spaceflight, are challenging psychologically. We have been evaluating self-directed tools to sustain and improve psychological well-being in these settings. The Expedition Application for Peak Psychological Performance (Expedition-APPP) is an interactive media-based set of self-directed tools that address conflict resolution, stress management, and depression treatment. Virtual reality (VR) of nature scenes is a tool to improve attention and relieve stress by providing users with an immersive nature experience. We evaluated both Expedition-APPP and VR in an ICE. METHODS: The Expedition-APP was evaluated during three, and nature VR during two, deployments at the HI-SEAS habitat, where crews of six were isolated for 8–12 mo. Participants used both the Expedition-APPP and VR and shared their feedback and experiences after the deployments in semistructured interviews. These interviews were evaluated using qualitative analysis techniques to gather generalizable insights into implementing autonomous mental health programs for people living and working in ICEs. RESULTS: Expedition-APPP modules provided a shared culture, language, and tools for working through challenges. VR allowed for access to emotions and experiences that were unavailable in the habitat. Suggestions for improvement included making refresher training easily available and providing a wider range of content to address different individuals’ coping styles. DISCUSSION: Both the Expedition-APPP and VR were appreciated and used, although a wider range of content and experiences was desired by participants. © 2020. All Rights Reserved.","depression; mental health.; qualitative research; virtual reality","adult; article; attention; female; habitat; human; human experiment; language; male; mental health; qualitative analysis; semi structured interview; stress; virtual reality",Article,"Final","",Scopus,2-s2.0-85098675681
"Zhao X., Liu C., Xu Z., Zhang L., Zhang R.","17436661300;57214105967;57214126904;57201266084;56898266500;","SSVEP Stimulus Layout Effect on Accuracy of Brain-Computer Interfaces in Augmented Reality Glasses",2020,"IEEE Access","8",, 8947980,"5990","5998",,,"10.1109/ACCESS.2019.2963442","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078237308&doi=10.1109%2fACCESS.2019.2963442&partnerID=40&md5=149148c8923287a093bfa864726e505a","School of Information Engineering, Zhengzhou University, Zhengzhou, 450001, China; Henan Key Laboratory of Brain Science and Brain-Computer Interface Technology, School of Electrical Engineering, Zhengzhou University, Zhengzhou, 450001, China","Zhao, X., School of Information Engineering, Zhengzhou University, Zhengzhou, 450001, China; Liu, C., School of Information Engineering, Zhengzhou University, Zhengzhou, 450001, China; Xu, Z., Henan Key Laboratory of Brain Science and Brain-Computer Interface Technology, School of Electrical Engineering, Zhengzhou University, Zhengzhou, 450001, China; Zhang, L., Henan Key Laboratory of Brain Science and Brain-Computer Interface Technology, School of Electrical Engineering, Zhengzhou University, Zhengzhou, 450001, China; Zhang, R., Henan Key Laboratory of Brain Science and Brain-Computer Interface Technology, School of Electrical Engineering, Zhengzhou University, Zhengzhou, 450001, China","Steady-state visual evoked potentials-based brain-computer interfaces (SSVEP-BCI) has the advantage of high information transfer rate (ITR) and little user training, and it has a high application value in the field of disability assistance and human-computer interaction. Generally SSVEP-BCI requires a personal computer screen (PC) to display several repetitive visual stimuli for inducing the SSVEP response, which reduces its portability and flexibility. Using augmented reality (AR) glasses worn on the head to display the repetitive visual stimuli could solve the above drawbacks, but whether it could achieve the same accuracy as PC screen in the case of reduced brightness and increased interference is unknown. In current study, we firstly designed 4 stimulus layouts and displayed them with Microsoft HoloLens (AR-SSVEP) glasses, comparison analysis showed that the classification accuracies are influenced by the stimulus layout when the stimulus duration is less than 3s. When the stimulus duration exceeds 3s, there is no significant accuracy difference between the 4 layouts. Then we designed a similar experimental paradigm on PC screen (PC-SSVEP) based on the best layout of AR. Classification results showed that AR-SSVEP achieved similar accuracy with PC-SSVEP when the stimulus duration is more than 3s, but when the stimulus duration is less than 2s, the accuracy of AR-SSVEP is lower than PC-SSVEP. Brain topological analysis indicated that the spatial distribution of SSVEP responses is similar, both of which are strongest in the occipital region. Current study indicated that stimulus layout is a key factor when building SSVEP-BCI with AR glasses, especially when the stimulation time is short. © 2013 IEEE.","augmented reality (AR); brain-computer interfaces (BCI); human-computer interaction; optical see-through (OST); Steady-state visual evoked potentials (SSVEP)","Augmented reality; Electrophysiology; Glass; Human computer interaction; Interface states; Personal computers; Topology; Classification accuracy; Classification results; Comparison analysis; High application value; Information transfer rate; Optical see-through; Steady state visual evoked potentials; Topological analysis; Brain computer interface",Article,"Final","",Scopus,2-s2.0-85078237308
"Parong J., Mayer R.E.","56520185200;7403065717;","Cognitive consequences of playing brain-training games in immersive virtual reality",2020,"Applied Cognitive Psychology","34","1",,"29","38",,1,"10.1002/acp.3582","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068404428&doi=10.1002%2facp.3582&partnerID=40&md5=634faef9fd69b550d99e1caed28751d8","Psychological and Brain Sciences Department, University of California, Santa Barbara, Santa Barbara, CA, United States","Parong, J., Psychological and Brain Sciences Department, University of California, Santa Barbara, Santa Barbara, CA, United States; Mayer, R.E., Psychological and Brain Sciences Department, University of California, Santa Barbara, Santa Barbara, CA, United States","The goal of the present study was to examine the effects of playing an immersive virtual reality game that included a collection of gamified cognitive tasks, Cerevrum, on specific components of cognition, including perceptual attention, mental rotation, working memory, visualization, visual field of view, and visual processing speed. Participants completed a pretest of cognitive assessments, played one of the two mini-games within Cerevrum (Stardust or Heroes) for 1.5 hr over three 30-min sessions and then completed a posttest of cognitive assessments and a questionnaire about interest and engagement during the game. An inactive control group completed only the pretest and posttest. Results showed no significant differences among the Heroes group, Stardust group, and control group on the posttest scores, even when controlled for pretest scores. These findings do not support the claim that playing brain-training games for a short period results in transfer of cognitive training to nongame venues. © 2019 John Wiley & Sons, Ltd.","brain training games; cognitive skill training; game-based learning; immersive virtual reality; video games","adult; Article; attention; behavior; cognition; controlled study; data visualization; exercise; experimental cognitive test; female; game; human; human experiment; intelligence; male; mental rotation test; Montreal cognitive assessment; nerve cell plasticity; power analysis; priority journal; questionnaire; skill; task performance; training; video game; virtual reality; young adult",Article,"Final","",Scopus,2-s2.0-85068404428
"Schwarze A., Kampling H., Niehaves B.","57217049797;57189869875;12139031400;","Advantages and propositions of learning emotion recognition in virtual reality for people with austism",2020,"27th European Conference on Information Systems - Information Systems for a Sharing Society, ECIS 2019",,,,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087108839&partnerID=40&md5=3f886071823c7f5052fd3f89580e1d9f","University of Siegen, Siegen, Germany","Schwarze, A., University of Siegen, Siegen, Germany; Kampling, H., University of Siegen, Siegen, Germany; Niehaves, B., University of Siegen, Siegen, Germany","People with an autism spectrum disorder face the daily challenge of social interactions - particularly in non-verbal communication. These difficulties make adequate interpersonal interactions “in real-time” a challenging obstacle to overcome in many cases and can lead to excessive demands, frustration and isolation (low level of Theory of Mind). Emotion cards are usually used in autism therapy to learn basic skills for recognizing emotions. Learning with autism is characterized by spontaneous - sometimes-extraordinary - mastery of complex contents. People with autism learn facts, details and routines well but have difficulties to transfer the learned contents to another context (Weak Central Coherence) or to react flexible to unpredicted events (low Executive Function). In addition, research has shown that autistics learn social competences while using a computer and performing practical exercises. Such systems provide the possibility to use an accepted computer simulated (virtual) environment in which autistic children can be taught social competences as emotion recognition. Consequently, we assume that learning emotion recognition in virtual learning environments can remove barriers and obstacles for autistics as they are more successful in solving social problems. Therefore, we are discussing in the paper at hand the potentials of how emotion recognition can be learned in virtual reality. © 27th European Conference on Information Systems - Information Systems for a Sharing Society, ECIS 2019. All rights reserved.","Autism; Case Study Research; Emotion Recognition Learning; Virtual Reality","Diseases; E-learning; Information systems; Information use; Speech recognition; Virtual reality; Autism spectrum disorders; Emotion recognition; Non-verbal communications; Recognizing emotions; Social competences; Social interactions; Virtual learning environments; Weak central coherences; Computer aided instruction",Conference Paper,"Final","",Scopus,2-s2.0-85087108839
"Kucukyilmaz A., Issak I.","13408746000;57211208447;","Online Identification of Interaction Behaviors from Haptic Data during Collaborative Object Transfer",2020,"IEEE Robotics and Automation Letters","5","1", 8854968,"96","102",,,"10.1109/LRA.2019.2945261","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072982745&doi=10.1109%2fLRA.2019.2945261&partnerID=40&md5=1cf1155574b1f564578949719ea7b38d","School of Computer Science, University of Lincoln, Lincoln, LN6 7TS, United Kingdom","Kucukyilmaz, A., School of Computer Science, University of Lincoln, Lincoln, LN6 7TS, United Kingdom; Issak, I., School of Computer Science, University of Lincoln, Lincoln, LN6 7TS, United Kingdom","Joint object transfer is a complex task, which is less structured and less specific than what is existing in several industrial settings. When two humans are involved in such a task, they cooperate through different modalities to understand the interaction states during operation and mutually adapt to one another's actions. Mutual adaptation implies that both partners can identify how well they collaborate (i.e. infer about the interaction state) and act accordingly. These interaction states can define whether the partners work in harmony, face conflicts, or remain passive during interaction. Understanding how two humans work together during physical interactions is important when exploring the ways a robotic assistant should operate under similar settings. This study acts as a first step to implement an automatic classification mechanism during ongoing collaboration to identify the interaction state during object co-manipulation. The classification is done on a dataset consisting of data from 40 subjects, who are partnered to form 20 dyads. The dyads experiment in a physical human-human interaction (pHHI) scenario to move an object in an haptics-enabled virtual environment to reach predefined goal configurations. In this study, we propose a sliding-window approach for feature extraction and demonstrate the online classification methodology to identify interaction patterns. We evaluate our approach using 1) a support vector machine classifier (SVMc) and 2) a Gaussian Process classifier (GPc) for multi-class classification, and achieve over ${\bf 80}\%$ accuracy with both classifiers when identifying general interaction types. © 2016 IEEE.","Classification; Feature Extraction; Force and Tactile Sensing; Haptics and Haptic Interfaces; Human Factors and Human-in-the-Loop; Learning and Adaptive Systems; Physical Human-Human Interaction; Physical Human-Robot Interaction; Recognition","Classification (of information); Extraction; Feature extraction; Haptic interfaces; Support vector machines; Virtual reality; Haptics and haptic interfaces; Human-human interactions; Human-in-the-loop; Learning and adaptive system; Physical human-robot interactions; Recognition; Tactile sensing; Human robot interaction",Article,"Final","",Scopus,2-s2.0-85072982745
"Kieu D., Luecke G.R., Gilbert S., Hunt T., Gilmore B., Meusel C., Kelly N.","57201394306;7004212933;14041448900;57201390342;35920397800;57190619218;55841195700;","Listening to the voice of the customer using an immersive combine simulator: Innovative techniques for product development",2020,"International Journal of Heavy Vehicle Systems","27","3",,"303","324",,,"10.1504/IJHVS.2020.108738","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091451479&doi=10.1504%2fIJHVS.2020.108738&partnerID=40&md5=b67495f13d4b1e073ee37d3c676fd281","Department of Mechanical Engineering, Iowa State University, Ames, IA  50011, United States; Virtual Reality Applications Center, Iowa State University, Ames, IA  50011, United States; John Deere Global Crop Harvesting, John Deere, East Moline, IL  61244, United States","Kieu, D., Department of Mechanical Engineering, Iowa State University, Ames, IA  50011, United States; Luecke, G.R., Department of Mechanical Engineering, Iowa State University, Ames, IA  50011, United States; Gilbert, S., Virtual Reality Applications Center, Iowa State University, Ames, IA  50011, United States; Hunt, T., John Deere Global Crop Harvesting, John Deere, East Moline, IL  61244, United States; Gilmore, B., John Deere Global Crop Harvesting, John Deere, East Moline, IL  61244, United States; Meusel, C., Virtual Reality Applications Center, Iowa State University, Ames, IA  50011, United States; Kelly, N., Virtual Reality Applications Center, Iowa State University, Ames, IA  50011, United States","This work describes a combine harvester simulator and virtual environment (VE). This interactive and realistic simulator is a novel and unique apparatus used for development and testing of human-machine systems during the design of agricultural vehicles and systems. The combine simulator and VE are being used to develop and evaluate new technologies and automated systems. The simulator provides an innovative testing platform in which to conduct active harvesting experiments that would otherwise be difficult or impossible to perform. The successes of two studies, 'auger spout aiming' and 'combine implement adjust' are described, including experimental results. The novel approach used with this simulator to acquire the voice of the customer can be generalised to the development of other products with a human interface, and applications in other domains are considered. Copyright © 2020 Inderscience Enterprises Ltd.","Computer graphics; Human computer interaction; Product development; Simulation; Systems simulation; User centred design; User interfaces; Virtual reality","Agricultural robots; Automation; Sentiment analysis; Simulators; Agricultural vehicles; Automated systems; Combine harvesters; Development and testing; Innovative techniques; Realistic simulators; Testing platforms; Voice of the customer; Combines",Article,"Final","",Scopus,2-s2.0-85091451479
"Koumaditis K., Chinello F., Mitkidis P., Karg S.T.","36666503100;36455475300;55734672700;57205264555;","Effectiveness of Virtual vs. Physical Training: The Case of Assembly Tasks, Trainer&#x0027;s Verbal Assistance and Task Complexity",2020,"IEEE Computer Graphics and Applications",,,,"","",,1,"10.1109/MCG.2020.3006330","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087495332&doi=10.1109%2fMCG.2020.3006330&partnerID=40&md5=9db15b279f39e679ba8ae86d5ee1a9c6","Business Development and Technology, Aarhus Universitet, 1006 Herning, rhus Denmark 15 (e-mail: kkoumaditis@btech.au.dk); Business Development and Technology, Aarhus Universitet, 1006 Herning, rhus Denmark (e-mail: chinello@btech.au.dk); Department of Management, Aarhus Universitet, 1006 Aarhus, rhus Denmark (e-mail: pm@mgmt.au.dk); Department of Management, Aarhus Universitet, 1006 Aarhus, rhus Denmark (e-mail: simonkarg@mgmt.au.dk)","Koumaditis, K., Business Development and Technology, Aarhus Universitet, 1006 Herning, rhus Denmark 15 (e-mail: kkoumaditis@btech.au.dk); Chinello, F., Business Development and Technology, Aarhus Universitet, 1006 Herning, rhus Denmark (e-mail: chinello@btech.au.dk); Mitkidis, P., Department of Management, Aarhus Universitet, 1006 Aarhus, rhus Denmark (e-mail: pm@mgmt.au.dk); Karg, S.T., Department of Management, Aarhus Universitet, 1006 Aarhus, rhus Denmark (e-mail: simonkarg@mgmt.au.dk)","Virtual Immersive Training (VIT) systems based on gamification of tasks are increasingly employed to train assembly workers. In this paper, we present a study that compares the effectiveness of virtual and physical training for teaching a bimanual assembly task and in a novel approach, we introduce Task Complexity (TCXB) as an indicator of assembly errors during final assembly. In a between-subjects experiment, 100 participants were trained to assemble a 3D cube in one of four conditions (physical, virtual and with trainer&#x0027;s verbal assistance or not). The results demonstrate that the best-performing conditions, both in terms of successful assemblies and time performance, are the ones that the physical objects are included in the training, while no significant difference is found when the trainer&#x0027;s verbal assistance is present or absent during training. Additionally, we address the validity of a practical TCXB list as a tool for supporting the design of VIT systems. IEEE","assembly; learning transfer; task complexity; training; virtual reality","Software architecture; Virtual reality; Assembly error; Assembly tasks; Assembly workers; Final assembly; Physical objects; Physical training; Successful assembly; Task complexity; E-learning; adult; article; comparative effectiveness; female; human; human experiment; major clinical study; male; teaching; training; validity",Article,"Article in Press","",Scopus,2-s2.0-85087495332
"Coelho A., Cardoso P., Van Zeller M., Santos L., Raimundo J., Vaz R.","23089899600;57192416173;57217996598;57217605046;57216526950;57220402899;","Gamifying the museological experience",2020,"CEUR Workshop Proceedings","2618",,,"5","8",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087832942&partnerID=40&md5=e6609bfec2f83285b55a85e428879493","FEUP, Faculty of Engineering, University of Porto, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal; FBAUP, Faculty of Fine Arts, University of Porto, Avenida Rodrigues de Freitas, 265, Porto, 4049-021, Portugal; INESC TEC, Institute for Systems and Computer Engineering, Technology and Science, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal","Coelho, A., FEUP, Faculty of Engineering, University of Porto, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal, INESC TEC, Institute for Systems and Computer Engineering, Technology and Science, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal; Cardoso, P., FEUP, Faculty of Engineering, University of Porto, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal, FBAUP, Faculty of Fine Arts, University of Porto, Avenida Rodrigues de Freitas, 265, Porto, 4049-021, Portugal, INESC TEC, Institute for Systems and Computer Engineering, Technology and Science, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal; Van Zeller, M., FEUP, Faculty of Engineering, University of Porto, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal; Santos, L., FEUP, Faculty of Engineering, University of Porto, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal; Raimundo, J., FEUP, Faculty of Engineering, University of Porto, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal, INESC TEC, Institute for Systems and Computer Engineering, Technology and Science, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal; Vaz, R., FEUP, Faculty of Engineering, University of Porto, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal","Museums continue to exert fascination in their visitors. However, the new generation of visitors expects museological experiences that promote their active participation. It is in this context that games and the gamification of such experiences capitalize on experiential learning by experimenting and enacting with in-game embedded artefact surrogates and know-how. In this article, we present four distinct projects that aim to enhance the visitors' experience in museums and green spaces, and also their effectiveness in informal learning. In the first project, gamification is used in combination with Augmented Reality to provide a more engaging experience in a boat museum. The drive of this experience is the metaphor of the stickers album collection to unleash the relevant information of the key-artefacts of the museum collection. The second and third projects focus on the use of pervasive games, more specifically location-based games, to enhance the visitors' experience and informal learning in a natural park and a botanical garden, respectively. The second project presents the concept of a mobile app for outdoor nature experiences. The drive for the experience in the third project is the narrative that intertwines specific locations in the botanic garden and a story inspired by the same place. Finally, in the fourth project, we focus on the potential of technology to provide accessibility in museums for people with special needs or disability, focusing more specifically on blind visitors. Copyright © 2020 for this paper by its authors.","Accessibility; Augmented Reality; Gamification; Location-based games; Pervasive games","Augmented reality; Gamification; Human computer interaction; Technology transfer; Botanical gardens; Experiential learning; Informal learning; Location based games; Museum collections; Pervasive game; Special needs; Specific location; Museums",Conference Paper,"Final","",Scopus,2-s2.0-85087832942
"Bube S., Dagnaes-Hansen J., Mahmood O., Rohrsted M., Bjerrum F., Salling L., Hansen R.B., Konge L.","57194870607;57196468497;57189755996;55102715900;55023838200;56884534500;57211445506;36704959000;","Simulation-based training for flexible cystoscopy – A randomized trial comparing two approaches",2020,"Heliyon","6","1", e03086,"","",,,"10.1016/j.heliyon.2019.e03086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078583061&doi=10.1016%2fj.heliyon.2019.e03086&partnerID=40&md5=41e0092b12957eee50dff66952e99298","Department of Urology, Roskilde Hospital, Zealand University Hospital, University of Copenhagen, Zealand Region, Roskilde, Denmark; Copenhagen Academy for Medical Education and Simulation, Rigshospitalet, University of Copenhagen, Capital Region, Copenhagen, Denmark; Department of Urology, Rigshospitalet, University of Copenhagen, Capital Region, Copenhagen, Denmark; Department of Surgery, Herlev/Gentofte Hospital, University of Copenhagen, Capital Region, Copenhagen, Denmark; Department of Anaesthesiology, Holbaek Hospital, Zealand Region, Holbaek, Denmark; Department of Urology, Herlev/Gentofte Hospital, University of Copenhagen, Capital Region, Copenhagen, Denmark","Bube, S., Department of Urology, Roskilde Hospital, Zealand University Hospital, University of Copenhagen, Zealand Region, Roskilde, Denmark, Copenhagen Academy for Medical Education and Simulation, Rigshospitalet, University of Copenhagen, Capital Region, Copenhagen, Denmark; Dagnaes-Hansen, J., Copenhagen Academy for Medical Education and Simulation, Rigshospitalet, University of Copenhagen, Capital Region, Copenhagen, Denmark, Department of Urology, Rigshospitalet, University of Copenhagen, Capital Region, Copenhagen, Denmark; Mahmood, O., Copenhagen Academy for Medical Education and Simulation, Rigshospitalet, University of Copenhagen, Capital Region, Copenhagen, Denmark, Department of Anaesthesiology, Holbaek Hospital, Zealand Region, Holbaek, Denmark; Rohrsted, M., Department of Urology, Rigshospitalet, University of Copenhagen, Capital Region, Copenhagen, Denmark; Bjerrum, F., Copenhagen Academy for Medical Education and Simulation, Rigshospitalet, University of Copenhagen, Capital Region, Copenhagen, Denmark, Department of Surgery, Herlev/Gentofte Hospital, University of Copenhagen, Capital Region, Copenhagen, Denmark; Salling, L., Department of Urology, Rigshospitalet, University of Copenhagen, Capital Region, Copenhagen, Denmark; Hansen, R.B., Copenhagen Academy for Medical Education and Simulation, Rigshospitalet, University of Copenhagen, Capital Region, Copenhagen, Denmark, Department of Urology, Herlev/Gentofte Hospital, University of Copenhagen, Capital Region, Copenhagen, Denmark; Konge, L., Copenhagen Academy for Medical Education and Simulation, Rigshospitalet, University of Copenhagen, Capital Region, Copenhagen, Denmark","Background: Simulation-based training allows trainees to experiment during training and end-of-training tests could increase motivation and retention. The aim of this trial was to determine if a simulation-based training program including directed self-regulated learning and post-testing improved clinical outcomes compared to a traditional simulation-based training program. Methods: A randomized trial was conducted involving 32 participants without prior experience in endoscopic procedures. The intervention group practiced independently in a simulation centre and got a post-test whereas the control group received traditional instructions and demonstrations before being allowed to practice. Three weeks after the intervention the participants performed cystoscopies on two consecutive patients. Clinical performance was assessed using a global rating scale (GRS) with established evidence of validity. Independent samples t-test, Cronbach's α, Pearson's r, and paired samples t-test were used for statistical analysis. Results: Twenty-five participants performed two cystoscopies on patients. There was no significant difference between the two study groups with respect to mean GRS of performance (p = 0.63, 95 % CI; -2.4–3.9). The internal consistency of the global rating scale was high, Cronbach's α = 0.91. Participants from both study groups demonstrated significant improvement between the first and second clinical procedures (p = 0.004, 95 % CI, 0.8–3.5). Eight (32%) and 15 (60%) participants demonstrated adequate clinical skills in their first and second procedure, respectively. Conclusions: No significant differences were found on the clinical transfer when comparing the two programs. Neither of our training programs was able to ensure consistent, competent performance on patients and this finding could serve as an important argument for simulation-based mastery learning where all training continues until a pre-defined level of proficiency is met. Trial registrations: The trial was submitted before enrolment of participants to the Regional Scientific Ethics Committee of the Capital Region which established that ethical approval was not necessary (H-4-2014-122). The trial was registered at Clinicaltrials.gov (NCT02411747). Health profession; Medicine; Education; Directed self-regulated learning; Mastery learning; Transfer; Testing effect; Flexible cystoscopy; Virtual reality simulators © 2019 Copenhagen Academy for Medical Education and Simulation, Rigshospitalet, Copenhagen, Capital Region, Denmark","Directed self-regulated learning; Education; Flexible cystoscopy; Health profession; Mastery learning; Medicine; Testing effect; Transfer; Virtual reality simulators",,Article,"Final","",Scopus,2-s2.0-85078583061
"Bellieny-Rabelo D., Nkomo N.P., Shyntum D.Y., Moleleki L.N.","55584559200;57211624338;56046133900;22958459600;","Horizontally Acquired Quorum-Sensing Regulators Recruited by the PhoP Regulatory Network Expand the Host Adaptation Repertoire in the Phytopathogen Pectobacterium brasiliense",2020,"mSystems","5","1", e00650-19,"","",,1,"10.1128/mSystems.00650-19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079229905&doi=10.1128%2fmSystems.00650-19&partnerID=40&md5=a4776cb06c2c2c30ad6daf2baaa1b3d5","Department of Biochemistry, Genetics and Microbiology, University of Pretoria, Pretoria, Gauteng, South Africa; Forestry and Agricultural Biotechnology Institute, University of Pretoria, Pretoria, Gauteng, South Africa","Bellieny-Rabelo, D., Department of Biochemistry, Genetics and Microbiology, University of Pretoria, Pretoria, Gauteng, South Africa, Forestry and Agricultural Biotechnology Institute, University of Pretoria, Pretoria, Gauteng, South Africa; Nkomo, N.P., Department of Biochemistry, Genetics and Microbiology, University of Pretoria, Pretoria, Gauteng, South Africa, Forestry and Agricultural Biotechnology Institute, University of Pretoria, Pretoria, Gauteng, South Africa; Shyntum, D.Y., Department of Biochemistry, Genetics and Microbiology, University of Pretoria, Pretoria, Gauteng, South Africa, Forestry and Agricultural Biotechnology Institute, University of Pretoria, Pretoria, Gauteng, South Africa; Moleleki, L.N., Department of Biochemistry, Genetics and Microbiology, University of Pretoria, Pretoria, Gauteng, South Africa, Forestry and Agricultural Biotechnology Institute, University of Pretoria, Pretoria, Gauteng, South Africa","In this study, we examine the impact of transcriptional network rearrangements driven by horizontal gene acquisition in PhoP and SlyA regulons using as a case study a phytopathosystem comprised of potato tubers and the soft-rot pathogen Pectobacterium brasiliense 1692 (Pb1692). Genome simulations and statistical analyses uncovered the tendency of PhoP and SlyA networks to mobilize lineage-specific traits predicted as horizontal gene transfer at late infection, highlighting the prominence of regulatory network rearrangements in this stage of infection. The evidence further supports the circumscription of two horizontally acquired quorum-sensing regulators (carR and expR1) by the PhoP network. By recruiting carR and expR1, the PhoP network also impacts certain host adaptation- and bacterial competition-related systems, seemingly in a quorum sensing-dependent manner, such as the type VI secretion system, carbapenem biosynthesis, and plant cell wall-degrading enzymes (PCWDE) like cellulases and pectate lyases. Conversely, polygalacturonases and the type III secretion system (T3SS) exhibit a transcriptional pattern that suggests quorum-sensing-independent regulation by the PhoP network. This includes an uncharacterized novel phage-related gene family within the T3SS gene cluster that has been recently acquired by two Pectobacterium species. The evidence further suggests a PhoP-dependent regulation of carbapenem- and PCWDE-encoding genes based on the synthesized products’ optimum pH. The PhoP network also controls slyA expression in planta, which seems to impact carbohydrate metabolism regulation, especially at early infection, when 76.2% of the SlyA-regulated genes from that category also require PhoP to achieve normal expression levels. IMPORTANCE Exchanging genetic material through horizontal transfer is a critical mechanism that drives bacteria to efficiently adapt to host defenses. In this report, we demonstrate that a specific plant-pathogenic species (from the Pectobacterium genus) successfully integrated a population density-based behavior system (quorum sensing) acquired through horizontal transfer into a resident stress-response gene regulatory network controlled by the PhoP protein. Evidence found here underscores that subsets of bacterial weaponry critical for colonization, typically known to respond to quorum sensing, are also controlled by PhoP. Some of these traits include different types of enzymes that can efficiently break down plant cell walls depending on the environmental acidity level. Thus, we hypothesize that PhoP’s ability to elicit regulatory responses based on acidity and nutrient availability fluctuations has strongly impacted the fixation of its regulatory connection with quorum sensing. In addition, another global gene regulator, known as SlyA, was found under the PhoP regulatory network. The SlyA regulator controls a series of carbohydrate metabolism-related traits, which also seem to be regulated by PhoP. By centralizing quorum sensing and slyA under PhoP scrutiny, Pectobacterium cells added an advantageous layer of control over those two networks that potentially enhances colonization efficiency. © 2020 Bellieny-Rabelo et al.","Carbapenems; Gene regulatory networks; Horizontal gene transfer; Pectobacterium; Quorum sensing; Type III secretion systems; Type VI secretion systems","carbapenem; cellulase; pecs protein; pectate lyase; PhoP protein; polygalacturonase; protein; RNA; slya protein; unclassified drug; Article; controlled study; gene cluster; gene regulatory network; horizontal gene transfer; host; multigene family; nonhuman; operon; Pectobacterium; Pectobacterium brasiliense; potato; promoter region; quorum sensing; real time reverse transcription polymerase chain reaction; regulon; RNA sequence; soft rot; transcription regulation; type III secretion system; type VI secretion system",Article,"Final","",Scopus,2-s2.0-85079229905
"Papanastasiou G., Drigas A., Skianis C., Lytras M., Papanastasiou E.","56205162600;8662839500;15124619200;55830169000;57195954324;","Virtual and augmented reality effects on K-12, higher and tertiary education students’ twenty-first century skills",2019,"Virtual Reality","23","4",,"425","436",,21,"10.1007/s10055-018-0363-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053216727&doi=10.1007%2fs10055-018-0363-2&partnerID=40&md5=8c4e5953263f908e07bb10c44dfd8d19","NCSR Demokritos, Patr. Gregoriou E’ & 27, Neapoleos str., Agia Paraskevi, 15341, Greece; University of Aegean, Karlovassi, Samos, 83200, Greece; The American College of Greece, 6 Gravias str., Agia Paraskevi, 15342, Greece; King Abdulaziz University, Jeddah, Saudi Arabia; National Technical University of Athens, Zografou Campus 9, Iroon Polytechniou str., Athens, 15780, Greece","Papanastasiou, G., NCSR Demokritos, Patr. Gregoriou E’ & 27, Neapoleos str., Agia Paraskevi, 15341, Greece, University of Aegean, Karlovassi, Samos, 83200, Greece; Drigas, A., NCSR Demokritos, Patr. Gregoriou E’ & 27, Neapoleos str., Agia Paraskevi, 15341, Greece; Skianis, C., University of Aegean, Karlovassi, Samos, 83200, Greece; Lytras, M., The American College of Greece, 6 Gravias str., Agia Paraskevi, 15342, Greece, King Abdulaziz University, Jeddah, Saudi Arabia; Papanastasiou, E., National Technical University of Athens, Zografou Campus 9, Iroon Polytechniou str., Athens, 15780, Greece","The purpose of this review article is to present state-of-the-art approaches and examples of virtual reality/augmented reality (VR/AR) systems, applications and experiences which improve student learning and the generalization of skills to the real world. Thus, we provide a brief, representative and non-exhaustive review of the current research studies, in order to examine the effects, as well as the impact of VR/AR technologies on K-12, higher and tertiary education students’ twenty-first century skills and their overall learning. According to the literature, there are promising results indicating that VR/AR environments improve learning outcomes and present numerous advantages of investing time and financial resources in K-12, higher and tertiary educational settings. Technological tools such as VR/AR improve digital-age literacy, creative thinking, communication, collaboration and problem solving ability, which constitute the so-called twenty-first century skills, necessary to transform information rather than just receive it. VR/AR enhances traditional curricula in order to enable diverse learning needs of students. Research and development relative to VR/AR technology is focused on a whole ecosystem around smart phones, including applications and educational content, games and social networks, creating immersive three-dimensional spatial experiences addressing new ways of human–computer interaction. Raising the level of engagement, promoting self-learning, enabling multi-sensory learning, enhancing spatial ability, confidence and enjoyment, promoting student-centered technology, combination of virtual and real objects in a real setting and decreasing cognitive load are some of the pedagogical advantages discussed. Additionally, implications of a growing VR/AR industry investment in educational sector are provided. It can be concluded that despite the fact that there are various barriers and challenges in front of the adoption of virtual reality on educational practices, VR/AR applications provide an effective tool to enhance learning and memory, as they provide immersed multimodal environments enriched by multiple sensory features. © 2018, Springer-Verlag London Ltd., part of Springer Nature.","Higher education; K-12; Tertiary education; Twenty-first century skills; Virtual and augmented reality","Augmented reality; Computer games; E-learning; Human computer interaction; Problem solving; Smartphones; Social sciences computing; Virtual reality; Higher education; Multi-sensory learning; Problem-solving abilities; Research and development; State-of-the-art approach; Tertiary education; Twenty-first century skills; Virtual and augmented reality; Students",Article,"Final","",Scopus,2-s2.0-85053216727
"Makransky G., Borre-Gude S., Mayer R.E.","50361371800;57209681979;7403065717;","Motivational and cognitive benefits of training in immersive virtual reality based on multiple assessments",2019,"Journal of Computer Assisted Learning","35","6",,"691","707",,36,"10.1111/jcal.12375","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067604165&doi=10.1111%2fjcal.12375&partnerID=40&md5=4254d76dbce5eee871a9f331659adb0f","Department of Psychology, University of Copenhagen, Copenhagen, Denmark; School of Engineering, University of Aarhus, Aarhus, Denmark; Department of Psychological and Brain Sciences, University of California, Santa Barbara, Santa Barbara, CA, United States","Makransky, G., Department of Psychology, University of Copenhagen, Copenhagen, Denmark; Borre-Gude, S., School of Engineering, University of Aarhus, Aarhus, Denmark; Mayer, R.E., Department of Psychological and Brain Sciences, University of California, Santa Barbara, Santa Barbara, CA, United States","The main objective of this study was to examine the effectiveness of immersive virtual reality (VR) as a medium for delivering laboratory safety training. We specifically compare an immersive VR simulation, a desktop VR simulation, and a conventional safety manual. The sample included 105 first year undergraduate engineering students (56 females). We include five types of learning outcomes including post-test enjoyment ratings; pre- to post-test changes in intrinsic motivation and self-efficacy; a post-test multiple choice retention test; and two behavioral transfer tests. Results indicated that the groups did not differ on the immediate retention test, suggesting that all three media were equivalent in conveying the basic knowledge. However, significant differences were observed favoring the immersive VR group compared to the text group on the two transfer tests involving the solving problems in a physical lab setting (d = 0.54, d = 0.57), as well as enjoyment (d = 1.44) and increases in intrinsic motivation (d = 0.69) and self-efficacy (d = 0.60). The desktop VR group scored significantly higher than the text group on one transfer test (d = 0.63) but not the other (d= 0.11), as well as enjoyment (d =1.11) and intrinsic motivation (d =0.83). © 2019 John Wiley & Sons Ltd","delayed transfer test; multimedia learning; safety training; simulation; virtual reality",,Article,"Final","",Scopus,2-s2.0-85067604165
"Abidi M.H., Al-Ahmari A., Ahmad A., Ameen W., Alkhalefah H.","55582207400;6603483674;8244331200;56789986100;57203434201;","Assessment of virtual reality-based manufacturing assembly training system",2019,"International Journal of Advanced Manufacturing Technology","105","9",,"3743","3759",,12,"10.1007/s00170-019-03801-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066028866&doi=10.1007%2fs00170-019-03801-3&partnerID=40&md5=eb3341de426ddac10e671c4a1662aee4","Raytheon Chair for Systems Engineering (RCSE Chair), Advanced Manufacturing Institute, King Saud University, Riyadh, 11421, Saudi Arabia; Industrial Engineering Department, College of Engineering, King Saud University, Riyadh, 11421, Saudi Arabia; Louisiana Community and Technical College System-Manufacturing Extension Partnership, Baton Rouge, LA, United States; Advanced Manufacturing Institute, King Saud University, Riyadh, 11421, Saudi Arabia","Abidi, M.H., Raytheon Chair for Systems Engineering (RCSE Chair), Advanced Manufacturing Institute, King Saud University, Riyadh, 11421, Saudi Arabia, Industrial Engineering Department, College of Engineering, King Saud University, Riyadh, 11421, Saudi Arabia; Al-Ahmari, A., Raytheon Chair for Systems Engineering (RCSE Chair), Advanced Manufacturing Institute, King Saud University, Riyadh, 11421, Saudi Arabia, Industrial Engineering Department, College of Engineering, King Saud University, Riyadh, 11421, Saudi Arabia; Ahmad, A., Louisiana Community and Technical College System-Manufacturing Extension Partnership, Baton Rouge, LA, United States; Ameen, W., Raytheon Chair for Systems Engineering (RCSE Chair), Advanced Manufacturing Institute, King Saud University, Riyadh, 11421, Saudi Arabia; Alkhalefah, H., Advanced Manufacturing Institute, King Saud University, Riyadh, 11421, Saudi Arabia","Digital manufacturing concept is gaining a lot of attention and popularity due to its enormous benefits. It is considered as one of the pillars or component of Industry 4.0. With the advancements in technology, digital manufacturing is becoming a reality rather than a concept only. It is applied to various stages of the manufacturing process such as design, prototyping, and assembly training. Virtual reality (VR) is a cog in a wheel of digital manufacturing. It can be used in various phases of manufacturing. Planning and conducting assembly operations account for the majority of the cost of a product. It is difficult to design and train assembly operations during the early stages of product design. Assembly is a vital step in manufacturing, so firms provide training to their employees and it costs them time and money. Therefore, this research work extends VR applications in manufacturing by integrating concepts and studies from training simulations to the evaluation of assembly training effectiveness and transfer of training. VR provides a platform for “learning by doing” instead of learning by seeing, listening, or observing. A series of user-based evaluation studies are conducted to ensure that the virtual manufacturing assembly simulation provides an effective and efficient means for evaluating assembly operations and for training assembly personnel. Different feedback cues of VR are implemented to evaluate the system. Moreover, several case studies are used to assess the effectiveness of VR-based training. The results of the study reveal that participants trained by VR committed fewer errors and took lesser time in actual product assembly when compared against the participant from traditional or baseline training group. © 2019, Springer-Verlag London Ltd., part of Springer Nature.","Assembly training; Industry 4.0; Manufacturing assembly; Virtual Reality","Agile manufacturing systems; E-learning; Industrial research; Industry 4.0; Personnel training; Product design; Virtual reality; Assembly operations; Assembly trainings; Digital manufacturing; Manufacturing assembly; Manufacturing process; Transfer of trainings; User-based evaluations; Virtual manufacturing; Assembly",Article,"Final","",Scopus,2-s2.0-85066028866
"Zhao M., Dai S.","57211961053;7203008798;","Intent inference of human hand motion for haptic feedback systems",2019,"Proceedings - 2019 IEEE International Conference on Artificial Intelligence and Virtual Reality, AIVR 2019",,, 8942346,"218","223",,,"10.1109/AIVR46125.2019.00046","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078023267&doi=10.1109%2fAIVR46125.2019.00046&partnerID=40&md5=40ed22bb33662574bee4ab71325471c7","State Key Laboratory of Virtual Reality, Technology and System, Beihang University, Beijing, China","Zhao, M., State Key Laboratory of Virtual Reality, Technology and System, Beihang University, Beijing, China; Dai, S., State Key Laboratory of Virtual Reality, Technology and System, Beihang University, Beijing, China","The haptic feedback system (HFS) in the virtual cockpit system (VCS) can definitely enhance the sense of immersion. Most HFSs in prior works sacrificed the native advantages of VCSs to achieve haptic interaction. This paper addresses the problem by proposing a novel framework for the HFS, which can predict the most likely interacting target of the human hand in advance. We introduce a HFS with a non-contact visual tracking sensor and a probability inference method based on Bayesian statistics, the features extracted by this HFS could be low-cost, high generality and flexibility. Simulations show that human intent inference can be computed in real-Time and the results can meet the requirements of the HFM, which provides an important basis for haptic interactions in VCSs. © 2019 IEEE.","Haptic Feedback; Human Computer Interaction; Intent Inference; Kalman Filter; Virtual Cockpit System","Artificial intelligence; Feedback control; Human computer interaction; Kalman filters; Bayesian statistics; Cockpit systems; Haptic feedback systems; Haptic feedbacks; Haptic interactions; Human hand motions; Intent inference; Probability inference; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85078023267
"Moriyama T., Asazu H., Takahashi A., Kajimoto H.","57202339848;6506297693;57195231000;6602141526;","Simple is vest: High-density tactile vest that realizes tactile transfer of fingers",2019,"SIGGRAPH Asia 2019 Emerging Technologies, SA 2019",,,,"42","43",,3,"10.1145/3355049.3360532","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076672766&doi=10.1145%2f3355049.3360532&partnerID=40&md5=4fb9058399b8282d250c118fdd67b102","University of Electro-Communications, Japan","Moriyama, T., University of Electro-Communications, Japan; Asazu, H., University of Electro-Communications, Japan; Takahashi, A., University of Electro-Communications, Japan; Kajimoto, H., University of Electro-Communications, Japan","We developed a high-density tactile vest that presents the haptic sensation of the five fingertips to the back rather than to the fingertip as a new haptic presentation method for objects in a virtual reality (VR) environment. The device adopts 144 eccentric mass vibration motors actuated individually and five Peltier elements. The voice coils present the contact points on the finger to the back and abdomen. When holding an object with fingers in VR scene, the sense of touch is presented to the wide area of the abdomen and back, so an accurate sense of which part of the finger is contacted can be comprehended. Compared with a fingertip-mounted display, it is possible to address issues of weight and size that hinder the free movement of fingers, while high-density distributed information can be presented. Furthermore, abdomen and back are totally free space in typical VR scenarios. © 2019 Copyright held by the owner/author(s).","Haptic devices; Vibrators","Vibrators; Virtual reality; Contact points; Distributed information; Eccentric mass; Haptic devices; Haptic sensation; Peltier elements; Sense of touch; Vibration motor; Interactive computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-85076672766
"Pietroszek K.","18037978700;","IRIS: Inter-reality intera",2019,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,, 3364731,"","",,1,"10.1145/3359996.3364731","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076146923&doi=10.1145%2f3359996.3364731&partnerID=40&md5=80b95c0fc86c12ee4478f0edc589963f","IDEAS Lab, American University, Washington, DC, United States","Pietroszek, K., IDEAS Lab, American University, Washington, DC, United States","While many metaphors were developed for interactions from a specific point at the reality-virtuality continuum, much less attention has been paid to designing metaphors that allow the users to cross the boundaries between the virtual, the augmented, and the real. We propose a use of an Inter-Reality Interactive Surface (IRIS) that enables users to collaborate across the reality-virtuality continuum within the same application. While we examine IRIS in the context of an immersive educational platform, UniVResity, the metaphor can be generalized to many other application domains. © 2019 Copyright held by the owner/author(s).","Augmented reality; Collaboration; Immersive learning; Interaction metaphor; Reality-virtuality continuum; Virtual reality","Augmented reality; Collaboration; Educational platforms; Immersive; Immersive learning; Interaction metaphors; Interactive surfaces; Virtuality continuum; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85076146923
"Pagé C., Bernier P.-M., Trempe M.","57209732350;9736834900;24176388500;","Using video simulations and virtual reality to improve decision-making skills in basketball",2019,"Journal of Sports Sciences","37","21",,"2403","2410",,8,"10.1080/02640414.2019.1638193","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068539753&doi=10.1080%2f02640414.2019.1638193&partnerID=40&md5=5a64e3c17e48958a6dbc864eb3fccefa","Département de kinanthropologie, Faculté des sciences de l’activité physique, Université de Sherbrooke, Sherbrooke, QC, Canada; Department of Sports Studies, Bishop’s University, Sherbrooke, QC, Canada","Pagé, C., Département de kinanthropologie, Faculté des sciences de l’activité physique, Université de Sherbrooke, Sherbrooke, QC, Canada; Bernier, P.-M., Département de kinanthropologie, Faculté des sciences de l’activité physique, Université de Sherbrooke, Sherbrooke, QC, Canada; Trempe, M., Département de kinanthropologie, Faculté des sciences de l’activité physique, Université de Sherbrooke, Sherbrooke, QC, Canada, Department of Sports Studies, Bishop’s University, Sherbrooke, QC, Canada","A large body of literature supports the effectiveness of using video simulations to improve decision-making skills in invasion sports. However, whether these improvements are transferable (from the laboratory to the court/field) and generalizable (from trained to untrained plays) remains unknown. In addition, it remains to be determined whether presenting the video simulations using virtual reality provides an added-value. To investigate these questions, varsity-level basketball players underwent four training sessions during which they observed video clips of basketball plays presented either on a computer screen (CS group) or using a virtual reality headset (VR group). A third group watched footage from NCAA playoff games on a computer screen (CTRL group). Decision-making was assessed on-court before and after the training sessions using two types of plays: “trained” plays (presented during the CS and VR training sessions) and “untrained” plays (presented only during the on-court tests). When facing the trained plays in the posttest, both VR and CS groups significantly outperformed the CTRL group. In contrast, when facing the untrained plays, the VR group outperformed both the CS and CTRL groups. Our results indicate that CS training leads to transferable but non-generalized decision-making gains while VR training leads to transferable and generalized gains. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","Decision-making; learning generalization; learning transfer; video simulation training; virtual reality","article; basketball player; court; decision making; human; simulation training; skill; transfer of learning; videorecording; virtual reality; adolescent; adult; basketball; female; male; motor performance; psychology; young adult; Adolescent; Adult; Basketball; Decision Making; Female; Generalization, Psychological; Humans; Male; Motor Skills; Transfer, Psychology; Video Recording; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85068539753
"Zou Y., Wang P., Tang Q., Sun Y.","57217006652;57217006341;57217400762;57217004882;","Implement Multi-Character Display in Virtual Reality Environment Based on Unet and Tracker",2019,"Proceedings - 2019 2nd International Conference on Safety Produce Informatization, IICSPI 2019",,, 9096025,"530","532",,,"10.1109/IICSPI48186.2019.9096025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085683784&doi=10.1109%2fIICSPI48186.2019.9096025&partnerID=40&md5=c77d19ebaa5c757cccf48ac7163524b2","Zunyi Power Supply Bureau, Safety Supervision Department, Zunyi, Guizhou, China","Zou, Y., Zunyi Power Supply Bureau, Safety Supervision Department, Zunyi, Guizhou, China; Wang, P., Zunyi Power Supply Bureau, Safety Supervision Department, Zunyi, Guizhou, China; Tang, Q., Zunyi Power Supply Bureau, Safety Supervision Department, Zunyi, Guizhou, China; Sun, Y., Zunyi Power Supply Bureau, Safety Supervision Department, Zunyi, Guizhou, China","Power grid operation is a very safe operation site, it is very important to be able to carry out related operations in accordance with the safe operation process, the existing traditional safe operation process, mainly in the traditional teaching mode or simulated real scene operation mode. In the links of management and training, operators lack intuitive experience and interaction, and they are not enough to show the serious consequences of illegal operation; As the head-mounted display becomes the most important interactive virtual reality display device, the 3d interactive display and the expressive force of the game engine are gradually improved, significantly improving participants' sense of immersion. Virtual reality technology can be used to build a simulation teaching platform for authentic visual experience, authentic representation of work flow and convincing interactive feedback. Virtual reality technology is used to establish a practical environment for grid operation in the virtual three-dimensional space of the computer that integrates class a illegal operation events. Users participating in the learning practice can operate in the virtual space according to the process. In this paper, based on unity built-in HAPI unet and third-party plug-in VRTK, the complex interaction of large-scale training business process is realized. Through VRTK, steam VR interface, the handle button state is obtained and information is transmitted on multiple instances, so as to determine the transfer and pickup state of interactive objects. © 2019 IEEE.","Inverse dynamics; Multiplayer networking technology; Multiplayer online interaction; Virtual reality technology","Crime; Electric power transmission networks; Helmet mounted displays; Interface states; Personnel training; Simulation platform; Head mounted displays; Interactive feedback; Interactive virtual reality; Power grid operations; Simulation teachings; Three dimensional space; Virtual reality technology; Virtual-reality environment; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85085683784
"Piccione J., Collett J., De Foe A.","57211538030;57206464821;55555885000;","Virtual skills training: the role of presence and agency",2019,"Heliyon","5","11", e02583,"","",,6,"10.1016/j.heliyon.2019.e02583","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074370179&doi=10.1016%2fj.heliyon.2019.e02583&partnerID=40&md5=41c139affc0f49a955d0d2674602e6aa","RMIT University, School of Health and Biomedical Sciences, Discipline of Psychology, Australia","Piccione, J., RMIT University, School of Health and Biomedical Sciences, Discipline of Psychology, Australia; Collett, J., RMIT University, School of Health and Biomedical Sciences, Discipline of Psychology, Australia; De Foe, A., RMIT University, School of Health and Biomedical Sciences, Discipline of Psychology, Australia","Virtual reality (VR) simulations provide increased feelings of presence and agency that could allow increased skill improvement during VR training. Direct relationships between active agency in VR and skill improvement have previously not been investigated. This study examined the relationship between (a) presence and agency, and (b) presence and skills improvement, via active and passive VR simulations and through measuring real-world golf-putting skill. Participants (n = 23) completed baseline putting skill assessment before using an Oculus Rift VR head-mounted display to complete active (putting with a virtual golf club) and passive (watching a game of golf) VR simulations. Measures of presence and agency were administered after each simulation, followed by a final putting skill assessment. The active simulation induced higher feelings of general presence and agency. However, no relationship was identified between presence and either agency or skill improvement. No skill improvement was evident in either the active or passive simulations, potentially due to the short training period applied, as well as a lack of realism in the VR simulations inhibiting a transfer of skills to a real environment. These findings reinforce previous literature that shows active VR to increase feelings of presence and agency. This study generates a number of fruitful research questions about the relationship between presence and skills training. © 2019 The AuthorsPsychology; Virtual reality; Presence; Human factors; Sport psychology © 2019 The Authors","Human factors; Presence; Psychology; Sport psychology; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85074370179
"Chew J.Y., Okayama K., Okuma T., Kawamoto M., Onda H., Kato N.","57189996822;57204778207;7004950282;56257346500;7006391806;57211832917;","Development of A Virtual Environment to Realize Human-Machine Interaction of Forklift Operation",2019,"2019 7th International Conference on Robot Intelligence Technology and Applications, RiTA 2019",,, 8932837,"112","118",,,"10.1109/RITAPP.2019.8932837","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078030425&doi=10.1109%2fRITAPP.2019.8932837&partnerID=40&md5=5c2a1a0ec9614f4b07ba4b3c1567ae88","National Institute of Advanced Industrial Science and Technology, Japan","Chew, J.Y., National Institute of Advanced Industrial Science and Technology, Japan; Okayama, K., National Institute of Advanced Industrial Science and Technology, Japan; Okuma, T., National Institute of Advanced Industrial Science and Technology, Japan; Kawamoto, M., National Institute of Advanced Industrial Science and Technology, Japan; Onda, H., National Institute of Advanced Industrial Science and Technology, Japan; Kato, N., National Institute of Advanced Industrial Science and Technology, Japan","This study presents an experimental concept to develop realistic Human-Machine Interaction (HMI) for a Virtual Environment (VE) and a novel evaluation methodology of such system. Such evaluation is motivated by the need to facilitate transfer of model/knowledge from VE to the Real Environment (RE), where it is crucial for the VE to trigger similar user behavior as in the RE. This paper discusses the application of such concept to evaluate interactions of forklift operation in the VE. First, a Virtual Reality (VR) forklift simulator is developed using motion capture and 3D reconstruction methods to mimic HMI of the real forklift operation. Then, the Dynamic Time Warping (DTW) algorithm is used for temporal evaluation of operation behaviors in VE and RE. Results of DTW (i.e. distance and correlation) are used as objective measures to evaluate fidelity of VE during forklift operations on the simulator. Results suggest the proposed forklift simulator triggers operation behavior which is similar (highly correlated) to that of real forklift operation. The contributions of this paper are (a) the novel VR forklift simulator system to realize interactions of real forklift in the VE, and (b) the proposed objective measures for temporal evaluation of the fidelity of VE. © 2019 IEEE.",,"Behavioral research; Intelligent robots; Man machine systems; Materials handling equipment; Simulators; Dynamic time warping algorithms; Evaluation methodologies; Highly-correlated; Human-machine interaction; Objective measure; Real environments; Simulator systems; Temporal evaluation; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85078030425
"Narciso D., Bessa M., Melo M., Vasconcelos-Raposo J.","57188767021;14031038800;7102354924;36070012200;","Virtual reality for training-the impact of smell on presence, cybersickness, fatigue, stress and knowledge transfer",2019,"ICGI 2019 - Proceedings of the International Conference on Graphics and Interaction",,, 8955071,"115","121",,1,"10.1109/ICGI47575.2019.8955071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078949972&doi=10.1109%2fICGI47575.2019.8955071&partnerID=40&md5=eea844c1f887a3d220806d274c29acf7","UTAD, Engineering Department, Vila Real, Portugal; INESC TEC, Porto, Portugal; UTAD, Departament of Education and Psychology, Vila Real, Portugal","Narciso, D., UTAD, Engineering Department, Vila Real, Portugal; Bessa, M., UTAD, Engineering Department, Vila Real, Portugal; Melo, M., INESC TEC, Porto, Portugal; Vasconcelos-Raposo, J., UTAD, Departament of Education and Psychology, Vila Real, Portugal","The area of professional training using virtual reality technologies has received considerable investment due to the advantages that virtual reality provides over traditional training. In this paper, we present an experiment whose goal was to analyse the impact that an additional stimulus has on the effectiveness of a virtual environment designed to train firefighters. The additional stimulus is a smell, more specifically the smell of burnt wood, which is consistent with the audiovisual content presented, and the effectiveness of the VE is measured through participant's feeling of presence, cybersickness, fatigue, stress and transfer of knowledge. The results indicate that, although the VE was successful in transferring knowledge, the addition of smell did not influence any of the measured variables. In the discussion section, we present the various factors that we believe have influenced this result. As future work, more experiments will be performed, with other stimuli, to understand better which stimuli increase participant's feeling of presence in the VE. © 2019 IEEE.","Multisensory Stimulation; Olfactory Sense; Virtual Reality","Knowledge management; Virtual reality; Audio-visual content; Feeling of presences; Knowledge transfer; Multisensory stimulations; Olfactory sense; Professional training; Transfer of knowledge; Virtual reality technology; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85078949972
"Forlim C.G., Bittner L., Mostajeran F., Steinicke F., Gallinat J., Kühn S.","56073571000;57211621650;57197835374;8883314100;7003503772;57203215366;","Stereoscopic Rendering via Goggles Elicits Higher Functional Connectivity During Virtual Reality Gaming",2019,"Frontiers in Human Neuroscience","13",, 365,"","",,5,"10.3389/fnhum.2019.00365","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074670363&doi=10.3389%2ffnhum.2019.00365&partnerID=40&md5=cf01b2c5f93edb1b14b4dbe531d24c96","Department of Psychiatry and Psychotherapy, University Medical Center Hamburg-Eppendorf (UKE), Hamburg, Germany; Department of Human-Computer-Interaction, University of Hamburg, Hamburg, Germany; Max Planck Institute for Human Development, Lise-Meitner Group for Environmental Neuroscience, Berlin, Germany","Forlim, C.G., Department of Psychiatry and Psychotherapy, University Medical Center Hamburg-Eppendorf (UKE), Hamburg, Germany; Bittner, L., Department of Psychiatry and Psychotherapy, University Medical Center Hamburg-Eppendorf (UKE), Hamburg, Germany; Mostajeran, F., Department of Human-Computer-Interaction, University of Hamburg, Hamburg, Germany; Steinicke, F., Department of Human-Computer-Interaction, University of Hamburg, Hamburg, Germany; Gallinat, J., Department of Psychiatry and Psychotherapy, University Medical Center Hamburg-Eppendorf (UKE), Hamburg, Germany; Kühn, S., Department of Psychiatry and Psychotherapy, University Medical Center Hamburg-Eppendorf (UKE), Hamburg, Germany, Max Planck Institute for Human Development, Lise-Meitner Group for Environmental Neuroscience, Berlin, Germany","Virtual reality (VR) simulates real-world scenarios by creating a sense of presence in its users. Such immersive scenarios lead to behavior that is more similar to that displayed in real world settings, which may facilitate the transfer of knowledge and skills acquired in VR to similar real world situations. VR has already been used in education, psychotherapy, rehabilitation and it comes as an appealing choice for training intervention purposes. The aim of the present study was to investigate to what extent VR technology for games presented via goggles can be used in a magnetic resonance imaging scanner (MRI), addressing the question of whether brain connectivity differs between VR stimulation via goggles and a presentation from a screen via mirror projection. Moreover, we wanted to investigate whether stereoscopic goggle stimulation, where both eyes receive different visual input, would elicit stronger brain connectivity than a stimulation in which both eyes receive the same visual input (monoscopic). To our knowledge, there is no previous research using games and functional connectivity (FC) in MRI to address this question. Multiple analyses approaches were taken so that different aspects of brain connectivity could be covered: fractional low-frequency fluctuation, independent component analysis (ICA), seed-based FC (SeedFC) and graph analysis. In goggle presentation (mono and stereoscopic) as contrasted to screen, we found differences in brain activation in left cerebellum and postcentral gyrus as well as differences in connectivity in the visual cortex and frontal inferior cortex [when focusing on the visual and default mode network (DMN)]. When considering connectivity in specific areas of interest, we found higher connectivity between bilateral superior frontal cortex and the temporal lobe, as well as bilateral inferior parietal cortex with right calcarine and right lingual cortex. Furthermore, we found superior frontal cortex and insula/putamen to be more strongly connected in goggle stereoscopic vs. goggle monoscopic, in line with our hypothesis. We assume that the condition that elicits higher brain connectivity values should be most suited for long-term brain training interventions given that, extended training under these conditions could permanently improve brain connectivity on a functional as well as on a structural level. © Copyright © 2019 Forlim, Bittner, Mostajeran, Steinicke, Gallinat and Kühn.","fMRI; fractional amplitude of low-frequency fluctuations; graph analysis; ICA; resting-state networks; seed-based functional connectivity; stereoscopic and monoscopic goggles; virtual reality","article; cerebellum; controlled study; default mode network; eye; frontal cortex; functional connectivity; functional magnetic resonance imaging; human; human experiment; independent component analysis; inferior parietal cortex; insula; plant seed; postcentral gyrus; putamen; temporal lobe; virtual reality; visual cortex",Article,"Final","",Scopus,2-s2.0-85074670363
"Tropea J., Johnson C.E., Nestel D., Paul S.K., Brand C.A., Hutchinson A.F., Bicknell R., Lim W.K.","24503349100;55677088128;7004284801;55936459500;7102268328;7101660152;57211469729;9246702800;","A screen-based simulation training program to improve palliative care of people with advanced dementia living in residential aged care facilities and reduce hospital transfers: Study protocol for the IMproving Palliative care Education and Training Using Simulation in Dementia (IMPETUS-D) cluster randomised controlled trial",2019,"BMC Palliative Care","18","1", 86,"","",,1,"10.1186/s12904-019-0474-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074062490&doi=10.1186%2fs12904-019-0474-x&partnerID=40&md5=e84e2a4b2338c3136e4ab0ad70de5c3e","Melbourne EpiCentre, Royal Melbourne Hospital, University of Melbourne and Melbourne Health, 7 East Main building, 300 Grattan Street, Parkville, VIC  3050, Australia; Monash Doctors Education, Monash Health Faculty of Medicine, Nursing and Health Sciences, Monash University, Monash Medical Centre, 246 Clayton Rd, Clayton, VIC  3168, Australia; Monash Institute for Health and Clinical Education, Monash University, 27 Rainforest Walk Wellington Road, Clayton, VIC  3800, Australia; School of Nursing and Midwifery, Deakin University, Locked Bag 20000, Geelong, VIC  3220, Australia; Department of Medicine and Aged Care, Melbourne Health and Department of Medicine, Royal Melbourne Hospital, University of Melbourne, 300 Grattan Street, Parkville, VIC  3050, Australia","Tropea, J., Melbourne EpiCentre, Royal Melbourne Hospital, University of Melbourne and Melbourne Health, 7 East Main building, 300 Grattan Street, Parkville, VIC  3050, Australia; Johnson, C.E., Monash Doctors Education, Monash Health Faculty of Medicine, Nursing and Health Sciences, Monash University, Monash Medical Centre, 246 Clayton Rd, Clayton, VIC  3168, Australia; Nestel, D., Monash Institute for Health and Clinical Education, Monash University, 27 Rainforest Walk Wellington Road, Clayton, VIC  3800, Australia; Paul, S.K., Melbourne EpiCentre, Royal Melbourne Hospital, University of Melbourne and Melbourne Health, 7 East Main building, 300 Grattan Street, Parkville, VIC  3050, Australia; Brand, C.A., Melbourne EpiCentre, Royal Melbourne Hospital, University of Melbourne and Melbourne Health, 7 East Main building, 300 Grattan Street, Parkville, VIC  3050, Australia; Hutchinson, A.F., School of Nursing and Midwifery, Deakin University, Locked Bag 20000, Geelong, VIC  3220, Australia; Bicknell, R., Department of Medicine and Aged Care, Melbourne Health and Department of Medicine, Royal Melbourne Hospital, University of Melbourne, 300 Grattan Street, Parkville, VIC  3050, Australia; Lim, W.K., Department of Medicine and Aged Care, Melbourne Health and Department of Medicine, Royal Melbourne Hospital, University of Melbourne, 300 Grattan Street, Parkville, VIC  3050, Australia","Background: Many people with advanced dementia live in residential aged care homes. Care home staff need the knowledge and skills to provide high-quality end-of-life (EOL) dementia care. However, several studies have found EOL dementia care to be suboptimal, and care staff have reported they would benefit from training in palliative care and dementia. Simulation offers an immersive learning environment and has been shown to improve learners' knowledge and skills. However, there is little research on simulation training for residential care staff. This article presents the development and evaluation protocol of IMproving Palliative care Education and Training Using Simulation in Dementia (IMPETUS-D) - a screen-based simulation training program on palliative dementia care, targeted at residential care staff. IMPETUS-D aims to improve the quality of palliative care provided to people living with dementia in residential care homes, including avoiding unnecessary transfers to hospital. Methods: A cluster RCT will assess the effect of IMPETUS-D. Twenty-four care homes (clusters) in three Australian cities will be randomised to receive either the IMPETUS-D intervention or usual training opportunities (control). The primary outcome is to reduce transfers to hospital and deaths in hospital by 20% over 6-months in the intervention compared to the control group. Secondary outcomes include uptake of goals of care plans over 6 and 12 months, change in staff knowledge and attitudes towards palliative dementia care over 6 months, change in transfers to hospital and deaths in hospital over 12 months. For the primary analysis logistic regression models will be used with standard errors weighted by the cluster effects. A mixed methods process evaluation will be conducted alongside the cluster RCT to assess the mechanisms of impact, the implementation processes and contextual factors that may influence the delivery and effects of the intervention. Discussion: In Australia, the need for high-quality advanced dementia care delivered in residential aged care is growing. This study will assess the effect of IMPETUS-D a new simulation-based training program on dementia palliative and EOL care. This large multisite trial will provide robust evidence about the impact of the intervention. If successful, it will be distributed to the broader residential care sector. Trial registration: ANZCTR, ACTRN12618002012257. Registered 14 December 2018. © 2019 The Author(s).","Care worker education; Cluster RCT; Dementia; End-of-life care; Long-term care homes; nursing homes; Nursing education; Palliative care; Process evaluation; Quality of care; Simulation training","Article; Australia; clinical practice; clinical protocol; cluster analysis; controlled study; dementia; geriatric care; health care quality; health personnel attitude; health program; human; learning environment; mortality rate; nursing home; nursing home patient; nursing home personnel; outcome assessment; palliative therapy; patient satisfaction; patient transport; professional knowledge; program evaluation; randomized controlled trial; simulation training; terminal care; dementia; organization and management; palliative therapy; patient transport; procedures; residential home; simulation training; Clinical Protocols; Dementia; Humans; Palliative Care; Patient Transfer; Quality of Health Care; Residential Facilities; Simulation Training",Article,"Final","",Scopus,2-s2.0-85074062490
"Fuchs K., Grundmann T., Fleisch E.","57191988486;57211689639;6602498499;","Towards identification of packaged products via computer vision: Convolutional neural networks for object detection and image classification in retail environments",2019,"ACM International Conference Proceeding Series",,, a26,"","",,1,"10.1145/3365871.3365899","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076132529&doi=10.1145%2f3365871.3365899&partnerID=40&md5=6edcb6696917a493da691ad9f4121a6a","D-MTEC, Auto-ID Labs ETH, HSG, ETH Zurich, Zurich, ZH, Switzerland","Fuchs, K., D-MTEC, Auto-ID Labs ETH, HSG, ETH Zurich, Zurich, ZH, Switzerland; Grundmann, T., D-MTEC, Auto-ID Labs ETH, HSG, ETH Zurich, Zurich, ZH, Switzerland; Fleisch, E., D-MTEC, Auto-ID Labs ETH, HSG, ETH Zurich, Zurich, ZH, Switzerland","Identification of packaged products in retail environments still relies on barcodes, requiring active user input and limited to one product at a time. Computer vision (CV) has already enabled many applications, but has so far been under-discussed in the retail domain, albeit allowing for faster, hands-free, more natural human-object interaction (e.g. via mixed reality headsets). To assess the potential of current convolutional neural network (CNN) architectures to reliably identify packaged products within a retail environment, we created and open-source a dataset of 300 images of vending machines with 15k labeled instances of 90 products. We assessed observed accuracies from transfer learning for image-based product classification (IC) and multi-product object detection (OD) on multiple CNN architectures, and the number of images instances required per product to achieve meaningful predictions. Results show that as little as six images are enough for 90% IC accuracy, but around 30 images are needed for 95% IC accuracy. For simultaneous OD, 42 instances per product are necessary and far more than 100 instances to produce robust results. Thus, this study demonstrates that even in realistic, fast-paced retail environments, image-based product identification provides an alternative to barcodes, especially for use-cases that do not require perfect 100% accuracy. © 2019 Copyright is held by the owner/author(s).","CNN; Computer vision; Product identification","Bar codes; Convolution; Human computer interaction; Image classification; Integrated circuits; Internet of things; Mixed reality; Network architecture; Neural networks; Object detection; Object recognition; Sales; Convolutional neural network; Human-object interaction; Multi-products; Open sources; Packaged products; Product classification; Product identification; Transfer learning; Computer vision",Conference Paper,"Final","",Scopus,2-s2.0-85076132529
"Xing J., Nagano K., Chen W., Xu H., Wei L.-Y., Zhao Y., Lu J., Kim B., Li H.","57221027161;55825559100;55570458100;57215128847;57220842683;57216268411;36022690300;57215125834;55082661800;","HairBrush for immersive data-driven hair modeling",2019,"UIST 2019 - Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology",,,,"263","279",,2,"10.1145/3332165.3347876","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074836439&doi=10.1145%2f3332165.3347876&partnerID=40&md5=01e3e032a54c97c840c07e37da5bfd78","USC Institute for Creative Technologies; Pinscreen; Wayne State University, United States; Adobe Research","Xing, J., USC Institute for Creative Technologies; Nagano, K., Pinscreen; Chen, W., USC Institute for Creative Technologies; Xu, H., Wayne State University, United States; Wei, L.-Y., Adobe Research; Zhao, Y., USC Institute for Creative Technologies; Lu, J., Adobe Research; Kim, B., Adobe Research; Li, H., USC Institute for Creative Technologies, Pinscreen","While hair is an essential component of virtual humans, it is also one of the most challenging digital assets to create. Existing automatic techniques lack the generality and flexibility to create rich hair variations, while manual authoring interfaces often require considerable artistic skills and efforts, especially for intricate 3D hair structures that can be difficult to navigate. We propose an interactive hair modeling system that can help create complex hairstyles in minutes or hours that would otherwise take much longer with existing tools. Modelers, including novice users, can focus on the overall hairstyles and local hair deformations, as our system intelligently suggests the desired hair parts. Our method combines the flexibility of manual authoring and the convenience of data-driven automation. Since hair contains intricate 3D structures such as buns, knots, and strands, they are inherently challenging to create using traditional 2D interfaces. Our system provides a new 3D hair authoring interface for immersive interaction in virtual reality (VR). Users can draw high-level guide strips, from which our system predicts the most plausible hairstyles via a deep neural network trained from a professionally curated dataset. Each hairstyle in our dataset is composed of multiple variations, serving as blend-shapes to fit the user drawings via global blending and local deformation. The fitted hair models are visualized as interactive suggestions that the user can select, modify, or ignore. We conducted a user study to confirm that our system can significantly reduce manual labor while improve the output quality for modeling a variety of head and facial hairstyles that are challenging to create via existing techniques. © 2019 ACM.","Data-driven; Hair; Machine learning; Modeling; User interface; Virtual reality","Blending; Deep neural networks; Deformation; Learning systems; Models; Virtual reality; Automatic technique; Data driven; Digital assets; Hair; Hair structure; Local deformations; Output quality; Virtual humans; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-85074836439
"Meyer O.A., Omdahl M.K., Makransky G.","57209494578;57209393925;50361371800;","Investigating the effect of pre-training when learning through immersive virtual reality and video: A media and methods experiment",2019,"Computers and Education","140",, 103603,"","",,37,"10.1016/j.compedu.2019.103603","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067602710&doi=10.1016%2fj.compedu.2019.103603&partnerID=40&md5=d590ca910c0cb30b088c51f9fb6fb682","Department of Psychology, University of Copenhagen, Denmark; Department of Psychology, University of Southern Denmark, Denmark","Meyer, O.A., Department of Psychology, University of Copenhagen, Denmark; Omdahl, M.K., Department of Psychology, University of Southern Denmark, Denmark; Makransky, G., Department of Psychology, University of Copenhagen, Denmark","Immersive virtual reality (VR) is predicted to have a significant impact on education; but most studies investigating learning with immersive VR have reported mixed results when compared to low-immersion media. In this study, a sample of 118 participants was used to test whether a lesson presented in either immersive VR or as a video could benefit from the pre-training principle, as a means of reducing cognitive load. Participants were randomly assigned to one of two method conditions (with/without pre-training), and one of two media conditions (immersive VR/video). The results showed an interaction between media and method, indicating that pre-training had a positive effect on knowledge (d = 0.81), transfer (d = 0.62), and self-efficacy (d = 0.64) directly following the intervention; and on self-efficacy (d = 0.84) in a one-week delayed post-test in the immersive VR condition. No effect was found for any of these variables within the video condition. © 2019 The Author(s)","Cognitive theory of multimedia learning; Immersive virtual reality; Multimedia learning; Pre-training principle","Virtual reality; Cognitive loads; Cognitive theory of multimedia learning; Immersive virtual reality; Immersive VR; Multi-media learning; Post test; Pre-training; Self efficacy; E-learning",Article,"Final","",Scopus,2-s2.0-85067602710
"Fernandes F., Werner C.","57202446568;7201754422;","Towards immersive learning in object-oriented paradigm: A preliminary study",2019,"Proceedings - 2019 21st Symposium on Virtual and Augmented Reality, SVR 2019",,, 8921030,"59","68",,,"10.1109/SVR.2019.00026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077235257&doi=10.1109%2fSVR.2019.00026&partnerID=40&md5=18c5e0ff98980061903b8ebf8218153d","Computer Science Department, IF Sudeste MG, Federal Institute Southeast of Minas Gerais, Manhuaçu, MG, Brazil; System Engineering and Computer Science Department, COPPE/UFRJ, Federal University of Rio de Janeiro, Rio de Janeiro, RJ, Brazil","Fernandes, F., Computer Science Department, IF Sudeste MG, Federal Institute Southeast of Minas Gerais, Manhuaçu, MG, Brazil; Werner, C., System Engineering and Computer Science Department, COPPE/UFRJ, Federal University of Rio de Janeiro, Rio de Janeiro, RJ, Brazil","Object-Oriented Paradigm Teaching is mandatory in the curriculum of the courses of the Computing area. Students are taught fundamental concepts about this paradigm, such as class, object, encapsulation, polymorphism, generalization and composition. One of the major challenges of Software Engineering is to teach complex and abstract concepts in a short time, with examples or simple projects done in academic environments. Virtual Reality has demonstrated advantages applied to Education, providing immersive experiences and new ways of visualization and interaction. However, this technology has not been extensively explored in Software Engineering. In this sense, this paper aims to present a disruptive method of teaching and learning support on fundamentals in object orientation paradigm based on Immersive Learning, called OO Game VR. In addition, an initial heuristic evaluation was performed with 6 subjects in order to identify usability problems. Despite problems found related to support learning, navigation and orientation, the natural expression of action and clear entry and exit points, the subjects were able to perform all the tasks, showing indications that the application has the potential to support teaching of OOP teaching through Immersive Learning. In future works, the usability problems will be fixed and specific methods will be applied for measuring influence immersion on learning outcomes. © 2019 IEEE.","Immersive learning; Object-oriented paradigm; Software engineering education; Virtual reality","Augmented reality; Engineering education; Learning systems; Software engineering; Teaching; Virtual reality; Academic environment; Fundamental concepts; Heuristic evaluation; Immersive learning; Object orientation; Object oriented paradigm; Teaching and learning; Usability problems; Object oriented programming",Conference Paper,"Final","",Scopus,2-s2.0-85077235257
"Wagner S., Joeres F., Gabele M., Hansen C., Preim B., Saalfeld P.","57209535826;57208648514;57208760476;55890379200;36744535200;56537022300;","Difficulty factors for VR cognitive rehabilitation training – Crossing a virtual road",2019,"Computers and Graphics (Pergamon)","83",,,"11","22",,2,"10.1016/j.cag.2019.06.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068072061&doi=10.1016%2fj.cag.2019.06.009&partnerID=40&md5=623e4c329cf5928dac5611ce3586ddc2","Department of Simulation and Graphics, University of Magdeburg, Germany","Wagner, S., Department of Simulation and Graphics, University of Magdeburg, Germany; Joeres, F., Department of Simulation and Graphics, University of Magdeburg, Germany; Gabele, M., Department of Simulation and Graphics, University of Magdeburg, Germany; Hansen, C., Department of Simulation and Graphics, University of Magdeburg, Germany; Preim, B., Department of Simulation and Graphics, University of Magdeburg, Germany; Saalfeld, P., Department of Simulation and Graphics, University of Magdeburg, Germany","Patients with cognitive or visual impairments have problems in dealing with complex situations. During the rehabilitation process, it is important to confront the patient with (everyday) tasks that have increasing degrees of difficulty to improve their performance. Immersive virtual reality training offers the potential to create a better transfer to daily life than non-immersive computer training. In cooperation with two neuropsychologists, an immersive virtual environment (VE) was developed in which cognitive training in the form of safe road crossing decisions can be performed. We present the experimental exploration and evaluation of difficulty factors within such a VR-based cognitive rehabilitation program. Four difficulty factors were identified and compared (number of relevant traffic lanes, speed of vehicles, distance between vehicles, and number of vehicles). The combination of these difficulty factors resulted in 36 training scenarios. The impact of the factors on participant performance and subjective perception of scenario difficulty were evaluated with 60 healthy participants to estimate the impact of the four factors to a situation's difficulty level. For the factors Relevant Lanes and Traffic Speed a clear influence on the perceived task difficulty could be determined. No clear influence could be found for the Gap Size. The Number of Vehicles had almost no effect on the perceived task difficulty. Finally, we asked two experienced neuropsychologists about the applicability of our developed system to patients, and they stated that the system is ready for a study on patients. © 2019 Elsevier Ltd","Cognitive rehabilitation; Disabilities; Virtual reality","E-learning; Roads and streets; Vehicles; Virtual reality; Cognitive rehabilitation; Cognitive training; Disabilities; Immersive virtual environments; Immersive virtual reality; Number of vehicles; Subjective perceptions; Visual impairment; Patient rehabilitation",Article,"Final","",Scopus,2-s2.0-85068072061
"Gupta A., Cecil J., Tapia O., Sweet-Darter M.","57200825298;7005940561;57207105216;56719728800;","Design of cyber-human frameworks for immersive learning",2019,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics","2019-October",, 8914205,"1563","1568",,,"10.1109/SMC.2019.8914205","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076785558&doi=10.1109%2fSMC.2019.8914205&partnerID=40&md5=24f60e31ee08e1c61b6ac33241f99727","Oklahoma State University, Center for Cyber-Physical Systems, Stillwater, United States; Anselm Center, Edmond, OK, United States","Gupta, A., Oklahoma State University, Center for Cyber-Physical Systems, Stillwater, United States; Cecil, J., Oklahoma State University, Center for Cyber-Physical Systems, Stillwater, United States; Tapia, O., Oklahoma State University, Center for Cyber-Physical Systems, Stillwater, United States; Sweet-Darter, M., Anselm Center, Edmond, OK, United States","This paper focuses on the creation of information centric Cyber-Human Learning Frameworks involving Virtual Reality based mediums. A generalized framework is proposed, which is adapted for two educational domains: One to support education and training of residents in orthopedic surgery and the other focusing on science learning for children with autism. Users, experts and technology based mediums play a key role in the design of such a Cyber-Human framework. Virtual Reality based immersive and haptic mediums were two of the technologies explored in the implementation of the framework for these learning domains. The proposed framework emphasizes the importance of Information-Centric Systems Engineering (ICSE) principles which emphasizes a user centric approach along with formalizing understanding of target subjects or processes for which the learning environments are being created. © 2019 IEEE.","Human-Computer Interaction; Virtual Learning; Virtual Reality","Computer aided instruction; Human computer interaction; Virtual reality; Children with autisms; Education and training; Immersive learning; Information-centric; Learning environments; Orthopedic surgery; Technology-based; Virtual learning; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85076785558
"Ip H.H.S., Li C., Leoni S., Chen Y., Ma K.-F., Wong C.H.-T., Li Q.","7005395690;56180363500;57192005943;57187275900;57192007385;57204512944;56190105400;","Design and Evaluate Immersive Learning Experience for Massive Open Online Courses (MOOCs)",2019,"IEEE Transactions on Learning Technologies","12","4", 8515107,"503","515",,3,"10.1109/TLT.2018.2878700","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055879387&doi=10.1109%2fTLT.2018.2878700&partnerID=40&md5=262dab079e4e3ad4edea8953a8886e91","Department of Computer Science, AIMtech Centre, City University of Hong Kong, Hong Kong; AIMtech Centre, City University of Hong Kong, Hong Kong; Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Chinese and History, City University of Hong Kong, Kowloon Tong, Hong Kong","Ip, H.H.S., Department of Computer Science, AIMtech Centre, City University of Hong Kong, Hong Kong; Li, C., Department of Computer Science, AIMtech Centre, City University of Hong Kong, Hong Kong; Leoni, S., AIMtech Centre, City University of Hong Kong, Hong Kong; Chen, Y., Department of Computer Science, City University of Hong Kong, Hong Kong; Ma, K.-F., Department of Chinese and History, City University of Hong Kong, Kowloon Tong, Hong Kong; Wong, C.H.-T., Department of Chinese and History, City University of Hong Kong, Kowloon Tong, Hong Kong; Li, Q., Department of Computer Science, City University of Hong Kong, Hong Kong","Massive open online courses (MOOCs), a unique form of online education enabled by web-based learning technologies, allow learners from anywhere in the world with any level of educational background to enjoy online education experience provided by many top universities all around the world. Traditionally, MOOC learning contents are always delivered as text-based or video-based materials. Although introducing immersive learning experience for MOOCs may sound exciting and potentially significative, there are a number of challenges given this unique setting. In this paper, we present the design and evaluation methodologies for delivering immersive learning experience to MOOC learners via multiple media. Specifically, we have applied the techniques in the production of a MOOC entitled Virtual Hong Kong: New World, Old Traditions, led by AIMtech Centre, City University of Hong Kong, which is the first MOOC (as our knowledge) that delivers immersive learning content for distant learners to appreciate and experience how the traditional culture and folklore of Hong Kong impact upon the lives of its inhabitants in the 21st Century. The methodologies applied here can be further generalized as the fundamental framework of delivering immersive learning for future MOOCs. © 2008-2011 IEEE.","e-learning.; immersive learning; Massive open online course; virtual reality","Computer aided instruction; Curricula; Design; Education; Learning systems; Virtual reality; Google; Immersive learning; Information and Communication Technologies; Massive open online course; Solid model; Urban areas; E-learning",Article,"Final","",Scopus,2-s2.0-85055879387
"Dieker L.A., Straub C., Hynes M., Hughes C.E., Bukathy C., Bousfield T., Mrstik S.","8352122200;55925439900;36728914300;7401857048;57216635239;57216636883;57200130874;","Using virtual rehearsal in a simulator to impact the performance of science teachers",2019,"International Journal of Gaming and Computer-Mediated Simulations","11","4",,"1","20",,1,"10.4018/IJGCMS.2019100101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084139085&doi=10.4018%2fIJGCMS.2019100101&partnerID=40&md5=81ff97ecff10f856a391269902d37c63","University of Central Florida, United States; Mursion Inc., United States; Hands on Educational Services, United States; Georgia Gwinnett College, United States","Dieker, L.A., University of Central Florida, United States; Straub, C., Mursion Inc., United States; Hynes, M., University of Central Florida, United States; Hughes, C.E., University of Central Florida, United States; Bukathy, C., Hands on Educational Services, United States; Bousfield, T., University of Central Florida, United States; Mrstik, S., Georgia Gwinnett College, United States","This study investigated the use of a virtual learning environment, TeachLivE, using pre-post group design to examine the effects of repeated virtual rehearsal sessions. Based upon past findings on the effectiveness of four 10-minutes sessions, the research team used refined methods to examine the effects of these sessions on 102 secondary science teachers. Teachers who took part in the simulated activities significantly increased their targeted behaviors compared to colleagues who had not taken part in the simulation activities. These results of behavior changes that occurred in the simulation were found to transfer back to the real classroom settings for the experimental group (simulation use). Results from this study further validates the impact of simulation in teacher education, showing professional learning in virtual-reality simulated classrooms can positively impact targeted teaching practices in a concentrated amount of time. Copyright © 2019, IGI Global.","Biology; Professional development; Science teacher education; Simulation; Simulation methods; Teacher education; Virtual rehearsal","Computer aided instruction; E-learning; Classroom settings; Experimental groups; Professional learning; Secondary science; Targeted behavior; Teacher education; Teaching practices; Virtual learning environments; Virtual reality",Article,"Final","",Scopus,2-s2.0-85084139085
"Boutros F., Damer N., Kirchbuchner F., Kuijper A.","57205379838;50861109400;57031859600;56131137100;","Eye-MMS: Miniature multi-scale segmentation network of key eye-regions in embedded applications",2019,"Proceedings - 2019 International Conference on Computer Vision Workshop, ICCVW 2019",,, 9022048,"3665","3670",,13,"10.1109/ICCVW.2019.00452","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082493607&doi=10.1109%2fICCVW.2019.00452&partnerID=40&md5=f767e071ce9f8f2e80f951c63200ac45","Fraunhofer Institute for Computer Graphics Research IGD, Germany; Technische Universität Darmstadt, Germany","Boutros, F., Fraunhofer Institute for Computer Graphics Research IGD, Germany, Technische Universität Darmstadt, Germany; Damer, N., Fraunhofer Institute for Computer Graphics Research IGD, Germany, Technische Universität Darmstadt, Germany; Kirchbuchner, F., Fraunhofer Institute for Computer Graphics Research IGD, Germany, Technische Universität Darmstadt, Germany; Kuijper, A., Fraunhofer Institute for Computer Graphics Research IGD, Germany, Technische Universität Darmstadt, Germany","Segmentation of the iris or sclera is an essential processing block in ocular biometric systems. However, human-computer interaction, as in VR/AR applications, requires multiple region segmentation to enable smoother interaction and eye-tracking. Such application does not only demand highly accurate and generalizable segmentation, it requires such segmentation model to be appropriate for the limited computational power of embedded systems. This puts strict limits on the size of the deployed deep learning models. This work presents a miniature multi-scale segmentation network consisting of inter-connected convolutional modules. We present a baseline multi-scale segmentation network and modify it to reduce its parameters by more than 80 times, while reducing its accuracy by less than 3%, resulting in our Eye-MMS model containing only 80k parameters. This work is developed on the OpenEDS database and is conducted in preparation for the OpenEDS Semantic Segmentation Challenge. © 2019 IEEE.","Biometrics; Embedded biometrics; Eye segmentation; Semantic segmentation","Biometrics; Computer vision; Deep learning; Embedded systems; Human computer interaction; Semantics; Biometric systems; Computational power; Embedded application; Embedded biometrics; Multiple regions; Multiscale segmentation; Segmentation models; Semantic segmentation; Eye tracking",Conference Paper,"Final","",Scopus,2-s2.0-85082493607
"Bruce R., Levett-Jones T., Courtney-Pratt H.","57210210919;15073003500;25521366600;","Transfer of Learning From University-Based Simulation Experiences to Nursing Students' Future Clinical Practice: An Exploratory Study",2019,"Clinical Simulation in Nursing","35",,,"17","24",,6,"10.1016/j.ecns.2019.06.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069900728&doi=10.1016%2fj.ecns.2019.06.003&partnerID=40&md5=29a7075efd54a269dee10cb0849bc228","Clinical Nurse Consultant, Rehabilitation and Aged Care, Medical and Interventional Services, Belmont Hospital, Gateshead, New South Wales  2290, Australia; Professor of Nursing Education, Discipline Lead, Faculty of Health, University of Technology Sydney, Ultimo, New South Wales  2007, Australia; Senior Lecturer, Graduate Research Coordinator, Wicking Dementia Research & Education Centre, University of Tasmania, Hobart, Tasmania  7001, Australia","Bruce, R., Clinical Nurse Consultant, Rehabilitation and Aged Care, Medical and Interventional Services, Belmont Hospital, Gateshead, New South Wales  2290, Australia; Levett-Jones, T., Professor of Nursing Education, Discipline Lead, Faculty of Health, University of Technology Sydney, Ultimo, New South Wales  2007, Australia; Courtney-Pratt, H., Senior Lecturer, Graduate Research Coordinator, Wicking Dementia Research & Education Centre, University of Tasmania, Hobart, Tasmania  7001, Australia","Background: Despite increasing use of simulation in nursing education, there is limited understanding of how simulation experiences influence students' future practice. The aim of this study was to explore recently graduated registered nurses' perceptions of how their learning from undergraduate university-based simulation experiences informed their current practice and the factors that facilitated or inhibited this transfer of learning. Methods: The study used an exploratory design framed by a qualitative descriptive methodology. Six nurses who had completed 3 to 12 months of clinical practice after graduation participated in semistructured interviews which were thematically analysed. Results: The importance of accepting responsibility, interprofessional communication, leadership skills, and promoting patient safety emerged as recurring themes. Conclusions: This study provided new insights into the transfer of learning from university-based simulation experiences to students' practice after graduation. Further research with other groups of learners and larger sample sizes will be valuable in taking this work forward. © 2019 International Nursing Association for Clinical Simulation and Learning","graduate nurse; nursing student; patient outcomes; simulation; transfer","adult; article; clinical practice; drug safety; exploratory research; human; interpersonal communication; leadership; nursing student; patient safety; perception; registered nurse; responsibility; sample size; semi structured interview; simulation; skill; transfer of learning",Article,"Final","",Scopus,2-s2.0-85069900728
"Herzberg S., Hansen M., Schoonover A., Skarica B., Mcnulty J., Harrod T., Snowden J.M., Lambert W., Guise J.-M.","57195277985;55432318100;57211510019;57115345800;57211583504;57211510684;55170527500;7102016031;7003556324;","Association between measured teamwork and medical errors: an observational study of prehospital care in the USA",2019,"BMJ Open","9","10", e025314,"","",,5,"10.1136/bmjopen-2018-025314","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074489314&doi=10.1136%2fbmjopen-2018-025314&partnerID=40&md5=9aefba68a625c623db103b0ae5f85f4a","Medical Scientist Training Program, Vanderbilt University Medical Center, Nashville, Tennessee, United States; Emergency Medicine, Oregon Health and Science University, Portland, Oregon, United States; Obstetrics and Gynecology, Oregon Health and Science University, Portland, Oregon, United States; Office of Simulation, Oregon Health and Science University, Portland, Oregon, United States; Department of Obstetrics and Gynecology/Public Health and Preventive Medicine, Oregon Health and Science University, Portland, Oregon, United States; Public Health and Preventative Medicine, Oregon Health and Science University, Portland, Oregon, United States","Herzberg, S., Medical Scientist Training Program, Vanderbilt University Medical Center, Nashville, Tennessee, United States; Hansen, M., Emergency Medicine, Oregon Health and Science University, Portland, Oregon, United States; Schoonover, A., Obstetrics and Gynecology, Oregon Health and Science University, Portland, Oregon, United States; Skarica, B., Obstetrics and Gynecology, Oregon Health and Science University, Portland, Oregon, United States; Mcnulty, J., Office of Simulation, Oregon Health and Science University, Portland, Oregon, United States; Harrod, T., Obstetrics and Gynecology, Oregon Health and Science University, Portland, Oregon, United States; Snowden, J.M., Department of Obstetrics and Gynecology/Public Health and Preventive Medicine, Oregon Health and Science University, Portland, Oregon, United States; Lambert, W., Public Health and Preventative Medicine, Oregon Health and Science University, Portland, Oregon, United States; Guise, J.-M., Obstetrics and Gynecology, Oregon Health and Science University, Portland, Oregon, United States","Objectives The goal of this study was to examine the relationship between measured teamwork and adverse safety events in the prehospital emergency care of children using high-fidelity simulation. We posit that non-technical skills such as leadership, teamwork, situation awareness and decision-making are associated with the clinical success of teams. Design Observational study. Setting Emergency medical services (EMS) responders were recruited from public fire and private transport agencies in Oregon State to participate in four simulations of paediatric emergencies using high-fidelity patient simulators, scene design, and professional actors playing parents and bystanders. Participants Forty-four fire/transport teams consisting of 259 EMS professionals consented to participate and completed simulations. Primary and secondary outcome measures Teams were assessed using the Clinical Teamwork Scale (CTS), a validated instrument that measures overall teamwork and 15 specific elements in five overarching domains: communication, decision-making, role responsibility (leadership and followership), situational awareness/resource management and patient-friendliness. We used generalised estimating equations to estimate the odds of error with increasing overall CTS teamwork score while adjusting for clinical scenario and potential clustering by team. Results Across 176 simulations, the mean overall score on the CTS was 6.04 (SD 2.10; range 1=poor to 10=perfect) and was normally distributed. The distribution of scores was similar across the four clinical scenarios. At least one error was observed in 82% of the simulations. In simulations with at least one observed error, the mean CTS score was 5.76 (SD 2.04) compared with 7.16 (SD 1.95) in scenarios with no observed error. Logistic regression analysis accounting for clustering at the team level revealed that the odds of an error decreased 28% with each unit increase in CTS (OR 0.72, 95% CI 0.59 to 0.88). Conclusions This study found that overall teamwork among care delivery teams was strongly associated with the risk of serious adverse events in simulated scenarios of caring for critically ill and injured children. © Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.","child; cooperative behavior; emergency medical services; humans; medical errors; patient care team; patient safety; patient simulation; teamwork","adult; Article; association; awareness; care behavior; critically ill patient; decision making; emergency care; emergency health service; female; human; interpersonal communication; leadership; major clinical study; male; medical error; observational study; patient safety; resource management; responsibility; teamwork; United States; child; clinical competence; emergency health service; medical error; Oregon; patient care; patient simulation; preschool child; statistical model; Awareness; Child; Child, Preschool; Clinical Competence; Communication; Decision Making; Emergency Medical Services; Female; Humans; Leadership; Logistic Models; Male; Medical Errors; Oregon; Patient Care Team; Patient Simulation",Article,"Final","",Scopus,2-s2.0-85074489314
"Škola F., Tinková S., Liarokapis F.","57189368470;57211272110;7801416785;","Progressive Training for Motor Imagery Brain-Computer Interfaces Using Gamification and Virtual Reality Embodiment",2019,"Frontiers in Human Neuroscience","13",, 329,"","",,9,"10.3389/fnhum.2019.00329","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073189702&doi=10.3389%2ffnhum.2019.00329&partnerID=40&md5=198ef3d60bdba1661c0d64955bfcdb1e","Faculty of Informatics, Masaryk University, Brno, Czech Republic","Škola, F., Faculty of Informatics, Masaryk University, Brno, Czech Republic; Tinková, S., Faculty of Informatics, Masaryk University, Brno, Czech Republic; Liarokapis, F., Faculty of Informatics, Masaryk University, Brno, Czech Republic","This paper presents a gamified motor imagery brain-computer interface (MI-BCI) training in immersive virtual reality. The aim of the proposed training method is to increase engagement, attention, and motivation in co-adaptive event-driven MI-BCI training. This was achieved using gamification, progressive increase of the training pace, and virtual reality design reinforcing body ownership transfer (embodiment) into the avatar. From the 20 healthy participants performing 6 runs of 2-class MI-BCI training (left/right hand), 19 were trained for a basic level of MI-BCI operation, with average peak accuracy in the session = 75.84%. This confirms the proposed training method succeeded in improvement of the MI-BCI skills; moreover, participants were leaving the session in high positive affect. Although the performance was not directly correlated to the degree of embodiment, subjective magnitude of the body ownership transfer illusion correlated with the ability to modulate the sensorimotor rhythm. © Copyright © 2019 Škola, Tinková and Liarokapis.","body ownership transfer; brain-computer interface; embodiment; gamification; motor imagery","accuracy; adaptation; adult; affect; Article; attention; body ownership transfer; brain computer interface; classification; clinical article; controlled study; electroencephalography; evidence based medicine; fatigue; female; gamified motor imagery brain computer interface; hand movement; human; illusion; machine learning; male; mathematical analysis; modulation transfer function; motivation; motor cortex; neuromodulation; online system; proprioceptive feedback; questionnaire; rating scale; robotics; self concept; sense of agency; sense of ownership; sensorimotor function; sensory evoked potential; sex difference; skill; tactile feedback; tactile stimulation; task performance; vibration; virtual reality; virtual reality embodiment; visual feedback",Article,"Final","",Scopus,2-s2.0-85073189702
"Kim A., Schweighofer N., Finley J.M.","57193429536;6701542947;24080097400;","Locomotor skill acquisition in virtual reality shows sustained transfer to the real world",2019,"Journal of NeuroEngineering and Rehabilitation","16","1", 113,"","",,12,"10.1186/s12984-019-0584-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072208527&doi=10.1186%2fs12984-019-0584-y&partnerID=40&md5=03fdeac9598efcc7ee28cf2ebcbf7be2","Division of Biokinesiology and Physical Therapy, University of Southern California, 1540 E. Alcazar St, CHP 155, Los Angeles, CA  90033, United States; Neuroscience Graduate Program, University of Southern California, Los Angeles, CA  90089, United States; Department of Biomedical Engineering, University of Southern California, Los Angeles, CA  90089, United States; Department of Computer Science, University of Southern California, Los Angeles, CA  90089, United States","Kim, A., Division of Biokinesiology and Physical Therapy, University of Southern California, 1540 E. Alcazar St, CHP 155, Los Angeles, CA  90033, United States; Schweighofer, N., Division of Biokinesiology and Physical Therapy, University of Southern California, 1540 E. Alcazar St, CHP 155, Los Angeles, CA  90033, United States, Neuroscience Graduate Program, University of Southern California, Los Angeles, CA  90089, United States, Department of Biomedical Engineering, University of Southern California, Los Angeles, CA  90089, United States, Department of Computer Science, University of Southern California, Los Angeles, CA  90089, United States; Finley, J.M., Division of Biokinesiology and Physical Therapy, University of Southern California, 1540 E. Alcazar St, CHP 155, Los Angeles, CA  90033, United States, Neuroscience Graduate Program, University of Southern California, Los Angeles, CA  90089, United States, Department of Biomedical Engineering, University of Southern California, Los Angeles, CA  90089, United States","Background: Virtual reality (VR) is a potentially promising tool for enhancing real-world locomotion in individuals with mobility impairment through its ability to provide personalized performance feedback and simulate real-world challenges. However, it is unknown whether novel locomotor skills learned in VR show sustained transfer to the real world. Here, as an initial step towards developing a VR-based clinical intervention, we study how young adults learn and transfer a treadmill-based virtual obstacle negotiation skill to the real world. Methods: On Day 1, participants crossed virtual obstacles while walking on a treadmill, with the instruction to minimize foot clearance during obstacle crossing. Gradual changes in performance during training were fit via non-linear mixed effect models. Immediate transfer was measured by foot clearance during physical obstacle crossing while walking over-ground. Retention of the obstacle negotiation skill in VR and retention of over-ground transfer were assessed after 24 h. Results: On Day 1, participants systematically reduced foot clearance throughout practice by an average of 5 cm (SD 4 cm) and transferred 3 cm (SD 1 cm) of this reduction to over-ground walking. The acquired reduction in foot clearance was also retained after 24 h in VR and over-ground. There was only a small, but significant 0.8 cm increase in foot clearance in VR and no significant increase in clearance over-ground on Day 2. Moreover, individual differences in final performance at the end of practice on Day 1 predicted retention both in VR and in the real environment. Conclusions: Overall, our results support the use of VR for locomotor training as skills learned in a virtual environment readily transfer to real-world locomotion. Future work is needed to determine if VR-based locomotor training leads to sustained transfer in clinical populations with mobility impairments, such as individuals with Parkinson's disease and stroke survivors. © 2019 The Author(s).","Motor learning; Obstacle negotiation; Retention; Transfer; Virtual reality","adult; Article; female; human; human experiment; locomotion; male; motor learning; normal human; Parkinson disease; population research; priority journal; skill retention; stroke survivor; task performance; transfer of learning; virtual reality; walking distance; walking speed; young adult; algorithm; biomechanics; foot; learning; motor performance; walking; walking difficulty; Adult; Algorithms; Biomechanical Phenomena; Female; Foot; Healthy Volunteers; Humans; Learning; Locomotion; Male; Mobility Limitation; Motor Skills; Transfer, Psychology; Virtual Reality; Walking; Young Adult",Article,"Final","",Scopus,2-s2.0-85072208527
"Nijman S.A., Veling W., Greaves-Lord K., Vermeer R.R., Vos M., Zandee C.E.R., Zandstra D.C., Geraets C.N.W., Pijnenborg G.H.M.","57205171580;19934411900;15925549000;57210891883;57210887069;57210897608;57210892122;57053538000;6507841579;","Dynamic Interactive Social Cognition Training in Virtual Reality (DiSCoVR) for social cognition and social functioning in people with a psychotic disorder: study protocol for a multicenter randomized controlled trial",2019,"BMC psychiatry","19","1", 272,"272","",,7,"10.1186/s12888-019-2250-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071753550&doi=10.1186%2fs12888-019-2250-0&partnerID=40&md5=41fa83c1682323ecbac6441ae1de7879","Department of Psychotic Disorders, GGZ Drenthe, LA, PO Box 30007, Assen, 9404, Netherlands; University Center of Psychiatry, University Medical Center Groningen, University of Groningen, RB, Hanzeplein 1 ,PO Box 30.001Groningen  9700, Netherlands; Department of Psychology, University of Groningen, Grote Kruisstraat 2/1Groningen  9712, Netherlands; Department of Child and Adolescent Psychiatry/Psychology, Erasmus MC-Sophia, CN, Wytemaweg 8, Rotterdam, 3015, Netherlands; Department of (Youth) Mental Health and Autism of Lentis Psychiatric Institute, JR, Laan Corpus den Hoorn 102-2Groningen  9728, Netherlands; Department of Yulius Autism, Dordrecht, Netherlands; Flexible Assertive Community Treatment Team, Outpatient Treatment Center, GGZ Delfland, Sint Jorisweg 2, Delft, 2612, Netherlands; Terneuzen, Netherlands","Nijman, S.A., Department of Psychotic Disorders, GGZ Drenthe, LA, PO Box 30007, Assen, 9404, Netherlands, University Center of Psychiatry, University Medical Center Groningen, University of Groningen, RB, Hanzeplein 1 ,PO Box 30.001Groningen  9700, Netherlands, Department of Psychology, University of Groningen, Grote Kruisstraat 2/1Groningen  9712, Netherlands; Veling, W., University Center of Psychiatry, University Medical Center Groningen, University of Groningen, RB, Hanzeplein 1 ,PO Box 30.001Groningen  9700, Netherlands; Greaves-Lord, K., Department of Child and Adolescent Psychiatry/Psychology, Erasmus MC-Sophia, CN, Wytemaweg 8, Rotterdam, 3015, Netherlands, Department of (Youth) Mental Health and Autism of Lentis Psychiatric Institute, JR, Laan Corpus den Hoorn 102-2Groningen  9728, Netherlands, Department of Yulius Autism, Dordrecht, Netherlands; Vermeer, R.R., Flexible Assertive Community Treatment Team, Outpatient Treatment Center, GGZ Delfland, Sint Jorisweg 2, Delft, 2612, Netherlands; Vos, M., University Center of Psychiatry, University Medical Center Groningen, University of Groningen, RB, Hanzeplein 1 ,PO Box 30.001Groningen  9700, Netherlands; Zandee, C.E.R., Flexible Assertive Community Treatment Team, Outpatient Treatment Center, GGZ Delfland, Sint Jorisweg 2, Delft, 2612, Netherlands; Zandstra, D.C., Terneuzen, Netherlands; Geraets, C.N.W., University Center of Psychiatry, University Medical Center Groningen, University of Groningen, RB, Hanzeplein 1 ,PO Box 30.001Groningen  9700, Netherlands; Pijnenborg, G.H.M., Department of Psychotic Disorders, GGZ Drenthe, LA, PO Box 30007, Assen, 9404, Netherlands, Department of Psychology, University of Groningen, Grote Kruisstraat 2/1Groningen  9712, Netherlands","BACKGROUND: Problems in social functioning (e.g., unemployment, social isolation), are common in people with a psychotic disorder. Social cognition is a treatment target to improve social functioning, as it is a proximal predictor of social functioning. Social Cognition Training (SCT) improves social cognition, but may not generalize (enduringly) to social functioning, perhaps due to insufficient opportunity to practice in daily-life social situations. Using virtual reality (VR) for SCT could address this problem, as VR is customizable, accessible, and interactive. We will test the effect of a VR SCT, 'DiSCoVR', on social cognition and social functioning in a randomized controlled trial (RCT). METHODS: In total 100 people with a psychotic disorder and deficits in social cognition will be recruited for this multicenter randomized controlled trial (RCT). Participants will be randomized to VR SCT (DiSCoVR) or VR relaxation training (VRelax; active control). DiSCoVR is a 16-session individual SCT, consisting of three modules: 1) emotion perception (recognizing facial emotions in a virtual shopping street); 2) social perception and theory of mind (observing social interactions between virtual characters and assessing their behavior, emotions and thoughts); and 3) application of higher-order social cognition in social interaction (role-playing personalized situations in VR). People receiving VRelax complete sixteen individual sessions, in which they receive psycho-education about stress, identify personal stressors, learn relaxation techniques, and explore relaxing immersive virtual environments. Assessments will be performed at baseline, post-treatment, and 3-month follow-up. Primary outcomes are emotion perception (Ekman 60 Faces), social perception and theory of mind (The Awareness of Social Inference Test). Secondary outcomes include social functioning (Personal and Social Performance Scale), experiences and social interactions in daily life (experience sampling of emotions, social participation and subjective experience of social situations), psychiatric symptoms (e.g., depression, perceived stress, anxiety, positive and negative symptoms) and self-esteem. DISCUSSION: To our knowledge, this will be the first RCT testing the efficacy of VR SCT. It will also investigate generalization to daily life social situations, the durability of treatment effects, and moderators and mediators of treatment success. TRIAL REGISTRATION: On December 5, 2017, this trial was registered prospectively in the Dutch Trial Register as NTR6863 .","Emotion perception; Psychotic disorder; Social cognition training; Social functioning; Theory of mind; Virtual reality","adolescent; adult; aged; clinical trial; cognition; cognitive behavioral therapy; female; human; human relation; male; middle aged; multicenter study; perception; procedures; psychology; psychosis; randomized controlled trial (topic); social behavior; social participation; theory of mind; treatment outcome; virtual reality exposure therapy; young adult; Adolescent; Adult; Aged; Cognition; Cognitive Behavioral Therapy; Female; Humans; Interpersonal Relations; Male; Middle Aged; Psychotic Disorders; Randomized Controlled Trials as Topic; Social Behavior; Social Participation; Social Perception; Theory of Mind; Treatment Outcome; Virtual Reality Exposure Therapy; Young Adult",Article,"Final","",Scopus,2-s2.0-85071753550
"Palmas F., Labode D., Plecher D.A., Klinker G.","57208681848;57211522317;55923283100;6603530980;","Comparison of a gamified and non-gamified virtual reality training assembly task",2019,"2019 11th International Conference on Virtual Worlds and Games for Serious Applications, VS-Games 2019 - Proceedings",,, 8864583,"1DUUMY","",,5,"10.1109/VS-Games.2019.8864583","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074257749&doi=10.1109%2fVS-Games.2019.8864583&partnerID=40&md5=c74c3636133e6da9ac1e76ca8a13f78c","Research Group Augmented Reality, Technical University of Munich, Munich, Germany","Palmas, F., Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Labode, D., Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Plecher, D.A., Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Klinker, G., Research Group Augmented Reality, Technical University of Munich, Munich, Germany","By using simulations in virtual reality (VR), people have the chance to train without supervision in a safe and controlled environment. VR simulation training allows users to gain new skills and apply them to real-life situations. However, the learning curve of this technology from a novice level could influence the expected learning results of a training session. A training approach based on the combination of VR and gamification could speed up this overall learning process and not just for a novice. In this paper we evaluate how gamification in a VR training session can improve the efficiency of the training and the accuracy of the task execution in a real-world practical test. In the training scenario of this study, 50 randomly assigned participants were divided into two groups. The groups were assigned to a gamified and a non-gamified version of the same VR training and were then guided through a step-by-step tutorial outlining how to solve an assembly task. Performance differences were evaluated based on time taken and specific errors made during the training session. The results of this study show, in general, that beneficial effects can be attributed to the use of gamification in the conducted VR training simulation, particularly for the VR novice participants. © 2019 IEEE.","Assembly task; Gamification; Learning transfer; Training; Virtual reality; Virtual training","Personnel training; Virtual reality; Assembly tasks; Beneficial effects; Controlled environment; Gamification; Learning Transfer; Training simulation; Virtual reality training; Virtual training; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85074257749
"Ryan E., Poole C.","57209315740;57006192700;","Impact of Virtual Learning Environment on Students’ Satisfaction, Engagement, Recall, and Retention",2019,"Journal of Medical Imaging and Radiation Sciences","50","3",,"408","415",,5,"10.1016/j.jmir.2019.04.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067334390&doi=10.1016%2fj.jmir.2019.04.005&partnerID=40&md5=925367af20b2450710f622091b817dbe","Trinity College Dublin, Applied Radiation Therapy Trinity, Discipline of Radiation Therapy, School of Medicine Dublin, Ireland","Ryan, E., Trinity College Dublin, Applied Radiation Therapy Trinity, Discipline of Radiation Therapy, School of Medicine Dublin, Ireland; Poole, C., Trinity College Dublin, Applied Radiation Therapy Trinity, Discipline of Radiation Therapy, School of Medicine Dublin, Ireland","Background: Virtual learning environments (VLEs) were introduced to progress students from passive to active learners. Active learning promotes the critical thinking skills essential for the transfer/use of classroom-acquired knowledge into the clinical setting. A VLE forms an increasingly vital component of clinical skills development in a range of disciplines. Material and Methods: A randomized control trial was conducted with students randomly attending one of two teaching sessions about radiation therapy. Both sessions were identical except a VLE was used in the second talk with the first being solely didactic. Anonymous questionnaires were distributed. Two weeks after the talks, participants were required to complete the same knowledge questionnaire to determine retention. Mann-Whitney, means, standard deviations, and chi-squared tests were used according to data characteristics. Qualitative data (open-ended questions) were analysed thematically. Results: Virtual learning seemed to significantly improve students' satisfaction/engagement and recall. A total of 40 students attended the teaching sessions. The student group taught using the VLE had higher mean scores for retention than the didactic group; however, this was not statistically significant. Use of VLEs was associated with greater satisfaction/engagement than didactic information (P = .003). Students' learning styles seemed to have no effect on their satisfaction/engagement and ease of learning. Three key themes emerged from the qualitative data: (1) the visuals were good/helpful, (2) the talk was informative, and (3) more details/visuals were required. Discussion and Conclusion: The key findings from this study suggest that there is a role for VLEs in the teaching of students. There is a need for the introduction of advanced technology into health care education as virtual reality, such as Virtual Environment of Radiotherapy, has shown improvement in students' satisfaction, engagement, and recall. Whether VLEs qualify students better than conventional didactic teaching is still undetermined, but these first results are encouraging. © 2019","clinical education; learning styles; radiotherapy/radiation therapy education; Virtual learning environment","adult; article; clinical article; clinical education; controlled study; female; human; human experiment; learning environment; learning style; male; questionnaire; radiotherapy; randomized controlled trial; recall; satisfaction; student; virtual reality; computer interface; education; medical education; medical student; procedures; psychology; radiology; radiotherapy; recall; Education, Medical; Educational Measurement; Humans; Mental Recall; Radiology; Radiotherapy; Students, Medical; Surveys and Questionnaires; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-85067334390
"Smith M., Walford N.S., Jimenez-Bescos C.","57202867830;7003391757;36608195700;","Using 3D modelling and game engine technologies for interactive exploration of cultural heritage: An evaluation of four game engines in relation to roman archaeological heritage",2019,"Digital Applications in Archaeology and Cultural Heritage","14",, e00113,"","",,4,"10.1016/j.daach.2019.e00113","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071373812&doi=10.1016%2fj.daach.2019.e00113&partnerID=40&md5=16efc06926cd483d946d1c5dec411b78","Geography Subject Area, School of Humanities, Religion and Philosophy, York St John University, Lord Mayor's Walk, York, YO31 7EX, United Kingdom; Department of Geography, Geology and the Environment, Kingston University, Penrhyn Road, Kingston upon ThamesKT1 2EE, United Kingdom; Department of Architecture and Built Environment, University of Nottingham, University Park Campus, Nottingham, NG7 2Rd, United Kingdom","Smith, M., Geography Subject Area, School of Humanities, Religion and Philosophy, York St John University, Lord Mayor's Walk, York, YO31 7EX, United Kingdom; Walford, N.S., Department of Geography, Geology and the Environment, Kingston University, Penrhyn Road, Kingston upon ThamesKT1 2EE, United Kingdom; Jimenez-Bescos, C., Department of Architecture and Built Environment, University of Nottingham, University Park Campus, Nottingham, NG7 2Rd, United Kingdom","Developments in information technology have challenged the traditional model of museums, libraries and similar venues acting as relatively passive ‘learning spaces’ for the public to access ‘knowledge’ as an exchange between tutor and learner, or in this context curator and visitor enabling them to offer more immersive and interactive modes of transfer. This article examines the development of a 3D model built from plans of a Roman edifice and its transfer into four game engines as vehicles for independent navigation around the ‘virtual building’. The game engines are evaluated in respect of their ability to enhance visitors’ experience by using an on-site facility when visiting a museum constructed over the physical remains. Cost and licensing override technical factors such as audiovisual and functional fidelity or composability and installing the system on a PC is preferable to more specialist game control devices if a broad user base is targeted. © 2019 Elsevier Ltd","3D modelling; Roman archaeology; Serious gaming; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85071373812
"Xu X., Shen L., Li S., Wang S.","57212107701;57212102274;57212108732;57212110295;","Research on 10kV line breaker check training system based on virtual reality",2019,"Proceedings - 2019 International Conference on Smart Grid and Electrical Automation, ICSGEA 2019",,, 8901373,"18","21",,,"10.1109/ICSGEA.2019.00013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075940419&doi=10.1109%2fICSGEA.2019.00013&partnerID=40&md5=cc1e8b915dcc9b8d2d27cdc93f2f99be","Shibei Power Supply Company of SIVIEPC, Shanghai, 200072, China","Xu, X., Shibei Power Supply Company of SIVIEPC, Shanghai, 200072, China; Shen, L., Shibei Power Supply Company of SIVIEPC, Shanghai, 200072, China; Li, S., Shibei Power Supply Company of SIVIEPC, Shanghai, 200072, China; Wang, S., Shibei Power Supply Company of SIVIEPC, Shanghai, 200072, China","The training is the important means to improve power system operators' quality and ensure the safe, stable and reliable operation of power system. The job of 10kV line breaker check is one of the most important tasks of relay protection, and the training effect of this job is directly related to the work efficiency and quality of relay protection employees. However, in the training for relay protection trainees, it is impossible to carry out the actual operation in the substation considering the safety factor, and the construction of simulated substation costs a lot. To solve this problem, this paper uses Unity to develop a 10kV line breaker check training system based on virtual reality (VR). The training system development tools, 10kV line breaker check project, the training system structure and function design are introduced in the paper. Practical application shows that the training system is simple to use, easy to learn, can timely and quickly transfer data and results, which has achieved a good training effect. © 2019 IEEE.","10kV line breaker check; Relay protection; Virtual reality","E-learning; Electric power system protection; Electric power transmission networks; Relay protection; Safety factor; Smart power grids; Virtual reality; Actual operation; Function designs; Line breakers; Power system operators; Quality of relays; Reliable operation; Training effects; Training Systems; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-85075940419
"He Q., McNamara T.P., Bodenheimer B., Klippel A.","56675107000;7004768772;56133948600;8438953000;","Acquisition and transfer of spatial knowledge during wayfinding",2019,"Journal of Experimental Psychology: Learning Memory and Cognition","45","8",,"1364","1386",,11,"10.1037/xlm0000654","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051931514&doi=10.1037%2fxlm0000654&partnerID=40&md5=a0330f54db114282d221d66a78e37eb9","School of Psychology, Georgia Institute of Technology, United States; Department of Psychology, Vanderbilt University, United States; Department of Electrical Engineering and Computer Science, Vanderbilt University, United States; Department of Geography, The Pennsylvania State University, United States","He, Q., School of Psychology, Georgia Institute of Technology, United States; McNamara, T.P., Department of Psychology, Vanderbilt University, United States; Bodenheimer, B., Department of Electrical Engineering and Computer Science, Vanderbilt University, United States; Klippel, A., Department of Geography, The Pennsylvania State University, United States","In the current study, we investigated the ways in which the acquisition and transfer of spatial knowledge were affected by (a) the type of spatial relations predominately experienced during learning (routes determined by walkways vs. straight-line paths between locations); (b) environmental complexity; and (c) the availability of rotational body-based information. Participants learned the layout of a virtual shopping mall by repeatedly searching for target storefronts located in 1 of the buildings. We created 2 novel learning conditions to encourage participants to use either route knowledge (paths on walkways between buildings) or survey knowledge (straight-line distances and directions from storefront to storefront) to find the target, and measured the development of route and survey knowledge in both learning conditions. Environmental complexity was manipulated by varying the alignment of the buildings with the enclosure, and the visibility within space. Body-based information was manipulated by having participants perform the experiment in front of a computer monitor or using a head-mounted display. After navigation, participants pointed to various storefronts from a fixed position and orientation. Results showed that the frequently used spatial knowledge could be developed similarly across environments with different complexities, but the infrequently used spatial knowledge was less developed in the complex environment. Furthermore, rotational body-based information facilitated spatial learning under certain conditions. Our results suggest that path integration may play an important role in spatial knowledge transfer, both from route to survey knowledge (cognitive map construction), and from survey to route knowledge (using cognitive map to guide wayfinding). © 2018 American Psychological Association.","Body-based information; Environmental complexity; Path integration; Spatial knowledge; Spatial navigation","adult; association; attention; distance perception; female; human; male; orientation; problem solving; social environment; spatial orientation; virtual reality; young adult; Adult; Attention; Cues; Distance Perception; Female; Humans; Male; Orientation; Problem Solving; Social Environment; Spatial Navigation; Transfer, Psychology; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85051931514
"Freeman D., Yu L.-M., Kabir T., Martin J., Craven M., Leal J., Lambe S., Brown S., Morrison A., Chapman K., Dudley R., O'Regan E., Rovira A., Goodsell A., Rosebrock L., Bergin A., Cryer T.L., Robotham D., Andleeb H., Geddes J.R., Hollis C., Clark D.M., Waite F.","57202665457;7404164174;8306023400;57207800864;56768273300;16316414400;56062305400;57197845312;7402258312;57193302351;7102777269;35364796300;36168782400;57210820949;55599839200;57220371600;57209103191;16246148900;57210820762;56883972800;7006624553;7404789162;56602675700;","Automated virtual reality (VR) cognitive therapy for patients with psychosis: Study protocol for a single-blind parallel group randomised controlled trial (gameChange)",2019,"BMJ Open","9","8", e031606,"","",,6,"10.1136/bmjopen-2019-031606","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071540567&doi=10.1136%2fbmjopen-2019-031606&partnerID=40&md5=48d536baa2fc52f9fa303f730a726d5d","Department of Psychiatry, University of Oxford, Oxford, United Kingdom; Oxford Health NHS Foundation Trust, Oxford, United Kingdom; NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom; Primary Care Clinical Trials Unit, Nuffield Department of Primary Care Health Sciences, University of Oxford, Oxford, United Kingdom; McPin Foundation, London, United Kingdom; NIHR MindTech, Institute of Mental Health, Division of Psychiatry and Applied Psychology, University of Nottingham, Nottingham, United Kingdom; Health Economics Research Centre, Nuffield Department of Population Health, University of Oxford, Oxford, United Kingdom; Greater Manchester Mental Health Foundation Trust, Manchester, United Kingdom; Division of Psychology and Mental Health, University of Manchester, Manchester, United Kingdom; Avon and Wiltshire Mental Health Partnership (AWP) NHS Trust, Bath, United Kingdom; Northumberland, Tyne and Wear NHS Foundation Trust, Newcastle upon Tyne, United Kingdom; University of Newcastle, Newcastle upon Tyne, United Kingdom; Nottinghamshire Healthcare NHS Foundation Trust, Nottingham, United Kingdom; Department of Experimental Psychology, University of Oxford, Oxford, United Kingdom","Freeman, D., Department of Psychiatry, University of Oxford, Oxford, United Kingdom, Oxford Health NHS Foundation Trust, Oxford, United Kingdom, NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom; Yu, L.-M., Primary Care Clinical Trials Unit, Nuffield Department of Primary Care Health Sciences, University of Oxford, Oxford, United Kingdom; Kabir, T., McPin Foundation, London, United Kingdom; Martin, J., NIHR MindTech, Institute of Mental Health, Division of Psychiatry and Applied Psychology, University of Nottingham, Nottingham, United Kingdom; Craven, M., NIHR MindTech, Institute of Mental Health, Division of Psychiatry and Applied Psychology, University of Nottingham, Nottingham, United Kingdom; Leal, J., Health Economics Research Centre, Nuffield Department of Population Health, University of Oxford, Oxford, United Kingdom; Lambe, S., Department of Psychiatry, University of Oxford, Oxford, United Kingdom, Oxford Health NHS Foundation Trust, Oxford, United Kingdom, NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom; Brown, S., NIHR MindTech, Institute of Mental Health, Division of Psychiatry and Applied Psychology, University of Nottingham, Nottingham, United Kingdom; Morrison, A., Greater Manchester Mental Health Foundation Trust, Manchester, United Kingdom, Division of Psychology and Mental Health, University of Manchester, Manchester, United Kingdom; Chapman, K., Avon and Wiltshire Mental Health Partnership (AWP) NHS Trust, Bath, United Kingdom; Dudley, R., Northumberland, Tyne and Wear NHS Foundation Trust, Newcastle upon Tyne, United Kingdom, University of Newcastle, Newcastle upon Tyne, United Kingdom; O'Regan, E., Nottinghamshire Healthcare NHS Foundation Trust, Nottingham, United Kingdom; Rovira, A., Department of Psychiatry, University of Oxford, Oxford, United Kingdom, Oxford Health NHS Foundation Trust, Oxford, United Kingdom, NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom; Goodsell, A., Department of Psychiatry, University of Oxford, Oxford, United Kingdom, Oxford Health NHS Foundation Trust, Oxford, United Kingdom, NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom; Rosebrock, L., Department of Psychiatry, University of Oxford, Oxford, United Kingdom, Oxford Health NHS Foundation Trust, Oxford, United Kingdom, NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom; Bergin, A., NIHR MindTech, Institute of Mental Health, Division of Psychiatry and Applied Psychology, University of Nottingham, Nottingham, United Kingdom; Cryer, T.L., McPin Foundation, London, United Kingdom; Robotham, D., McPin Foundation, London, United Kingdom; Andleeb, H., McPin Foundation, London, United Kingdom; Geddes, J.R., Department of Psychiatry, University of Oxford, Oxford, United Kingdom, Oxford Health NHS Foundation Trust, Oxford, United Kingdom, NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom; Hollis, C., NIHR MindTech, Institute of Mental Health, Division of Psychiatry and Applied Psychology, University of Nottingham, Nottingham, United Kingdom; Clark, D.M., Oxford Health NHS Foundation Trust, Oxford, United Kingdom, NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom, Department of Experimental Psychology, University of Oxford, Oxford, United Kingdom; Waite, F., Department of Psychiatry, University of Oxford, Oxford, United Kingdom, Oxford Health NHS Foundation Trust, Oxford, United Kingdom, NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom","Introduction Many patients with psychosis experience everyday social situations as anxiety-provoking. The fears can arise, for example, from paranoia, hallucinations, social anxiety or negative-self beliefs. The fears lead patients to withdraw from activities, and this isolation leads to a cycle of worsening physical and mental health. Breaking this cycle requires highly active treatment directly in the troubling situations so that patients learn that they can safely and confidently enter them. However patients with psychosis seldom receive such life-changing interventions. To solve this problem we have developed an automated psychological treatment delivered in virtual reality (VR). It allows patients to experience computer simulations of the situations that they find anxiety-provoking. A virtual coach guides patients, using cognitive techniques, in how to overcome their fears. Patients are willing to enter VR simulations of anxiety-provoking situations because they know the simulations are not real, but the learning made transfers to the real world. Methods and analysis 432 patients with psychosis and anxious avoidance of social situations will be recruited from National Health Service (NHS) secondary care services. In the gameChange trial, they will be randomised (1:1) to the six-session VR cognitive treatment added to treatment as usual or treatment as usual alone. Assessments will be conducted at 0, 6 (post-treatment) and 26 weeks by a researcher blind to allocation. The primary outcome is avoidance and distress in real-life situations, using a behavioural assessment task, at 6 weeks. The secondary outcomes are psychiatric symptoms, activity levels and quality of life. All main analyses will be intention-to-treat. Moderation and mediation will be tested. An economic evaluation will be conducted. Ethics and dissemination The trial has received ethical approval from the NHS South Central - Oxford B Research Ethics Committee (19/SC/0075). A key output will be a high-quality automated VR treatment for patients to overcome anxious avoidance of social situations. Trial registration number ISRCTN17308399. © Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY. Published by BMJ.","Cognitive therapy; Psychosis; Schizophrenia; Treatment; Virtual reality","adult; anxiety; Article; avoidance behavior; behavior assessment; clinical outcome; clinical trial protocol; cognitive therapy; computer simulation; controlled study; cost effectiveness analysis; distress syndrome; economic evaluation; fear; human; intention to treat analysis; major clinical study; multicenter study; psychosis; psychotherapy; quality of life; randomized controlled trial; single blind procedure; virtual reality; cognitive behavioral therapy; computer assisted therapy; England; multicenter study (topic); procedures; psychology; psychosis; randomized controlled trial (topic); time factor; treatment outcome; virtual reality exposure therapy; Cognitive Behavioral Therapy; England; Humans; Multicenter Studies as Topic; Psychotic Disorders; Quality of Life; Randomized Controlled Trials as Topic; Single-Blind Method; Therapy, Computer-Assisted; Time Factors; Treatment Outcome; Virtual Reality Exposure Therapy",Article,"Final","",Scopus,2-s2.0-85071540567
"Steffen J.H., Gaskin J.E., Meservy T.O., Jenkins J.L., Wolman I.","57200579874;36006215900;8965919200;36713489900;57210317891;","Framework of Affordances for Virtual Reality and Augmented Reality",2019,"Journal of Management Information Systems","36","3",,"683","729",,10,"10.1080/07421222.2019.1628877","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070323987&doi=10.1080%2f07421222.2019.1628877&partnerID=40&md5=4cc7e578379bb372fe5452b489db6237","Terry College of Business, University of Georgia, United States; Management Information Systems, Brigham Young University, United States; Information Systems, Brigham Young University, United States; Information Systems, Brigham Young University, United States; Master of Information Systems Management program, Brigham Young University, United States","Steffen, J.H., Terry College of Business, University of Georgia, United States; Gaskin, J.E., Management Information Systems, Brigham Young University, United States; Meservy, T.O., Information Systems, Brigham Young University, United States; Jenkins, J.L., Information Systems, Brigham Young University, United States; Wolman, I., Master of Information Systems Management program, Brigham Young University, United States","Virtual reality (VR) and augmented reality (AR) technologies continue to grow and present possibilities to change the ways we learn, accomplish tasks, and interact with the world. However, widespread adoption has continually languished below purported potential. We suggest that a more complete understanding of the underlying motives driving users to take advantage of VR and AR would aid researchers by consolidating fragmented knowledge across domains and by identifying paths for additional inquiry. Additionally, practitioners could identify areas of unmet motives for using VR and AR. To examine the motives for virtualization, we draw upon Gibson’s seminal work on affordances to create a framework of generalized affordances for virtually assisted activities relative to the affordances of physical reality. This framework facilitates comparison of virtualized activities to non-virtualized activities, comparison of similar activities across VR and AR, and delineates areas of inquiry for future research. The validity of the framework was explored through two quantitative studies and one qualitative study of a wide variety of professionals. We found that participants perceive a significant difference between physical reality and both VR and AR for all proposed affordances, and that for many affordances, users perceive a difference in the ability of AR and VR to enact them. The qualitative study confirmed the general structure of the framework, while also revealing additional sub-affordances to explore. Theoretically, this suggests that examining the affordances that differentiate these technologies from physical reality may be a valid approach to understanding why users adopt these technologies. Practitioners may find success by focusing development on the specific affordances that VR or AR is best equipped to enact. ©, Copyright © Taylor & Francis Group, LLC.","adoption motivations; augmented reality; technology adoption; technology affordances; theoretical framework; virtual reality; virtually assisted activities","Augmented reality; Virtual reality; Adoption motivations; Technology adoption; Technology affordances; Theoretical framework; virtually assisted activities; Engineering education",Article,"Final","",Scopus,2-s2.0-85070323987
"Wu H., Wang Y., Qiu J., Liu J., Zhang X.L.","14030737900;57204950159;57203815608;57203815337;55715154500;","User-defined gesture interaction for immersive VR shopping applications",2019,"Behaviour and Information Technology","38","7",,"726","741",,7,"10.1080/0144929X.2018.1552313","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058093939&doi=10.1080%2f0144929X.2018.1552313&partnerID=40&md5=658f7a33df4427d9da8503cc19cb20a1","The School of Communication and Design, Sun Yat-sen University, Guangzhou, China; Department of Medical Oncology, Sun Yat-sen University Cancer Center, State Key Laboratory of Oncology, South China, Collaborative Innovation Center for Cancer Medicine, Guangzhou, China; College of Information Sciences and Technology, Pennsylvania State University, University Park, PA, United States","Wu, H., The School of Communication and Design, Sun Yat-sen University, Guangzhou, China; Wang, Y., Department of Medical Oncology, Sun Yat-sen University Cancer Center, State Key Laboratory of Oncology, South China, Collaborative Innovation Center for Cancer Medicine, Guangzhou, China; Qiu, J., The School of Communication and Design, Sun Yat-sen University, Guangzhou, China; Liu, J., The School of Communication and Design, Sun Yat-sen University, Guangzhou, China; Zhang, X.L., College of Information Sciences and Technology, Pennsylvania State University, University Park, PA, United States","Gesture elicitation studies, which are a popular technology for collecting requirements and expectations by involving real users in gesture design processes, often suffer from gesture disagreement and legacy bias and may not generate optimal gestures for a target system in practice. This paper reports a research project on user-defined gestures for interacting with immersive VR shopping applications. The main contribution of this work is the proposal of a more practical method for deriving more reliable gestures than traditional gesture elicitation studies. We applied this method to a VR shopping application and obtained empirical evidence for the benefits of deriving two gestures in the a priori stage and selecting the top-two gestures in the a posteriori stage of traditional elicitation studies for each referent. We hope that this research can help lay a theoretical foundation for freehand-gesture-based user interface design and be generalised to all freehand-gesture-based applications. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.","elicitation study; Gestural interaction; online shopping; user-centered design; virtual reality","Human computer interaction; Software design; User centered design; Virtual reality; Design process; elicitation study; Gestural interaction; Online shopping; Practical method; Theoretical foundations; User interface designs; User-defined gestures; User interfaces",Article,"Final","",Scopus,2-s2.0-85058093939
"Juliano J.M., Saldana D., Schmiesing A., Liew S.-L.","57209396794;57194044260;57194041188;36992162200;","Experience with head-mounted virtual reality (HMD-VR) predicts transfer of HMD-VR motor skills",2019,"International Conference on Virtual Rehabilitation, ICVR","2019-July",, 8994345,"","",,,"10.1109/ICVR46560.2019.8994345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080146106&doi=10.1109%2fICVR46560.2019.8994345&partnerID=40&md5=e52cf9a653b976ff6d3a6891f629dc26","University of Southern California (USC), Neuroscience Graduate Program, Los Angeles, CA, United States; University of Southern California, Chan Division of Occupational, Los Angeles, CA, United States","Juliano, J.M., University of Southern California (USC), Neuroscience Graduate Program, Los Angeles, CA, United States; Saldana, D., University of Southern California, Chan Division of Occupational, Los Angeles, CA, United States; Schmiesing, A., University of Southern California, Chan Division of Occupational, Los Angeles, CA, United States; Liew, S.-L., University of Southern California, Chan Division of Occupational, Los Angeles, CA, United States","Immersive, head-mounted virtual reality (HMD-VR) has the potential to be a useful tool for motor rehabilitation. However, when developing tools for rehabilitation, it is essential to design interventions that will be most effective for generalizing to the real world. Therefore, it is important to understand what factors facilitate transfer from HMD-VR to non-HMD-VR environments. Here we used a well-established test of skilled motor learning, the Sequential Visual Isometric Pinch Task (SVIPT), to train healthy individuals in an HMD-VR environment. We examined whether learned motor skills transferred to a more conventional (non-HMD-VR) environment and what factors facilitated transfer. Our results suggest that on average, learned motor skills from this task transfer from an immersive virtual environment to a conventional environment; however, some individuals did not transfer the learned motor skills. We then examined individual differences between those that did show transfer and those that did not. We found that individuals who had previous exposure to HMD-VR were more likely to transfer their learned motor skills than those who did not. Individual differences in previous exposure to HMD-VR environments prior to training may serve as a predictor to whether learned motor skills will transfer out of HMD-VR. © 2019 IEEE.","head-mounted virtual reality; skilled motor learning; transfer","Helmet mounted displays; Virtual reality; Head mounted virtual reality; Healthy individuals; Immersive virtual environments; Individual Differences; Motor learning; Motor rehabilitation; Task transfer; transfer; Transfer learning",Conference Paper,"Final","",Scopus,2-s2.0-85080146106
"Maidenbaum S., Patel A., Stein E., Jacobs J.","54585718400;57202138700;57216239090;35558503500;","Spatial Memory Rehabilitation in Virtual Reality - Extending findings from Epilepsy Patients to the General Population",2019,"International Conference on Virtual Rehabilitation, ICVR","2019-July",, 8994573,"","",,3,"10.1109/ICVR46560.2019.8994573","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077928726&doi=10.1109%2fICVR46560.2019.8994573&partnerID=40&md5=44af684832ef69c1fb3ec696f673b77f","Columbia University, Biomedical EngineeringNY, United States","Maidenbaum, S., Columbia University, Biomedical EngineeringNY, United States; Patel, A., Columbia University, Biomedical EngineeringNY, United States; Stein, E., Columbia University, Biomedical EngineeringNY, United States; Jacobs, J., Columbia University, Biomedical EngineeringNY, United States","Spatial memory is a critical function. Without it, we cannot understand our environment, situate ourselves within it, or remember where items are located. Most research on the neural basis of spatial memory is conducted either with invasive brain recordings from animals or with non-invasive imaging in humans. An emerging way to link these areas is by studying rare invasive recordings from the human brain, which can be obtained from epilepsy patients who have electrodes surgically implanted for seizure mapping. In recent years this invasive method has expanded our understanding of how the human brain represents space and has also suggested methods for modulating and potentially rehabilitating memory. However, it is unclear whether these results from epilepsy patients generalize to the non-epileptic population, and from testing in hospital rooms to more immersive and comfortable setups. Here, groups of epilepsy patients (n=69) and healthy participants (n=17) performed the same virtual spatial memory task, enabling us to compare their spatial memory performance. Moreover, we compared spatial memory performance between a standard computer screen versus a head-mounted display. We found that the spatial memory performance of epilepsy patients performing our task in a hospital was similar to that of matched healthy participants performing the task in the lab. Furthermore, actual spatial memory performance was similar on the group level irrespective of the interface used, despite the fact that subjects reported higher immersion with the head mounted display. By showing consistent spatial memory performance with a single paradigm across epilepsy patients and healthy participants, as well as with the use of different display modalities, our results provide a baseline for evaluating findings regarding the neural basis of spatial memory and neuromodulation for rehabilitation. More broadly, these results demonstrate that findings from neurosurgical patients are comparable to the wider population. © 2019 IEEE.","Epilepsy; Immersive; Memory Rehabilitation; Spatial memory; Virtual Reality","Brain; Brain mapping; Helmet mounted displays; Hospitals; Neurology; Virtual reality; Critical functions; Epilepsy; General population; Head mounted displays; Immersive; Neurosurgical patients; Non-invasive imaging; Spatial memory; Patient rehabilitation",Conference Paper,"Final","",Scopus,2-s2.0-85077928726
"Wei S.-E., Saragih J., Simon T., Harley A.W., Lombardi S., Perdoch M., Hypes A., Wang D., Badino H., Sheikh Y.","55485702800;16178291100;36444916900;56115289800;57204687314;24822136000;57189798081;57211427209;8981371600;9437184000;","VR facial animation via multiview image translation",2019,"ACM Transactions on Graphics","38","4", 67,"","",,16,"10.1145/3306346.3323030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073888466&doi=10.1145%2f3306346.3323030&partnerID=40&md5=f6eae33b4d0ae00f03aadbb5bba01c86","Carnegie Mellon University, Facebook Reality Labs, United States; Facebook Reality Labs, Pittsburgh, PA, United States","Wei, S.-E., Facebook Reality Labs, Pittsburgh, PA, United States; Saragih, J., Facebook Reality Labs, Pittsburgh, PA, United States; Simon, T., Facebook Reality Labs, Pittsburgh, PA, United States; Harley, A.W., Carnegie Mellon University, Facebook Reality Labs, United States, Facebook Reality Labs, Pittsburgh, PA, United States; Lombardi, S., Facebook Reality Labs, Pittsburgh, PA, United States; Perdoch, M., Facebook Reality Labs, Pittsburgh, PA, United States; Hypes, A., Facebook Reality Labs, Pittsburgh, PA, United States; Wang, D., Facebook Reality Labs, Pittsburgh, PA, United States; Badino, H., Facebook Reality Labs, Pittsburgh, PA, United States; Sheikh, Y., Facebook Reality Labs, Pittsburgh, PA, United States","A key promise of Virtual Reality (VR) is the possibility of remote social interaction that is more immersive than any prior telecommunication media. However, existing social VR experiences are mediated by inauthentic digital representations of the user (i.e., stylized avatars). These stylized representations have limited the adoption of social VR applications in precisely those cases where immersion is most necessary (e.g., professional interactions and intimate conversations). In this work, we present a bidirectional system that can animate avatar heads of both users’ full likeness using consumer-friendly headset mounted cameras (HMC). There are two main challenges in doing this: unaccommodating camera views and the image-to-avatar domain gap. We address both challenges by leveraging constraints imposed by multiview geometry to establish precise image-to-avatar correspondence, which are then used to learn an end-to-end model for real-time tracking. We present designs for a training HMC, aimed at data-collection and model building, and a tracking HMC for use during interactions in VR. Correspondence between the avatar and the HMC-acquired images are automatically found through self-supervised multiview image translation, which does not require manual annotation or one-to-one correspondence between domains. We evaluate the system on a variety of users and demonstrate significant improvements over prior work. © 2019 Copyright held by the owner/author(s).","And Phrases: Face Tracking; Differentiable Rendering; Unsupervised Image Style Transfer","Virtual reality; Bidirectional system; Differentiable Rendering; Digital representations; Face Tracking; Multi-view geometry; Professional interactions; Social interactions; Unsupervised Image Style Transfer; Cameras",Article,"Final","",Scopus,2-s2.0-85073888466
"Wang H., Wang Q., Hu F.","57214057788;57145088700;57205211655;","Are you afraid of heights and suitable for working at height?",2019,"Biomedical Signal Processing and Control","52",,,"23","31",,4,"10.1016/j.bspc.2019.03.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063350700&doi=10.1016%2fj.bspc.2019.03.011&partnerID=40&md5=aa4056a7eff76371071e3dc5157f14a2","NO. 3-11, Wenhua Road, Heping District, Shenyang, 110819, China","Wang, H., NO. 3-11, Wenhua Road, Heping District, Shenyang, 110819, China; Wang, Q., NO. 3-11, Wenhua Road, Heping District, Shenyang, 110819, China; Hu, F., NO. 3-11, Wenhua Road, Heping District, Shenyang, 110819, China","Fear of highs is one of the most common phobias all around world. It could affect people's life, work and health. Standing on high-altitude can lead to fear, anxiety or even panic to some people. In this paper, EEG method is creatively combined with VR technology to assess the severity of fear of heights. By doing time-frequency analysis, we found that alpha band (8–13 Hz) and high beta (20–30 Hz) are sensitive to fear of heights and frontal and parietotemporal areas are the regions of interests for fear of heights. Then using cross mutual information we built up a functional brain networks of every subject. And we extracted EEG features from the brain networks. Statistical analysis was performed to select the features based on significance of difference. Finally, we implemented classification. The performance of classifiers (the average accuracy could reach 94.44%) based on the proposed method was compared to the performance of classifiers based on the traditional physiological features. As a result, the proposed method was verified to be reliable and superior on estimating the severity of fear of heights. In addition, the system was tested on elderly people and came out with good performance. It turns out that the proposed system has good generalization capability and adaptability. © 2019","EEG; Fear of heights; Functional brain network; VR","Biomedical engineering; Control engineering; Electroencephalography; Brain networks; Fear of heights; Generalization capability; Mutual informations; Performance of classifier; Physiological features; Regions of interest; Time frequency analysis; Signal processing; acrophobia; adult; agitation; anxiety; Article; brain function; controlled study; electroencephalogram; electrooculogram; entropy; fear; female; human; male; muscle tone; nerve cell network; normal human; priority journal; supervised machine learning; virtual reality; work environment",Article,"Final","",Scopus,2-s2.0-85063350700
"Lopez C.E., Ashour O., Tucker C.","57193163382;36080456300;15833577900;","An introduction to the CLICK approach: Leveraging virtual reality to integrate the industrial engineering curriculum",2019,"ASEE Annual Conference and Exposition, Conference Proceedings",,,,"","",,3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076433701&partnerID=40&md5=0b9ee7dc3d5e083d23ad59a1d87115c6","Pennsylvania State University, University Park, United States; Penn State Erie, Behrend College, United States","Lopez, C.E., Pennsylvania State University, University Park, United States; Ashour, O., Penn State Erie, Behrend College, United States; Tucker, C., Pennsylvania State University, University Park, United States","This work introduces a new approach called Connected Learning and Integrated Course Knowledge (CLICK). CLICK is intended to provide an integrative learning experience by leveraging Virtual Reality (VR) technology to help provide a theme to connect and transfer the knowledge of engendering concepts. Integrative learning is described as the process of creating connections between concepts (i.e., skill and knowledge) from different resources and experiences, linking theory and practice, and using a variation of platforms to help students' understanding. In the CLICK approach, the integration is achieved by VR learning modules that serve as a platform for a common theme and include various challenges and exercises from multiple courses across the IE curriculum. Moreover, the modules will provide an immersive and realistic experience, which the authors hypothesize, will improve how the students relate what they learn in a classroom, to real-life experiences. The goals of the CLICK approach are to (i) provide the needed connection between courses and improve students' learning, and (ii) provide the needed linkage between theory and practice through a realistic representation of systems using VR. This work presents the results from an initial usability test performed on one of the VR modules. The results from the usability test indicate that participants liked the realism of the VR module. However, there are still some areas for improvement, and future work will focus on assessing the impact of the CLICK approach on students' learning, motivation, and preparation to be successful engineers, areas which could translate to a STEM pipeline for the future workforce. © American Society for Engineering Education, 2019",,"Curricula; Engineering education; Knowledge management; Virtual reality; Integrated course; Integrative learning; Learning modules; Life experiences; Multiple course; New approaches; Theory and practice; Usability tests; Students",Conference Paper,"Final","",Scopus,2-s2.0-85076433701
"ElZomor M., Youssef O.","57190814645;57184009100;","Coupling haptic learning with technology to advance informal sTEM pedagogies",2019,"ASEE Annual Conference and Exposition, Conference Proceedings",,,,"","",,1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078724961&partnerID=40&md5=a7c4d937977639c351f36f40db141b2e","Florida International University, United States; University of Arizona, United States","ElZomor, M., Florida International University, United States; Youssef, O., University of Arizona, United States","Research in the field of engineering education highlights the ineffectiveness of one-way, lecture-based teaching and strongly advocates that faculty adopt new pedagogies that integrate technological tools. Such strategies actively engage learners and support their understanding. To revolutionize the traditional haptic learning pedagogy, Virtual Reality (VR) can be incorporated to support science, technology, engineering, and mathematics (STEM) students' level of learning, advance their communication skills and enhance problem-solving skills. VR is a technological tool that immerses students in the real built environment and utilizes different parts of the brain to access auditory and visual data. This ongoing, work in progress, research study describes the process of interweaving between engineering, technology, architecture and building sciences, through integration of VR. VR was used to leverage a seamless virtual application thus complementing theories with unlimited interactive pedagogies, which kept learners engaged, interested and ultimately fosters retention particularly in haptic courses. Specifically, this study integrates the VR technology into an Environmental Science Laboratory to support teaching, enhance students' understanding, and increase retention as well as triggering an interactive educational environment. This paper focuses on the method of advancing haptic learning with VR through introducing and analyzing five modules taught in a building sciences laboratory course in addition to sharing limitations and some lessons learned of this pedagogy. Consequently advancing an unorthodox pedagogical approach that not only provides students with a unique educational experience but also equips them with know-how and knowledge to utilize emerging technologies. © American Society for Engineering Education, 2019",,"Engineering research; Environmental technology; Students; Teaching; Technical presentations; Technology transfer; Architecture and buildings; Communication skills; Educational environment; Educational experiences; Emerging technologies; Environmental science; Problem solving skills; Science , technology , engineering , and mathematics; Engineering education",Conference Paper,"Final","",Scopus,2-s2.0-85078724961
"Toth K.A., Moreland J., Zhou C.Q., Balachandran A., Zhang M.F., Roudebush J.C.","57208035174;35109608300;7403347472;57214444492;57214450285;57205038347;","Development of an educational wind turbine troubleshooting and safety simulator",2019,"ASEE Annual Conference and Exposition, Conference Proceedings",,,,"","",,1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078726658&partnerID=40&md5=d49e56d904b56e935334d3c19ae651f4","Purdue University Northwest, United States; CIVS, Purdue University Northwest, United States; Center for Innovation through Visualization and Simulation; Ivy Tech Community College","Toth, K.A., Purdue University Northwest, United States; Moreland, J., Purdue University Northwest, United States; Zhou, C.Q., CIVS, Purdue University Northwest, United States; Balachandran, A., Center for Innovation through Visualization and Simulation; Zhang, M.F., Purdue University Northwest, United States; Roudebush, J.C., Ivy Tech Community College","This project is developing a web-based, interactive 3D simulator for community college wind energy technician training programs. Directly contributing to the current project are two previous wind energy projects: “Wind Tech TV,” a 2010 NSF Advanced Technological Education (ATE) project that compiled a library of online training materials for wind turbine technician training, and “Mixed Reality Simulators for Wind Energy Education,” a U.S. Department of Education Fund for the Improvement of Postsecondary Education (FIPSE) project that produced a series of simulators for wind energy educators and students to provide hands-on experiences and promote critical thinking. The new simulator is designed to teach troubleshooting and safety strategies, promote critical-thinking and problem-solving skills, and enhance the transfer of knowledge from classrooms to real-world situations. Learner immersion in a simulated environment and progression through numerous troubleshooting scenarios is expected to provide a better-prepared and more skilled workforce for the wind energy industry. Multiple community colleges, a wind energy company, two NSF ATE Centers, and a university research center comprise the multidisciplinary team working on this project. Community colleges are leading the curriculum and educational module design and implementation, industry collaborators are advising on needed skills and recommended activities, and the university research center is developing the software. Data from implementation in one community college so far show a 10% score increase for students using the simulator compared to traditional instruction alone. © American Society for Engineering Education, 2019",,"Curricula; Engineering education; Knowledge management; Mixed reality; Simulators; Wind power; Wind turbines; Advanced Technological Education; Department of Education; Multi-disciplinary teams; Postsecondary education; Problem solving skills; Simulated environment; Traditional instruction; Transfer of knowledge; Students",Conference Paper,"Final","",Scopus,2-s2.0-85078726658
"Gupta S., Tsiakas K., Owens L., Makedon F.","57191260906;56236865600;57209983843;57207521629;","VIIs: A vocational interactive immersive storytelling framework for skill training and performance assessment",2019,"ACM International Conference Proceeding Series",,,,"411","415",,,"10.1145/3316782.3324016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069223879&doi=10.1145%2f3316782.3324016&partnerID=40&md5=8bef72cc84cc29ccb09269339f96f390","University of Texas at Arlington, Arlington, TX, United States; Yale University, New Haven, CT, United States","Gupta, S., University of Texas at Arlington, Arlington, TX, United States; Tsiakas, K., Yale University, New Haven, CT, United States; Owens, L., University of Texas at Arlington, Arlington, TX, United States; Makedon, F., University of Texas at Arlington, Arlington, TX, United States","Training and assessment of a new worker is the most vital part of any vocational industry. The landscape of jobs and work is changing rapidly, thanks to the emerging new technology and the advancement of knowledge in the scientific fields. This technological and scientific revolution presents an opportunity in the creation of new industries and occupations, enhanced productivity and quality of work life, and the potential for more people to participate in the workforce. But these come at risk and disadvantage of an increased cost of training as well as lack of proper training in a few industries. In this paper, we propose to build a vIIS framework - A Vocational Interactive Immersive Storytelling system that uses storytelling in an Interactive virtual environment to train and assess a worker a new skill. The major advantage of this vIIS system is that it provides constant feedback in an engaging immersive virtual reality environment and has better memory retention and recall of the trained task. For assessment, we intend to collect data such as task completion time, accuracy, error rate, qualitative feedback and also measure transfer learning. © 2019 Association for Computing Machinery.","Framework; Interaction; Training; Virtual reality","Job satisfaction; Personnel training; Framework; Immersive virtual reality; Interaction; Interactive virtual environments; Performance assessment; Qualitative feedback; Quality of work life; Scientific revolutions; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85069223879
"Vertemati M., Cassin S., Rizzetto F., Vanzulli A., Elli M., Sampogna G., Gallieni M.","6602085318;57205576019;57205575796;16026541900;7003507564;57193081915;7004243711;","A Virtual Reality Environment to Visualize Three-Dimensional Patient-Specific Models by a Mobile Head-Mounted Display",2019,"Surgical Innovation","26","3",,"359","370",,7,"10.1177/1553350618822860","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060629868&doi=10.1177%2f1553350618822860&partnerID=40&md5=e7b6cc98e1f592ddf43393f6e8f6d519","Università degli Studi di Milano, Milan, Italy","Vertemati, M., Università degli Studi di Milano, Milan, Italy; Cassin, S., Università degli Studi di Milano, Milan, Italy; Rizzetto, F., Università degli Studi di Milano, Milan, Italy; Vanzulli, A., Università degli Studi di Milano, Milan, Italy; Elli, M., Università degli Studi di Milano, Milan, Italy; Sampogna, G., Università degli Studi di Milano, Milan, Italy; Gallieni, M., Università degli Studi di Milano, Milan, Italy","Introduction. With the availability of low-cost head-mounted displays (HMDs), virtual reality environments (VREs) are increasingly being used in medicine for teaching and clinical purposes. Our aim was to develop an interactive, user-friendly VRE for tridimensional visualization of patient-specific organs, establishing a workflow to transfer 3-dimensional (3D) models from imaging datasets to our immersive VRE. Materials and Methods. This original VRE model was built using open-source software and a mobile HMD, Samsung Gear VR. For its validation, we enrolled 33 volunteers: morphologists (n = 11), trainee surgeons (n = 15), and expert surgeons (n = 7). They tried our VRE and then filled in an original 5-point Likert-type scale 6-item questionnaire, considering the following parameters: ease of use, anatomy comprehension compared with 2D radiological imaging, explanation of anatomical variations, explanation of surgical procedures, preoperative planning, and experience of gastrointestinal/neurological disorders. Results in the 3 groups were statistically compared using analysis of variance. Results. Using cross-sectional medical imaging, the developed VRE allowed to visualize a 3D patient-specific abdominal scene in 1 hour. Overall, the 6 items were evaluated positively by all groups; only anatomy comprehension was statistically significant different among the 3 groups. Conclusions. Our approach, based on open-source software and mobile hardware, proved to be a valid and well-appreciated system to visualize 3D patient-specific models, paving the way for a potential new tool for teaching and preoperative planning. © The Author(s) 2019.","anatomy; head-mounted display; mobile; training; virtual reality","anatomy; Article; clinical practice; computer assisted tomography; human; image segmentation; medical education; nuclear magnetic resonance imaging; partial nephrectomy; questionnaire; radiography; surgeon; surgical technique; surgical training; three-dimensional imaging; training; treatment planning; virtual reality; computer assisted surgery; computer interface; devices; equipment design; software; three dimensional imaging; x-ray computed tomography; Equipment Design; Humans; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Software; Surgery, Computer-Assisted; Surveys and Questionnaires; Tomography, X-Ray Computed; User-Computer Interface; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85060629868
"Chen M., Saad W., Yin C., Debbah M.","57113807700;57203259001;7201995655;35588784300;","Data Correlation-Aware Resource Management in Wireless Virtual Reality (VR): An Echo State Transfer Learning Approach",2019,"IEEE Transactions on Communications","67","6", 8648419,"4267","4280",,16,"10.1109/TCOMM.2019.2900624","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067570259&doi=10.1109%2fTCOMM.2019.2900624&partnerID=40&md5=a5394beb4157a6063a3abd74b6a89eb1","Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA  24061, United States; Mathematical and Algorithmic Sciences Lab, Huawei France RD, Paris, 92100, France","Chen, M., Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Saad, W., Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA  24061, United States; Yin, C., Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Debbah, M., Mathematical and Algorithmic Sciences Lab, Huawei France RD, Paris, 92100, France","Providing seamless connectivity for wireless virtual reality (VR) users has emerged as a key challenge for future cloud-enabled cellular networks. In this paper, the problem of wireless VR resource management is investigated for a wireless VR network in which VR contents are sent by a cloud to cellular small base stations (SBSs). The SBSs will collect tracking data from the VR users, over the uplink, in order to generate the VR content and transmit it to the end-users using downlink cellular links. For this model, the data requested or transmitted by the users can exhibit correlation, since the VR users may engage in the same immersive virtual environment with different locations and orientations. As such, the proposed resource management framework can factor in such spatial data correlation, so as to better manage uplink and downlink traffic. This potential spatial data correlation can be factored into the resource allocation problem to reduce the traffic load in both the uplink and downlink. In the downlink, the cloud can transmit 360° contents or specific visible contents (e.g., user field of view) that are extracted from the original 360° contents to the users according to the users' data correlation so as to reduce the backhaul traffic load. In the uplink, each SBS can associate with the users that have similar tracking information so as to reduce the tracking data size. This data correlation-aware resource management problem is formulated as an optimization problem whose goal is to maximize the users' successful transmission probability, defined as the probability that the content transmission delay of each user satisfies an instantaneous VR delay target. To solve this problem, a machine learning algorithm that uses echo state networks (ESNs) with transfer learning is introduced. By smartly transferring information on the SBS's utility, the proposed transfer-based ESN algorithm can quickly cope with changes in the wireless networking environment due to users' content requests and content request distributions. Simulation results demonstrate that the developed algorithm achieves up to 15.8% and 29.4% gains in terms of successful transmission probability compared to Q-learning with data correlation and Q-learning without data correlation, respectively. © 1972-2012 IEEE.","echo state networks; resource allocation; transfer learning; Virtual reality","E-learning; Information management; Learning algorithms; Machine learning; Natural resources management; Probability; Problem solving; Resource allocation; Virtual reality; Echo state networks; Immersive virtual environments; Resource allocation problem; Resource management framework; Resource management problems; Transfer learning; Transmission probabilities; Wireless networking environment; Data reduction",Conference Paper,"Final","",Scopus,2-s2.0-85067570259
"van Ginkel S., Gulikers J., Biemans H., Noroozi O., Roozen M., Bos T., van Tilborg R., van Halteren M., Mulder M.","56543234400;55886508300;6603110521;57207851921;57206788460;57206775089;57206775011;57206781899;15136874400;","Fostering oral presentation competence through a virtual reality-based task for delivering feedback",2019,"Computers and Education","134",,,"78","97",,16,"10.1016/j.compedu.2019.02.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061989143&doi=10.1016%2fj.compedu.2019.02.006&partnerID=40&md5=ff9494b02443b0098dadc0d406cbdf81","VR Lab of the Archimedes Institute, Hogeschool Utrecht, University of Applied Sciences, bode 68, P.O. Box 8130, Wageningen, NL 6700 EW, Netherlands; Department of Education and Learning Sciences, Social Sciences Group, Wageningen University & Research, bode 68, P.O. Box 8130, Wageningen, NL 6700 EW, Netherlands; Groningen Institute for Evolutionary Life Sciences, Department of Behavioural Neuroscience, University of Groningen, P.O. Box 11103, Groningen, CC  9700, Netherlands; NCOI Education Management, Box 447, Hilversum, NL 1200 AK, Netherlands; CoVince, Adventurous Learning, Reyer Anslostraat 28, Utrecht, DJ  3522, Netherlands","van Ginkel, S., VR Lab of the Archimedes Institute, Hogeschool Utrecht, University of Applied Sciences, bode 68, P.O. Box 8130, Wageningen, NL 6700 EW, Netherlands, Department of Education and Learning Sciences, Social Sciences Group, Wageningen University & Research, bode 68, P.O. Box 8130, Wageningen, NL 6700 EW, Netherlands; Gulikers, J., Department of Education and Learning Sciences, Social Sciences Group, Wageningen University & Research, bode 68, P.O. Box 8130, Wageningen, NL 6700 EW, Netherlands; Biemans, H., Department of Education and Learning Sciences, Social Sciences Group, Wageningen University & Research, bode 68, P.O. Box 8130, Wageningen, NL 6700 EW, Netherlands; Noroozi, O., Department of Education and Learning Sciences, Social Sciences Group, Wageningen University & Research, bode 68, P.O. Box 8130, Wageningen, NL 6700 EW, Netherlands; Roozen, M., Groningen Institute for Evolutionary Life Sciences, Department of Behavioural Neuroscience, University of Groningen, P.O. Box 11103, Groningen, CC  9700, Netherlands; Bos, T., NCOI Education Management, Box 447, Hilversum, NL 1200 AK, Netherlands; van Tilborg, R., CoVince, Adventurous Learning, Reyer Anslostraat 28, Utrecht, DJ  3522, Netherlands; van Halteren, M., CoVince, Adventurous Learning, Reyer Anslostraat 28, Utrecht, DJ  3522, Netherlands; Mulder, M., Department of Education and Learning Sciences, Social Sciences Group, Wageningen University & Research, bode 68, P.O. Box 8130, Wageningen, NL 6700 EW, Netherlands","While previous studies have stressed the importance of feedback delivered by experts, it is unclear whether students’ oral presentation competence can be fostered through innovative technology for delivering feedback. This experimental study examined the effectiveness of a virtual reality-based task, in which first-year undergraduate students practiced their presentation in a virtual environment and received feedback produced by the system, on their presentation competence components (i.e. cognition, behaviour and attitudes towards presenting). The effects were compared with a control condition, which was a face-to-face presentation task with expert feedback. The students’ performance was measured using pre- and post-test multiple-choice tests, validated rubrics, and self-evaluation instruments. Results revealed significant improvements from pre-test to post-test in all three presentation competence components, without a difference between the conditions. Furthermore, the self-evaluation tests showed that students who presented in virtual reality were appreciative of the detailed and analytical feedback they received. Because of sample size limitations, the effects found could not be generalised. Therefore, future research on a larger sample is needed to examine population effects. Follow-up studies should focus on the extent to which virtual reality-based tasks can encourage self-regulation skills for the effective and efficient integration of these tasks in presentation courses. © 2019 Elsevier Ltd","Formative assessment; Higher education; Oral presentation competence; Virtual reality","Feedback; Technical presentations; Testing; Virtual reality; Follow-up Studies; Formative assessment; Higher education; Innovative technology; Oral presentations; Presentation tasks; Self regulation; Undergraduate students; Students",Article,"Final","",Scopus,2-s2.0-85061989143
"Alvarez F., Breitgand D., Griffin D., Andriani P., Rizou S., Zioulis N., Moscatelli F., Serrano J., Keltsch M., Trakadas P., Phan T.K., Weit A., Acar U., Prieto O., Iadanza F., Carrozzo G., Koumaras H., Zarpalas D., Jimenez D.","35748490600;55897138000;57212692328;55822591900;34977594700;57188750773;57195199192;57202434085;35102594300;6603036390;55234792400;57170688900;57203587451;57209359596;57203587033;24483290900;17434625400;8238770900;57210230706;","An Edge-to-Cloud Virtualized Multimedia Service Platform for 5G Networks",2019,"IEEE Transactions on Broadcasting","65","2", 8667014,"369","380",,23,"10.1109/TBC.2019.2901400","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063366825&doi=10.1109%2fTBC.2019.2901400&partnerID=40&md5=6016d63371f304f2be7fcab27364b95b","GATV Research Group, Universidad Politecnica de Madrid, Madrid, 28040, Spain; Computing As A Service, IBM Haifa Research Labs, Haifa, 3498825, Israel; Institute of Communications and Connected Systems, Department of Electronic and Electrical Engineering, University College London, London, WC1E 7JE, United Kingdom; Research and Development Laboratory, Engineering Ingegneria Informatica S.p.A., Rome, 00144, Italy; European Projects Department, Singular Logic, Athens, 145 64, Greece; Information Technologies Institute, Centre for Research and Technology Hellas, Thessaloniki, 57001, Greece; NextWorks, Pisa, 56122, Italy; Signals, Systems and Radiocommunications Department, Universidad Politecnica de Madrid, Madrid, 28040, Spain; Research and Development Department, Institut fur Rundfunktechnik, Munich, 80939, Germany; Department of Electrical Engineering, Technological and Educational, Institute of Sterea Ellada, Psachna, 34100, Greece; Multimedia Research and Development Department, NETAS, Istanbul, 34912, Turkey; Network Department, Radio Television Espanola, Madrid, 28007, Spain; Institute of Informatics and Telecommunications, NCSR Demokritos, Athens, 15310, Greece","Alvarez, F., GATV Research Group, Universidad Politecnica de Madrid, Madrid, 28040, Spain; Breitgand, D., Computing As A Service, IBM Haifa Research Labs, Haifa, 3498825, Israel; Griffin, D., Institute of Communications and Connected Systems, Department of Electronic and Electrical Engineering, University College London, London, WC1E 7JE, United Kingdom; Andriani, P., Research and Development Laboratory, Engineering Ingegneria Informatica S.p.A., Rome, 00144, Italy; Rizou, S., European Projects Department, Singular Logic, Athens, 145 64, Greece; Zioulis, N., Information Technologies Institute, Centre for Research and Technology Hellas, Thessaloniki, 57001, Greece; Moscatelli, F., NextWorks, Pisa, 56122, Italy; Serrano, J., Signals, Systems and Radiocommunications Department, Universidad Politecnica de Madrid, Madrid, 28040, Spain; Keltsch, M., Research and Development Department, Institut fur Rundfunktechnik, Munich, 80939, Germany; Trakadas, P., Department of Electrical Engineering, Technological and Educational, Institute of Sterea Ellada, Psachna, 34100, Greece; Phan, T.K., GATV Research Group, Universidad Politecnica de Madrid, Madrid, 28040, Spain; Weit, A., GATV Research Group, Universidad Politecnica de Madrid, Madrid, 28040, Spain; Acar, U., Multimedia Research and Development Department, NETAS, Istanbul, 34912, Turkey; Prieto, O., Network Department, Radio Television Espanola, Madrid, 28007, Spain; Iadanza, F., GATV Research Group, Universidad Politecnica de Madrid, Madrid, 28040, Spain; Carrozzo, G., NextWorks, Pisa, 56122, Italy; Koumaras, H., Institute of Informatics and Telecommunications, NCSR Demokritos, Athens, 15310, Greece; Zarpalas, D., Information Technologies Institute, Centre for Research and Technology Hellas, Thessaloniki, 57001, Greece; Jimenez, D., GATV Research Group, Universidad Politecnica de Madrid, Madrid, 28040, Spain","The focus of research into 5G networks to date has been largely on the required advances in network architectures, technologies, and infrastructures. Less effort has been put on the applications and services that will make use of and exploit the flexibility of 5G networks built upon the concept of software-defined networking (SDN) and network function virtualization (NFV). Media-based applications are amongst the most demanding services, requiring large bandwidths for high audio-visual quality, low-latency for interactivity, and sufficient infrastructure resources to deliver the computational power for running the media applications in the networked cloud. This paper presents a novel service virtualization platform (SVP), called 5G-MEDIA SVP, which leverages the principles of NFV and SDN to facilitate the development, deployment, and operation of media services on 5G networks. The platform offers an advanced cognitive management environment for the provisioning of network services (NSs) and media-related applications, which directly link their lifecycle management with user experience as well as optimization of infrastructure resource utilization. Another innovation of 5G-MEDIA SVP is the integration of serverless computing with media intensive applications in 5G networks, increasing cost effectiveness of operation and simplifying development and deployment time. The proposed SVP is being validated against three media use cases: 1) immersive virtual reality 3-D gaming application; 2) remote production of broadcast content incorporating user generated contents; and 3) dynamically adaptive content distribution networks for the intelligent distribution of ultrahigh definition content. The preliminary results of the 5G-MEDIA SVP platform evaluation are compared against current practice and show that the proposed platform provides enhanced functionality for the operators and infrastructure owners, while ensuring better NS performance to service providers and end users. © 1963-12012 IEEE.","5G networks; content delivery networks; immersive media; network functions virtualization; remote production; serverless computing","Application programs; Bandwidth; Cloud computing; Computer architecture; Cost effectiveness; Distributed computer systems; Media streaming; Multimedia services; Network function virtualization; Queueing networks; Tools; Transfer functions; Virtual reality; Content delivery network; G-networks; Immersive media; Media; Mobile communications; Network functions; serverless computing; Streaming media; 5G mobile communication systems",Article,"Final","",Scopus,2-s2.0-85063366825
"Maclean S., Geddes F., Kelly M., Della P.","57191624436;36339358500;35477541400;6507752617;","Realism and presence in simulation: Nursing student perceptions and learning outcomes",2019,"Journal of Nursing Education","58","6",,"330","338",,10,"10.3928/01484834-20190521-03","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067130996&doi=10.3928%2f01484834-20190521-03&partnerID=40&md5=a7fd2edb6ba049d1b1b22dd95b43a2d7","School of Nursing, Midwifery and Paramedicine, Curtin University, Perth, WA, Australia","Maclean, S., School of Nursing, Midwifery and Paramedicine, Curtin University, Perth, WA, Australia; Geddes, F., School of Nursing, Midwifery and Paramedicine, Curtin University, Perth, WA, Australia; Kelly, M., School of Nursing, Midwifery and Paramedicine, Curtin University, Perth, WA, Australia; Della, P., School of Nursing, Midwifery and Paramedicine, Curtin University, Perth, WA, Australia","Background: Research examining how perceived realism and presence affects participants’ learning experiences and outcomes is limited. Method: A convergent mixed-methods design was used, with quantitative data assigned as the primary method. After engaging in a communication training simulation, 141 undergraduate nursing students completed the Concept of Presence, Simulation Design, and the Quality of Discharge Teaching scales. A subsample of 12 participants were interviewed to provide qualitative data, as the secondary method, on their learning experience. Hierarchical multiple regression analysis was performed on the quantitative data and thematic analysis for qualitative data. Results: Differences in participants’ perceived realism and level of presence were not affected by the communication-based learning interventions. A positive, fully mediated relationship between realism, presence, and learning outcomes in discharge communication skills was found. The quality of the simulation experience gave participants the opportunity to reflect on their knowledge and capacity to transfer skills into clinical practice. Conclusion: The convergence of findings supports the theory that perceived realism and presence positively affected learning outcomes. © SLACK Incorporated.",,"adult; article; clinical practice; communication skill; female; human; human experiment; learning; major clinical study; male; mixed cell culture; multiple regression; nursing student; perception; quantitative analysis; simulation; teaching; thematic analysis; attitude; nursing education; nursing student; procedures; psychology; simulation training; young adult; Adult; Attitude; Education, Nursing, Baccalaureate; Female; Humans; Learning; Male; Simulation Training; Students, Nursing; Young Adult",Article,"Final","",Scopus,2-s2.0-85067130996
"Rogers J.M., Duckworth J., Middleton S., Steenbergen B., Wilson P.H.","57205393446;36460871400;7102867349;6701413521;7404348396;","Elements virtual rehabilitation improves motor, cognitive, and functional outcomes in adult stroke: Evidence from a randomized controlled pilot study",2019,"Journal of NeuroEngineering and Rehabilitation","16","1", 56,"","",,11,"10.1186/s12984-019-0531-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066015714&doi=10.1186%2fs12984-019-0531-y&partnerID=40&md5=05d2f102a4b02f5b33162a9028b41868","University of Sydney, Faculty of Health Sciences, Sydney, NSW, Australia; School of Design, RMIT, Melbourne, VIC, Australia; Nursing Research Institute, St Vincent's Health Australia and Australian Catholic University, Sydney, NSW, Australia; Behavioural Science Institute, Radboud University, Nijmegen, Netherlands; Centre for Disability and Development Research (CeDDR) and School of Behavioural and Health Science, Australian Catholic University, Melbourne, VIC, Australia","Rogers, J.M., University of Sydney, Faculty of Health Sciences, Sydney, NSW, Australia; Duckworth, J., School of Design, RMIT, Melbourne, VIC, Australia; Middleton, S., Nursing Research Institute, St Vincent's Health Australia and Australian Catholic University, Sydney, NSW, Australia; Steenbergen, B., Behavioural Science Institute, Radboud University, Nijmegen, Netherlands; Wilson, P.H., Centre for Disability and Development Research (CeDDR) and School of Behavioural and Health Science, Australian Catholic University, Melbourne, VIC, Australia","Background: Virtual reality technologies show potential as effective rehabilitation tools following neuro-trauma. In particular, the Elements system, involving customized surface computing and tangible interfaces, produces strong treatment effects for upper-limb and cognitive function following traumatic brain injury. The present study evaluated the efficacy of Elements as a virtual rehabilitation approach for stroke survivors. Methods: Twenty-one adults (42-94 years old) with sub-acute stroke were randomized to four weeks of Elements virtual rehabilitation (three weekly 30-40 min sessions) combined with treatment as usual (conventional occupational and physiotherapy) or to treatment as usual alone. Upper-limb skill (Box and Blocks Test), cognition (Montreal Cognitive Assessment and selected CogState subtests), and everyday participation (Neurobehavioral Functioning Inventory) were examined before and after inpatient training, and one-month later. Results: Effect sizes for the experimental group (d = 1.05-2.51) were larger compared with controls (d = 0.11-0.86), with Elements training showing statistically greater improvements in motor function of the most affected hand (p = 0.008), and general intellectual status and executive function (p ≤ 0.001). Proportional recovery was two- to three-fold greater than control participants, with superior transfer to everyday motor, cognitive, and communication behaviors. All gains were maintained at follow-up. Conclusion: A course of Elements virtual rehabilitation using goal-directed and exploratory upper-limb movement tasks facilitates both motor and cognitive recovery after stroke. The magnitude of training effects, maintenance of gains at follow-up, and generalization to daily activities provide compelling preliminary evidence of the power of virtual rehabilitation when applied in a targeted and principled manner. Trial registration: this pilot study was not registered. © 2019 The Author(s).","Cognition; Motor activity; Rehabilitation; Stroke; Upper extremity; Virtual reality","adult; aged; Article; Box and Blocks Test; cerebrovascular accident; clinical article; clinical effectiveness; cognition; CogState subtest; controlled study; effect size; Elements virtual rehabilitation; executive function; female; follow up; human; male; Montreal cognitive assessment; motor performance; Neurobehavioral Functioning Inventory; neurologic examination; occupational therapy; outcome assessment; physiotherapy; pilot study; priority journal; randomized controlled trial (topic); telerehabilitation; very elderly; cerebrovascular accident; convalescence; devices; middle aged; motor activity; pathophysiology; physiology; procedures; randomized controlled trial; stroke rehabilitation; virtual reality; Adult; Aged; Aged, 80 and over; Cognition; Female; Humans; Male; Middle Aged; Motor Activity; Physical Therapy Modalities; Pilot Projects; Recovery of Function; Stroke; Stroke Rehabilitation; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85066015714
"Li J., Kong Y., Röggla T., De Simone F., Ananthanarayan S., De Ridder H., El Ali A., Cesar P.","57203114304;57209395670;57188760937;25822067800;36170274900;35387764300;36701307500;16237880000;","Measuring and understanding photo sharing experiences in social virtual reality",2019,"Conference on Human Factors in Computing Systems - Proceedings",,,,"","",,8,"10.1145/3290605.3300897","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067595707&doi=10.1145%2f3290605.3300897&partnerID=40&md5=cab8f7ecc1cca5e5950db66af176998d","Centrum Wiskunde and Informatica, Amsterdam, Netherlands; University of Oldenburg, Oldenburg, Germany; Delft University of Technology, Delft, Netherlands; Centrum Wiskunde and Informatica, Delft University of Technology, Amsterdam, Netherlands","Li, J., Centrum Wiskunde and Informatica, Amsterdam, Netherlands; Kong, Y., Centrum Wiskunde and Informatica, Amsterdam, Netherlands; Röggla, T., Centrum Wiskunde and Informatica, Amsterdam, Netherlands; De Simone, F., Centrum Wiskunde and Informatica, Amsterdam, Netherlands; Ananthanarayan, S., University of Oldenburg, Oldenburg, Germany; De Ridder, H., Delft University of Technology, Delft, Netherlands; El Ali, A., Centrum Wiskunde and Informatica, Amsterdam, Netherlands; Cesar, P., Centrum Wiskunde and Informatica, Delft University of Technology, Amsterdam, Netherlands","Millions of photos are shared online daily, but the richness of interaction compared with face-to-face (F2F) sharing is still missing. While this may change with social Virtual Reality (socialVR), we still lack tools to measure such immersive and interactive experiences. In this paper, we investigate photo sharing experiences in immersive environments, focusing on socialVR. Running context mapping (N=10), an expert creative session (N=6), and an online experience clustering questionnaire (N=20), we develop and statistically evaluate a questionnaire to measure photo sharing experiences. We then ran a controlled, within-subject study (N=26 pairs) to compare photo sharing under F2F, Skype, and Facebook Spaces. Using interviews, audio analysis, and our questionnaire, we found that socialVR can closely approximate F2F sharing. We contribute empirical findings on the immersiveness differences between digital communication media, and propose a socialVR questionnaire that can in the future generalize beyond photo sharing. © 2019 Copyright held by the owner/author(s).","Immersion; Photo sharing; Presence; Questionnaire; Social; Virtual reality","Digital communication systems; Human computer interaction; Human engineering; Virtual reality; Immersion; Photo sharing; Presence; Questionnaire; Social; Surveys",Conference Paper,"Final","",Scopus,2-s2.0-85067595707
"Çakiroğlu Ü., Gökoğlu S.","26656621800;57192837084;","Development of fire safety behavioral skills via virtual reality",2019,"Computers and Education","133",,,"56","68",,28,"10.1016/j.compedu.2019.01.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060856945&doi=10.1016%2fj.compedu.2019.01.014&partnerID=40&md5=9e0b2c837029344bc6f9ecd3a9e473a9","Trabzon University, Fatih Faculty of Education, Department of Computer and Instructional Technology Education, Trabzon, Turkey; Kastamonu University, Cide Rıfat Ilgaz Vocational School, Department of Computer Technologies, Kastamonu, Turkey","Çakiroğlu, Ü., Trabzon University, Fatih Faculty of Education, Department of Computer and Instructional Technology Education, Trabzon, Turkey; Gökoğlu, S., Kastamonu University, Cide Rıfat Ilgaz Vocational School, Department of Computer Technologies, Kastamonu, Turkey","In recent years, virtual reality has become prevalent in many educational settings. In this study, virtual reality-based behavioral skills training (VR-BST) approach is proposed to teach basic behavioral skills for fire safety. A virtual reality-based environment was designed and implemented in the context of the design-based research. A group of ten primary school students received a basic fire safety training package through this environment and in situ training was implemented when needed. The results indicated that students’ fire safety behavioral skills significantly improved with the use of virtual reality based training and the majority of the students could transfer their behavioral skills to real environments. The way of modelling the behaviors in this study and integrating in situ training into the learning environment positively contributed to the development of behavioral skills. The study concludes with suggestions for practitioners and researchers in the field of virtual reality for behavioral skills training. © 2019 Elsevier Ltd","Fire safety training; Virtual reality; Virtual reality-based behavioral skills training (VR-BST)","Computer aided instruction; Fires; Students; Virtual reality; Design-based research; Educational settings; Fire safety; Learning environments; Primary schools; Real environments; Skills training; E-learning",Article,"Final","",Scopus,2-s2.0-85060856945
"Chen M., Saad W., Yin C.","57113807700;57203259001;7201995655;","Liquid State Based Transfer Learning for 360° Image Transmission in Wireless VR Networks",2019,"IEEE International Conference on Communications","2019-May",, 8761494,"","",,2,"10.1109/ICC.2019.8761494","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070234616&doi=10.1109%2fICC.2019.8761494&partnerID=40&md5=f2882dac4d905d889b9c8f4018e9a94e","Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Wireless at VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, United States","Chen, M., Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Saad, W., Wireless at VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, United States; Yin, C., Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China","In this paper, the problem of 360° image transmission is studied for a wireless network of virtual reality (VR) users that communicate with cellular base stations (BSs). The VR users will send their uplink tracking information to the BS and receive the VR images in the downlink. To satisfy VR users' delay target, the BSs can change the image transmission format for each image requested by users so as to reduce the downlink traffic load. Meanwhile, the VR users can directly rotate the already received VR image and use the rotated VR images at a later time to further reduce the downlink traffic load. This 360° image transmission and image rotation problem is then formulated as an optimization problem whose goal is to maximize the users' successful transmission probability which is defined as the probability that the delay of tracking information and image transmission for each VR user satisfies the VR delay requirement. A liquid state machine (LSM) based transfer learning algorithm is proposed to solve this optimization problem. The proposed LSM-based transfer learning algorithm enables each BS to transfer the already learned successful transmission to the new successful transmission that must be learned so as to increase the convergence speed. Simulation results show that the proposed algorithm achieves 14.9% gain in terms of successful transmission probability compared to Q-learning. © 2019 IEEE.",,"Imaging systems; Optimization; Probability; Reinforcement learning; Virtual reality; Cellular base stations; Convergence speed; Downlink traffics; Liquid state machines; Optimization problems; Transfer learning; Transmission formats; Transmission probabilities; Learning algorithms",Conference Paper,"Final","",Scopus,2-s2.0-85070234616
"Danial S.N., Smith J., Khan F., Veitch B.","24823887800;56493414900;7402008246;7003302037;","Human-Like Sequential Learning of Escape Routes for Virtual Reality Agents",2019,"Fire Technology","55","3",,"1057","1083",,6,"10.1007/s10694-019-00819-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061744721&doi=10.1007%2fs10694-019-00819-7&partnerID=40&md5=be55ed4202479890ae1986222a196948","Faculty of Engineering and Applied Science, Centre for Risk, Integrity and Safety Engineering (C-RISE), Memorial University, St. John’s, NL, Canada","Danial, S.N., Faculty of Engineering and Applied Science, Centre for Risk, Integrity and Safety Engineering (C-RISE), Memorial University, St. John’s, NL, Canada; Smith, J., Faculty of Engineering and Applied Science, Centre for Risk, Integrity and Safety Engineering (C-RISE), Memorial University, St. John’s, NL, Canada; Khan, F., Faculty of Engineering and Applied Science, Centre for Risk, Integrity and Safety Engineering (C-RISE), Memorial University, St. John’s, NL, Canada; Veitch, B., Faculty of Engineering and Applied Science, Centre for Risk, Integrity and Safety Engineering (C-RISE), Memorial University, St. John’s, NL, Canada","The Piper Alpha disaster (1988) witnessed 167 casualties. The offshore safety guidelines developed afterward highlighted the need for effective and regular training to overcome the problems in evacuation procedures. Today, virtual environments are effective training platforms due to high-end audio/visual and interactive capabilities. These virtual environments exploit agents with human-like steering capabilities, but with limited or no capacity to learn routes. This work proposes a sequential route learning methodology for agents that resembles the way people learn routes. The methodology developed here exploits a generalized stochastic Petri-net based route learning model iteratively. The simulated results are compared with the route learning strategies of human participants. The data on human participants were collected by the authors from an earlier study in a virtual environment. The main contribution lies in modeling people’s route learning behavior over the course of successive exposures. It is found that the proposed methodology models human-like sequential route learning if there are no easy detours from the original escape route. Although the model does not accurately capture individual learning strategies for all decision nodes, it can be used as a model of compliant, rule-following training guides for a virtual environment. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Emergency evacuation; Emergency training; Fire safety; Human-like route learning; Intelligent agents; Petri nets; Virtual reality","E-learning; Fires; Intelligent agents; Iterative methods; Learning systems; Offshore oil well production; Petri nets; Stochastic models; Stochastic systems; Virtual reality; Emergency evacuation; Emergency training; Evacuation procedures; Fire safety; Generalized Stochastic Petri nets; Individual learning; Route learning; Sequential learning; Intelligent virtual agents",Article,"Final","",Scopus,2-s2.0-85061744721
"Zaragoza-Siqueiros J., Medellin-Castillo H.I., de la Garza-Camargo H., Lim T., Ritchie J.M.","56582397300;8579367300;57205670877;24923001300;7403187395;","An integrated haptic-enabled virtual reality system for orthognathic surgery planning",2019,"Computer Methods in Biomechanics and Biomedical Engineering","22","5",,"499","517",,4,"10.1080/10255842.2019.1566817","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061031514&doi=10.1080%2f10255842.2019.1566817&partnerID=40&md5=001900041eb9709390d157631314cea6","Facultad de Ingeniería, Universidad Autónoma de San Luis Potosí, San Luis Potosí, Mexico; Facultad de Estomatología, Universidad Autónoma de San Luis Potosí, San Luis Potosí, Mexico; Institute of Mechanical, Process and Energy Engineering, School of Engineering and Physical Sciences, Heriot-Watt University, Riccarton, Edinburgh, United Kingdom","Zaragoza-Siqueiros, J., Facultad de Ingeniería, Universidad Autónoma de San Luis Potosí, San Luis Potosí, Mexico; Medellin-Castillo, H.I., Facultad de Ingeniería, Universidad Autónoma de San Luis Potosí, San Luis Potosí, Mexico; de la Garza-Camargo, H., Facultad de Estomatología, Universidad Autónoma de San Luis Potosí, San Luis Potosí, Mexico; Lim, T., Institute of Mechanical, Process and Energy Engineering, School of Engineering and Physical Sciences, Heriot-Watt University, Riccarton, Edinburgh, United Kingdom; Ritchie, J.M., Institute of Mechanical, Process and Energy Engineering, School of Engineering and Physical Sciences, Heriot-Watt University, Riccarton, Edinburgh, United Kingdom","Conventional Orthognathic surgery (OGS) planning involves cephalometric analyses and dental casts to be mounted on an articulator. Dental segments are subsequently identified, cut and repositioned to allow the fabrication of intraoral wafers that guide the positioning of the osteotomy bone segments. This conventional planning introduces many inaccuracies that affect the post-surgery outcomes. Although computer technologies have advanced computational tools for OGS planning, they have failed in providing a practical solution. Many focuses only on some specific stages of the planning process, and their ability to transfer preoperative planning data to the operating room is limited. This paper proposes a new integrated haptic-enabled virtual reality (VR) system for OGS planning. The system incorporates CAD tools and haptics to facilitate a complete planning process and is able to automatically generate preoperative plans. A clinical pre-diagnosis is also provided automatically by the system based on the patient’s digital data. A functional evaluation based on a real patient case study demonstrates that the proposed virtual OGS planning method is feasible and more effective than the traditional approach at increasing the intuitiveness and reducing errors and planning times. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","computer-aided surgery; haptic technologies; Orthognathic surgery (OGS); surgery planning; virtual reality (VR)","Virtual reality; Cephalometric analysis; Computer aided surgery; Haptic technology; Orthognathic surgeries; Pre-operative planning; Surgery planning; Traditional approaches; Virtual reality system; Surgery; acrylic acid resin; hydroxyapatite; nerve cell adhesion molecule; adult; Article; case report; clinical article; computer aided design; cone beam computed tomography; daily life activity; human; male; mastoidectomy; maxillofacial surgery; middle aged; nuclear magnetic resonance imaging; osteotomy; panoramic radiography; priority journal; three dimensional imaging; training; treadmill exercise; virtual reality; cephalometry; computer assisted surgery; computer simulation; face; orthognathic surgery; patient care planning; physiology; procedures; time factor; touch; Adult; Cephalometry; Computer Simulation; Computer-Aided Design; Face; Humans; Imaging, Three-Dimensional; Male; Orthognathic Surgery; Patient Care Planning; Surgery, Computer-Assisted; Time Factors; Touch; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85061031514
"Makransky G., Terkildsen T.S., Mayer R.E.","50361371800;57205338475;7403065717;","Adding immersive virtual reality to a science lab simulation causes more presence but less learning",2019,"Learning and Instruction","60",,,"225","236",,159,"10.1016/j.learninstruc.2017.12.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039065813&doi=10.1016%2fj.learninstruc.2017.12.007&partnerID=40&md5=bec8f76c5a5c407cea29ee47829f155c","Department of Psychology, University of Copenhagen, Copenhagen, Denmark; Psychological and Brain Sciences, University of California Santa BarbaraCA, United States","Makransky, G., Department of Psychology, University of Copenhagen, Copenhagen, Denmark; Terkildsen, T.S., Department of Psychology, University of Copenhagen, Copenhagen, Denmark; Mayer, R.E., Psychological and Brain Sciences, University of California Santa BarbaraCA, United States","Virtual reality (VR) is predicted to create a paradigm shift in education and training, but there is little empirical evidence of its educational value. The main objectives of this study were to determine the consequences of adding immersive VR to virtual learning simulations, and to investigate whether the principles of multimedia learning generalize to immersive VR. Furthermore, electroencephalogram (EEG) was used to obtain a direct measure of cognitive processing during learning. A sample of 52 university students participated in a 2 × 2 experimental cross-panel design wherein students learned from a science simulation via a desktop display (PC) or a head-mounted display (VR); and the simulations contained on-screen text or on-screen text with narration. Across both text versions, students reported being more present in the VR condition (d = 1.30); but they learned less (d = 0.80), and had significantly higher cognitive load based on the EEG measure (d = 0.59). In spite of its motivating properties (as reflected in presence ratings), learning science in VR may overload and distract the learner (as reflected in EEG measures of cognitive load), resulting in less opportunity to build learning outcomes (as reflected in poorer learning outcome test performance). © 2017 Elsevier Ltd","Cognitive load; EEG; Presence; Redundancy principle; Simulation; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85039065813
"Baxter G., Hainey T.","7202105776;16238485400;","Student perceptions of virtual reality use in higher education",2019,"Journal of Applied Research in Higher Education","12","3",,"413","424",,5,"10.1108/JARHE-06-2018-0106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064012439&doi=10.1108%2fJARHE-06-2018-0106&partnerID=40&md5=0dda0a11d1aef1b0a553cca74f01eefc","Department of Computing, University of the West of Scotland, Paisley, United Kingdom","Baxter, G., Department of Computing, University of the West of Scotland, Paisley, United Kingdom; Hainey, T., Department of Computing, University of the West of Scotland, Paisley, United Kingdom","Purpose: This paper provides an analysis and insight into undergraduate student views concerning the use of virtual reality technology towards whether it has the potential to support and provide novel pedagogical avenues towards teaching and learning in higher education. The purpose of this paper is to ascertain student views about the application of VR technology within their degree programmes from a pedagogical perspective in addition to identifying potential challenges to VR adoption. Design/methodology/approach: The research design adopted a mixed methods approach through the use of a questionnaire that was disseminated to undergraduate students studying in the discipline area of the creative industries. Through a series of open and closed questions, student views on VR adoption in higher education were analysed both quantitatively and qualitatively. The results were analysed statistically through a series of Mann–Whitney and Kruskal–Wallis tests. The qualitative statements were contextualised in the overall perspective of the research with the more relevant viewpoints identified to coincide with aspects of VR discovered in the literature. Findings: The predominant findings of the research indicated that the majority of the students considered the use of VR to have useful pedagogical implications though not all findings were positive. The findings provided a sound overview of the benefits and potential drawbacks of VR use in general with a more specific focus in an educational context. Research limitations/implications: Limitations of the research include the lack of overall generalisations that can be formed from the study due to the sample size and the fact that the results were based from one specific academic institution. Practical implications: The findings of the research will provide educators with an insight into various perceptions of VR adoption within higher education. This will aid towards allowing them to reflect on whether VR is an appropriate tool to integrate within their curriculum and pedagogical approaches towards course delivery. Originality/value: Though several studies have explored the use of VR in multiple contexts and subject areas, there still needs to be more research towards its potential drawbacks in a teaching and learning scenario and how to resolve these issues. © 2019, Emerald Publishing Limited.","Engagement; Higher education; Immersion; Presence; Virtual reality; VR technology",,Article,"Final","",Scopus,2-s2.0-85064012439
"Stroe I.P., Ciupe A., Meza S.N., Orza B.","57209343958;57105700600;24829838400;24503681900;","FireEscape: A gamified coordinative aproach to multiplayer fire-safety training",2019,"IEEE Global Engineering Education Conference, EDUCON","April-2019",, 8725148,"1316","1323",,,"10.1109/EDUCON.2019.8725148","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067504866&doi=10.1109%2fEDUCON.2019.8725148&partnerID=40&md5=5f665dbff98f0a0805983f4572211f3d","Multimedia Systems and Applications Laboratory, Technical University of Cluj-Napoca, Cluj-Napoca, Romania","Stroe, I.P., Multimedia Systems and Applications Laboratory, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Ciupe, A., Multimedia Systems and Applications Laboratory, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Meza, S.N., Multimedia Systems and Applications Laboratory, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Orza, B., Multimedia Systems and Applications Laboratory, Technical University of Cluj-Napoca, Cluj-Napoca, Romania","Emergency trainings simulated in alternative environments are fundamentally dependent on user engagement and may be addressed as crucial validation scenarios for proposing new approaches to learning designs. Developing an interactive engaging experience while building a know-how becomes a challenging demand to be addressed in current training setups. A fire-safety training has been recreated as a gamified learning experience, where coordinative multiplayer gameplay elements have been integrated in 3D fire emergency simulation. 3C implications (collaboration, cooperation, coordination) have been analyzed for modeling multiuser navigation and a coordinative approach has been selected for accomplishing the goal-oriented mission of successful evacuation in a fire-based emergency scenario. Game-based analytics have been collected and analyzed in an experimental pre-test, addressed to 1st year students enrolled in the Faculty of Electronics, Telecommunications and Information Technology of the Technical University of Cluj-Napoca, Romania, where out of a total number of 196 students, 22 participants actively ran the simulation as either belonging to the control or experimental group. © 2019 IEEE.","Coordinative interaction; Gameplay analytics; Gamified simulation; Learning design; Multiplayer setup","Air navigation; Engineering education; Human computer interaction; Students; Technology transfer; Coordinative interaction; Gameplay; Gamified simulation; Learning designs; Multiplayers; Fires",Conference Paper,"Final","",Scopus,2-s2.0-85067504866
"Sportillo D., Paljic A., Ojeda L.","56912310500;34873176200;57194572140;","On-Road Evaluation of Autonomous Driving Training",2019,"ACM/IEEE International Conference on Human-Robot Interaction","2019-March",, 8673277,"182","190",,9,"10.1109/HRI.2019.8673277","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063979607&doi=10.1109%2fHRI.2019.8673277&partnerID=40&md5=bd03eba8222bcb01343450cc3fe89a9d","PSL Research University, Center for Robotics, MINES ParisTech Groupe PSA, Paris, France; Groupe PSA, Velizy-Villacoublay, France","Sportillo, D., PSL Research University, Center for Robotics, MINES ParisTech Groupe PSA, Paris, France; Paljic, A., PSL Research University, Center for Robotics, MINES ParisTech Groupe PSA, Paris, France; Ojeda, L., Groupe PSA, Velizy-Villacoublay, France","Driver interaction with increasingly automated vehicles requires prior knowledge of system capabilities, operational know-how to use novel car equipment and responsiveness to unpredictable situations. With the purpose of getting drivers ready for autonomous driving, in a between-subject study sixty inexperienced participants were trained with an on-board video tutorial, an Augmented Reality (AR) program and a Virtual Reality (VR) simulator. To evaluate the transfer of training to real driving scenarios, a test drive on public roads was conducted implementing, for the first time in these conditions, the Wizard of Oz (WoZ) protocol. Results suggest that VR and AR training can foster knowledge acquisition and improve reaction time performance in take-over requests. Moreover, participants' behavior during the test drive highlights the ecological validity of the experiment thanks to the effective implementation of the WoZ methodology. © 2019 IEEE.","Augmented Reality; Automated Vehicles; Human-Vehicle Interaction; TOR; Transfer of Training; Virtual Reality; Wizard of Oz","Augmented reality; Human reaction time; Man machine systems; Network security; Technology transfer; Vehicles; Virtual reality; Automated vehicles; Autonomous driving; Driver interaction; Ecological validity; Human vehicle interactions; System capabilities; Transfer of trainings; Wizard of Oz; Human robot interaction",Conference Paper,"Final","",Scopus,2-s2.0-85063979607
"Rivière E., Aubin E., Tremblay S.-L., Lortie G., Chiniara G.","36653247600;57207825927;57207818090;6701371276;55583067300;","A new tool for assessing short debriefings after immersive simulation: Validity of the SHORT scale",2019,"BMC Medical Education","19","1", 82,"","",,1,"10.1186/s12909-019-1503-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062949408&doi=10.1186%2fs12909-019-1503-4&partnerID=40&md5=7e7e3cbbb14cc58434f779a4794d0e4a","Department of Internal Medicine, Haut-Leveque Hospital, University Hospital Centre of Bordeaux, Pessac, France; Medical Faculty, Bordeaux University, Bordeaux, France; SimBA-S Simulation Centre, University and Hospital of Bordeaux, Quebec, Canada; Apprentiss Centre (Simulation Centre), Laval UniversityQC, Canada; Independent ResearcherQC, Canada; University Institute of Cardiology and Pneumology of QuebecQC, Canada; Emergency Unit, Levis Hotel-Dieu Hospital, University Hospital of Quebec, Lévis, Canada; Department of Anesthesiology and Intensive Care, Laval UniversityQC, Canada","Rivière, E., Department of Internal Medicine, Haut-Leveque Hospital, University Hospital Centre of Bordeaux, Pessac, France, Medical Faculty, Bordeaux University, Bordeaux, France, SimBA-S Simulation Centre, University and Hospital of Bordeaux, Quebec, Canada, Apprentiss Centre (Simulation Centre), Laval UniversityQC, Canada; Aubin, E., Independent ResearcherQC, Canada; Tremblay, S.-L., Apprentiss Centre (Simulation Centre), Laval UniversityQC, Canada, University Institute of Cardiology and Pneumology of QuebecQC, Canada; Lortie, G., Apprentiss Centre (Simulation Centre), Laval UniversityQC, Canada, Emergency Unit, Levis Hotel-Dieu Hospital, University Hospital of Quebec, Lévis, Canada; Chiniara, G., Apprentiss Centre (Simulation Centre), Laval UniversityQC, Canada, Department of Anesthesiology and Intensive Care, Laval UniversityQC, Canada","Background: Simulation is being increasingly used worldwide in healthcare education. However, it is costly both in terms of finances and human resources. As a consequence, several institutions have designed programs offering several short immersive simulation sessions, each followed by short debriefings. Although debriefing is recommended, no tool exists to assess appropriateness of short debriefings after such simulation sessions. We have developed the Simulation in Healthcare retrOaction Rating Tool (SHORT) to assess short debriefings, and provide some validity evidence for its use. Methods: We designed this scale based on our experience and previously published instruments, and tested it by assessing short debriefings of simulation sessions offered to emergency medicine residents at Laval University (Canada) from 2015 to 2016. Analysis of its reliability and validity was done using Standards for educational and psychological testing. Generalizability theory was used for testing internal structure evidence for validity. Results: Two raters independently assessed 22 filmed short debriefings. Mean debriefing length was 10:35 (min 7:21; max 14:32). Calculated generalizability (reliability) coefficients are φ = 0.80 and φ-λ3 = 0.82. The generalizability coefficient for a single rater assessing three debriefings is φ = 0.84. Conclusions: The G study shows a high generalizability coefficient (φ ≥ 0.80), which demonstrates a high reliability. The response process evidence for validity provides evidence that no errors were associated with using the instrument. Further studies should be done to demonstrate validity of the English version of the instrument and to validate its use by novice raters trained in the use of the SHORT. © 2019 The Author(s).","Educational measurement; Formative feedback; Generalizability theory; High-fidelity simulation training; Patient simulation; SHORT; Simulation training","adult; article; Canada; constructive feedback; emergency medicine; error; female; high fidelity simulation training; human; human experiment; male; patient simulation; psychologic test; reliability; resident; theoretical study; validity; clinical competence; constructive feedback; education; medical education; practice guideline; procedures; reproducibility; standards; validation study; Clinical Competence; Education, Medical; Educational Measurement; Formative Feedback; Humans; Patient Simulation; Practice Guidelines as Topic; Reproducibility of Results",Article,"Final","",Scopus,2-s2.0-85062949408
"Lefrançois C., Messier J.","57205320434;6701376943;","Adaptation and spatial generalization to a triaxial visuomotor perturbation in a virtual reality environment",2019,"Experimental Brain Research","237","3",,"793","803",,1,"10.1007/s00221-018-05462-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059527050&doi=10.1007%2fs00221-018-05462-2&partnerID=40&md5=551f79a4521fa4dc12a52c1dbe021d34","École de kinésiologie et des sciences de l’activité physique, Faculté de médecine, Université de Montréal, 2100, boul. Édouard-Montpetit, bureau 8225, Montreal, QC  H3T 1J4, Canada; Institut universitaire de gériatrie de Montréal, Université de Montréal, Montréal, QC, Canada","Lefrançois, C., École de kinésiologie et des sciences de l’activité physique, Faculté de médecine, Université de Montréal, 2100, boul. Édouard-Montpetit, bureau 8225, Montreal, QC  H3T 1J4, Canada; Messier, J., École de kinésiologie et des sciences de l’activité physique, Faculté de médecine, Université de Montréal, 2100, boul. Édouard-Montpetit, bureau 8225, Montreal, QC  H3T 1J4, Canada, Institut universitaire de gériatrie de Montréal, Université de Montréal, Montréal, QC, Canada","We explored visuomotor adaptation and spatial generalization of three-dimensional reaching movements performed in a virtual reality environment. We used a multiphase learning paradigm. First, subjects performed reaching movements to six targets without visual feedback (VF) (pre-exposure phase). Next, participants aimed at one target with veridical VF (baseline phase). Immediately after, they were required to adapt their movements to a triaxial visuomotor perturbation (horizontal, vertical, and sagittal translations) between actual hand motion and VF of hand motion in the virtual environment (learning phase). Finally, subjects aimed at the same targets as in the baseline (aftereffect) and pre-exposure phases (generalization) without VF (post-exposure phase). The results revealed spatial axis-dependent visuomotor adaptation capacities. First, subjects showed smaller intertrial variability along the horizontal compared to the sagittal and vertical axes during the baseline and learning phases. Second, although subjects were unaware of the visual distortion, they adapted their movements to each component of the triaxial perturbation. However, they showed reduced learning rate and less persistent adaptation (aftereffect) along the vertical than the horizontal and sagittal axes. Similarly, subjects transferred the newly learned visuomotor association to untrained regions of the workspace, but their average level of generalization was smaller along the vertical than the horizontal and sagittal axes. Collectively, our results suggest that adapting three-dimensional movements to a visual distortion involves distinct processes according to the specific sensorimotor integration demands of moving along each spatial axis. This finding supports the idea that the brain employs a modular decomposition strategy to simplify complex multidimensional visuomotor tasks. © 2019, Springer-Verlag GmbH Germany, part of Springer Nature.","Kinematic; Movement adaptation; Reaching movement; Spatial generalization; Virtual reality; Visuomotor perturbation","adult; article; brain; decomposition; human; learning; motion; publication; sensorimotor integration; virtual reality; visual feedback; adaptation; biomechanics; depth perception; motor activity; physiology; psychomotor performance; sensory feedback; virtual reality; vision; young adult; Adaptation, Physiological; Adult; Biomechanical Phenomena; Feedback, Sensory; Generalization (Psychology); Humans; Motor Activity; Psychomotor Performance; Space Perception; Virtual Reality; Visual Perception; Young Adult",Article,"Final","",Scopus,2-s2.0-85059527050
"Andreasen N.K., Baceviciute S., Pande P., Makransky G.","57210913825;55441702500;56534799500;50361371800;","Virtual reality instruction followed by enactment can increase procedural knowledge in a science lesson",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8797755,"840","841",,2,"10.1109/VR.2019.8797755","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071855895&doi=10.1109%2fVR.2019.8797755&partnerID=40&md5=33eb6d9b3fc921873229350ee2e8f972","Aalborg University, Denmark; University of Copenhagen, Denmark; Roskilde University, Denmark","Andreasen, N.K., Aalborg University, Denmark; Baceviciute, S., University of Copenhagen, Denmark; Pande, P., Roskilde University, Denmark; Makransky, G., Aalborg University, Denmark","A 2×2 between-subjects experiment (a) investigated and compared the instructional effectiveness of immersive virtual reality (VR) versus video as media for teaching scientific procedural knowledge, and (b) examined the efficacy of enactment as a generative learning strategy in combination with the respective instructional media. A total of 117 high school students (74 females) were randomly distributed across four instructional groups - VR and enactment, video and enactment, only VR, and only video. Outcome measures included declarative knowledge, procedural knowledge, knowledge transfer, and subjective ratings of perceived enjoyment. Results indicated that there were no main effects or interactions for the outcomes of declarative knowledge or transfer. However, there was a significant interaction between media and method for the outcome of procedural knowledge with the VR and enactment group having the highest performance. Furthermore, media also seemed to have a significant effect on student perceived enjoyment, indicating that the groups enjoyed the VR simulation significantly more than the video. The results deepen our understanding of how we learn with immersive technology, as well as suggest important implications for implementing VR in schools. © 2019 IEEE.","Enactment; Generative learning strategy; Learning; Procedural knowledge; Virtual reality","E-learning; Knowledge management; Learning systems; Virtual reality; Declarative knowledge; Enactment; Immersive technologies; Immersive virtual reality; Learning; Learning strategy; Procedural knowledge; Randomly distributed; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-85071855895
"Hoppe A.H., Marek F., Van De Camp F., Stietelhaqen R.","57195069885;57210910641;22235493700;57210914556;","VirtualTablet: Extending movable surfaces with touch interaction",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8797993,"980","981",,3,"10.1109/VR.2019.8797993","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071844187&doi=10.1109%2fVR.2019.8797993&partnerID=40&md5=e1432398a595971e51b267c0541e2f1a","Karlsruhe Institute of Technology (KIT) - IAR, Germany; Fraunhofer IOS8, Germany","Hoppe, A.H., Karlsruhe Institute of Technology (KIT) - IAR, Germany; Marek, F., Karlsruhe Institute of Technology (KIT) - IAR, Germany; Van De Camp, F., Fraunhofer IOS8, Germany; Stietelhaqen, R., Karlsruhe Institute of Technology (KIT) - IAR, Germany","Immersive output and effortless input are two core aspects of a virtual reality (VR) experience. We transfer ubiquitous touch interaction with haptic feedback into a virtual environment (VE). The movable and cheap real world object supplies an accurate touch detection equal to a ray-casting interaction with a controller. Moreover, the virtual tablet extends the functionality of a real world tablet. Additional information is displayed in mid-air around the touchable area and the tablet can be turned over to interact with both sides. It allows easy to learn and precise system interaction and can even augment the established touch metaphor with new paradigms. © 2019 IEEE.","Centered computing; Human; Human computer interaction (HCI); Interaction paradigms; Virtual reality","Rendering (computer graphics); User interfaces; Virtual reality; Centered computing; Haptic feedbacks; Human; Human computer interaction (HCI); Interaction paradigm; Real-world objects; System interactions; Touch interaction; Human computer interaction",Conference Paper,"Final","",Scopus,2-s2.0-85071844187
"Day B., Ebrahimi E., Hartman L.S., Pagano C.C., Robb A.C., Babu S.V.","55578106200;55868302600;56369773000;7005950745;55211963300;9039004700;","Examining the effects of altered avatars on perception-action in virtual reality",2019,"Journal of Experimental Psychology: Applied","25","1",,"1","24",,10,"10.1037/xap0000192","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055081790&doi=10.1037%2fxap0000192&partnerID=40&md5=d74d5faae21781732add1aad9ad044df","Department of Psychology, Butler University, United States; Department of Computer Science, University of North Carolina-Wilmington, United States; Department of Psychology, Clemson University, United States; School of Computing, Clemson University, United States","Day, B., Department of Psychology, Butler University, United States; Ebrahimi, E., Department of Computer Science, University of North Carolina-Wilmington, United States; Hartman, L.S., Department of Psychology, Clemson University, United States; Pagano, C.C., Department of Psychology, Clemson University, United States; Robb, A.C., School of Computing, Clemson University, United States; Babu, S.V., School of Computing, Clemson University, United States","In virtual reality (VR), avatars are graphical representations of people. Previous research highlights benefits of having a self-avatar when perceiving-acting while embedded in a virtual environment. We studied the effect that an altered avatar had on the perception of one's action capabilities. In Experiment 1, some participants acted with a normal, or faithful, avatar whereas another group of participants used an avatar with an extended arm, all in virtual reality. Experiment 2 utilized the same methodology and procedure as Experiment 1, except that only a calibration phase occurred in VR, whereas other phases were completed in the real world. All participants performed reaches to various distances presented visually. Results showed that calibration to altered dimensions of avatars is possible after receiving feedback while acting with the altered avatar. Calibration occurred more quickly when feedback was used to transition from a normal avatar to an altered avatar than when transitioning from the altered avatar back to the normal avatar without feedback. The implications of these findings for training in virtual reality simulations and for transfer to the real world are discussed, along with the implications for the concept of an embodied action schema. © 2018 American Psychological Association.","Action capabilities; Avatar; Calibration; Perception-action; Virtual reality","adolescent; computer interface; feedback system; female; human; male; movement (physiology); perception; physiology; virtual reality; Adolescent; Feedback; Female; Humans; Male; Movement; Perception; User-Computer Interface; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85055081790
"Huynh B., Orlosky J., Hollerer T.","57192544046;55641218100;8358959700;","In-situ labeling for augmented reality language learning",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8798358,"1606","1611",,2,"10.1109/VR.2019.8798358","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071876610&doi=10.1109%2fVR.2019.8798358&partnerID=40&md5=85211cef84f8fbe0b5cffddb75bffc83","University of California, Santa Barbara, United States; Osaka University, Japan","Huynh, B., University of California, Santa Barbara, United States; Orlosky, J., Osaka University, Japan; Hollerer, T., University of California, Santa Barbara, United States","Augmented Reality is a promising interaction paradigm for learning applications. It has the potential to improve learning outcomes by merging educational content with spatial cues and semantically relevant objects within a learner's everyday environment. The impact of such an interface could be comparable to the method of loci, a well known memory enhancement technique used by memory champions and polyglots. However, using Augmented Reality in this manner is still impractical for a number of reasons. Scalable object recognition and consistent labeling of objects is a significant challenge, and interaction with arbitrary (unmodeled) physical objects in AR scenes has consequently not been well explored. To help address these challenges, we present a framework for in-situ object labeling and selection in Augmented Reality, with a particular focus on language learning applications. Our framework uses a generalized object recognition model to identify objects in the world in real time, integrates eye tracking to facilitate selection and interaction within the interface, and incorporates a personalized learning model that dynamically adapts to student's growth. We show our current progress in the development of this system, including preliminary tests and benchmarks. We explore challenges with using such a system in practice, and discuss our vision for the future of AR language learning applications. © 2019 IEEE.","Centered computing; Human; Mixed and augmented reality; Semi; Supervised learning; Theory and algorithms for application domains","Augmented reality; Computation theory; Eye tracking; Genetic algorithms; Object recognition; Supervised learning; User interfaces; Virtual reality; Centered computing; Educational contents; Human; Interaction paradigm; Memory enhancement; Mixed and augmented realities; Personalized learning; Semi; Learning systems",Conference Paper,"Final","",Scopus,2-s2.0-85071876610
"Shen S., Chen H.-T., Leong T.W.","56157229100;7501615750;55234419400;","Training transfer of bimanual assembly tasks in cost-differentiated virtual reality systems",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8797917,"1152","1153",,1,"10.1109/VR.2019.8797917","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071837898&doi=10.1109%2fVR.2019.8797917&partnerID=40&md5=13e8c93f7df6294c0c8067b89ed781b6","School of Software University of Technology, Sydney, Australia","Shen, S., School of Software University of Technology, Sydney, Australia; Chen, H.-T., School of Software University of Technology, Sydney, Australia; Leong, T.W., School of Software University of Technology, Sydney, Australia","Recent advances of the affordable virtual reality headsets make virtual reality training an economical choice when compared to traditional training. However, these virtual reality devices present a range of different levels of virtual reality fidelity and interactions. Few works have evaluated their validity against the traditional training formats. This paper presents a study that compares the learning efficiency of a bimanual gearbox assembly task among traditional training, virtual reality training with direct 3D inputs (HTC VIVE), and virtual reality training without 3D inputs (Google Cardboard). A pilot study was conducted and the result shows that HTC VIVE brings the best learning outcomes. © 2019 IEEE.","Assistive systems; Head; Learning transfer; Mounted display; Virtual reality","User interfaces; Virtual reality; Assistive system; Head; Learning efficiency; Learning Transfer; Virtual reality devices; Virtual reality system; Virtual reality training; Virtual-reality headsets; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85071837898
"Bialkova S., Dickhoff B.","36247103900;57210915943;","Encouraging rehabilitation trials: The potential of 360° immersive instruction videos",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8797805,"1443","1447",,,"10.1109/VR.2019.8797805","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071832880&doi=10.1109%2fVR.2019.8797805&partnerID=40&md5=d7ce467e61a2a59195ec7197703c62de","Utrecht University, Netherlands; Saxion University of Applied Sciences, Netherlands","Bialkova, S., Utrecht University, Netherlands; Dickhoff, B., Saxion University of Applied Sciences, Netherlands","Despite the rapid growth of the VR/AR/ XR applications in the health-care sector, enhancing health and well-being with innovative technologies often is a challenge. Part of the challenge is the limited knowledge transfer between the healthcare, technology, the patients demands, and how these demands could be appropriately met. The current study addressed this challenge when exploring the potential of 360° immersive instruction videos in encouraging rehabilitation trials. A professional VR/ video maker studio created the video for the purpose of the current research. A rehabilitation therapist was recorded while performing rehabilitation exercise as it is done in the real life practice. Patients currently in various rehabilitation trials (motor vs. cardiovascular) were exposed to the 360° immersive instruction video. Their experience was compared with the control group, i.e. healthy people. The VR experience and the rehabilitation exercise experience were evaluated as measures of the Virtual Reality Rehabilitation (VRR) impact. Results showed that 360° immersive videos engaged patients well, irrespective of the rehabilitation trial they are currently in. Regression modelling further demonstrated that the more people liked the VR experience, the more they enjoyed the rehabilitation activity. The more the rehabilitation activity was enjoyed, the more people were satisfied with the VRR. Current outcomes are discussed in the framework of a model of VRR impact, which is a solid base for long-term exercise adherence. The model could be implemented to successfully develop immersive instructional videos as efficient tools in the course of physical rehabilitation trials, and thus, to enhance health and well-being. © 2019 IEEE.","360 videos; Patients engagement; Virtual reality rehabilitation","Health care; Knowledge management; User interfaces; Virtual reality; 360 videos; Innovative technology; Instructional videos; Patients engagement; Physical rehabilitation; Regression modelling; Rehabilitation activities; Rehabilitation exercise; Patient rehabilitation",Conference Paper,"Final","",Scopus,2-s2.0-85071832880
"Schirm J.","57210919413;","Case-studies of contemporary presence theory: Towards more objective and reliable measures of presence",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8798203,"1363","1364",,1,"10.1109/VR.2019.8798203","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071868739&doi=10.1109%2fVR.2019.8798203&partnerID=40&md5=de4e40fcdbef031db14d738b4716aa0a","Sheffield Hallam University, United Kingdom; Reutlingen University, Germany","Schirm, J., Sheffield Hallam University, United Kingdom, Reutlingen University, Germany","A large body of literature is concerned with models of presence-The sensory illusion of being part of a virtual scene-but there is still no general agreement on how to measure it in an objective and reliable way. When it comes to virtual reality, presence is often considered as one of the main factors contributing to quality of experience, yet existing methods either rely on subjective assessments of users or on specifics of the virtual environment they are applied in, making it difficult for experimental procedures to be generalized. This paper presents ideas for research into promising measures of presence, based on first experiments with novel behavioral measures inside a rich environment which users can feel present in more naturally. © 2019 IEEE.","Centered computing; Centered computing; HCI design and evaluation methods; Human; Human; Human computer interaction (HCI); Human computer interaction (HCI); Interaction paradigms; User studies; Virtual reality","Computation theory; Human computer interaction; Quality of service; User interfaces; Centered computing; HCI design; Human; Human computer interaction (HCI); Interaction paradigm; User study; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85071868739
"Danieau F., Gubins I., Olivier N., Dumas O., Denis B., Lopez T., Mollet N., Frager B., Avril Q.","37057062300;57210915853;57210919806;57163193100;57210918555;7103065998;24481532200;57210914421;38662147000;","Automatic generation and stylization of 3d facial rigs",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8798208,"784","792",,1,"10.1109/VR.2019.8798208","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071882939&doi=10.1109%2fVR.2019.8798208&partnerID=40&md5=f362bc829724f056f31ddb2b21e43cad","Technicolor, France; Utrecht University, Netherlands; ESIR, France; Technicolor Experience Center, United States","Danieau, F., Technicolor, France; Gubins, I., Utrecht University, Netherlands; Olivier, N., ESIR, France; Dumas, O., Technicolor, France; Denis, B., Technicolor, France; Lopez, T., Technicolor, France; Mollet, N., Technicolor, France; Frager, B., Technicolor Experience Center, United States; Avril, Q., Technicolor, France","In this paper, we present a fully automatic pipeline for generating and stylizing high geometric and textural quality facial rigs. They are automatically rigged with facial blendshapes for animation, and can be used across platforms for applications including virtual reality, augmented reality, remote collaboration, gaming and more. From a set of input facial photos, our approach is to be able to create a photorealistic, fully rigged character in less than seven minutes. The facial mesh reconstruction is based on state-of-The art photogrammetry approaches. Automatic landmarking coupled with ICP registration with regularization provide direct correspondence and registration from a given generic mesh to the acquired facial mesh. Then, using deformation transfer, existing blendshapes are transferred from the generic to the reconstructed facial mesh. The reconstructed face is then fit to the full body generic mesh. Extra geometry such as jaws, teeth and nostrils are retargeted and transferred to the character. An automatic iris color extraction algorithm is performed to colorize a separate eye texture, animated with dynamic UVs. Finally, an extra step applies a style to the photorealis-tic face to enable blending of personalized facial features into any other character. The user's face can then be adapted to any human or non-human generic mesh. A pilot user study was performed to evaluate the utility of our approach. Up to 65% of the participants were successfully able to discern the presence of one's unique facial features when the style was not too far from a humanoid shape. © 2019 IEEE.","Animation; Character; Pipeline; Virtual reality","Animation; Augmented reality; Blending; Mesh generation; Pipelines; Textures; Virtual reality; Automatic Generation; Automatic landmarking; Character; Color extraction; Deformation transfer; Mesh reconstruction; Remote collaboration; Textural quality; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-85071882939
"Wälti M.J., Woolley D.G., Wenderoth N.","57208053401;11839714300;57206162402;","Reinstating verbal memories with virtual contexts: Myth or reality?",2019,"PLoS ONE","14","3", e0214540,"","",,4,"10.1371/journal.pone.0214540","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063680448&doi=10.1371%2fjournal.pone.0214540&partnerID=40&md5=cc683e6cb6fa67ee6cb942a63665b850","Department of Health Sciences and Technology, ETH Zurich, Zurich, Switzerland; Neuroscience Center Zurich (ZNZ), University and ETH Zurich, Zurich, Switzerland","Wälti, M.J., Department of Health Sciences and Technology, ETH Zurich, Zurich, Switzerland, Neuroscience Center Zurich (ZNZ), University and ETH Zurich, Zurich, Switzerland; Woolley, D.G., Department of Health Sciences and Technology, ETH Zurich, Zurich, Switzerland; Wenderoth, N., Department of Health Sciences and Technology, ETH Zurich, Zurich, Switzerland, Neuroscience Center Zurich (ZNZ), University and ETH Zurich, Zurich, Switzerland","When learning new information, contextual information about the encoding situation is stored in addition to the focal memory content. Later, these strings of extra information can help retrieve the learned content as demonstrated by experiments where contextual cues from an encoding situation facilitate remembering and improve memory performance when reinstated during retrieval. This context-dependent memory effect has been investigated over the course of several decades and has been demonstrated with many different types of contexts. Based on this, the widely held belief is that context-dependent memory is a strong and robust effect, with transferable substance for everyday learning and potential clinical applications. Here we report the results of a multi-study design investigating the influence of reinstated visual contexts on memory performance. Data from 120 participants were included in three studies comprising a variety of visual cues. We show convincingly that even rich, salient and fully surrounding visual contexts provided by virtual reality are not sufficient to induce effects of context-dependency in a free recall memory task. We also investigated contextual modulation of oscillatory brain activity in order to test the effect of reinstated neural contexts, which failed to evoke a robust effect when re-tested in an internal conceptual replication study. Moreover, a Bayesian sequential statistical analysis revealed moderate to strong evidence against the hypothesis that reinstatement of visual contexts benefits free recall memory tasks indicating that effects are small and may not be suitable for transfer into everyday learning. © 2019 Wälti et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"adult; article; context-dependent memory; female; human; human experiment; learning; major clinical study; male; modulation; replication study; statistical analysis; verbal memory; virtual reality; association; brain; physiology; recall; vision; young adult; Brain; Cues; Female; Humans; Male; Mental Recall; Visual Perception; Young Adult",Article,"Final","",Scopus,2-s2.0-85063680448
"Mayer R.E.","7403065717;","Thirty years of research on online learning",2019,"Applied Cognitive Psychology","33","2",,"152","159",,29,"10.1002/acp.3482","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056195613&doi=10.1002%2facp.3482&partnerID=40&md5=3ede938104f084edb5cb91a233a368e8","Department of Psychological and Brain Sciences, University of California, Santa Barbara, CA, United States","Mayer, R.E., Department of Psychological and Brain Sciences, University of California, Santa Barbara, CA, United States","This paper presents a personal account of developments in research on online learning over the past 30 years. Research on how to design online instruction represents an example of applying the science of learning to education. It contributes to the science of learning (as exemplified by developments in cognitive load theory, the cognitive theory of multimedia learning, and incorporating metacognitive, motivational, and affective aspects of learning), the science of instruction (as exemplified by the continuing development of research-based principles of instructional design), and the science of assessment (as exemplified by supplementing self-report surveys and retention tests with multilevel transfer tests, log file data during learning, and cognitive neuroscience measures of cognitive processing during learning). Some recurring themes are that learning is caused by instructional methods rather than instructional media, so research should focus on features that are uniquely afforded by digital learning environments; instructional practice should be grounded in rigorous and systematic research, including value-added experiments aimed at pinpointing the active ingredients in online instruction; research in online learning should identify boundary conditions under which instructional techniques are most effective; and research in online learning should test and contribute to learning theory. © 2018 John Wiley & Sons, Ltd.","digital learning; instructional design; multimedia learning; online learning; science of learning","art; Article; behavior; behavior change; clinical assessment; comparative study; computer graphics; dynamics; education; electrocorticography; evidence based practice center; evolutionary adaptation; facial expression; financial management; functional magnetic resonance imaging; game; health care survey; human; information processing; knowledge; learning; long term memory; mathematical analysis; methodology; mild cognitive impairment; multilevel analysis; neuroscience; priority journal; psychology; research; science; sensory memory; simulation; suspended animation; technology; working memory",Article,"Final","",Scopus,2-s2.0-85056195613
"Ju U., Kang J., Wallraven C.","56316712000;56399690100;6507395861;","To brake or not to brake? Personality traits predict decision-making in an accident situation",2019,"Frontiers in Psychology","10","FEB", 134,"","",,6,"10.3389/fpsyg.2019.00134","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061043915&doi=10.3389%2ffpsyg.2019.00134&partnerID=40&md5=82eae33b00b4fc0b93f19e3bf11ceb65","Department of Brain and Cognitive Engineering, Cognitive Systems Lab, Korea University, Seoul, South Korea; Department of Biomedical Science, Interdisciplinary Affective Neuroscience Lab, Korea University, Seoul, South Korea; Empathy Research Institute, Goyang, South Korea","Ju, U., Department of Brain and Cognitive Engineering, Cognitive Systems Lab, Korea University, Seoul, South Korea; Kang, J., Department of Biomedical Science, Interdisciplinary Affective Neuroscience Lab, Korea University, Seoul, South Korea, Empathy Research Institute, Goyang, South Korea; Wallraven, C., Department of Brain and Cognitive Engineering, Cognitive Systems Lab, Korea University, Seoul, South Korea","Many situations require decisions to be made in very little time-in emergency or accident situations such decisions will carry potentially harmful consequences. Can we predict how people react in such situations from their personality traits alone? Since experimental tests of accident situations are not possible in the real world, existing studies usually employ text-based surveys or post-situation assessments, making predictions and generalization difficult. In the present study, we used virtual reality to create a more life-like situation in order to study decision-making under controlled circumstances. In our experiment, participants trained in an immersive car simulation to complete a race-course as fast as possible. In the testing phase, pedestrians appeared on the course without warning, forcing participants to react. The experiment used a one-shot design to avoid pre-meditation and to test naïve, rapid decision-making. Participants' reactions could be classified into two categories: people who tried to brake, and people who potentially endangered pedestrians by not braking or conducting hazardous evasion maneuvers. Importantly, this latter group of participants scored significantly higher on psychopathy-related traits among a set of personality-related factors. Additional personality factors, as well as age, gender, gaming expertise, and driving experience did not significantly influence participants' decision-making. This result was true for both a Korean sample (N = 94) and an independently-tested German sample (N = 94), indicating cross-cultural stability of the results. Overall, our results demonstrate that decision-making in an extreme, simulated accident situation is critically influenced by personality traits. © 2019 Ju, Kang and Wallraven.","Accident situation; Decision-making; Driving; Personality; Psychopathy; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85061043915
"Nelson C., Wunsche B.C.","57199851783;6602216444;","A Low-Spec Extendable GPU-Based Audio Library",2019,"International Conference Image and Vision Computing New Zealand","2018-November",, 8634764,"","",,1,"10.1109/IVCNZ.2018.8634764","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062805330&doi=10.1109%2fIVCNZ.2018.8634764&partnerID=40&md5=2b3a7f33c5eaed4c5bed772586b07309","Department of Computer Science, Boston University, Boston, MA, United States; Department of Computer Science, University of Auckland, Auckland, New Zealand","Nelson, C., Department of Computer Science, Boston University, Boston, MA, United States; Wunsche, B.C., Department of Computer Science, University of Auckland, Auckland, New Zealand","Sound is an essential entity for creating realistic immersive virtual environments in applications such as computer games, health psychology, and scientific visualisation. Current multimedia libraries offer many tools for processing and synthesising sound but are usually executed on the CPU and/or suffer from vendor lock-in. In this paper we present a novel low-spec GPU implementation of an audio library. Preliminary studies suggest that the implementation improves speed by an order of magnitude compared to a CPU implementation. Furthermore a GPU-based implementation frees valuable resources on the CPU for other applications and it is ideal for applications where sounds and graphics are integrated and hence can be both executed on the GPU without requiring expensive data transfer between main memory and the graphics card. © 2018 IEEE.","audio analysis; audio libraries; GPGPU; graphics hardware; music synthesis; sound rendering","Audio acoustics; Computer games; Computer graphics equipment; Data transfer; Libraries; Program processors; Virtual reality; Audio analysis; GPGPU; Graphics hardware; Music synthesis; Sound rendering; Graphics processing unit",Conference Paper,"Final","",Scopus,2-s2.0-85062805330
"Mertens G., Wagensveld P., Engelhard I.M.","56642504800;57204568011;6701593489;","Cue conditioning using a virtual spider discriminates between high and low spider fearful individuals",2019,"Computers in Human Behavior","91",,,"192","200",,4,"10.1016/j.chb.2018.10.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056172525&doi=10.1016%2fj.chb.2018.10.006&partnerID=40&md5=01119daeb39d2e59e0cf4f30d5d0e9d1","Department of Clinical Psychology, Utrecht University, Utrecht, Netherlands","Mertens, G., Department of Clinical Psychology, Utrecht University, Utrecht, Netherlands; Wagensveld, P., Department of Clinical Psychology, Utrecht University, Utrecht, Netherlands; Engelhard, I.M., Department of Clinical Psychology, Utrecht University, Utrecht, Netherlands","The fear conditioning paradigm is one of the most commonly used procedures to examine the etiology and treatment of anxiety disorders in laboratories. However, findings with this procedure often do not generalize to clinical settings. Virtual reality (VR) is a promising tool for improving the ecological and predictive validity of fear conditioning. The current study explored whether a classical differential cue conditioning paradigm with spider-fearful participants can be conducted in a VR-environment. Specifically, 25 spider-fearful and 25 non-fearful female students participated in a fear-conditioning experiment with a virtual spider as an unconditioned stimulus (US). The experiment took place in a virtual office in which participants viewed an avatar of themselves sitting at a desk. Conditioned stimuli (CS) were a blue (CS+; 100% reinforcement) and a green (CS-) light emitted by a desk lamp. Fear reactions were measured by fear ratings, skin conductance responses (SCR), and fear potentiated startle responses (FPS). Our results indicated stronger differential fear conditioning for spider-fearful participants than for non-fearful participants. Furthermore, we demonstrate that these results relate specifically to spider-fear, and not to general trait anxiety. We conclude that fear conditioning in VR is a promising tool to improve the validity of classical fear conditioning procedures. © 2018 Elsevier Ltd","Acquisition; Extinction; Fear conditioning; Spider-related fear; Virtual reality","Light extinction; Mobile computing; Acquisition; Clinical settings; Female students; Skin conductance response; Spider-related fear; Virtual office; Virtual reality; adult; anxiety; article; clinical article; controlled study; electrodermal response; fear conditioning test; female; human; nonhuman; reinforcement; spider; startle reflex; stimulus; student; validity; virtual reality",Article,"Final","",Scopus,2-s2.0-85056172525
"Bigras C., Kairy D., Archambault P.S.","57205472507;6508266422;55328034600;","Augmented feedback for powered wheelchair training in a virtual environment",2019,"Journal of NeuroEngineering and Rehabilitation","16","1", 12,"","",,1,"10.1186/s12984-019-0482-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060140090&doi=10.1186%2fs12984-019-0482-3&partnerID=40&md5=10900dea4a41979a17573bc46e311771","Integrated Program in Neuroscience, McGill University, Montreal, Canada; Interdisciplinary Research Center in Rehabilitation (CRIR), Montreal, Canada; École de Réadaptation, Faculté de Médecine, Université de Montréal, Montreal, Canada; School of Physical and Occupational Therapy, McGill University, Montreal, Canada","Bigras, C., Integrated Program in Neuroscience, McGill University, Montreal, Canada, Interdisciplinary Research Center in Rehabilitation (CRIR), Montreal, Canada; Kairy, D., École de Réadaptation, Faculté de Médecine, Université de Montréal, Montreal, Canada; Archambault, P.S., Interdisciplinary Research Center in Rehabilitation (CRIR), Montreal, Canada, School of Physical and Occupational Therapy, McGill University, Montreal, Canada","Background: Powered wheelchair (PW) driving is a complex activity and requires the acquisition of several skills. Given the risks involved with PW use, safe and effective training methods are needed. Virtual reality training allows users to practice difficult tasks in a safe environment. An additional benefit is that augmented feedback can be provided to optimize learning. The purpose of this study was to investigate whether providing augmented feedback during powered wheelchair simulator training results in superior performance, and whether skills learned in a virtual environment transfer to real PW driving. Methods: Forty healthy young adults were randomly allocated to two groups: one received augmented feedback during simulator training while the control group received no augmented feedback. PW driving performance was assessed at baseline in both the real and virtual environment (RE and VE), after training in VE and two days later in VE and RE (retention and transfer tests). Results: Both groups showed significantly better task completion time and number of collisions in the VE after training and these results were maintained two days later. The transfer test indicated better performance in the RE compared to baseline for both groups. Because time and collisions interact, a post-hoc 2D Kolmogonov-Smirnov test was used to investigate the differences in the speed-accuracy distributions for each group; a significant difference was found for the group receiving augmented feedback, before and after training, whereas the difference was not significant for the control group. There were no differences at the retention test, suggesting that augmented feedback was most effective during and immediately after training. Conclusions: PW simulator training is effective in improving task completion time and number of collisions. A small effect of augmented feedback was seen when looking at differences in the speed-accuracy distributions, highlighting the importance of accounting for the speed-accuracy tradeoff for PW driving. © 2019 The Author(s).","Augmented feedback; Powered wheelchair; Training; Virtual reality","adult; Article; environmental factor; feedback system; human; human experiment; information technology; Kolmogorov Smirnov test; measurement accuracy; normal human; priority journal; retention time; skill; training; velocity; virtual reality; computer interface; computer simulation; controlled study; feedback system; female; male; physiology; procedures; psychomotor performance; randomized controlled trial; simulation training; wheelchair; young adult; Computer Simulation; Feedback; Female; Humans; Male; Psychomotor Performance; Simulation Training; User-Computer Interface; Virtual Reality; Wheelchairs; Young Adult",Article,"Final","",Scopus,2-s2.0-85060140090
"Geronazzo M., Sikstrom E., Kleimola J., Avanzini F., De Gotzen A., Serafin S.","36720522500;55354784700;24829233900;7005300654;24724148200;6603367536;","The Impact of an Accurate Vertical Localization with HRTFs on Short Explorations of Immersive Virtual Reality Scenarios",2019,"Proceedings of the 2018 IEEE International Symposium on Mixed and Augmented Reality, ISMAR 2018",,, 8613754,"90","97",,8,"10.1109/ISMAR.2018.00034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062179431&doi=10.1109%2fISMAR.2018.00034&partnerID=40&md5=5a0b7c6c5270986682096e1aad3ed439","Dept. of Architecture, Design and Media Technology, Aalborg University, Denmark; Virsabi ApS, Denmark; Hefio Ltd, Denmark; Dept. of Computer Science, University of Milano, Italy","Geronazzo, M., Dept. of Architecture, Design and Media Technology, Aalborg University, Denmark; Sikstrom, E., Virsabi ApS, Denmark; Kleimola, J., Hefio Ltd, Denmark; Avanzini, F., Dept. of Computer Science, University of Milano, Italy; De Gotzen, A., Dept. of Architecture, Design and Media Technology, Aalborg University, Denmark; Serafin, S., Dept. of Architecture, Design and Media Technology, Aalborg University, Denmark","Achieving a full 3D auditory experience with head-related transfer functions (HRTFs) is still one of the main challenges of spatial audio rendering. HRTFs capture the listener's acoustic effects and personal perception, allowing immersion in virtual reality (VR) applications. This paper aims to investigate the connection between listener sensitivity in vertical localization cues and experienced presence, spatial audio quality, and attention. Two VR experiments with head-mounted display (HMD) and animated visual avatar are proposed: (i) a screening test aiming to evaluate the participants' localization performance with HRTFs for a non-visible spatialized audio source, and (ii) a 2 minute free exploration of a VR scene with five audiovisual sources in a both non-spatialized (2D stereo panning) and spatialized (free-field HRTF rendering) listening conditions. The screening test allows a distinction between good and bad localizers. The second one shows that no biases are introduced in the quality of the experience (QoE) due to different audio rendering methods; more interestingly, good localizers perceive a lower audio latency and they are less involved in the visual aspects. © 2018 IEEE.","Auditory feedback; Human-centered computing; Interaction devices; Interaction paradigms; Interaction techniques; Sound-based input / output Human-centered computing; Virtual reality; Human-centered computing","Augmented reality; Helmet mounted displays; Three dimensional computer graphics; Transfer functions; Virtual reality; Auditory feedback; Human-centered computing; Input/output; Interaction devices; Interaction paradigm; Interaction techniques; Sound reproduction",Conference Paper,"Final","",Scopus,2-s2.0-85062179431
"Hofmann S.M., Klotzsche F., Mariola A., Nikulin V.V., Villringer A., Gaebler M.","57203966872;57203973247;57203969187;7007084310;7007157177;55551073400;","Decoding subjective emotional arousal during a naturalistic VR experience from EEG using LSTMs",2019,"Proceedings - 2018 IEEE International Conference on Artificial Intelligence and Virtual Reality, AIVR 2018",,, 8613645,"128","131",,5,"10.1109/AIVR.2018.00026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062183906&doi=10.1109%2fAIVR.2018.00026&partnerID=40&md5=1ac742f01e79eb17010913730181993a","Amsterdam Brain and Cognition, University of Amsterdam, Amsterdam, Netherlands; Berlin School of Mind and Brain, Humboldt Universität zu Berlin, Berlin, Germany; Sussex Neuroscience, University of Sussex, Sussex, United Kingdom; Neurology, MPI Hum. Cog. and Brain Sci., Leipzig, Germany","Hofmann, S.M., Amsterdam Brain and Cognition, University of Amsterdam, Amsterdam, Netherlands; Klotzsche, F., Berlin School of Mind and Brain, Humboldt Universität zu Berlin, Berlin, Germany; Mariola, A., Sussex Neuroscience, University of Sussex, Sussex, United Kingdom; Nikulin, V.V., Neurology, MPI Hum. Cog. and Brain Sci., Leipzig, Germany; Villringer, A., Neurology, MPI Hum. Cog. and Brain Sci., Leipzig, Germany; Gaebler, M., Neurology, MPI Hum. Cog. and Brain Sci., Leipzig, Germany","Emotional arousal (EA) denotes a heightened state of activation that has both subjective and physiological aspects. The neurophysiology of subjective EA, among other mind-brain-body phenomena, can best be tested when subjects are stimulated in a natural fashion. Immersive virtual reality (VR) enables naturalistic experimental stimulation and thus promises to increase the ecological validity of research findings i.e., how well they generalize to real-life settings. In this study, 45 participants experienced virtual rollercoaster rides while their brain activity was recorded using electroencephalography (EEG). A Long Short-Term Memory (LSTM) recurrent neural network (RNN) was then trained on the alpha-frequency (8-12 Hz) component of the EEG signal (input) and the retrospectively acquired continuous reports of subjective EA (target). With the LSTM-based model, subjective EA could be predicted significantly above chance level. This demonstrates a novel EEG-based decoding approach for subjective states of experience in naturalistic research designs using VR. © 2018 IEEE.","Continuous time series; Emotional arousal; Naturalistic research designs; Neural decoding; Subjective experience","Brain; Continuous time systems; Decoding; Electrophysiology; Long short-term memory; Neurophysiology; Virtual reality; Well stimulation; Continuous-time; Emotional arousal; Neural decoding; Research designs; Subjective experiences; Electroencephalography",Conference Paper,"Final","",Scopus,2-s2.0-85062183906
"Quadrado V.H., Silva T.D.D., Favero F.M., Tonks J., Massetti T., Monteiro C.B.D.M.","55550627100;55546962700;36113108600;16679895300;55546122700;55481862300;","Motor learning from virtual reality to natural environments in individuals with Duchenne muscular dystrophy",2019,"Disability and Rehabilitation: Assistive Technology","14","1",,"12","20",,6,"10.1080/17483107.2017.1389998","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033687758&doi=10.1080%2f17483107.2017.1389998&partnerID=40&md5=8a11d47532816e529ffcc1dda607c6ab","Department of Physical Therapy, Speech and Occupational Therapy, University of São Paulo, São Paulo, Brazil; School of Arts, Sciences and Humanities, University of São Paulo, São Paulo, Brazil; University of Exeter Medical School, Exeter, United Kingdom; Haven Clinical Psychology Practice, Cornwall, United Kingdom","Quadrado, V.H., Department of Physical Therapy, Speech and Occupational Therapy, University of São Paulo, São Paulo, Brazil; Silva, T.D.D., School of Arts, Sciences and Humanities, University of São Paulo, São Paulo, Brazil; Favero, F.M., School of Arts, Sciences and Humanities, University of São Paulo, São Paulo, Brazil; Tonks, J., University of Exeter Medical School, Exeter, United Kingdom, Haven Clinical Psychology Practice, Cornwall, United Kingdom; Massetti, T., Department of Physical Therapy, Speech and Occupational Therapy, University of São Paulo, São Paulo, Brazil; Monteiro, C.B.D.M., Department of Physical Therapy, Speech and Occupational Therapy, University of São Paulo, São Paulo, Brazil, School of Arts, Sciences and Humanities, University of São Paulo, São Paulo, Brazil","Purpose: To examine whether performance improvements in the virtual environment generalize to the natural environment. Study design: we had 64 individuals, 32 of which were individuals with DMD and 32 were typically developing individuals. Methods: The groups practiced two coincidence timing tasks. In the more tangible button-press task, the individuals were required to ‘intercept’ a falling virtual object at the moment it reached the interception point by pressing a key on the computer. In the more abstract task, they were instructed to ‘intercept’ the virtual object by making a hand movement in a virtual environment using a webcam. Results and Conclusions: For individuals with DMD, conducting a coincidence timing task in a virtual environment facilitated transfer to the real environment. However, we emphasize that a task practiced in a virtual environment should have higher rates of difficulties than a task practiced in a real environment.IMPLICATIONS FOR REHABILITATION Virtual environments can be used to promote improved performance in ?real-world? environments. Virtual environments offer the opportunity to create paradigms similar ?real-life? tasks, however task complexity and difficulty levels can be manipulated, graded and enhanced to increase likelihood of success in transfer of learning and performance. Individuals with DMD, in particular, showed immediate performance benefits after using virtual reality. © 2017, © 2017 Informa UK Limited, trading as Taylor & Francis Group.","computer-assisted technology; Duchenne muscular dystrophy; motor learning; timing coincident; virtual reality","adult; case control study; computer interface; Duchenne muscular dystrophy; human; male; motor performance; pathophysiology; physiology; task performance; virtual reality exposure therapy; Adult; Case-Control Studies; Humans; Male; Motor Skills; Muscular Dystrophy, Duchenne; Task Performance and Analysis; User-Computer Interface; Virtual Reality Exposure Therapy",Article,"Final","",Scopus,2-s2.0-85033687758
"Boyce M.W., Rowan C.P., Shorter P.L., Moss J.D., Amburn C.R., Garneau C.J., Sottilare R.A.","57189320664;51564868300;57204817713;24332598600;55391888100;24341035700;6506196843;","The impact of surface projection on military tactics comprehension",2019,"Military Psychology","31","1",,"45","59",,4,"10.1080/08995605.2018.1529487","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057323107&doi=10.1080%2f08995605.2018.1529487&partnerID=40&md5=feb5b6c8776f21becab5cc98fa94ee9d","Human Research and Engineering Directorate, US Army Research Laboratory, Orlando, FL, United States; Department of Behavioral Sciences and Leadership, United States Military Academy at West Point, West Point, NY, United States","Boyce, M.W., Human Research and Engineering Directorate, US Army Research Laboratory, Orlando, FL, United States; Rowan, C.P., Department of Behavioral Sciences and Leadership, United States Military Academy at West Point, West Point, NY, United States; Shorter, P.L., Human Research and Engineering Directorate, US Army Research Laboratory, Orlando, FL, United States; Moss, J.D., Human Research and Engineering Directorate, US Army Research Laboratory, Orlando, FL, United States; Amburn, C.R., Human Research and Engineering Directorate, US Army Research Laboratory, Orlando, FL, United States; Garneau, C.J., Human Research and Engineering Directorate, US Army Research Laboratory, Orlando, FL, United States; Sottilare, R.A., Human Research and Engineering Directorate, US Army Research Laboratory, Orlando, FL, United States","This experiment assessed how displaying information onto different surfaces (flat vs. raised) influenced the performance, workload, and engagement of cadets answering questions on military tactics. Sixty-two cadets in a within-subjects design each answered 24 tactics-related questions across 2 conditions (12 on flat, 12 on raised) which were measured by accuracy and time on task. After each set of 12 questions, the cadets took postsurveys assessing engagement, measured by a modified User Engagement Scale and the System Usability Scale, and workload measured by the NASA-TLX. Findings indicated that raised terrain surface led to reduced workload and increased engagement and time on task as compared to the flat terrain surface. A practice effect drove performance metrics (time on task and accuracy), where the learner performed better on the second surface type displayed. This research contributes to expanding the literature base that supports alternative display methods to increase engagement and augment instruction of military tactics tasks. © 2019, © 2019 Society for Military Psychology Division 19 of the American Psychological Association.","Augmented reality sandtable (ARES); generalized intelligent framework for tutoring (GIFT); military tactics; terrain; United States military academy (USMA)","adult; army; article; comprehension; female; human; human experiment; major clinical study; male; United States; workload",Article,"Final","",Scopus,2-s2.0-85057323107
"Qin Z., Tai Y., Xia C., Peng J., Huang X., Chen Z., Li Q., Shi J.","57197755201;36984437500;57205556936;57214109873;18436902100;36633870500;55911980700;8640031700;","Towards Virtual VATS, Face, and Construct Evaluation for Peg Transfer Training of Box, VR, AR, and MR Trainer",2019,"Journal of Healthcare Engineering","2019",, 6813719,"","",,4,"10.1155/2019/6813719","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060519204&doi=10.1155%2f2019%2f6813719&partnerID=40&md5=3f4666c758e681e13ee471dd0a467665","Yunnan Key Laboratory of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, 650000, China; Department of Thoracic Surgery, Yunnan First People's Hospital, Kunming, 650000, China","Qin, Z., Yunnan Key Laboratory of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, 650000, China; Tai, Y., Yunnan Key Laboratory of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, 650000, China; Xia, C., Yunnan Key Laboratory of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, 650000, China; Peng, J., Department of Thoracic Surgery, Yunnan First People's Hospital, Kunming, 650000, China; Huang, X., Yunnan Key Laboratory of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, 650000, China; Chen, Z., Yunnan Key Laboratory of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, 650000, China; Li, Q., Yunnan Key Laboratory of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, 650000, China; Shi, J., Yunnan Key Laboratory of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, 650000, China","The aim of this study is to develop and assess the peg transfer training module face, content and construct validation use of the box, virtual reality (VR), cognitive virtual reality (CVR), augmented reality (AR), and mixed reality (MR) trainer, thereby to compare advantages and disadvantages of these simulators. Training system (VatsSim-XR) design includes customized haptic-enabled thoracoscopic instruments, virtual reality helmet set, endoscope kit with navigation, and the patient-specific corresponding training environment. A cohort of 32 trainees comprising 24 novices and 8 experts underwent the real and virtual simulators that were conducted in the department of thoracic surgery of Yunnan First People's Hospital. Both subjective and objective evaluations have been developed to explore the visual and haptic potential promotions in peg transfer education. Experiments and evaluation results conducted by both professional and novice thoracic surgeons show that the surgery skills from experts are better than novices overall, AR trainer is able to provide a more balanced training environments on visuohaptic fidelity and accuracy, box trainer and MR trainer demonstrated the best realism 3D perception and surgical immersive performance, respectively, and CVR trainer shows a better clinic effect that the traditional VR trainer. Combining these in a systematic approach, tuned with specific fidelity requirements, medical simulation systems would be able to provide a more immersive and effective training environment. © 2019 Zhibao Qin et al.",,"Augmented reality; E-learning; Mixed reality; Transplantation (surgical); Evaluation results; Medical simulations; Patient specific; Subjective and objective evaluations; Thoracic surgery; Training modules; Training Systems; Virtual simulators; Surgical equipment; adult; Article; augmented reality; construct validity; facial recognition; female; human; intermethod comparison; male; medical education; mixed reality; postgraduate student; simulation training; skill; thoracic surgeon; video assisted thoracoscopic surgery; virtual reality; clinical competence; comparative study; computer interface; computer simulation; education; lung tumor; middle aged; procedures; software; teaching; video assisted thoracoscopic surgery; virtual reality; young adult; Adult; Augmented Reality; Clinical Competence; Computer Simulation; Computer-Assisted Instruction; Female; Humans; Lung Neoplasms; Male; Middle Aged; Software; Thoracic Surgery, Video-Assisted; User-Computer Interface; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85060519204
"Schiavon M., Keber M., Cossutta A., Zini A., Jez M., Ambrosio L.","57211568046;23008588000;57211567113;55332827800;56081909900;56865597700;","Virtual reality in shipbuilding: Three use cases in a cruise ship design process",2019,"RINA, Royal Institution of Naval Architects - 19th International Conference on Computer Applications in Shipbuilding, ICCAS 2019","1",,,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074450034&partnerID=40&md5=842897b25714bc524d05ebe39d5ae178","Fincantieri S.p.A, Italy; Fincantieri Oil and Gas S.p.A., Italy; CETENA S.p.A., Italy; Arsenal S.r.l., Italy","Schiavon, M., Fincantieri S.p.A, Italy; Keber, M., Fincantieri Oil and Gas S.p.A., Italy; Cossutta, A., Fincantieri S.p.A, Italy; Zini, A., CETENA S.p.A., Italy; Jez, M., Arsenal S.r.l., Italy; Ambrosio, L., Fincantieri S.p.A, Italy","Due to the complexity of modern cruise ships, efficient management of information is in many cases possible only by introducing suitable advanced technological solutions. In this paper we discuss the implications of using a virtual reality (VR) system in a cruise ship design process. At the initial stages, most of the information about a vessel is included in its design in the form of 3D CAD models, which are normally not accessible to stakeholders with insufficient CAD skills. By transferring the models to an immersive environment, the understanding of the project normally improves for expert as well as non-expert stakeholders. However, the potential of the technology is dependent on the quality of pre-processing of CAD models for VR and on the set-up of the VR scenes. As described, the workflow in the design process must therefore be carefully adjusted to allow seamless transfer of files between CAD and VR environments. © 2019: The Royal Institution of Naval Architects.",,"Shipbuilding; Ships; Shipyards; Virtual reality; 3d cad models; Cruise ships; Design process; Efficient managements; Immersive environment; Pre-processing; Seamless transfer; Technological solution; Computer aided design",Conference Paper,"Final","",Scopus,2-s2.0-85074450034
"Kalarat K., Koomhin P.","16319061300;55619841400;","Real-time volume rendering interaction in Virtual Reality",2019,"International Journal of Technology","10","7",,"1307","1314",,,"10.14716/ijtech.v10i7.3259","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076044621&doi=10.14716%2fijtech.v10i7.3259&partnerID=40&md5=005226cee497ef28d0d76d480aa41a00","School of Informatics, Walailak University, 222 Thaiburi, Thasala District, Nakhon Si Thammarat, 80161, Thailand; School of Medicine, Walailak University, 222 Thaiburi, Thasala District, Nakhon Si Thammarat, 80161, Thailand","Kalarat, K., School of Informatics, Walailak University, 222 Thaiburi, Thasala District, Nakhon Si Thammarat, 80161, Thailand; Koomhin, P., School of Medicine, Walailak University, 222 Thaiburi, Thasala District, Nakhon Si Thammarat, 80161, Thailand","Volume visualization using Direct Volume Rendering (DVR) techniques is used to view information inside 3D volumetric data. Data is classified using a transfer function to emphasize or filter some parts of volumetric information, such as that from Computed Tomography (CT) or Magnetic Resonance Imaging (MRI). In this paper, we introduced an application for real-time volume rendering interaction with 1D transfer functions using Virtual Reality (VR) technology based on the Oculus Rift headset and Oculus Touch controllers. Resulting images were visualized stereoscopically at 60 frames per second using a ray-casting shader, which works based on Graphics Processing Unit (GPU). To evaluate the system, 20 participants interacted with the application to complete three tasks, including a free viewpoint scan, clipping planes renderer, and an editable transfer function in the virtual environment. Then, a survey was carried out using a questionnaire to gather data. Findings showed that the average usability score for the application was 87.54, which suggested that it was highly usable. © IJTech 2019.","Direct volume rendering; Ray casting; Virtual environment; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85076044621
"Kramberger I., Kacic Z., Donaj G.","6602310875;7004382027;55874344700;","Binocular Phase-Coded Visual Stimuli for SSVEP-Based BCI",2019,"IEEE Access","7",, 8688386,"48912","48922",,2,"10.1109/ACCESS.2019.2910737","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065069612&doi=10.1109%2fACCESS.2019.2910737&partnerID=40&md5=a0d4afa389cdff1a61934e32668abebb","Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, 2000, Slovenia","Kramberger, I., Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, 2000, Slovenia; Kacic, Z., Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, 2000, Slovenia; Donaj, G., Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, 2000, Slovenia","This paper presents a method of binocular visual stimulation for brain-computer interfaces (BCIs) based on steady-state visual evoked potentials (SSVEPs) using phase-coded symbols. The proposed method's emphasis is on a binocular phase-coded visual stimulus, which is based on the phase differences between the left- and right-eye stimuli, and a symbol detection and recognition procedure based on SSVEP response of the left and right occipital lobes of the user's scalp, where the SSVEP response is obtained as electroencephalography (EEG) signaling. The symbols are coded as phase differences and maintain the same frequency of the sine wave-modulated light provided to the user's left and right eyes as a binocular visual stimulation. Based on this method, a basic system setup is presented to explore the possibilities of binocular phase-coded visual stimuli for virtual or augmented reality applications, where the binocular visual stimulation was achieved by the specially designed head-mounted displays. Multiple visually coded targets are realized as eight different phase-coded binocular symbols and further evaluated as a random sequence of single targets, thus representing the situations in virtual or augmented reality, where multiple visually coded targets are present but not visualized to the user simultaneously within the same field of view. The offline results obtained from ten healthy subjects revealed that an average symbol recognition accuracy of 90.63% and an information transfer rate (ITR) of 70.55 bits/min were achieved for a symbol stimulation time of 2 s. The results of this paper demonstrate the feasibility of using binocular visual stimuli for SSVEP-based BCIs, where reasonable ITR is achieved using single-frequency binocular phase-coded symbols. The proposed method indicates the possibility of combining it with 3D wearable visualization technologies, such as binocular head-mounted displays (HMDs), in order to improve the intuitiveness of the interaction with more immersive user experience using BCI modalities. © 2013 IEEE.","Brain computer interfaces; Brain stimulation; Data acquisition; Electroencephalography; Human computer interaction; Phase measurement; Steady state visually evoked potential; Three-dimensional displays; Virtual reality; Visualization; Wearable sensors","Augmented reality; Binoculars; Data acquisition; Data visualization; Electroencephalography; Electrophysiology; Flow visualization; Helmet mounted displays; Human computer interaction; Interface states; Pattern recognition; Phase measurement; Three dimensional computer graphics; Three dimensional displays; Virtual reality; Visualization; Wearable computers; Wearable sensors; Augmented reality applications; Brain computer interfaces (BCIs); Brain stimulation; Head mounted displays; Information transfer rate; Steady state visual evoked potential (SSVEPs); Steady state visually evoked potentials; Visualization technologies; Brain computer interface",Article,"Final","",Scopus,2-s2.0-85065069612
"Oberdörfer S., Latoschik M.E.","57192160404;6602976914;","Knowledge encoding in game mechanics: Transfer-oriented knowledge learning in desktop-3D and VR",2019,"International Journal of Computer Games Technology","2019",, 7626349,"","",,4,"10.1155/2019/7626349","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065769392&doi=10.1155%2f2019%2f7626349&partnerID=40&md5=0741462efb8e93e61183958445a8371b","Human-Computer Interaction, University of Würzburg, Würzburg, Germany","Oberdörfer, S., Human-Computer Interaction, University of Würzburg, Würzburg, Germany; Latoschik, M.E., Human-Computer Interaction, University of Würzburg, Würzburg, Germany","Affine Transformations (ATs) are a complex and abstract learning content. Encoding the AT knowledge in Game Mechanics (GMs) achieves a repetitive knowledge application and audiovisual demonstration. Playing a serious game providing these GMs leads to motivating and effective knowledge learning. Using immersive Virtual Reality (VR) has the potential to even further increase the serious game's learning outcome and learning quality. This paper compares the effectiveness and efficiency of desktop-3D and VR in respect to the achieved learning outcome. Also, the present study analyzes the effectiveness of an enhanced audiovisual knowledge encoding and the provision of a debriefing system. The results validate the effectiveness of the knowledge encoding in GMs to achieve knowledge learning. The study also indicates that VR is beneficial for the overall learning quality and that an enhanced audiovisual encoding has only a limited effect on the learning outcome. © 2019 Sebastian Oberdörfer and Marc Erich Latoschik.",,"Encoding (symbols); Knowledge management; Signal encoding; Virtual reality; Affine transformations; Effectiveness and efficiencies; Immersive virtual reality; Knowledge application; Knowledge learning; Learning contents; Learning outcome; Learning quality; Serious games",Article,"Final","",Scopus,2-s2.0-85065769392
"Riva G., Wiederhold B.K., Mantovani F.","56962750600;7003634518;7006190897;","Neuroscience of Virtual Reality: From Virtual Exposure to Embodied Medicine",2019,"Cyberpsychology, Behavior, and Social Networking","22","1",,"82","96",,74,"10.1089/cyber.2017.29099.gri","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055999466&doi=10.1089%2fcyber.2017.29099.gri&partnerID=40&md5=cd9711ea83953e848a8ad11e7c485d1c","Applied Technology for Neuro-Psychology Lab, IRCCS Istituto Auxologico Italiano, Milan, Italy; Department of Psychology, Università Cattolica Del Sacro Cuore, Largo Gemelli 1, Milan, 20123, Italy; Virtual Reality Medical Center, San Diego, CA, United States; Virtual Reality Medical Institute, Brussels, Belgium; Department of Human Sciences for Education, Università degli Studi di Milano-Bicocca, Milan, Italy","Riva, G., Applied Technology for Neuro-Psychology Lab, IRCCS Istituto Auxologico Italiano, Milan, Italy, Department of Psychology, Università Cattolica Del Sacro Cuore, Largo Gemelli 1, Milan, 20123, Italy; Wiederhold, B.K., Virtual Reality Medical Center, San Diego, CA, United States, Virtual Reality Medical Institute, Brussels, Belgium; Mantovani, F., Department of Human Sciences for Education, Università degli Studi di Milano-Bicocca, Milan, Italy","Is virtual reality (VR) already a reality in behavioral health? To answer this question, a meta-review was conducted to assess the meta-analyses and systematic and narrative reviews published in this field in the last twenty-two months. Twenty-five different articles demonstrated the clinical potential of this technology in both the diagnosis and the treatment of mental health disorders: VR compares favorably to existing treatments in anxiety disorders, eating and weight disorders, and pain management, with long-term effects that generalize to the real world. But why is VR so effective? Here, the following answer is suggested: VR shares with the brain the same basic mechanism: embodied simulations. According to neuroscience, to regulate and control the body in the world effectively, the brain creates an embodied simulation of the body in the world used to represent and predict actions, concepts, and emotions. VR works in a similar way: the VR experience tries to predict the sensory consequences of an individual's movements, providing to him/her the same scene he/she will see in the real world. To achieve this, the VR system, like the brain, maintains a model (simulation) of the body and the space around it. If the presence in the body is the outcome of different embodied simulations, concepts are embodied simulations, and VR is an embodied technology, this suggests a new clinical approach discussed in this article: the possibility of altering the experience of the body and facilitating cognitive modeling/change by designing targeted virtual environments able to simulate both the external and the internal world/body. © Giuseppe Riva et al. 2019; Published by Mary Ann Liebert, Inc.",,"analgesia; anxiety disorder; cognitive neuroscience; human; mental disease; meta analysis; virtual reality; virtual reality exposure therapy; Anxiety Disorders; Cognitive Neuroscience; Humans; Mental Disorders; Pain Management; Virtual Reality; Virtual Reality Exposure Therapy",Article,"Final","",Scopus,2-s2.0-85055999466
"Chang C.-H., Lin C.-Y., Wang R.-G., Chou C.-C.","57203374856;46062172900;57203964800;55710381200;","Applying Deep Learning and Building Information Modeling to Indoor Positioning Based on Sound",2019,"Computing in Civil Engineering 2019: Visualization, Information Modeling, and Simulation - Selected Papers from the ASCE International Conference on Computing in Civil Engineering 2019",,,,"193","199",,1,"10.1061/9780784482421.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068750871&doi=10.1061%2f9780784482421.025&partnerID=40&md5=4715e36373be40eb5a8db12c0c7eabc7","Information Technology for Disaster Prevention Program, Dept. of Civil Engineering, National Central Univ., 300 Jhongda Rd., Jhongli Dist., Taoyuan City, 32001, Taiwan; National Science and Technology Center for Disaster Reduction (NCDR), 9F, No. 200, Sec. 3, Beisin Rd., Xindian Dist., New Taipei City, 23143, Taiwan","Chang, C.-H., Information Technology for Disaster Prevention Program, Dept. of Civil Engineering, National Central Univ., 300 Jhongda Rd., Jhongli Dist., Taoyuan City, 32001, Taiwan; Lin, C.-Y., National Science and Technology Center for Disaster Reduction (NCDR), 9F, No. 200, Sec. 3, Beisin Rd., Xindian Dist., New Taipei City, 23143, Taiwan; Wang, R.-G., Information Technology for Disaster Prevention Program, Dept. of Civil Engineering, National Central Univ., 300 Jhongda Rd., Jhongli Dist., Taoyuan City, 32001, Taiwan; Chou, C.-C., Information Technology for Disaster Prevention Program, Dept. of Civil Engineering, National Central Univ., 300 Jhongda Rd., Jhongli Dist., Taoyuan City, 32001, Taiwan","At present, indoor positioning has great potential for disaster mitigation, such as guiding evacuees to safe places. This research aims at developing such a sound-based method using artificial intelligence (AI) and building information modeling (BIM). Amid a disaster, first responders can quickly set up the proposed system to help indoor positioning, which relies on BIM, virtual reality (VR), and head related transfer functions (HRTF) techniques to simulate virtual sound fields. Then, a deep learning model is trained so as to be able to predict the current zone within a room based on the sound received. Unity, a serious game platform, and Steam Audio, a Unity plugin designed for adding 3D audio to VR experience, are employed to generate input data sets. The overall accuracy of the output results is about 90% though the training time is long, which can be reduced if more powerful computing resources are utilized. © 2019 American Society of Civil Engineers.",,"Acoustic fields; Architectural design; Disasters; Indoor positioning systems; Information theory; Serious games; Sound reproduction; Virtual reality; Visualization; Building Information Model - BIM; Computing resource; Disaster mitigation; First responders; Head related transfer function; Indoor positioning; Learning models; Overall accuracies; Deep learning",Conference Paper,"Final","",Scopus,2-s2.0-85068750871
"Eiler T.J., Grünewald A., Brück R.","57209602482;55320081200;9639255900;","Fighting substance dependency combining AAT therapy and virtual reality with game design elements",2019,"VISIGRAPP 2019 - Proceedings of the 14th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications","2",,,"28","37",,2,"10.5220/0007362100280037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068205164&doi=10.5220%2f0007362100280037&partnerID=40&md5=4f227b31e734c7f5ac635d8330c0a3a1","Medical Informatics and Microsystems Engineering, University of Siegen, Hölderlinstraße 3, Siegen, 57076, Germany","Eiler, T.J., Medical Informatics and Microsystems Engineering, University of Siegen, Hölderlinstraße 3, Siegen, 57076, Germany; Grünewald, A., Medical Informatics and Microsystems Engineering, University of Siegen, Hölderlinstraße 3, Siegen, 57076, Germany; Brück, R., Medical Informatics and Microsystems Engineering, University of Siegen, Hölderlinstraße 3, Siegen, 57076, Germany","Smoking poses a significant health risk and is still the main cause of premature mortality today. The Approach Avoidance Task (AAT) developed by Rinck and Becker aims to develop a substance dependence therapy that can reach the digital society. In this paper, a demonstrator that transfers the AAT procedure into virtual reality (VR) is presented. This demonstrator was used to carry out an evaluation with twenty participants who were asked to use the program and evaluate it by means of questionnaires and interviews. In addition, the reaction times (RTs) of the test persons were recorded and evaluated. The results show that the transfer of the AAT procedure to VR is possible and promising. Above all, the use of three-dimensional scenarios and objects, with which one interacts during the training, were well received and increased the immersion as well as the felt embodiment. The use of game design elements has also proved helpful and has had a positive influence on user motivation. Copyright © 2019 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved","Approach Avoidance Task; Approach Bias; Cognitive Bias Modification; Digital Medicine; Game Design; Substance Dependency; Therapy; Virtual Reality; VR Applications","Design; Health risks; Human computer interaction; Surveys; Virtual reality; Approach Avoidance Task; Approach Bias; Cognitive bias; Game design; Substance Dependency; Therapy; VR applications; Computer vision",Conference Paper,"Final","",Scopus,2-s2.0-85068205164
"Liang Z., Zhou K., Gao K.","57219563458;14326511900;57202081500;","Development of Virtual Reality Serious Game for Underground Rock-Related Hazards Safety Training",2019,"IEEE Access","7",, 8795446,"118639","118649",,5,"10.1109/ACCESS.2019.2934990","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096356867&doi=10.1109%2fACCESS.2019.2934990&partnerID=40&md5=6f76e226cf1620939d4a0a5c67da7438","School of Resources and Safety Engineering, Central South University, Changsha, China","Liang, Z., School of Resources and Safety Engineering, Central South University, Changsha, China; Zhou, K., School of Resources and Safety Engineering, Central South University, Changsha, China; Gao, K., School of Resources and Safety Engineering, Central South University, Changsha, China","Traditional safety training media to transfer safety knowledge specific to the rock-related hazards in underground mines are mainly video or manuals, which are inefficient and bring a poor training experience. In this paper, we designed and developed a serious game based on virtual reality (VR) technology in order to efficiently transfer safety knowledge and enable enhanced interactive safety training. For different training purposes and users, we designed two modes, one for professional scaling training suitable for novice scalers, the other for rock-related hazards perception training suitable for other miners. Our game is built based on game engine-Unity3D and equipped with HTC VIVE to improve immersion. The game pipeline is to have trainees basically understand safety knowledge through guided interaction and then make a self-adaptive practice to fully master it. We evaluated the effectiveness of our game, and the results of the comparative experiment show that our game is more efficient than the instructional video in both training modes. The application of our game is proven to have the potential to change the safety situation of underground mines and evaluate the level of safety awareness and risk aversion of the miners in the future. © 2013 IEEE.","rock-related hazards; Safety training; serious game; underground mining; virtual reality","E-learning; Education computing; Hazards; Miners; Virtual reality; Comparative experiments; Instructional videos; Level of safeties; Safety knowledge; Safety training; Training experiences; Training purpose; Underground mine; Serious games",Article,"Final","",Scopus,2-s2.0-85096356867
"O'Rourke M.","57214560510;","Connecting fun and learning- an activity-theoretical approach to competency based game development",2019,"ASCILITE 2015 - Australasian Society for Computers in Learning and Tertiary Education, Conference Proceedings",,,,"517","521",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071727079&partnerID=40&md5=c873212f7885116d6504e4ff8ba0d266","Deakin University, Australia","O'Rourke, M., Deakin University, Australia","Games-based learning has the potential to improve engagement and skill development. This research explores the development of the White Card Game and the impact that fun has on learning outcomes. The first-person shooter style game offers a contextualised, situated experience that equips learners with skills and an understanding of the socially complex world of work. The research has approached the analysis through an Activity Theoretical framework. This approach involved: analysing the interactions between components in the games-based learning activity system while they evolved; identifying contradictions and exploring the mediation that progressed the activity outcome; and examining fun within the games-based learning context. This analysis revealed significant increases in knowledge transfer, skill development and engagement with the curriculum in comparison to conventional pedagogical approaches. © ASCILITE 2015 - Australasian Society for Computers in Learning and Tertiary Education, Conference Proceedings.All right reserved.","Activity system; Fun; Games-based learning; Immersive environments; Scaffold","Knowledge management; Scaffolds; Software design; Activity Systems; First person shooter; Games-based learning; Immersive environment; Knowledge transfer; Pedagogical approach; Theoretical approach; Theoretical framework; Learning systems",Conference Paper,"Final","",Scopus,2-s2.0-85071727079
"Voda A., Martin O., Naves Neto P.R., Gascuel J.-D., Schmerber S.","35866536800;7102395624;57215538281;57213401968;6701617902;","Visual-vestibular compensation in balance recovery: A transfer function model-based analysis",2019,"IFAC-PapersOnLine","52","26",,"88","93",,,"10.1016/j.ifacol.2019.12.241","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081099853&doi=10.1016%2fj.ifacol.2019.12.241&partnerID=40&md5=a6c88436cdc9e0771a90639bb69b19a6","GIPSA-lab, Univ. Grenoble-Alpes, Saint Martin, d'Hères, F-38402, France; MAVERICK Team-LJK CNRS, Univ. Grenoble-Alpes, France; Grenoble University Hospital, NET Clinic, Grenoble, France","Voda, A., GIPSA-lab, Univ. Grenoble-Alpes, Saint Martin, d'Hères, F-38402, France; Martin, O., GIPSA-lab, Univ. Grenoble-Alpes, Saint Martin, d'Hères, F-38402, France; Naves Neto, P.R., GIPSA-lab, Univ. Grenoble-Alpes, Saint Martin, d'Hères, F-38402, France; Gascuel, J.-D., MAVERICK Team-LJK CNRS, Univ. Grenoble-Alpes, France; Schmerber, S., Grenoble University Hospital, NET Clinic, Grenoble, France","During immersive balance rehabilitation, automatic visual-vestibular compensations occurs to reduce the patients' visual reliance and improve the equilibrium. This paper describes the use of an identification procedure to characterise the relationship between visual stimulation features involved in this adaptive sensory compensation, and the balance improvement. The purpose is to determine the stimulus-response transfer functions (TF) associated to the equilibrium enhancement. Standing vestibular patients were stimulated by visual virtual flows, whose pattern and speed changed throughout successive stimulation sessions. The analysis of the feet centre-of-pressure, disequilibrium, and identified models parameters for one representative vestibular patient, showed that TF parameters evolved related to the gradual balance recovery boosted by the visual-vestibular compensation. This results suggest that identified TF parameters are suitable indicators for measuring the effect of sensory substitution on equilibrium recovery. This first step to model the relationship between the sensory re-weighting flexibility and the adaptation of postural commands is essential for future clinical studies using identification methods for sensorimotor evaluation in individualized vision-based balance rehabilitation. © 2019 IFAC-PapersOnLine. All rights reserved.","adaptive motor control; Human balance deficit; modelling; rehabilitation; sensory integration; transfer function model; virtual reality; visual-vestibular compensation","Models; Recovery; Transfer functions; Virtual reality; Adaptive motor controls; Balance rehabilitations; Human balance; Identification method; Identification procedure; Sensory integration; Sensory substitution; Transfer function model; Patient rehabilitation",Conference Paper,"Final","",Scopus,2-s2.0-85081099853
"Lu C.Y., Kao C., Kang S.C., Lai J.S., Lee T.H.","57210197618;57201400350;23090862400;57210195557;7501439901;","A generalized procedure to develop a virtual environment for the conducting of hydraulics laboratory experiments",2019,"EG-ICE 2010 - 17th International Workshop on Intelligent Computing in Engineering",,,,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083946596&partnerID=40&md5=222e4af45d29d05541703d58db385d57","National Taiwan University, Taiwan","Lu, C.Y., National Taiwan University, Taiwan; Kao, C., National Taiwan University, Taiwan; Kang, S.C., National Taiwan University, Taiwan; Lai, J.S., National Taiwan University, Taiwan; Lee, T.H., National Taiwan University, Taiwan","In many engineering fields, laboratory experiment courses are a core aspect of engineering classes. Students can learn basic theories through manipulating the equipment and observing the phenomena in the experiments, cultivating an engineer's keen sense of observation. However, due to high costs and limited numbers of experimental equipment, students must be divided into groups having to take turns to do the experiment, causing a lot of difficulty and inconvenience in conducting this kind of laboratory course. Maneuverable virtual equipment is an ideal approach for providing a feasible alternative to using physical laboratory equipment in courses. Yet such an alternative is not without its challenges. Developing virtual equipment requires mapping experimental procedures from the physical world onto virtual environments. The system developers need to deal with constraints unique to virtual environments, such as limitations in user interfaces and computer calculation speed. It requires effective integration of the expertise between experienced teachers and the 3D system programmers. To achieve this purpose, our research has proposed a generalized procedure for developing virtual equipment and instruments for procedure-based experiments. The procedure has four main phases: (1) observation, (2) storyboard, (3) implementation, and (4) user test; or OSIT in short. To validate the OSIT, it was used to develop and implement virtual equipment for a standard hydraulic experiment, called the Force Vortex Experiment, at National Taiwan University. We found that using OSIT significantly reduced the total elapsed time of communication between instructors and 3D programmers. OSIT also delivered software that better matched users' needs. © Nottingham University Press","Engineering education; Hydraulic experiment; User centered design; Virtual equipment","Computation theory; Curricula; Engineering education; Intelligent computing; Laboratories; Software design; User centered design; User interfaces; Virtual reality; Computer calculation; Experimental equipments; Experimental procedure; Feasible alternatives; Laboratory experiments; National Taiwan University; Physical laboratory; Virtual equipments; Hydraulic machinery",Conference Paper,"Final","",Scopus,2-s2.0-85083946596
"Luo Y., Gao B., Deng Y., Zhu X., Jiang T., Zhao X., Yang Z.","8410343300;57190227969;57190222435;55696685000;57197095290;57192669458;7405433286;","Automated brain extraction and immersive exploration of its layers in virtual reality for the rhesus macaque MRI data sets",2019,"Computer Animation and Virtual Worlds","30","1", e1841,"","",,3,"10.1002/cav.1841","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047658599&doi=10.1002%2fcav.1841&partnerID=40&md5=89cba5bca06fb90d62e098981099b536","College of Information Science and Technology, Beijing Normal University, Beijing, China; Brainnetome Center, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Brain and Cognitive Science, Institute of Biophysics, Chinese Academy of Sciences, Beijing, China","Luo, Y., College of Information Science and Technology, Beijing Normal University, Beijing, China; Gao, B., Brainnetome Center, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Deng, Y., College of Information Science and Technology, Beijing Normal University, Beijing, China; Zhu, X., College of Information Science and Technology, Beijing Normal University, Beijing, China; Jiang, T., Brainnetome Center, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Zhao, X., State Key Laboratory of Brain and Cognitive Science, Institute of Biophysics, Chinese Academy of Sciences, Beijing, China; Yang, Z., Brainnetome Center, Institute of Automation, Chinese Academy of Sciences, Beijing, China","As we know, the rhesus macaque as a nonhuman primate is quite similar to a human being in genetics. Moreover, it has become essential in animal model anatomy and physiology in many modern medicine research such as the cardiovascular and cerebrovascular diseases in the recent years. This paper describes a pipeline from the raw rhesus macaque brain magnetic resonance imaging data to intuitive 3D inspection of its layers. Brain extraction is an initial step for subsequent analyses, but most of the existing methods so far are designed for human brain, which does not work well with the rhesus macaque. Firstly, we propose a reliable and efficient method to extract the brain from magnetic resonance imaging data sets based on dividing the brain into blocks. Then, we design a trapezoid opacity transfer function based on Compute Unified Device Architecture (CUDA)-based real-time volume ray casting, which is dedicated to volume rendering to make the inspection more intuitive. Besides, for an immersive exploration in virtual reality benefits understanding the volumetric data sets, so we also design a layer filter for the segmented rhesus macaque brain data sets, which facilitates the inspection of the interior in Region of Interest (ROI) by an intuitive bimanual interaction via a Leap Motion sensor. Our experiments prove usability and efficiency. © 2018 John Wiley & Sons, Ltd.","3D inspection; bimanual gesture interaction; brain extraction; rhesus macaque; volume visualization","Extraction; Image segmentation; Magnetic resonance imaging; Virtual reality; Volume rendering; Volumetric analysis; 3D inspection; Brain extraction; Gesture interaction; Rhesus macaque; Volume visualization; Inspection",Article,"Final","",Scopus,2-s2.0-85047658599
"Asbee J., Parsons T.","57201196275;57208201581;","Cognitive effects of transcranial direct current stimulation and virtual environments",2019,"Annual Review of CyberTherapy and Telemedicine","17",,,"11","16",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088231363&partnerID=40&md5=235e180d8675d7257305a628bf71d34a","Computational Neuropsychology and Simulation Lab, University of North Texas, United States","Asbee, J., Computational Neuropsychology and Simulation Lab, University of North Texas, United States; Parsons, T., Computational Neuropsychology and Simulation Lab, University of North Texas, United States","Transcranial direct current stimulation (tDCS) involves the introduction of a small amount of current to the participant’s brain to influence brain activity in the stimulated areas. Research using tDCS has involved a wide range of cognitive and affective domains. A limitation to the generalization of these findings to everyday cognitive processes is that these studies often involve simple stimuli that may not reflect the more dynamic cognitive and affective processes found in activities of daily living. To address this issue, a growing number of studies have begun using virtual environments (VE) that include dynamic simulations of everyday activities. Lacking is a quantitative meta-analysis that enhances understanding of the cognitive manipulations resulting from tDCS protocols that include VEs. Searches of electronic databases yielded 756 studies. Thirteen studies (618 subjects) met inclusion criteria. Preliminary results reveal that tDCS produced a statistically significant Hedge’s g of 0.45. The effect for tDCS was statistically significant for both immersive virtual stimuli, g = 0.25, and screen captures from VEs, g = 0.79. Analyses of results relative to cognitive domains revealed that tDCS had the greatest influence on risk assessment, g = 0.67. Small effect sizes were observed for attention and executive functioning, g = 0.21 and hippocampal dependent tasks, g = 0.17. In summary, while tDCS combined with VEs produced medium effects on cognition, the effects were relative to cognitive domain. A potentially promising use of tDCS with VEs may be that of training. © 2019, Interactive Media Institute. All rights reserved.","Cognition; Meta-analysis; Transcranial direct current stimulation; Virtual reality","adult; article; attention; daily life activity; effect size; executive function; female; hippocampus; human; human experiment; male; meta analysis; preliminary data; quantitative analysis; risk assessment; systematic review; transcranial direct current stimulation; virtual reality",Article,"Final","",Scopus,2-s2.0-85088231363
"Zhu D., Zhou Q., Han T., Chen Y.","57213510302;35096857600;57195952219;57221457399;","360 Degree Panorama Synthesis from Sequential Views Based on Improved FC-Densenets",2019,"IEEE Access","7",, 8926406,"180503","180511",,1,"10.1109/ACCESS.2019.2958111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077180697&doi=10.1109%2fACCESS.2019.2958111&partnerID=40&md5=fbd2a5bd98ad8ca7fcca16c8373f3968","Artificial Intelligence Institute, Shanghai Jiao Tong University, Shanghai, 200240, China; School of Information and Computer, Shanghai Business School, Shanghai, 201400, China; Department of Computer Science, Stevens Institute of Technology, Hoboken, NJ  07030, United States; Hainan Air Traffic Management Sub-Bureau, Haikou, 570000, China","Zhu, D., Artificial Intelligence Institute, Shanghai Jiao Tong University, Shanghai, 200240, China; Zhou, Q., School of Information and Computer, Shanghai Business School, Shanghai, 201400, China; Han, T., Department of Computer Science, Stevens Institute of Technology, Hoboken, NJ  07030, United States; Chen, Y., Hainan Air Traffic Management Sub-Bureau, Haikou, 570000, China","Inspired by the effectiveness of deep learning model, many panorama saliency prediction models based on deep learning began to emerge and achieved significant performance improvement. However, this kind of model requires a large number of labeled ground-truth data, and the existing panorama datasets are small-scale and difficult to train the deep learning models. To address this problem, we propose a novel panorama generative model for synthesizing realistic and sharp-looking panorama. In particular, our proposed panorama generative model consists of two sub-networks of generator and discriminator. At first, in order to make the synthesized panorama more realistic, we employ the improved Fully-Convolutional Densely Connected Convolutional Networks (FC-DenseNets) as the generator network. Secondly, we design a new correlation layer in the discriminator network, which can calculate the similarity between the generated image and the ground-truth image, and achieve the pixel level accuracy. The experimental results show that our proposed method outperforms other baseline work and has superior generalization ability to synthesize real-world data. © 2013 IEEE.","correlation layer; generative model; panorama; saliency prediction; Virtual reality","Convolution; Discriminators; Large dataset; Virtual reality; Convolutional networks; Generalization ability; Generative model; Ground truth data; Learning models; New correlations; panorama; Prediction model; Deep learning",Article,"Final","",Scopus,2-s2.0-85077180697
"De Vin L.J., Jacobsson L., Odhe J.","57204489827;57193552068;57195807121;","Simulator-assisted lean production training",2019,"Production and Manufacturing Research","7","1",,"433","447",,4,"10.1080/21693277.2019.1644248","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069793882&doi=10.1080%2f21693277.2019.1644248&partnerID=40&md5=5b98fd6419d075d2e77835f82b42305c","Department of Engineering and Physics, Karlstad University, Karlstad, Sweden","De Vin, L.J., Department of Engineering and Physics, Karlstad University, Karlstad, Sweden; Jacobsson, L., Department of Engineering and Physics, Karlstad University, Karlstad, Sweden; Odhe, J., Department of Engineering and Physics, Karlstad University, Karlstad, Sweden","In Lean Production training and education, simulators are often used. These can take the form of for instance desktop games, computer simulations, or full-scale simulators. Many training participants perceive models for experiential learning and for continuous improvement processes as complex and abstract. Based on experiences from training sessions in a full-scale simulator Karlstad Lean Factory®, a unified model for learning and improvement work is presented. This model stimulates training transfer and is perceived as intuitive. It also shows instructional scaffolding as a learning method. Suggestions for future work include investigating synergy with Smart Manufacturing and the use of Lean Production simulators for innovative product realisation. © 2019, © 2019 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.","instructional scaffolding; Karlstad Lean Factory®; Lean production; training transfer; training within industry","Computer games; Lean production; Manufacture; Scaffolds; Simulators; Continuous improvement process; Experiential learning; Innovative product; instructional scaffolding; Smart manufacturing; Training and education; Training sessions; Unified Modeling; Learning systems",Article,"Final","",Scopus,2-s2.0-85069793882
"Trevizan I.L., Silva T.D., Dawes H., Massetti T., Crocetta T.B., Favero F.M., Oliveira A.S.B., De Araújo L.V., Santos A.C.C., De Abreu L.C., Coe S., Monteiro C.B.D.M.","57189443519;55546962700;7003895377;55546122700;54898013000;36113108600;35550845300;57195720273;57205114787;57192659178;55901034900;55481862300;","Efficacy of different interaction devices using non-immersive virtual tasks in individuals with Amyotrophic Lateral Sclerosis: A cross-sectional randomized trial",2018,"BMC Neurology","18","1", 209,"","",,5,"10.1186/s12883-018-1212-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058649682&doi=10.1186%2fs12883-018-1212-3&partnerID=40&md5=6d1543c38a814e800d46221b3241afd0","Department of Speech Therapy, Physiotherapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Rua Cipotânea, 51, São Paulo, CEP: 05360-000, Brazil; Federal University of São Paulo, Paulista School of Medicine, Rua Sena Madureira, 1500, São Paulo, CEP: 04021-001, Brazil; Institute of Nursing and Allied Health Research, Oxford Brookes University, Headington Campus, Oxford, OX3 0BP, United Kingdom; Department of Clinical Neurology, University of Oxford, Oxford, OX3 9DU, United Kingdom; Department of Physiotherapy, Speech Therapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Rua Cipotânea, 51, São Paulo, CEP: 05360-000, Brazil; Department of Scientific Writing, Faculty of Medicine ABC, Avenida Príncipe de Gales, 821, Santo André, São Paulo, CEP: 09060-650, Brazil; School of Arts, Sciences and Humanities, University of São Paulo, Rua Arlindo Bettio, 1000, São Paulo, CEP: 038-28-000, Brazil","Trevizan, I.L., Department of Speech Therapy, Physiotherapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Rua Cipotânea, 51, São Paulo, CEP: 05360-000, Brazil; Silva, T.D., Federal University of São Paulo, Paulista School of Medicine, Rua Sena Madureira, 1500, São Paulo, CEP: 04021-001, Brazil; Dawes, H., Institute of Nursing and Allied Health Research, Oxford Brookes University, Headington Campus, Oxford, OX3 0BP, United Kingdom, Department of Clinical Neurology, University of Oxford, Oxford, OX3 9DU, United Kingdom; Massetti, T., Department of Physiotherapy, Speech Therapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Rua Cipotânea, 51, São Paulo, CEP: 05360-000, Brazil; Crocetta, T.B., Department of Scientific Writing, Faculty of Medicine ABC, Avenida Príncipe de Gales, 821, Santo André, São Paulo, CEP: 09060-650, Brazil; Favero, F.M., Federal University of São Paulo, Paulista School of Medicine, Rua Sena Madureira, 1500, São Paulo, CEP: 04021-001, Brazil; Oliveira, A.S.B., Federal University of São Paulo, Paulista School of Medicine, Rua Sena Madureira, 1500, São Paulo, CEP: 04021-001, Brazil; De Araújo, L.V., School of Arts, Sciences and Humanities, University of São Paulo, Rua Arlindo Bettio, 1000, São Paulo, CEP: 038-28-000, Brazil; Santos, A.C.C., Federal University of São Paulo, Paulista School of Medicine, Rua Sena Madureira, 1500, São Paulo, CEP: 04021-001, Brazil; De Abreu, L.C., Department of Scientific Writing, Faculty of Medicine ABC, Avenida Príncipe de Gales, 821, Santo André, São Paulo, CEP: 09060-650, Brazil; Coe, S., Institute of Nursing and Allied Health Research, Oxford Brookes University, Headington Campus, Oxford, OX3 0BP, United Kingdom; Monteiro, C.B.D.M., Department of Physiotherapy, Speech Therapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Rua Cipotânea, 51, São Paulo, CEP: 05360-000, Brazil, School of Arts, Sciences and Humanities, University of São Paulo, Rua Arlindo Bettio, 1000, São Paulo, CEP: 038-28-000, Brazil","Background: Amyotrophic Lateral Sclerosis (ALS) is a rapid progressive neurodegenerative disease, characterized by a selective loss of motor neurons, brain stem and spinal cord which leads to deterioration of motor abilities. Devices that promote interaction with tasks on computers can enhance performance and lead to greater independence and utilization of technology. Objective: To evaluate performance on a computer task in individuals with ALS using three different commonly used non-immersive devices. Method: Thirty individuals with ALS (18 men and 12 women, mean age 59 years, range 44-74 years) with a mean score of 26, (minimum score of 14 and maximum 41) on the Revised Amyotrophic Lateral Sclerosis Functional Rating Scale (ALSFRS-R) and 30 healthy controls matched for age and gender, participated. All participants were randomly divided into three groups, each using a different device system (motion tracking, finger motion control or touchscreen) to perform three task phases (acquisition, retention and transfer). Results: Both the ALS and control group (CG) showed better performance on the computer task when using the touchscreen device, but there was limited transfer of performance onto the task performed on the Finger Motion control or motion tracking. However, we found that using the motion tracking device led to transfer of performance to the touchscreen. Conclusion: This study presents novel and important findings when selecting interaction devices for individuals with ALS to access technology by demonstrating immediate performance benefits of using a touchscreen device, such as improvement of motor skills. There were possible transferable skills obtained when using virtual systems which may allow flexibility and enable individuals to maintain performance overtime. Trial registration: Registration name: Virtual Task in Amyotrophic Lateral Sclerosis; Registration number: NCT03113630; retrospectively registered on 04/13/2017. Date of enrolment of the first participant to the trial: 02/02/2016. © 2018 The Author(s).","Amyotrophic lateral sclerosis; Motor activity; Rehabilitation; User-computer Interface; Virtual reality exposure therapy","acquisition phase; adult; aged; amyotrophic lateral sclerosis; Article; clinical article; controlled study; cross-sectional study; Fatigue Severity Scale; female; finger motion control device; human; information processing; male; motion tracking device; neurologic disease assessment; quality of life; retention phase; Revised Amyotrophic Lateral Sclerosis Functional Rating Scale; scoring system; touchscreen device; transfer phase; virtual reality; amyotrophic lateral sclerosis; computer interface; middle aged; motor performance; pathophysiology; randomized controlled trial; retrospective study; Adult; Aged; Amyotrophic Lateral Sclerosis; Cross-Sectional Studies; Female; Humans; Male; Middle Aged; Motor Skills; Retrospective Studies; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-85058649682
"Boton C.","37017251600;","Supporting constructability analysis meetings with Immersive Virtual Reality-based collaborative BIM 4D simulation",2018,"Automation in Construction","96",,,"1","15",,30,"10.1016/j.autcon.2018.08.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052856267&doi=10.1016%2fj.autcon.2018.08.020&partnerID=40&md5=3d990781587b82ec708ca7ac60851335","Department of Construction Engineering, Ecole de Technologie Supérieure, 1100, rue Notre-Dame Ouest, Montréal, Québec  H3C 1K3, Canada","Boton, C., Department of Construction Engineering, Ecole de Technologie Supérieure, 1100, rue Notre-Dame Ouest, Montréal, Québec  H3C 1K3, Canada","Immersive Virtual Reality-based collaborative BIM 4D simulation can offer a unique, supportive environment for conducting constructability analysis meetings in the construction industry. While many research works have addressed various aspects of VR-based 4D simulation, there is still no comprehensive and neutral framework to help both practitioners and experts to identify the main challenges to address. This paper proposes four main complementary steps with which to define the VR environment, to develop the 4D model, to prepare and transfer the model in the VR system and to conduct constructability analysis meeting. In the current state of the framework, the 4D-based constructability analysis is more about the collaborative use of 4D rather than the collaborative generation and interaction with the 4D model. Each step of the framework is supported by appropriate methods and tools. A collaborative personas-based case study helps to evaluate the framework and to show how it can be used. Compared to recent related works, the proposed framework is more structured and comprehensive, providing a structured approach using concepts from multiple scientific areas. © 2018 Elsevier B.V.",,"Architectural design; Construction industry; 4d simulations; Constructability analysis; Immersive virtual reality; Neutral framework; Related works; Structured approach; VR systems; Virtual reality",Article,"Final","",Scopus,2-s2.0-85052856267
"Tarr B., Slater M., Cohen E.","56364689400;7202932472;23968508000;","Synchrony and social connection in immersive Virtual Reality",2018,"Scientific Reports","8","1", 3693,"","",,20,"10.1038/s41598-018-21765-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042744157&doi=10.1038%2fs41598-018-21765-4&partnerID=40&md5=253be66f64014d213e892baff3bf0d41","Institute of Cognitive and Evolutionary Anthropology, University of Oxford, 64 Banbury Rd, Oxford, OX2 6PN, United Kingdom; Department of Experimental Psychology, University of Oxford, South Parks Rd, Oxford, OX 1 3UD, United Kingdom; Institució Catalana de Recerca i Estudis Avançats (ICREA), 23 Passeig de Lluís Companys, Barcelona, 08010, Spain; Faculty of Psychology, University of Barcelona, 171 Passeig de la Vall d'Hebron, Barcelona, 08035, Spain; Department of Computer Science, University College London, Gower Street, London, WC1E 6BT, United Kingdom; Wadham College, Parks Rd, Oxford, OX1 3PN, United Kingdom","Tarr, B., Institute of Cognitive and Evolutionary Anthropology, University of Oxford, 64 Banbury Rd, Oxford, OX2 6PN, United Kingdom, Department of Experimental Psychology, University of Oxford, South Parks Rd, Oxford, OX 1 3UD, United Kingdom; Slater, M., Institució Catalana de Recerca i Estudis Avançats (ICREA), 23 Passeig de Lluís Companys, Barcelona, 08010, Spain, Faculty of Psychology, University of Barcelona, 171 Passeig de la Vall d'Hebron, Barcelona, 08035, Spain, Department of Computer Science, University College London, Gower Street, London, WC1E 6BT, United Kingdom; Cohen, E., Institute of Cognitive and Evolutionary Anthropology, University of Oxford, 64 Banbury Rd, Oxford, OX2 6PN, United Kingdom, Wadham College, Parks Rd, Oxford, OX1 3PN, United Kingdom","Synchronising movements in time with others can have significant positive effects on affiliative attitudes and behaviors. To explore the generalizability of synchrony effects, and to eliminate confounds of suggestion, competence and shared intention typical of standard laboratory and field experiments, we used an Immersive Virtual Reality (VR) environment. Participants, represented as virtual humans, took part in a joint movement activity with two other programmed virtual humans. The timings of the co-participant characters' movements were covertly manipulated to achieve synchrony or non-synchrony with the focal participant. Participants in the synchrony condition reported significantly greater social closeness to their virtual co-participants than those in the non-synchrony condition. Results indicate that synchrony in joint action causes positive social effects and that these effects are robust in a VR setting. The research can potentially inform the development of VR interventions for social and psychological wellbeing. © The Author(s)2018.",,"adult; article; field experiment; human; intimacy; joint function; psychological well-being; virtual reality; adolescent; female; male; questionnaire; social behavior; young adult; Adolescent; Adult; Female; Humans; Male; Social Behavior; Surveys and Questionnaires; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85042744157
"Babaians E., Tamiz M., Sarti Y., Mogoei A., Mehrabi E.","57188707391;55746759800;57211075801;57211074600;55569573500;","ROS2Unity3D; High-performance plugin to interface ROS with unity3d engine",2018,"2018 9th Conference on Artificial Intelligence and Robotics and 2nd Asia-Pacific International Symposium, AIAR 2018",,, 8769798,"59","64",,3,"10.1109/AIAR.2018.8769798","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072559001&doi=10.1109%2fAIAR.2018.8769798&partnerID=40&md5=f2cda416efc765297cb2be81c4c277ae","Tehran Polytechnic, Arsamrobotics Co. LTD., Amirkabir University of Technology, No.424, Hafez AVE, Tehran, Iran","Babaians, E., Tehran Polytechnic, Arsamrobotics Co. LTD., Amirkabir University of Technology, No.424, Hafez AVE, Tehran, Iran; Tamiz, M., Tehran Polytechnic, Arsamrobotics Co. LTD., Amirkabir University of Technology, No.424, Hafez AVE, Tehran, Iran; Sarti, Y., Tehran Polytechnic, Arsamrobotics Co. LTD., Amirkabir University of Technology, No.424, Hafez AVE, Tehran, Iran; Mogoei, A., Tehran Polytechnic, Arsamrobotics Co. LTD., Amirkabir University of Technology, No.424, Hafez AVE, Tehran, Iran; Mehrabi, E., Tehran Polytechnic, Arsamrobotics Co. LTD., Amirkabir University of Technology, No.424, Hafez AVE, Tehran, Iran","In this paper, we propose a novel highperformance method to interface ROS (Robot Operating System) from the Unity3d engine. In this regard, we introduce a message passing middleware to perform decentralized and efficient data transfer. We utilize the ZeroMQ; Google Protobuf and GStreamer libraries to achieve these aims. For evaluation, we compare our approach with state of the art Siemens ROS# U nity3D plugin. On the other hand, we simulate various essential robotic sensors such as LIDAR, RGBD, and Monocular cameras in Unity3D to experiment our solution in complex enough robotic scenarios. As Unity3D support a variety of devices and VR (Virtual Reality) capabilities, this solution may help researchers to perform better human-computer interaction using ROS and Unity3d engine. Besides, for developers who are not familiar with URDF and programming side of ROS Gazebo Sim, this will be a more natural way to exporting their 3D meshes to the Unity3D engine and simulate robotic experiments with ROS. © 2018 IEEE.","Google Protobuf; GStreamer; Robotic Simulation; ROS; Unity3d; ZeroMQ","Data transfer; Engines; Human computer interaction; Message passing; Middleware; Robotics; Virtual reality; Google Protobuf; Gstreamer; Robotic simulation; Unity3d; ZeroMQ; Robot programming",Conference Paper,"Final","",Scopus,2-s2.0-85072559001
"Bourgeois A., Badier E., Baron N., Carruzzo F., Vuilleumier P.","54942986700;57204930250;56258963900;57204933522;57200075380;","Influence of reward learning on visual attention and eye movements in a naturalistic environment: A virtual reality study",2018,"PLoS ONE","13","12", e0207990,"","",,2,"10.1371/journal.pone.0207990","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058002614&doi=10.1371%2fjournal.pone.0207990&partnerID=40&md5=a09fc135a143b758a457603057d5533b","Neuroscience Department, Laboratory for Behavioral Neurology and Imaging of Cognition, University of Geneva, Geneva, Switzerland; Swiss Center for Affective Sciences, University of Geneva-CISA, Geneva, Switzerland","Bourgeois, A., Neuroscience Department, Laboratory for Behavioral Neurology and Imaging of Cognition, University of Geneva, Geneva, Switzerland; Badier, E., Swiss Center for Affective Sciences, University of Geneva-CISA, Geneva, Switzerland; Baron, N., Swiss Center for Affective Sciences, University of Geneva-CISA, Geneva, Switzerland; Carruzzo, F., Neuroscience Department, Laboratory for Behavioral Neurology and Imaging of Cognition, University of Geneva, Geneva, Switzerland; Vuilleumier, P., Neuroscience Department, Laboratory for Behavioral Neurology and Imaging of Cognition, University of Geneva, Geneva, Switzerland","Rewards constitute crucial signals that motivate approach behavior and facilitate the perceptual processing of objects associated with favorable outcomes in past encounters. Reward-related influences on perception and attention have been reliably observed in studies where a reward is paired with a unidimensional low-level visual feature, such as the color or orientation of a line in visual search tasks. However, our environment is drastically different and composed of multidimensional and changing visual features, encountered in complex and dynamic scenes. Here, we designed an immersive virtual reality (VR) experiment using a 4-frame CAVE system to investigate the impact of rewards on attentional orienting and gaze patterns in a naturalistic and ecological environment. Forty-one healthy participants explored a virtual forest and responded to targets appearing on either the left or right side of their path. To test for reward-induced biases in spatial orienting, targets on one side were associated with high reward, whereas those on the opposite side were paired with a low reward. Eye-movements recording showed that left-side high rewards led to subsequent increase of eye gaze fixations towards this side of the path, but no such asymmetry was found after exposure to right-sided high rewards. A milder spatial bias was also observed after left-side high rewards during subsequent exploration of a virtual castle yard, but not during route turn choices along the forest path. Our results indicate that reward-related influences on attention and behavior may be better learned in left than right space, in line with a right hemisphere dominance, and could generalize to another environment to some extent, but not to spatial choices in another decision task, suggesting some domain- or context-specificity. This proof-of-concept study also outlines the advantages and the possible drawbacks of the use of the 3D CAVE immersive platform for VR in neuroscience. © 2018 Bourgeois et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"adult; article; clinical article; controlled study; eye movement; female; forest; gaze; hemispheric dominance; human; human experiment; learning; male; neuroscience; proof of concept; reward; right hemisphere; virtual reality; visual attention; adolescent; anatomy and histology; attention; depth perception; eye fixation; learning; physiology; spatial orientation; Adolescent; Adult; Attention; Cerebrum; Female; Fixation, Ocular; Functional Laterality; Humans; Learning; Male; Orientation, Spatial; Reward; Space Perception; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85058002614
"Van Ma L., Yu G., Kim J.-Y., Won Y., Kim J.","57196123260;57203912139;56526721100;8090706900;14631948300;","An efficient transmission method based on HEVC multi-view adaptive video streaming over P2P network in NFV",2018,"Journal of Supercomputing","74","12",,"6939","6959",,2,"10.1007/s11227-018-2594-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053488828&doi=10.1007%2fs11227-018-2594-0&partnerID=40&md5=2d9e16299aef9c0fb8d525e3e8545881","School of Electronics and Computer Engineering, Chonnam National University, 77, Yongbong-ro, Buk-gu, Gwangju, 500-757, South Korea","Van Ma, L., School of Electronics and Computer Engineering, Chonnam National University, 77, Yongbong-ro, Buk-gu, Gwangju, 500-757, South Korea; Yu, G., School of Electronics and Computer Engineering, Chonnam National University, 77, Yongbong-ro, Buk-gu, Gwangju, 500-757, South Korea; Kim, J.-Y., School of Electronics and Computer Engineering, Chonnam National University, 77, Yongbong-ro, Buk-gu, Gwangju, 500-757, South Korea; Won, Y., School of Electronics and Computer Engineering, Chonnam National University, 77, Yongbong-ro, Buk-gu, Gwangju, 500-757, South Korea; Kim, J., School of Electronics and Computer Engineering, Chonnam National University, 77, Yongbong-ro, Buk-gu, Gwangju, 500-757, South Korea","Researchers and entertainment companies have given lots of attention to virtual reality over the past decade. 3D multi-view is a technology that provides interactions that are similar to those in the real world. However, 3D video streaming has a high data transfer rate because we must transmit multimedia data at a rate several times higher than that used for regular streaming. Besides, network throughput is unstable due to the inherent limitations of network infrastructure, which degrades video streaming quality. Additionally, network failure can occur frequently, causing stalling in multimedia playback. Hence, a network system is required to have more than one backup route in order to successfully guarantee the reliability of a network at all times. Furthermore, in the field of multi-view transmission, not much research has been published that has been conducted in a network virtualization environment. Therefore, we present a study on adaptive-based, high-efficiency video coding with three-dimensional, multi-view streaming over a peer-to-peer network. First, we study adaptive bitrate streaming methods based on high-efficiency video coding. Then we research transmitting multi-view data over a multi-path system. In the experiment, we first record a video from different views using five cameras. Next we merge recorded videos from the five cameras into a file and encode it before transmitting it over the peer-to-peer network. Moreover, we build a virtualized system using Docker virtualization technology and network function virtualization. The results of the experiment show that transmitting high-volume data over a multi-path network channel increases the streaming buffer level, which is about 20% higher than an adaptive streaming 3D method. It also makes the video quality 4% higher than in an HEVC-based adaptive streaming method. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","3D multi-view; Adaptive streaming; CDN; HEVC; Multi-path; NFV; P2P; Video streaming","Cameras; Data communication systems; Data transfer; Data transfer rates; Distributed computer systems; Efficiency; Network function virtualization; Video streaming; Virtual reality; Adaptive streaming; HEVC; High data transfer rates; High-efficiency video coding; Multi-views; Multipaths; Network virtualization environments; Virtualization technologies; Peer to peer networks",Article,"Final","",Scopus,2-s2.0-85053488828
"Deherkar K., Martin G., George N., Maurya V.","55575267000;57206929971;57205293919;57205293847;","Gesture Controlled Virtual Reality Based Conferencing",2018,"2018 International Conference on Smart City and Emerging Technology, ICSCET 2018",,, 8537334,"","",,,"10.1109/ICSCET.2018.8537334","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059411790&doi=10.1109%2fICSCET.2018.8537334&partnerID=40&md5=6aa4b5f07daebc5b4567fca9b157c741","Computer Engineering Department, Don Bosco Institute of Technology, Mumbai, India","Deherkar, K., Computer Engineering Department, Don Bosco Institute of Technology, Mumbai, India; Martin, G., Computer Engineering Department, Don Bosco Institute of Technology, Mumbai, India; George, N., Computer Engineering Department, Don Bosco Institute of Technology, Mumbai, India; Maurya, V., Computer Engineering Department, Don Bosco Institute of Technology, Mumbai, India","The technology available today for interacting with a virtual environment involves wired or wireless hand controls with limited buttons or a large setup involving a camera and/or a sensor to capture movements. The cost of such a setup is such that it makes it inaccessible to most. The project aims at providing a cost effective VR solution which can produce the same effect with precision and flexibility, which is accessible to all. The proposed idea is to provide a hardware device that provides the user with an immersive VR experience and uses hand gestures captured via a camera placed on the device to control and interact with the VR environment. As an application of the project, an interactive workspace environment would be simulated, using a single hardware component that provides the user the viewing interface as well as can be controlled by simple hand gestures eliminating the need for additional hand-held devices controls. The project will also delve into the field of supervised learning to make possible the implementation of gesture recognition. © 2018 IEEE.","File transfer; Gesture Recognition; Hand Gesture Controls; Sensor; Supervised learning; Virtual Reality; VOIP; VR","Cameras; Cost effectiveness; Hardware; Sensors; Smart city; Supervised learning; Virtual reality; Cost effective; File transfers; Hand gesture control; Hand held device; Hardware components; Hardware devices; Interactive workspace; VOIP; Gesture recognition",Conference Paper,"Final","",Scopus,2-s2.0-85059411790
"Van Leeuwen J.P., Hermans K., Jylhä A., Quanjer A.J., Nijman H.","7101943103;57205245949;34881770200;57207729757;57205248742;","Effectiveness of virtual reality in participatory urban planning",2018,"ACM International Conference Proceeding Series",,,,"128","136",,2,"10.1145/3284389.3284491","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062789034&doi=10.1145%2f3284389.3284491&partnerID=40&md5=66845dda78c73dc95036872de2752b7b","Hague University of Applied Sciences, The Hague, Netherlands; Municipality of The Hague, Netherlands; Twynstra and Gudde, Utrecht, Netherlands","Van Leeuwen, J.P., Hague University of Applied Sciences, The Hague, Netherlands; Hermans, K., Municipality of The Hague, Netherlands; Jylhä, A., Hague University of Applied Sciences, The Hague, Netherlands; Quanjer, A.J., Hague University of Applied Sciences, The Hague, Netherlands; Nijman, H., Twynstra and Gudde, Utrecht, Netherlands","In urban planning, 3D modeling and virtual reality (VR) provide new means for involving citizens in the planning process. For municipal government, it is essential to know how effective these means are, to justify investments. In this study, we present a case of using VR in a municipal process of civic participation concerning the redesign of a public park. The process included co-design activities and involved citizens in decision-making through a ballot, using 3D-rendered versions of competing designs. In co-design, 3D-modeling tools were instrumental in empowering citizens to negotiate design decisions, to discuss the quality of designs with experts, and to collectively take decisions. This paper demonstrates that, in a ballot on competing designs with 1302 citizens, VR headsets proved to be equally effective compared to other display technologies in informing citizens during decision making. The results of an additional, controlled experiment indicate that VR headsets provide higher engagement and more vivid memories than viewing the designs on non-immersive displays. By integrating research into a municipal process, we contribute evidence of cognitive and engagement effects of using 3D modeling and immersive VR technologies to empower citizens in participatory urban planning. The case described in the paper concerns a public park; a similar approach could be applied to the design of public installations including media architecture. © 2018 Association for Computing Machinery.","Civic engagement; Participatory design; Urban planning; Virtual reality","Architecture; Decision making; Technology transfer; Urban planning; Virtual reality; 3D modeling tools; Civic engagement; Competing designs; Controlled experiment; Display technologies; Integrating research; Municipal government; Participatory design; 3D modeling",Conference Paper,"Final","",Scopus,2-s2.0-85062789034
"Valdez M.T., Ferreira C.M., Maciel Barbosa F.P.","36006535100;55146902800;6603186154;","Application of Virtual Reality Tools in the Teaching of Concepts in Projects of Fast Loading Stations",2018,"2018 28th EAEEIE Annual Conference, EAEEIE 2018",,, 8534239,"","",,,"10.1109/EAEEIE.2018.8534239","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059042151&doi=10.1109%2fEAEEIE.2018.8534239&partnerID=40&md5=a3e0043e2ff361bd98e544fd3fd729fa","Departamento de Engenharia Eletrotecnica, Coimbra Polytechnic - ISEC, Coimbra, Portugal; Faculdade de Engenharia da Universidade Do Porto and INESC TEC Porto, Departamento de Engenharia Eletrotecnica e de Computadores, Porto, Portugal","Valdez, M.T., Departamento de Engenharia Eletrotecnica, Coimbra Polytechnic - ISEC, Coimbra, Portugal; Ferreira, C.M., Departamento de Engenharia Eletrotecnica, Coimbra Polytechnic - ISEC, Coimbra, Portugal; Maciel Barbosa, F.P., Faculdade de Engenharia da Universidade Do Porto and INESC TEC Porto, Departamento de Engenharia Eletrotecnica e de Computadores, Porto, Portugal","The classroom will always present great challenges to the teachers. It is important to know how to provide learning to a new generation of students and to try to understand how students learn today. Each student arrives at school with a diversity of knowledge resulting from their own life experience, probably divergent from that of their colleagues. On the other hand, the domain of the new Information and Communication Technologies (ICTs) is part of their own experience. The teacher/student relationship is becoming more and digital and, therefore, the limitations of space are more and more reduced. ICTS have greatly altered the way students have access to knowledge, how they share it or how they simply organize the work. Thus, traditional pedagogical strategies and processes must integrate technologies, as a way to apply new work methodologies that value the students' reflection and critical thinking. In return, technology will bring them closer to knowledge, increasing their autonomy and consequent motivation. This work aimed at introducing the topic of sustainable mobility, so that electric vehicles become a growing reality in everyday life. A power generation system was proposed using a grid of photovoltaic panels, which in turn will allow the sustained feeding of a quick charging station. The surplus of electricity produced by the grid of panels can be used to meet the energy needs of a service station. A varied range of software tools were used to address the challenge. This article aims at discussing the use of different software in the educational environment, highlighting the advantages, as well as the difficulties associated with the approach. Several educational software types were used in the final project of a master's degree in ISEC (Instituto Superior de Engenharia de Coimbra). Software tools are an effective way to train students. The use of virtual reality tools in concept teaching of fast charging stations was quite effective in the improvement of students. © 2018 IEEE.","Fast loading stations; Photovoltaic panels; Skelion; Sketch Up; Virtual reality tools","Computer software; E-learning; Electric power transmission networks; Photovoltaic cells; Technology transfer; Virtual reality; Fast loading; Photovoltaic panels; Skelion; Sketch Up; Virtual reality tools; Students",Conference Paper,"Final","",Scopus,2-s2.0-85059042151
"Sun L., Zhou Y., Hansen P., Geng W., Li X.","55492960600;57202023332;8862059000;35205280800;57202025304;","Cross-objects user interfaces for video interaction in virtual reality museum context",2018,"Multimedia Tools and Applications","77","21",,"29013","29041",,4,"10.1007/s11042-018-6091-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046717130&doi=10.1007%2fs11042-018-6091-5&partnerID=40&md5=e8d9ecfa78ebb388228c207d63d520a5","International Design Institute, Zhejiang University, Hangzhou, China; Alibaba-Zhejiang University Joint Institute of Frontier Technologies, Hangzhou, China; Department of Computer Science and Systems, Stockholm University, Kista, Sweden; Department of Digital Media, Zhejiang University, Hangzhou, China","Sun, L., International Design Institute, Zhejiang University, Hangzhou, China; Zhou, Y., International Design Institute, Zhejiang University, Hangzhou, China, Alibaba-Zhejiang University Joint Institute of Frontier Technologies, Hangzhou, China; Hansen, P., Department of Computer Science and Systems, Stockholm University, Kista, Sweden; Geng, W., Department of Digital Media, Zhejiang University, Hangzhou, China; Li, X., Alibaba-Zhejiang University Joint Institute of Frontier Technologies, Hangzhou, China, Department of Digital Media, Zhejiang University, Hangzhou, China","Museums are good places for learning and nowadays many museums are integrating digital media such as video and increasingly moving towards using virtual reality. In the physical world people used to seek information from object surfaces e.g. posters on the wall and this has been used as a metaphor in the virtual reality museum: numerous videos were inhabited within virtual objects and shaped cross-objects user interfaces (COUIs). However, how such interfaces perform for video interactions still needs more investigations. In this study we implemented and investigated COUIs in comparison with the conventional card-style user interfaces and the plain virtual reality user interfaces in the virtual reality museum. The results reported no significant differences in the perceived usability or learning experience between these user interfaces, except the COUIs had a lower level of satisfaction than the card-style user interfaces. However, the COUIs showed greater efficiency with shorter eye fixation durations and higher saccade frequencies, and within these COUIs instances, namely the fully-detached, semi-attached, and fully-attached COUIs, the fully-attached instance was closest to the form of interacting with physical object surfaces and it reported highest efficiency as well. Rationales behind these results and implications generalising for the future design of COUIs, are discussed. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Cross-objects user interfaces; Museum learning experience; Perceived usability; Video interaction; Virtual reality museum","Digital storage; Efficiency; Virtual reality; Future designs; Learning experiences; Level of satisfaction; Museum learning; Perceived usability; Physical objects; Video interactions; Virtual objects; User interfaces",Article,"Final","",Scopus,2-s2.0-85046717130
"Saadatzi M.N., Pennington R.C., Welch K.C., Graham J.H.","36642836100;35275756900;37662476200;22234453000;","Small-Group Technology-Assisted Instruction: Virtual Teacher and Robot Peer for Individuals with Autism Spectrum Disorder",2018,"Journal of Autism and Developmental Disorders","48","11",,"3816","3830",,13,"10.1007/s10803-018-3654-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048787004&doi=10.1007%2fs10803-018-3654-2&partnerID=40&md5=d5853c28c780b6a5dad1df59c573f29c","Department of Electrical and Computer Engineering, University of Louisville, Louisville, KY  40292, United States; Department of Special Education and Child Development, University of North Carolina at Charlotte, Charlotte, NC, United States","Saadatzi, M.N., Department of Electrical and Computer Engineering, University of Louisville, Louisville, KY  40292, United States; Pennington, R.C., Department of Special Education and Child Development, University of North Carolina at Charlotte, Charlotte, NC, United States; Welch, K.C., Department of Electrical and Computer Engineering, University of Louisville, Louisville, KY  40292, United States; Graham, J.H., Department of Electrical and Computer Engineering, University of Louisville, Louisville, KY  40292, United States","The authors combined virtual reality technology and social robotics to develop a tutoring system that resembled a small-group arrangement. This tutoring system featured a virtual teacher instructing sight words, and included a humanoid robot emulating a peer. The authors used a multiple-probe design across word sets to evaluate the effects of the instructional package on the explicit acquisition and vicarious learning of sight words instructed to three children with autism spectrum disorder (ASD) and the robot peer. Results indicated that participants acquired, maintained, and generalized 100% of the words explicitly instructed to them, made fewer errors while learning the words common between them and the robot peer, and vicariously learned 94% of the words solely instructed to the robot. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Autism spectrum disorder; Observational learning; Sight word instruction; Small-group instruction; Social robotics; Virtual reality and pedagogical agents","Article; autism; case report; child; clinical article; error; human; learning; male; preschool child; priority journal; robotics; school child; teacher; technology; virtual reality; word recognition; autism; education; peer group; procedures; psychology; randomization; robotics; teaching; Autism Spectrum Disorder; Child; Computer-Assisted Instruction; Education, Special; Humans; Male; Peer Group; Random Allocation; Robotics",Article,"Final","",Scopus,2-s2.0-85048787004
"Supančič J.S., III, Rogez G., Yang Y., Shotton J., Ramanan D.","55924622700;23398276500;57218495715;23019722900;6506835622;","Depth-Based Hand Pose Estimation: Methods, Data, and Challenges",2018,"International Journal of Computer Vision","126","11",,"1180","1198",,25,"10.1007/s11263-018-1081-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045261450&doi=10.1007%2fs11263-018-1081-7&partnerID=40&md5=78afd9622b2219c4f6455006c57b650b","University of California, Irvine, United States; Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP*, LJK, Grenoble, 38000, France; Institute of Engineering Univ., Grenoble Alpes, France; Baidu Institute of Deep Learning, Sunnyvale, United States; Microsoft Research, Cambridge, United Kingdom; Carnegie Mellon University, Pittsburgh, PA, United States","Supančič, J.S., III, University of California, Irvine, United States; Rogez, G., Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP*, LJK, Grenoble, 38000, France, Institute of Engineering Univ., Grenoble Alpes, France; Yang, Y., Baidu Institute of Deep Learning, Sunnyvale, United States; Shotton, J., Microsoft Research, Cambridge, United Kingdom; Ramanan, D., Carnegie Mellon University, Pittsburgh, PA, United States","Hand pose estimation has matured rapidly in recent years. The introduction of commodity depth sensors and a multitude of practical applications have spurred new advances. We provide an extensive analysis of the state-of-the-art, focusing on hand pose estimation from a single depth frame. To do so, we have implemented a considerable number of systems, and have released software and evaluation code. We summarize important conclusions here: (1) Coarse pose estimation appears viable for scenes with isolated hands. However, high precision pose estimation [required for immersive virtual reality and cluttered scenes (where hands may be interacting with nearby objects and surfaces) remain a challenge. To spur further progress we introduce a challenging new dataset with diverse, cluttered scenes. (2) Many methods evaluate themselves with disparate criteria, making comparisons difficult. We define a consistent evaluation criteria, rigorously motivated by human experiments. (3) We introduce a simple nearest-neighbor baseline that outperforms most existing systems. This implies that most systems do not generalize beyond their training sets. This also reinforces the under-appreciated point that training data is as important as the model itself. We conclude with directions for future progress. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Benchmarking; Datasets; Hand pose; RGB-D sensor","Artificial intelligence; Benchmarking; Software engineering; Datasets; Evaluation criteria; Hand pose; Hand pose estimations; Immersive virtual reality; Nearest neighbors; Rgb-d sensors; State of the art; Virtual reality",Article,"Final","",Scopus,2-s2.0-85045261450
"Morrongiello B.A., Corbett M., Beer J., Koutsoulianos S.","7005908503;14031185400;57191228993;57204440464;","A pilot randomized controlled trial testing the effectiveness of a pedestrian training program that teaches children where and how to cross the street safely",2018,"Journal of Pediatric Psychology","43","10",,"1147","1159",,4,"10.1093/jpepsy/jsy056","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055596602&doi=10.1093%2fjpepsy%2fjsy056&partnerID=40&md5=74d1641d4809e67e8c0ab26ff335b2da","Department of Psychology, University of Guelph, Canada; Department of Pscyhology, University of Guelph, Mackinnon Building Extension, Guelph, ON  N1G 2W1, Canada","Morrongiello, B.A., Department of Pscyhology, University of Guelph, Mackinnon Building Extension, Guelph, ON  N1G 2W1, Canada; Corbett, M., Department of Psychology, University of Guelph, Canada; Beer, J., Department of Psychology, University of Guelph, Canada; Koutsoulianos, S., Department of Psychology, University of Guelph, Canada","Objective: Pedestrian injury is a leading cause of injury-related mortality for children. This pilot randomized controlled trial tested the efficacy of a training program to teach where and how to cross safely. Methods: Using fully immersive virtual reality technology, 142 children 7-10 years of age were recruited, with 130 completing crossing measures before (pretest) and immediately after (posttest) training. Training comprised 1.5 hr, was tailored to each child's performance over trials, and focused on either where to cross (n = 44 children completed testing) or how to cross safely (n = 43); corresponding control groups comprised 22 and 21 children, respectively. Following training, children in the intervention groups completed additional tasks to test conceptual knowledge and generalization of learning. Children in the control groups spent the same time as those in training groups but played a video game that used the same game controller but provided no training in street crossing. Results: The primary outcomes were errors in crossing at posttest, controlling for pretest error scores. Children in the intervention group made from 75% to 98% fewer errors at posttest than control children for all pedestrian safety variables related to where and how to cross safely, with effect sizes (incidence rate ratios) varying between 0.02 and 0.25. They also showed a generalization of what they had learned and applied this knowledge to novel posttraining situations. Conclusion: Training within a virtual pedestrian environment can successfully improve children's conceptual understanding and crossing behaviors for both where and how to cross streets safely. © The Author(s) 2018. Published by Oxford University Press on behalf of the Society of Pediatric Psychology.","Behavioral training; Children; Pedestrian; Virtual reality","child; controlled study; education; female; human; male; pedestrian; pilot study; prevention and control; procedures; program evaluation; randomized controlled trial; safety; traffic accident; virtual reality; walking; Accidents, Traffic; Child; Female; Humans; Male; Pedestrians; Pilot Projects; Program Evaluation; Safety; Virtual Reality; Walking",Article,"Final","",Scopus,2-s2.0-85055596602
"Szczurowski K., Smith M.","57202899868;57196078717;","'Woodlands'-A Virtual Reality Serious Game Supporting Learning of Practical Road Safety Skills",2018,"2018 IEEE Games, Entertainment, Media Conference, GEM 2018",,, 8516493,"427","435",,6,"10.1109/GEM.2018.8516493","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057030782&doi=10.1109%2fGEM.2018.8516493&partnerID=40&md5=ad57ac1f8e24833e90e1f57db49254f1","Department of Informatics, Institute of Technology Blanchardstown, Dublin, Ireland","Szczurowski, K., Department of Informatics, Institute of Technology Blanchardstown, Dublin, Ireland; Smith, M., Department of Informatics, Institute of Technology Blanchardstown, Dublin, Ireland","In developed societies road safety skills are taught early and often practiced under the supervision of a parent, providing children with a combination of theoretical and practical knowledge. At some point children will attempt to cross a road unsupervised, at that point in time their safety depends on the effectiveness of their road safety education. To date, various attempts to supplement road safety education with technology were made. Most common approach focus on addressing declarative knowledge, by delivering road safety theory in an engaging fashion. Apart from expanding on text based resources to include instructional videos and animations, some stakeholders (e.g.: Irish Road Safety Authority) attempt to take advantage of game-based learning [1]. However, despite the high capacity for interaction being common in Virtual Environments, available game-based solutions to road safety education are currently limited to delivering and assessing declarative knowledge. With recent advancements in the field of Virtual Reality (VR) Head Mounted Displays, procedural knowledge might also be addressed in Virtual Environments. This paper describes the design and development process of a computer-supported learning system that attempts to address psycho-motor skills involved in crossing a road safely, changing learners' attitude towards road safety best practices, and enabling independent practice of transferable skills. By implementing game-based learning principles and following best practice for serious game design (such as making educational components essential to successful game-play, or instructional scaffolding) we hope to make it not only more effective, but also engaging, allowing us to rely on learners' intrinsic motivation [2], to increase their independent practice time and provide them with feedback that will help to condition safe behaviour and increase retention. Presence in Virtual Reality might evoke responses to Virtual Environment as if it was real (RAIR) [3] and enable learners to truly experience learning scenarios. In consequence leading to formation of autobiographical memories constructed from multisensory input, which should result in an increased knowledge retention and transfer [4]. © 2018 IEEE.","Experiential Learning; Game-Based Learning; Road Safety; Serious Game; Virtual Environment; Virtual Reality; VR","Accident prevention; Animation; E-learning; Education computing; Helmet mounted displays; Learning systems; Motor transportation; Roads and streets; Scaffolds; Virtual reality; Autobiographical memory; Computer supported learning systems; Declarative knowledge; Design and development process; Experiential learning; Game-based Learning; Head mounted displays; Road safety; Serious games",Conference Paper,"Final","",Scopus,2-s2.0-85057030782
"Krekhov A., Krüger J., Cmentowski S.","41761856000;42761557200;57197770288;","VR animals: Surreal body ownership in virtual reality games",2018,"CHI PLAY 2018 - Proceedings of the 2018 Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts",,,,"503","511",,7,"10.1145/3270316.3271531","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058482003&doi=10.1145%2f3270316.3271531&partnerID=40&md5=ad8f33934d960d9672b9af89e5fd61db","University of Duisburg-Essen, Duisburg, 47057, Germany","Krekhov, A., University of Duisburg-Essen, Duisburg, 47057, Germany; Krüger, J., University of Duisburg-Essen, Duisburg, 47057, Germany; Cmentowski, S., University of Duisburg-Essen, Duisburg, 47057, Germany","The illusion of being someone else and to perceive a virtual body as our own is one of the strengths of virtual reality setups. Past research explored that phenomenon regarding human-like virtual representations. In contrast, our ongoing work focuses on playing VR games in the role of an animal. We present five ways to control three different animals in a VR environment. The controls range from third person companion mode to first person full-body tracking. Our exploratory study indicates that virtual body ownership is also applicable to animals, which paves the way to a number of novel, animal-centered game mechanics. Based on interview outcomes, we also discuss possible directions for further research regarding non-humanoid VR experiences in digital games. © 2018 Copyright is held by the owner/author(s).","Animal avatar control; Animal embodiment; Body transfer illusion; Virtual body ownership; Virtual reality games","Animals; Human computer interaction; Interactive computer graphics; Interactive computer systems; Body transfer illusion; Digital games; Exploratory studies; First person; Full-body tracking; Human like; Virtual bodies; Virtual representations; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85058482003
"Brouwer A.-M., van der Waa J., Stokking H.","7102575587;57193858656;25032071700;","BCI to potentially enhance streaming images to a VR headset by predicting head rotation",2018,"Frontiers in Human Neuroscience","12",, 420,"","",,1,"10.3389/fnhum.2018.00420","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056811876&doi=10.3389%2ffnhum.2018.00420&partnerID=40&md5=51b5275784df9bd4315f22469dfaa8f4","Department of Perceptual and Cognitive Systems, Netherlands Organization for Applied Scientific Research (TNO), Soesterberg, Netherlands; Department of Media Networking, Netherlands Organization for Applied Scientific Research (TNO), Den Haag, Netherlands","Brouwer, A.-M., Department of Perceptual and Cognitive Systems, Netherlands Organization for Applied Scientific Research (TNO), Soesterberg, Netherlands; van der Waa, J., Department of Perceptual and Cognitive Systems, Netherlands Organization for Applied Scientific Research (TNO), Soesterberg, Netherlands; Stokking, H., Department of Media Networking, Netherlands Organization for Applied Scientific Research (TNO), Den Haag, Netherlands","While numerous studies show that brain signals contain information about an individual’s current state that are potentially valuable for smoothing man–machine interfaces, this has not yet lead to the use of brain computer interfaces (BCI) in daily life. One of the main challenges is the common requirement of personal data that is correctly labeled concerning the state of interest in order to train a model, where this trained model is not guaranteed to generalize across time and context. Another challenge is the requirement to wear electrodes on the head. We here propose a BCI that can tackle these issues and may be a promising case for BCI research and application in everyday life. The BCI uses EEG signals to predict head rotation in order to improve images presented in a virtual reality (VR) headset. When presenting a 360° video to a headset, field-of-view approaches only stream the content that is in the current field of view and leave out the rest. When the user rotates the head, other content parts need to be made available soon enough to go unnoticed by the user, which is problematic given the available bandwidth. By predicting head rotation, the content parts adjacent to the currently viewed part could be retrieved in time for display when the rotation actually takes place. We here studied whether head rotations can be predicted on the basis of EEG sensor data and if so, whether application of such predictions could be applied to improve display of streaming images. Eleven participants generated left- and rightward head rotations while head movements were recorded using the headsets motion sensing system and EEG. We trained neural network models to distinguish EEG epochs preceding rightward, leftward, and no rotation. Applying these models to streaming EEG data that was withheld from the training showed that 400 ms before rotation onset, the probability “no rotation” started to decrease and the probabilities of an upcoming right- or leftward rotation started to diverge in the correct direction. In the proposed BCI scenario, users already wear a device on their head allowing for integrated EEG sensors. Moreover, it is possible to acquire accurately labeled training data on the fly, and continuously monitor and improve the model’s performance. The BCI can be harnessed if it will improve imagery and therewith enhance immersive experience. © 2018 Brouwer, van der Waa and Stokking.","Applied neuroscience; Brain computer interface; EEG; Head mounted display; Head rotation; Movement prediction; Neuroadaptive technology; Virtual reality","adult; Article; artificial neural network; brain computer interface; electroencephalography; head movement; human; human experiment; image display; image processing; imagery; normal human; prediction; probability; signal transduction; videorecording; virtual reality",Article,"Final","",Scopus,2-s2.0-85056811876
"Škola F., Liarokapis F.","57189368470;7801416785;","Embodied VR environment facilitates motor imagery brain–computer interface training",2018,"Computers and Graphics (Pergamon)","75",,,"59","71",,12,"10.1016/j.cag.2018.05.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049323107&doi=10.1016%2fj.cag.2018.05.024&partnerID=40&md5=561e34077968d8ba1953764e02e33b25","Faculty of Informatics, Masaryk University, Botanická 68a, Brno, Czech Republic","Škola, F., Faculty of Informatics, Masaryk University, Botanická 68a, Brno, Czech Republic; Liarokapis, F., Faculty of Informatics, Masaryk University, Botanická 68a, Brno, Czech Republic","Motor imagery (MI) is the predominant control paradigm for brain–computer interfaces (BCIs). After sufficient effort is invested to the training, the accuracy of commands mediated by mental imagery of bodily movements grows to a satisfactory level. However, many issues with the MI-BCIs persist; e.g., low bit transfer rate, BCI illiteracy, sub-optimal training procedure. Especially the training process for the MI-BCIs requires improvements. Currently, the training has an inappropriate form, resulting in a high mental and temporal demand on the users (weeks of training are required for the control). This study aims at addressing the issues with the MI-BCI training. To support the learning process, an embodied training environment was created. Participants were placed into a virtual reality environment observed from a first-person view of a human-like avatar, and their rehearsal of MI actions was reflected by the corresponding movements performed by the avatar. Leveraging extension of the sense of ownership, agency, and self-location towards a non-body object (principles known from the rubber hand illusion and the body transfer illusions) has already been proven to help in producing stronger EEG correlates of MI. These principles were used to facilitate the MI-BCI training process for the first time. Performance of 30 healthy participants after two sessions of training was measured using an on-line BCI scenario. The group trained using our embodied VR environment gained significantly higher average accuracy for BCI actions (58.3%) than the control group, trained with a standard MI-BCI training protocol (52.9%). © 2018 Elsevier Ltd","Body transfer illusion; Brain–Computer interfaces; Embodiment; Motor imagery; Rubber hand illusion; Virtual reality","Interfaces (computer); Rubber; Virtual reality; Bit transfer rates; Body transfer illusion; Embodiment; Learning process; Motor imagery; Optimal training; Predominant control; Virtual-reality environment; Brain computer interface",Article,"Final","",Scopus,2-s2.0-85049323107
"Peterson S.M., Rios E., Ferris D.P.","57194682956;57203844599;35236545200;","Transient visual perturbations boost short-term balance learning in virtual reality by modulating electrocortical activity",2018,"Journal of Neurophysiology","120","4",,"1998","2010",,12,"10.1152/jn.00292.2018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054775411&doi=10.1152%2fjn.00292.2018&partnerID=40&md5=6bb8b6acedd0dbcf8cee246dcfe15e9e","Department of Biomedical Engineering, School of Engineering, University of Michigan, Ann Arbor, MI, United States; J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, Gainesville, FL, United States","Peterson, S.M., Department of Biomedical Engineering, School of Engineering, University of Michigan, Ann Arbor, MI, United States; Rios, E., Department of Biomedical Engineering, School of Engineering, University of Michigan, Ann Arbor, MI, United States; Ferris, D.P., J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, Gainesville, FL, United States","Immersive virtual reality can expose humans to novel training and sensory environments, but motor training with virtual reality has not been able to improve motor performance as much as motor training in real-world conditions. An advantage of immersive virtual reality that has not been fully leveraged is that it can introduce transient visual perturbations on top of the visual environment being displayed. The goal of this study was to determine whether transient visual perturbations introduced in immersive virtual reality modify electrocortical activity and behavioral outcomes in human subjects practicing a novel balancing task during walking. We studied three groups of healthy young adults (5 male and 5 female for each) while they learned a balance beam walking task for 30 min under different conditions. Two groups trained while wearing a virtual reality headset, and one of those groups also had half-second visual rotation perturbations lasting ~10% of the training time. The third group trained without virtual reality. We recorded high-density electroencephalography (EEG) and movement kinematics. We hypothesized that virtual reality training with perturbations would increase electrocortical activity and improve balance performance compared with virtual reality training without perturbations. Our results confirmed the hypothesis. Brief visual perturbations induced increased theta spectral power and decreased alpha spectral power in parietal and occipital regions and improved balance performance in posttesting. Our findings indicate that transient visual perturbations during immersive virtual reality training can boost short-term motor learning by inducing a cognitive change, minimizing the negative effects of virtual reality on motor training. NEW & NOTEWORTHY We found that transient visual perturbations in virtual reality during balance training can boost short-term motor learning by inducing a cognitive change, overcoming the negative effects of immersive virtual reality. As a result, subjects training in immersive virtual reality with visual perturbations have equivalent performance improvement as training in real-world conditions. Visual perturbations elicited cortical responses in occipital and parietal regions and may have improved the brain’s ability to adapt to variations in sensory input. © 2018 American Physiological Society. All rights reserved.","Adaptive generalization; Balance training; Electroencephalography; Motor learning; Virtual reality","adult; article; case report; clinical article; electroencephalography; female; human; human experiment; kinematics; male; motor learning; occipital cortex; rotation; sensory stimulation; virtual reality; walking; young adult",Article,"Final","",Scopus,2-s2.0-85054775411
"Jimenez Y.A., Wang W., Stuart K., Cumming S., Thwaites D., Lewis S.","36664582700;7501760667;12773566600;7004353703;7006384833;35478819000;","Breast Cancer Patients’ Perceptions of a Virtual Learning Environment for Pretreatment Education",2018,"Journal of Cancer Education","33","5",,"983","990",,4,"10.1007/s13187-017-1183-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012191640&doi=10.1007%2fs13187-017-1183-x&partnerID=40&md5=8d5650ad6f0b2594825c7973e5d01c8f","Faculty of Health Sciences, The University of Sydney, Lidcombe, NSW, Australia; The Crown Princess Mary Cancer Centre, Westmead Hospital, Westmead, NSW, Australia; School of Physics, The University of Sydney, Sydney, NSW, Australia","Jimenez, Y.A., Faculty of Health Sciences, The University of Sydney, Lidcombe, NSW, Australia; Wang, W., The Crown Princess Mary Cancer Centre, Westmead Hospital, Westmead, NSW, Australia; Stuart, K., The Crown Princess Mary Cancer Centre, Westmead Hospital, Westmead, NSW, Australia; Cumming, S., Faculty of Health Sciences, The University of Sydney, Lidcombe, NSW, Australia; Thwaites, D., School of Physics, The University of Sydney, Sydney, NSW, Australia; Lewis, S., Faculty of Health Sciences, The University of Sydney, Lidcombe, NSW, Australia","The process and technicalities of radiation therapy (RT) for cancer treatment can be challenging for patients to understand as RT involves complex procedures, highly specialised equipment, and radiation itself has limited sensory characteristics. Hence, it is imperative that education programs are specifically planned and developed to suit the needs of patients, address radiation as an entity and include salient visual aids. In this context, the Virtual Environment for Radiotherapy Training (VERT) system, primarily created for RT practitioner simulation, may provide unique opportunities for patient education. This article reports on patient feedback of a newly developed breast cancer patient education program, which integrates the VERT system as the focal education tool. The education program content included RT immobilisation, simulation, planning and treatment components, along with an introduction to the VERT system. Nineteen breast cancer patients (n = 19) completed an evaluation questionnaire at the completion of their VERT education program. Open-ended questions were used to detect the least and most useful aspects of the education session. Patient feedback indicated a high regard for the comprehensiveness of the education program, with particular acknowledgement of the three dimensional visual features of the VERT system. It is proposed that VERT’s high visual impact should be exploited in tailored patient education programs in order to obtain maximum patient engagement and make significant gains in effective knowledge transfer. © 2017, American Association for Cancer Education.","Breast cancer; Patient education; Radiation therapy; VERT","adult; aged; audiovisual aid; breast tumor; computer interface; female; human; middle aged; patient education; patient satisfaction; procedures; psychology; Adult; Aged; Audiovisual Aids; Breast Neoplasms; Female; Humans; Middle Aged; Patient Education as Topic; Patient Satisfaction; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-85012191640
"Narbutt M., Allen A., Skoglund J., Chinen M., Hines A.","14830442200;57195237656;7004049754;56556720800;35179621200;","AMBIQUAL-A full reference objective quality metric for ambisonic spatial audio",2018,"2018 10th International Conference on Quality of Multimedia Experience, QoMEX 2018",,, 8463408,"","",,12,"10.1109/QoMEX.2018.8463408","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054367108&doi=10.1109%2fQoMEX.2018.8463408&partnerID=40&md5=3b3e686e001f1dd456d15a0af3758001","School of Computing, Dublin Institute of Technology, Dublin, Ireland; Google Inc., San Francisco, CA, United States; School of Computer Science, University College Dublin, Dublin, Ireland","Narbutt, M., School of Computing, Dublin Institute of Technology, Dublin, Ireland; Allen, A., Google Inc., San Francisco, CA, United States; Skoglund, J., Google Inc., San Francisco, CA, United States; Chinen, M., Google Inc., San Francisco, CA, United States; Hines, A., School of Computer Science, University College Dublin, Dublin, Ireland","Streaming spatial audio over networks requires efficient encoding techniques that compress the raw audio content without compromising quality of experience. Streaming service providers such as YouTube need a perceptually relevant objective audio quality metric to monitor users' perceived quality and spatial localization accuracy. In this paper we introduce a full reference objective spatial audio quality metric, AMBIQUAL, which assesses both Listening Quality and Localization Accuracy. In our solution both metrics are derived directly from the B-format Ambisonic audio. The metric extends and adapts the algorithm used in ViSQOLAudio, a full reference objective metric designed for assessing speech and audio quality. In particular, Listening Quality is derived from the omnidirectional channel and Localization Accuracy is derived from a weighted sum of similarity from B-format directional channels. This paper evaluates whether the proposed AMBIQUAL objective spatial audio quality metric can predict two factors: Listening Quality and Localization Accuracy by comparing its predictions with results from MUSHRA subjective listening tests. In particular, we evaluated the Listening Quality and Localization Accuracy of First and Third-Order Ambisonic audio compressed with the OPUS 1.2 codec at various bitrates (i.e. 32, 128 and 256, 512kbps respectively). The sample set for the tests comprised both recorded and synthetic audio clips with a wide range of time-frequency characteristics. To evaluate Localization Accuracy of compressed audio a number of fixed and dynamic (moving vertically and horizontally) source positions were selected for the test samples. Results showed a strong correlation (PCC=0.919; Spearman=0.882 regarding Listening Quality and PCC=0.854; Spearman=0.842 regarding Localization Accuracy) between objective quality scores derived from the B-format Ambisonic audio using AMBIQUAL and subjective scores obtained during listening MUSHRA tests. AMBIQUAL displays very promising quality assessment predictions for spatial audio. Future work will optimise the algorithm to generalise and validate it for any Higher Order Ambisonic formats. © 2018 IEEE.","ambisonics; audio coding; audio compression; MUSHRA; opus codec; spatial audio; virtual reality",,Conference Paper,"Final","",Scopus,2-s2.0-85054367108
"DeForest C.A., Blackman V., Alex J.E., Reeves L., Mora A., Perez C., Maddry J., Selby D., Walrath B.","57210955716;15753672100;57201637945;57189590306;26655909200;57189592178;57210349889;57210961004;6504107934;","An Evaluation of Navy En Route Care Training Using a High-Fidelity Medical Simulation Scenario of Interfacility Patient Transport",2018,"Military medicine","183","9-10",,"e383","e391",,,"10.1093/milmed/usx129","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072020042&doi=10.1093%2fmilmed%2fusx129&partnerID=40&md5=529ef11efc126bc644dd8d49ea2c9be5","Department of Emergency Medicine, Naval Medical Center Camp Lejeune, Jacksonville, United States; Daniel K. Inouye Graduate School of Nursing, Uniform Services University of Health Sciences, Bldg E, Rm 2044, MD, 4301 Jones Bridge Road, Bethesda, United States; Department of Emergency Medicine, United States Naval Hospital Okinawa, Okinawa Prefecture 901-2203, Ginowan, Japan; Air Force En route Care Research Center, JBSA, TX, 59th Medical Wing/Surgical Operations Group/U.S. Institute of Surgical Research ,3698 Chambers Pass STE BFT Sam Houston; 1st Medical Battalion, 1st Marine Logistics Group, Bldg 22164, Camp Pendleton, CA, Italy; Department of Emergency Medicine, Naval Medical Center San Diego, 34800 Bob Wilson Dr, San Diego, CA","DeForest, C.A., Department of Emergency Medicine, Naval Medical Center Camp Lejeune, Jacksonville, United States; Blackman, V., Daniel K. Inouye Graduate School of Nursing, Uniform Services University of Health Sciences, Bldg E, Rm 2044, MD, 4301 Jones Bridge Road, Bethesda, United States; Alex, J.E., Department of Emergency Medicine, United States Naval Hospital Okinawa, Okinawa Prefecture 901-2203, Ginowan, Japan; Reeves, L., Air Force En route Care Research Center, JBSA, TX, 59th Medical Wing/Surgical Operations Group/U.S. Institute of Surgical Research ,3698 Chambers Pass STE BFT Sam Houston; Mora, A., Air Force En route Care Research Center, JBSA, TX, 59th Medical Wing/Surgical Operations Group/U.S. Institute of Surgical Research ,3698 Chambers Pass STE BFT Sam Houston; Perez, C., Air Force En route Care Research Center, JBSA, TX, 59th Medical Wing/Surgical Operations Group/U.S. Institute of Surgical Research ,3698 Chambers Pass STE BFT Sam Houston; Maddry, J., Air Force En route Care Research Center, JBSA, TX, 59th Medical Wing/Surgical Operations Group/U.S. Institute of Surgical Research ,3698 Chambers Pass STE BFT Sam Houston; Selby, D., 1st Medical Battalion, 1st Marine Logistics Group, Bldg 22164, Camp Pendleton, CA, Italy; Walrath, B., Department of Emergency Medicine, Naval Medical Center San Diego, 34800 Bob Wilson Dr, San Diego, CA","INTRODUCTION: Military prehospital and en route care (ERC) directly impacts patient morbidity and mortality. Provider knowledge and skills are critical variables in the effectiveness of ERC. No Navy doctrine defines provider choice for patient transport or requires standardized provider training. Frequently, Search and Rescue Medical Technicians (SMTs) and Navy Nurses (ERC RNs) are tasked with this mission though physicians have also been used. Navy ERC provider training varies greatly by professional role. Historically, evaluations of ERC and patient outcomes have been based on retrospective analyses of incomplete data sets that provide limited insight on ERC practices. Little evidence exists to determine if current training is adequate to care for the most common injuries seen in combat trauma patients. MATERIALS AND METHODS: Simulation technology facilitates a standardized patient encounter to enable complete, prospective data collection while studying provider type as the independent variable. Information acquired through skill performance observation can be used to make evidence-based recommendations to improve ERC training. This IRB approved multi-center study funded through a Congressionally Directed Medical Research Program grant from the Combat Casualty Care Intramural Research Joint En Route Care portfolio evaluated Navy ERC providers. The study evaluated 84 SMT, ERC RN, and physician participants in the performance of critical and secondary actions during an immersive, high-fidelity, patient transport simulation scenario focused on the care during an interfacility transfer. Simulation evaluators with military ERC expertise, blinded to participant training and background, graded each participant's performance. Inter-rater reliability was calculated using Cohen's Kappa to evaluate concordance between evaluator assessments. Categorical data were reported as frequencies and percentages. Performance attempt and accuracy rates were compared with likelihood ratio chi-square or Fisher's exact test where appropriate. Tests were two-tailed and we considered results significant, that is, a difference not likely due to chance exists between groups, if p < 0.05. Confidence intervals were used to present overlap in performance between provider types. RESULTS: Critical and secondary actions were assessed. A majority of providers completed at least one of the critical life-saving actions; only one participant completed all critical actions. Evaluation of critical actions demonstrated that a tourniquet was applied by 64% of providers, blood products administered by 46%, needle decompression performed by 51%, and a complete handoff report performed by 48%. Assessment of secondary actions demonstrated analgesic was accurately administered by 24% of all providers, and 44% reinforced the ""hemorrhaging amputation site dressing."" CONCLUSION: Over 98% of participants failed to properly perform all critical actions during the interfacility transfer scenario, which in a real-life combat casualty transport scenario could result in a preventable death. Study results demonstrate serious skill deficits among all types of Navy ERC providers. These data can be used to improve the training of Navy ERC providers, ultimately improving care to injured soldiers, sailors, airmen, and marines. Published by Oxford University Press on behalf of the Association of Military Surgeons of the United States 2018.","aeromedical evacuation; combat casualty care; critical care transport; en route care; military medicine","aerospace medicine; chi square distribution; clinical competence; education; emergency health service; human; patient simulation; patient transport; procedures; program evaluation; prospective study; simulation training; soldier; Aerospace Medicine; Chi-Square Distribution; Clinical Competence; Educational Measurement; Emergency Medical Services; Humans; Military Personnel; Patient Simulation; Patient Transfer; Program Evaluation; Prospective Studies; Simulation Training",Article,"Final","",Scopus,2-s2.0-85072020042
"Grubert J., Witzani L., Ofek E., Pahud M., Kranz M., Kristensson P.O.","35114754100;56024891600;10139546600;6602493330;12239425600;6507412583;","Text Entry in Immersive Head-Mounted Display-Based Virtual Reality Using Standard Keyboards",2018,"25th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2018 - Proceedings",,, 8446059,"159","166",,41,"10.1109/VR.2018.8446059","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053830754&doi=10.1109%2fVR.2018.8446059&partnerID=40&md5=751e12a3f39023107cd2837e1c6effd0","Coburg University of Applied Sciences and Arts, Germany; University of Passau, Germany; Microsoft Research, Germany; University of Cambridge, United Kingdom","Grubert, J., Coburg University of Applied Sciences and Arts, Germany; Witzani, L., University of Passau, Germany; Ofek, E., Microsoft Research, Germany; Pahud, M., Coburg University of Applied Sciences and Arts, Germany; Kranz, M., Coburg University of Applied Sciences and Arts, Germany; Kristensson, P.O., University of Cambridge, United Kingdom","We study the performance and user experience of two popular mainstream text entry devices, desktop keyboards and touchscreen keyboards, for use in Virtual Reality (VR) applications. We discuss the limitations arising from limited visual feedback, and examine the efficiency of different strategies of use. We analyze a total of 24 hours of typing data in VR from 24 participants and find that novice users are able to retain about 60% of their typing speed on a desktop keyboard and about 40-45% of their typing speed on a touchscreen keyboard. We also find no significant learning effects, indicating that users can transfer their typing skills fast into VR. Besides investigating baseline performances, we study the position in which keyboards and hands are rendered in space. We find that this does not adversely affect performance for desktop keyboard typing and results in a performance trade-off for touchscreen keyboard typing. © 2018 IEEE.","H.5.2: [User Interfaces-Input devices and strategies.]","Economic and social effects; Helmet mounted displays; Typewriter keyboards; Virtual reality; Visual communication; Base-line performance; Head mounted displays; Input devices and strategies; Learning effects; Performance trade-off; Touch-screen keyboards; User experience; Visual feedback; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-85053830754
"Krum D.M., Kang S.-H., Phan T.","6701630874;22835064900;55869140500;","Influences on the Elicitation of Interpersonal Space with Virtual Humans",2018,"25th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2018 - Proceedings",,, 8446235,"223","229",,1,"10.1109/VR.2018.8446235","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053822218&doi=10.1109%2fVR.2018.8446235&partnerID=40&md5=efee792ec391075882d1fad42a20ac03","University of Southern California, Institute for Creative Technologies, United States","Krum, D.M., University of Southern California, Institute for Creative Technologies, United States; Kang, S.-H., University of Southern California, Institute for Creative Technologies, United States; Phan, T., University of Southern California, Institute for Creative Technologies, United States","The emergence of low cost virtual and augmented reality systems has encouraged the development of immersive training applications for medical, military, and many other fields. Many of the training scenarios for these various fields may require the presentation of realistic interactions with virtual humans. It is thus vital to determine the critical factors of fidelity required in those interactions to elicit naturalistic behavior on the part of trainees. Negative training may occur if trainees are inadvertently influenced to react in ways that are unexpected and unnatural, hindering proper learning and transfer of skills and knowledge back into real world contexts. In this research, we examined whether haptic priming (presenting an illusion of virtual human touch at the beginning of the virtual experience) and different locomotion techniques (either joystick or physical walking) might affect proxemic behavior in human users. The results of our study suggest that locomotion techniques can alter proxemic behavior in significant ways. Haptic priming did not appear to impact proxemic behavior, but did increase rapport and other subjective social measures. The results suggest that designers and developers of immersive training systems should carefully consider the impact of even simple design and fidelity choices on trainee reactions in social interactions. © 2018 IEEE.","fidelity; haptic priming; immersive training; locomotion techniques; proxemics; Virtual humans; virtual reality","Augmented reality; Behavioral research; Biocommunications; Human computer interaction; Military applications; User interfaces; fidelity; haptic priming; Immersive; Locomotion technique; proxemics; Virtual humans; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85053822218
"Karatsidis A., Richards R.E., Konrath J.M., Van Den Noort J.C., Schepers H.M., Bellusci G., Harlaar J., Veltink P.H.","57192812821;57037821600;57189991841;26644544500;15623758700;23007370300;6701663252;7006060993;","Validation of wearable visual feedback for retraining foot progression angle using inertial sensors and an augmented reality headset",2018,"Journal of NeuroEngineering and Rehabilitation","15","1", 78,"","",,24,"10.1186/s12984-018-0419-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051667667&doi=10.1186%2fs12984-018-0419-2&partnerID=40&md5=861c4fb0e465747960f724d9f249c8d0","Xsens Technologies B.V, Pantheon 6, Enschede, 7521 PR, Netherlands; Department of Biomedical Signals and Systems (BSS), Technical Medical Centre, University of Twente, Enschede, Netherlands; Department of Rehabilitation Medicine, Amsterdam Movement Sciences, VU University Medical Center, Amsterdam, Netherlands; Academic Medical Center, Musculoskeletal Imaging Quantification Center (MIQC), Department of Radiology and Nuclear Medicine, Amsterdam Movement Sciences, Amsterdam, Netherlands; Department of Biomechanical Engineering, Delft University of Technology, Delft, Netherlands","Karatsidis, A., Xsens Technologies B.V, Pantheon 6, Enschede, 7521 PR, Netherlands, Department of Biomedical Signals and Systems (BSS), Technical Medical Centre, University of Twente, Enschede, Netherlands; Richards, R.E., Department of Rehabilitation Medicine, Amsterdam Movement Sciences, VU University Medical Center, Amsterdam, Netherlands; Konrath, J.M., Xsens Technologies B.V, Pantheon 6, Enschede, 7521 PR, Netherlands; Van Den Noort, J.C., Department of Rehabilitation Medicine, Amsterdam Movement Sciences, VU University Medical Center, Amsterdam, Netherlands, Academic Medical Center, Musculoskeletal Imaging Quantification Center (MIQC), Department of Radiology and Nuclear Medicine, Amsterdam Movement Sciences, Amsterdam, Netherlands; Schepers, H.M., Xsens Technologies B.V, Pantheon 6, Enschede, 7521 PR, Netherlands; Bellusci, G., Xsens Technologies B.V, Pantheon 6, Enschede, 7521 PR, Netherlands; Harlaar, J., Department of Rehabilitation Medicine, Amsterdam Movement Sciences, VU University Medical Center, Amsterdam, Netherlands, Department of Biomechanical Engineering, Delft University of Technology, Delft, Netherlands; Veltink, P.H., Department of Biomedical Signals and Systems (BSS), Technical Medical Centre, University of Twente, Enschede, Netherlands","Background: Gait retraining interventions using real-time biofeedback have been proposed to alter the loading across the knee joint in patients with knee osteoarthritis. Despite the demonstrated benefits of these conservative treatments, their clinical adoption is currently obstructed by the high complexity, spatial demands, and cost of optical motion capture systems. In this study we propose and evaluate a wearable visual feedback system for gait retraining of the foot progression angle (FPA). Methods: The primary components of the system are inertial measurement units, which track the human movement without spatial limitations, and an augmented reality headset used to project the visual feedback in the visual field. The adapted gait protocol contained five different target angles ranging from 15 degrees toe-out to 5 degrees toe-in. Eleven healthy participants walked on an instrumented treadmill, and the protocol was performed using both an established laboratory visual feedback driven by optical motion capture, and the proposed wearable system. Results and conclusions: The wearable system tracked FPA with an accuracy of 2.4 degrees RMS and ICC=0.94 across all target angles and subjects, when compared to an optical motion capture reference. In addition, the effectiveness of the biofeedback, reflected by the number of steps with FPA value ±2 degrees from the target, was found to be around 50% in both wearable and laboratory approaches. These findings demonstrate that retraining of the FPA using wearable inertial sensing and visual feedback is feasible with effectiveness matching closely an established laboratory method. The proposed wearable setup may reduce the complexity of gait retraining applications and facilitate their transfer to routine clinical practice. © 2018 The Author(s).","Augmented reality headset; Foot progression angle; Gait retraining; Inertial sensors; Knee osteoarthritis; Real-time biofeedback","adult; Article; biomechanics; female; foot progression angle; gait; human; human experiment; male; mathematical analysis; measurement accuracy; musculoskeletal system parameters; normal human; priority journal; virtual reality; visual feedback; walking; electronic device; foot; gait; knee; knee osteoarthritis; physiology; sensory feedback; validation study; Adult; Biomechanical Phenomena; Feedback, Sensory; Female; Foot; Gait; Humans; Knee Joint; Male; Osteoarthritis, Knee; Virtual Reality; Walking; Wearable Electronic Devices",Article,"Final","",Scopus,2-s2.0-85051667667
"Agus M., Boges D., Gagnon N., Magistretti P.J., Hadwiger M., Calí C.","57195623616;56780189200;57202248458;7007046209;14021127100;24337622600;","GLAM: Glycogen-derived Lactate Absorption Map for visual analysis of dense and sparse surface reconstructions of rodent brain structures on desktop systems and virtual environments",2018,"Computers and Graphics (Pergamon)","74",,,"85","98",,12,"10.1016/j.cag.2018.04.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047628319&doi=10.1016%2fj.cag.2018.04.007&partnerID=40&md5=a276e314d27f8e5d009691c6386a7ce3","Visual Computing Center, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia; Biological and Environmental Science and Engineering Division, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia; CRS4 - Center for Advanced Studies, Research and Development in Sardinia, Pula(CA), Italy","Agus, M., Visual Computing Center, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia, CRS4 - Center for Advanced Studies, Research and Development in Sardinia, Pula(CA), Italy; Boges, D., Biological and Environmental Science and Engineering Division, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia; Gagnon, N., Biological and Environmental Science and Engineering Division, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia; Magistretti, P.J., Biological and Environmental Science and Engineering Division, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia; Hadwiger, M., Visual Computing Center, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia; Calí, C., Biological and Environmental Science and Engineering Division, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia","Human brain accounts for about one hundred billion neurons, but they cannot work properly without ultrastructural and metabolic support. For this reason, mammalian brains host another type of cells called “glial cells”, whose role is to maintain proper conditions for efficient neuronal function. One type of glial cell, astrocytes, are involved in particular in the metabolic support of neurons, by feeding them with lactate, one byproduct of glucose metabolism that they can take up from blood vessels, and store it under another form, glycogen granules. These energy-storage molecules, whose morphology resembles to spheres with a diameter ranging 10–80 nanometers roughly, can be easily recognized using electron microscopy, the only technique whose resolution is high enough to resolve them. Understanding and quantifying their distribution is of particular relevance for neuroscientists, in order to understand where and when neurons use energy under this form. To answer this question, we developed a visualization technique, dubbed GLAM (Glycogen-derived Lactate Absorption Map), and customized for the analysis of the interaction of astrocytic glycogen on surrounding neurites in order to formulate hypotheses on the energy absorption mechanisms. The method integrates high-resolution surface reconstruction of neurites, astrocytes, and the energy sources in form of glycogen granules from different automated serial electron microscopy methods, like focused ion beam scanning electron microscopy (FIB-SEM) or serial block face electron microscopy (SBEM), together with an absorption map computed as a radiance transfer mechanism. The resulting visual representation provides an immediate and comprehensible illustration of the areas in which the probability of lactate shuttling is higher. The computed dataset can be then explored and quantified in a 3D space, either using 3D modeling software or virtual reality environments. Domain scientists have evaluated the technique by either using the computed maps for formulating functional hypotheses or for planning sparse reconstructions to avoid excessive occlusion. Furthermore, we conducted a pioneering user study showing that immersive VR setups can ease the investigation of the areas of interest and the analysis of the absorption patterns in the cellular structures. © 2018 Elsevier Ltd","3D interactive visual analysis; Nanometric scale brain reconstructions; Neuroenergetics; Scientific visualization; Virtual Reality in Neuroscience","Blood vessels; Data visualization; Electrons; Granulation; Ion beams; Mammals; Metabolism; Neurons; Repair; Scanning electron microscopy; Three dimensional computer graphics; Virtual reality; Visualization; Brain reconstruction; Energy-storage molecule; Focused ion beam-scanning electron microscopies; Interactive visual analysis; Neuroenergetics; Virtual-reality environment; Visual representations; Visualization technique; Surface reconstruction",Article,"Final","",Scopus,2-s2.0-85047628319
"Buatois A., Flumian C., Schultheiss P., Avarguès-Weber A., Giurfa M.","57190951756;57203869544;36982215400;35721565900;7003298526;","Transfer of visual learning between a virtual and a real environment in honey bees: The role of active vision",2018,"Frontiers in Behavioral Neuroscience","12",, 139,"","",,7,"10.3389/fnbeh.2018.00139","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053289877&doi=10.3389%2ffnbeh.2018.00139&partnerID=40&md5=1c2229d71b1b598dc01b36b32cfa5419","Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse, France","Buatois, A., Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse, France; Flumian, C., Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse, France; Schultheiss, P., Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse, France; Avarguès-Weber, A., Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse, France; Giurfa, M., Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse, France","To study visual learning in honey bees, we developed a virtual reality (VR) system in which the movements of a tethered bee walking stationary on a spherical treadmill update the visual panorama presented in front of it (closed-loop conditions), thus creating an experience of immersion within a virtual environment. In parallel, we developed a small Y-maze with interchangeable end-boxes, which allowed replacing repeatedly a freely walking bee into the starting point of the maze for repeated decision recording. Using conditioning and transfer experiments between the VR setup and the Y-maze, we studied the extent to which movement freedom and active vision are crucial for learning a simple color discrimination. Approximately 57% of the bees learned the visual discrimination in both conditions. Transfer from VR to the maze improved significantly the bees’ performances: 75% of bees having chosen the CS+ continued doing so and 100% of bees having chosen the CS- reverted their choice in favor of the CS+. In contrast, no improvement was seen for these two groups of bees during the reciprocal transfer from the Y-maze to VR. In this case, bees exhibited inconsistent choices in the VR setup. The asymmetric transfer between contexts indicates that the information learned in each environment may be different despite the similar learning success. Moreover, it shows that reducing the possibility of active vision and movement freedom in the passage from the maze to the VR impairs the expression of visual learning while increasing them in the reciprocal transfer improves it. Our results underline the active nature of visual processing in bees and allow discussing the developments required for immersive VR experiences in insects. © 2018 Buatois, Flumian, Schultheiss, Avarguès-Weber and Giurfa.","Honey bees; Insect cognition; Transfer of learning; Virtual reality; Visual conditioning; Y-maze","animal experiment; Article; color discrimination; discrimination learning; honeybee; learning; mental performance; nonhuman; simulation training; transfer of learning; virtual learning; virtual reality; vision; visual discrimination; visual discrimination learning test; visual learning; Y-maze test",Article,"Final","",Scopus,2-s2.0-85053289877
"Foloppe D.A., Richard P., Yamaguchi T., Etcharry-Bouyx F., Allain P.","55226000800;57210457077;42862771500;6701526596;16633275200;","The potential of virtual reality-based training to enhance the functional autonomy of Alzheimer's disease patients in cooking activities: A single case study",2018,"Neuropsychological Rehabilitation","28","5",,"709","733",,28,"10.1080/09602011.2015.1094394","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944937051&doi=10.1080%2f09602011.2015.1094394&partnerID=40&md5=59dbbc30086ab0a5bc50a1a244ddd880","Laboratoire de Psychologie des Pays de Loire (EA 4638), LUNAM Université, Université d'Angers, Angers, France; Laboratoire Angevin de Recherche en Ingénierie des Systèmes (EA 7315), LUNAM Université, Université d'Angers, Angers, France; Department of Applied Electronics, Faculty of Industrial Science and Technology, Tokyo University of Science, Tokyo, Japan; Département de Neurologie, Unité de Neuropsychologie, Chu Angers, France","Foloppe, D.A., Laboratoire de Psychologie des Pays de Loire (EA 4638), LUNAM Université, Université d'Angers, Angers, France, Laboratoire Angevin de Recherche en Ingénierie des Systèmes (EA 7315), LUNAM Université, Université d'Angers, Angers, France; Richard, P., Laboratoire Angevin de Recherche en Ingénierie des Systèmes (EA 7315), LUNAM Université, Université d'Angers, Angers, France; Yamaguchi, T., Department of Applied Electronics, Faculty of Industrial Science and Technology, Tokyo University of Science, Tokyo, Japan; Etcharry-Bouyx, F., Laboratoire de Psychologie des Pays de Loire (EA 4638), LUNAM Université, Université d'Angers, Angers, France, Département de Neurologie, Unité de Neuropsychologie, Chu Angers, France; Allain, P., Laboratoire de Psychologie des Pays de Loire (EA 4638), LUNAM Université, Université d'Angers, Angers, France, Département de Neurologie, Unité de Neuropsychologie, Chu Angers, France","Impairments in performing activities of daily living occur early in the course of Alzheimer's disease (AD). There is a great need to develop non-pharmacological therapeutic interventions likely to reduce dependency in everyday activities in AD patients. This study investigated whether it was possible to increase autonomy in these patients in cooking activities using interventions based on errorless learning, vanishing-cue, and virtual reality techniques. We recruited a 79-year-old woman who met NINCDS-ADRDA criteria for probable AD. She was trained in four cooking tasks for four days per task, one hour per day, in virtual and in real conditions. Outcome measures included subjective data concerning the therapeutic intervention and the experience of virtual reality, repeated assessments of training activities, neuropsychological scores, and self-esteem and quality of life measures. The results indicated that our patient could relearn some cooking activities using virtual reality techniques. Transfer to real life was also observed. Improvement of the task performance remained stable over time. This case report supports the value of a non-immersive virtual kitchen to help people with AD to relearn cooking activities. © 2015 Informa UK Limited, trading as Taylor & Francis Group.","activities of daily living; Alzheimer's disease; cognitive rehabilitation; non-pharmacological intervention; virtual reality","aged; Alzheimer disease; case report; computer assisted therapy; daily life activity; female; human; learning; neurorehabilitation; psychology; virtual reality; Activities of Daily Living; Aged; Alzheimer Disease; Female; Humans; Learning; Neurological Rehabilitation; Therapy, Computer-Assisted; Virtual Reality",Article,"Final","",Scopus,2-s2.0-84944937051
"Rivière E., Saucier D., Lafleur A., Lacasse M., Chiniara G.","36653247600;7005302177;56490345600;8603839300;55583067300;","Twelve tips for efficient procedural simulation",2018,"Medical Teacher","40","7",,"743","751",,7,"10.1080/0142159X.2017.1391375","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032220031&doi=10.1080%2f0142159X.2017.1391375&partnerID=40&md5=66da187a9c5e396befcffe0b2603d71c","Department of Internal Medicine, Haut-Leveque Hospital, University Hospital Centre of Bordeaux, Pessac, France; Apprentiss Centre (Simulation Centre), Laval University, Quebec City, Canada; Centre of Applied Research to Educative Methods (CAREM), University of Bordeaux, Bordeaux, France; Department of Family and Emergency Medicine, Laval University, Quebec City, Canada; Office of Education and Continuing Professional Development (Vice-décanat à la pédagogie et au développement professional continu), Laval University, Quebec City, Canada; Department of Medicine, Laval University, Quebec City, Canada; Department of Anaesthesiology and Intensive Care, Laval University, Quebec City, Canada","Rivière, E., Department of Internal Medicine, Haut-Leveque Hospital, University Hospital Centre of Bordeaux, Pessac, France, Apprentiss Centre (Simulation Centre), Laval University, Quebec City, Canada, Centre of Applied Research to Educative Methods (CAREM), University of Bordeaux, Bordeaux, France; Saucier, D., Department of Family and Emergency Medicine, Laval University, Quebec City, Canada, Office of Education and Continuing Professional Development (Vice-décanat à la pédagogie et au développement professional continu), Laval University, Quebec City, Canada; Lafleur, A., Office of Education and Continuing Professional Development (Vice-décanat à la pédagogie et au développement professional continu), Laval University, Quebec City, Canada, Department of Medicine, Laval University, Quebec City, Canada; Lacasse, M., Office of Education and Continuing Professional Development (Vice-décanat à la pédagogie et au développement professional continu), Laval University, Quebec City, Canada, Department of Medicine, Laval University, Quebec City, Canada; Chiniara, G., Apprentiss Centre (Simulation Centre), Laval University, Quebec City, Canada, Department of Anaesthesiology and Intensive Care, Laval University, Quebec City, Canada","Procedural simulation (PS) is increasingly being used worldwide in healthcare for training caregivers in psychomotor competencies. It has been demonstrated to improve learners’ confidence and competence in technical procedures, with consequent positive impacts on patient outcomes and safety. Several frameworks can guide healthcare educators in using PS as an educational tool. However, no theory-informed practical framework exists to guide them in including PS in their training programs. We present 12 practical tips for efficient PS training that translates educational concepts from theory to practice, based on the existing literature. In doing this, we aim to help healthcare educators to adequately incorporate and use PS both for optimal learning and for transfer into professional practice. © 2017, © 2017 Informa UK Limited, trading as Taylor & Francis Group.",,"human; professional practice; simulation training; clinical competence; constructive feedback; education; learning; medical education; problem based learning; procedures; program development; simulation training; standards; Clinical Competence; Education, Medical; Educational Measurement; Formative Feedback; Humans; Learning; Problem-Based Learning; Program Development; Simulation Training",Article,"Final","",Scopus,2-s2.0-85032220031
"Javorsky T., Skola F., Sylaiou S., Martins J., Liarokapis F.","57208864345;57189368470;14828467500;7201798943;7801416785;","Investigating Body Transfer Illusion from Human to Monkey Body",2018,"9th International Conference on Intelligent Systems 2018: Theory, Research and Innovation in Applications, IS 2018 - Proceedings",,, 8710499,"549","556",,2,"10.1109/IS.2018.8710499","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065998646&doi=10.1109%2fIS.2018.8710499&partnerID=40&md5=bef30408d08d925ed47f51e717304554","HCILab Masaryk University, Brno, Czech Republic; School of Social Sciences, Hellenic Open University, Patra, Greece; Faculty of Sciences and Technology, Universidade Tova de Lisboa, Lisbon, Portugal","Javorsky, T., HCILab Masaryk University, Brno, Czech Republic; Skola, F., HCILab Masaryk University, Brno, Czech Republic; Sylaiou, S., School of Social Sciences, Hellenic Open University, Patra, Greece; Martins, J., Faculty of Sciences and Technology, Universidade Tova de Lisboa, Lisbon, Portugal; Liarokapis, F., HCILab Masaryk University, Brno, Czech Republic","This paper presents a virtual reality study examining the magnitude of embodiment into a human and nonhuman avatar. It examines the user experience of inhabiting the body of animals in immersive virtual environments. Participants embodied in a human-like virtual avatar experienced body transfer illusion into a body of a monkey. The experiment consisted of two variants. In the first variant, participants did not have the ability to control the hands inside the Monkey avatar, they were instructed to just look over the scene from their fixed point of view. In the second variant, the ability to move arms and hands of the Monkey avatar was enabled, and this fact was articulated to the test subjects. Results suggest that the body transfer illusion is indeed possible. The study also indicates that the actual shape or visual representation of the body matters less than the amount and diversity of stimuli, and possibilities of controlling the avatar's body. Results of this study can be leveraged in the design of e-learning, health-care, and affective computing platforms, where amplification of the human-oriented design using malleable virtual avatars can bring additional feedback channel to the users. © 2018 IEEE.","Body transfer illusion; Sensors; Virtual reality","Computation theory; Intelligent systems; Sensors; Affective Computing; Body transfer illusion; Feedback channel; Fixed points; Immersive virtual environments; User experience; Virtual avatar; Visual representations; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85065998646
"Bier B., Ouellet E., Belleville S.","56293391400;55567624500;57203072633;","Computerized attentional training and transfer with virtual reality: Effect of age and training type",2018,"Neuropsychology","32","5",,"597","614",,13,"10.1037/neu0000417","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049186196&doi=10.1037%2fneu0000417&partnerID=40&md5=6c581ac80b223d391c8f488f654ce2b0","Research Centre, Institut universitaire de gériatrie de Montréal, Montreal, Canada; Department of Psychology, University of Montreal, Canada","Bier, B., Research Centre, Institut universitaire de gériatrie de Montréal, Montreal, Canada, Department of Psychology, University of Montreal, Canada; Ouellet, E., Research Centre, Institut universitaire de gériatrie de Montréal, Montreal, Canada, Department of Psychology, University of Montreal, Canada; Belleville, S., Research Centre, Institut universitaire de gériatrie de Montréal, Montreal, Canada, Department of Psychology, University of Montreal, Canada","Objective: The aims of this study were to assess whether computerized attentional training improves dual-tasking abilities in older adults and whether its effect and transfer are modulated by age and the type of training provided. This study also used virtual reality (VR) as a proxy to measure transfer in a real life related context. Method: Sixty participants (30 older and 30 younger adults) were randomized to either: (a) single-task training (two tasks practiced in focused attention; visual detection and alphanumeric equation task); or (b) divided attention variable-priority training (varying the amount of attention to put on each task when performed concurrently). Training effects were assessed at pre- and post-training with tasks similar to the one used in training. Transfer was measured with the virtual car ride, an immersive dual-task scenario and a self-reported questionnaire. Results: In older adults, variable-priority improved attentional control abilities and led to better transfer in the VR dual-task scenario compared with single-task. Younger adults benefited equally from the two types of training and transfer was found on the Alpha span task when performed concurrently in VR. Single-task improved the ability of all participants to carry out the tasks in the focused attention condition. No transfer effects were found on the self-reported measure for either training type or age. Conclusion: Attention remains plastic in old age and programs designed to improve attentional control might be beneficial to older adults. Importantly, training can produce transfer to more real life related tasks and transfer remains possible throughout the life span. © 2018 American Psychological Association.","Aging; Cognitive training; Dual-task; Transfer; Virtual-reality","adult; age; aged; Article; attention; cognitive therapy; computerized attentional training; controlled study; female; human; human experiment; intermethod comparison; male; normal human; priority journal; questionnaire; randomized controlled trial; self report; single task training; therapy effect; variable priority training; virtual reality; visual discrimination; aging; computer; middle aged; physiology; psychology; transfer of learning; young adult; Adult; Age Factors; Aged; Aging; Attention; Computers; Female; Humans; Male; Middle Aged; Transfer (Psychology); Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85049186196
"Divekar R.R., Drozdal J., Zhou Y., Song Z., Allen D., Rouhani R., Zhao R., Zheng S., Balagyozyan L., Su H.","57202807050;57204003069;35423165100;57204006549;57213441174;57202800876;56461916600;57204002012;57204003575;57202802558;","Interaction challenges in AI equipped environments built to teach foreign languages through dialogue and task-completion",2018,"DIS 2018 - Proceedings of the 2018 Designing Interactive Systems Conference",,,,"597","610",,7,"10.1145/3196709.3196717","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054038258&doi=10.1145%2f3196709.3196717&partnerID=40&md5=d07decf48bf6629f34cb5d5dcdf9d100","Rensselaer Polytechnic Institute, Troy, NY  12180, United States; IBM Thomas J. Watson Research Laboratory, Yorktown Heights, NY  10598, United States","Divekar, R.R., Rensselaer Polytechnic Institute, Troy, NY  12180, United States; Drozdal, J., Rensselaer Polytechnic Institute, Troy, NY  12180, United States; Zhou, Y., Rensselaer Polytechnic Institute, Troy, NY  12180, United States; Song, Z., Rensselaer Polytechnic Institute, Troy, NY  12180, United States; Allen, D., Rensselaer Polytechnic Institute, Troy, NY  12180, United States; Rouhani, R., Rensselaer Polytechnic Institute, Troy, NY  12180, United States; Zhao, R., Rensselaer Polytechnic Institute, Troy, NY  12180, United States; Zheng, S., Rensselaer Polytechnic Institute, Troy, NY  12180, United States; Balagyozyan, L., Rensselaer Polytechnic Institute, Troy, NY  12180, United States; Su, H., Rensselaer Polytechnic Institute, Troy, NY  12180, United States, IBM Thomas J. Watson Research Laboratory, Yorktown Heights, NY  10598, United States","As cities around the world become more diverse in culture and language, there is a growing need for learning foreign languages. To further this excitement, we have built a human-scale, immersive room with a virtual AI agent that aids foreign language learning. Our system aids the language learning process through task-completion exercises using multi-modal dialogue. The Cognitive and Immersive Room (CIR) is developed as an immersive Chinese restaurant to teach Mandarin, but the interaction challenges and solutions can be reasonably generalized to other languages taught using similar techniques. As users interact with the immersive environment and the virtual AI agent, they face several user interaction challenges. These challenges arise from new learners' lack of proficiency in the foreign language. By studying user interactions in the CIR, we were able to articulate some of the interaction challenges. We have enhanced the AI agent, virtual environment, and the on-boarding process for new users to mitigate these challenges. The enhancements and the results which show that they were effective are discussed here. © 2018 Copyright held by the owner/author(s).","Immersive room; Intelligent agent; Language teaching; Mandarin as a foreign language; Mandarin teaching; Multi-modal interaction; Three dimensional virtual worlds","Intelligent agents; User interfaces; Foreign language; Immersive; Language teachings; Multi-Modal Interactions; Three-dimensional virtual world; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85054038258
"Huber T., Paschold M., Hansen C., Lang H., Kneist W.","18535462800;50361876100;55890379200;7402486188;7005632003;","Artificial Versus Video-Based Immersive Virtual Surroundings: Analysis of Performance and User’s Preference",2018,"Surgical Innovation","25","3",,"280","285",,5,"10.1177/1553350618761756","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047495181&doi=10.1177%2f1553350618761756&partnerID=40&md5=0ad928be9ec543737a9d0024a2671f68","University Medicine of the Johannes Gutenberg-University, Mainz, Germany; Otto-von-Guericke University, Magdeburg, Germany","Huber, T., University Medicine of the Johannes Gutenberg-University, Mainz, Germany; Paschold, M., University Medicine of the Johannes Gutenberg-University, Mainz, Germany; Hansen, C., Otto-von-Guericke University, Magdeburg, Germany; Lang, H., University Medicine of the Johannes Gutenberg-University, Mainz, Germany; Kneist, W., University Medicine of the Johannes Gutenberg-University, Mainz, Germany","Introduction. Immersive virtual reality (VR) laparoscopy simulation connects VR simulation with head-mounted displays to increase presence during VR training. The goal of the present study was the comparison of 2 different surroundings according to performance and users’ preference. Methods. With a custom immersive virtual reality laparoscopy simulator, an artificially created VR operating room (AVR) and a highly immersive VR operating room (IVR) were compared. Participants (n = 30) performed 3 tasks (peg transfer, fine dissection, and cholecystectomy) in AVR and IVR in a crossover study design. Results. No overall difference in virtual laparoscopic performance was obtained when comparing results from AVR with IVR. Most participants preferred the IVR surrounding (n = 24). Experienced participants (n = 10) performed significantly better than novices (n = 10) in all tasks regardless of the surrounding (P <.05). Participants with limited experience (n = 10) showed differing results. Presence, immersion, and exhilaration were significantly higher in IVR. Two thirds assumed that IVR would have a positive influence on their laparoscopic simulator use. Conclusion. This first study comparing AVR and IVR did not reveal differences in virtual laparoscopic performance. IVR is considered the more realistic surrounding and is therefore preferred by the participants. © 2018, © The Author(s) 2018.","abdominal surgery; immersive virtual reality; laparoscopy; simulation; training; virtual surgery","adult; Article; cholecystectomy; clinical assessment; crossover procedure; cyber sickness; diseases; female; fine dissection; human; immersive virtual reality; laparoscopy; male; medical procedures; medical student; middle aged; peg transfer; performance; questionnaire; task performance; virtual reality; young adult; clinical competence; education; medical education; procedures; surgeon; Adult; Clinical Competence; Education, Medical; Female; Humans; Laparoscopy; Male; Middle Aged; Surgeons; Surveys and Questionnaires; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85047495181
"Riva G., Wiederhold B.K., Chirico A., Di Lernia D., Mantovani F., Gaggioli A.","56962750600;7003634518;56755080200;57189076325;7006190897;6603138127;","Brain and virtual reality: What do they have in common and how to exploit their potential",2018,"Annual Review of CyberTherapy and Telemedicine","2018","16",,"3","8",,5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067840584&partnerID=40&md5=3a878bb1f64f53b14d1ef91b66876123","Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy; Applied Technology for Neuro-Psychology Lab. Istituto Auxologico Italiano, Milan, Italy; Interactive Media Institute, San Diego, CA, United States; Department of Human Sciences for Education, Università degli Studi di Milano-Bicocca, Milan, Italy","Riva, G., Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy, Applied Technology for Neuro-Psychology Lab. Istituto Auxologico Italiano, Milan, Italy; Wiederhold, B.K., Interactive Media Institute, San Diego, CA, United States; Chirico, A., Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy; Di Lernia, D., Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy; Mantovani, F., Department of Human Sciences for Education, Università degli Studi di Milano-Bicocca, Milan, Italy; Gaggioli, A., Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy, Applied Technology for Neuro-Psychology Lab. Istituto Auxologico Italiano, Milan, Italy","Different studies suggest that Virtual Reality (VR) is an effective tool for behavioural health, with long-term effects that generalize to the real world. Here we suggest that the efficacy of VR can be explained by how it works. Specifically, VR shares with our brain the same basic mechanism: embodied simulations. Different major discoveries in the field of neuroscience suggest that our brain produces and updates an embodied simulation of the body in the world. This simulation is actively used by different cognitive processes to represent and predict actions, concepts, and emotions. VR works in a similar way: through the integration of data from trackers and contents of a simulated 3D world, a VR system builds a model (simulation) of the body and the space around it. Like the brain, the VR system uses the simulation to predict the sensory consequences of the individual’s movements. In this view, the more the VR model is similar to the brain model, the more the individual feels present in the VR world. The paper discusses the potential of this link, by suggesting the emergence of a new clinical approach that uses the simulative potential of VR to exploit/empower (transformation of flow) and/or correct/update (embodied medicine) the predictive/simulative mechanisms of the brain. © 2018, Interactive Media Institute. All rights reserved.","Behavioural health; Embodied medicine; Embodied simulation; Neuroscience; Predictive coding; Virtual reality","article; brain; drug efficacy; human; human experiment; medical decision making; neuroscience; simulation; virtual reality",Article,"Final","",Scopus,2-s2.0-85067840584
"Wall K.J., Cumming T.B., Koenig S.T., Pelecanos A.M., Copland D.A.","37038732700;25222759400;35217731600;36168407200;6603939137;","Using technology to overcome the language barrier: the Cognitive Assessment for Aphasia App",2018,"Disability and Rehabilitation","40","11",,"1333","1344",,6,"10.1080/09638288.2017.1294210","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014614339&doi=10.1080%2f09638288.2017.1294210&partnerID=40&md5=153075f5fe196008f375f3ed9a5a5263","Centre for Clinical Research, The University of Queensland, Brisbane, Australia; School of Health and Rehabilitation Sciences, The University of Queensland, Brisbane, Australia; The Florey Institute for Neuroscience and Mental Health, University of MelbourneVIC, Australia; Katana Simulations Pty Ltd, Adelaide, Australia; Statistic Unit, QIMR Berghofer Medical Research Institute, Brisbane, Australia","Wall, K.J., Centre for Clinical Research, The University of Queensland, Brisbane, Australia, School of Health and Rehabilitation Sciences, The University of Queensland, Brisbane, Australia; Cumming, T.B., The Florey Institute for Neuroscience and Mental Health, University of MelbourneVIC, Australia; Koenig, S.T., Katana Simulations Pty Ltd, Adelaide, Australia; Pelecanos, A.M., Statistic Unit, QIMR Berghofer Medical Research Institute, Brisbane, Australia; Copland, D.A., Centre for Clinical Research, The University of Queensland, Brisbane, Australia, School of Health and Rehabilitation Sciences, The University of Queensland, Brisbane, Australia","Purpose: We developed and explored the feasibility and user acceptance of the Cognitive Assessment for Aphasia App: a non-immersive virtual reality cognitive assessment for stroke survivors, designed to be inclusive of individuals with aphasia. Methods: Participants were assessed on a battery of pen-and-paper cognitive tests and the Cognitive Assessment for Aphasia App. Feasibility was explored by quantifying missing data for test completion, determining user acceptance for the app by measuring participants’ preferred testing method, enjoyment and perceived task difficulty and time-taken to complete the test. Results: Sixty-four stroke participants (35 with aphasia, 29 without aphasia) and 32 controls were recruited. Only one participant with aphasia was unable to complete all the Cognitive Assessment for Aphasia App tasks, whereas 13 participants were unable to complete all pen-and-paper tasks. Only 14% of participants preferred the pen-and-paper tests, and preference did not significantly differ between groups. Ninety-five per cent of participants were neutral or enjoyed the app and 4% perceived it to be very difficult. Higher age was negatively associated with user acceptance measures. Conclusion: The study shows preliminary evidence for the Cognitive Assessment for Aphasia App to be a feasible cognitive assessment for stroke survivors with and without aphasia. The app is currently being validated in stroke.Implications for rehabilitation The Cognitive Assessment for Aphasia App is a feasible tool for assessing post-stroke cognition in acute, inpatient rehabilitation and community settings. In research trials examining cognition, individuals with aphasia are often excluded. The Cognitive Assessment for Aphasia App permits the inclusion of these individuals, enhancing generalizability. The Cognitive Assessment for Aphasia App provides an alternative method to assess cognition that is quicker and preferred over standard neuropsychological tests. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","cognitive impairments; language impairments; neuropsychological tests; technology; user acceptance; Virtual reality","age; aged; aphasia; case control study; cerebrovascular accident; complication; female; human; male; mobile application; reaction time; short term memory; virtual reality; Age Factors; Aged; Aphasia; Case-Control Studies; Female; Humans; Male; Memory, Short-Term; Mobile Applications; Reaction Time; Stroke; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85014614339
"Hai W., Jain N., Wydra A., Thalmann N.M., Thalmann D.","57201904238;35498072000;57201913246;55218502200;7005885082;","Increasing the feeling of social presence by incorporating realistic interactions in multi-party VR",2018,"ACM International Conference Proceeding Series",,,,"7","10",,2,"10.1145/3205326.3205345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048396292&doi=10.1145%2f3205326.3205345&partnerID=40&md5=e227e300e07f40bfe7197535609178cd","Institute for Media Innovation, Nanyang Technological University, Singapore; École polytechnique fédérale de Lausanne, Switzerland","Hai, W., Institute for Media Innovation, Nanyang Technological University, Singapore; Jain, N., Institute for Media Innovation, Nanyang Technological University, Singapore; Wydra, A., Institute for Media Innovation, Nanyang Technological University, Singapore; Thalmann, N.M., Institute for Media Innovation, Nanyang Technological University, Singapore; Thalmann, D., École polytechnique fédérale de Lausanne, Switzerland","Behavioral realism and realistic interactions are major criteria for improving social presence in virtual reality environments. We focus on multi-party VR applications where computer agents and avatars interact, share and collaborate with each other using objects. Our formulation employs realistic animations to simulate human-like behavioral motions of computer agents while they interact with avatars to enhance the sense of social presence in the VR environment. We exemplify our proposed model in a VR volleyball game setup. We model specific underlying interactions like gazing, collision detection and miscellaneous reactions (like how to pick a volleyball, how to transfer the ball to server) between computers players and avatars in the VR Volleyball game. We conduct a preliminary user survey to illustrate the significance of inclusion of realistic interactions for improving sense of social presence in a multi-party VR environment. © 2018 Copyright held by the owner/author(s).","Agent; Avatar; Behavior realism; Interactions; Multiparty; Social presence; VR","Agents; Animation; Beam plasma interactions; Behavioral research; Interactive computer graphics; Sports; Virtual reality; Avatar; Behavior realism; Collision detection; Miscellaneous reactions; Multiparty; Social presence; Virtual-reality environment; VR applications; Computer games",Conference Paper,"Final","",Scopus,2-s2.0-85048396292
"Jung J., Ahn Y.J.","57220995238;57201853639;","Effects of interface on procedural skill transfer in virtual training: Lifeboat launching operation study",2018,"Computer Animation and Virtual Worlds","29","3-4", e1812,"","",,7,"10.1002/cav.1812","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046267906&doi=10.1002%2fcav.1812&partnerID=40&md5=0f4881ff1662eaf041a1adb3184611b7","Korea Research Institute of Ships and Ocean Engineering, Daejeon, South Korea; Korea Institute of Maritime and Fisheries Technology, Busan, South Korea","Jung, J., Korea Research Institute of Ships and Ocean Engineering, Daejeon, South Korea; Ahn, Y.J., Korea Institute of Maritime and Fisheries Technology, Busan, South Korea","A comparative study assessing the effect of interface type on procedural skill transfer during virtual training is presented. The aim of this research is to evaluate the transferability of two aspects of procedural skills, that is, procedural knowledge and technical skills. We established one group with a lecture and three virtual training groups with a combination of output and input devices: a monitor and keyboard/mouse, a head-mounted display (HMD) and joypad, and an HMD and wearable sensors. The task for assessment was a lifeboat launching operation that requires a participant to memorize a 10-step procedure utilizing 14 different pieces of equipment that should be manipulated in each step. Before and after training, we evaluated the participants' procedural knowledge and technical skill on a real lifeboat. The monitor and keyboard/mouse group showed the best performance in a procedural knowledge assessment that addressed visually induced recollections from the real lifeboat. Alternatively, in the assessment of technical skills that determined manipulation ability that requires word-based mnemonics, the HMD and wearable sensors group outperformed the other groups. Moreover, the results showed that the virtual training was a more efficient training format for short-term training than a lecture due to the freedom of observation viewpoint, despite simulator sickness. Copyright © 2018 John Wiley & Sons, Ltd.","interface; maritime safety; procedural skill transfer; virtual reality; virtual training","Helmet mounted displays; Interfaces (materials); Lifeboats; Typewriter keyboards; Virtual reality; Wearable sensors; Comparative studies; Head mounted displays; Lifeboat launching; Maritime safety; Procedural knowledge; Simulator sickness; Skill transfer; Virtual training; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85046267906
"Choi I.","7401471770;","Interactive sonification exploring emergent behavior applying models for biological information and listening",2018,"Frontiers in Neuroscience","12","APR", 197,"","",,,"10.3389/fnins.2018.00197","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046093599&doi=10.3389%2ffnins.2018.00197&partnerID=40&md5=e8c761fe497c5f2b255227a098b4bc8c","Studio for International Media and Technology, MediaCity UK School of Arts and Media, University of Salford, Manchester, United Kingdom","Choi, I., Studio for International Media and Technology, MediaCity UK School of Arts and Media, University of Salford, Manchester, United Kingdom","Sonification is an open-ended design task to construct sound informing a listener of data. Understanding application context is critical for shaping design requirements for data translation into sound. Sonification requires methodology to maintain reproducibility when data sources exhibit non-linear properties of self-organization and emergent behavior. This research formalizes interactive sonification in an extensible model to support reproducibility when data exhibits emergent behavior. In the absence of sonification theory, extensibility demonstrates relevant methods across case studies. The interactive sonification framework foregrounds three factors: reproducible system implementation for generating sonification; interactive mechanisms enhancing a listener's multisensory observations; and reproducible data from models that characterize emergent behavior. Supramodal attention research suggests interactive exploration with auditory feedback can generate context for recognizing irregular patterns and transient dynamics. The sonification framework provides circular causality as a signal pathway for modeling a listener interacting with emergent behavior. The extensible sonification model adopts a data acquisition pathway to formalize functional symmetry across three subsystems: Experimental Data Source, Sound Generation, and Guided Exploration. To differentiate time criticality and dimensionality of emerging dynamics, tuning functions are applied between subsystems to maintain scale and symmetry of concurrent processes and temporal dynamics. Tuning functions accommodate sonification design strategies that yield order parameter values to render emerging patterns discoverable as well as rehearsable, to reproduce desired instances for clinical listeners. Case studies are implemented with two computational models, Chua's circuit and Swarm Chemistry social agent simulation, generating data in real-time that exhibits emergent behavior. Heuristic Listening is introduced as an informal model of a listener's clinical attention to data sonification through multisensory interaction in a context of structured inquiry. Three methods are introduced to assess the proposed sonification framework: Listening Scenario classification, data flow Attunement, and Sonification Design Patterns to classify sound control. Case study implementations are assessed against these methods comparing levels of abstraction between experimental data and sound generation. Outcomes demonstrate the framework performance as a reference model for representing experimental implementations, also for identifying common sonification structures having different experimental implementations, identifying common functions implemented in different subsystems, and comparing impact of affordances across multiple implementations of listening scenarios. © 2018 Choi.","Biological information; Cognitive cycle; Emergent behavior; Interaction design; Listening; Media psychology; Sonification; Supramodal attention","Article; auditory feedback; behavior; Chuas circuit; conceptual framework; data collection method; data flow attunement; emergent behavior; experimental data source; guided exploration; heuristic listening; human; information model; information processing; interactive voice response system; listening scenario classification; medical information; modulation transfer function; nonlinear system; pattern recognition; reproducibility; signal processing; signal transduction; sonification design pattern; sound generation; Swarm Chemistry; temporal analysis; time factor; tuning function; ultrasound",Article,"Final","",Scopus,2-s2.0-85046093599
"Esmaeili A.H., Thwaites H., Woods P.C.","56789724600;23486917000;16065290700;","Immersive virtual environments for tacit knowledge transfer focusing on gestures: A workflow",2018,"Proceedings of the 2017 23rd International Conference on Virtual Systems and Multimedia, VSMM 2017","2018-January",,,"1","6",,2,"10.1109/VSMM.2017.8346255","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049737638&doi=10.1109%2fVSMM.2017.8346255&partnerID=40&md5=1a430cf6a167fb75cee6105e335a5f16","Centre for Research-Creation in Digital Media, School of Arts, Sunway University, Malaysia; Faculty of Creative Multimedia, Multimedia University, Malaysia","Esmaeili, A.H., Centre for Research-Creation in Digital Media, School of Arts, Sunway University, Malaysia; Thwaites, H., Centre for Research-Creation in Digital Media, School of Arts, Sunway University, Malaysia; Woods, P.C., Faculty of Creative Multimedia, Multimedia University, Malaysia","This study presents a workflow for creating immersive virtual environments for tacit knowledge transfer. The main focus is on gestures, which are related to skill, performance, or physical emotion (not facial) e.g. sports, martial arts, playing instruments, acting, etc. The initial idea behind this design is to provide a virtual practice environment mainly for actors in order to learn new gestures or moves. However, this virtual environment can also be used by many other target audiences based on their needs. Sometimes, ambiguity is part of knowledge transfer and becomes more salient or critical when it comes to tacit knowledge, especially at early stages of transfer. Performance while maintaining believable gesture is a must have requirement for actors. Visual references (mainly video in absence of trainer) are commonly used by actors in order to learn specific moves or gestures. However, videos are limited to 2D screen view (even if stereoscopic or 360°) and do not provide chance of studying a fre zing moment from all angles, simultaneously. Although this can be partly mimicked using multi-camera rig, it is still limited to the number of shots taken and only provides a linear frame sequence (mostly used as VFX). Immersive virtual environments not only eliminate this limitation but also provide one to one scale experience. In this study, the process of creating such environment is discussed in detail. This includes planning, concept design, selecting tools, establishing the environment, properly selecting or creating the virtual character(s), capturing the motion or using existing ones from different Mocap libraries, actor's interaction with VR equipment, user experience, etc. In addition to studying reference moves and gestures (frame by frame and from any angle), the user is able to observe his/her performance in VR. This can be achieved using motion capture cameras installed at the practice location. The captured content is later assigned to the user's virtual representative i.e. a 3d character created based on his/her physical body features for side by side analysis with the reference. This provides countless interaction possibilities that cannot be achieved in the real world. Few examples are: multiplying the reference character and freeze two or more different moments (frames) and create a walkthrough, creating an immersive timeline based on the actor's progress (also requires multiplying), assigning reference moves to the user's avatar to be compared with his/her movements by himself/herself or anyone else (different from side by side comparison with the reference character), and many others. What has been discussed above is fully illustrated and described in this paper including detailed figures. The contribution of this study can be extended to various fields from acting and sport to stop motion and creative art, as the processes presented in the paper are designed in the most affordable way, using hardware and software currently available to basic users. © 2017 IEEE.","Gesture; Htc vive; Immersive virtual environments; Immersive virtual reality; Learning in virtual reality; Mocap; Oculus rift; Steam Vr; Tacit knowledge transfer; Unity; Virtual reality","Cameras; Digital libraries; Knowledge management; Sports; Stereo image processing; Virtual reality; Gesture; Htc vive; Immersive virtual environments; Immersive virtual reality; Mocap; Oculus rift; Tacit knowledge transfers; Unity; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85049737638
"Boyd L.E., Gupta S., Vikmani S.B., Gutierrez C.M., Yang J., Linstead E., Hayes G.R.","36141837900;57209786164;57193740783;57202044763;57202050920;16307496400;8589042500;","VrSocial: Toward immersive therapeutic VR systems for children with autism",2018,"Conference on Human Factors in Computing Systems - Proceedings","2018-April",,,"","",,10,"10.1145/3173574.3173778","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046938462&doi=10.1145%2f3173574.3173778&partnerID=40&md5=1cc86c91907a43d818f2dc3fe15937ce","Department of Informatics, UC Irvine, Irvine, United States; Cornona Del Mar High School, Newport Beach, United States; Computer Science Chapman University, Orange, United States","Boyd, L.E., Department of Informatics, UC Irvine, Irvine, United States; Gupta, S., Department of Informatics, UC Irvine, Irvine, United States; Vikmani, S.B., Department of Informatics, UC Irvine, Irvine, United States; Gutierrez, C.M., Department of Informatics, UC Irvine, Irvine, United States; Yang, J., Cornona Del Mar High School, Newport Beach, United States; Linstead, E., Computer Science Chapman University, Orange, United States; Hayes, G.R., Department of Informatics, UC Irvine, Irvine, United States","Social communication frequently includes nuanced nonverbal communication cues, including eye contact, gestures, facial expressions, body language, and tone of voice. This type of communication is central to face-to-face interaction, but can be challenging for children and adults with autism. Innovative technologies can provide support by augmenting human-delivered cuing and automated prompting. Specifically, immersive virtual reality (VR) offers an option to generalize social skill interventions by concretizing nonverbal information in real-time social interactions. In this work, we explore the design and evaluation of three nonverbal communication applications in immersive VR. The results of this work indicate that delivering real-time visualizations of proximity, speaker volume, and duration of one's speech is feasible in immersive VR and effective for real-time support for proximity regulation for children with autism. We conclude with design considerations for therapeutic VR systems. © 2018 Association for Computing Machinery.","Accessibility; Assistive technology; Autism; Immersive VR; Nonverbal communication; Prosody; Proximity; Visualization","Diseases; Flow visualization; Human engineering; Visualization; Accessibility; Assistive technology; Autism; Immersive VR; Non-verbal communications; Prosody; Proximity; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85046938462
"Gabriel A., Ortiz M.","56405176100;57202605654;","Virtual reality and recommendation system to design mobility system",2018,"Proceedings - 13th International Conference on Signal-Image Technology and Internet-Based Systems, SITIS 2017","2018-January",,,"490","495",,,"10.1109/SITIS.2017.86","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048889953&doi=10.1109%2fSITIS.2017.86&partnerID=40&md5=a1c55b2837395eefbd726b86ef1ddb3e","LCPI, Arts et Métiers ParisTech, Paris, France; ERPI, Université de Lorraine, Nancy, France","Gabriel, A., LCPI, Arts et Métiers ParisTech, Paris, France; Ortiz, M., ERPI, Université de Lorraine, Nancy, France","In the domain of urbanism and more particularly the design of mobility system, the end-users are poorly involved whereas they condition the success of new infrastructure. The generalization of policies for active mobility urges the importance of correctly design the system of mobility. The success goes through the consideration of end-user needs. However, there is always a gap between the needs of the users and reality. We assume that virtual reality can ease user-centered design approach by letting the users experiment the technical solutions. Although maps and mockup permit exchanges between designers and end-users to improve the final design, this research assume that immersive environment is more efficient. Virtual reality seems to be a relevant tool for a user-centered approach applied to mobility system. The difficulty remains providing the adapted information to the designers who are the responsible to make the decision of the solution. The aim is not only to use virtual reality in the design process but also suggests a methodology to imply users in the design process and assist the designer during the decision-making. © 2017 IEEE.","Mobility system; Recommandation system; Virtual reality","Decision making; Human computer interaction; Regional planning; Virtual reality; Design process; End users; Immersive environment; Mobility systems; Recommandation system; Technical solutions; User-centered approach; User-centered design approaches; User centered design",Conference Paper,"Final","",Scopus,2-s2.0-85048889953
"Massetti T., Fávero F.M., De Menezes L.D.C., Alvarez M.P.B., Crocetta T.B., Guarnieri R., Nunes F.L.S., Monteiro C.B.D.M., Silva T.D.D.","55546122700;36113108600;57191485293;57193085957;54898013000;57193692889;7102392843;55481862300;55546962700;","Achievement of Virtual and Real Objects Using a Short-Term Motor Learning Protocol in People with Duchenne Muscular Dystrophy: A Crossover Randomized Controlled Trial",2018,"Games for Health Journal","7","2",,"107","115",,12,"10.1089/g4h.2016.0088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045379157&doi=10.1089%2fg4h.2016.0088&partnerID=40&md5=fe7ff5c326b3e0fd633cb2d730cfe4f7","Faculty of Medicine, University of São Paulo, Rua: Cipotanea, 51. Cidade Universitaria, Sao Paulo, CEP 05360-160, Brazil; Paulista School of Medicine, Federal University of São Paulo, UNIFESP, São Paulo, Brazil; Faculty of Medicine, ABC, Santo André, Brazil; School of Arts, Sciences and Humanities, University of São Paulo, EACH-USP, São Paulo, Brazil","Massetti, T., Faculty of Medicine, University of São Paulo, Rua: Cipotanea, 51. Cidade Universitaria, Sao Paulo, CEP 05360-160, Brazil; Fávero, F.M., Paulista School of Medicine, Federal University of São Paulo, UNIFESP, São Paulo, Brazil; De Menezes, L.D.C., Faculty of Medicine, University of São Paulo, Rua: Cipotanea, 51. Cidade Universitaria, Sao Paulo, CEP 05360-160, Brazil; Alvarez, M.P.B., Faculty of Medicine, University of São Paulo, Rua: Cipotanea, 51. Cidade Universitaria, Sao Paulo, CEP 05360-160, Brazil; Crocetta, T.B., Faculty of Medicine, ABC, Santo André, Brazil; Guarnieri, R., Faculty of Medicine, ABC, Santo André, Brazil; Nunes, F.L.S., School of Arts, Sciences and Humanities, University of São Paulo, EACH-USP, São Paulo, Brazil; Monteiro, C.B.D.M., Faculty of Medicine, University of São Paulo, Rua: Cipotanea, 51. Cidade Universitaria, Sao Paulo, CEP 05360-160, Brazil; Silva, T.D.D., Paulista School of Medicine, Federal University of São Paulo, UNIFESP, São Paulo, Brazil","Objective: To evaluate whether people with Duchenne muscular dystrophy (DMD) practicing a task in a virtual environment could improve performance given a similar task in a real environment, as well as distinguishing whether there is transference between performing the practice in virtual environment and then a real environment and vice versa. Methods: Twenty-two people with DMD were evaluated and divided into two groups. The goal was to reach out and touch a red cube. Group A began with the real task and had to touch a real object, and Group B began with the virtual task and had to reach a virtual object using the Kinect system. Results: ANOVA showed that all participants decreased the movement time from the first (M = 973 ms) to the last block of acquisition (M = 783 ms) in both virtual and real tasks and motor learning could be inferred by the short-term retention and transfer task (with increasing distance of the target). However, the evaluation of task performance demonstrated that the virtual task provided an inferior performance when compared to the real task in all phases of the study, and there was no effect for sequence. Conclusions: Both virtual and real tasks promoted improvement of performance in the acquisition phase, short-term retention, and transfer. However, there was no transference of learning between environments. In conclusion, it is recommended that the use of virtual environments for individuals with DMD needs to be considered carefully. © Copyright 2018, Mary Ann Liebert, Inc. 2018.","Duchenne muscular dystrophy; Virtual reality game","adolescent; analysis of variance; Brazil; child; computer interface; controlled study; crossover procedure; Duchenne muscular dystrophy; human; male; motor performance; physiology; psychology; randomized controlled trial; standards; task performance; transfer of learning; trends; video game; virtual reality; young adult; Adolescent; Analysis of Variance; Brazil; Child; Cross-Over Studies; Humans; Male; Motor Skills; Muscular Dystrophy, Duchenne; Task Performance and Analysis; Transfer (Psychology); User-Computer Interface; Video Games; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85045379157
"Murcia-López M., Steed A.","57194036190;18435050200;","A comparison of virtual and physical training transfer of bimanual assembly tasks",2018,"IEEE Transactions on Visualization and Computer Graphics","24","4",,"1574","1583",,22,"10.1109/TVCG.2018.2793638","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041644744&doi=10.1109%2fTVCG.2018.2793638&partnerID=40&md5=df74850c0558ed09574af1eb79529d4e","University College London, United Kingdom","Murcia-López, M., University College London, United Kingdom; Steed, A., University College London, United Kingdom","As we explore the use of consumer virtual reality technology for training applications, there is a need to evaluate its validity compared to more traditional training formats. In this paper, we present a study that compares the effectiveness of virtual training and physical training for teaching a bimanual assembly task. In a between-subjects experiment, 60 participants were trained to solve three 3D burr puzzles in one of six conditions comprised of virtual and physical training elements. In the four physical conditions, training was delivered via paper-And video-based instructions, with or without the physical puzzles to practice with. In the two virtual conditions, participants learnt to assemble the puzzles in an interactive virtual environment, with or without 3D animations showing the assembly process. After training, we conducted immediate tests in which participants were asked to solve a physical version of the puzzles. We measured performance through success rates and assembly completion testing times. We also measured training times as well as subjective ratings on several aspects of the experience. Our results show that the performance of virtually trained participants was promising. A statistically significant difference was not found between virtual training with animated instructions and the best performing physical condition (in which physical blocks were available during training) for the last and most complex puzzle in terms of success rates and testing times. Performance in retention tests two weeks after training was generally not as good as expected for all experimental conditions. We discuss the implications of the results and highlight the validity of virtual reality systems in training. © 2018 IEEE Computer Society. All rights reserved.","Assembly; Learning transfer; Training; Virtual reality","Assembly; Ergonomics; Haptic interfaces; Personnel training; Testing; Virtual reality; Experimental conditions; Interactive virtual environments; Learning Transfer; Statistically significant difference; Three-dimensional display; Training applications; Virtual reality system; Virtual reality technology; E-learning; adult; comparative study; computer interface; female; human; male; physiology; task performance; transfer of learning; virtual reality; young adult; Adult; Female; Humans; Male; Task Performance and Analysis; Transfer (Psychology); User-Computer Interface; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85041644744
"Rousset T., Bourdin C., Goulon C., Monnoyer J., Vercher J.-L.","57063135900;6603566648;26535970800;57063170900;7004221343;","Misperception of egocentric distances in virtual environments: More a question of training than a technological issue?",2018,"Displays","52",,,"8","20",,2,"10.1016/j.displa.2018.02.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042939701&doi=10.1016%2fj.displa.2018.02.004&partnerID=40&md5=bb33373e8b990b9c57e6879e0a9e61d9","Aix-Marseille Univ, CNRS, ISM, Marseille, France; Groupe PSA, Velizy Villacoublay, France","Rousset, T., Aix-Marseille Univ, CNRS, ISM, Marseille, France; Bourdin, C., Aix-Marseille Univ, CNRS, ISM, Marseille, France; Goulon, C., Aix-Marseille Univ, CNRS, ISM, Marseille, France; Monnoyer, J., Aix-Marseille Univ, CNRS, ISM, Marseille, France, Groupe PSA, Velizy Villacoublay, France; Vercher, J.-L., Aix-Marseille Univ, CNRS, ISM, Marseille, France","Findings from virtual reality applications in general and driving or flight simulators in particular, are frequently generalized to the study of human behavior. Thus, it is crucial to ensure that the virtuality of the experimental setup has little or no effect on perception of space and motion. Most studies show that observers immersed in virtual environments (VE) perceive virtual space as compressed relative to the real world, resulting in systematic underestimations of egocentric distance. Parallax and stereopsis, known to be important depth cues for distance perception, at least for short distances, are rarely used together in driving simulators, so their interactive role during driving tasks is still not clear. Inter-individual differences in misperception are also referred to, though few studies have explored this. The aim of this study was, first, to determine whether egocentric distance perception in driving simulation depends on two depth cues, binocular disparity and motion parallax, and, second, to examine the effect of inter-individual differences. Several conditions were tested, both with and without stereoscopic vision of the scene and/or motion parallax of the head. We focused first on a range of long distances, 40–80 m (Experiment 1) and subsequently widened the range to distances from 5 to 80 m, thereby including short distances where stereopsis should be more relevant (Experiment 2). The study reveals great inter-individual variability, clearly distinguishing two participant profiles. However, results suggest that such differences do not depend on the availability of motion parallax and stereoscopic vision. The findings also show that an initial familiarization phase, under conditions similar to those of the experiments, can be predictive of participants’ perceptual behavior. © 2018 The Authors","Distance perception; Inter-individual variability; Parallax; Stereoscopy","Behavioral research; Depth perception; E-learning; Flight simulators; Geometrical optics; Stereo image processing; Binocular disparity; Distance perception; Driving simulation; Driving simulator; Individual variability; Inter-individual differences; Parallax; Stereoscopic vision; Virtual reality",Article,"Final","",Scopus,2-s2.0-85042939701
"Ma X., Yao Z., Wang Y., Pei W., Chen H.","57201641690;56911568900;7601519371;8365780300;10041330500;","Combining brain-computer interface and eye tracking for high-speed text entry in virtual reality",2018,"International Conference on Intelligent User Interfaces, Proceedings IUI",,,,"263","267",,5,"10.1145/3172944.3172988","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045452448&doi=10.1145%2f3172944.3172988&partnerID=40&md5=fff13c6fae5b3a42372fadd56cf28d65","Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China; University of Chinese, Academy of Sciences, Beijing, China; Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China","Ma, X., Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China, University of Chinese, Academy of Sciences, Beijing, China, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China; Yao, Z., Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China, University of Chinese, Academy of Sciences, Beijing, China, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China; Wang, Y., Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China, University of Chinese, Academy of Sciences, Beijing, China, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China; Pei, W., Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China, University of Chinese, Academy of Sciences, Beijing, China, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China; Chen, H., Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China, University of Chinese, Academy of Sciences, Beijing, China, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China","Gaze interaction provides an efficient way for users to communicate and control in virtual reality (VR) presented by head-mounted displays. In gaze-based text-entry systems, eye tracking and brain-computer interface (BCI) are the two most commonly used approaches. This paper presents a hybrid BCI system for text entry in VR by combining steady-state visual evoked potentials (SSVEP) and eye tracking. The user interface in VR designed a 40-target virtual keyboard using a joint frequency-phase modulation method for SSVEP. Eye position was measured by an eyetracking accessory in the VR headset. Target-related gaze direction was detected by combining simultaneously recorded SSVEP and eye position data. Offline and online experiments indicate that the proposed system can type at a speed around 10 words per minute, leading to an information transfer rate (ITR) of 270 bits per minute. The results further demonstrate the superiority of the hybrid method over single-modality methods for VR applications. © 2018 Association for Computing Machinery.","Brain-computer interface; Eye tracking; Steady-state visual evoked potentials; Text entry; Virtual reality","Electrophysiology; Eye tracking; Helmet mounted displays; Interface states; User interfaces; Virtual reality; Head mounted displays; Information transfer rate; Modulation methods; On-line experiments; Steady state visual evoked potentials; Text entry; Text entry systems; Virtual Keyboards; Brain computer interface",Conference Paper,"Final","",Scopus,2-s2.0-85045452448
"Fromberger P., Jordan K., Müller J.L.","22957487700;7202963516;7404871741;","Virtual reality applications for diagnosis, risk assessment and therapy of child abusers",2018,"Behavioral Sciences and the Law","36","2",,"235","244",,10,"10.1002/bsl.2332","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045625005&doi=10.1002%2fbsl.2332&partnerID=40&md5=556f40ad3c484a23a287c5d8d5e87f1a","Clinic for Psychiatry and Psychotherapy - Forensic Psychiatry, Human Medical Center Göttingen, Georg-August-Universität Göttingen, Germany","Fromberger, P., Clinic for Psychiatry and Psychotherapy - Forensic Psychiatry, Human Medical Center Göttingen, Georg-August-Universität Göttingen, Germany; Jordan, K., Clinic for Psychiatry and Psychotherapy - Forensic Psychiatry, Human Medical Center Göttingen, Georg-August-Universität Göttingen, Germany; Müller, J.L., Clinic for Psychiatry and Psychotherapy - Forensic Psychiatry, Human Medical Center Göttingen, Georg-August-Universität Göttingen, Germany","Despite the successful application of virtual reality (VR) in a wide variety of mental disorders and the obvious potentials that VR provides, the use of VR in the context of criminology and forensic psychology is sparse. For forensic mental health professionals, VR provides some advantages that outrun general advantages of VR, e.g., ecological validity and controllability of social situations. Most important seems to be the unique possibility to expose offenders and to train coping skills in virtual situations, which are able to elicit disorder-relevant behavior—without endangering others. VR has already been used for the assessment of deviant sexual interests, for testing the ability to transfer learned coping skills communicated during treatment to behavior, and for risk assessment of child abusers. This article reviews and discusses these innovative research projects with regard to their impact on current clinical practice regarding risk assessment and treatment as well as other implementations of VR applications in forensic mental health. Finally, ethical guidelines for VR research in forensic mental health are provided. Copyright © 2018 John Wiley & Sons, Ltd.",,"child; child abuse; human; mental disease; risk assessment; virtual reality; Child; Child Abuse; Humans; Mental Disorders; Risk Assessment; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85045625005
"Serafin S., Geronazzo M., Erkut C., Nilsson N.C., Nordahl R.","6603367536;36720522500;6507065675;54993660100;32867973300;","Sonic Interactions in Virtual Reality: State of the Art, Current Challenges, and Future Directions",2018,"IEEE Computer Graphics and Applications","38","2",,"31","43",,27,"10.1109/MCG.2018.193142628","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045191223&doi=10.1109%2fMCG.2018.193142628&partnerID=40&md5=d0263b24cb2f433025831c345d9340bd","Aalborg University, Department of Architecture, Design, and Media Technology, Denmark; Aalborg University, Denmark","Serafin, S., Aalborg University, Department of Architecture, Design, and Media Technology, Denmark; Geronazzo, M., Aalborg University, Department of Architecture, Design, and Media Technology, Denmark; Erkut, C., Aalborg University, Denmark; Nilsson, N.C., Aalborg University, Denmark; Nordahl, R., Aalborg University, Department of Architecture, Design, and Media Technology, Denmark","A high-fidelity but efficient sound simulation is an essential element of any VR experience. Many of the techniques used in virtual acoustics are graphical rendering techniques suitably modified to account for sound generation and propagation. In recent years, several advances in hardware and software technologies have been facilitating the development of immersive interactive sound-rendering experiences. In this article, we present a review of the state of the art of such simulations, with a focus on the different elements that, combined, provide a complete interactive sonic experience. This includes physics-based simulation of sound effects and their propagation in space together with binaural rendering to simulate the position of sound sources. We present how these different elements of the sound design pipeline have been addressed in the literature, trying to find the trade-off between accuracy and plausibility. Recent applications and current challenges are also presented. © 1981-2012 IEEE.","computer graphics; head-related transfer function; sonic interaction; sound rendering","Economic and social effects; Object recognition; Immersive; Information interfaces and representations; Information technology and systems; Sonic interactions; Sound and music computing; Virtual reality",Article,"Final","",Scopus,2-s2.0-85045191223
"Kim Y., Hong S., Kim G.J.","55699533800;57192155448;7403061980;","Augmented reality-based remote coaching for fast-paced physical task",2018,"Virtual Reality","22","1",,"25","36",,1,"10.1007/s10055-017-0315-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019101055&doi=10.1007%2fs10055-017-0315-2&partnerID=40&md5=e40202059b42698cc108a85ea29bb3d0","Digital Experience Laboratory, Korea University, Anam-dong, Seongbuk-gu, Seoul, South Korea","Kim, Y., Digital Experience Laboratory, Korea University, Anam-dong, Seongbuk-gu, Seoul, South Korea; Hong, S., Digital Experience Laboratory, Korea University, Anam-dong, Seongbuk-gu, Seoul, South Korea; Kim, G.J., Digital Experience Laboratory, Korea University, Anam-dong, Seongbuk-gu, Seoul, South Korea","One popular application of augmented reality (AR) is the real-time guidance and training in which the AR user receives useful information by a remote expert. For relatively fast-paced tasks, presentation of such guidance in a way that the recipient can make immediate recognition and quick understanding can be an especially challenging problem. In this paper, we present an AR-based tele-coaching system applied to the game of tennis, called the AR coach, and explore for interface design guidelines through a user study. We have evaluated the player’s performance for instruction understanding when the coaching instruction was presented in four different modalities: (1) Visual—visual only, (2) Sound—aural only/mono, (3) 3D Sound—aural only/3D and (4) Multimodal—both visual and aural/mono. Results from the experiment suggested that, among the three, the visual-only augmentation was the most effective and least distracting for the given pace of information transfer (e.g., under every 3 s). We attribute such a result to the characteristic of the visual modality to encode and present a lot of information at once and the human’s limited capability in handling and fusing multimodal information at a relatively fast rate. © 2017, Springer-Verlag London.","Augmented reality; Multimodal feedback; Pre-attentive recognition; Tele-coaching","Software engineering; Virtual reality; Information transfers; Interface designs; Multi-modal information; Multimodal feedback; Pre-attentive; Remote experts; Tele-coaching; Visual modalities; Augmented reality",Article,"Final","",Scopus,2-s2.0-85019101055
"Berger C.C., Gonzalez-Franco M., Tajadura-Jiménez A., Florencio D., Zhang Z.","57210476689;36080251200;23569030500;6602865660;13609600600;","Generic HRTFs may be good enough in virtual reality. Improving source localization through cross-modal plasticity",2018,"Frontiers in Neuroscience","12","FEB", 21,"","",,17,"10.3389/fnins.2018.00021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041845498&doi=10.3389%2ffnins.2018.00021&partnerID=40&md5=3453eac39fc20cf19e5f21f4ee10c783","Microsoft Research, Redmond, WA, United States; Division of Biology and Biological Engineering, California Institute of Technology, Pasadena, CA, United States; UCL Interaction Centre, University College London, London, United Kingdom; Interactive Systems DEI-Lab, Universidad Carlos III de Madrid, Madrid, Spain; Department Electrical Engineering, University of Washington, Seattle, WA, United States","Berger, C.C., Microsoft Research, Redmond, WA, United States, Division of Biology and Biological Engineering, California Institute of Technology, Pasadena, CA, United States; Gonzalez-Franco, M., Microsoft Research, Redmond, WA, United States; Tajadura-Jiménez, A., UCL Interaction Centre, University College London, London, United Kingdom, Interactive Systems DEI-Lab, Universidad Carlos III de Madrid, Madrid, Spain; Florencio, D., Microsoft Research, Redmond, WA, United States; Zhang, Z., Microsoft Research, Redmond, WA, United States, Department Electrical Engineering, University of Washington, Seattle, WA, United States","Auditory spatial localization in humans is performed using a combination of interaural time differences, interaural level differences, as well as spectral cues provided by the geometry of the ear. To render spatialized sounds within a virtual reality (VR) headset, either individualized or generic Head Related Transfer Functions (HRTFs) are usually employed. The former require arduous calibrations, but enable accurate auditory source localization, which may lead to a heightened sense of presence within VR. The latter obviate the need for individualized calibrations, but result in less accurate auditory source localization. Previous research on auditory source localization in the real world suggests that our representation of acoustic space is highly plastic. In light of these findings, we investigated whether auditory source localization could be improved for users of generic HRTFs via cross-modal learning. The results show that pairing a dynamic auditory stimulus, with a spatio-temporally aligned visual counterpart, enabled users of generic HRTFs to improve subsequent auditory source localization. Exposure to the auditory stimulus alone or to asynchronous audiovisual stimuli did not improve auditory source localization. These findings have important implications for human perception as well as the development of VR systems as they indicate that generic HRTFs may be enough to enable good auditory source localization in VR. © 2018 Berger, Gonzalez-Franco, Tajadura-Jiménez, Florencio and Zhang.","Auditory perception; Auditory training; Cross-modal perception; Cross-modal plasticity; HRTF (head related transfer function); Spatial audio; Virtual reality","article; auditory stimulation; calibration; head; hearing; human; learning; plasticity; virtual reality",Article,"Final","",Scopus,2-s2.0-85041845498
"Chittaro L., Corbett C.L., McLean G.A., Zangrando N.","7004119007;7102781291;57196262227;36172681100;","Safety knowledge transfer through mobile virtual reality: A study of aviation life preserver donning",2018,"Safety Science","102",,,"159","168",,35,"10.1016/j.ssci.2017.10.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032438643&doi=10.1016%2fj.ssci.2017.10.012&partnerID=40&md5=7748b44406f111c455481c472e4b9707","Human-Computer Interaction Lab (HCI Lab), University of Udine, Italy; Prime Stratagem, LLC, United States","Chittaro, L., Human-Computer Interaction Lab (HCI Lab), University of Udine, Italy; Corbett, C.L., Prime Stratagem, LLC, United States; McLean, G.A., Prime Stratagem, LLC, United States; Zangrando, N., Human-Computer Interaction Lab (HCI Lab), University of Udine, Italy","Aviation safety knowledge is a key factor in determining how passengers will respond in an emergency, but the effectiveness of the tools (preflight safety briefing, safety briefing card) used by airlines to educate passengers about safety has been shown to be lacking. This paper explores how one of these tools could be made interactive in order to increase its effectiveness. In particular, we use Virtual Reality (VR) techniques, adapting them to the constraints imposed by on-board aircraft use, such as usage on non-immersive, small displays. As a practical application, the paper examines aviation life preserver donning, which the literature has shown to be particularly difficult for passengers. To evaluate the proposed mobile VR tool, we contrasted it with the traditional safety briefing card in a between-groups study with 68 participants, age 20–24, focusing on different aspects of effectiveness. The results of the study show that the participants who used the mobile VR tool were able to transfer the presented safety knowledge to the real world, and don an aviation life preserver significantly faster and with fewer errors than participants who used the traditional briefing card. Moreover, these objective results were consistent with subjective ratings by participants; the mobile VR tool was perceived as significantly more engaging, simpler, and more effective than the traditional briefing card. Finally, participants who used the mobile VR tool attained a higher level of self-efficacy. The generalizability of these results would benefit with additional work aimed at an older age cohort that would ostensibly be less familiar with interactive VR technology. © 2017 Elsevier Ltd","Aviation safety; Mobile devices; Safety education; Safety training; Virtual reality","Fighter aircraft; Knowledge management; Mobile devices; Safety engineering; Training aircraft; Transportation; Virtual reality; Aviation safety; Safety education; Safety knowledge; Safety training; Self efficacy; Small display; Subjective rating; VR technology; Safety factor; adult; aircraft; analytical error; Article; aviation; briefing card; clinical effectiveness; controlled study; female; human; knowledge; male; priority journal; self concept; simulation training; traffic safety; virtual reality; young adult",Article,"Final","",Scopus,2-s2.0-85032438643
"Li X., Yi W., Chi H.-L., Wang X., Chan A.P.C.","57193211001;55125204800;35096047900;8945580300;56844258500;","A critical review of virtual and augmented reality (VR/AR) applications in construction safety",2018,"Automation in Construction","86",,,"150","162",,176,"10.1016/j.autcon.2017.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034043364&doi=10.1016%2fj.autcon.2017.11.003&partnerID=40&md5=2ee7532a8fe659b1dda070548e3767b4","Department of Building and Real Estate, The Hong Kong Polytechnic University, Hong Kong; School of Engineering and Advanced Technology, College of Sciences, Massey University, New Zealand; The Australasian Joint Research Centre for Building Information Modelling, School of Built Environment, Curtin University, Perth, Australia; The International Scholar, Department of Housing and Interior Design, Kyung Hee University, Australia","Li, X., Department of Building and Real Estate, The Hong Kong Polytechnic University, Hong Kong; Yi, W., School of Engineering and Advanced Technology, College of Sciences, Massey University, New Zealand; Chi, H.-L., Department of Building and Real Estate, The Hong Kong Polytechnic University, Hong Kong; Wang, X., The Australasian Joint Research Centre for Building Information Modelling, School of Built Environment, Curtin University, Perth, Australia, The International Scholar, Department of Housing and Interior Design, Kyung Hee University, Australia; Chan, A.P.C., Department of Building and Real Estate, The Hong Kong Polytechnic University, Hong Kong","Construction is a high hazard industry which involves many factors that are potentially dangerous to workers. Safety has always been advocated by many construction companies, and they have been working hard to make sure their employees are protected from fatalities and injuries. With the advent of Virtual and Augmented Reality (VR/AR), there has been a witnessed trend of capitalizing on sophisticated immersive VR/AR applications to create forgiving environments for visualizing complex workplace situations, building up risk-preventive knowledge and undergoing training. To better understand the state-of-the-art of VR/AR applications in construction safety (VR/AR-CS) and from which to uncover the related issues and propose possible improvements, this paper starts with a review and synthesis of research evidence for several VR/AR prototypes, products and the related training and evaluation paradigms. Predicated upon a wide range of well-acknowledged scholarly journals, this paper comes up with a generic taxonomy consisting of VR/AR technology characteristics, application domains, safety scenarios and evaluation methods. According to this taxonomy, a number of technical features and types that could be implemented in the context of construction safety enhancement are derived and further elaborated, while significant application domains and trends regarding the VR/AR-CS research are generalized, i.e., hazards recognition and identification, safety training and education, safety instruction and inspection, and so on. Last but not least, this study sets forth a list of gaps derived from the in-depth review and comes up with the prospective research works. It is envisioned that the outcomes of this paper could assist both researchers and industrial practitioners with appreciating the research and practice frontier of VR/AR-CS and soliciting the latest VR/AR applications. © 2017 Elsevier B.V.","Augmented reality; Construction; Review; Safety; Virtual reality","Accident prevention; Augmented reality; Construction; Construction industry; Hazards; Industrial research; Occupational risks; Petroleum reservoir evaluation; Reviews; Taxonomies; Construction companies; Construction safety; Evaluation methods; Industrial practitioners; Safety instructions; Scholarly journals; Technology characteristics; Virtual and augmented reality; Virtual reality",Article,"Final","",Scopus,2-s2.0-85034043364
"Ip H.H.S., Wong S.W.L., Chan D.F.Y., Byrne J., Li C., Yuan V.S.N., Lau K.S.Y., Wong J.Y.W.","7005395690;35095800900;7402216810;55327177600;56180363500;57190301256;56014513500;57190292326;","Enhance emotional and social adaptation skills for children with autism spectrum disorder: A virtual reality enabled approach",2018,"Computers and Education","117",,,"1","15",,52,"10.1016/j.compedu.2017.09.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034031316&doi=10.1016%2fj.compedu.2017.09.010&partnerID=40&md5=5461287673669e8bfbf4e12a366653f0","Centre for Innovative Applications of Internet and Multimedia Technologies, City University of Hong Kong, Kowloon Tong, Hong Kong; Department of Education Studies, Hong Kong Baptist University, Kowloon Tong, Hong Kong; Department of Paediatrics, Faculty of Medicine, The Chinese University of Hong Kong, Shatin, Hong Kong","Ip, H.H.S., Centre for Innovative Applications of Internet and Multimedia Technologies, City University of Hong Kong, Kowloon Tong, Hong Kong; Wong, S.W.L., Department of Education Studies, Hong Kong Baptist University, Kowloon Tong, Hong Kong; Chan, D.F.Y., Department of Paediatrics, Faculty of Medicine, The Chinese University of Hong Kong, Shatin, Hong Kong; Byrne, J., Centre for Innovative Applications of Internet and Multimedia Technologies, City University of Hong Kong, Kowloon Tong, Hong Kong; Li, C., Centre for Innovative Applications of Internet and Multimedia Technologies, City University of Hong Kong, Kowloon Tong, Hong Kong; Yuan, V.S.N., Centre for Innovative Applications of Internet and Multimedia Technologies, City University of Hong Kong, Kowloon Tong, Hong Kong; Lau, K.S.Y., Centre for Innovative Applications of Internet and Multimedia Technologies, City University of Hong Kong, Kowloon Tong, Hong Kong; Wong, J.Y.W., Centre for Innovative Applications of Internet and Multimedia Technologies, City University of Hong Kong, Kowloon Tong, Hong Kong","Deficits in social-emotional reciprocity, one of the diagnostic criteria of Autism Spectrum Disorder (ASD), greatly hinders children with ASD from responding appropriately and adapting themselves in various social situations. Although evidences have shown that virtual reality environment is a promising tool for emotional and social adaptation skills training on ASD population, there is a lack of large-scale trials with intensive evaluations to support such findings. This paper presents a virtual reality enabled program for enhancing emotional and social adaptation skills for children with ASD. Six unique learning scenarios, of which one focuses on emotion control and relaxation strategies, four that simulate various social situations, and one that facilitates consolidation and generalization, are designed and developed with corresponding psychoeducation procedures and protocols. The learning scenarios are presented to the children via a 4-side immersive virtual reality environment (a.k.a., half-CAVE) with non-intrusive motion tracking. A total number of 94 children between the ages of 6–12 with clinical diagnosis of ASD participated in the 28-session program that lasted for 14 weeks. By comparing pre- and post-assessments, results reported in this paper show significant improvements in the project's primary measures on children's emotion expression and regulation and social-emotional reciprocity but not on other secondary measures. © 2017 Elsevier Ltd","Autism spectrum disorders; Emotional skills; Situated learning; Social adaptation; Virtual reality","Diagnosis; Diseases; Motion tracking; Program diagnostics; Social aspects; Autism spectrum disorders; Children with autisms; Emotional skills; Immersive virtual reality; Relaxation strategies; Situated learning; Social adaptation; Virtual-reality environment; Virtual reality",Article,"Final","",Scopus,2-s2.0-85034031316
"Rus-Calafell M., Garety P., Sason E., Craig T.J.K., Valmaggia L.R.","35094538900;7004167371;57195105778;55243134200;23006795600;","Virtual reality in the assessment and treatment of psychosis: A systematic review of its utility, acceptability and effectiveness",2018,"Psychological Medicine","48","3",,"362","391",,59,"10.1017/S0033291717001945","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025459856&doi=10.1017%2fS0033291717001945&partnerID=40&md5=53842339e061dc473278c927a1ab6c8c","King's College London, Institute of Psychiatry Psychology and Neuroscience, PO 77, De Crespigny Park, London, SE5 8AF, United Kingdom; South London and Maudsley NHS Trust, London, United Kingdom","Rus-Calafell, M., King's College London, Institute of Psychiatry Psychology and Neuroscience, PO 77, De Crespigny Park, London, SE5 8AF, United Kingdom, South London and Maudsley NHS Trust, London, United Kingdom; Garety, P., King's College London, Institute of Psychiatry Psychology and Neuroscience, PO 77, De Crespigny Park, London, SE5 8AF, United Kingdom, South London and Maudsley NHS Trust, London, United Kingdom; Sason, E., King's College London, Institute of Psychiatry Psychology and Neuroscience, PO 77, De Crespigny Park, London, SE5 8AF, United Kingdom; Craig, T.J.K., King's College London, Institute of Psychiatry Psychology and Neuroscience, PO 77, De Crespigny Park, London, SE5 8AF, United Kingdom, South London and Maudsley NHS Trust, London, United Kingdom; Valmaggia, L.R., King's College London, Institute of Psychiatry Psychology and Neuroscience, PO 77, De Crespigny Park, London, SE5 8AF, United Kingdom, South London and Maudsley NHS Trust, London, United Kingdom","Over the last two decades, there has been a rapid increase of studies testing the efficacy and acceptability of virtual reality in the assessment and treatment of mental health problems. This systematic review was carried out to investigate the use of virtual reality in the assessment and the treatment of psychosis. Web of Science, PsychInfo, EMBASE, Scopus, ProQuest and PubMed databases were searched, resulting in the identification of 638 articles potentially eligible for inclusion; of these, 50 studies were included in the review. The main fields of research in virtual reality and psychosis are: safety and acceptability of the technology; neurocognitive evaluation; functional capacity and performance evaluation; assessment of paranoid ideation and auditory hallucinations; and interventions. The studies reviewed indicate that virtual reality offers a valuable method of assessing the presence of symptoms in ecologically valid environments, with the potential to facilitate learning new emotional and behavioural responses. Virtual reality is a promising method to be used in the assessment of neurocognitive deficits and the study of relevant clinical symptoms. Furthermore, preliminary findings suggest that it can be applied to the delivery of cognitive rehabilitation, social skills training interventions and virtual reality-assisted therapies for psychosis. The potential benefits for enhancing treatment are highlighted. Recommendations for future research include demonstrating generalisability to real-life settings, examining potential negative effects, larger sample sizes and long-term follow-up studies. The present review has been registered in the PROSPERO register: CDR 4201507776. Copyright © Cambridge University Press 2017.","Hallucinations; neuropsychology; paranoia; psychosis; schizophrenia; social functioning; systematic review; virtual reality","computer interface; human; patient attitude; patient safety; psychosis; randomized controlled trial (topic); virtual reality exposure therapy; Humans; Patient Acceptance of Health Care; Patient Safety; Psychotic Disorders; Randomized Controlled Trials as Topic; User-Computer Interface; Virtual Reality Exposure Therapy",Article,"Final","",Scopus,2-s2.0-85025459856
"Dehn L.B., Kater L., Piefke M., Botsch M., Driessen M., Beblo T.","55893825700;57192807227;6507173176;6602523499;56056374100;55978325200;","Training in a comprehensive everyday-like virtual reality environment compared to computerized cognitive training for patients with depression",2018,"Computers in Human Behavior","79",,,"40","52",,15,"10.1016/j.chb.2017.10.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032007894&doi=10.1016%2fj.chb.2017.10.019&partnerID=40&md5=2353908903251aac94bfb95d545d8767","Clinic for Psychiatry and Psychotherapy Bethel, Remterweg 69-71, Bielefeld, D-33617, Germany; Clinic of Internal and Geriatric Medicine, Schildische Str. 99, Bielefeld, D-33611, Germany; Department of Psychology and Psychotherapy, Witten/Herdecke University, Alfred-Herrhausen-Str. 50, Witten, D-58448, Germany; Computer Graphics and Geometry Processing, Bielefeld University, P.O. Box 10 01 31, Bielefeld, D-33501, Germany","Dehn, L.B., Clinic for Psychiatry and Psychotherapy Bethel, Remterweg 69-71, Bielefeld, D-33617, Germany; Kater, L., Clinic of Internal and Geriatric Medicine, Schildische Str. 99, Bielefeld, D-33611, Germany; Piefke, M., Department of Psychology and Psychotherapy, Witten/Herdecke University, Alfred-Herrhausen-Str. 50, Witten, D-58448, Germany; Botsch, M., Computer Graphics and Geometry Processing, Bielefeld University, P.O. Box 10 01 31, Bielefeld, D-33501, Germany; Driessen, M., Computer Graphics and Geometry Processing, Bielefeld University, P.O. Box 10 01 31, Bielefeld, D-33501, Germany; Beblo, T., Clinic for Psychiatry and Psychotherapy Bethel, Remterweg 69-71, Bielefeld, D-33617, Germany","Neurocognitive impairments in patients with depression compromise everyday functioning. Thus, should neuropsychological therapy be designed as real-life-like as possible to maximize transfer effects? We investigated whether ecological validity of computerized cognitive training could be increased by a comprehensive everyday-life-simulating training device combining virtual reality, 360°-all-around visibility and autonomous navigation motions. In an eight days training program, patients exercised the learning and purchasing of shopping list products in a virtual supermarket using either the novel training device (n = 21) or a corresponding desktop application (n = 17). In a pre-post-design, effects of the two training conditions were compared regarding several outcome measures. Altogether, results did not prove a benefit of the more naturalistic training setting regarding different training performances (recognition, performance speed, spatial orientation), self-perceived daily cognitive impairments, a real-life shopping task as well as various neuropsychological capabilities. Findings are discussed in the context of general challenges in striving after ecological validity in neuropsychology. © 2017 Elsevier Ltd","Cognitive impairment; Cognitive remediation; Computerized training; Depression; Ecological validity; Virtual reality","Application programs; Ecology; Virtual reality; Autonomous navigation; Cognitive impairment; Depression; Desktop applications; Ecological validity; Spatial orientations; Training conditions; Virtual-reality environment; E-learning",Article,"Final","",Scopus,2-s2.0-85032007894
"Ankomah P., Vangorp P.","57217224949;18435394900;","Virtual reality: A literature review and metrics-based classification",2018,"Computer Graphics and Visual Computing, CGVC 2018",,,,"173","181",,,"10.2312/cgvc.20181222","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086820445&doi=10.2312%2fcgvc.20181222&partnerID=40&md5=67913b689e62c8521ffe6266f4e15c46","Edge Hill University, United Kingdom","Ankomah, P., Edge Hill University, United Kingdom; Vangorp, P., Edge Hill University, United Kingdom","This paper presents a multi-disciplinary overview of research evaluating virtual reality (VR). The main aim is to review and classify VR research based on several metrics: presence and immersion, navigation and interaction, knowledge improvement, performance and usability. With the continuous development and consumerisation of VR, several application domains have studied the impact of VR as an enhanced alternative environment for performing tasks. However, VR experiment results often cannot be generalised but require specific datasets and tasks suited to each domain. This review and classification of VR metrics presents an alternative metrics-based view of VR experiments and research. © 2018 The Author(s) Eurographics Proceedings © 2018 The Eurographics Association.",,"Consumerisation; Continuous development; Literature reviews; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85086820445
"Doniger G.M., Beeri M.S., Bahar-Fuchs A., Gottlieb A., Tkachov A., Kenan H., Livny A., Bahat Y., Sharon H., Ben-Gal O., Cohen M., Zeilig G., Plotnik M.","6507913418;55664808600;24068290900;57195223683;57201615263;57201616398;57189464305;25926895000;36614758100;57197727270;57201616049;6701802378;6603202801;","Virtual reality-based cognitive-motor training for middle-aged adults at high Alzheimer's disease risk: A randomized controlled trial",2018,"Alzheimer's and Dementia: Translational Research and Clinical Interventions","4",,,"118","129",,28,"10.1016/j.trci.2018.02.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045377385&doi=10.1016%2fj.trci.2018.02.005&partnerID=40&md5=ec7cee9f2f2fad023982a4168a65d80c","Center of Advanced Technologies in Rehabilitation, Sheba Medical Center, Ramat Gan, Israel; Joseph Sagol Neuroscience Center, Sheba Medical Center, Ramat Gan, Israel; Baruch Ivcher School of Psychology, Interdisciplinary Center (IDC) Herzliya, Herzliya, Israel; Department of Psychiatry, The Icahn School of Medicine at Mount Sinai, New York, NY, United States; Center for Research on Aging, Health, and Wellbeing, Research School of Population Health, The Australian National University, Canberra, ACT, Australia; The Academic Unit for Psychiatry of Old Age, Department of Psychiatry, The University of Melbourne, Victoria, Australia; Sackler Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel; Department of Diagnostic Imaging, Sheba Medical Center, Ramat Gan, Israel; Department of Neurological Rehabilitation, Sheba Medical Center, Ramat Gan, Israel; Department of Physiology and Pharmacology, Sackler Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel; Sagol School of Neuroscience, Tel Aviv University, Tel Aviv, Israel","Doniger, G.M., Center of Advanced Technologies in Rehabilitation, Sheba Medical Center, Ramat Gan, Israel, Joseph Sagol Neuroscience Center, Sheba Medical Center, Ramat Gan, Israel, Baruch Ivcher School of Psychology, Interdisciplinary Center (IDC) Herzliya, Herzliya, Israel; Beeri, M.S., Joseph Sagol Neuroscience Center, Sheba Medical Center, Ramat Gan, Israel, Baruch Ivcher School of Psychology, Interdisciplinary Center (IDC) Herzliya, Herzliya, Israel, Department of Psychiatry, The Icahn School of Medicine at Mount Sinai, New York, NY, United States; Bahar-Fuchs, A., Joseph Sagol Neuroscience Center, Sheba Medical Center, Ramat Gan, Israel, Center for Research on Aging, Health, and Wellbeing, Research School of Population Health, The Australian National University, Canberra, ACT, Australia, The Academic Unit for Psychiatry of Old Age, Department of Psychiatry, The University of Melbourne, Victoria, Australia; Gottlieb, A., Center of Advanced Technologies in Rehabilitation, Sheba Medical Center, Ramat Gan, Israel; Tkachov, A., Joseph Sagol Neuroscience Center, Sheba Medical Center, Ramat Gan, Israel; Kenan, H., Joseph Sagol Neuroscience Center, Sheba Medical Center, Ramat Gan, Israel; Livny, A., Joseph Sagol Neuroscience Center, Sheba Medical Center, Ramat Gan, Israel, Sackler Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel, Department of Diagnostic Imaging, Sheba Medical Center, Ramat Gan, Israel; Bahat, Y., Center of Advanced Technologies in Rehabilitation, Sheba Medical Center, Ramat Gan, Israel; Sharon, H., Center of Advanced Technologies in Rehabilitation, Sheba Medical Center, Ramat Gan, Israel; Ben-Gal, O., Center of Advanced Technologies in Rehabilitation, Sheba Medical Center, Ramat Gan, Israel; Cohen, M., Center of Advanced Technologies in Rehabilitation, Sheba Medical Center, Ramat Gan, Israel, Joseph Sagol Neuroscience Center, Sheba Medical Center, Ramat Gan, Israel; Zeilig, G., Sackler Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel, Department of Neurological Rehabilitation, Sheba Medical Center, Ramat Gan, Israel; Plotnik, M., Center of Advanced Technologies in Rehabilitation, Sheba Medical Center, Ramat Gan, Israel, Department of Physiology and Pharmacology, Sackler Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel, Sagol School of Neuroscience, Tel Aviv University, Tel Aviv, Israel","Introduction: Ubiquity of Alzheimer's disease (AD) coupled with relatively ineffectual pharmacologic treatments has spurred interest in nonpharmacologic lifestyle interventions for prevention or risk reduction. However, evidence of neuroplasticity notwithstanding, there are few scientifically rigorous, ecologically relevant brain training studies focused on building cognitive reserve in middle age to protect against cognitive decline. This pilot study will examine the ability of virtual reality (VR) cognitive training to improve cognition and cerebral blood flow (CBF) in middle-aged individuals at high AD risk due to parental history. Methods: The design is an assessor-blind, parallel group, randomized controlled trial of VR cognitive-motor training in middle-aged adults with AD family history. The experimental group will be trained with adaptive “real-world” VR tasks targeting sustained and selective attention, working memory, covert rule deduction, and planning, while walking on a treadmill. One active control group will perform the VR tasks without treadmill walking; another will walk on a treadmill while watching scientific documentaries (nonspecific cognitive stimulation). A passive (waitlist) control group will not receive training. Training sessions will be 45 minutes, twice/week for 12 weeks. Primary outcomes are global cognition and CBF (from arterial spin labeling [ASL]) at baseline, immediately after training (training gain), and 3 months post-training (maintenance gain). We aim to recruit 125 participants, including 20 passive controls and 35 in the other groups. Discussion: Current pharmacologic therapies are for symptomatic AD patients, whereas nonpharmacologic training is administrable before symptom onset. Emerging evidence suggests that cognitive training improves cognitive function. However, a more ecologically valid cognitive-motor VR setting that better mimics complex daily activities may augment transfer of trained skills. VR training has benefited clinical cohorts, but benefit in asymptomatic high-risk individuals is unknown. If effective, this trial may help define a prophylactic regimen for AD, adaptable for home-based application in high-risk individuals. © 2018 The Authors","Alzheimer's disease; Arterial spin labeling; Cerebral blood flow; Cognition; Cognitive training; MRI; Neuroplasticity; Prevention; Virtual reality","adult; age; Alzheimer disease; arterial spin labeling; Article; brain blood flow; cognition; cognitive reserve; controlled study; daily life activity; high risk patient; human; major clinical study; middle aged; motor performance; nerve cell plasticity; nerve degeneration; nuclear magnetic resonance imaging; outcome assessment; pilot study; priority journal; prospective study; quality of life; randomized controlled trial; selective attention; software design; training; transfer of learning; virtual reality; walking; working memory",Article,"Final","",Scopus,2-s2.0-85045377385
"Zou Z., Arruda L., Ergan S.","57195301528;57208333256;55220455300;","Characteristics of models that impact transformation of BIMS to virtual environments to support facility management operations",2018,"Journal of Civil Engineering and Management","24","6",,"481","498",,4,"10.3846/jcem.2018.5689","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064496403&doi=10.3846%2fjcem.2018.5689&partnerID=40&md5=35a032e52c6b450afc702c6dc1657507","Department of Civil and Urban Engineering, New York University, New York City, United States","Zou, Z., Department of Civil and Urban Engineering, New York University, New York City, United States; Arruda, L., Department of Civil and Urban Engineering, New York University, New York City, United States; Ergan, S., Department of Civil and Urban Engineering, New York University, New York City, United States","Building information models (BIMs) have been used by the Architectural/Engineering/Construction (AEC) industry with a focus on storing and exchanging digital information about building components. However, the untapped potential of BIMs in facility operations and the experience of facility operators while they interact with digital building information have not been understood widely. One of the underlying bottlenecks in the use of BIMs in the FM phase is the lack of interactions with components to easily access information of interest, and the lack of ways to navigate in models with full spatial understanding. Virtual environments (VEs), which represent physical spaces digitally in virtual worlds, enable interactions with virtual components to access information with spatial understanding. The underlying challenges in the conversion of BIMs to VE hinder a streamlined process. This paper provides a detailed analysis of building size, geometric complexities of discipline models and level of geometric granularity as factors contributing to inefficient transformation of BIMs to VE. The paper also provides research findings on a set of computational approaches such as polygon reduction and occlusion culling to overcome challenges and improve the data transfer faced in converting BIMs into VEs over a range and size of facility models. © 2018 The Author(s).","BIM; Facility management; Virtual reality","Data transfer; Mathematical transformations; Office buildings; Virtual reality; Building Information Model - BIM; Computational approach; Digital information; Facility management; Facility operations; Geometric complexity; Support facilities; Virtual components; Architectural design",Article,"Final","",Scopus,2-s2.0-85064496403
"Bezerra Í.M.P., Crocetta T.B., Massetti T., Silva T.D.D., Guarnieri R., Meira C.D.M., Arab C., Abreu L.C.D., Araujo L.V.D., Monteiro C.B.D.M.","55248144800;54898013000;55546122700;55546962700;57193692889;6701406955;56464254500;57192659178;12788134600;55481862300;","Functional performance comparison between real and virtual tasks in older adults",2018,"Medicine (United States)","97","4", e9612,"","",,10,"10.1097/MD.0000000000009612","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041266682&doi=10.1097%2fMD.0000000000009612&partnerID=40&md5=6c2f222175e31be25005f14616055f16","School of Arts, Sciences and Humanities of the University of São Paulo-EACH - USP, São Paulo, Brazil; Postgraduate Program in Public Policies and Local Development, School of Sciences of Santa Casa de Misericordia de VitoriaVIC, United States; Laboratory of Design of Studies and Scientific Writing, ABC School of Medicine, Santo Andre, Brazil; Department of Speech Therapy, Physical Therapy and Occupational Therapy, University of São Paulo, São Paulo, Brazil; Paulista School of Medicine, Department of Cardiology, Federal University of Sao Paulo - UNIFESP, São Paulo, Brazil","Bezerra, Í.M.P., School of Arts, Sciences and Humanities of the University of São Paulo-EACH - USP, São Paulo, Brazil, Postgraduate Program in Public Policies and Local Development, School of Sciences of Santa Casa de Misericordia de VitoriaVIC, United States; Crocetta, T.B., Laboratory of Design of Studies and Scientific Writing, ABC School of Medicine, Santo Andre, Brazil; Massetti, T., Department of Speech Therapy, Physical Therapy and Occupational Therapy, University of São Paulo, São Paulo, Brazil; Silva, T.D.D., School of Arts, Sciences and Humanities of the University of São Paulo-EACH - USP, São Paulo, Brazil, Paulista School of Medicine, Department of Cardiology, Federal University of Sao Paulo - UNIFESP, São Paulo, Brazil; Guarnieri, R., Laboratory of Design of Studies and Scientific Writing, ABC School of Medicine, Santo Andre, Brazil; Meira, C.D.M., School of Arts, Sciences and Humanities of the University of São Paulo-EACH - USP, São Paulo, Brazil; Arab, C., Paulista School of Medicine, Department of Cardiology, Federal University of Sao Paulo - UNIFESP, São Paulo, Brazil; Abreu, L.C.D., Postgraduate Program in Public Policies and Local Development, School of Sciences of Santa Casa de Misericordia de VitoriaVIC, United States, Laboratory of Design of Studies and Scientific Writing, ABC School of Medicine, Santo Andre, Brazil; Araujo, L.V.D., School of Arts, Sciences and Humanities of the University of São Paulo-EACH - USP, São Paulo, Brazil; Monteiro, C.B.D.M., School of Arts, Sciences and Humanities of the University of São Paulo-EACH - USP, São Paulo, Brazil, Department of Speech Therapy, Physical Therapy and Occupational Therapy, University of São Paulo, São Paulo, Brazil","Introduction: Ageing is usually accompanied by deterioration of physical abilities, such as muscular strength, sensory sensitivity, and functional capacity, making chronic diseases, and the well-being of older adults new challenges to global public health. Objective: The purpose of this study was to evaluate whether a task practiced in a virtual environment could promote better performance and enable transfer to the same task in a real environment. Method: The study evaluated 65 older adults of both genders, aged 60 to 82 years (M = 69.6, SD = 6.3). A timing coincident task was applied to measure the perceptual-motor ability to perform a motor response. The participants were divided into 2 groups: started in a real interface and started in a virtual interface. Results: All subjects improved their performance during the practice, but improvement was not observed for the real interface, as the participants were near maximum performance from the beginning of the task. However, there was no transfer of performance from the virtual to real environment or vice versa. Conclusions: The virtual environment was shown to provide improvement of performance with a short-Term motor learning protocol in a timing coincident task. This result suggests that the practice of tasks in a virtual environment seems to be a promising tool for the assessment and training of healthy older adults, even though there was no transfer of performance to a real environment. Trial registration: ISRCTN02960165. Registered 8 November 2016. Copyright © 2018 the Author(s). Published by Wolters Kluwer Health, Inc.","computer tasks; older adults; timing coincident; virtual reality","adult; aged; Article; cross-sectional study; female; hand movement; human; major clinical study; male; measurement error; motor performance; priority journal; software; task performance; virtual reality; controlled study; geriatric assessment; middle aged; motor performance; procedures; randomized controlled trial; very elderly; Aged; Aged, 80 and over; Cross-Sectional Studies; Female; Geriatric Assessment; Humans; Male; Middle Aged; Motor Skills; Task Performance and Analysis; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85041266682
"Yu R., Bowman D.A.","57194156709;57203231782;","Force Push: Exploring expressive gesture-to-force mappings for remote object manipulation in virtual reality",2018,"Frontiers in ICT","5","SEP", 25,"","",,2,"10.3389/fict.2018.00025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062438355&doi=10.3389%2ffict.2018.00025&partnerID=40&md5=3987dec276a6c82ab4e4052eff44f795","Center for Human-Computer Interaction, Virginia Tech, Blacksburg, VA, United States; Department of Computer Science, Virginia Tech, Blacksburg, VA, United States","Yu, R., Center for Human-Computer Interaction, Virginia Tech, Blacksburg, VA, United States, Department of Computer Science, Virginia Tech, Blacksburg, VA, United States; Bowman, D.A., Center for Human-Computer Interaction, Virginia Tech, Blacksburg, VA, United States, Department of Computer Science, Virginia Tech, Blacksburg, VA, United States","This paper presents Force Push, a novel gesture-based interaction technique for remote object manipulation in virtual reality (VR). Inspired by the design of magic powers in popular culture, Force Push uses intuitive hand gestures to drive physics-based movement of the object. Using a novel algorithm that dynamically maps rich features of hand gestures to the properties of the physics simulation, both coarse-grained ballistic movements and fine-grained refinement movements can be achieved seamlessly and naturally. An initial user study of a limited translation task showed that, although its gesture-to-force mapping is inherently harder to control than traditional position-to-position mappings, Force Push is usable even for extremely difficult tasks. Direct position-to-position control outperformed Force Push when the initial distance between the object and the target was close relative to the required accuracy; however, the gesture-based method began to show promising results when they were far away from each other. As for subjective user experience, Force Push was perceived as more natural and fun to use, even though its controllability and accuracy were thought to be inferior to direct control. This paper expands the design space of object manipulation beyond mimicking reality, and provides hints on using magical gestures and physics-based techniques for higher usability and hedonic qualities in user experience. © 2018 Yu and Bowman.","Controllability; Hand gesture; Object manipulation; Physics-based manipulation; Transfer function; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85062438355
"Discher S., Masopust L., Schulz S., Richter R., Döllner J.","54580703900;57203454864;57203460069;36195159400;6602981892;","A point-based and image-based multi-pass rendering technique for visualizing massive 3D point clouds in VR environments",2018,"Journal of WSCG","26","2",,"76","84",,4,"10.24132/JWSCG.2018.26.2.2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051790175&doi=10.24132%2fJWSCG.2018.26.2.2&partnerID=40&md5=d2bf1c659270f30ccdb79203d3076cc2","Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Straße 2-3, Potsdam, 14482, Germany","Discher, S., Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Straße 2-3, Potsdam, 14482, Germany; Masopust, L., Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Straße 2-3, Potsdam, 14482, Germany; Schulz, S., Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Straße 2-3, Potsdam, 14482, Germany; Richter, R., Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Straße 2-3, Potsdam, 14482, Germany; Döllner, J., Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Straße 2-3, Potsdam, 14482, Germany","Real-time rendering for 3D point clouds allows for interactively exploring and inspecting real-world assets, sites, or regions on a broad range of devices but has to cope with their vastly different computing capabilities. Virtual reality (VR) applications rely on high frame rates (i.e., around 90 fps as opposed to 30 - 60 fps) and show high sensitivity to any kind of visual artifacts, which are typical for 3D point cloud depictions (e.g., holey surfaces or visual clutter due to inappropriate point sizes). We present a novel rendering system that allows for an immersive, nausea-free exploration of arbitrary large 3D point clouds on state-of-the-art VR devices such as HTC Vive and Oculus Rift. Our approach applies several point-based and image-based rendering techniques that are combined using a multipass rendering pipeline. The approach does not require to derive generalized, mesh-based representations in a preprocessing step and preserves precision and density of the raw 3D point cloud data. The presented techniques have been implemented and evaluated with massive real-world data sets from aerial, mobile, and terrestrial acquisition campaigns containing up to 2.6 billion points to show the practicability and scalability of our approach. © 2018, Vaclav Skala Union Agency. All rights reserved.","3D point clouds; Real-time rendering; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85051790175
"Habgood J., Moore D., Alapont S., Ferguson C., Oostendorp H.","57070173700;57213311788;57197781258;57205183842;56764325100;","The reveal educational environmental narrative framework for playstation vr",2018,"Proceedings of the European Conference on Games-based Learning","2018-October",,,"175","183",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058978973&partnerID=40&md5=e1870e35e65d3ebc481a098bc61309f6","Steel Minions Game Studio, Sheffield Hallam University, Sheffield, United Kingdom; Institute of Information and Computing Sciences, Utrecht University, Netherlands","Habgood, J., Steel Minions Game Studio, Sheffield Hallam University, Sheffield, United Kingdom; Moore, D., Steel Minions Game Studio, Sheffield Hallam University, Sheffield, United Kingdom; Alapont, S., Steel Minions Game Studio, Sheffield Hallam University, Sheffield, United Kingdom; Ferguson, C., Institute of Information and Computing Sciences, Utrecht University, Netherlands; Oostendorp, H., Institute of Information and Computing Sciences, Utrecht University, Netherlands","The REVEAL project is pioneering the use of PlayStation VR for educational applications which engage audiences in Europe's rich scientific and cultural heritage. The REVEAL software framework facilitates the development of Educational Environmental Narrative (EEN) games in virtual reality for the PlayStation 4. The framework is composed of a set of software layers and editor plugins which augment an existing game engine technology (""The PhyreEngine"") and facilitate its transfer to educational applications. The PhyreEngine was created by Sony Interactive Entertainment Europe and is free and open source to registered PlayStation developers, including academic partners under the PlayStation First scheme. The REVEAL framework is built on top of the PhyreEngine and will be made similarly available to PlayStation developers through Sony Interactive Entertainment's developer network. This paper describes the functionality and design of the REVEAL framework, including its graph-based architecture, node-based locomotion system and high-resolution paper artefact rendering system. Key supporting tools are also described, including the Story Scaffolding Tool and its role in collecting detailed game analytics. The application of the framework is illustrated through an EEN case study application based on the life of Dr. Edward Jenner: the 18th century scientist credited with the discovery of vaccination. Finally, we discuss how we will empirically evaluate the effectiveness of a VR application and its components. © 2018, Dechema e.V. All rights reserved.","Environmental narrative games; Game-based learning; Virtual reality","Computer programming; Graphic methods; Open source software; Scaffolds; Virtual reality; Cultural heritages; Educational Applications; Environmental narrative games; Game-based Learning; Interactive entertainment; Locomotion system; Rendering system; Software frameworks; Application programs",Conference Paper,"Final","",Scopus,2-s2.0-85058978973
"Loch F., Ziegler U., Vogel-Heuser B.","55193685600;57203760799;6603480302;","Integrating Haptic Interaction into a Virtual Training System for Manual Procedures in Industrial Environments",2018,"IFAC-PapersOnLine","51","11",,"60","65",,4,"10.1016/j.ifacol.2018.08.235","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052855877&doi=10.1016%2fj.ifacol.2018.08.235&partnerID=40&md5=4dd09d028ffbbd0208d11a259f82b266","Institute for Automation and Information Systems, Technical University of Munich, Garching, Germany","Loch, F., Institute for Automation and Information Systems, Technical University of Munich, Garching, Germany; Ziegler, U., Institute for Automation and Information Systems, Technical University of Munich, Garching, Germany; Vogel-Heuser, B., Institute for Automation and Information Systems, Technical University of Munich, Garching, Germany","Many virtual training systems have been proposed to address the increasing complexity of manufacturing environments. However, existing training systems focus on visual interaction and neglect the haptic sense, which is a crucial component of manual tasks. This paper introduces a concept for a virtual training system for industrial procedures that introduces physical components to improve the training process. Introducing physical components is expected to improve the efficiency of training systems by transporting a sense for the haptic properties of tools and components and facilitate the transfer of the skills to the real work environment. The system allows practicing physical tasks using real tools and components. The didactic concept is based on the idea of multimodal learning and provides an environment that allows active experimentation. The application of the concept in an exemplary procedure is demonstrated. © 2018","Adaptive systems; Haptic interaction; Human-machine interface; Interaction mechanisms; Maintenance; Training; Virtual reality","Adaptive systems; Haptic interfaces; Maintenance; Personnel training; Virtual addresses; Virtual reality; Active experimentation; Haptic interactions; Human Machine Interface; Industrial environments; Interaction mechanisms; Manufacturing environments; Multi-modal learning; Virtual training systems; E-learning",Article,"Final","",Scopus,2-s2.0-85052855877
"Mourdi Y., Sadgal M., Berrada Fathi W., El Kabtane H.","56925355100;22836597000;56611915900;56925348600;","OpenSimulator based multi-user virtual world: A framework for the creation of distant and virtual practical activities",2018,"International Journal of Advanced Computer Science and Applications","9","8",,"175","186",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061456775&partnerID=40&md5=9794e668e75c155d730c5836ca8024f4","Faculty Semlalia, University Cadi Ayyad, Marrakesh, Morocco","Mourdi, Y., Faculty Semlalia, University Cadi Ayyad, Marrakesh, Morocco; Sadgal, M., Faculty Semlalia, University Cadi Ayyad, Marrakesh, Morocco; Berrada Fathi, W., Faculty Semlalia, University Cadi Ayyad, Marrakesh, Morocco; El Kabtane, H., Faculty Semlalia, University Cadi Ayyad, Marrakesh, Morocco","The exponential growth of technology has contributed to the positive revolution of distance learning. E-learning is becoming increasingly used in the transfer of knowledge where instructors can model and script their courses in several formats such as files, videos and quizzes. In order to complete their courses, practical activities are very important. Several instructors have joined Multi-User Virtual World (MUVW) communities such as SecondeLife, as they offer a degree of interrelated realism and interaction between users. The modeling and scenarization of practical activities in the MUVWs remains a very difficult task considering the technologies used by these MUVWs and the necessary prerequisites. In this paper, we propose a framework for the OpenSimulator MUVWs that can simplify the scenarization of practical activities using the OpenSpace3D software and without requiring designers to have expertise in programming or coding. © 2018 International Journal of Advanced Computer Science and Applications.","E-Learning; Multi-user virtual world; OpenSimulator; Practical activities; Virtual laboratories; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85061456775
"Coggan J.S., Cali C., Keller D., Agus M., Boges D., Abdellah M., Kare K., Lehväslaiho H., Eilemann S., Jolivet R.B., Hadwiger M., Markram H., Schürmann F., Magistretti P.J.","6701474322;24337622600;56362554200;57195623616;56780189200;56432915800;57192556476;7003953883;14827866300;9743375700;14021127100;56275180000;23976834700;7007046209;","A process for digitizing and simulating biologically realistic oligocellular networks demonstrated for the neuro-Glio-Vascular ensemble",2018,"Frontiers in Neuroscience","12",, 664,"","",,13,"10.3389/fnins.2018.00664","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054012828&doi=10.3389%2ffnins.2018.00664&partnerID=40&md5=3306b4e2382240d523d87fbaf69f9593","Blue Brain Project, Cole Polytechnique Fdrale de Lausanne (EPFL), Geneva, Switzerland; Biological and Environmental Sciences and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Visual Computing Center, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; CRS4, Center of Research and Advanced Studies in Sardinia, Visual Computing, Pula, Italy; CSC – IT Center for Science, Espoo, Finland; Departement de Physique Nuclaire et Corpusculaire, University of Geneva, Geneva, Switzerland; European Organization for Nuclear Research, Geneva, Switzerland","Coggan, J.S., Blue Brain Project, Cole Polytechnique Fdrale de Lausanne (EPFL), Geneva, Switzerland; Cali, C., Biological and Environmental Sciences and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Keller, D., Blue Brain Project, Cole Polytechnique Fdrale de Lausanne (EPFL), Geneva, Switzerland; Agus, M., Visual Computing Center, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia, CRS4, Center of Research and Advanced Studies in Sardinia, Visual Computing, Pula, Italy; Boges, D., Biological and Environmental Sciences and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Abdellah, M., Blue Brain Project, Cole Polytechnique Fdrale de Lausanne (EPFL), Geneva, Switzerland; Kare, K., Biological and Environmental Sciences and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Lehväslaiho, H., Biological and Environmental Sciences and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia, CSC – IT Center for Science, Espoo, Finland; Eilemann, S., Blue Brain Project, Cole Polytechnique Fdrale de Lausanne (EPFL), Geneva, Switzerland; Jolivet, R.B., Departement de Physique Nuclaire et Corpusculaire, University of Geneva, Geneva, Switzerland, European Organization for Nuclear Research, Geneva, Switzerland; Hadwiger, M., Visual Computing Center, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Markram, H., Blue Brain Project, Cole Polytechnique Fdrale de Lausanne (EPFL), Geneva, Switzerland; Schürmann, F., Blue Brain Project, Cole Polytechnique Fdrale de Lausanne (EPFL), Geneva, Switzerland; Magistretti, P.J., Biological and Environmental Sciences and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia","One will not understand the brain without an integrated exploration of structure and function, these attributes being two sides of the same coin: together they form the currency of biological computation. Accordingly, biologically realistic models require the re-creation of the architecture of the cellular components in which biochemical reactions are contained. We describe here a process of reconstructing a functional oligocellular assembly that is responsible for energy supply management in the brain and creating a computational model of the associated biochemical and biophysical processes. The reactions that underwrite thought are both constrained by and take advantage of brain morphologies pertaining to neurons, astrocytes and the blood vessels that deliver oxygen, glucose and other nutrients. Each component of this neuro-glio-vasculature ensemble (NGV) carries-out delegated tasks, as the dynamics of this system provide for each cell-type its own energy requirements while including mechanisms that allow cooperative energy transfers. Our process for recreating the ultrastructure of cellular components and modeling the reactions that describe energy flow uses an amalgam of state-of the-art techniques, including digital reconstructions of electron micrographs, advanced data analysis tools, computational simulations and in silico visualization software. While we demonstrate this process with the NGV, it is equally well adapted to any cellular system for integrating multimodal cellular data in a coherent framework. Copyright © 2018 Coggan.","3D reconstruction; Electron microscopy; Energy metabolism; In silico visualization; NGV; Simulation","glucose; oxygen; Article; astrocyte; biochemical analysis; biophysics; blood vessel; brain blood vessel; brain function; cell component; cell structure; cell ultrastructure; computer model; computer simulation; conceptual framework; electron microscopy; energy metabolism; energy resource; energy transfer; functional morphology; human; image reconstruction; image segmentation; mathematical model; nerve cell network; neuroscience; nonhuman; qualitative analysis; three dimensional imaging; virtual reality",Article,"Final","",Scopus,2-s2.0-85054012828
"Shewaga R., Uribe-Quevedo A., Kapralos B., Lee K., Alam F.","55777602000;55208144400;57203087583;57208340448;37025424400;","A serious game for anesthesia-based crisis resource management training",2018,"Computers in Entertainment","16","2", 6,"","",,3,"10.1145/3180660","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064575425&doi=10.1145%2f3180660&partnerID=40&md5=a5f89f7402697fc11835f145c76036a7","Software Informatics Research Centre, University of Ontario Institute of Technology, Oshawa, Onatrio  L1H 7K4, Canada; Department of Anaesthesia, Sunnybrook Health Sciences Centre, 2075 Bayview Ave, Toronto, ON  M4N 3M5, Canada","Shewaga, R., Software Informatics Research Centre, University of Ontario Institute of Technology, Oshawa, Onatrio  L1H 7K4, Canada; Uribe-Quevedo, A., Software Informatics Research Centre, University of Ontario Institute of Technology, Oshawa, Onatrio  L1H 7K4, Canada; Kapralos, B., Software Informatics Research Centre, University of Ontario Institute of Technology, Oshawa, Onatrio  L1H 7K4, Canada; Lee, K., Department of Anaesthesia, Sunnybrook Health Sciences Centre, 2075 Bayview Ave, Toronto, ON  M4N 3M5, Canada; Alam, F., Department of Anaesthesia, Sunnybrook Health Sciences Centre, 2075 Bayview Ave, Toronto, ON  M4N 3M5, Canada","Simulation-based training has been widely adopted in medical education as a tool in the practice and development of skills within a safe, controlled, and monitored environment. However, significant cost and logistical challenges exist within traditional simulation practices. The rising popularity of gaming has seen the wide application of serious games to medical education and training. Serious gaming (and virtual simulation in general) offers a viable alternative to traditional training practices, offering students/trainees the opportunity to train until they reach a specific competency level in a safe, interactive, engaging, and cost-effective manner for effective skills transfer to the real world. Here we present a serious game for anesthesia-based crisis resource management (ACRM) training. The ACRM serious game provides trainees the opportunity to react to a simulated medical emergency within a virtual operating room while providing an interactive, and engaging training experience. Results of an experiment that was conducted to examine the usability (the ease of use of the serious game and its interface) of the serious game, and its ability to engage trainees, indicate that although improvements to the user interface can be made, it shows promise as an immersive and engaging complementary training tool. © 2018 ACM.","Anesthesia; Crisis resource management; Serious gaming; Virtual simulation","Anesthesiology; Cost effectiveness; Medical education; Natural resources management; Resource allocation; Students; User interfaces; Anesthesia; Education and training; Resource management; Serious gaming; Simulation practices; Simulation-based training; Training experiences; Virtual simulations; Serious games",Article,"Final","",Scopus,2-s2.0-85064575425
"Kumar P., Agrawal A., Prasad S.","57199976385;56900480800;36997272500;","Multimodal interface for temporal pattern based interactive large volumetric visualization",2017,"IEEE Region 10 Annual International Conference, Proceedings/TENCON","2017-December",,,"1239","1244",,2,"10.1109/TENCON.2017.8228047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044224017&doi=10.1109%2fTENCON.2017.8228047&partnerID=40&md5=bd35782deaf2c7989d27dc21afbc4f41","Indian Institute of Information Technology, Allahabad, India; Nanyang Technical University, Singapore","Kumar, P., Indian Institute of Information Technology, Allahabad, India; Agrawal, A., Indian Institute of Information Technology, Allahabad, India; Prasad, S., Nanyang Technical University, Singapore","Scientific data visualization is a prominent area of research in the development of Virtual Reality Applications in order to make it more interactive and robotic. But the efficient interaction with the large size of medical data is a challenging task to diagnose virtual surgerical environment learning for a Physician. In this paper, we proposed a multimodal interface for GPU-accelerated interactive large scale volumetric data rendering to overcome this limitation. The large data has been pre-processed by octree method. An improved raycasting algorithm is used in association with a transfer function classification method for the effective rendering. The temporal data is used for defining gestures, retrieving in a pattern from the wearable device for providing multimodality with the large rendered data. A gesture vocabulary has been defined by these patterns for the navigation in visualizing the large scale medical data, which consists of five complex interactive postures used for Normal, Picking, Rotation, Dragging, and Zooming gestures. These gesture vocabularies have been categorized by kNN classification method of pattern recognition. Experimental results of the proposed approach are analyzed with the help of various ANOVA and T-testing graphs using SPSS 20 version tool and confidence interval of interaction with hand gestures vocabulary. The results of proposed approach are further compared with the existing approaches in which Microsoft Kinect and P5 dataglove have been used. The proposed system has been navigated by the DG5 VHand 2.0 Bluetooth version hand dataglove as wearable assistive device to achieve an effective interaction. The system has been tested on 10 different sizes of volume datasets ranging from 10MB to 3.15 GB. The scope of this paper is basically to develop system training with robotic arm in medical domain. © 2017 IEEE.","Hand DataGlove; Human-Computer Interaction; Large scale; Medical Dataset; Multimodal Inteface; Volume Rendering","Human computer interaction; Interactive computer systems; Pattern recognition; Robotics; Virtual reality; Visualization; Volume rendering; Volumetric analysis; Wearable technology; Dataglove; Inteface; Large scale; Medical dataset; Multi-modal interfaces; Scientific data visualization; Volumetric visualization; Wearable assistive devices; Data visualization",Conference Paper,"Final","",Scopus,2-s2.0-85044224017
"Li Y., Zhang J., Sun W., Wang J., Gao X.","56201159300;35436414500;57196712013;57201057458;8694616600;","VREX: Virtual reality education eXpansion could help to improve the class experience (VREX Platform and Community for VR based Education)",2017,"Proceedings - Frontiers in Education Conference, FIE","2017-October",,,"1","5",,7,"10.1109/FIE.2017.8190660","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043232821&doi=10.1109%2fFIE.2017.8190660&partnerID=40&md5=3f64d16993e0b0815f54443965183308","School of Computer Science and Engineering, Beihang University, Beijing, China; Electrical Engineering, Princeton UniversityNJ, United States; Dept. for Cyber Online Popularization of Science, Chinese Science and Technology Museum, Beijing, China","Li, Y., School of Computer Science and Engineering, Beihang University, Beijing, China, Electrical Engineering, Princeton UniversityNJ, United States; Zhang, J., School of Computer Science and Engineering, Beihang University, Beijing, China, Dept. for Cyber Online Popularization of Science, Chinese Science and Technology Museum, Beijing, China; Sun, W., School of Computer Science and Engineering, Beihang University, Beijing, China; Wang, J., Dept. for Cyber Online Popularization of Science, Chinese Science and Technology Museum, Beijing, China; Gao, X., School of Computer Science and Engineering, Beihang University, Beijing, China","This paper proposed an innovative education platform-VREX (Virtual Reality based Education eXpansion), with combination of online and offline, to improve the curriculum building and teaching experience. VREX is based on Virtual Reality (VR) and we believe VR can revolutionize the education ecosystem. With some trials, we found VR can be used to promote curriculum effectiveness in an immersive environment so that students can have intuitive sense to understand some abstract knowledge, which is always hard for teachers to describe. We have tried to transfer slides into VR scenes, for the students to learn knowledge in a rather real but totally virtual world. The main contributions were made: (1) VREX build an open and immersion virtual O2O classroom with internet and VR devices so that real classrooms might be used in a different way in the future. (2) VREX provides a distributed mode for students to experience an interactive learning process at anytime, anywhere and any-frequency. (3) VREX can be used to support education in different disciplines, from K-12 to Universities, and we provided some practical cases, like 'Marine Life' to show creatures in deep sea, which provides immersive experience to makes students feel they were there. Finally, the feasibility and advantage of VREX are proved by the actual statistical data in the 3rd season 2017. © 2017 IEEE.","Immersion; Interaction; Virtual classroom; Virtual reality; VR cloud platform","Computer aided instruction; Curricula; Learning systems; Marine education; Students; Teaching; Virtual reality; Cloud platforms; Curriculum buildings; Immersion; Immersive environment; Innovative education; Interaction; Interactive learning; Virtual Classroom; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85043232821
"Zhao S., Medhi D.","56267593400;35576162400;","SDN-Assisted adaptive streaming framework for tile-based immersive content using MPEG-DASH",2017,"2017 IEEE Conference on Network Function Virtualization and Software Defined Networks, NFV-SDN 2017","2017-January",,,"1","6",,17,"10.1109/NFV-SDN.2017.8169831","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043255095&doi=10.1109%2fNFV-SDN.2017.8169831&partnerID=40&md5=97d53c7d9943e8303ea76d5f5ab72271","Department of Computer Science Electrical Engineering University, Missouri–Kansas, United States","Zhao, S., Department of Computer Science Electrical Engineering University, Missouri–Kansas, United States; Medhi, D., Department of Computer Science Electrical Engineering University, Missouri–Kansas, United States","Video streaming over the internet for new 3D immersive media such as Virtual Reality and 360-degree videos has drawn great attention from both consumers and researchers in recent years. One of the biggest challenges in streaming such 3D media is the high bandwidth demands. While traditional 2D video streaming is still dominating network peak traffic, new inventions are accelerating the adoption of immersive contents and devices. A new Tile-based video is introduced in both a video codec and streaming layer to reduce the transferred media size. Dynamic adaptive streaming over HTTP has become one of the de facto effective adaptive streaming approaches that can fully utilize the existing physical IP network infrastructure. In this paper, we propose a tile-based streaming framework using software-defined networking. By prioritizing streaming flows, based on the region of interests, our approach can improve the user’s quality of experience (QoE). © 2017 IEEE.","DASH Streaming; Immersive VR/360; MPEG-DASH; Software-Defined Networking; Spatial Relationship Description","HTTP; Motion Picture Experts Group standards; Network function virtualization; Quality of service; Software defined networking; Transfer functions; Video streaming; Virtual reality; Virtualization; Adaptive streaming; Dynamic Adaptive Streaming over HTTP; Immersive media; Immersive VR; Mpeg dashes; Quality of experience (QoE); Region of interest; Spatial relationships; Media streaming",Conference Paper,"Final","",Scopus,2-s2.0-85043255095
"Johnson-Glenberg M.C., Megowan-Romanowicz C.","6507238066;26537877500;","Embodied science and mixed reality: How gesture and motion capture affect physics education",2017,"Cognitive Research: Principles and Implications","2","1", 24,"","",,30,"10.1186/s41235-017-0060-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038820372&doi=10.1186%2fs41235-017-0060-9&partnerID=40&md5=f5b98014a9c22b3850ab96e5474bf458","Department of Psychology, Arizona State University, Tempe, AZ, United States; Embodied Games LLC, Tempe, AZ, United States; Modeling Instruction Institute, Sacramento, CA, United States","Johnson-Glenberg, M.C., Department of Psychology, Arizona State University, Tempe, AZ, United States, Embodied Games LLC, Tempe, AZ, United States; Megowan-Romanowicz, C., Modeling Instruction Institute, Sacramento, CA, United States","A mixed design was created using text and game-like multimedia to instruct in the content of physics. The study assessed which variables predicted learning gains after a 1-h lesson on the electric field. The three manipulated variables were: (1) level of embodiment; (2) level of active generativity; and (3) presence of story narrative. Two types of tests were administered: (1) a traditional text-based physics test answered with a keyboard; and (2) a more embodied, transfer test using the Wacom large tablet where learners could use gestures (long swipes) to create vectors and answers. The 166 participants were randomly assigned to four conditions: (1) symbols and text; (2) low embodied; (3) high embodied/active; or (4) high embodied/active with narrative. The last two conditions were active because the on-screen content could be manipulated with gross body gestures gathered via the Kinect sensor. Results demonstrated that the three groups that included embodiment learned significantly more than the symbols and text group on the traditional keyboard post-test. When knowledge was assessed with the Wacom tablet format that facilitated gestures, the two active gesture-based groups scored significantly higher. In addition, engagement scores were significantly higher for the two active embodied groups. The Wacom results suggest test sensitivity issues; the more embodied test revealed greater gains in learning for the more embodied conditions. We recommend that as more embodied learning comes to the fore, more sensitive tests that incorporate gesture be used to accurately assess learning. The predicted differences in engagement and learning for the condition with the graphically rich story narrative were not supported. We hypothesize that a narrative effect for motivation and learning may be difficult to uncover in a lab experiment where participants are primarily motivated by course credit. Several design principles for mediated and embodied science education are proposed. © 2017, The Author(s).","Embodied science; Game-based learning; Gesture and learning; Mixed reality; Narrative; Physics; Science education; STEM; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85038820372
"Bork F., Barmaki R., Eck U., Yu K., Sandor C., Navab N.","57188681620;57079124100;6507331080;57202881272;15061666200;7003458998;","Empirical study of non-reversing magic mirrors for augmented reality anatomy learning",2017,"Proceedings of the 2017 IEEE International Symposium on Mixed and Augmented Reality, ISMAR 2017",,, 8115415,"169","176",,13,"10.1109/ISMAR.2017.33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041662291&doi=10.1109%2fISMAR.2017.33&partnerID=40&md5=675b96017db2c791bfef11db7746c384","Technische Universität München, Munich, Germany; Johns Hopkins University, Baltimore, MD, United States; Nara Institute of Technology, Nara, Japan","Bork, F., Technische Universität München, Munich, Germany; Barmaki, R., Johns Hopkins University, Baltimore, MD, United States; Eck, U., Technische Universität München, Munich, Germany; Yu, K., Technische Universität München, Munich, Germany; Sandor, C., Nara Institute of Technology, Nara, Japan; Navab, N., Technische Universität München, Munich, Germany, Johns Hopkins University, Baltimore, MD, United States","Left-right confusion occurs across the entire population and refers to an impeded ability to distinguish between left and right. In medicine this phenomenon is particularly relevant as left and right are always defined with respect to the patient's point of view, i.e. the doctor's right is the patient's left. Traditional anatomy learning resources such as illustrations in textbooks naturally consider this by consistently depicting the anatomy of a patient as seen by an observer standing in front. Augmented Reality Magic Mirrors (MM) are one example of novel anatomy teaching resources and show a user's digital mirror image augmented with virtual anatomy on a large display. As left and right appear to be reversed in such MM setups, similar to real-world physical mirrors, intriguing perceptual questions arise: is a non-reversing MM (NRMM) the more natural choice for the task of anatomy learning and do users even learn anatomy the wrong way with a traditional, reversing MM (RMM)' In this paper, we explore the perceptual differences between an NRMM and RMM design and present the first empirical study comparing these two concepts for the purpose of anatomy learning. Experimental results demonstrate that medical students perform significantly better at identifying anatomically correct placement of virtual organs in an NRMM. However, interaction was significantly more difficult compared to an RMM. We explore the underlying psychological effects and discuss the implications of using an NRMM on user perception, knowledge transfer, and interaction. This study is relevant for the design of future MM systems in the medical domain and lessons-learned can be transferred to other application domains. © 2017 IEEE.",,"Augmented reality; Knowledge management; Mirrors; Empirical studies; Knowledge transfer; Learning resource; Medical students; Perceptual difference; Psychological effects; Teaching resources; User perceptions; Education",Conference Paper,"Final","",Scopus,2-s2.0-85041662291
"Jambi E., Gardner M., Callaghan V.","57200312836;9840290400;35561000000;","Supporting mixed-mode role-play activities in a virtual environment",2017,"2017 9th Computer Science and Electronic Engineering Conference, CEEC 2017 - Proceedings",,, 8101598,"49","54",,2,"10.1109/CEEC.2017.8101598","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040770954&doi=10.1109%2fCEEC.2017.8101598&partnerID=40&md5=45879562f9a5911e01905c3d63554e10","Department of Computer Science, University of Essex, United Kingdom; King Abdulaziz University, Jeddah, Saudi Arabia","Jambi, E., Department of Computer Science, University of Essex, United Kingdom, King Abdulaziz University, Jeddah, Saudi Arabia; Gardner, M., Department of Computer Science, University of Essex, United Kingdom; Callaghan, V., Department of Computer Science, University of Essex, United Kingdom","This paper introduces an approach to harness the advantages of 3D virtual environments in a more effective way in order to benefit the student's learning in understanding abstract concepts. It is a proposal for a generalized framework that generates a mixed-simulation role-play activity. In this activity, the student functions as a part of a working system in a virtual environment in order to complete different tasks. This framework acts as a template that can be used to design different role-play activities for diverse subjects. © 2017 IEEE.","Immersive Learning; Mix-Simulation; Role-Play; Virtual Environment; Virtual Reality","Computer science; Computers; Engineering; Industrial engineering; 3-D virtual environment; Abstract concept; Immersive learning; Mixed mode; Mixed simulation; Role play; Working systems; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85040770954
"Su Y.-C., Grauman K.","57191432526;6506707692;","Making 360° Video Watchable in 2D: Learning videography for click free viewing",2017,"Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017","2017-January",,,"1368","1376",,74,"10.1109/CVPR.2017.150","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044315437&doi=10.1109%2fCVPR.2017.150&partnerID=40&md5=8b01872eba23c1fc162c07793d7b3806","University of Texas, Austin, United States","Su, Y.-C., University of Texas, Austin, United States; Grauman, K., University of Texas, Austin, United States","360° video requires human viewers to actively control ""where"" to look while watching the video. Although it provides a more immersive experience of the visual content, it also introduces additional burden for viewers; awkward interfaces to navigate the video lead to suboptimal viewing experiences. Virtual cinematography is an appealing direction to remedy these problems, but conventional methods are limited to virtual environments or rely on hand-crafted heuristics. We propose a new algorithm for virtual cinematography that automatically controls a virtual camera within a 360° video. Compared to the state of the art, our algorithm allows more general camera control, avoids redundant outputs, and extracts its output videos substantially more efficiently. Experimental results on over 7 hours of real ""in the wild"" video show that our generalized camera control is crucial for viewing 360° video, while the proposed efficient algorithm is essential for making the generalized control computationally tractable. © 2017 IEEE.",,"Cameras; Computer vision; Heuristic methods; Video recording; Virtual reality; Camera controls; Conventional methods; Immersive; State of the art; Virtual camera; Virtual cinematography; Visual content; Pattern recognition",Conference Paper,"Final","",Scopus,2-s2.0-85044315437
"Huber T., Paschold M., Hansen C., Wunderling T., Lang H., Kneist W.","18535462800;50361876100;55890379200;57193857398;7402486188;7005632003;","New dimensions in surgical training: immersive virtual reality laparoscopic simulation exhilarates surgical staff",2017,"Surgical Endoscopy","31","11",,"4472","4477",,56,"10.1007/s00464-017-5500-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017182338&doi=10.1007%2fs00464-017-5500-6&partnerID=40&md5=83d81dd35d910a73edf015e3e70d0f69","Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Langenbeckstraße 1, Mainz, 55131, Germany; Department of Simulation and Graphics, Faculty of Computer Science, Otto-von-Guericke University Magdeburg, Magdeburg, Germany","Huber, T., Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Langenbeckstraße 1, Mainz, 55131, Germany; Paschold, M., Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Langenbeckstraße 1, Mainz, 55131, Germany; Hansen, C., Department of Simulation and Graphics, Faculty of Computer Science, Otto-von-Guericke University Magdeburg, Magdeburg, Germany; Wunderling, T., Department of Simulation and Graphics, Faculty of Computer Science, Otto-von-Guericke University Magdeburg, Magdeburg, Germany; Lang, H., Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Langenbeckstraße 1, Mainz, 55131, Germany; Kneist, W., Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Langenbeckstraße 1, Mainz, 55131, Germany","Introduction: Virtual reality (VR) and head mount displays (HMDs) have been advanced for multimedia and information technologies but have scarcely been used in surgical training. Motion sickness and individual psychological changes have been associated with VR. The goal was to observe first experiences and performance scores using a new combined highly immersive virtual reality (IVR) laparoscopy setup. Methods: During the study, 10 members of the surgical department performed three tasks (fine dissection, peg transfer, and cholecystectomy) on a VR simulator. We then combined a VR HMD with the VR laparoscopic simulator and displayed the simulation on a 360° video of a laparoscopic operation to create an IVR laparoscopic simulation. The tasks were then repeated. Validated questionnaires on immersion and motion sickness were used for the study. Results: Participants’ times for fine dissection were significantly longer during the IVR session (regular: 86.51 s [62.57 s; 119.62 s] vs. IVR: 112.35 s [82.08 s; 179.40 s]; p = 0.022). The cholecystectomy task had higher error rates during IVR. Motion sickness did not occur at any time for any participant. Participants experienced a high level of exhilaration, rarely thought about others in the room, and had a high impression of presence in the generated IVR world. Conclusion: This is the first clinical and technical feasibility study using the full IVR laparoscopy setup combined with the latest laparoscopic simulator in a 360° surrounding. Participants were exhilarated by the high level of immersion. The setup enables a completely new generation of surgical training. © 2017, Springer Science+Business Media New York.","Abdominal surgery; Immersive virtual reality; Laparoscopy; Simulation; Training; Virtual surgery","abdominal surgery; Article; cholecystectomy; dissection; feasibility study; female; human; laparoscopic surgery; male; motion sickness; operating room personnel; priority journal; surgical training; time; virtual reality; clinical competence; education; health care personnel; laparoscopy; procedures; questionnaire; simulation training; statistics and numerical data; Clinical Competence; Feasibility Studies; Female; Health Personnel; Humans; Laparoscopy; Male; Simulation Training; Surveys and Questionnaires; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85017182338
"McClelland J.C., Teather R.J., Girouard A.","57197781412;24588246800;16303494200;","HaptoBend: Shape-changing passive haptic feedback in virtual reality",2017,"SUI 2017 - Proceedings of the 2017 Symposium on Spatial User Interaction",,,,"82","90",,20,"10.1145/3131277.3132179","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037047945&doi=10.1145%2f3131277.3132179&partnerID=40&md5=f5343c613cffb410c595b59c94070b0e","Carleton University, Ottawa, Canada","McClelland, J.C., Carleton University, Ottawa, Canada; Teather, R.J., Carleton University, Ottawa, Canada; Girouard, A., Carleton University, Ottawa, Canada","We present HaptoBend, a novel shape-changing input device providing passive haptic feedback (PHF) for a wide spectrum of objects in virtual reality (VR). Past research in VR shows that PHF increases presence and improves user task performance. However, providing PHF for multiple objects usually requires complex, immobile systems, or multiple props. HaptoBend addresses this problem by allowing users to bend the device into 2D plane-like shapes and multi-surface 3D shapes. We believe HaptoBend’s physical approximations of virtual objects can provide realistic haptic feedback through research demonstrating the dominance of human vision over other senses in VR. To test the effectiveness of HaptoBend in matching 2D planar and 3D multi-surface shapes, we conducted an experiment modeled after gesture elicitation studies with 20 participants. High goodness and ease scores show shape-changing passive haptic devices, like HaptoBend, are an effective approach to generalized haptics. Further analysis supports the use of physical approximations for realistic haptic feedback. © 2017 Copyright is held by the owner/author(s).","Haptic feedback; Shape-changing interactions; Virtual Reality","Haptic interfaces; Effective approaches; Haptic feedbacks; Multiple objects; Passive haptic devices; Physical approximations; Task performance; Virtual objects; Wide spectrum; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85037047945
"Huygelier H., Gillebert C.R., Van Ee R., Vanden Abeele V.","57188732781;23990683200;55031825700;25723833200;","The design of a virtual reality game for stroke-induced attention deficits",2017,"CHI PLAY 2017 Extended Abstracts - Extended Abstracts Publication of the Annual Symposium on Computer-Human Interaction in Play",,,,"223","230",,1,"10.1145/3130859.3131308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034756562&doi=10.1145%2f3130859.3131308&partnerID=40&md5=779b5fdd38cb7a4503ba8e2411baf41e","KU Leuven, Leuven, 3000, Belgium; Philips Research Laboratories, Eindhoven, 5600, Netherlands; E-Media Lab, KU Leuven, Leuven, 3000, Belgium","Huygelier, H., KU Leuven, Leuven, 3000, Belgium; Gillebert, C.R., KU Leuven, Leuven, 3000, Belgium; Van Ee, R., KU Leuven, Leuven, 3000, Belgium, Philips Research Laboratories, Eindhoven, 5600, Netherlands; Vanden Abeele, V., E-Media Lab, KU Leuven, Leuven, 3000, Belgium","Hemispatial neglect is a spatial attention deficit that occurs in 25 up to 50% of stroke survivors and has a negative impact on functional recovery. Despite an increased understanding of the mechanisms underlying hemispatial neglect, there is no effective treatment yet. In particular, the transfer of treatment effects to daily life is often missing. A more ecological approach to rehabilitation may therefore produce better treatment effects. Here we present the design of a virtual reality game for stroke patients with spatial attention deficits. Moreover, we present the use of our 'Intervention Logic - Game Mechanic' model which details how theorygrounded intervention principles were translated into game mechanics and desired treatment outcomes. Additionally, we demonstrate how simulations on the basis of player models aid in designing a dynamic difficulty adjustment algorithm and reduce the need for elaborate gameplay testing. © 2017 Copyright is held by the owner/author(s).","Attention; Dynamic difficulty adjustment; Hemispatial neglect; Rehabilitation; Stroke; Virtual reality","Abstracting; Dynamics; Electronic medical equipment; Interactive computer systems; Patient rehabilitation; Virtual reality; Adjustment algorithms; Attention; Attention deficit; Ecological approaches; Functional recovery; Hemispatial neglect; Stroke; Treatment outcomes; Human computer interaction",Conference Paper,"Final","",Scopus,2-s2.0-85034756562
"Dubovi I., Levy S.T., Dagan E.","57194381219;7402774725;6701806618;","Now I know how! The learning process of medication administration among nursing students with non-immersive desktop virtual reality simulation",2017,"Computers and Education","113",,,"16","27",,41,"10.1016/j.compedu.2017.05.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019934867&doi=10.1016%2fj.compedu.2017.05.009&partnerID=40&md5=919db5ba81874d7253ec797d5f546f84","Department of Learning, Instruction and Teacher Education, Faculty of Education, University of Haifa, Israel; The Cheryl Spencer Department of Nursing, Faculty of Social Welfare and Health Sciences, University of Haifa, Israel","Dubovi, I., Department of Learning, Instruction and Teacher Education, Faculty of Education, University of Haifa, Israel, The Cheryl Spencer Department of Nursing, Faculty of Social Welfare and Health Sciences, University of Haifa, Israel; Levy, S.T., Department of Learning, Instruction and Teacher Education, Faculty of Education, University of Haifa, Israel; Dagan, E., The Cheryl Spencer Department of Nursing, Faculty of Social Welfare and Health Sciences, University of Haifa, Israel","The purpose of this study was to create and explore an effective and accessible teaching method for the higher education of professionals requiring practical skills. We aimed to evaluate the effectiveness of our Pharmacology Inter-Leaved Learning Virtual Reality (PILL-VR) simulation when applied to nursing education, as a tool for learning medication administration procedures. A quasi-experimental pretest-intervention-posttest comparison group design was conducted based on quantitative analysis of questionnaires, video recordings and worksheets. Participants were nursing students who either learned medication administration processes with a PILL-VR simulation platform (experimental group; n = 82) or who learned with lecture-based curriculum (n = 47; comparison group). The results revealed significantly higher conceptual and procedural knowledge learning gains following activity with the PILL-VR simulation compared to studying via lecture-based curriculum. PILL-VR exposed the students to their own errors, allowing procedure rehearsal followed by constant feedback which is essential to skill acquisition. Although PILL-VR is based on a desktop system, it facilitated a strong sense of presence. A small positive correlation was found on questionnaire scores between the sense of presence, particularly the sense of control, and conceptual-procedural learning of medication administration. This indicates that by improving students' sense of control in the PILL-VR, the learning process can be improved. Hence, VR simulations may provide affordable and flexible access to practice necessary practical skills in higher education, which is crucial to developing students’ expertise. © 2017 Elsevier Ltd","Higher education; Nursing education; Simulation; Virtual reality","Curricula; E-learning; Learning systems; Nursing; Surveys; Technology transfer; Video recording; Virtual reality; Analysis of questionnaire; Desktop virtual reality; Higher education; Nursing education; Positive correlations; Procedural knowledge; Procedural learning; Simulation; Students",Article,"Final","",Scopus,2-s2.0-85019934867
"Siegel Z.D., Kelly J.W., Cherep L.A.","56094810300;55346243800;57193440989;","Rescaling of perceived space transfers across virtual environments",2017,"Journal of Experimental Psychology: Human Perception and Performance","43","10",,"1805","1814",,8,"10.1037/xhp0000401","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027048373&doi=10.1037%2fxhp0000401&partnerID=40&md5=f4e76dd94dd38e9b80bcfb4f93c94273","Department of Psychology, Iowa State University, United States","Siegel, Z.D., Department of Psychology, Iowa State University, United States; Kelly, J.W., Department of Psychology, Iowa State University, United States; Cherep, L.A., Department of Psychology, Iowa State University, United States","Research over the past 20 years has consistently shown that egocentric distance is underperceived in virtual environments (VEs) compared with real environments. In 2 experiments, judgments of object distance (Experiment 1) and object size (Experiment 2) improved after a brief period of walking through the VE with continuous visual feedback. Whereas improvement of blind-walking distance judgments could be attributable to recalibration of walking, improvement in perceived size is considered evidence for rescaling of perceived space, whereby perceived size and distance increased after walking interaction. Furthermore, improvements in judged distance and size transferred to a new VE. Distance judgments, but not size judgments, continued to improve after additional walking interaction in the new VE. These results have theoretical implications regarding the effects of walking interaction on perceived space, and practical implications regarding methods of improving perceived distance in VEs. © 2017 American Psychological Association.",,"depth perception; human; psychological feedback; psychology; virtual reality; vision; walking; Feedback, Psychological; Humans; Space Perception; Virtual Reality; Visual Perception; Walking",Article,"Final","",Scopus,2-s2.0-85027048373
"Rábago J.L., López-Doueil M., Sancho R., Hernández-Pinto P., Neira N., Capa E., Larraz E., Redondo-Figuero C.G., Maestre J.M.","55130658800;57039141000;55882800300;16401435900;57193705757;57193703349;57193706247;9637769400;7006524764;","Learning outcomes evaluation of a simulation-based introductory course to anaesthesia [Evaluación de los resultados de aprendizaje de un curso de introducción a la anestesiología basado en simulación clínica]",2017,"Revista Espanola de Anestesiologia y Reanimacion","64","8",,"431","440",,4,"10.1016/j.redar.2016.12.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016051441&doi=10.1016%2fj.redar.2016.12.008&partnerID=40&md5=17a6d265118ce7d6507d49dbe81c5872","Hospital virtual Valdecilla, Santander, Spain; Servicio de Anestesiología, Reanimación y Terapéutica del Dolor, Hospital Universitario Valdecilla, Santander, Spain; Instituto de Investigación Sanitaria Valdecilla, Santander, Spain","Rábago, J.L., Hospital virtual Valdecilla, Santander, Spain, Servicio de Anestesiología, Reanimación y Terapéutica del Dolor, Hospital Universitario Valdecilla, Santander, Spain; López-Doueil, M., Hospital virtual Valdecilla, Santander, Spain, Servicio de Anestesiología, Reanimación y Terapéutica del Dolor, Hospital Universitario Valdecilla, Santander, Spain; Sancho, R., Hospital virtual Valdecilla, Santander, Spain, Servicio de Anestesiología, Reanimación y Terapéutica del Dolor, Hospital Universitario Valdecilla, Santander, Spain; Hernández-Pinto, P., Hospital virtual Valdecilla, Santander, Spain, Servicio de Anestesiología, Reanimación y Terapéutica del Dolor, Hospital Universitario Valdecilla, Santander, Spain; Neira, N., Hospital virtual Valdecilla, Santander, Spain, Servicio de Anestesiología, Reanimación y Terapéutica del Dolor, Hospital Universitario Valdecilla, Santander, Spain; Capa, E., Hospital virtual Valdecilla, Santander, Spain, Servicio de Anestesiología, Reanimación y Terapéutica del Dolor, Hospital Universitario Valdecilla, Santander, Spain; Larraz, E., Hospital virtual Valdecilla, Santander, Spain, Servicio de Anestesiología, Reanimación y Terapéutica del Dolor, Hospital Universitario Valdecilla, Santander, Spain; Redondo-Figuero, C.G., Hospital virtual Valdecilla, Santander, Spain, Instituto de Investigación Sanitaria Valdecilla, Santander, Spain; Maestre, J.M., Hospital virtual Valdecilla, Santander, Spain, Servicio de Anestesiología, Reanimación y Terapéutica del Dolor, Hospital Universitario Valdecilla, Santander, Spain","Objective An increased number of errors and reduced patient safety have been reported during the incorporation of residents, as this period involves learning new skills. The objectives were to evaluate the learning outcomes of an immersive simulation boot-camp for incoming residents before starting the clinical rotations. Airway assessment, airway control with direct laryngoscopy, and epidural catheterization competencies were evaluated. Material and method Twelve first-year anaesthesiology residents participated. A prospective study to evaluate transfer of endotracheal intubation skills learned at the simulation centre to clinical practice (primary outcome) was conducted. A checklist of 28 skills and behaviours was used to assess the first supervised intubation performed during anaesthesia induction in ASA I/II patients. Secondary outcome was self-efficacy to perform epidural catheterization. A satisfaction survey was also performed. Results Seventy-five percent of residents completed more than 21 out of 28 skills and behaviours to assess and control the airway during their first intubation in patients. Twelve items were performed by all residents and 5 by half of them. More than 83% of participants reported a high level of self-efficacy in placing an epidural catheter. All participants would recommend the course to their colleagues. Conclusions A focused intensive simulation-based boot-camp addressing key competencies required to begin anaesthesia residency was well received, and led to transfer of airway management skills learned to clinical settings when performing for first time on patients, and to increased self-reported efficacy in performing epidural catheterization. © 2017 Sociedad Española de Anestesiología, Reanimación y Terapéutica del Dolor","Epidural anaesthesia; Intratracheal intubation; Learning; Patient simulation; Self-efficacy; Simulation training","anesthesiology; consumer attitude; curriculum; education; evaluation study; human; learning curve; medical education; prospective study; respiration control; self concept; simulation training; Airway Management; Anesthesiology; Consumer Behavior; Curriculum; Educational Measurement; Humans; Internship and Residency; Learning Curve; Prospective Studies; Self Efficacy; Simulation Training",Article,"Final","",Scopus,2-s2.0-85016051441
"Gomez J., Hoffman H.G., Bistricky S.L., Gonzalez M., Rosenberg L., Sampaio M., Garcia-Palacios A., Navarro-Haro M.V., Alhalabi W., Rosenberg M., Meyer W.J., III, Linehan M.M.","57220827769;7201677607;18036721500;57195929836;7201774858;57192413810;55917735200;56955636800;35316856000;9275212500;55444517900;7005724678;","The use of virtual reality facilitates dialectical behavior therapy® ""observing sounds and visuals"" mindfulness skills training exercises for a Latino patient with severe burns: A case study",2017,"Frontiers in Psychology","8","SEP", 1611,"","",,9,"10.3389/fpsyg.2017.01611","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030161102&doi=10.3389%2ffpsyg.2017.01611&partnerID=40&md5=cfc6de9a2ef8d7ba69415b3340aa8e50","Department of Psychology, Shriners Hospitals for Children-Galveston, Galveston, TX, United States; Clinical Health and Applied Sciences, University of Houston-Clear Lake, Houston, TX, United States; Virtual Reality Research Center at the Human Photonics Lab, Mechanical Engineering Department, University of Washington, Seattle, WA, United States; Department of Psychiatry and Behavioral Sciences, University of Texas Medical Branch, Galveston, TX, United States; Psychology Department, Jaume I University, Castellón de la Plana, Spain; Centro de Investigación Biomedica en Red-Fisiopatologia de la Obesidad y Nutricion (CIBERobn), Madrid, Spain; Hospital General de Catalunya, Barcelona, Spain; Virtual Reality Research Center, Computer Science Department, Effat University, Jeddah, Saudi Arabia; Behavioral Research and Therapy Clinics, Department of Psychology, University of Washington, Seattle, WA, United States","Gomez, J., Department of Psychology, Shriners Hospitals for Children-Galveston, Galveston, TX, United States, Clinical Health and Applied Sciences, University of Houston-Clear Lake, Houston, TX, United States; Hoffman, H.G., Virtual Reality Research Center at the Human Photonics Lab, Mechanical Engineering Department, University of Washington, Seattle, WA, United States; Bistricky, S.L., Clinical Health and Applied Sciences, University of Houston-Clear Lake, Houston, TX, United States; Gonzalez, M., Department of Psychology, Shriners Hospitals for Children-Galveston, Galveston, TX, United States, Department of Psychiatry and Behavioral Sciences, University of Texas Medical Branch, Galveston, TX, United States; Rosenberg, L., Department of Psychology, Shriners Hospitals for Children-Galveston, Galveston, TX, United States, Department of Psychiatry and Behavioral Sciences, University of Texas Medical Branch, Galveston, TX, United States; Sampaio, M., Virtual Reality Research Center at the Human Photonics Lab, Mechanical Engineering Department, University of Washington, Seattle, WA, United States; Garcia-Palacios, A., Psychology Department, Jaume I University, Castellón de la Plana, Spain, Centro de Investigación Biomedica en Red-Fisiopatologia de la Obesidad y Nutricion (CIBERobn), Madrid, Spain; Navarro-Haro, M.V., Hospital General de Catalunya, Barcelona, Spain; Alhalabi, W., Virtual Reality Research Center, Computer Science Department, Effat University, Jeddah, Saudi Arabia; Rosenberg, M., Department of Psychology, Shriners Hospitals for Children-Galveston, Galveston, TX, United States, Department of Psychiatry and Behavioral Sciences, University of Texas Medical Branch, Galveston, TX, United States; Meyer, W.J., III, Department of Psychology, Shriners Hospitals for Children-Galveston, Galveston, TX, United States, Department of Psychiatry and Behavioral Sciences, University of Texas Medical Branch, Galveston, TX, United States; Linehan, M.M., Behavioral Research and Therapy Clinics, Department of Psychology, University of Washington, Seattle, WA, United States","Sustaining a burn injury increases an individual's risk of developing psychological problems such as generalized anxiety, negative emotions, depression, acute stress disorder, or post-traumatic stress disorder. Despite the growing use of Dialectical Behavioral Therapy® (DBT®) by clinical psychologists, to date, there are no published studies using standard DBT® or DBT® skills learning for severe burn patients. The current study explored the feasibility and clinical potential of using Immersive Virtual Reality (VR) enhanced DBT® mindfulness skills training to reduce negative emotions and increase positive emotions of a patient with severe burn injuries. The participant was a hospitalized (in house) 21-year-old Spanish speaking Latino male patient being treated for a large (> 35% TBSA) severe flame burn injury. Methods: The patient looked into a pair of Oculus Rift DK2 virtual reality goggles to perceive the computer-generated virtual reality illusion of floating down a river, with rocks, boulders, trees, mountains, and clouds, while listening to DBT® mindfulness training audios during 4 VR sessions over a 1 month period. Study measures were administered before and after each VR session. Results: As predicted, the patient reported increased positive emotions and decreased negative emotions. The patient also accepted the VR mindfulness treatment technique. He reported the sessions helped him become more comfortable with his emotions and he wanted to keep using mindfulness after returning home. Conclusions: Dialectical Behavioral Therapy is an empirically validated treatment approach that has proved effective with non-burn patient populations for treating many of the psychological problems experienced by severe burn patients. The current case study explored for the first time, the use of immersive virtual reality enhanced DBT® mindfulness skills training with a burn patient. The patient reported reductions in negative emotions and increases in positive emotions, after VR DBT® mindfulness skills training. Immersive Virtual Reality is becoming widely available to mainstream consumers, and thus has the potential to make this treatment available to a much wider number of patient populations, including severe burn patients. Additional development, and controlled studies are needed. © 2017 Gomez, Hoffman, Bistricky, Gonzalez, Rosenberg, Sampaio, Garcia-Palacios, Navarro-Haro, Alhalabi, Rosenberg, Meyer and Linehan.","Burn patients; Dialectical behavioral therapy; Emotions; Mindfulness; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85030161102
"Lin L., Parmar D., Babu S.V., Leonard A.E., Daily S.B., Jörg S.","57077354200;55869852800;9039004700;56146540500;8212520300;26221294500;","How character customization affects learning in computational thinking",2017,"Proceedings - SAP 2017, ACM Symposium on Applied Perception",,, a1,"","",,7,"10.1145/3119881.3119884","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030788272&doi=10.1145%2f3119881.3119884&partnerID=40&md5=1e03140af2a33557bbe2e67d008086c7","Clemson University, United States; University of Florida, United States","Lin, L., Clemson University, United States; Parmar, D., Clemson University, United States; Babu, S.V., Clemson University, United States; Leonard, A.E., Clemson University, United States; Daily, S.B., University of Florida, United States; Jörg, S., Clemson University, United States","The ability to select or customize characters in educational applications and games has been shown to influence factors related to learning effects such as transfer, self-efficacy, and motivation. Most previous conclusions on the perception of virtual characters and the effect of character assignment in interactive applications have been reached through short, one-task experiments. To investigate more long-term effects of assigning versus customizing characters as well as explore perceptions of personal character appearance, we conduct a study in which sixth and seventh grade students are introduced to programming concepts with the software VEnvI (Virtual Environment Interactions) in seven one-hour sessions over two weeks. In VEnvI, students create performances for virtual characters by assembling blocks. With a between-subjects design, in which some of the students can alter their character and others are not given that possibility, we examine the influence of the presence or absence of character choice options on learning. We hypothesize that students have higher learning outcomes when they can choose and customize how their character looks compared to when they are assigned a character. We confirm this hypothesis for a category of learning (Remember and Understand) and give insights on students' relationships with their character. © 2017 Association for Computing Machinery.","Character appearance; Character customization; Pedagogical agent; Virtual character","Students; Virtual reality; Character appearance; Character customization; Computational thinkings; Educational Applications; Interactive applications; Pedagogical agents; Programming concepts; Virtual character; Education",Conference Paper,"Final","",Scopus,2-s2.0-85030788272
"Hoedt S., Claeys A., Van Landeghem H., Cottyn J.","57045968300;57045712400;23013574600;35145389900;","The evaluation of an elementary virtual training system for manual assembly",2017,"International Journal of Production Research","55","24",,"7496","7508",,13,"10.1080/00207543.2017.1374572","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029453228&doi=10.1080%2f00207543.2017.1374572&partnerID=40&md5=629547701b08d4d25cbd017c7ccd8fb2","Department of Industrial Systems Engineering and Product Design, Ghent University, Gent-Zwijnaarde, Belgium; Department of Agile and Human Centered Production and Robotic Systems, Flanders Make, Ghent, Belgium","Hoedt, S., Department of Industrial Systems Engineering and Product Design, Ghent University, Gent-Zwijnaarde, Belgium, Department of Agile and Human Centered Production and Robotic Systems, Flanders Make, Ghent, Belgium; Claeys, A., Department of Industrial Systems Engineering and Product Design, Ghent University, Gent-Zwijnaarde, Belgium, Department of Agile and Human Centered Production and Robotic Systems, Flanders Make, Ghent, Belgium; Van Landeghem, H., Department of Industrial Systems Engineering and Product Design, Ghent University, Gent-Zwijnaarde, Belgium, Department of Agile and Human Centered Production and Robotic Systems, Flanders Make, Ghent, Belgium; Cottyn, J., Department of Industrial Systems Engineering and Product Design, Ghent University, Gent-Zwijnaarde, Belgium, Department of Agile and Human Centered Production and Robotic Systems, Flanders Make, Ghent, Belgium","Due to the low volume high variety strategies of manufacturing companies, manual assembly operators have a much larger cognitive load than before. The expertise of the operators must be kept up to date at any time. Since the high investment and low flexibility of a real setting to perform a manual assembly training, a virtual replica is introduced in many cases. The aim of this paper is to study the effect of an elementary virtual training for manual assembly tasks. In literature, different studies on the topic can be found; nevertheless, a comparison between the different studies is not possible due to diverse evaluation methods and descriptions. A benchmark for a uniform evaluation of virtual training systems is presented and applied to this experiment. Two groups were submitted to a number of manual assembly tasks. The test group got a virtual training period in advance. A significant learning transfer during that training period was observed. When the first assembly of the reference group is counted as a real training, no significant difference can be found between the virtual and real training. The outcomes of this experiment will be used in future work to compare different virtual training systems and influential factors such as the assembly complexity. Furthermore, the application of virtual training to manual assembly in a mixed-model environment and its industrial usability are topics that still need to be studied. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","Learning effect; Manual assembly; Virtual manufacturing; Virtual reality; Virtual training","Agile manufacturing systems; Virtual reality; Evaluation methods; Influential factors; Learning effects; Manual assembly; Manufacturing companies; Virtual manufacturing; Virtual training; Virtual training systems; E-learning",Article,"Final","",Scopus,2-s2.0-85029453228
"Hudak J., Blume F., Dresler T., Haeussinger F.B., Renner T.J., Fallgatter A.J., Gawrilow C., Ehlis A.-C.","57192717210;57113781000;24466569200;53979521900;15833222900;7004260129;16233108200;35567040300;","Near-infrared spectroscopy-based frontal lobe neurofeedback integrated in virtual reality modulates brain and behavior in highly impulsive adults",2017,"Frontiers in Human Neuroscience","11",, 425,"","",,19,"10.3389/fnhum.2017.00425","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032012534&doi=10.3389%2ffnhum.2017.00425&partnerID=40&md5=18be33720336565bc9575c980685706e","LEAD Graduate School and Research Network, University of Tübingen, Tübingen, Germany; Department of Psychiatry and Psychotherapy, University Hospital Tübingen, Tübingen, Germany; Department of Child and Adolescence Psychiatry, University Hospital Tübingen, Tübingen, Germany; Center for Integrative Neuroscience, University of Tübingen, Tübingen, Germany; Department of Psychology, University of Tübingen, Tübingen, Germany; Center for Individual Development and Adaptive Education of Children at Risk, Goethe University Frankfurt, Frankfurt, Germany","Hudak, J., LEAD Graduate School and Research Network, University of Tübingen, Tübingen, Germany; Blume, F., LEAD Graduate School and Research Network, University of Tübingen, Tübingen, Germany; Dresler, T., LEAD Graduate School and Research Network, University of Tübingen, Tübingen, Germany, Department of Psychiatry and Psychotherapy, University Hospital Tübingen, Tübingen, Germany; Haeussinger, F.B., Department of Psychiatry and Psychotherapy, University Hospital Tübingen, Tübingen, Germany; Renner, T.J., Department of Child and Adolescence Psychiatry, University Hospital Tübingen, Tübingen, Germany; Fallgatter, A.J., LEAD Graduate School and Research Network, University of Tübingen, Tübingen, Germany, Department of Psychiatry and Psychotherapy, University Hospital Tübingen, Tübingen, Germany, Center for Integrative Neuroscience, University of Tübingen, Tübingen, Germany; Gawrilow, C., LEAD Graduate School and Research Network, University of Tübingen, Tübingen, Germany, Department of Psychology, University of Tübingen, Tübingen, Germany, Center for Individual Development and Adaptive Education of Children at Risk, Goethe University Frankfurt, Frankfurt, Germany; Ehlis, A.-C., LEAD Graduate School and Research Network, University of Tübingen, Tübingen, Germany, Department of Psychiatry and Psychotherapy, University Hospital Tübingen, Tübingen, Germany","Based on neurofeedback (NF) training as a neurocognitive treatment in attention-deficit/hyperactivity disorder (ADHD), we designed a randomized, controlled functional near-infrared spectroscopy (fNIRS) NF intervention embedded in an immersive virtual reality classroom in which participants learned to control overhead lighting with their dorsolateral prefrontal brain activation. We tested the efficacy of the intervention on healthy adults displaying high impulsivity as a sub-clinical population sharing common features with ADHD. Twenty participants, 10 in an experimental and 10 in a shoulder muscle-based electromyography control group, underwent eight training sessions across 2 weeks. Training was bookended by a pre- and post-test including go/no-go, n-back, and stop-signal tasks (SST). Results indicated a significant reduction in commission errors on the no-go task with a simultaneous increase in prefrontal oxygenated hemoglobin concentration for the experimental group, but not for the control group. Furthermore, the ability of the subjects to gain control over the feedback parameter correlated strongly with the reduction in commission errors for the experimental, but not for the control group, indicating the potential importance of learning feedback control in moderating behavioral outcomes. In addition, participants of the fNIRS group showed a reduction in reaction time variability on the SST. Results indicate a clear effect of our NF intervention in reducing impulsive behavior possibly via a strengthening of frontal lobe functioning. Virtual reality additions to conventional NF may be one way to improve the ecological validity and symptom-relevance of the training situation, hence positively affecting transfer of acquired skills to real life. © 2017 Hudak, Blume, Dresler, Haeussinger, Renner, Fallgatter, Gawrilow and Ehlis.","ADHD; Impulsivity; Neurofeedback; NIRS; Virtual reality","adult; Article; cognition assessment; controlled study; electromyography; female; frontal lobe; go no go task; human; human experiment; impulsiveness; learning; male; mental task; n-back test; near infrared spectroscopy; neurofeedback; neuromodulation; randomized controlled trial; response time; stop signal task; task performance; virtual reality; young adult",Article,"Final","",Scopus,2-s2.0-85032012534
"Tidoni E., Abu-Alqumsan M., Leonardis D., Kapeller C., Fusco G., Guger C., Hintermuller C., Peer A., Frisoli A., Tecchia F., Bergamasco M., Aglioti S.M.","46261708700;41261045900;54389543000;37083868500;56388423300;55903211100;8440419500;15823160300;6603070041;6603477008;7003907071;7007006465;","Local and Remote Cooperation with Virtual and Robotic Agents: A P300 BCI Study in Healthy and People Living with Spinal Cord Injury",2017,"IEEE Transactions on Neural Systems and Rehabilitation Engineering","25","9", 7797151,"1622","1632",,19,"10.1109/TNSRE.2016.2626391","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029600422&doi=10.1109%2fTNSRE.2016.2626391&partnerID=40&md5=b17bb08935767322e6f8bed36b476792","Department of Psychology, University of Rome la Sapienza, Rome, 00185, Italy; Fondazione Santa Lucia IRCCS, Rome, Italy; Chair of Automatic Control Engineering, Technical University of Munich, TUM, Munich, Germany; Percro Laboratory, Scuola Superiore sant'Anna, Pisa, Italy; Guger Technologies OG, Graz, 8020, Austria; G.tec Medical Engineering GmbH, Schiedlberg, Austria; Bristol Robotics Laboratory, University of the West of England, Bristol, Bristol, United Kingdom","Tidoni, E., Department of Psychology, University of Rome la Sapienza, Rome, 00185, Italy, Fondazione Santa Lucia IRCCS, Rome, Italy; Abu-Alqumsan, M., Chair of Automatic Control Engineering, Technical University of Munich, TUM, Munich, Germany; Leonardis, D., Percro Laboratory, Scuola Superiore sant'Anna, Pisa, Italy; Kapeller, C., Guger Technologies OG, Graz, 8020, Austria, G.tec Medical Engineering GmbH, Schiedlberg, Austria; Fusco, G., Department of Psychology, University of Rome la Sapienza, Rome, 00185, Italy, Fondazione Santa Lucia IRCCS, Rome, Italy; Guger, C., Guger Technologies OG, Graz, 8020, Austria, G.tec Medical Engineering GmbH, Schiedlberg, Austria; Hintermuller, C., Guger Technologies OG, Graz, 8020, Austria, G.tec Medical Engineering GmbH, Schiedlberg, Austria; Peer, A., Bristol Robotics Laboratory, University of the West of England, Bristol, Bristol, United Kingdom; Frisoli, A., Percro Laboratory, Scuola Superiore sant'Anna, Pisa, Italy; Tecchia, F., Percro Laboratory, Scuola Superiore sant'Anna, Pisa, Italy; Bergamasco, M., Percro Laboratory, Scuola Superiore sant'Anna, Pisa, Italy; Aglioti, S.M., Department of Psychology, University of Rome la Sapienza, Rome, 00185, Italy, Fondazione Santa Lucia IRCCS, Rome, Italy","The development of technological applications that allow people to control and embody external devices within social interaction settings represents a major goal for current and future brain-computer interface (BCI) systems. Prior research has suggested that embodied systems may ameliorate BCI end-user's experience and accuracy in controlling external devices. Along these lines, we developed an immersive P300-based BCI application with a head-mounted display for virtual-local and robotic-remote social interactions and explored in a group of healthy participants the role of proprioceptive feedback in the control of a virtual surrogate (Study 1). Moreover, we compared the performance of a small group of people with spinal cord injury (SCI) to a control group of healthy subjects during virtual and robotic social interactions (Study 2), where both groups received a proprioceptive stimulation. Our attempt to combine immersive environments, BCI technologies and neuroscience of body ownership suggests that providing realistic multisensory feedback still represents a challenge. Results have shown that healthy and people living with SCI used the BCI within the immersive scenarios with good levels of performance (as indexed by task accuracy, optimizations calls and Information Transfer Rate) and perceived control of the surrogates. Proprioceptive feedback did not contribute to alter performance measures and body ownership sensations. Further studies are necessary to test whether sensorimotor experience represents an opportunity to improve the use of future embodied BCI applications. © 2001-2011 IEEE.","Body illusions - tendon vibration; brain-computer interface (BCI) P300; spinal cord injury; teleoperation; virtual reality","Computer control systems; Feedback; Helmet mounted displays; Interfaces (computer); Patient rehabilitation; Remote control; Robotics; Sensory perception; Social sciences; Virtual reality; Body illusions - tendon vibration; Head mounted displays; Immersive environment; Information transfer rate; Multi-sensory feedback; Performance measure; Spinal cord injuries (SCI); Technological applications; Brain computer interface; adult; Article; biceps brachii muscle; brain computer interface; clinical article; computer graphics; controlled study; discriminant analysis; female; human; human computer interaction; kinematics; male; mathematical analysis; middle aged; neuroscience nursing; proprioceptive feedback; questionnaire; real time tracking system; remote sensing; sensorimotor cortex; social interaction; spinal cord injury; telemonitoring; tendon; virtual reality; visual acuity; visual stimulation; computer interface; event related potential; imagination; man machine interaction; movement (physiology); pathophysiology; procedures; randomized controlled trial; reproducibility; robotics; sensitivity and specificity; Spinal Cord Injuries; task performance; young adult; Adult; Brain-Computer Interfaces; Event-Related Potentials, P300; Female; Humans; Imagination; Male; Man-Machine Systems; Movement; Reproducibility of Results; Robotics; Sensitivity and Specificity; Spinal Cord Injuries; Task Performance and Analysis; User-Computer Interface; Young Adult",Article,"Final","",Scopus,2-s2.0-85029600422
"Shochat G., Maoz S., Stark-Inbar A., Blumenfeld B., Rand D., Preminger S., Sacher Y.","57197733805;57197737292;57191206641;13408503500;8610999900;14833131300;6506781178;","Motion-based virtual reality cognitive training targeting executive functions in acquired brain injury community-dwelling individuals: A feasibility and initial efficacy pilot",2017,"International Conference on Virtual Rehabilitation, ICVR","2017-June",, 8007530,"","",,4,"10.1109/ICVR.2017.8007530","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034269195&doi=10.1109%2fICVR.2017.8007530&partnerID=40&md5=f02845a48c89fde17904e5b502faa247","Department of Traumatic Brain Injury, Loewenstein Rehabilitation Center, Raanana, Israel; Intendu Ltd, Herzliya, Israel; Department of Occupational Therapy, Tel Aviv University, Tel Aviv, Israel","Shochat, G., Department of Traumatic Brain Injury, Loewenstein Rehabilitation Center, Raanana, Israel; Maoz, S., Intendu Ltd, Herzliya, Israel; Stark-Inbar, A., Intendu Ltd, Herzliya, Israel; Blumenfeld, B., Intendu Ltd, Herzliya, Israel; Rand, D., Department of Occupational Therapy, Tel Aviv University, Tel Aviv, Israel; Preminger, S., Intendu Ltd, Herzliya, Israel; Sacher, Y., Department of Traumatic Brain Injury, Loewenstein Rehabilitation Center, Raanana, Israel","Acquired brain injury (ABI) is a leading cause of long-term cognitive disability, often involving deficits in executive functions (EF). ABI patients usually stop receiving cognitive treatment when leaving the rehabilitation facility or shortly thereafter, due to the high cost of therapy sessions and the mobility requirement to access therapy. Software solutions offer a promising tool for accessible and affordable cognitive rehabilitation in the home environment. However, research provides limited evidence for effective transfer of benefits from computerized cognitive training to real-life functions. Virtual reality (VR) exergames using motion-interaction offer a more realistic and natural training environment, and are therefore expected to facilitate a more effective transfer. Although commercial exergames may bring about some cognitive gains, they usually do not target cognitive functions directly. Here we describe a novel exergames platform, the Active Brain Trainer (ABT), designed to directly target EF, using games in multiple realistic contexts. The software adapts in real-time to the patient's behavior, providing feedback and rewards, and hence may enhance usability and compliance. The primary goal of the current study is to assess the feasibly and acceptability of this platform for community-dwelling ABI patients during the chronic phase. A secondary goal is to assess the initial efficacy on EF and functional benefits from program training. Participants were instructed to use the games for 15-20 sessions. Neuropsychological assessments of EF and daily life functions were performed before and after training. Participants also filled a satisfaction questionnaire following training. All training and assessments were conducted in the participants' homes. Game performance was recorded throughout training sessions. Preliminary results from the six ABI patients who successfully completed the program so far show no adverse effects. Participants reported enjoyment and satisfaction from training. Participants performed increasingly more challenging EF tasks within game environments. Initial results show improvements in functional tasks and most executive neuropsychological assessments following training. Additional participants are currently being trained to increase the power of the results. These preliminary findings support the feasibility and potential efficacy of the motion-based cognitive training of EF for community-dwelling individuals with ABI. © 2017 IEEE.","acquired brain injury; Cognitive training; community-dwelling; executive functions; exergames; motion-based","Buildings; E-learning; Housing; Patient treatment; Virtual reality; Acquired brain injuries; Cognitive training; community-dwelling; Executive function; Exergames; motion-based; Patient rehabilitation",Conference Paper,"Final","",Scopus,2-s2.0-85034269195
"Ragan E.D., Scerbo S., Bacim F., Bowman D.A.","26667185300;55210765300;16174310700;57203231782;","Amplified Head Rotation in Virtual Reality and the Effects on 3D Search, Training Transfer, and Spatial Orientation",2017,"IEEE Transactions on Visualization and Computer Graphics","23","8", 7547900,"1880","1895",,22,"10.1109/TVCG.2016.2601607","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028407406&doi=10.1109%2fTVCG.2016.2601607&partnerID=40&md5=36f5ebc4f3b8d70469432fd11b448a6f","Texas A and M University, College Station, TX  77843, United States; Virginia Tech, Blacksburg, VA  24061, United States","Ragan, E.D., Texas A and M University, College Station, TX  77843, United States; Scerbo, S., Virginia Tech, Blacksburg, VA  24061, United States; Bacim, F., Virginia Tech, Blacksburg, VA  24061, United States; Bowman, D.A., Virginia Tech, Blacksburg, VA  24061, United States","Many types of virtual reality (VR) systems allow users to use natural, physical head movements to view a 3D environment. In some situations, such as when using systems that lack a fully surrounding display or when opting for convenient low-effort interaction, view control can be enabled through a combination of physical and virtual turns to view the environment, but the reduced realism could potentially interfere with the ability to maintain spatial orientation. One solution to this problem is to amplify head rotations such that smaller physical turns are mapped to larger virtual turns, allowing trainees to view the entire surrounding environment with small head movements. This solution is attractive because it allows semi-natural physical view control rather than requiring complete physical rotations or a fully-surrounding display. However, the effects of amplified head rotations on spatial orientation and many practical tasks are not well understood. In this paper, we present an experiment that evaluates the influence of amplified head rotation on 3D search, spatial orientation, and cybersickness. In the study, we varied the amount of amplification and also varied the type of display used (head-mounted display or surround-screen CAVE) for the VR search task. By evaluating participants first with amplification and then without, we were also able to study training transfer effects. The findings demonstrate the feasibility of using amplified head rotation to view 360 degrees of virtual space, but noticeable problems were identified when using high amplification with a head-mounted display. In addition, participants were able to more easily maintain a sense of spatial orientation when using the CAVE version of the application, which suggests that visibility of the user's body and awareness of the CAVE's physical environment may have contributed to the ability to use the amplification technique while keeping track of orientation. © 1995-2012 IEEE.","3D interaction; cybersickness; Rotation amplification; Search; Spatial orientation; Virtual reality","Caves; E-learning; Helmet mounted displays; Virtual reality; 3D interactions; Amplification technique; Cybersickness; Head mounted displays; Physical environments; Search; Spatial orientations; Surrounding environment; Rotation",Article,"Final","",Scopus,2-s2.0-85028407406
"Johnson C.M., McIlwain S., Gray O., Willson B., Vorderstrasse A.","55476414500;57191912305;57194557749;57191913695;36343108200;","Creating a sustainable collaborative consumer health application for chronic disease self-management",2017,"Journal of Biomedical Informatics","71",,,"198","206",,5,"10.1016/j.jbi.2017.06.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020762730&doi=10.1016%2fj.jbi.2017.06.004&partnerID=40&md5=0eb37f04e986c27dbc69ba8ead44b8da","Duke University School of Nursing, 307 Trent Drive, Durham, NC  27710, United States; Virtual Heroes Raleigh – a Division of Applied Research Associates, 8537 Six Forks Road, Suite 600, Raleigh, NC  27615, United States","Johnson, C.M., Duke University School of Nursing, 307 Trent Drive, Durham, NC  27710, United States; McIlwain, S., Virtual Heroes Raleigh – a Division of Applied Research Associates, 8537 Six Forks Road, Suite 600, Raleigh, NC  27615, United States; Gray, O., Virtual Heroes Raleigh – a Division of Applied Research Associates, 8537 Six Forks Road, Suite 600, Raleigh, NC  27615, United States; Willson, B., Virtual Heroes Raleigh – a Division of Applied Research Associates, 8537 Six Forks Road, Suite 600, Raleigh, NC  27615, United States; Vorderstrasse, A., Duke University School of Nursing, 307 Trent Drive, Durham, NC  27710, United States","As the prevalence of chronic diseases increase, there is a need for consumer-centric health informatics applications that assist individuals with disease self-management skills. However, due to the cost of development of these applications, there is also a need to build a disease agnostic architecture so that they could be reused for any chronic disease. This paper describes the architecture of a collaborative virtual environment (VE) platform, LIVE©, that was developed to teach self-management skills and provide social support to those individuals with type 2 diabetes. However, a backend database allows for the application to be easily reused for any chronic disease. We tested its usability in the context of a larger randomized controlled trial of its efficacy. The usability was scored as ‘good’ by half of the participants in the evaluation. Common errors in the testing and solutions to address initial usability issues are discussed. Overall, LIVE© represents a usable and generalizable platform that will be adapted to other chronic diseases and health needs in future research and applications. © 2017 Elsevier Inc.","Chronic disease; Consumer health informatics; Self-management; Type 2 diabetes; Virtual environments","Environmental management; Health; Virtual reality; Chronic disease; Collaborative virtual environment; Consumer health informatics; Health informatics; Randomized controlled trial; Research and application; Self management; Type-2 diabetes; Diseases; adult; Article; chronic disease; clinical article; controlled study; data base; female; human; male; medical informatics; non insulin dependent diabetes mellitus; priority journal; self care; skill; social support; software; teaching; virtual reality; aged; chronic disease; computer system; consumer health informatics; disease management; middle aged; non insulin dependent diabetes mellitus; randomized controlled trial; Aged; Chronic Disease; Computer Systems; Consumer Health Informatics; Diabetes Mellitus, Type 2; Disease Management; Female; Humans; Male; Medical Informatics Applications; Middle Aged; Self Care; Social Support",Article,"Final","",Scopus,2-s2.0-85020762730
"Ahmad A.","8244331200;","Using audio to train pace in a virtual environment",2017,"ASEE Annual Conference and Exposition, Conference Proceedings","2017-June",,,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030562513&partnerID=40&md5=8c54f0091d10fbb134b10ed9e2fe8dcc","Northwestern State University of Louisiana, United States","Ahmad, A., Northwestern State University of Louisiana, United States","Virtual reality has been used for training in multiple domains including military, healthcare and manufacturing. The integration of additional modalities (other than visual) is an ongoing research topic in virtual reality. This paper presents an experimental evaluation of the utility of using auditory cues to train temporal tasks (e.g., pace setting) in virtual training systems. There were four different auditory cues used for training pace: 1) a metronome, 2) non-spatial auditory earcons, 3) a spatialized auditory earcon, and 4) no audio. Sixty-eight people participated in the study. A pre- post between subjects' experimental design was used, with eight training trials. The measure used for assessing pace performance was the average deviation from a predetermined desired pace. The results demonstrated that a metronome was not effective in training participants to maintain a desired pace, while, spatial and non-spatial earcons were effective strategies for pace training. Moreover, an examination of post-training performance as compared to pre-training suggests some transfer of learning. Design guidelines were extracted for integrating auditory cues for pace training tasks in virtual environments. © American Society for Engineering Education, 2017.",,"Design of experiments; Engineering education; Virtual reality; Auditory cues; Average deviation; Experimental evaluation; Multiple domains; Research topics; Training trials; Transfer of learning; Virtual training systems; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85030562513
"Song S., Yang J.","55340188800;37045870100;","Configurable component framework supporting motion platform-based VR simulators",2017,"Journal of Mechanical Science and Technology","31","6",,"2985","2996",,2,"10.1007/s12206-017-0542-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025633040&doi=10.1007%2fs12206-017-0542-1&partnerID=40&md5=3864684d5c2c89bba0d90acd7c4c99e6","Department of Industrial Engineering, Ajou University, 206 Worldcup-ro, Suwon, 16499, South Korea","Song, S., Department of Industrial Engineering, Ajou University, 206 Worldcup-ro, Suwon, 16499, South Korea; Yang, J., Department of Industrial Engineering, Ajou University, 206 Worldcup-ro, Suwon, 16499, South Korea","This paper classifies functional elements of a motion platform-based VR simulator by its component types, and proposes a VR simulator component framework (VSCF) that can be used in various VR simulators by integrating associated components. The VSCF consists of a VSCF component manager (VCM), VSCF components (VCs), and a VSCF data interface (VDI). The functional elements of a VR simulator are defined by the VC units that are registered to the VCM and operated on by the VR simulator. The VCM manages the registered VCs and plays a role in controlling information exchange between VCs. The information for VCs is defined at the VDI while the VCM stores essential elements necessary to collect and transfer information into the VDI and provide it to VCs. Simulator developers configure VCs depending on functional elements required by the VR simulator and define the VDI for information exchange between VCs from which they are able to build various motion platform-based VR simulators by integrating the VCs through the VCM. In this study, two VR simulators were developed to verify the applicability of the VSCF: The first was a VR simulator for firefighting robot training and the second was a VR simulator for electrical wheelchair operation. © 2017, The Korean Society of Mechanical Engineers and Springer-Verlag GmbH Germany.","Component framework; Component framework; Motion platform; Virtual reality simulator","Information dissemination; Virtual reality; Component framework; Fire-fighting robot; Functional elements; Information exchanges; Motion platforms; Simulator components; Transfer information; Virtual reality simulator; Simulators",Article,"Final","",Scopus,2-s2.0-85025633040
"Vergara D., Rubio M.P., Lorenzo M.","57211856936;56817934900;34979055000;","On the design of virtual reality learning environments in engineering",2017,"Multimodal Technologies and Interaction","1","2", 11,"","",,43,"10.3390/mti1020011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043994822&doi=10.3390%2fmti1020011&partnerID=40&md5=874bccfd998af002acd8c1ac19fa2e93","Technological Department, University Catholic of Ávila, C/Canteros, s/n, Avila, 05005, Spain; Construction Department, University of Salamanca, Campus Viriato, Zamora, 37008, Spain; Department of Mechanical Engineering, University of Salamanca, ETSII, Avda. Fernando Ballesteros, 2, Béjar, Salamanca  37700, Spain","Vergara, D., Technological Department, University Catholic of Ávila, C/Canteros, s/n, Avila, 05005, Spain; Rubio, M.P., Construction Department, University of Salamanca, Campus Viriato, Zamora, 37008, Spain; Lorenzo, M., Department of Mechanical Engineering, University of Salamanca, ETSII, Avda. Fernando Ballesteros, 2, Béjar, Salamanca  37700, Spain","Currently, the use of virtual reality (VR) is being widely applied in different fields, especially in computer science, engineering, and medicine. Concretely, the engineering applications based on VR cover approximately one half of the total number of VR resources (considering the research works published up to last year, 2016). In this paper, the capabilities of different computational software for designing VR applications in engineering education are discussed. As a result, a general flowchart is proposed as a guide for designing VR resources in any application. It is worth highlighting that, rather than this study being based on the applications used in the engineering field, the obtained results can be easily extrapolated to other knowledge areas without any loss of generality. This way, this paper can serve as a guide for creating a VR application. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Design; Education; Engineering; Instruction; Virtual laboratory; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85043994822
"Brunhart-Lupo N., Bush B.W., Gruchalla K., Smith S.","55781621700;36866246700;25960789400;57212961760;","Simulation exploration through immersive parallel planes",2017,"2016 Workshop on Immersive Analytics, IA 2016",,, 7932377,"19","24",,3,"10.1109/IMMERSIVE.2016.7932377","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025675994&doi=10.1109%2fIMMERSIVE.2016.7932377&partnerID=40&md5=76040040e11aa7e93b6095f7bc40b631","National Renewable Energy Laboratory, United States; Los Alamos Visualization Associates, United States","Brunhart-Lupo, N., National Renewable Energy Laboratory, United States; Bush, B.W., National Renewable Energy Laboratory, United States; Gruchalla, K., National Renewable Energy Laboratory, United States; Smith, S., Los Alamos Visualization Associates, United States","We present a visualization-driven simulation system that tightly couples systems dynamics simulations with an immersive virtual environment to allow analysts to rapidly develop and test hypotheses in a high-dimensional parameter space. To accomplish this, we generalize the two-dimensional parallel-coordinates statistical graphic as an immersive «parallel-planes» visualization for multivariate time series emitted by simulations running in parallel with the visualization. In contrast to traditional parallel coordinate's mapping the multivariate dimensions onto coordinate axes represented by a series of parallel lines, we map pairs of the multivariate dimensions onto a series of parallel rectangles. As in the case of parallel coordinates, each individual observation in the dataset is mapped to a polyline whose vertices coincide with its coordinate values. Regions of the rectangles can be «brushed» to highlight and select observations of interest: A «slider» control allows the user to filter the observations by their time coordinate. In an immersive virtual environment, users interact with the parallel planes using a joystick that can select regions on the planes, manipulate selection, and filter time. The brushing and selection actions are used to both explore existing data as well as to launch additional simulations corresponding to the visually selected portions of the input parameter space. As soon as the new simulations complete, their resulting observations are displayed in the virtual environment. This tight feedback loop between simulation and immersive analytics accelerates users' realization of insights about the simulation and its output. © 2016 IEEE.","I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Virtual reality","Computer aided software engineering; Computer graphics; Data visualization; Three dimensional computer graphics; Visualization; High-dimensional; I.3.7 [computer graphics]: three-dimensional graphics and realism - virtual realities; Immersive virtual environments; Multivariate time series; Parallel coordinates; Simulation systems; Statistical graphics; Time coordinates; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85025675994
"Martin K.A., Laviola J.J.","56119040300;6602792780;","The Transreality Interaction Platform: Enabling Interaction across Physical and Virtual Reality",2017,"Proceedings - 2016 IEEE International Conference on Internet of Things; IEEE Green Computing and Communications; IEEE Cyber, Physical, and Social Computing; IEEE Smart Data, iThings-GreenCom-CPSCom-Smart Data 2016",,, 7917082,"177","186",,3,"10.1109/iThings-GreenCom-CPSCom-SmartData.2016.54","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020224414&doi=10.1109%2fiThings-GreenCom-CPSCom-SmartData.2016.54&partnerID=40&md5=a8854fd2389e9f894285444a67202328","Dept. of Computer Science, University of Central Florida, Orlando, FL, United States","Martin, K.A., Dept. of Computer Science, University of Central Florida, Orlando, FL, United States; Laviola, J.J., Dept. of Computer Science, University of Central Florida, Orlando, FL, United States","The convergence of the Internet of Things (IoT) and interactive systems will enable future interactive environments which transcend physical and virtual reality. Embedded Things provide sensors and actuators to virtualize the physical environment, while Interactive Things extend the virtualized environment with modalities for human interaction, ranging from tangible and wearable interfaces to immersive virtual and augmented reality interfaces. We introduce the Transreality Interaction Platform (TrIP) to enable service ecosystems which situate virtual objects alongside virtualized physical objects and allow for novel ad-hoc interactions between humans, virtual, and physical objects in a transreality environment. TrIP provides a generalized middleware platform addressing the unique challenges that arise in complex transreality systems which have yet to be fully explored in current IoT or HCI research. We describe the system architecture, data model, and query language for the platform and present a proof-of-concept implementation. We evaluate the performance of the implementation and demonstrate its use integrating embedded and interactive things for seamless interaction across physical and virtual realities. © 2016 IEEE.","Augmented Reality; Interactive Systems; Interactive Things; Internet of Things; Tangible User Interface; Transreality; Virtual Reality","Augmented reality; Green computing; Internet of things; Middleware; Query languages; Search engines; User interfaces; Interactive Environments; Interactive system; Interactive Things; Internet of thing (IOT); Tangible user interfaces; Transreality; Virtual and augmented reality; Virtualized environment; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85020224414
"de Mello Monteiro C.B., da Silva T.D., de Abreu L.C., Fregni F., de Araujo L.V., Ferreira F.H.I.B., Leone C.","36952872700;55546962700;57192659178;57209478889;12788134600;55636322055;11839802700;","Short-term motor learning through non-immersive virtual reality task in individuals with down syndrome",2017,"BMC Neurology","17","1", 71,"","",,18,"10.1186/s12883-017-0852-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018501272&doi=10.1186%2fs12883-017-0852-z&partnerID=40&md5=5639b95a8cff8c75da9ed4a63b4b088e","University of São Paulo, School of Arts, Sciences and Humanities, Av. Arlindo Béttio, 1000, Ermelino Matarazzo, São Paulo, 03828-000, Brazil; University of São Paulo, School of Public Health, São Paulo, Brazil; Harvard University, Harvard School of Public Health, Boston, MA, United States; University of São Paulo, Center for Neurosciences (NEC), São Paulo, Brazil; Harvard Medical School, Spaulding Rehabilitation Hospital and Massachusetts General Hospital, Boston, MA, United States","de Mello Monteiro, C.B., University of São Paulo, School of Arts, Sciences and Humanities, Av. Arlindo Béttio, 1000, Ermelino Matarazzo, São Paulo, 03828-000, Brazil, University of São Paulo, School of Public Health, São Paulo, Brazil; da Silva, T.D., University of São Paulo, School of Arts, Sciences and Humanities, Av. Arlindo Béttio, 1000, Ermelino Matarazzo, São Paulo, 03828-000, Brazil, Harvard University, Harvard School of Public Health, Boston, MA, United States; de Abreu, L.C., University of São Paulo, School of Public Health, São Paulo, Brazil; Fregni, F., University of São Paulo, Center for Neurosciences (NEC), São Paulo, Brazil, Harvard Medical School, Spaulding Rehabilitation Hospital and Massachusetts General Hospital, Boston, MA, United States; de Araujo, L.V., University of São Paulo, School of Arts, Sciences and Humanities, Av. Arlindo Béttio, 1000, Ermelino Matarazzo, São Paulo, 03828-000, Brazil; Ferreira, F.H.I.B., University of São Paulo, School of Arts, Sciences and Humanities, Av. Arlindo Béttio, 1000, Ermelino Matarazzo, São Paulo, 03828-000, Brazil; Leone, C., University of São Paulo, School of Public Health, São Paulo, Brazil","Background: Down syndrome (DS) has unique physical, motor and cognitive characteristics. Despite cognitive and motor difficulties, there is a possibility of intervention based on the knowledge of motor learning. However, it is important to study the motor learning process in individuals with DS during a virtual reality task to justify the use of virtual reality to organize intervention programs. The aim of this study was to analyze the motor learning process in individuals with DS during a virtual reality task. Methods: A total of 40 individuals participated in this study, 20 of whom had DS (24 males and 8 females, mean age of 19 years, ranging between 14 and 30 yrs.) and 20 typically developing individuals (TD) who were matched by age and gender to the individuals with DS. To examine this issue, we used software that uses 3D images and reproduced a coincidence-timing task. Results: The results showed that all individuals improved performance in the virtual task, but the individuals with DS that started the task with worse performance showed higher difference from the beginning. Besides that, they were able to retain and transfer the performance with increase of speed of the task. Conclusion: Individuals with DS are able to learn movements from virtual tasks, even though the movement time was higher compared to the TD individuals. The results showed that individuals with DS who started with low performance improved coincidence- timing task with virtual objects, but were less accurate than typically developing individuals. Trial registration:ClinicalTrials.govIdentifier: NCT02719600. © 2017 The Author(s).","Down syndrome; Physical therapy modalities; Rehabilitation; User-computer interface; Virtual reality","accuracy; adolescent; adult; age; Article; clinical article; controlled study; Down syndrome; female; gender; human; male; motor learning; movement (physiology); software; task performance; therapy effect; virtual reality; clinical trial; computer interface; computer simulation; Down syndrome; learning; procedures; virtual reality exposure therapy; young adult; Adolescent; Adult; Computer Simulation; Down Syndrome; Female; Humans; Learning; Male; Task Performance and Analysis; User-Computer Interface; Virtual Reality Exposure Therapy; Young Adult",Article,"Final","",Scopus,2-s2.0-85018501272
"Bertrand J., Bhargava A., Madathil K.C., Gramopadhye A., Babu S.V.","55858839700;57194158382;37075253800;7005569103;9039004700;","The effects of presentation method and simulation fidelity on psychomotor education in a bimanual metrology training simulation",2017,"2017 IEEE Symposium on 3D User Interfaces, 3DUI 2017 - Proceedings",,, 7893318,"59","68",,7,"10.1109/3DUI.2017.7893318","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019003187&doi=10.1109%2f3DUI.2017.7893318&partnerID=40&md5=01f06159d13212f502fbea389f779a5b","Clemson University, United States","Bertrand, J., Clemson University, United States; Bhargava, A., Clemson University, United States; Madathil, K.C., Clemson University, United States; Gramopadhye, A., Clemson University, United States; Babu, S.V., Clemson University, United States","In this study, we empirically evaluated the effects of presentation method and simulation fidelity on task performance and psychomotor skills acquisition in an immersive bimanual simulation towards precision metrology education. In a 2 × 2 experiment design, we investigated a large-screen immersive display (LSID) with a head-mounted display (HMD), and the presence versus absence of gravity. Advantages of the HMD include interacting with the simulation in a more natural manner as compared to using a large-screen immersive display due to the similarities between the interactions afforded in the virtual compared to the real-world task. Suspending the laws of physics may have an effect on usability and in turn could affect learning outcomes. Our dependent variables consisted of a pre and post cognition questionnaire, quantitative performance measures, perceived workload and system usefulness, and a psychomotor assessment to measure to what extent transfer of learning took place from the virtual to the real world. Results indicate that the HMD condition was preferable to the immersive display in several metrics while the no-gravity condition resulted in users adopting strategies that were not advantageous for task performance. © 2017 IEEE.","and virtual realities; augmented; H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Artificial","Personnel training; Units of measurement; User interfaces; Virtual reality; augmented; Dependent variables; H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Artificial; Head mounted displays; Large-screen immersive displays; Simulation fidelity; Training simulation; Transfer of learning; Helmet mounted displays",Conference Paper,"Final","",Scopus,2-s2.0-85019003187
"Anglin J., Saldana D., Schmiesing A., Liew S.-L.","57193856710;57194044260;57194041188;36992162200;","Transfer of a skilled motor learning task between virtual and conventional environments",2017,"Proceedings - IEEE Virtual Reality",,, 7892346,"401","402",,10,"10.1109/VR.2017.7892346","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018412711&doi=10.1109%2fVR.2017.7892346&partnerID=40&md5=65da755f34034bf37533b59e030ddbca","University of Southern California, Los Angeles, CA, United States","Anglin, J., University of Southern California, Los Angeles, CA, United States; Saldana, D., University of Southern California, Los Angeles, CA, United States; Schmiesing, A., University of Southern California, Los Angeles, CA, United States; Liew, S.-L., University of Southern California, Los Angeles, CA, United States","Immersive, head-mounted virtual reality (HMD-VR) can be a potentially useful tool for motor rehabilitation. However, it is unclear whether the motor skills learned in HMD-VR transfer to the non-virtual world and vice-versa. Here we used a well-established test of skilled motor learning, the Sequential Visual Isometric Pinch Task (SVIPT), to train individuals in either an HMD-VR or conventional training (CT) environment. Participants were then tested in both environments. Our results show that participants who train in the CT environment have an improvement in motor performance when they transfer to the HMD-VR environment. In contrast, participants who train in the HMD-VR environment show a decrease in skill level when transferring to the CT environment. This has implications for how training in HMD-VR and CT may affect performance in different environments. © 2017 IEEE.","Skilled motor learning; Transfer; Virtual reality","E-learning; Helmet mounted displays; Virtual reality; Head mounted virtual reality; Motor learning; Motor performance; Motor rehabilitation; Motor skills; Skill levels; Transfer; Virtual worlds; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-85018412711
"Ng A.K.T.","57190281471;","Cognitive psychology and human factors engineering of virtual reality",2017,"Proceedings - IEEE Virtual Reality",,, 7892349,"407","408",,1,"10.1109/VR.2017.7892349","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018458440&doi=10.1109%2fVR.2017.7892349&partnerID=40&md5=21c24a780861ae214df7983eca402d37","University of Hong Kong, Hong Kong, Hong Kong","Ng, A.K.T., University of Hong Kong, Hong Kong, Hong Kong","This position paper summarizes the author's research interest in Cognitive Psychology and Human-Computer Interaction in the imseCAVE, a CAVE-like system in the University of Hong Kong. Several areas of interest were explored while finding the thesis topic for the Ph.D. research. They include a perception research on distance estimation with proposed error correction mechanism, neurofeedback meditation with EEG in VR and the effect with audio and video, the study of training transfer in VR training, the comparison and research of cybersickness between HMD and the imseCAVE, and comparing VR gaming in TV, HMD, and the imseCAVE by performance, activity level and time perception. With a broad interest, the exact direction is still in the search and requires future exploration. © 2017 IEEE.","Cognitive psychology; HCI; Virtual environment","Error correction; Human computer interaction; Human engineering; Psychophysiology; Activity levels; Audio and video; Cognitive psychology; Correction mechanism; Distance estimation; Position papers; Research interests; Time perception; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85018458440
"Xu M., Murcia-Lopez M., Steed A.","57194043735;57194036190;18435050200;","Object location memory error in virtual and real environments",2017,"Proceedings - IEEE Virtual Reality",,, 7892303,"315","316",,9,"10.1109/VR.2017.7892303","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018434814&doi=10.1109%2fVR.2017.7892303&partnerID=40&md5=a93916712582a06b89ab064f03b0fe94","University College London, United Kingdom","Xu, M., University College London, United Kingdom; Murcia-Lopez, M., University College London, United Kingdom; Steed, A., University College London, United Kingdom","We aim to further explore the transfer of spatial knowledge from virtual to real spaces. Based on previous research on spatial memory in immersive virtual reality (VR) we ran a study that looked at the effect of three locomotion techniques (joystick, pointing-and-teleporting and walking-in-place) on object location learning and recall. Participants were asked to learn the location of a virtual object in a virtual environment (VE). After a short period of time they were asked to recall the location by placing a real version of the object in the real-world equivalent environment. Results indicate that the average placement error, or distance between original and recalled object location, is approximately 20cm for all locomotion technique conditions. This result is similar to the outcome of a previous study on spatial memory in VEs that used real walking. We report this unexpected finding and suggest further work on spatial memory in VR by recommending the replication of this study in different environments and using objects with a wider diversity of properties, including varying sizes and shapes. © 2017 IEEE.","Augmented; H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Artificial; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism - Virtual Reality; Virtual Realities","Computer graphics; Three dimensional computer graphics; Virtual reality; Augmented; H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Artificial; I.3.7 [computer graphics]: three-dimensional graphics and realism - virtual realities; Immersive virtual reality; Locomotion technique; Real environments; Spatial knowledge; Walking-in-place; Location",Conference Paper,"Final","",Scopus,2-s2.0-85018434814
"Kron F.W., Fetters M.D., Scerbo M.W., White C.B., Lypson M.L., Padilla M.A., Gliva-McConvey G.A., Belfore L.A., II, West T., Wallace A.M., Guetterman T.C., Schleicher L.S., Kennedy R.A., Mangrulkar R.S., Cleary J.F., Marsella S.C., Becker D.M.","6507996266;7004019124;7004570474;7404153169;7801547132;57204399859;6507367882;6701466625;57192807346;54581868300;56652174000;57192804112;55426202400;6603310114;35304582500;6603739353;7401884246;","Using a computer simulation for teaching communication skills: A blinded multisite mixed methods randomized controlled trial",2017,"Patient Education and Counseling","100","4",,"748","759",,38,"10.1016/j.pec.2016.10.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008205645&doi=10.1016%2fj.pec.2016.10.024&partnerID=40&md5=710665b12ba082123fd3497a2090b92c","Department of Family Medicine, University of Michigan, Ann Arbor, MI  48104, United States; Department of Psychology, Old Dominion University, Norfolk, VA  23529, United States; Department of Medical Education, University of Virginia School of Medicine, Charlottesville, VA  22908, United States; Department of Internal Medicine, Department of Learning Health Sciences, University of Michigan Medical School, Ann Arbor, MI  48104, United States; Sentara Center for Simulation and Immersive Learning, Eastern Virginia Medical School, Norfolk, VA  23501, United States; Department of Electrical and Computer Engineering, Old Dominion University, Norfolk, VA  23529, United States; Department of Medicine, School of Medicine and Public Health, University of Wisconsin-MadisonWI  53706, United States; Department of Computer Science, Department of Psychology, Northeastern University, Boston, MA  02115, United States; Department of Medicine, University of Virginia Health System, Charlottesville, VA  22908, United States","Kron, F.W., Department of Family Medicine, University of Michigan, Ann Arbor, MI  48104, United States; Fetters, M.D., Department of Family Medicine, University of Michigan, Ann Arbor, MI  48104, United States; Scerbo, M.W., Department of Psychology, Old Dominion University, Norfolk, VA  23529, United States; White, C.B., Department of Medical Education, University of Virginia School of Medicine, Charlottesville, VA  22908, United States; Lypson, M.L., Department of Internal Medicine, Department of Learning Health Sciences, University of Michigan Medical School, Ann Arbor, MI  48104, United States; Padilla, M.A., Department of Psychology, Old Dominion University, Norfolk, VA  23529, United States; Gliva-McConvey, G.A., Sentara Center for Simulation and Immersive Learning, Eastern Virginia Medical School, Norfolk, VA  23501, United States; Belfore, L.A., II, Department of Electrical and Computer Engineering, Old Dominion University, Norfolk, VA  23529, United States; West, T., Sentara Center for Simulation and Immersive Learning, Eastern Virginia Medical School, Norfolk, VA  23501, United States; Wallace, A.M., Sentara Center for Simulation and Immersive Learning, Eastern Virginia Medical School, Norfolk, VA  23501, United States; Guetterman, T.C., Department of Family Medicine, University of Michigan, Ann Arbor, MI  48104, United States; Schleicher, L.S., Department of Family Medicine, University of Michigan, Ann Arbor, MI  48104, United States; Kennedy, R.A., Department of Psychology, Old Dominion University, Norfolk, VA  23529, United States; Mangrulkar, R.S., Department of Internal Medicine, Department of Learning Health Sciences, University of Michigan Medical School, Ann Arbor, MI  48104, United States; Cleary, J.F., Department of Medicine, School of Medicine and Public Health, University of Wisconsin-MadisonWI  53706, United States; Marsella, S.C., Department of Computer Science, Department of Psychology, Northeastern University, Boston, MA  02115, United States; Becker, D.M., Department of Medicine, University of Virginia Health System, Charlottesville, VA  22908, United States","Objectives To assess advanced communication skills among second-year medical students exposed either to a computer simulation (MPathic-VR) featuring virtual humans, or to a multimedia computer-based learning module, and to understand each group's experiences and learning preferences. Methods A single-blinded, mixed methods, randomized, multisite trial compared MPathic-VR (N = 210) to computer-based learning (N = 211). Primary outcomes: communication scores during repeat interactions with MPathic-VR's intercultural and interprofessional communication scenarios and scores on a subsequent advanced communication skills objective structured clinical examination (OSCE). Multivariate analysis of variance was used to compare outcomes. Secondary outcomes: student attitude surveys and qualitative assessments of their experiences with MPathic-VR or computer-based learning. Results MPathic-VR-trained students improved their intercultural and interprofessional communication performance between their first and second interactions with each scenario. They also achieved significantly higher composite scores on the OSCE than computer-based learning-trained students. Attitudes and experiences were more positive among students trained with MPathic-VR, who valued its providing immediate feedback, teaching nonverbal communication skills, and preparing them for emotion-charged patient encounters. Conclusions MPathic-VR was effective in training advanced communication skills and in enabling knowledge transfer into a more realistic clinical situation. Practice implications MPathic-VR's virtual human simulation offers an effective and engaging means of advanced communication training. © 2016 Elsevier Ireland Ltd","Breaking bad news; Communication training; Computer simulation; Computer-based conversational agent; Cultural competence; Doctor-patient relationship; Healthcare communication; Human-computer interaction; Intelligent tutoring systems; Inter-professional communication; Intercultural communication; Knowledge transfer; Mindful practice; Mixed methods research; Nonverbal communication; Reflection in action; Reflection on action; Simulation; Training transfer; Virtual Human","adult; Article; clinical examination; communication skill; computer simulation; computer system; controlled study; emotion; female; human; male; medical student; Modeling Professionalism and Teaching Humanistic Communication in Virtual Reality; nonverbal communication; objective structured clinical examination; randomized controlled trial; single blind procedure; student attitude; clinical competence; computer interface; computer simulation; curriculum; doctor patient relation; interpersonal communication; medical education; patient simulation; psychology; Adult; Clinical Competence; Communication; Computer Simulation; Curriculum; Education, Medical; Female; Humans; Male; Patient Simulation; Physician-Patient Relations; Single-Blind Method; Students, Medical; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-85008205645
"Booth R.G., Scerbo C.K., Sinclair B., Hancock M., Reid D., Denomy E.","13410954600;57193060960;7103124839;56331834000;57194381277;6506719925;","Exploring learning content and knowledge transfer in baccalaureate nursing students using a hybrid mental health practice experience",2017,"Nurse Education Today","51",,,"57","62",,5,"10.1016/j.nedt.2017.01.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010465129&doi=10.1016%2fj.nedt.2017.01.006&partnerID=40&md5=0b82763166cd713abd129f2435686dd1","Arthur Labatt Family School of Nursing, Western University, London, Canada; Mackenzie Health, Richmond Hill, Canada","Booth, R.G., Arthur Labatt Family School of Nursing, Western University, London, Canada; Scerbo, C.K., Mackenzie Health, Richmond Hill, Canada; Sinclair, B., Arthur Labatt Family School of Nursing, Western University, London, Canada; Hancock, M., Arthur Labatt Family School of Nursing, Western University, London, Canada; Reid, D., Arthur Labatt Family School of Nursing, Western University, London, Canada; Denomy, E., Arthur Labatt Family School of Nursing, Western University, London, Canada","Background Little research has been completed exploring knowledge development and transfer from and between simulated and clinical practice settings in nurse education. Objectives This study sought to explore the content learned, and the knowledge transferred, in a hybrid mental health clinical course consisting of simulated and clinical setting experiences. Design A qualitative, interpretive descriptive study design. Settings Clinical practice consisted of six 10-hour shifts in a clinical setting combined with six two-hour simulations. Participants 12 baccalaureate nursing students enrolled in a compressed time frame program at a large, urban, Canadian university participated. Methods Document analysis and a focus group were used to draw thematic representations of content and knowledge transfer between clinical environments (i.e., simulated and clinical settings) using the constant comparative data analysis technique. Results Four major themes arose: (a) professional nursing behaviors; (b) understanding of the mental health nursing role; (c) confidence gained in interview skills; and, (d) unexpected learning. Conclusions Nurse educators should further explore the intermingling of simulation and clinical practice in terms of knowledge development and transfer with the goal of preparing students to function within the mental health nursing specialty. © 2017 Elsevier Ltd","Clinical simulation; Hybrid learning experience; Knowledge transfer; Mental health; Reciprocal learning; Simulation","baccalaureate nursing student; clinical article; clinical practice; data analysis; doctor patient relation; human; interview; learning; nurse; psychiatric nursing; simulation; skill; study design; university; attitude to health; Canada; clinical competence; education; mental health; nursing education; nursing student; psychology; qualitative research; simulation training; Canada; Clinical Competence; Education, Nursing, Baccalaureate; Health Knowledge, Attitudes, Practice; Humans; Learning; Mental Health; Nursing Education Research; Qualitative Research; Simulation Training; Students, Nursing",Article,"Final","",Scopus,2-s2.0-85010465129
"Musbahi O., Aydin A., Al Omran Y., Skilbeck C.J., Ahmed K.","56928322400;55976433600;56114181100;16029608400;15764669400;","Current Status of Simulation in Otolaryngology: A Systematic Review",2017,"Journal of Surgical Education","74","2",,"203","215",,54,"10.1016/j.jsurg.2016.09.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006293395&doi=10.1016%2fj.jsurg.2016.09.007&partnerID=40&md5=074611704a4086042fa43d2f835ca294","Barts and The London School of Medicine and Dentistry, Queen Mary University of London, United Kingdom; MRC Center for Transplantation, Guy's Hospital, King's College London, London, United Kingdom; Department of Oncology, Royal Berkshire NHS Foundation Trust, United Kingdom; Department of ENT and Head and Neck Surgery, Guy's Hospital, Guy's & St Thomas’ NHS Foundation Trust, London, United Kingdom","Musbahi, O., Barts and The London School of Medicine and Dentistry, Queen Mary University of London, United Kingdom; Aydin, A., MRC Center for Transplantation, Guy's Hospital, King's College London, London, United Kingdom; Al Omran, Y., Department of Oncology, Royal Berkshire NHS Foundation Trust, United Kingdom; Skilbeck, C.J., Department of ENT and Head and Neck Surgery, Guy's Hospital, Guy's & St Thomas’ NHS Foundation Trust, London, United Kingdom; Ahmed, K., MRC Center for Transplantation, Guy's Hospital, King's College London, London, United Kingdom","Objective Otolaryngology is a highly technical and demanding specialty and the requirements for surgical trainees to acquire proficiency remains challenging. Simulation has been purported to be an effective tool in assisting with this. The aim of this systematic review is to identify the available otolaryngology simulators, their status of validation, and evaluation the level of evidence behind each training model and thereby establish a level of recommendation. Design PubMed, ERIC, and Google Scholar databases were searched for articles that described otolaryngology simulators or training models between 1980 and April 2016. Any validation studies for simulators were also retrieved. Titles and abstracts were screened for relevance using the preferred reporting items for systematic reviews and meta-analysis (PRISMA) guidelines. Level of evidence (LoE) and Level of recommendation (LoR) was awarded to each study and model, respectively. Results A total of 70 studies were identified describing 64 simulators. Out of these, at least 54 simulators had 1 validation study. Simulators for the ear and temporal bone surgery were the most common (n = 32), followed by laryngeal and throat (n = 20) and endoscopic sinus surgery (n = 12). Face validity was evaluated by 29 studies, 20 attempted to show construct, 20 assessed content, 20 transfer, and only 2 assessed concurrent validity. Of the validation assessments, 2 were classified as Level 1b, 10 Level 2a, and 48 Level 2b. No simulators received the highest LoR, but 8 simulators received a LoR of 2. Conclusions Despite the lack of evidence in outcome studies and limited number of high-validity otolaryngology simulators, the role of simulation continues to grow across surgical specialties Hence, it is imperative that the simulators are of high validity and construct for trainees to practice and rehearse surgical skills to develop confidence. © 2017 Association of Program Directors in Surgery","ENT; Interpersonal and Communication Skills; otolaryngology; Patient Care; Practice-Based Learning and Improvement; simulation; systematic review; training; validation","Article; clinical evaluation; concurrent validity; endoscopic sinus surgery; evidence based practice; face validity; human; larynx surgery; mastoidectomy; Medline; meta analysis (topic); middle ear surgery; myringotomy; nonhuman; otorhinolaryngology; outcome assessment; practice guideline; priority journal; simulation training; skill; systematic review; throat surgery; tympanostomy tube; validation study; clinical competence; computer simulation; education; female; male; medical education; otorhinolaryngology; procedures; reproducibility; simulation training; United Kingdom; Clinical Competence; Computer Simulation; Education, Medical, Graduate; Female; Humans; Internship and Residency; Male; Otolaryngology; Reproducibility of Results; Simulation Training; United Kingdom",Article,"Final","",Scopus,2-s2.0-85006293395
"Dong M., Guo R.","57193733822;55211939300;","Towards understanding the capability of spatial audio feedback in virtual environments for people with visual impairments",2017,"2016 IEEE 2nd Workshop on Everyday Virtual Reality, WEVR 2016",,, 7859538,"15","20",,2,"10.1109/WEVR.2016.7859538","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016202855&doi=10.1109%2fWEVR.2016.7859538&partnerID=40&md5=dcc177c18146e2d51b17f8469cf200ab","Kennesaw State University, United States","Dong, M., Kennesaw State University, United States; Guo, R., Kennesaw State University, United States","This research analyzes if and how the Head Related Transfer Function (HRTF) can be used to support effective Human-Computer Interaction when people in a Virtual Environment (VE) without visual feedback. If sounds can be located in a VE by using HRTF only, designing and developing considerably safer but diversified training environments might greatly benefit individuals with visual impairments. To investigate this, we ran 2 usability studies: 1) to ascertain whether the HRTF could provide sufficient position information in VEs; 2) to learn whether the HRTF could provide sufficient distance and direction information in VEs. The results showed that a continuous audio feedback could help navigate in a VE without vision feedback. © 2016 IEEE.","3D Audio; Assistive technology; HRTF; User study","Human computer interaction; Sound reproduction; Transfer functions; Visual communication; 3D audio; Assistive technology; Head related transfer function; HRTF; Position information; Usability studies; User study; Visual impairment; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85016202855
"Alrashidi M., Gardner M., Callaghan V.","56405416200;9840290400;35561000000;","Evaluating the use of pedagogical virtual machine with augmented reality to support learning embedded computing activity",2017,"ACM International Conference Proceeding Series","Part F127852",,,"44","50",,5,"10.1145/3057039.3057088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020897950&doi=10.1145%2f3057039.3057088&partnerID=40&md5=1972383f936d31a50cf8e2cd069e1e9a","School of Computer Science and Electronic Engineering, University of Essex, Colchester, United Kingdom","Alrashidi, M., School of Computer Science and Electronic Engineering, University of Essex, Colchester, United Kingdom; Gardner, M., School of Computer Science and Electronic Engineering, University of Essex, Colchester, United Kingdom; Callaghan, V., School of Computer Science and Electronic Engineering, University of Essex, Colchester, United Kingdom","Embedded computing is often considered as a hidden technology where learners can require more assistance to inspect processes and activities hidden within the technologies, making use of debugging, monitoring, and visual tools. To the student, this kind of technology often has abstract behaviours where the only information/things people can see is the final action, and they do not know how the internal processes work and communicate inside the embedded computing device to achieve the desired result. Augmented reality (AR) can overcome this issue and produce a magic-lens view for revealing hidden embedded computing activities. This can result in learners achieving a better level of knowledge and awareness of the technology, as well as higher learning outcomes. AR on its own will not improve the learning processes without first considering how to manage and represent the hidden information. Therefore, a pedagogical virtual machine (PVM) model was employed, and to evaluate the learning effectiveness of the proposed model. We conducted an experiment based on a problem-solving educational mobile robot task. Twenty students participated in the experimental (AR approach) and control (conventional approach) group. The result showed that the augmented reality approach was more effective in increasing students' computational thinking and learning outcomes. In addition, the augmented reality approach reduced both time completion and debugging times. © 2017 ACM.","Augmented reality; Embedded computing; Learning and teaching; Learning object; Mixed reality; Pedagogical virtual machine; Real-time feedback; Robot","Augmented reality; E-learning; Education; Embedded systems; Network security; Problem solving; Program debugging; Robots; Students; Teaching; Technology transfer; Virtual machine; Virtual reality; Embedded computing; Learning and teachings; Learning objects; Mixed reality; Real-time feedback; Engineering education",Conference Paper,"Final","",Scopus,2-s2.0-85020897950
"Lala D., Nishida T.","54784768100;35595754400;","A data-driven passing interaction model for embodied basketball agents",2017,"Journal of Intelligent Information Systems","48","1",,"27","60",,1,"10.1007/s10844-015-0386-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944705860&doi=10.1007%2fs10844-015-0386-z&partnerID=40&md5=709b8dc853b1f0be83ce58f999a5bfbc","Graduate School of Informatics, Kyoto University, Yoshida-Honmachi, Sakyo-ku, Kyoto  606-8501, Japan","Lala, D., Graduate School of Informatics, Kyoto University, Yoshida-Honmachi, Sakyo-ku, Kyoto  606-8501, Japan; Nishida, T., Graduate School of Informatics, Kyoto University, Yoshida-Honmachi, Sakyo-ku, Kyoto  606-8501, Japan","Human beings have an ability to transition smoothly between individual and collaborative activities and to recognize these types of activity in other humans. Our long-term goal is to devise an agent which can function intelligently in an environment with frequent switching between individual and collaborative tasks. A basketball scenario is such an environment, however there currently do not exist suitable interactive agents for this domain. In this paper we take a step towards intelligent basketball agents by contributing a data-driven generalized model of passing interactions. We first collect data on human-human interaction in virtual basketball to discover patterns of behavior surrounding passing interactions. Through these patterns we produce a model of rotation behavior before and after passes are executed. We then implement this model into an actual basketball agent and then conduct an experiment with a human-agent team. Results show that the agent using the model can at least communicate better than a task-competent agent with limited communication, with participants rating the agent as being able to recognize and express its intention. In addition we analyze passing interactions using Herbert Clark’s joint activity theory and propose that the concepts, while completely theoretical, should be considered as a basis for agent design. © 2015, Springer Science+Business Media New York.","Data modeling; Human-agent interaction; Intelligent agents; Joint activity theory","Activity coefficients; Data structures; Intelligent agents; Sports; Virtual reality; Collaborative activities; Collaborative tasks; Frequent switching; Generalized models; Human agent interactions; Human-human interactions; Joint activity; Limited communication; Software agents",Article,"Final","",Scopus,2-s2.0-84944705860
"Crichton M.T.","9845619900;","From cockpit to operating theatre to drilling rig floor: five principles for improving safety using simulator-based exercises to enhance team cognition",2017,"Cognition, Technology and Work","19","1",,"73","84",,14,"10.1007/s10111-016-0396-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994545637&doi=10.1007%2fs10111-016-0396-9&partnerID=40&md5=3504423960ab7e6a9dff8e029e05132c","People Factor Consultants Ltd, Langstane House, 221-229 Union Street, Aberdeen, AB11 6BQ, United Kingdom","Crichton, M.T., People Factor Consultants Ltd, Langstane House, 221-229 Union Street, Aberdeen, AB11 6BQ, United Kingdom","For over 30 years, aviation has conducted training courses to enhance team performance and improve safety involving simulation with observation and directed feedback. Participants’ performance is observed by trained and experienced observers who then provide feedback using behaviour-based evidence noted during the simulator exercise. More recently, in healthcare, operating theatre personnel have adopted simulator-based training (SBT), observation and feedback for learning and practice to reduce the potential for human errors and improve safety. Maritime and nuclear power also incorporate high-fidelity simulators and feedback in team training interventions including technical and non-technical skills. The design and development of drilling rig simulators means that drill crews can now practise and test out their decision-making and receive feedback from observers, with the aim of improving team non-technical skills and consequently reducing the potential for errors. This paper presents five principles gleaned from research and the experiences of both aviation and healthcare to be applied to the development of simulator-based exercising for drilling teams. The principles include: (a) developing learning objectives and expected performance standards; (b) training the team as a whole; (c) using a structured observation tool; (d) providing feedback during a structured debrief; (e) repeat the SBT regularly to enhance expertise and retain performance standards. It is anticipated that these principles can be generalised for simulator-based exercising to benefit team social and cognitive competences in other high-hazard or process industries. © 2016, The Author(s).","Behavioural markers; Crew Resource Management; Non-technical skills; Simulator-based exercises; Team performance; Training","Decision making; Drilling rigs; Health care; Human resource management; Simulators; Behavioural markers; Crew resource managements; Design and Development; High-fidelity simulators; Non-technical skills; Performance standards; Structured observation; Team performance; Personnel training",Article,"Final","",Scopus,2-s2.0-84994545637
"Halabi O., El-Seoud S.A., Aljaam J.M., Alpona H., Al-Hemadi M., Al-Hassan D.","57203219290;6507058670;24528095900;56407207400;57194434607;57194429167;","Design of immersive virtual reality system to improve communication skills in individuals with autism",2017,"International Journal of Emerging Technologies in Learning","12","5",,"50","64",,10,"10.3991/ijet.v12i05.6766","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020066717&doi=10.3991%2fijet.v12i05.6766&partnerID=40&md5=e2208a321c0b786aa1272f0ea478869e","Department of Computer Science and Engineering, Qatar University, P.O. Box 2713, Doha, Qatar; Faculty of Informatics and Computer Science, The British University in Egypt, El Sherouk City, Cairo, Egypt","Halabi, O., Department of Computer Science and Engineering, Qatar University, P.O. Box 2713, Doha, Qatar; El-Seoud, S.A., Faculty of Informatics and Computer Science, The British University in Egypt, El Sherouk City, Cairo, Egypt; Aljaam, J.M., Department of Computer Science and Engineering, Qatar University, P.O. Box 2713, Doha, Qatar; Alpona, H., Department of Computer Science and Engineering, Qatar University, P.O. Box 2713, Doha, Qatar; Al-Hemadi, M., Department of Computer Science and Engineering, Qatar University, P.O. Box 2713, Doha, Qatar; Al-Hassan, D., Department of Computer Science and Engineering, Qatar University, P.O. Box 2713, Doha, Qatar","Individuals with autism spectrum disorder (ASD) regularly experience situations in which they need to give answers but do not know how to respond; for example, questions related to everyday life activities that are asked by strangers. Research geared at utilizing technology to mend social and communication impairments in children with autism is actively underway. Immersive virtual reality (VR) is a relatively recent technology that has the potential of being an effective therapeutic tool for developing various skills in autistic children. This paper presents an interactive scenario-based VR system developed to improve the communications skills of autistic children. The system utilizes speech recognition to provide natural interaction and role-play and turntaking to evaluate and verify the effectiveness of the immersive environment on the social performance of autistic children. In experiments conducted, participants showed more improved performance with a computer augmented virtual environment (CAVE) than with a head mounted display (HMD) or a normal desktop. The results indicate that immersive VR could be more satisfactory and motivational than desktop for children with ASD.","Autism spectrum disorder; Communication skill; Immersion; Social performance; Virtual reality","Diseases; Helmet mounted displays; Speech recognition; Technology transfer; Virtual reality; Autism spectrum disorders; Children with autisms; Communication skills; Head mounted displays; Immersion; Immersive environment; Immersive virtual reality; Social performance; Education",Article,"Final","",Scopus,2-s2.0-85020066717
"Hai N.D., Chaudhary N.K., Peksi S., Ranjan R., He J., Gan W.-S.","57201183624;57201189529;56770063300;55635587900;55968222200;7103165543;","Fast HRFT measurement system with unconstrained head movements for 3D audio in virtual and augmented reality applications",2017,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings","2017-March",,,"6576","6577",,6,"10.1109/ICASSP.2017.8005299","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043706787&doi=10.1109%2fICASSP.2017.8005299&partnerID=40&md5=2e61ea590626739ebb07bbeba7d4c3fd","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Maxim Integrated Products, Inc., Singapore","Hai, N.D., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Chaudhary, N.K., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Peksi, S., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Ranjan, R., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; He, J., Maxim Integrated Products, Inc., Singapore; Gan, W.-S., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","Binaural audio plays an indispensable role in virtual reality (VR) and augmented reality (AR). Binaural audio recreates the sensation of the three dimensional auditory experience using Head- Related Transfer Functions (HRTFs). HRTFs are as unique as our fingerprint. To achieve an immersive audio experience, HRTFs measured from every particular user is required. Nowadays, the conventional methods for HRTF measurements requires a wellcontrolled environment, hardly any movement of the user, and projecting to the user a high level of unpleasant sound in a rather long duration. Such difficulties have greatly limited the use of individually measurement HRTFs and hinder the authenticity of immersive audio. To solve these problems, we proposed a fast and convenient HRTF measurement system that is an order of magnitude faster and more importantly, it does not place any constraints on the user's movement. With the help of a head-Tracker and advanced adaptive signal processing algorithms, this system is able to achieve satisfactory HRTF measurement accuracy. In this demonstration, we will present a fast real-Time HRTF acquisition system and show how the individualized HRTFs improve the audio experience in VR/AR applications. © 2017 IEEE.","Augmented reality (AR); Binauralrendering; Fast and relaxed HRTF acquisition; Virtual reality (VR)","Augmented reality; Bins; Signal processing; Transfer functions; Virtual reality; Acquisition systems; Adaptive signal processing; Binauralrendering; Conventional methods; Fast and relaxed HRTF acquisition; Head related transfer function; Measurement accuracy; Virtual and augmented reality; Sound reproduction",Conference Paper,"Final","",Scopus,2-s2.0-85043706787
"Spicer R.P., Russell S.M., Rosenberg E.S.","25723810300;57190403263;23991764900;","The mixed reality of things: Emerging challenges for human-information interaction",2017,"Proceedings of SPIE - The International Society for Optical Engineering","10207",, 102070A,"","",,4,"10.1117/12.2268004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025639079&doi=10.1117%2f12.2268004&partnerID=40&md5=d839fefcd114f2d66f187a208b9a6873","University of Southern California, United States; U.S. Army Research Lab, United States","Spicer, R.P., University of Southern California, United States; Russell, S.M., U.S. Army Research Lab, United States; Rosenberg, E.S., University of Southern California, United States","Virtual and mixed reality technology has advanced tremendously over the past several years. This nascent medium has the potential to transform how people communicate over distance, train for unfamiliar tasks, operate in challenging environments, and how they visualize, interact, and make decisions based on complex data. At the same time, the marketplace has experienced a proliferation of network-connected devices and generalized sensors that are becoming increasingly accessible and ubiquitous. As the nternet of Things"" expands to encompass a predicted 50 billion connected devices by 2020, the volume and complexity of information generated in pervasive and virtualized environments will continue to grow exponentially. The convergence of these trends demands a theoretically grounded research agenda that can address emerging challenges for human-information interaction (HII). Virtual and mixed reality environments can provide controlled settings where HII phenomena can be observed and measured, new theories developed, and novel algorithms and interaction techniques evaluated. In this paper, we describe the intersection of pervasive computing with virtual and mixed reality, identify current research gaps and opportunities to advance the fundamental understanding of HII, and discuss implications for the design and development of cyber-human systems for both military and civilian use. © 2017 SPIE.","Human-Information Interaction; Mixed Reality; Virtual Reality","Complex networks; Ubiquitous computing; Design and Development; Human-information interaction; Interaction techniques; Mixed reality; Mixed reality technologies; Mixed-reality environment; Novel algorithm; Virtualized environment; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85025639079
"Gilbert K.A.","57195204967;","Investigating the use and design of immersive simulation to improve self-efficacy for aspiring principals",2017,"Journal of Information Technology Education: Innovations in Practice","16","1",,"127","169",,2,"10.28945/3726","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026251032&doi=10.28945%2f3726&partnerID=40&md5=4a6ea259d7cabedc8f81be6143e3afb1","Department of Teaching and Leading, Augusta University, Augusta, GA, United States","Gilbert, K.A., Department of Teaching and Leading, Augusta University, Augusta, GA, United States","Aim/Purpose Improving public schools is a focus of federal legislation in the United States with much of the burden placed on principals. However, preparing principals for this task has proven elusive despite many changes in programming by insti-tutions of higher learning. Emerging technologies that rely on augmented and virtual realities are posited to be powerful pedagogical tools for closing this gap. Background This study investigated the effects of immersive simulation technologies on principals' self-efficacy after treatment and the perceived significance of the design of the immersive simulation experience as an effective tool for adult learners. Methodology The investigator employed a multiple-methods study that relied on a purposive sample of graduate students enrolled in educational leadership programs at two small universities in the southeastern United States. Participants completed a two-hour module of immersive simulation designed to facilitate transfer of knowledge to skills thereby increasing their self-efficacy. Contribution This paper contributes to a small body of literature that examines the use of immersive simulation to prepare aspiring principals. Findings The findings indicate moderate effect sizes in changes in self-efficacy, positive attitudes toward immersive simulation as a pedagogical tool, and significance in the design of immersive simulation modules. This suggests that immersive sim-ulation, when properly designed, aids principals in taking action to improve schools. Recommendations for Practitioners Educational leadership programs might consider the use of immersive simula-tions to enhance principals' ability to meet the complex demands of leading in the 21st century. Impact on Society Principals may be more adept at improving schools if preparation programs provided consistent opportunities to engage in immersive simulations.Future Research Future research should be conducted with larger sample sizes and longitudinally to determine the effectiveness of this treatment.","Action re-view cycle; Critical pedagogy; Immersive simulation; Principals; School improvement; Self-efficacy; Situated learning","Knowledge management; Virtual reality; Action re-view cycle; Critical pedagogies; Immersive; Principals; School improvement; Self efficacy; Situated learning; Students",Article,"Final","",Scopus,2-s2.0-85026251032
"Zhou P., Morales U., Wang X., Yang X.","57192267604;55287597300;8661390100;35774975600;","Integration of virtual reality and CFD techniques for thermal fluid education",2017,"ASME 2017 Heat Transfer Summer Conference, HT 2017","1",,,"","",,2,"10.1115/HT2017-4793","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032990661&doi=10.1115%2fHT2017-4793&partnerID=40&md5=08fa8544029bbc7898b56c03ac73a359","Mechanical Engineering Department, Purdue University Northwest, Hammond, IN, United States; Electrical and Computer Engineering Department, Purdue University Northwest, Hammond, IN, United States","Zhou, P., Mechanical Engineering Department, Purdue University Northwest, Hammond, IN, United States; Morales, U., Electrical and Computer Engineering Department, Purdue University Northwest, Hammond, IN, United States; Wang, X., Mechanical Engineering Department, Purdue University Northwest, Hammond, IN, United States; Yang, X., Electrical and Computer Engineering Department, Purdue University Northwest, Hammond, IN, United States","Engineering courses such as thermodynamics, fluid mechanics and heat transfer always involve many abstract math, physics concepts and equations-which are difficult to teach and understand. As fundamental courses in engineering programs, they are sometimes taught in big class size-where students may not receive adequate attention and assistance from instructors. To improve the teaching and learning efficiency, we proposed to develop virtual reality based interactive modules for learning computational fluid dynamics. In this paper, case-study learning module is demonstrated for conduction heat transfer. The programming languages of C# and Unity3D were used for the software development. Computational fluid dynamics simulation results obtained from ANSYS/FLUENT were incorporated in the program. The program has the integrated modules of mobility, interactivity, and controllability for the 3D modeling and simulations. Each module was developed separately for facilitating the program management, extension, and upgrades in the future. The developed interactive programs, incorporating rich, interactive, and engaging learning contexts, will help students gain and apply knowledge to solve real-world problems in mechanical engineering. Copyright © 2017 ASME.",,"Computational fluid dynamics; Curricula; E-learning; Education; Electronic equipment; Fluid dynamics; Fluid mechanics; Gas turbines; Heat conduction; Oscillators (electronic); Software design; Students; Teaching; Thermodynamics; Virtual reality; Computational fluid dynamics simulations; Engineering course; Engineering program; Integrated module; Interactive programs; Program management; Real-world problem; Teaching and learning; Heat transfer",Conference Paper,"Final","",Scopus,2-s2.0-85032990661
"Zipp S.A., Krause T., Craig S.D.","57188634623;57200820571;7201656711;","The impact of user biases toward a virtual human's skin tone on triage errors within a virtual world for emergency management training",2017,"Proceedings of the Human Factors and Ergonomics Society","2017-October",,,"2057","2061",,1,"10.1177/1541931213601998","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042474103&doi=10.1177%2f1541931213601998&partnerID=40&md5=7e250c8fa5273cbdaea756d3f0e5fb69","Human Systems Engineering, Arizona State University, United States","Zipp, S.A., Human Systems Engineering, Arizona State University, United States; Krause, T., Human Systems Engineering, Arizona State University, United States; Craig, S.D., Human Systems Engineering, Arizona State University, United States","Biases influence the decisions people make in everyday life, even if they are unaware of it. This behavior transfers into social interactions in virtual environments. These systems are becoming an increasingly common platform for training, so it is critical to understand how biases will impact them. The present study investigates the effect of the ethnicity bias on error behaviors within a virtual world for medical triage training. Two between subjects variables, participant skin tone (light, dark) and avatar skin tone (light, dark), and one within subjects variable, agent/patient skin tone (light, dark), were manipulated to create a 2 × 2 × 2 mixed design with four conditions. Effects on errors were observed on errors made while helping patient (agents). Participants made considerably more errors while triaging dark-skinned agents which increased the amount of time spent on them, in comparison to light-skinned agents. Within a virtual world for training, people apply general ethnic biases against dark-skinned individuals, which is important to consider when designing such systems because the biases could impact the effectiveness of the training. Copyright 2017 by Human Factors and Ergonomics Society.","Emergency response training; Ethnicity bias; Virtual humans; Virtual worlds","E-learning; Ergonomics; Errors; Human engineering; Interactive computer graphics; Risk management; Common platform; Emergency management; Emergency response; Ethnicity bias; Social interactions; Time spent; Virtual humans; Virtual worlds; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85042474103
"Fechter M., Wartzack S.","57115088300;6506007420;","Natural finger interaction for cad assembly modeling",2017,"Proceedings of the ASME Design Engineering Technical Conference","1",, 67555,"","",,2,"10.1115/DETC2017-67555","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034773383&doi=10.1115%2fDETC2017-67555&partnerID=40&md5=72d41fefc5239e3e102d2bdfca44f30d","Department of Mechanical Engineering, Friedrich-Alexander-University Erlangen-Nuremberg, Erlangen, Germany","Fechter, M., Department of Mechanical Engineering, Friedrich-Alexander-University Erlangen-Nuremberg, Erlangen, Germany; Wartzack, S., Department of Mechanical Engineering, Friedrich-Alexander-University Erlangen-Nuremberg, Erlangen, Germany","In current CAD software the process of assembly modeling is hindered by a large number of separate rotation and translation actions necessary, especially in case of larger assemblies. Additionally matching faces, edges or points must be selected by clicking to define the appropriate constraint. In contrast to that, the process of assembling two normal sized physical parts in the real world seems to be rather simple. That is because we know how to grasp and move objects with our hands intuitively from our everyday experience. The idea behind this contribution is to enable the product developer to assemble CAD parts in a virtual environment through natural finger interaction like in reality. Therefore we present an overall method that combines the natural finger interaction with virtual objects and the insertion of constraints between rotationally symmetric CAD parts. The developed algorithms identify matching surfaces on the basis of the geometry as well as position and orientation of the parts in 3D space. This paper highlights the method to use a combination of real-Time physics simulation and a heuristic approach to achieve an intuitive interaction interface. Additionally, we describe the detection algorithms developed to find assembly relationships between rotationally symmetric CAD parts without prior constraint definition. We also present a prototype system to demonstrate the functionality of the overall method. Furthermore, challenges for future research, such as extending the functionality of the detection algorithms on additional part types, like non-rotationally symmetric shapes, are discussed. Draft Video: https://vimeo.com/203437638. © 2017 ASME.","Assembly modeling; Computer-Aided design; Natural user interface; Virtual reality","Geometry; Heuristic methods; Signal detection; Technology transfer; User interfaces; Virtual reality; Assembly model; Detection algorithm; Finger interactions; Heuristic approach; Intuitive interaction; Natural user interfaces; Position and orientations; Product developers; Computer aided design",Conference Paper,"Final","",Scopus,2-s2.0-85034773383
"Pundlik S., Yi H., Liu R., Peli E., Luo G.","8728311600;57193212126;57193214918;7005237694;36499782000;","Magnifying smartphone screen using google glass for low-vision Users",2017,"IEEE Transactions on Neural Systems and Rehabilitation Engineering","25","1", 7439852,"49","58",,7,"10.1109/TNSRE.2016.2546062","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011664764&doi=10.1109%2fTNSRE.2016.2546062&partnerID=40&md5=e2f14ea3908eeb8f7782abb76b22ef69","Schepens Eye Research Institute, Mass Eye and Ear, Harvard Medical School, Boston, MA  02114, United States; Computer Science Department, Northeastern University, Boston, MA  77005, United States","Pundlik, S., Schepens Eye Research Institute, Mass Eye and Ear, Harvard Medical School, Boston, MA  02114, United States; Yi, H., Computer Science Department, Northeastern University, Boston, MA  77005, United States; Liu, R., Schepens Eye Research Institute, Mass Eye and Ear, Harvard Medical School, Boston, MA  02114, United States; Peli, E., Schepens Eye Research Institute, Mass Eye and Ear, Harvard Medical School, Boston, MA  02114, United States; Luo, G., Schepens Eye Research Institute, Mass Eye and Ear, Harvard Medical School, Boston, MA  02114, United States","Magnification is a key accessibility feature used by low-vision smartphone users. However, small screen size can lead to loss of context and make interaction with magnified displays challenging. We hypothesize that controlling the viewport with head motion can be natural and help in gaining access to magnified displays. We implement this idea using a Google Glass that displays the magnified smartphone screenshots received in real time via Bluetooth. Instead of navigating with touch gestures on the magnified smartphone display, the users can view different screen locations by rotating their head, and remotely interacting with the smartphone. It is equivalent to looking at a large virtual image through a head contingent viewing port, in this case, the Glass display with ∼ 15° field of view. The system can transfer seven screenshots per second at 8× magnification, sufficient for tasks where the display content does not change rapidly. A pilot evaluation of this approach was conducted with eight normally sighted and four visually impaired subjects performing assigned tasks using calculator and music player apps. Results showed that performance in the calculation task was faster with the Glass than with the phone's built-in screen zoom. We conclude that head contingent scanning control can be beneficial in navigating magnified small smartphone displays, at least for tasks involving familiar content layout. © 2001-2011 IEEE.","Google Glass; low-vision aid; screen magnification; smartphone app","Glass; Smartphones; Touch screens; Wearable computers; Field of views; Gaining access; Head motion; Low vision; Music players; Small screens; Virtual images; Visually impaired; Signal encoding; Article; client server application; clinical trial (topic); human; image display; information processing; low vision; low vision magnifier; macular degeneration; mobile application; smartphone; visual acuity; visual orientation; adult; aged; case report; computer assisted diagnosis; computer interface; computer terminal; device failure analysis; devices; equipment design; female; image enhancement; male; middle aged; procedures; reproducibility; sensitivity and specificity; treatment outcome; Vision, Low; Adult; Aged; Computer Terminals; Data Display; Equipment Design; Equipment Failure Analysis; Female; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Male; Middle Aged; Reproducibility of Results; Sensitivity and Specificity; Smartphone; Treatment Outcome; User-Computer Interface; Vision, Low",Article,"Final","",Scopus,2-s2.0-85011664764
"Metcalfe J.S., Marathe A.R., Haynes B., Paul V.J., Gremillion G.M., Drnec K., Atwater C., Estepp J.R., Lukos J.R., Carter E.C., Nothwang W.D.","7202136535;23018952300;57191544347;51564457800;33367661400;57190183747;57191544604;23389315100;12770538000;54787468100;6507700570;","Building a framework to manage trust in automation",2017,"Proceedings of SPIE - The International Society for Optical Engineering","10194",, 101941U,"","",,12,"10.1117/12.2264245","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024402214&doi=10.1117%2f12.2264245&partnerID=40&md5=9dd4db3f0d79227fa4a70e9d7d8131b0","U.S. ARL' HRED, 459 Mulberry Point Rd., Aberdeen Proving Ground, MD  21005, United States; U.S. Army TARDEC, 6305 E. 11 Mile Rd., Warren, MI  48092, United States; U.S. ARL-SEDD, 2800 Powder Mill Rd, Adelphi, MD  20783, United States; DCS Corporation, 7400 Miller Dr., Warren, MI  48092, United States; U.S. AFRL, 1864 4th St., Wright-Patterson AFB, OH  45433, United States; U.S. Navy SPAWAR, 53560 Hull St., San Diego, CA  92152, United States","Metcalfe, J.S., U.S. ARL' HRED, 459 Mulberry Point Rd., Aberdeen Proving Ground, MD  21005, United States; Marathe, A.R., U.S. ARL' HRED, 459 Mulberry Point Rd., Aberdeen Proving Ground, MD  21005, United States; Haynes, B., U.S. Army TARDEC, 6305 E. 11 Mile Rd., Warren, MI  48092, United States; Paul, V.J., U.S. Army TARDEC, 6305 E. 11 Mile Rd., Warren, MI  48092, United States; Gremillion, G.M., U.S. ARL' HRED, 459 Mulberry Point Rd., Aberdeen Proving Ground, MD  21005, United States, U.S. ARL-SEDD, 2800 Powder Mill Rd, Adelphi, MD  20783, United States; Drnec, K., U.S. ARL' HRED, 459 Mulberry Point Rd., Aberdeen Proving Ground, MD  21005, United States; Atwater, C., U.S. Army TARDEC, 6305 E. 11 Mile Rd., Warren, MI  48092, United States, DCS Corporation, 7400 Miller Dr., Warren, MI  48092, United States; Estepp, J.R., U.S. AFRL, 1864 4th St., Wright-Patterson AFB, OH  45433, United States; Lukos, J.R., U.S. Navy SPAWAR, 53560 Hull St., San Diego, CA  92152, United States; Carter, E.C., U.S. ARL' HRED, 459 Mulberry Point Rd., Aberdeen Proving Ground, MD  21005, United States; Nothwang, W.D., U.S. ARL-SEDD, 2800 Powder Mill Rd, Adelphi, MD  20783, United States","All automations must, at some point in their lifecycle, interface with one or more humans. Whether operators, end-users, or bystanders, human responses can determine the perceived utility and acceptance of an automation. It has been long believed that human trust is a primary determinant of human-automation interactions and further presumed that calibrating trust can lead to appropriate choices regarding automation use. However, attempts to improve joint system performance by calibrating trust have not yet provided a generalizable solution. To address this, we identified several factors limiting the direct integration of trust, or metrics thereof, into an active mitigation strategy. The present paper outlines our approach to addressing this important issue, its conceptual underpinnings, and practical challenges encountered in execution. Among the most critical outcomes has been a shift in focus from trust to basic interaction behaviors and their antecedent decisions. This change in focus inspired the development of a testbed and paradigm that was deployed in two experiments of human interactions with driving automation that were executed in an immersive, full-motion simulation environment. Moreover, by integrating a behavior and physiology-based predictor within a novel consequence-based control system, we demonstrated that it is possible to anticipate particular interaction behaviors and influence humans towards more optimal choices about automation use in real time. Importantly, this research provides a fertile foundation for the development and integration of advanced, wearable technologies for sensing and inferring critical state variables for better integration of human elements into otherwise fully autonomous systems. © 2017 SPIE.","Human-Automation Interaction; Trust in Automation; Decision-Making; Consequence-Based Control; Motion-Based Simulation; EEG; Psychophysiology; Privileged Sensing Framework","Critical current density (superconductivity); Integration; Man machine systems; Nanotechnology; Physiology; Wearable technology; Autonomous systems; Direct integration; Human interactions; Human-automation interactions; Interaction behavior; Mitigation strategy; Motion simulations; Perceived utility; Automation",Conference Paper,"Final","",Scopus,2-s2.0-85024402214
"Yu J., Park J.","56131024300;57192642325;","Real-time facial tracking in virtual reality",2016,"SA 2016 - SIGGRAPH ASIA 2016 VR Showcase",,, a3,"","",,5,"10.1145/2996376.2996390","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006968903&doi=10.1145%2f2996376.2996390&partnerID=40&md5=162a2b3d033461b479bad62831e3db98","BinaryVR. Inc., United States","Yu, J., BinaryVR. Inc., United States; Park, J., BinaryVR. Inc., United States","Virtual reality (VR) emerges as the next social computing platform. For realizing immersive social interactions, projecting facial expressions onto the virtual avatar a crucial component. This is a challenge in VR as it requires capturing the facial motions behind the VR head mounted displays (HMDs). In this paper, we present a real-time facial expression tracking system in VR HMDs. The core of the system is a 3D camera attached to the HMDs, capturing motions on the lower half of the face, which enables users to track and retarget their facial animations in realtime onto CG avatars. The system is capable of capturing 20 facial expression parameters and transfer it onto the 3D character in real-time. © 2016. ACM.","Facial capture; Virtual reality","Cameras; Helmet mounted displays; Interactive computer graphics; Three dimensional computer graphics; Virtual reality; Facial animation; Facial capture; Facial expression parameters; Facial Expressions; Head mounted displays; Social computing; Social interactions; Tracking system; Face recognition",Conference Paper,"Final","",Scopus,2-s2.0-85006968903
"Deep A., Prasad P., Narayana S., Chang M., Murthy S.","56565060100;7202702525;57192574829;24464236600;35275628500;","Game based learning of blood clotting concepts",2016,"Proceedings - IEEE 16th International Conference on Advanced Learning Technologies, ICALT 2016",,, 7757042,"526","530",,,"10.1109/ICALT.2016.70","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006846926&doi=10.1109%2fICALT.2016.70&partnerID=40&md5=5574a56a0509920aee3e6db612cce05c","IDP-Educational Technology, IIT-Bombay, India; School of Computing and Information Systems, Athabasca University, Canada","Deep, A., IDP-Educational Technology, IIT-Bombay, India; Prasad, P., IDP-Educational Technology, IIT-Bombay, India; Narayana, S., IDP-Educational Technology, IIT-Bombay, India; Chang, M., School of Computing and Information Systems, Athabasca University, Canada; Murthy, S., IDP-Educational Technology, IIT-Bombay, India","In this paper we describe the architecture of virtual clot (vCLOT), a virtual world system designed to teach procedural knowledge of blood clotting process, in a game based learning environment. vCLOT utilizes virtual world to give learners an immersive learning experience while actively participating in tasks that require them to apply the procedural knowledge they have learned. Design of vCLOT combines the immersivity of virtual worlds with the power of knowledge structures. Immersivity provides learners with the opportunity to make decisions at every level of the game. This transfers control of interaction to the learner, enabling the learner to be actively engaged in knowledge construction process. Knowledge structures are a neat way to represent domain and learner data. The user interface of vCLOT is designed and implemented with Open Wonderland which is an open-source 3D toolkit. The learning goal which is to learn about blood clotting process, is aligned with the game goal, which is application of blood clot process steps to heal an injury. The game goal is presented as a quest in which the learner interacts with concepts by either dragging them or synthesizing them from other concepts. Learners complete the quest on successful formation of blood clot which in turn implies that they have learnt the blood clot process. We plan to do a usability study to improve the system before starting actual intervention. © 2016 IEEE.","Blood clotting; Game based learning; Open wonderland; Procedural knowledge; Quest","Blood; Computer aided instruction; Interactive computer graphics; User interfaces; Virtual reality; Blood clotting; Game-based Learning; Open wonderland; Procedural knowledge; Quest; Engineering education",Conference Paper,"Final","",Scopus,2-s2.0-85006846926
"Le Moulec G., Argelaguet F., Lécuyer A., Gouranton V.","57192165950;15021985300;6601917415;6506588443;","Take-over control paradigms in collaborative virtual environments for training",2016,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST","02-04-November-2016",,,"65","68",,4,"10.1145/2993369.2993410","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998910064&doi=10.1145%2f2993369.2993410&partnerID=40&md5=9444ca4562b9db97ffb13b3665b8b5d4","INSA de Rennes, IRISA, Inria, France","Le Moulec, G., INSA de Rennes, IRISA, Inria, France; Argelaguet, F., INSA de Rennes, IRISA, Inria, France; Lécuyer, A., INSA de Rennes, IRISA, Inria, France; Gouranton, V., INSA de Rennes, IRISA, Inria, France","The main objective of this paper is to study and formalize the Take-Over Control in Collaborative Virtual Environments for Training (CVET). The Take-Over Control represents the transfer (the take over) of the interaction control of an object between two or more users. This paradigm is particularly useful for training scenarios, in which the interaction control could be continuously exchanged between the trainee and the trainer, e.g. the latter guiding and correcting the trainee's actions. The paper presents the formalization of the Take-Over Control followed by an illustration focusing in a use-case of collaborative maritime navigation. In the presented use-case, the trainee has to avoid an under-water obstacle with the help of a trainer who has additional information about the obstacle. The use-case allows to highlight the different elements a Take-Over Control situation should enforce, such as user's awareness. Different Take-Over Control techniques were provided and evaluated focusing on the transfer exchange mechanism and the visual feedback. The results show that participants preferred the Take-Over Control technique which maximized the user awareness.","Awareness; CVET; Take-Over Control","Virtual reality; Visual communication; Awareness; Collaborative virtual environments for training; Control techniques; CVET; Exchange mechanism; Interaction controls; Maritime navigation; Training scenario; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-84998910064
"Nosek M.A., Robinson-Whelen S., Hughes R.B., Nosek T.M.","7007061473;6602746261;7404305965;7003843987;","An internet-based virtual reality intervention for enhancing self-esteem in women with disabilities: Results of a feasibility study",2016,"Rehabilitation Psychology","61","4",,"358","370",,11,"10.1037/rep0000107","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990853361&doi=10.1037%2frep0000107&partnerID=40&md5=202639022de74918fafe7d7b01609c4e","Department of Physical Medicine and Rehabilitation, Baylor College of Medicine, United States; Department of Psychology, University of Montana, Missoula, United States; Department of Physiology and Biophysics, Case Western Reserve University, United States","Nosek, M.A., Department of Physical Medicine and Rehabilitation, Baylor College of Medicine, United States; Robinson-Whelen, S., Department of Physical Medicine and Rehabilitation, Baylor College of Medicine, United States; Hughes, R.B., Department of Psychology, University of Montana, Missoula, United States; Nosek, T.M., Department of Physiology and Biophysics, Case Western Reserve University, United States","Purpose: To examine the feasibility of an online self-esteem enhancement group program for women with disabilities. Method: A sample of 19 racially and ethnically diverse, community-living women with physical disabilities, 22 to 61 years old, participated in a 7-session interactive group intervention (extending Hughes et al., 2004) in the 3-D, immersive, virtual environment of SecondLife.com, using avatars with voice and text communication. Baseline and postintervention questionnaires were administered online. Criteria for determining feasibility were (a) enrollment, (b) engagement, (c) acceptability, and (d) improvement on measures of self-esteem, depression, self-efficacy, and social support. Results: We attained our enrollment goal and engagement exceeded expectations. Acceptability was positive; participants gave ""helpful"" and ""enjoyable"" ratings of 3.21 and 3.27, respectively, (mean on a 1 to 4 Likert scale, where 4 = high) to 5 intervention components-session materials, group sharing and discussion, relaxation exercises, action planning, and group excursions. Significant increases from baseline to postintervention were found on the Rosenberg Self-Esteem Scale (p = .02; Cohen's d = .60) and the Center for Epidemiologic Studies Depression Scale-10 (p = .005; Cohen's d = .74), with a trend toward significance on the Generalized Self-Efficacy Scale (p = .08; Cohen's d = .42). The intervention did not significantly affect the measure of social support. Implications: An intervention to enhance self-esteem may have a corollary benefit on depressive symptomatology. Offering psychoeducational, small group interventions using online virtual worlds shows promise for circumventing disability-related and environmental barriers to accessing mental health services experienced by women with mobility limitations, and should undergo further development and testing. © 2016 American Psychological Association.","Disability; Intervention; Self-esteem; Virtual reality; Women","adult; arthropathy; Article; behavior therapy; Center for Epidemiological Studies Depression Scale; cerebrovascular accident; clinical article; community assessment; computer simulation; connective tissue disease; depression assessment; feasibility study; female; group therapy; health care access; human; Internet; interpersonal communication; mental health service; neuromuscular disease; outcome assessment; physical disability; psychoeducation; psychotherapy; relaxation training; self esteem; social interaction; social support; three dimensional imaging; traumatic brain injury; virtual reality; computer assisted therapy; computer interface; depression; disabled person; group therapy; middle aged; online system; patient satisfaction; psychology; self concept; young adult; Adult; Depression; Disabled Persons; Feasibility Studies; Female; Humans; Internet; Middle Aged; Online Systems; Patient Satisfaction; Psychotherapy, Group; Self Concept; Therapy, Computer-Assisted; User-Computer Interface; Young Adult",Article,"Final","",Scopus,2-s2.0-84990853361
"Haghani M., Sarvi M., Shahhoseini Z., Boltes M.","56581972200;6603291145;56582182500;9233277400;","How simple hypothetical-choice experiments can be utilized to learn humans' navigational escape decisions in emergencies",2016,"PLoS ONE","11","11", e0166908,"","",,25,"10.1371/journal.pone.0166908","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995937663&doi=10.1371%2fjournal.pone.0166908&partnerID=40&md5=7a09596c7098393394a15a6c4184296a","Centre for Disaster Management and Public Safety, School of Engineering, University of Melbourne, Stationary Ln, Parkville, VIC  3052, Australia; Jülich Supercomputing Centre, Forschungszentrum Jülich, Jülich, 52425, Germany","Haghani, M., Centre for Disaster Management and Public Safety, School of Engineering, University of Melbourne, Stationary Ln, Parkville, VIC  3052, Australia; Sarvi, M., Centre for Disaster Management and Public Safety, School of Engineering, University of Melbourne, Stationary Ln, Parkville, VIC  3052, Australia; Shahhoseini, Z., Centre for Disaster Management and Public Safety, School of Engineering, University of Melbourne, Stationary Ln, Parkville, VIC  3052, Australia; Boltes, M., Jülich Supercomputing Centre, Forschungszentrum Jülich, Jülich, 52425, Germany","How humans resolve non-trivial tradeoffs in their navigational choices between the social interactions (e.g., the presence and movements of others) and the physical factors (e.g., spatial distances, route visibility) when escaping from threats in crowded confined spaces? The answer to this question has major implications for the planning of evacuations and the safety of mass gatherings as well as the design of built environments. Due to the challenges of collecting behavioral data from naturally-occurring evacuation settings, laboratory-based virtual-evacuation experiments have been practiced in a number of studies. This class of experiments faces the traditional question of contextual bias and generalizability: How reliably can we infer humans' behavior from decisions made in hypothetical settings? Here, we address these questions by making a novel link between two different forms of empirical observations. We conduct hypothetical emergency exit-choice experiments framed as simple pictures, and then mimic those hypothetical scenarios in more realistic fashions through staging mock evacuation trials with actual crowds. Econometric choice models are estimated based on the observations made in both experimental contexts. The models are contrasted with each other from a number of perspectives including their predictions as well as the sign, magnitude, statistical significance, person-to-person variations (reflecting individuals' perception/preference differences) and the scale (reflecting context-dependent decision randomness) of their inferred parameters. Results reveal a surprising degree of resemblance between the models derived from the two contexts. Most strikingly, they produce fairly similar prediction probabilities whose differences average less than 10%. There is also unexpected consensus between the inferences derived from both experimental sources on many aspects of people's behavior notably in terms of the perception of social interactions. Results show that we could have elicited peoples' escape strategies with fair precision without observing them in action (i.e., simply by using only hypothetical-choice data as an inexpensive, practical and non-invasive experimental technique in this context). As a broader application, this offers promising evidence as to the potential applicability of the hypothetical-decision experiments to other decision contexts (at least for non-financial decisions) when field or real-world data is prohibitively unavailable. As a practical application, the behavioral insights inferred from our observations (reflected in the estimated parameters) can improve how accurately we predict the movement patterns of human crowds in emergency scenarios arisen in complex spaces. Fully-generic-in-parameters, our proposed models can even be directly introduced to a broad range of crowd simulation software to replicate navigation decision making of evacuees. © 2016 Haghani et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"consensus; decision making; emergency; experimental model; human; perception; prediction; probability; social interaction; software; staging; statistical significance; behavioral science; clinical trial; crowding (area); decision making; female; harm reduction; male; spatial orientation; Biobehavioral Sciences; Crowding; Decision Making; Female; Harm Reduction; Humans; Male; Spatial Navigation",Article,"Final","",Scopus,2-s2.0-84995937663
"Kleanthous S., Michael M., Samaras G., Christodoulou E.","23090785400;57194857066;7003437264;6701424116;","Transactive memory in task-driven 3d virtual world teams",2016,"ACM International Conference Proceeding Series","23-27-October-2016",, a93,"","",,4,"10.1145/2971485.2996728","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997496992&doi=10.1145%2f2971485.2996728&partnerID=40&md5=832ce1f46f51b3bb90bf09061d1b7f52","Citard Services LTD, Nicosia, Cyprus; Open University of Cyprus, Nicosia, Cyprus; Department of Computer Science University of Cyprus, Cyprus","Kleanthous, S., Citard Services LTD, Nicosia, Cyprus; Michael, M., Open University of Cyprus, Nicosia, Cyprus; Samaras, G., Department of Computer Science University of Cyprus, Cyprus; Christodoulou, E., Citard Services LTD, Nicosia, Cyprus","Collaboration and knowledge sharing in small teams is very usual not only in education but also in industry, in gaming and in our lives. Interdisciplinary teams are formed and their members are expected to collaborate, exploit their capabilities and know-how towards achieving a common goal. In this work we explore whether parameters associated with the development of Transactive Memory System (TMS) can be reflected in a 3D virtual world. People from diverse background and profession brought together in teams to work towards completing an assigned task within a 3D virtual world. The results show strong associations between the parameters of a TMS, collaboration activities and communication scales examined.","3d virtual world; Collaboration; Transactive memory","Computer games; Technology transfer; Virtual reality; 3d virtual worlds; Collaboration; Collaboration activities; Interdisciplinary teams; Knowledge-sharing; Task-driven; Transactive memory; Transactive memory systems; Human computer interaction",Conference Paper,"Final","",Scopus,2-s2.0-84997496992
"Ariza O., Freiwald J., Laage N., Feist M., Salloum M., Bruder G., Steinicke F.","57197830700;57191980479;57191982482;57191977364;35753484300;23391698600;8883314100;","Inducing body-transfer illusions in VR by providing brief phases of visual-tactile stimulation",2016,"SUI 2016 - Proceedings of the 2016 Symposium on Spatial User Interaction",,,,"61","68",,4,"10.1145/2983310.2985760","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995687176&doi=10.1145%2f2983310.2985760&partnerID=40&md5=6963e453917408cd9526505c632cd9aa","Human-Computer Interaction, Department of Informatics, Universität Hamburg, Germany","Ariza, O., Human-Computer Interaction, Department of Informatics, Universität Hamburg, Germany; Freiwald, J., Human-Computer Interaction, Department of Informatics, Universität Hamburg, Germany; Laage, N., Human-Computer Interaction, Department of Informatics, Universität Hamburg, Germany; Feist, M., Human-Computer Interaction, Department of Informatics, Universität Hamburg, Germany; Salloum, M., Human-Computer Interaction, Department of Informatics, Universität Hamburg, Germany; Bruder, G., Human-Computer Interaction, Department of Informatics, Universität Hamburg, Germany; Steinicke, F., Human-Computer Interaction, Department of Informatics, Universität Hamburg, Germany","Current developments in the area of virtual reality (VR) allow numerous users to experience immersive virtual environments (VEs) in a broad range of application fields. In the same way, some research has shown novel advances in wearable devices to provide vibrotactile feedback which can be combined with low-cost technology for hand tracking and gestures recognition. The combination of these technologies can be used to investigate interesting psychological illusions. For instance, body-transfer illusions, such as the rubber-hand illusion or elongated-arm illusion, have shown that it is possible to give a person the persistent illusion of body transfer after only brief phases of synchronized visual-haptic stimulation. The motivation of this paper is to induce such perceptual illusions by combining VR, vibrotactile and tracking technologies, offering an interesting way to create new spatial interaction experiences centered on the senses of sight and touch. We present a technology framework that includes a pair of self-made gloves featuring vibrotactile feedback that can be synchronized with audio-visual stimulation in order to reproduce body-transfer illusions in VR. We present in detail the implementation of the framework and show that the proposed technology setup is able to induce the elongatedarm illusion providing automatic tactile stimuli, instead of the traditional approach based on manually synchronized stimulation. © 2016 ACM.","3D touch interaction; Body-transfer illusions; Head-mounted display; Vibrotactile feedback; Virtual environments","Helmet mounted displays; Sensory perception; Synchronization; Virtual reality; Audio-visual stimulation; Body-transfer illusions; Gestures recognition; Head mounted displays; Immersive virtual environments; Touch interaction; Traditional approaches; Vibro-tactile feedbacks; Wearable technology",Conference Paper,"Final","",Scopus,2-s2.0-84995687176
"Barsom E.Z., Graafland M., Schijven M.P.","57140782000;27267612800;6602492995;","Systematic review on the effectiveness of augmented reality applications in medical training",2016,"Surgical Endoscopy","30","10",,"4174","4183",,157,"10.1007/s00464-016-4800-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959096172&doi=10.1007%2fs00464-016-4800-6&partnerID=40&md5=46df8c1076fea9f35efc5138cf107b53","Department of Surgery, Academic Medical Centre, PO Box 22660, Amsterdam, 1100 DD, Netherlands; Department of Surgery, Flevo Hospital, Almere, Netherlands","Barsom, E.Z., Department of Surgery, Academic Medical Centre, PO Box 22660, Amsterdam, 1100 DD, Netherlands; Graafland, M., Department of Surgery, Academic Medical Centre, PO Box 22660, Amsterdam, 1100 DD, Netherlands, Department of Surgery, Flevo Hospital, Almere, Netherlands; Schijven, M.P., Department of Surgery, Academic Medical Centre, PO Box 22660, Amsterdam, 1100 DD, Netherlands","Background: Computer-based applications are increasingly used to support the training of medical professionals. Augmented reality applications (ARAs) render an interactive virtual layer on top of reality. The use of ARAs is of real interest to medical education because they blend digital elements with the physical learning environment. This will result in new educational opportunities. The aim of this systematic review is to investigate to which extent augmented reality applications are currently used to validly support medical professionals training. Methods: PubMed, Embase, INSPEC and PsychInfo were searched using predefined inclusion criteria for relevant articles up to August 2015. All study types were considered eligible. Articles concerning AR applications used to train or educate medical professionals were evaluated. Results: Twenty-seven studies were found relevant, describing a total of seven augmented reality applications. Applications were assigned to three different categories. The first category is directed toward laparoscopic surgical training, the second category toward mixed reality training of neurosurgical procedures and the third category toward training echocardiography. Statistical pooling of data could not be performed due to heterogeneity of study designs. Face-, construct- and concurrent validity was proven for two applications directed at laparoscopic training, face- and construct validity for neurosurgical procedures and face-, content- and construct validity in echocardiography training. In the literature, none of the ARAs completed a full validation process for the purpose of use. Conclusion: Augmented reality applications that support blended learning in medical training have gained public and scientific interest. In order to be of value, applications must be able to transfer information to the user. Although promising, the literature to date is lacking to support such evidence. © 2016, The Author(s).","Augmented reality; Medical education; Medical specialist training; Surgery; Training","Article; augmented reality application; concurrent validity; construct validity; content validity; echocardiography; face validity; human; laparoscopic surgery; medical education; neurosurgery; priority journal; simulation training; simulator; software; surgical training; systematic review; validation process; virtual reality; clinical competence; computer interface; computer simulation; education; laparoscopy; learning; software; Clinical Competence; Computer Simulation; Humans; Laparoscopy; Learning; Neurosurgical Procedures; Software; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84959096172
"Chen W., Ladeveze N., Clavel C., Bourdot P.","55918917900;26537655000;57210674262;14051447300;","Refined experiment of the altered human joystick for user cohabitation in multi-stereocopic immersive CVEs",2016,"2016 IEEE 3rd VR International Workshop on Collaborative Virtual Environments, 3DCVE 2016",,, 7563558,"1","8",,1,"10.1109/3DCVE.2016.7563558","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991287566&doi=10.1109%2f3DCVE.2016.7563558&partnerID=40&md5=bb8eb089f580f84d422dbe6a238fec7c","VENISE Group, CNRS-LIMSI, Orsay, France; CPU Group, CNRS-LIMSI, Orsay, France","Chen, W., VENISE Group, CNRS-LIMSI, Orsay, France; Ladeveze, N., VENISE Group, CNRS-LIMSI, Orsay, France; Clavel, C., CPU Group, CNRS-LIMSI, Orsay, France; Bourdot, P., VENISE Group, CNRS-LIMSI, Orsay, France","Immersive multi-user virtual environments give good support for closely-coupled collaboration between co-located users. More complex collaborative tasks may require individual user navigation to achieve loosely-coupled collaboration. We designed a navigation framework based on the human joystick metaphor with some alterations for cohabitation management. This model allows each user to navigate independently using a human joystick based control while avoiding physical obstacles and staying within the usable part of the system. We conducted a series of user studies to investigate the influence of each alteration by testing their combinations on various navigation tasks. The results show that modified transfer functions and adaptive neutral orientations improve users' cohabitation performance, while the impact of adaptive neutral positions need to be further studied. © 2016 IEEE.","I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Virtual Reality","Computer graphics; Navigation; Virtual reality; Co-located; Collaborative tasks; I.3.7 [computer graphics]: three-dimensional graphics and realism - virtual realities; Loosely coupled; Multi-user virtual environment; Navigation tasks; User navigation; User study; Three dimensional computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-84991287566
[No author name available],[No author id available],"3D collaborative interaction for aerospace industry",2016,"2016 IEEE 3rd VR International Workshop on Collaborative Virtual Environments, 3DCVE 2016",,, 7563560,"13","15",,2,"10.1109/3DCVE.2016.7563560","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991288183&doi=10.1109%2f3DCVE.2016.7563560&partnerID=40&md5=24b3302663bdf11ae98e7c28dab8d490",,"","3D collaborative interaction raises issues like awareness of the Virtual Environment that have been well known for some time. They have been the subject of research activities that have led to some interesting results described in the literature. Unfortunately, most of these results have not yet been not implemented in the software systems daily used by industry and remains only theoretical concepts. That is why we recently started a project to transfer some of these results in the aerospace industry for the Airbus Group. Beyond this first transfer target, we also intend to measure the real gains (in real industrial conditions) for the users, and then for the company. This second goal is essential because in most publications, user testing is not satisfying (lack of real users, lack of real procedures, non significant number of subjects). In this paper, we describe the first step of this work in progress and more precisely, the basic interaction features we have developed. Currently, we are designing the first user tests. © 2016 IEEE.",,"Virtual reality; Collaborative interaction; Industrial conditions; Interaction features; Research activities; Software systems; User testing; User tests; Work in progress; Aerospace industry",Conference Paper,"Final","",Scopus,2-s2.0-84991288183
"Mei C., Quarles J.","56421487500;55868360300;","A software framework for developing mathematical model driven virtual human",2016,"2016 IEEE Virtual Humans and Crowds for Immersive Environments, VHCIE 2016",,, 7563567,"12","16",,,"10.1109/VHCIE.2016.7563567","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991325547&doi=10.1109%2fVHCIE.2016.7563567&partnerID=40&md5=852f12a7b2d423cfb8f9e0d9ad2b0961","Department of Computer Science, University of Texas, San Antonio, United States","Mei, C., Department of Computer Science, University of Texas, San Antonio, United States; Quarles, J., Department of Computer Science, University of Texas, San Antonio, United States","Virtual Humans (VH) have many benefits, such as simulating humans when using real humans is difficult, impossible, or dangerous. VHs realism in behavior and response may be improved by mathematical models, which can provide dynamic responses and interactions and have the potential to be widely applied in training and education, such as medical training (e.g. physiological models of blood flow). However, the difficulties of developing mathematical model driven VHs may restrict the application of it, especially in the areas where the professionals do not know how to program (e.g. doctors). We present Mathematical Virtual People (MVP), which is a software framework that may simplify the developing job and encourage the applications of VHs driven by mathematical models, such as the drug reaction models and the cardiovascular system models. © 2016 IEEE.","Mathematical Model; Software Framework; Virtual Human","Application programs; Cardiovascular system; Computer programming; Mathematical models; Technology transfer; Virtual reality; Blood flow; Cardiovascular system models; Medical training; Reaction model; Software frameworks; Training and education; Virtual humans; Physiological models",Conference Paper,"Final","",Scopus,2-s2.0-84991325547
"Ferrer-Torregrosa J., Jiménez-Rodríguez M.Á., Torralba-Estelles J., Garzón-Farinós F., Pérez-Bermejo M., Fernández-Ehrling N.","56497953600;57168816300;57190985796;57190983121;57191966548;57190981162;","Distance learning ects and flipped classroom in the anatomy learning: Comparative study of the use of augmented reality, video and notes",2016,"BMC Medical Education","16","1", 230,"","",,35,"10.1186/s12909-016-0757-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985023167&doi=10.1186%2fs12909-016-0757-3&partnerID=40&md5=2e184d9ddd34f0b6947a0cca5249f5bf","Department of Podiatry, School of Physiotherapy and Podiatry, Catholic University of Valencia, San Vicente Martir, C/ Ramiro de Maeztu 14, Torrente, 46900, Spain; Didactics and Educational Innovation, School of Psychology, Teaching and Educational Sciences, Catholic University of Valencia, San Vicente Martir, Valencia, Spain; Faculty of Nursing, Catholic University of Valencia, San Vicente Martir, Valencia, Spain; Doctoral School, Catholic University of Valencia, San Vicente Martir, Valencia, Spain","Ferrer-Torregrosa, J., Department of Podiatry, School of Physiotherapy and Podiatry, Catholic University of Valencia, San Vicente Martir, C/ Ramiro de Maeztu 14, Torrente, 46900, Spain; Jiménez-Rodríguez, M.Á., Didactics and Educational Innovation, School of Psychology, Teaching and Educational Sciences, Catholic University of Valencia, San Vicente Martir, Valencia, Spain; Torralba-Estelles, J., Department of Podiatry, School of Physiotherapy and Podiatry, Catholic University of Valencia, San Vicente Martir, C/ Ramiro de Maeztu 14, Torrente, 46900, Spain; Garzón-Farinós, F., Department of Podiatry, School of Physiotherapy and Podiatry, Catholic University of Valencia, San Vicente Martir, C/ Ramiro de Maeztu 14, Torrente, 46900, Spain; Pérez-Bermejo, M., Faculty of Nursing, Catholic University of Valencia, San Vicente Martir, Valencia, Spain; Fernández-Ehrling, N., Doctoral School, Catholic University of Valencia, San Vicente Martir, Valencia, Spain","Background: The establishment of the ECTS (European Credit Transfer System) is one of the pillars of the European Space of Higher Education. This way of accounting for the time spent in training has two essential parts, classroom teaching (work with the professor) and distance learning (work without the professor, whether in an individual or collective way). Much has been published on the distance learning part, but less on the classroom teaching section. In this work, the authors investigate didactic strategies and associated aids for distance learning work in a concept based on flipped classroom where transmitting information is carried out with aids that the professor prepares, so that the student works in an independent way before the classes, thus being able to dedicate the classroom teaching time to more complex learning and being able to count on the professor's help. Methods: Three teaching aids applied to the study of anatomy have been compared: Notes with images, videos, and augmented reality. Four dimensions have been compared: the time spent, the acquired learnings, the metacognitive perception, and the prospects of the use of augmented reality for study. Results: The results show the effectiveness, in all aspects, of augmented reality when compared with the rest of aids. The questionnaire assessed the acquired knowledge through a course exam, where 5.60 points were obtained for the notes group, 6.54 for the video group, and 7.19 for the augmented reality group. That is 0.94 more points for the video group compared with the notes and 1.59 more points for the augmented reality group compared with the notes group. Conclusions: This research demonstrates that, although technology has not been sufficiently developed for education, it is expected that it can be improved in both the autonomous work of the student and the academic training of health science students and that we can teach how to learn. Moreover, one can see how the grades of the students who studied with augmented reality are more grouped and that there is less dispersion in the marks compared with other materials. © 2016 The Author(s).","Anatomy; Augmented reality; Autonomous learning; ECTS; Flipped classroom; Metacognition","anatomy; comparative study; health science; human; human experiment; learning; metacognition; perception; questionnaire; rest; teaching; videorecording; academic achievement; anatomy; comparative study; computer interface; education; educational model; health personnel attitude; learning; medical literature; organization and management; problem based learning; procedures; program evaluation; Spain; standards; Anatomy; Attitude of Health Personnel; Computer-Assisted Instruction; Education, Distance; Education, Graduate; Educational Measurement; Humans; Learning; Medical Writing; Models, Educational; Problem-Based Learning; Program Evaluation; Spain; User-Computer Interface; Video Recording",Article,"Final","",Scopus,2-s2.0-84985023167
"Hindlekar S., Zordan V.B., Smith E.E., III, Welter J.C., McKay W.G.","57190856629;6506123075;57190862696;57190858179;57190862863;","MechVR: Interactive VR motion simulation of ""mech"" biped robot",2016,"ACM SIGGRAPH 2016 VR Village, SIGGRAPH 2016",,, a14,"","",,5,"10.1145/2929490.2932422","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983474967&doi=10.1145%2f2929490.2932422&partnerID=40&md5=0d1a3d843da1949194dcb16907062b6f","Clemson University, United States","Hindlekar, S., Clemson University, United States; Zordan, V.B., Clemson University, United States; Smith, E.E., III, Clemson University, United States; Welter, J.C., Clemson University, United States; McKay, W.G., Clemson University, United States","MechVR is an interactive VR/Motion simulator that offers an experience of driving a 3D simulated robot in a custom training world. From the user's perspective, they ""enter"" the cockpit of a giant motorized biped, and experience an immersive, interactive virtual reality training ride as they drive the simulated robotic machine themselves. The idea is not unlike a flight simulator, but for an imaginary, giant walking, running, and flying robot machine. Under the hood is a custom software base that drives state-of-the-art motion simulation equipment based on a custom user interface. Our research questions include the control and physical fidelity of the virtual robot, and the transfer of the experience into an interactive realworld simulation (hardware) as well as the design of the user experience for this and similar applications, e.g. prototyping amusement park rides, and/or novel arcade-style motion experiences. © 2016 Copyright held by the owner/author(s).","Motion simulation in the real world and virtual; Virtual reality","Computer graphics; Computer software; Flight simulators; Interface states; Machine design; Robots; User interfaces; Virtual reality; Amusement-park rides; Interactive virtual reality; Motion simulations; Real-world; Real-world simulation; Research questions; Simulated robot; State of the art; Interactive computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-84983474967
"Oh S.Y., Shriram K., Laha B., Baughman S., Ogle E., Bailenson J.","57149166100;57192920978;36093147000;55595658500;57190405635;6602840468;","Immersion at scale: Researcher's guide to ecologically valid mobile experiments",2016,"Proceedings - IEEE Virtual Reality","2016-July",, 7504747,"249","250",,6,"10.1109/VR.2016.7504747","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979777886&doi=10.1109%2fVR.2016.7504747&partnerID=40&md5=243f587709ce0639cbac41ccf2ac87e0","Department of Communication, Stanford University, United States","Oh, S.Y., Department of Communication, Stanford University, United States; Shriram, K., Department of Communication, Stanford University, United States; Laha, B., Department of Communication, Stanford University, United States; Baughman, S., Department of Communication, Stanford University, United States; Ogle, E., Department of Communication, Stanford University, United States; Bailenson, J., Department of Communication, Stanford University, United States","While there have been hundreds of psychological studies using virtual reality (VR) over the past few decades, those studies have almost exclusively been conducted in laboratory settings using small samples of college students with little demographic variance. Hence, the generalizability of the results is limited, as not all findings will apply outside the college demographic. In this paper, we present our mobile VR project (Immersion at Scale) where we conduct VR experiment sessions in naturalistic settings (e.g., local events, museums, etc.). On average, we were able to collect data from 20-25 people for each 4-hour data collection session of Immersion at Scale. We discovered a number of obstacles and opportunities based on bringing VR out into the field. Thus, we do not focus on experimental stimuli and results, but methodological guidelines based on our iterative design improvements from pilot testing. © 2016 IEEE.","Experimental methodology; Field study; Psychology","Iterative methods; Population statistics; Students; Virtual reality; College students; Data collection; Demographic variance; Experimental methodology; Field studies; Iterative design; Methodological guidelines; Psychology; Data acquisition",Conference Paper,"Final","",Scopus,2-s2.0-84979777886
"Daher S., Kim K., Lee M., Raij A., Schubert R., Bailenson J., Welch G.","57062307400;56159628700;56159565300;9735776700;55550102700;6602840468;35572266400;","Exploring social presence transfer in real-virtual human interaction",2016,"Proceedings - IEEE Virtual Reality","2016-July",, 7504705,"165","166",,3,"10.1109/VR.2016.7504705","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979780820&doi=10.1109%2fVR.2016.7504705&partnerID=40&md5=0475bd8bf66bb730025fb18d977c3e83","University of Central Florida, United States; UNC-Chapel Hill, United States; Stanford University, United States","Daher, S., University of Central Florida, United States; Kim, K., University of Central Florida, United States; Lee, M., University of Central Florida, United States; Raij, A., University of Central Florida, United States; Schubert, R., University of Central Florida, United States, UNC-Chapel Hill, United States; Bailenson, J., Stanford University, United States; Welch, G., University of Central Florida, United States","We explore whether a peripheral observation of apparent mutual social presence between a real human (RH) and a virtual human (VH) can in turn increase a subject's sense of social presence with the VH. In other words, we explore whether social presence can transfer from one RH-VH interaction to another. Specifically, we carried out an experiment where human subjects were asked to play a game with a VH. As they entered the game room, approximately half of the subjects were exposed to a brief but apparently engaging conversation between an RH and the VH. The subjects who were exposed to the brief RH-VH interaction had significantly higher measures of both emotional connection and the attentional allocation dimension of social presence for the VH, compared to those who were not. We describe the motivation, the experiment, and the results. © 2016 IEEE.","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Artificial, Augmented, and Virtual Realities; J.4 [Computer Applications]: Social and Behavioral Sciences - Psychology","Behavioral research; Emotional connections; Exposed to; H.5.1 [Information interfaces and presentation]: Multimedia Information Systems Artificial , augmented , and virtual realities; Human subjects; J.4 [computer applications]: social and behavioral sciences - psychologies; Social presence; Virtual humans; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84979780820
"Lee M., Kim K., Daher S., Raij A., Schubert R., Bailenson J., Welch G.","56159565300;56159628700;57062307400;9735776700;55550102700;6602840468;35572266400;","The Wobbly Table: Increased Social Presence via Subtle Incidental Movement of a Real-Virtual Table",2016,"Proceedings - IEEE Virtual Reality","2016-July",, 7504683,"11","17",,27,"10.1109/VR.2016.7504683","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979788594&doi=10.1109%2fVR.2016.7504683&partnerID=40&md5=f824efacb20dd6e82bbe106e978d234b","University of Central Florida, United States; UNC, Chapel Hill, United States; Stanford University, United States","Lee, M., University of Central Florida, United States; Kim, K., University of Central Florida, United States; Daher, S., University of Central Florida, United States; Raij, A., University of Central Florida, United States; Schubert, R., University of Central Florida, United States, UNC, Chapel Hill, United States; Bailenson, J., Stanford University, United States; Welch, G., University of Central Florida, United States","While performing everyday interactions, we often incidentally touch and move objects in subtle ways. These objects are not necessarily directly related to the task at hand, and the movement of an object might even be entirely unintentional. If another person is touching the object at the same time, the movement can transfer through the object and be experienced - however subtly - by the other person. For example, when one person hands a drink to another, at some point both individuals will be touching the glass, and consequently exerting small (often unnoticed) forces on the other person. Despite the frequency of such subtle incidental movements of shared objects in everyday interactions, few have examined how these movements affect human-virtual human (VH) interaction. We ran an experiment to assess how presence and social presence are affected when a person experiences subtle, incidental movement through a shared real-virtual object. We constructed a real-virtual room with a table that spanned the boundary between the real and virtual environments. The participant was seated on the real side of the table, which visually extended into the virtual world via a projection screen, and the VH was seated on the virtual side of the table. The two interacted by playing a game of Twenty Questions, where one player asked the other a series of 20 yes/no questions to deduce what object the other player was thinking about. During the game, the wobbly group of subjects experienced subtle incidental movements of the real-virtual table: the entire real-virtual table tilted slightly away/toward the subject when the virtual/real human leaned on it. The control group also played the same game, except the table did not wobble. Results indicate that the wobbly group had higher presence and social presence with the virtual human in general, with statistically significant increases in presence, co-presence, and attentional allocation. We present the experiment and results, and discuss some potential implications for virtual human systems and some potential future studies. © 2016 IEEE.","Augmented and Virtual Realities; H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Artificial; J.4 [Computer Applications]: Social and Behavioral Sciences - Psychology","Behavioral research; Augmented and virtual realities; H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Artificial; J.4 [computer applications]: social and behavioral sciences - psychologies; Social presence; Virtual human systems; Virtual humans; Virtual objects; Virtual tables; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84979788594
"Sun P., Cuykendall S., Carlson K., Lantin M., Schiphorst T.","57190403711;55850525700;54386556400;6603400697;6506745859;","SpaceDisplaced: Investigating presence through mediated participatory environments",2016,"ACM International Conference Proceeding Series","05-06-July-2016",, 24,"","",,2,"10.1145/2948910.2948945","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979752767&doi=10.1145%2f2948910.2948945&partnerID=40&md5=f8f3ead1f367e28013874db9a53581c7","School of Interactive Arts and Technology, Simon Fraser University, Canada Emily Carr University of Art + Design, Canada","Sun, P., School of Interactive Arts and Technology, Simon Fraser University, Canada Emily Carr University of Art + Design, Canada; Cuykendall, S., School of Interactive Arts and Technology, Simon Fraser University, Canada Emily Carr University of Art + Design, Canada; Carlson, K., School of Interactive Arts and Technology, Simon Fraser University, Canada Emily Carr University of Art + Design, Canada; Lantin, M., School of Interactive Arts and Technology, Simon Fraser University, Canada Emily Carr University of Art + Design, Canada; Schiphorst, T., School of Interactive Arts and Technology, Simon Fraser University, Canada Emily Carr University of Art + Design, Canada","spaceDisplaced: Investigating Presence Through Mediated Participatory Environments is an interdisciplinary telepresence performance that linked four physical spaces. We conducted a participatory telepresence performance to explore how the experience of presence in separate spaces is influenced by the scale, function, sonic potential and accessibility of the space that each performer inhabits. The performance served as a form of experience modeling, a design methodology put forth by Schiphorst and Andersen (2004) that uses somatic, theater, and dance practices to model and structure experiences that can inform interaction design. In this paper we describe our exploration of personal, social and environmental forms of presence in the performance. We demonstrate how our findings led to new insights on how to stage the experience of presence. We apply these findings in Presence in a Box: Crossing Liminal Spaces, an interactive public performance where participants can transfer the experience of presence between small and large spaces.","Cognition and perception; Immersive; Movement; Multimedia recording; Proprioception; Sensory alterations; Sound environment; Technological unconscious; Telepresence; Virtual reality","Sensory perception; Virtual reality; Immersive; Movement; Multimedia recording; Sensory alterations; Sound environment; Technological unconscious; Telepresence; Visual communication",Conference Paper,"Final","",Scopus,2-s2.0-84979752767
"Qian K., Jiang T., Wang M., Yang X., Zhang J.","57213057429;57189034015;55694491200;55683846400;55912086700;","Energized soft tissue dissection in surgery simulation",2016,"Computer Animation and Virtual Worlds","27","3-4",,"280","289",,4,"10.1002/cav.1691","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992310134&doi=10.1002%2fcav.1691&partnerID=40&md5=c47996009aad72cf6c1199ca4812cabc","National Center for Computer Animation, Bournemouth University, Dorset, United Kingdom; Northwest A and F University, Xianyang, China","Qian, K., National Center for Computer Animation, Bournemouth University, Dorset, United Kingdom; Jiang, T., National Center for Computer Animation, Bournemouth University, Dorset, United Kingdom; Wang, M., Northwest A and F University, Xianyang, China; Yang, X., National Center for Computer Animation, Bournemouth University, Dorset, United Kingdom; Zhang, J., National Center for Computer Animation, Bournemouth University, Dorset, United Kingdom","With the development of virtual reality technology, surgery simulation has become an effective way to train the operation skills for surgeons. Soft tissue dissection, as one of the most frequently performed operations in surgery, is indispensable to an immersive and high-fidelity surgery simulator. Energized dissection tools are much more commonly used than the traditional sharp scalpels for patient safety. Unfortunately, the interaction of such tools with the soft tissues has been largely ignored in the research of surgical simulators. In this paper, we have proposed an energized soft tissue dissection model. We categorize the soft tissues into three types (fascia, membrane, and fat) and simulate their physical property accordingly. The dissection algorithm we propose employs an edge-based structure, which offers an effective mechanism for the generation of incisions dissected with energized tools. The mesh topology will not be changed when it is dissected by an energized tool, rather it is controlled by the heat transfer model. Our dissection method is highly compatible and efficient to the physically based simulation resolved by a pre-factorized linear system. We have proposed an energized soft tissue dissection model. We categorize the soft tissues into three types (fascia, membrane, and fat) and simulate their physical property accordingly. The dissection algorithm employs an edge-based structure, which offers an effective mechanism for the generation of incisions dissected with energized tools. Our dissection method is highly compatible and efficient to the physically based simulation resolved by a pre-factorized linear system. © 2016 John Wiley & Sons, Ltd.","deformation simulation; energized dissection; strain limiting; surgery simulation","Dissection; Heat transfer; Histology; Linear systems; Surgery; Tissue; Topology; Virtual reality; Deformation simulation; Effective mechanisms; Heat transfer model; Physically-based simulation; Surgery simulations; Surgery Simulator; Surgical simulators; Virtual reality technology; Surgical equipment",Conference Paper,"Final","",Scopus,2-s2.0-84992310134
"Passig D., Tzuriel D., Eshel-Kedmi G.","6601988661;6602906610;57118320800;","Improving children's cognitive modifiability by dynamic assessment in 3D Immersive Virtual Reality environments",2016,"Computers and Education","95",,,"296","308",,62,"10.1016/j.compedu.2016.01.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958149996&doi=10.1016%2fj.compedu.2016.01.009&partnerID=40&md5=a42ac173562935adf46419cfa9156e56","School of Education, Bar-Ilan University, Ramat-Gan, 52900, Israel","Passig, D., School of Education, Bar-Ilan University, Ramat-Gan, 52900, Israel; Tzuriel, D., School of Education, Bar-Ilan University, Ramat-Gan, 52900, Israel; Eshel-Kedmi, G., School of Education, Bar-Ilan University, Ramat-Gan, 52900, Israel","Increasing evidence reveals the efficacy of dynamic assessment (DA) procedure in providing rich and reliable feedback regarding children's cognitive modifiability. The DA procedure included four phases: Pre-teaching test, teaching, post-teaching and transfer test two weeks after teaching. The teaching phase includes mediated learning experience strategies. Children's cognitive modifiability was examined by pre- to post-teaching improvement and by the transfer test. Children in Grades 1 and 2 (n = 117) were randomly assigned into three experimental groups and one control group. Each of the experimental groups was given the teaching phase in a different modality: 3D Immersive Virtual Reality (IVR, n = 36), 2D (n = 36), and tangible blocks (TB, n = 24). The control group (n = 21) was not given teaching phase. The teaching phase included strategies of solving problems from the Analogies Subtest of the Cognitive Modifiability Battery (CMB). Pre- And post-teaching CMB Analogies tests were administered to all groups followed by CMB Transfer Analogies two weeks later. The findings indicate that the 2D and TB groups showed higher cognitive modifiability than the control group. Also, the findings indicate that teaching in a 3D IVR environment contributed to the children's cognitive modifiability more than in the other groups in the CMB Transfer Analogies. The findings are discussed in relation to the unique enhancing characteristics of the 3D IVR condition combined with the applied mediation strategies. © 2016 Elsevier Ltd. All rights reserved.","Analogical reasoning; Cognitive modifiability; Dynamic assessment; Mediated learning strategies; Virtual reality","Virtual reality; Analogical reasoning; Control groups; Dynamic assessment; Experimental groups; Immersive virtual reality; Learning experiences; Learning strategy; Modifiability; Education",Article,"Final","",Scopus,2-s2.0-84958149996
"Laha B., Bowman D.A., Laidlaw D.H., Socha J.J.","36093147000;57203231782;56652601600;8585845700;","A classification of user tasks in visual analysis of volume data",2016,"2015 IEEE Scientific Visualization Conference, SciVis 2015 - Proceedings",,, 7429485,"1","8",,8,"10.1109/SciVis.2015.7429485","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966270171&doi=10.1109%2fSciVis.2015.7429485&partnerID=40&md5=8c95c71341bd6416906fada0144deda0","Stanford University, United States; Virginia Tech, United States; Brown University, United States","Laha, B., Stanford University, United States; Bowman, D.A., Virginia Tech, United States; Laidlaw, D.H., Brown University, United States; Socha, J.J., Virginia Tech, United States","Empirical findings from studies in one scientific domain have very limited applicability to other domains, unless we formally establish deeper insights on the generalizability of task types. We present a domain-independent classification of visual analysis tasks with volume visualizations. This taxonomy will help researchers design experiments, ensure coverage, and generate hypotheses in empirical studies with volume datasets. To develop our taxonomy, we first interviewed scientists working with spatial data in disparate domains. We then ran a survey to evaluate the design participants in which were scientists and professionals from around the world, working with volume data in various scientific domains. Respondents agreed substantially with our taxonomy design, but also suggested important refinements. We report the results in the form of a goal-based generic categorization of visual analysis tasks with volume visualizations. Our taxonomy covers tasks performed with a wide variety of volume datasets. © 2015 IEEE.","3D Interaction; Empirical Evaluation; Scientific Visualization; Task Taxonomy; Virtual Reality; Volume Visualization","Data visualization; Surveys; Taxonomies; Virtual reality; Visualization; 3D interactions; Design experiments; Domain independents; Empirical evaluations; Empirical findings; Empirical studies; Volume data sets; Volume visualization; Three dimensional computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-84966270171
"Sankaranarayanan G., Li B., Manser K., Jones S.B., Jones D.B., Schwaitzberg S., Cao C.G.L., De S.","15623319200;57169023100;55996844500;15739783000;55387240300;7007036892;25957557800;7202304567;","Face and construct validation of a next generation virtual reality (Gen2-VR©) surgical simulator",2016,"Surgical Endoscopy","30","3",,"979","985",,13,"10.1007/s00464-015-4278-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959176014&doi=10.1007%2fs00464-015-4278-7&partnerID=40&md5=a5508327f4021456b0383555601182e6","Center for Modeling, Simulation and Imaging in Medicine (CeMSIM), Rensselaer Polytechnic Institute, 110 8th Street, JEC 2049, Troy, NY  12180, United States; School of Mechanical Engineering and Automation, Northeastern University, Shenyang, China; Cambridge Health Alliance, Cambridge, MA, United States; Beth Israel Deaconess Medical Center, Boston, MA, United States; Wright State University, Dayton, OH, United States; Department of Mechanical, Aerospace and Nuclear Engineering, Rensselaer Polytechnic Institute, 110 8th Street, JEC 2049, Troy, NY  12180, United States","Sankaranarayanan, G., Center for Modeling, Simulation and Imaging in Medicine (CeMSIM), Rensselaer Polytechnic Institute, 110 8th Street, JEC 2049, Troy, NY  12180, United States; Li, B., Center for Modeling, Simulation and Imaging in Medicine (CeMSIM), Rensselaer Polytechnic Institute, 110 8th Street, JEC 2049, Troy, NY  12180, United States, School of Mechanical Engineering and Automation, Northeastern University, Shenyang, China; Manser, K., Cambridge Health Alliance, Cambridge, MA, United States; Jones, S.B., Beth Israel Deaconess Medical Center, Boston, MA, United States; Jones, D.B., Beth Israel Deaconess Medical Center, Boston, MA, United States; Schwaitzberg, S., Cambridge Health Alliance, Cambridge, MA, United States; Cao, C.G.L., Wright State University, Dayton, OH, United States; De, S., Center for Modeling, Simulation and Imaging in Medicine (CeMSIM), Rensselaer Polytechnic Institute, 110 8th Street, JEC 2049, Troy, NY  12180, United States, Department of Mechanical, Aerospace and Nuclear Engineering, Rensselaer Polytechnic Institute, 110 8th Street, JEC 2049, Troy, NY  12180, United States","Introduction: Surgical performance is affected by distractors and interruptions to surgical workflow that exist in the operating room. However, traditional surgical simulators are used to train surgeons in a skills laboratory that does not recreate these conditions. To overcome this limitation, we have developed a novel, immersive virtual reality (Gen2-VR©) system to train surgeons in these environments. This study was to establish face and construct validity of our system. Methods and procedures: The study was a within-subjects design, with subjects repeating a virtual peg transfer task under three different conditions: Case I: traditional VR; Case II: Gen2-VR© with no distractions and Case III: Gen2-VR© with distractions and interruptions. In Case III, to simulate the effects of distractions and interruptions, music was played intermittently, the camera lens was fogged for 10 s and tools malfunctioned for 15 s at random points in time during the simulation. At the completion of the study subjects filled in a 5-point Likert scale feedback questionnaire. A total of sixteen subjects participated in this study. Results: Friedman test showed significant difference in scores between the three conditions (p &lt; 0.0001). Post hoc analysis using Wilcoxon signed-rank tests with Bonferroni correction further showed that all the three conditions were significantly different from each other (Case I, Case II, p &lt; 0.0001), (Case I, Case III, p &lt; 0.0001) and (Case II, Case III, p = 0.009). Subjects rated that fog (mean 4.18) and tool malfunction (median 4.56) significantly hindered their performance. Conclusion: The results showed that Gen2-VR© simulator has both face and construct validity and that it can accurately and realistically present distractions and interruptions in a simulated OR, in spite of limitations of the current HMD hardware technology. © 2015, Springer Science+Business Media New York.","Cognitive simulator; Face and construct validation; Gen2-VR©; Head-mounted display; Immersive virtual reality; Surgery simulator","accuracy; Article; Bonferroni correction; camera; computer program; construct validity; face validity; female; Friedman test; human; human experiment; Likert scale; male; monitor; music; operating room; post hoc analysis; priority journal; simulator; statistical model; surgeon; surgery simulator; surgical training; virtual reality; Wilcoxon signed ranks test; attention; computer interface; education; feedback system; laparoscopy; procedures; simulation training; validation study; Attention; Feedback; Female; Humans; Laparoscopy; Male; Simulation Training; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84959176014
"Bissonnette J., Dubé F., Provencher M.D., Moreno Sala M.T.","56851382000;56847321800;6701663481;56849540700;","Evolution of music performance anxiety and quality of performance during virtual reality exposure training",2016,"Virtual Reality","20","1",,"71","81",,20,"10.1007/s10055-016-0283-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956974350&doi=10.1007%2fs10055-016-0283-y&partnerID=40&md5=7505058e9853e029faf1370ade2c0945","Laval University, Pavillon Louis-Jacques-Casault, 1055 Avenue du Séminaire, Québec, QC  G1V 0A6, Canada; School of Psychology, Laval University, Québec, QC, Canada","Bissonnette, J., Laval University, Pavillon Louis-Jacques-Casault, 1055 Avenue du Séminaire, Québec, QC  G1V 0A6, Canada; Dubé, F., Laval University, Pavillon Louis-Jacques-Casault, 1055 Avenue du Séminaire, Québec, QC  G1V 0A6, Canada; Provencher, M.D., School of Psychology, Laval University, Québec, QC, Canada; Moreno Sala, M.T., Laval University, Pavillon Louis-Jacques-Casault, 1055 Avenue du Séminaire, Québec, QC  G1V 0A6, Canada","Virtual reality exposure is increasingly used as a method of treatment for anxiety disorders. This exploratory study examines a virtual reality exposure training (VRET) conceived for the treatment of music performance anxiety (MPA). The aim is to obtain first-level knowledge in the music field concerning VRET. This article analyzes how MPA, concentration and quality of performance evolve during VRET. Nine music students participated in six 1-h sessions of VRET spread out over 3 weeks. They were exposed to four different virtual environments representing typical audiences for musicians. The findings indicate a significant decrease in MPA between sessions. They also indicate a significant increase in performance quality within sessions and a positive correlation between absorption ability and level of anxiety at the beginning of the VRET. Further studies must be conducted to evaluate the generalizability potential of these results to real performance situations. © 2016, Springer-Verlag London.","Exposure; Immersion ability; Music; Performance anxiety; Treatment; Virtual reality","Virtual reality; Exposure; Immersion ability; Music; Performance anxiety; Treatment; E-learning",Article,"Final","",Scopus,2-s2.0-84956974350
"Gortari A.B.O.D.","55977387100;","What Can Game Transfer Phenomena Tell Us about the Impact of Highly Immersive Gaming Technologies?",2016,"Proceedings - 2015 International Conference on Interactive Technologies and Games, ITAG 2015",,, 7399494,"84","89",,2,"10.1109/iTAG.2015.15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969204309&doi=10.1109%2fiTAG.2015.15&partnerID=40&md5=b149a3dda72c0b588ce2026e18d1999e","Division of Psychology, Nottingham Trent University, Nottingham, United Kingdom","Gortari, A.B.O.D., Division of Psychology, Nottingham Trent University, Nottingham, United Kingdom","The imminent introduction of highly immersive technologies for entertainment that bring exciting possibilities for the users also raises important questions regarding the impact on their well-being. Game Transfer Phenomena (GTP), a research approach focusing on understanding the psychosocial effects of video game playing by examining non-volitional phenomena (e.g., Altered sensorial perceptions, automatic mental processes, involuntary motoric activations and behaviours related to playing video games), suggests similarities between gamers' experiences reported after playing on conventional devices and side effects of highly immersive technologies (e.g., Head-up displays, highly realistic virtual environments). The aim of this paper is to discuss the challenges highly immersive technologies posit to the malleable human mind, taking into account not only the side-effects of the virtual immersion manifesting as physical symptoms, but also the psychosocial implications. © 2015 IEEE.","effects of video game playing; Game Transfer Phenomena; head-up displays; impact of VR; Virtual reality","Head-up displays; Interactive computer graphics; Virtual reality; Immersive gaming; Immersive technologies; impact of VR; Physical symptoms; Psycho-social effects; Research approach; Transfer phenomenon; Video game playing; Human computer interaction",Conference Paper,"Final","",Scopus,2-s2.0-84969204309
"Wang P., Li Y., Yu L., Zhang J., Xu Z.","55693634800;55900103000;57221079387;55172141600;36718326200;","A novel assembly simulation method based on semantics and geometric constraint",2016,"Assembly Automation","36","1",,"34","50",,10,"10.1108/AA-05-2015-036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956666683&doi=10.1108%2fAA-05-2015-036&partnerID=40&md5=72405365e78c075a5ff5f4d370eea853","Ministry of Education Key Lab of Contemporary Design and Integrated Manufacturing Technology, Northwestern Polytechnical University, Xi'an, China; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China","Wang, P., Ministry of Education Key Lab of Contemporary Design and Integrated Manufacturing Technology, Northwestern Polytechnical University, Xi'an, China; Li, Y., Ministry of Education Key Lab of Contemporary Design and Integrated Manufacturing Technology, Northwestern Polytechnical University, Xi'an, China; Yu, L., Ministry of Education Key Lab of Contemporary Design and Integrated Manufacturing Technology, Northwestern Polytechnical University, Xi'an, China; Zhang, J., Ministry of Education Key Lab of Contemporary Design and Integrated Manufacturing Technology, Northwestern Polytechnical University, Xi'an, China; Xu, Z., School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China","Purpose - The purpose of this paper is to provide a novel assembly simulation method to reduce the repetitive and tedious assembly simulation work. Currently, assembly simulation is always carried out by human-computer interaction, which is a time-consuming and tedious work. The most important reason for this problem is that the assembly simulation is a mapping between human intent and movements of models; at the same time, assembly information is transferred from semantic level to geometric level. However, some essential assembly information is lost during the transfer, and it must be accomplished through manual definition. To address the issue, a novel assembly simulation method is proposed in this paper based on semantics and geometric constraint. Design/methodology/approach - First, an assembly operation semantic model is put forward to integrate and manage the semantic information of assembly, and some rules for modeling are generalized. Second, method for transferring assembly information from semantic level to geometric level is presented by dividing assembly operation into a set of simulation actions and providing some rules for this division. Then, a geometric constraint-based calculation method is proposed to obtain the essential parameters of each simulation action. Finally, cases are studied to demonstrate the effectiveness of the method. Findings - Results show that laborious work would be reduced, and the redundant human participation would be avoided in assembly simulation. Practical implications - It has the potential and possibility to change the current pattern of assembly simulation. Originality/value - A novel assembly simulation method based on semantics and geometric constraint is presented to make assembly simulation more convenient and faster. © 2015 Emerald Group Publishing Limited.","Assembly operation; Assembly simulation; Geometric constraint; Semantics; Simulation action","Geometry; Human computer interaction; Information management; Assembly information; Assembly operations; Assembly simulation; Current patterns; Design/methodology/approach; Geometric constraint; Semantic information; Simulation action; Semantics",Article,"Final","",Scopus,2-s2.0-84956666683
"Liaw S.Y., Wong L.F., Lim E.Y.P., Ang S.B.L., Mujumdar S., Ho J.T.Y., Mordiffi S.Z., Ang E.N.K.","39061715100;56471195500;57188647368;36785202800;56030146800;56504473000;6505941019;23099412200;","Effectiveness of a Web-based simulation in improving nurses' workplace practice with deteriorating ward patients: A pre- and postintervention study",2016,"Journal of Medical Internet Research","18","2", e37,"","",,24,"10.2196/jmir.5294","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962061536&doi=10.2196%2fjmir.5294&partnerID=40&md5=2eea7fef9aa925ca18ddf0cd74325fe7","National University of Singapore, Level 2 Clinical Research Centre, Block MD 11, Singapore, Singapore; National University Hospital, Singapore, Singapore","Liaw, S.Y., National University of Singapore, Level 2 Clinical Research Centre, Block MD 11, Singapore, Singapore; Wong, L.F., National University of Singapore, Level 2 Clinical Research Centre, Block MD 11, Singapore, Singapore; Lim, E.Y.P., National University Hospital, Singapore, Singapore; Ang, S.B.L., National University Hospital, Singapore, Singapore; Mujumdar, S., National University Hospital, Singapore, Singapore; Ho, J.T.Y., National University Hospital, Singapore, Singapore; Mordiffi, S.Z., National University Hospital, Singapore, Singapore; Ang, E.N.K., National University of Singapore, Level 2 Clinical Research Centre, Block MD 11, Singapore, Singapore","Background: Nurses play an important role in detecting patients with clinical deterioration. However, the problem of nurses failing to trigger deteriorating ward patients still persists despite the implementation of a patient safety initiative, the Rapid Response System. A Web-based simulation was developed to enhance nurses' role in recognizing and responding to deteriorating patients. While studies have evaluated the effectiveness of the Web-based simulation on nurses' clinical performance in a simulated environment, no study has examined its impact on nurses' actual practice in the clinical setting. Objective: The objective of this study was to evaluate the impact of Web-based simulation on nurses' recognition of and response to deteriorating patients in clinical settings. The outcomes were measured across all levels of Kirkpatrick's 4-level evaluation model with clinical outcome on triggering rates of deteriorating patients as the primary outcome measure. Methods: A before-and-after study was conducted on two general wards at an acute care tertiary hospital over a 14-month period. All nurses from the two study wards who undertook the Web-based simulation as part of their continuing nursing education were invited to complete questionnaires at various time points to measure their motivational reaction, knowledge, and perceived transfer of learning. Clinical records on cases triggered by ward nurses from the two study wards were evaluated for frequency and types of triggers over a period of 6 months pre- and 6 months postintervention. Results: The number of deteriorating patients triggered by ward nurses in a medical general ward increased significantly (P<.001) from pre- (84/937, 8.96%) to postintervention (91/624, 14.58%). The nurses reported positively on the transfer of learning (mean 3.89, SD 0.49) from the Web-based simulation to clinical practice. A significant increase (P<.001) on knowledge posttest score from pretest score was also reported. The nurses also perceived positively their motivation (mean 3.78, SD 0.56) to engage in the Web-based simulation. Conclusions: This study provides evidence on the effectiveness of Web-based simulation in improving nursing practice when recognizing and responding to deteriorating patients. This educational tool could be implemented by nurse educators worldwide to address the educational needs of a large group of hospital nurses responsible for patients in clinical deterioration.","Clinical deterioration; Nursing education; Nursing practice; Online learning; Transfer of learning; Web-based simulation","clinical practice; comparative effectiveness; deterioration; doctor patient relation; emergency care; human; human experiment; information processing; learning; model; motivation; nurse; nursing education; nursing practice; pretest posttest design; questionnaire; recognition; tertiary care center; workplace; adult; female; Internet; learning; male; nurse; standards; utilization; workplace; Adult; Female; Humans; Internet; Learning; Male; Nurses; Surveys and Questionnaires; Workplace",Article,"Final","",Scopus,2-s2.0-84962061536
"Lu X.-Q., Davis S.R.","57157731400;7405958602;","Priming effects on people’s safety decision in a virtual reality construction simulator",2016,"Civil Engineering and Urban Planning IV - Proceedings of the 4th International Conference on Civil Engineering and Urban Planning, CEUP 2015",,,,"501","505",,,"10.1201/b19880-94","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016748831&doi=10.1201%2fb19880-94&partnerID=40&md5=d3881ff710ca41f39d4e2ac3088122cf","University of New South Wales, Sydney, Australia","Lu, X.-Q., University of New South Wales, Sydney, Australia; Davis, S.R., University of New South Wales, Sydney, Australia","A Virtual Reality (VR) simulation is the imitation of a real-world process or system in a virtual environment. It has been considered to assist training in many fields. This study investigated the priming effects on people’s safety decision in a virtual construction simulator, in order to improve the design of a virtual reality simulator to be used in training. Preliminary study results show that the addition of priming factors to a VR simulator contributes to people’s sense of presence in a virtual environment. When people are primed by the concept of safety, they are more likely to perceive more risks and observe the environment carefully. Limitations of the research are that it applies to a specific problem and results need to be generalized over a larger set of problems. Future research is required to collect data over a large sample size. © 2016 Taylor & Francis Group, London.",,"Safety engineering; Simulators; Urban planning; Priming effects; Real-world process; Sample sizes; Sense of presences; Specific problems; Virtual construction; Virtual reality simulator; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85016748831
"Nathanael D., Mosialos S., Vosniakos G.-C., Tsagkas V.","6506068895;14058702100;6701789136;37105230000;","Development and Evaluation of a Virtual Reality Training System Based on Cognitive Task Analysis: The Case of CNC Tool Length Offsetting",2016,"Human Factors and Ergonomics In Manufacturing","26","1",,"52","67",,12,"10.1002/hfm.20613","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955099078&doi=10.1002%2fhfm.20613&partnerID=40&md5=8a1e68c2850b77abc085eb5d383bc1f5","School of Mechanical Engineering, National Technical University of Athens, Zografou, GR-15780, Greece","Nathanael, D., School of Mechanical Engineering, National Technical University of Athens, Zografou, GR-15780, Greece; Mosialos, S., School of Mechanical Engineering, National Technical University of Athens, Zografou, GR-15780, Greece; Vosniakos, G.-C., School of Mechanical Engineering, National Technical University of Athens, Zografou, GR-15780, Greece; Tsagkas, V., School of Mechanical Engineering, National Technical University of Athens, Zografou, GR-15780, Greece","This article reports on the development and evaluation of a virtual reality training system (VRTS) for a specific machining task. A cognitive task analysis of expert machinists was conducted to examine whether this can be effective in developing a VRTS concerning tool length offsetting for a machining center. This analysis provided the necessary information for development and calibration of such a system. Subsequently, the effectiveness of the VRTS was evaluated by conducting an experiment with 29 mechanical engineering students. The VRTS set-up comprised a video projection of the machining center and a physical mock-up of its interface. The system demonstrated positive training transfer for the toll length offsetting task in terms of task accomplishment and of time to complete the task. No positive transfer was observed in terms of task accuracy, probably due to perceptual biases induced by the detailed specification of the VRTS. The present work provides evidence that cognitive task analysis was effective in identifying a number of key skills pertaining to the tool length offsetting task and in implementing ways to facilitate training in such tasks in a virtual environment. This article also demonstrates that even for tasks that include subtle perceptual skills VRTS may be beneficial regardless of the level of physical fidelity, provided that the cognitive organization of a task is adequately mapped in the system. © 2014 Wiley Periodicals, Inc.","CNC machining; Perceptual skills; Simulation; Training; Virtual reality","Job analysis; Machining; Machining centers; Personnel training; Virtual reality; Cnc machining; Cognitive organization; Cognitive task analysis; Mechanical engineering students; Perceptual skills; Simulation; Task accomplishment; Virtual reality training; E-learning",Article,"Final","",Scopus,2-s2.0-84955099078
"Fordell H., Bodin K., Eklund A., Malm J.","36863417800;36141751000;56417299600;56251047600;","RehAtt – Scanning training for neglect enhanced by multi-sensory stimulation in virtual reality",2016,"Topics in Stroke Rehabilitation","23","3",,"191","199",,13,"10.1080/10749357.2016.1138670","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976589910&doi=10.1080%2f10749357.2016.1138670&partnerID=40&md5=6727d51c16e6aca715bdaf7273ebe3c4","Department of Pharmacology and Clinical Neuroscience, Umeå University, Sweden; Department of Computing Science (HPC2N and UMIT), Umeå University, Sweden; Department of Radiation Sciences, Umeå University, Sweden","Fordell, H., Department of Pharmacology and Clinical Neuroscience, Umeå University, Sweden; Bodin, K., Department of Computing Science (HPC2N and UMIT), Umeå University, Sweden; Eklund, A., Department of Radiation Sciences, Umeå University, Sweden; Malm, J., Department of Pharmacology and Clinical Neuroscience, Umeå University, Sweden","Background: There is a lack of effective treatment for neglect. We have developed a new training method, RehAtt™. The objective of this study was to determine whether RehAtt™ improves spatial attention in chronic neglect after stroke. Methods: RehAtt™ consists of a computer with monitor, 3D glasses, and a force feedback interface (Robotic pen) giving sensory motor activation to the contra-lesional arm. The software combines visual scanning training with multi-sensory stimulation in 3D virtual reality (VR) game environment. Fifteen stroke patients with chronic neglect (duration > 6 month) had repeated baseline evaluations to confirm stability of symptoms. There were no test–retest effects for any of the tests. Thereafter, all patients trained 15 h in RehAtt™ (3 x 1 h for 5 weeks). A neglect test battery and Catherine Bergego Scale, CBS, were used to assess behavioral outcome after intervention. CBS was also used at a 6-month follow-up. Results: Using repeated measurement analysis improvements due to the training were found for Star cancellation test (p = 0.006), Baking tray task (p < 0.001), and Extinction test (p = 0.05). In the Posner task improvements were seen fewer missed targets (p = 0.024). CBS showed improvements in activities of daily life immediately after training (p < 0.01). After 6 months the patients still reported improvement in CBS. Conclusion: RehAtt™ is a new concept for rehabilitation of neglect. Training with the VR-method improved spatial attention and showed transfer to improved spatial attention in activities of daily living in chronic neglect. Our results are promising and merit further studies. © 2015 Informa UK Limited, trading as Taylor & Francis Group.","Attention; Cognitive rehabilitation; Spatial neglect; Stroke; Treatment; Virtual reality","aged; Article; attention; attention test; Baking tray task; cancellation test; cerebrovascular accident; clinical article; computer; computer program; disease duration; Extinction test; feedback system; female; human; male; monitor; Posner task; sensory stimulation; spectacles; Star cancellation test; stroke patient; task performance; virtual reality; visual deprivation; cerebrovascular accident; complication; daily life activity; depth perception; devices; outcome assessment; perception disorder; physiology; procedures; stroke rehabilitation; transfer of learning; Activities of Daily Living; Aged; Attention; Female; Humans; Male; Outcome Assessment (Health Care); Perceptual Disorders; Space Perception; Stroke; Stroke Rehabilitation; Transfer (Psychology); Virtual Reality",Article,"Final","",Scopus,2-s2.0-84976589910
"Alghamdi M., Regenbrecht H., Hoermann S., Langlotz T., Aldridge C.","36459710000;6603333462;54787745300;8250843500;57062294500;","Social presence and mode of video communication in a Collaborative Virtual Environment",2016,"Pacific Asia Conference on Information Systems, PACIS 2016 - Proceedings",,,,"","",,6,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011117105&partnerID=40&md5=0235f7bf3ef9f4bdceecd4b42a98b91e","Department of Information Science, University of Otago, New Zealand; School of Electrical and Information Engineering, University of Sydney, Sydney, Australia","Alghamdi, M., Department of Information Science, University of Otago, New Zealand; Regenbrecht, H., Department of Information Science, University of Otago, New Zealand; Hoermann, S., School of Electrical and Information Engineering, University of Sydney, Sydney, Australia; Langlotz, T., Department of Information Science, University of Otago, New Zealand; Aldridge, C., Department of Information Science, University of Otago, New Zealand","Collaborative Virtual Environments (CVE) with co-located or remote video communication functionality require a continuous experience of social presence. If, at any stage during the experience the communication interrupts presence then the CVE experience as a whole is affected - spatial presence is then decoupled from social presence. We present a solution to this problem by introducing the concept of a virtualized version of Google Glass™ called Virtual Glass. Virtual Glass is integrated into the CVE as a real-world metaphor for a communication device, one particularly suited for collaborative instructor-performer systems. Together with domain experts we developed a prototype system based on an instructor-performer architecture. In two studies with a total number of 115 participants we showed that the concept of Virtual Glass is effective, that it supports a high level of social presence and that the social presence for the performers is rated significantly higher than a standard picture-in-picture videoconferencing approach used for the performers. We present our experimental system, our studies, and the generalizability of our approach towards future uses.","Human-computer interface; Videoconferencing; Virtual reality","Display devices; Glass; Human computer interaction; Information systems; Video conferencing; Collaborative virtual environment; Communication device; Domain experts; Experimental system; Human computer interfaces; Prototype system; Social presence; Video communications; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85011117105
"Milanovic I., Eppes T.","6602855434;6603542302;","Application building in undergraduate courses with a simulation component",2016,"American Society of Mechanical Engineers, Fluids Engineering Division (Publication) FEDSM","2",, 7844,"","",,7,"10.1115/FEDSM2016-7844","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021741416&doi=10.1115%2fFEDSM2016-7844&partnerID=40&md5=eb4514ab72d920843d1e0d700818b300","University of Hartford, West Hartford, CT, United States","Milanovic, I., University of Hartford, West Hartford, CT, United States; Eppes, T., University of Hartford, West Hartford, CT, United States","The undergraduate engineering curriculum at our institution is replete with both problem-based and project-based learning components. This paper focuses on the third and most complex methodology needed to prepare students for a successful career in engineering: inquiry-based learning (IBL). With IBL, students learn with the aid of mentoring how to develop and answer a research question. However, IBL requires a significant timeinvestment, both in and outside the classroom. This is one of the teaching challenges within lecture-based thermo-fluids courses, where the coverage of required material does not allow much time for both IBL and development of field-specific simulation skills. Additional challenges include the reliance on mathematical tools that often hamper student understanding of the underlying phenomena and difficulty in providing immersive and exciting visuals that support in-depth learning. An IBL component was incorporated into a simulationbased design in two successive junior year courses: fluid mechanics and heat transfer. Both courses were modified to contain scaffolded and contextualized simulations with application building that develop: (a) technical competency by developing modeling skills, (b) deeper understanding of thermofluids by solving realistic technological problems, and (c) writing skills by producing technical reports for each simulation. Companies are increasingly using simulation applications to extend the benefits of product and process models beyond engineering to other internal business functions such as manufacturing, product development, and sales technical support. Applications involve creating a simplified interface that still contains the full efficacy of the underlying model without having to expose the end user to its complexity. An 'Application' building component adds a new skillset that further strengthens our program graduates. Consequently, supported by mentoring, students now integrate prior skills into an independent research initiative. They propose, plan and execute a design that is of their interest, relevant to the course topics, and suitable in rigor. In parallel with skillset and technical knowledge building, strategies and resources are introduced to engage students in a research topic of their choosing. This process includes preparing a statement of work, reviewing relevant literature, completing a technical study, and documenting the results. The results to date are presented along with some examples of student projects. © 2016 by ASME.",,"Application programs; Curricula; Education computing; Engineering education; Fluid mechanics; Heat transfer; Microchannels; Professional aspects; Students; Teaching; Inquiry based learning (IBL); Project based learning; Simulation applications; Simulation components; Simulation-based designs; Technical competencies; Undergraduate Courses; Undergraduate engineering; Education",Conference Paper,"Final","",Scopus,2-s2.0-85021741416
"Mihaljevic S.E., Howard V.M.","57027560000;30267681900;","Incorporating interprofessional evidenced-based sepsis simulation education for certified nursing assistants (cnas) and licensed care providers within long-term care settings for process and quality improvement",2016,"Critical Care Nursing Quarterly","39","1",,"24","33",,2,"10.1097/CNQ.0000000000000092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952360100&doi=10.1097%2fCNQ.0000000000000092&partnerID=40&md5=75a7abb1cdfe4c360a92e6dc3dd73f22","Robert Morris University, RISE Center, Moon Township, PA, United States; Robert Morris University, School of Nursing and Health Sciences, Moon Township, PA, United States; Carlow University, 3333 Fifth Avenue, Pittsburgh, PA  15213, United States","Mihaljevic, S.E., Carlow University, 3333 Fifth Avenue, Pittsburgh, PA  15213, United States; Howard, V.M., Robert Morris University, RISE Center, Moon Township, PA, United States, Robert Morris University, School of Nursing and Health Sciences, Moon Township, PA, United States","Improving resident safety and quality of care by maximizing interdisciplinary communication among long-term care providers is essential in meeting the goals of the United States' Federal Health care reform. The new Triple Aim goals focus on improved patient outcomes, increasing patient satisfaction, and decreased health care costs, thus providing consumers with quality, efficient patient-focused care. Within the United States, sepsis is the 10th leading cause of death with a 28.6% mortality rate in the elderly, increasing to 40% to 60% in septic shock. As a result of the Affordable Care Act, the Centers for Medicare &Medicaid services supported the Interventions to Reduce Acute Care Transfers 3.0 program to improve health care quality and prevent avoidable rehospitalization by improving assessment, documentation, and communication among health care providers. The Interventions to Reduce Acute Care Transfers 3.0 tools were incorporated in interprofessional sepsis simulations throughout 19 long-term care facilities to encourage the early recognition of sepsis symptoms and prompt communication of sepsis symptoms among interdisciplinary teams. As a result of this simulation training, many long-term care organizations have adopted the STOP and WATCH and SBAR tools as a venue to communicate resident condition changes. Copyright © 2016 Wolters Kluwer Health, Inc. All rights reserved.","evidenced-based; Interdisciplinary team; Long-term care; SBAR; sepsis; Simulation","Article; cause of death; disease simulation; evidence based practice; health care personnel; health care policy; health care quality; hospital readmission; hospitalization; human; interdisciplinary communication; long term care; medicaid; medical education; medicare; nursing assistant; patient safety; sepsis; septic shock; simulation training; staff training; total quality management; education; intensive care; interdisciplinary communication; long term care; nursing assistant; procedures; sepsis; total quality management; United States; Critical Care; Evidence-Based Practice; Humans; Interdisciplinary Communication; Long-Term Care; Nurses' Aides; Patient Protection and Affordable Care Act; Quality Improvement; Sepsis; Shock, Septic; Simulation Training; United States",Article,"Final","",Scopus,2-s2.0-84952360100
"De Win G., Van Bruwaene S., Kulkarni J., Van Calster B., Aggarwal R., Allen C., Lissens A., De Ridder D., Miserez M.","12779954100;26536965100;57221100849;57203255765;8616911800;57221111250;6507545871;57221084691;6603926707;","An evidence-based laparoscopic simulation curriculum shortens the clinical learning curve and reduces surgical adverse events",2016,"Advances in Medical Education and Practice","7",,,"357","370",,24,"10.2147/AMEP.S102000","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006285535&doi=10.2147%2fAMEP.S102000&partnerID=40&md5=a4bfa56b0f3ba2abab563f248f7ec18e","Department of Urology, Antwerp University Hospital, Belgium; Faculty of Health Sciences, University of Antwerp, Antwerp, Belgium; Department of Urology, University Hospitals of KU Leuven, Belgium; Centre for Surgical Technologies, KU Leuven, Leuven, Belgium; Kulkarni Endo Surgery Institute, Pune, India; Department of Development and Regeneration, KU Leuven, Leuven, Belgium; Department of Surgery, Faculty of Medicine, McGill University, Montreal, QC, Canada; Steinberg Centre for Simulation and Interactive Learning, Faculty of Medicine, McGill University, Montreal, QC, Canada; School of Arts and Sciences, University of Pennsylvania, Philadelphia, PA, United States; Department of Abdominal Surgery, University Hospitals Leuven, Leuven, Belgium","De Win, G., Department of Urology, Antwerp University Hospital, Belgium, Faculty of Health Sciences, University of Antwerp, Antwerp, Belgium; Van Bruwaene, S., Department of Urology, University Hospitals of KU Leuven, Belgium, Centre for Surgical Technologies, KU Leuven, Leuven, Belgium; Kulkarni, J., Kulkarni Endo Surgery Institute, Pune, India; Van Calster, B., Department of Development and Regeneration, KU Leuven, Leuven, Belgium; Aggarwal, R., Department of Surgery, Faculty of Medicine, McGill University, Montreal, QC, Canada, Steinberg Centre for Simulation and Interactive Learning, Faculty of Medicine, McGill University, Montreal, QC, Canada; Allen, C., School of Arts and Sciences, University of Pennsylvania, Philadelphia, PA, United States; Lissens, A., Centre for Surgical Technologies, KU Leuven, Leuven, Belgium; De Ridder, D., Department of Urology, University Hospitals of KU Leuven, Belgium; Miserez, M., Centre for Surgical Technologies, KU Leuven, Leuven, Belgium, Department of Abdominal Surgery, University Hospitals Leuven, Leuven, Belgium","Background: Surgical simulation is becoming increasingly important in surgical education. However, the method of simulation to be incorporated into a surgical curriculum is unclear. We compared the effectiveness of a proficiency-based preclinical simulation training in laparoscopy with conventional surgical training and conventional surgical training interspersed with standard simulation sessions. Materials and methods: In this prospective single-blinded trial, 30 final-year medical students were randomized into three groups, which differed in the way they were exposed to laparoscopic simulation training. The control group received only clinical training during residency, whereas the interval group received clinical training in combination with simulation training. The Center for Surgical Technologies Preclinical Training Program (CST PTP) group received a proficiency-based preclinical simulation course during the final year of medical school but was not exposed to any extra simulation training during surgical residency. After 6 months of surgical residency, the influence on the learning curve while performing five consecutive human laparoscopic cholecystectomies was evaluated with motion tracking, time, Global Operative Assessment of Laparoscopic Skills, and number of adverse events (perforation of gall bladder, bleeding, and damage to liver tissue). Results: The odds of adverse events were 4.5 (95% confidence interval 1.3–15.3) and 3.9 (95% confidence interval 1.5–9.7) times lower for the CST PTP group compared with the control and interval groups. For raw time, corrected time, movements, path length, and Global Operative Assessment of Laparoscopic Skills, the CST PTP trainees nearly always started at a better level and were never outperformed by the other trainees. Conclusion: Proficiency-based preclinical training has a positive impact on the learning curve of a laparoscopic cholecystectomy and diminishes adverse events. © 2016 De Win et al.","Laparoscopy; Learning curve; Simulation; Transfer of skills",,Article,"Final","",Scopus,2-s2.0-85006285535
"Antoniou P.E., Dafli E., Bamidis P.D.","56237199800;35753237600;6603398831;","Design of novel teaching episodes in medical education using emerging experiential digital assets; technology enabled medical education beyond the Gimmicky",2015,"Proceedings - 15th IEEE International Conference on Computer and Information Technology, CIT 2015, 14th IEEE International Conference on Ubiquitous Computing and Communications, IUCC 2015, 13th IEEE International Conference on Dependable, Autonomic and Secure Computing, DASC 2015 and 13th IEEE International Conference on Pervasive Intelligence and Computing, PICom 2015",,, 7363280,"1560","1565",,2,"10.1109/CIT/IUCC/DASC/PICOM.2015.360","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964308542&doi=10.1109%2fCIT%2fIUCC%2fDASC%2fPICOM.2015.360&partnerID=40&md5=bb402e284e22108407dcce7ed5955125","Medical Physics Laboratory, Medical School Aristotle University of Thessaloniki, Thessaloniki, Greece","Antoniou, P.E., Medical Physics Laboratory, Medical School Aristotle University of Thessaloniki, Thessaloniki, Greece; Dafli, E., Medical Physics Laboratory, Medical School Aristotle University of Thessaloniki, Thessaloniki, Greece; Bamidis, P.D., Medical Physics Laboratory, Medical School Aristotle University of Thessaloniki, Thessaloniki, Greece","Medical education has always been about experiential hands on training to prepare future doctors to create the necessary skillset to deal with the sensitive and immediate nature of their work. Contemporary experiential technologies such as Virtual and Augmented reality offer a realistic but consequence free test-bed in which to interact safely and cope with emotional challenges pertaining to the realistic tasks simulated through these media. This work describes the design guidelines and workflow for incorporating these novel virtual assets in medical education through serious role play learning episodes. This approach consists of the case selection, the identification of roles, information flow and narrative requirements, implementation of technological narrative tools and implementation of the learning episode. Using a specific example of case transfer through this model we describe the process, outline implementation, assessment and technological considerations. Finally rationale for this work as a counterweight to technological hype fluctuations and integration of these media into the mainstream curricula is discussed. © 2015 IEEE.","Autgmented reality; Medical education; Serious role play; Virtual reality; Virtual worlds","Augmented reality; Curricula; Education; Medical education; Personnel training; Ubiquitous computing; Virtual reality; Autgmented reality; Case selections; Digital assets; Hands-on-trainings; Information flows; Role play; Virtual and augmented reality; Virtual worlds; Engineering education",Conference Paper,"Final","",Scopus,2-s2.0-84964308542
"Allain K., Dado B., Gelderen M.V., Hokke O., Oliveira M., Bidarra R., Gaubitch N.D., Hendriks R.C., Kybartas B.","57188864917;57188867795;57188866678;57188868769;56260321500;6602846970;14825163800;7005452305;56120159200;","An audio game for training navigation skills of blind children",2015,"2015 IEEE 2nd VR Workshop on Sonic Interactions for Virtual Environments, SIVE 2015 - Proceedings",,, 7361292,"49","52",,13,"10.1109/SIVE.2015.7361292","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963935798&doi=10.1109%2fSIVE.2015.7361292&partnerID=40&md5=41ebe438968f6467bd23d886adbdf9b1","Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands","Allain, K., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands; Dado, B., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands; Gelderen, M.V., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands; Hokke, O., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands; Oliveira, M., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands; Bidarra, R., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands; Gaubitch, N.D., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands; Hendriks, R.C., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands; Kybartas, B., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands","Training blind children to use audio-based navigation is a demanding and risky task, as children can walk into objects and hurt themselves. Furthermore, training outdoors is dangerous due to traffic, noise and weather conditions. Having a controlled indoor environment is safer but not always available. To tackle this problem, we developed an audio-based computer game, Legend of Iris (LOI), specifically designed to train navigation skills. The game is a 3D exploration game, which uses the headtracking capabilities of the Oculus Rift to create an immersive experience, and the new sound libraries AstoundSound and Phonon3D, to generate an accurate and realistic soundscape. These libraries use a head-related transfer function, allowing the player to localize the audio source in 3D space. The design of LOI involved selecting sounds that are easily recognizable to provide cues to blind people playing the game. A subset of these cues were incorporated into the game. To verify the effectiveness of the game in developing audio orientation and navigation skills, we performed a preliminary qualitative experiment with blind children in a dedicated school. LOI scored high in terms of accuracy and immersion, but a larger test is required to make statistical conclusions. © 2015 IEEE.",,"Libraries; Motion compensation; Navigation; Virtual reality; 3d explorations; Audio sources; Audio-based navigation; Blind children; Head related transfer function; Indoor environment; Orientation and navigation; Qualitative experiments; Computer games",Conference Paper,"Final","",Scopus,2-s2.0-84963935798
"Zünd F., Bérard P., Chapiro A., Schmid S., Ryffel M., Gross M., Bermano A.H., Sumner R.W.","56104206700;56437364600;32867535500;54400459700;56439932500;7403745074;53983538400;9040664600;","Unfolding the 8-Bit Era",2015,"ACM International Conference Proceeding Series","24-25-November-2015",, 9,"","",,,"10.1145/2824840.2824848","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959317581&doi=10.1145%2f2824840.2824848&partnerID=40&md5=5cbb578c8d211a59ee5060964373cfcd","ETH Zurich, Universitätsstrasse 8, Zürich, 8092, Switzerland; Disney Research Zurich, Stampfenbachstrasse 48, Zürich, 8006, Switzerland","Zünd, F., ETH Zurich, Universitätsstrasse 8, Zürich, 8092, Switzerland; Bérard, P., ETH Zurich, Universitätsstrasse 8, Zürich, 8092, Switzerland, Disney Research Zurich, Stampfenbachstrasse 48, Zürich, 8006, Switzerland; Chapiro, A., ETH Zurich, Universitätsstrasse 8, Zürich, 8092, Switzerland, Disney Research Zurich, Stampfenbachstrasse 48, Zürich, 8006, Switzerland; Schmid, S., ETH Zurich, Universitätsstrasse 8, Zürich, 8092, Switzerland, Disney Research Zurich, Stampfenbachstrasse 48, Zürich, 8006, Switzerland; Ryffel, M., Disney Research Zurich, Stampfenbachstrasse 48, Zürich, 8006, Switzerland; Gross, M., ETH Zurich, Universitätsstrasse 8, Zürich, 8092, Switzerland, Disney Research Zurich, Stampfenbachstrasse 48, Zürich, 8006, Switzerland; Bermano, A.H., ETH Zurich, Universitätsstrasse 8, Zürich, 8092, Switzerland, Disney Research Zurich, Stampfenbachstrasse 48, Zürich, 8006, Switzerland; Sumner, R.W., ETH Zurich, Universitätsstrasse 8, Zürich, 8092, Switzerland, Disney Research Zurich, Stampfenbachstrasse 48, Zürich, 8006, Switzerland","We propose a hardware and software system that transforms 8-bit side-scrolling console video games into immersive multiplayer experiences. We enhance a classic video game console with custom hardware that time-multiplexes eight gamepad inputs to automatically hand off control from one gamepad to the next. Because control transfers quickly, people at a large event can frequently step in and out of a game and naturally call to their peers to join any time a gamepad is vacant. Video from the game console is captured and processed by a vision algorithm that stitches it into a continuous, expanding panoramic texture, which is displayed in real time on a 360 degree projection system at a large event space. With this system, side-scrolling games unfold across the walls of the room to encircle a large party, giving the feeling that the entire party is taking place inside of the game's world. When such a display system is not available, we also provide a virtual reality recreation of the experience. We show results of our system for a number of classic console games tested at a large live event. Results indicate that our work provides a successful recipe to create immersive, multiplayer, interactive experiences that leverage the nostalgic appeal of 8-bit games. © 2015 ACM.","Games; Panoramic stitching; Virtual reality","Display devices; Hardware; Interactive computer graphics; Reconfigurable hardware; Virtual reality; Custom hardwares; Display system; Game consoles; Games; Hardware and software; Panoramic stitching; Video game consoles; Vision algorithms; Human computer interaction",Conference Paper,"Final","",Scopus,2-s2.0-84959317581
"Dedmon M.M., Paddle P.M., Phillips J., Kobayashi L., Franco R.A., Song P.C.","56045566400;23971103300;56822763200;6602256106;7202551215;54885669600;","Development and Validation of a High-Fidelity Porcine Laryngeal Surgical Simulator",2015,"Otolaryngology - Head and Neck Surgery (United States)","153","3",,"420","426",,21,"10.1177/0194599815590118","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940974575&doi=10.1177%2f0194599815590118&partnerID=40&md5=e0a05e29646923ca593dffa5485109a9","Department of Otology and Laryngology, Harvard Medical School, Boston, MA, United States; Department of Otolaryngology, Massachusetts Eye and Ear Infirmary, 243 Charles St, Boston, MA  02114, United States; Department of Emergency Medicine, Rhode Island Hospital, Providence, RI, United States","Dedmon, M.M., Department of Otology and Laryngology, Harvard Medical School, Boston, MA, United States, Department of Otolaryngology, Massachusetts Eye and Ear Infirmary, 243 Charles St, Boston, MA  02114, United States; Paddle, P.M., Department of Otology and Laryngology, Harvard Medical School, Boston, MA, United States, Department of Otolaryngology, Massachusetts Eye and Ear Infirmary, 243 Charles St, Boston, MA  02114, United States; Phillips, J., Department of Otology and Laryngology, Harvard Medical School, Boston, MA, United States, Department of Otolaryngology, Massachusetts Eye and Ear Infirmary, 243 Charles St, Boston, MA  02114, United States; Kobayashi, L., Department of Emergency Medicine, Rhode Island Hospital, Providence, RI, United States; Franco, R.A., Department of Otology and Laryngology, Harvard Medical School, Boston, MA, United States, Department of Otolaryngology, Massachusetts Eye and Ear Infirmary, 243 Charles St, Boston, MA  02114, United States; Song, P.C., Department of Otology and Laryngology, Harvard Medical School, Boston, MA, United States, Department of Otolaryngology, Massachusetts Eye and Ear Infirmary, 243 Charles St, Boston, MA  02114, United States","Objective Design and validate a laryngeal surgical simulator to teach phonomicrosurgical techniques. Study Design Device development and prospective validation. Setting Tertiary medical center. Subjects and Methods A novel laryngeal fixation device and custom laryngoscope were produced for use with ex vivo porcine larynx specimens. Vocal fold lesions such as nodules and keratotic lesions were simulated with silicone injections and epithelial markings. A prospective validation using postsimulation surveys, global rating scales, and procedure-specific checklists was performed with a group of 15 medical students, otolaryngology residents, fellows, and attending laryngologists. Three procedures were performed: vocal fold augmentation, excision of a simulated vocal fold nodule, and excision of a simulated vocal fold keratosis. Results Participants overwhelmingly agreed that the simulator provided a realistic dissection experience that taught skills that would transfer to real operating scenarios. Expert performance was statistically superior to novice performance for excision of simulated vocal fold nodules and keratotic lesions, while no difference was observed for injection laryngoplasty. Conclusion The ability to learn and rehearse surgical procedures in a safe environment is invaluable, particularly for delicate and highly technical phonomicrosurgical operations. We have developed a high-fidelity laryngeal surgical simulator complete with pathological lesions such as nodules and keratoses to teach these procedures. A prospective study demonstrated validity of our global rating scale and checklist assessments for vocal fold nodule and keratosis excision procedures, allowing them to be confidently incorporated into phonomicrosurgical training programs for surgeons of all levels of expertise. © Official journal of the American Academy of Otolaryngology-Head and Neck Surgery Foundation 2015.","education; laryngeal surgery; laryngology; phonomicrosurgery; simulation; validation","adult; animal tissue; Article; checklist; controlled study; cricoid; ex vivo study; face validity; female; freestanding laryngeal fixator; human; instrument validation; interrater reliability; intrarater reliability; laryngoplasty; laryngoscope; Likert scale; male; medical education; medical student; nonhuman; otolaryngologist; outcome assessment; professional competence; professional knowledge; rating scale; resident; scoring system; simulation; simulator; surgical anatomy; surgical microscope; surgical technique; surgical training; animal; audiovisual equipment; disease model; education; equipment design; larynx; medical education; microsurgery; otorhinolaryngology; pig; prospective study; reproducibility; surgery; validation study; videorecording; Adult; Animals; Checklist; Disease Models, Animal; Education, Medical, Continuing; Education, Medical, Graduate; Equipment Design; Female; Humans; Laryngoscopes; Larynx; Male; Microsurgery; Models, Anatomic; Otolaryngology; Prospective Studies; Reproducibility of Results; Swine; Video Recording",Article,"Final","",Scopus,2-s2.0-84940974575
"Qidwai U., Ajimsha M.S.","6602234511;36935923900;","Can immersive type of Virtual Reality bring EMG pattern changes post facial palsy?",2015,"Proceedings of the 2015 Science and Information Conference, SAI 2015",,, 7237227,"756","760",,,"10.1109/SAI.2015.7237227","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957837199&doi=10.1109%2fSAI.2015.7237227&partnerID=40&md5=35218ea6df1ae0cac754bc35808d59db","KINDI Lab for Computing Research, Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Physiotherapy Specialist, Dept. of Physical Therapy, Hamad Medical Corporation, Doha, Qatar","Qidwai, U., KINDI Lab for Computing Research, Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Ajimsha, M.S., Physiotherapy Specialist, Dept. of Physical Therapy, Hamad Medical Corporation, Doha, Qatar","The loss of facial expression via facial paralysis is a devastating condition, both functionally and aesthetically. However, given the life-long plasticity of the brain one could assume that recovery could be facilitated by the harnessing of mechanisms underlying neuronal reorganization. Currently it is not clear how this reorganization can be mobilized. Novel technology based neurorehabilitation techniques hold promise to address this issue. In this paper an immersive Virtual Reality (VR) based system is presented that is based on a number of hypotheses related to the neural structures targeted for recovery/reorganization, the structure of training system, and the role of individualization. The purpose of this paper is to examine the effects of an immersive type virtual reality (VR) intervention on activation of facial upper quadrant muscles following facial palsy in comparison with a control program. The key components of an immersive Virtual Reality (VR) based system and its effectiveness on facial palsy rehabilitation has been described in the form of experimental findings. Experimental trial was performed on an individual with facial upper quadrant muscles weakness due to facial palsy in a crossover study methodology with and without VR. EMG patterns from the facial upper quadrant muscles were recorded and analyzed for results. This trial has plotted a positive relationship between VR and facial upper quadrant muscles activation following a neurological impetus. The results reported here also show a consistent transfer of movement kinematics between physical and virtual tasks. EMG analysis has shown progressing improvement in the muscle activation in response to the challenging and impulsive activities in the virtual environment provided by the immersive VR devise. © 2015 IEEE.","EMG-based measurements; Facial palsy; Impulsive impetus; Virtual Reality","Activation analysis; Chemical activation; Muscle; Experimental trials; Facial Expressions; Facial palsy; Immersive virtual reality; Impulsive impetus; Movement kinematics; Neural structures; Neurorehabilitation; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84957837199
"Katz B.F.G., Felinto D.Q., Touraine D., Poirier-Quinot D., Bourdot P.","35557015800;54788920100;6506895230;55613431100;14051447300;","BlenderVR: Open-source framework for interactive and immersive VR",2015,"2015 IEEE Virtual Reality Conference, VR 2015 - Proceedings",,, 7223366,"203","204",,12,"10.1109/VR.2015.7223366","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954548555&doi=10.1109%2fVR.2015.7223366&partnerID=40&md5=9cd4b67baa192a1ea65bdcc275d8639b","LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France","Katz, B.F.G., LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France; Felinto, D.Q., LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France; Touraine, D., LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France; Poirier-Quinot, D., LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France; Bourdot, P., LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France","BlenderVR is an open-source project framework for interactive and immersive applications based on an extension of the Blender Game Engine to Virtual Reality applications. BlenderVR is a generalization of the BlenderCAVE project, accounting for alternate platforms (e.g., HMD, video-walls). The goal is to provide a flexible and easy to use framework for the creation of VR applications for various platforms, making use of the existing power of the BGE's graphics rendering and physics engine. Compatible with 3 major Operating Systems, BlenderVR has been developed by VR researchers with support from the Blender Community. BlenderVR currently handles multi-screen/multi-user tracked stereoscopic rendering through efficient low-level master/slave synchronization process with multimodal interactions via OSC and VRPN protocols. © 2015 IEEE.","H.5.1 [Multimedia Information Systems]: Artificial, augmented, and virtual realities; I.3.2 [Graphics Systems]: Distributed/network graphics","Blending; Computer graphics; Stereo image processing; Three dimensional computer graphics; Virtual reality; Distributed/network graphics; H.5.1 [multimedia information systems]: artificial , augmented , and virtual realities; Immersive application; Multi-Modal Interactions; Open source frameworks; Open source projects; Stereoscopic renderings; Synchronization process; Rendering (computer graphics)",Conference Paper,"Final","",Scopus,2-s2.0-84954548555
"Bertrand J., Brickler D., Babu S., Madathil K., Zelaya M., Wang T., Wagner J., Gramopadhye A., Luo J.","55858839700;57063224300;9039004700;37075253800;24345548300;55858602500;55693743100;7005569103;57217336220;","The role of dimensional symmetry on bimanual psychomotor skills education in immersive virtual environments",2015,"2015 IEEE Virtual Reality Conference, VR 2015 - Proceedings",,, 7223317,"3","10",,13,"10.1109/VR.2015.7223317","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954500994&doi=10.1109%2fVR.2015.7223317&partnerID=40&md5=d705a74c3695a12bc56f14ec051c3cba","Clemson University, United States","Bertrand, J., Clemson University, United States; Brickler, D., Clemson University, United States; Babu, S., Clemson University, United States; Madathil, K., Clemson University, United States; Zelaya, M., Clemson University, United States; Wang, T., Clemson University, United States; Wagner, J., Clemson University, United States; Gramopadhye, A., Clemson University, United States; Luo, J., Clemson University, United States","The need for virtual reality applications for education and training involving bimanual dexterous activities has been increasing in recent years. However, it is unclear how the amount of correspondence between a virtual interaction metaphor to the real-world equivalent, otherwise known as dimensional symmetry, affects bimanual pscyhomotor skills training and how skills learned in the virtual simulation transfer to the real world. How does the number of degrees of freedom enhance or hinder the learning process? Does the increase in dimensional symmetry affect cognitive load? In an empirical evaluation, we compare the effectiveness of a natural 6-DOF interaction metaphor to a simplified 3-DOF metaphor. Our simulation interactively educates users in the step-by-step process of taking a precise measurement using calipers and micrometers in a simulated technical workbench environment. We conducted a usability study to evaluate the user experience and pedagogical benefits using measures including a pre and post cognition questionnaire over all levels of Bloom's taxonomy, workload assessment, system usability, and real world psychomotor assessment tasks. Results from the pre and post cognition questionnaires suggest that learning outcomes improved throughout all levels of Bloom's taxonomy for both conditions, and trends in the data suggest that the 6-DOF metaphor was more effective in real-world skill transference compared to the 3-DOF metaphor. © 2015 IEEE.","Bimanual interaction; dimensional symmetry; psychomotor skills education","Blooms (metal); Degrees of freedom (mechanics); Education; Human computer interaction; Personnel training; Surveys; Taxonomies; Virtual reality; Bi-manual interaction; Education and training; Empirical evaluations; Immersive virtual environments; Interaction metaphors; Number of degrees of freedom; Precise measurements; Virtual interactions; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-84954500994
"Rousset T., Bourdin C., Goulon C., Monnoyer J., Vercher J.-L.","57063135900;6603566648;26535970800;57063170900;7004221343;","Does virtual reality affect visual perception of egocentric distance?",2015,"2015 IEEE Virtual Reality Conference, VR 2015 - Proceedings",,, 7223403,"277","278",,3,"10.1109/VR.2015.7223403","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954502515&doi=10.1109%2fVR.2015.7223403&partnerID=40&md5=7108f93a962da5ba619a2614530680f4","Aix Marseille Université, CNRS, ISM UMR 7287, Marseille, 13288, France; PSA Peugeot Citroën, Velizy Villacoublay, France","Rousset, T., Aix Marseille Université, CNRS, ISM UMR 7287, Marseille, 13288, France; Bourdin, C., Aix Marseille Université, CNRS, ISM UMR 7287, Marseille, 13288, France; Goulon, C., Aix Marseille Université, CNRS, ISM UMR 7287, Marseille, 13288, France; Monnoyer, J., PSA Peugeot Citroën, Velizy Villacoublay, France; Vercher, J.-L., Aix Marseille Université, CNRS, ISM UMR 7287, Marseille, 13288, France","Virtual reality (driving simulators) tends to generalize for the study of human behavior in mobility. It is thus crucial to ensure that perception of space and motion is little or not affected by the virtual environment (VE). The aim of this study was to determine a metrics of distance perception in VEs and whether this metrics depends on interactive factors: stereoscopy and motion parallax. After a training session, participants were asked, while driving, to estimate the relative location (5 to 80 m) of a car on the same road. The overall results suggest that distance perception in this range does not depend on interactive factors. In average, as generally reported, subjects underestimated the distances whatever the vision conditions. However, the study revealed a large interpersonal variability: two profiles of participants were defined, those who quite accurately perceived distances in VR and those who underestimated distances as usually reported. Overall, this classification was correlated to the level of performance of participants during the training phase. Furthermore, learning performance is predictive of the behavior of participants. © 2015 IEEE.","distance perception; Driving simulation; parallax; stereoscopy; variability","Behavioral research; Depth perception; Geometrical optics; Stereo image processing; Distance perception; Driving simulation; Driving simulator; Learning performance; parallax; Perceived distances; Relative location; variability; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84954502515
"Andrews S., Vincent J.B., McCormick J.","57185000800;57184835300;57197554028;","Duet: Improvising spatial dialogues with an artificially intelligent agent",2015,"SUI 2015 - Proceedings of the 3rd ACM Symposium on Spatial User Interaction",,,,"57","60",,,"10.1145/2788940.2788952","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961205751&doi=10.1145%2f2788940.2788952&partnerID=40&md5=217ef1efc54e66e4387fe530c4afaac3","Deakin University, 221 Burwood Highway, Burwood, VIC  3125, Australia","Andrews, S., Deakin University, 221 Burwood Highway, Burwood, VIC  3125, Australia; Vincent, J.B., Deakin University, 221 Burwood Highway, Burwood, VIC  3125, Australia; McCormick, J., Deakin University, 221 Burwood Highway, Burwood, VIC  3125, Australia","This paper presents an experimental framework for a virtual reality artwork, Duet, that employs a combination of live, full body motion capture and Oculus Rift HMD to construct an experience through which a human User can spatially interact with an artificially intelligent Agent. The project explores conceptual notions of embodied knowledge transfer, shared poetics of movement and distortions of the body schema. Within this context, both the User and the Agent become performers, constructing an intimate and spontaneously generated proximal space. The project generates a visualization of the relationship between the User and the Agent without the context of a fixed VR landscape or architecture. The Agent's ability to retain and accumulate movement knowledge in a way that mimics human learning transforms an interactive experience into a collaborative one. The virtual representation of both performers is distorted and amplified in a dynamic manner, enhancing the potential for creative dialogue between the Agent and the User. © 2015 ACM.","Aesthetic Interaction; Agents and Intelligent Systems; Embodiment; Performance; Virtual Reality","Intelligent agents; Intelligent systems; Knowledge management; Virtual reality; Aesthetic Interaction; Embodied knowledge; Embodiment; Full-body motions; Human learning; Performance; Proximal spaces; Virtual representations; Intelligent virtual agents",Conference Paper,"Final","",Scopus,2-s2.0-84961205751
"Ding L., Gao H.B., Deng Z.Q., Li Y.K., Liu G.J., Yang H.G., Yu H.T.","55705576600;13610503300;55536964400;56110332200;9276223000;56693135400;36803010800;","Three-layer intelligence of planetary exploration wheeled mobile robots: Robint, virtint, and humint",2015,"Science China Technological Sciences","58","8",,"1299","1317",,9,"10.1007/s11431-015-5853-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938423557&doi=10.1007%2fs11431-015-5853-9&partnerID=40&md5=4e08f26b67459d9c321e15e0ad7de284","State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, 150001, China; School of Aeronautics and Astronautics, University of Electronic Science and Technology of China, Chengdu, 611731, China; Department of Aerospace Engineering, Ryerson University, Toronto, M5B 2K3, Canada","Ding, L., State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, 150001, China; Gao, H.B., State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, 150001, China; Deng, Z.Q., State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, 150001, China; Li, Y.K., School of Aeronautics and Astronautics, University of Electronic Science and Technology of China, Chengdu, 611731, China; Liu, G.J., Department of Aerospace Engineering, Ryerson University, Toronto, M5B 2K3, Canada; Yang, H.G., State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, 150001, China; Yu, H.T., Department of Aerospace Engineering, Ryerson University, Toronto, M5B 2K3, Canada","The great success of the Sojourner rover in the Mars Pathfinder mission set off a global upsurge of planetary exploration with autonomous wheeled mobile robots (WMRs), or rovers. Planetary WMRs are among the most intelligent space systems that combine robotic intelligence (robint), virtual intelligence (virtint), and human intelligence (humint) synergetically. This article extends the architecture of the three-layer intelligence stemming from successful Mars rovers and related technologies in order to support the R&D of future tele-operated robotic systems. Double-layer human-machine interfaces are suggested to support the integration of humint from scientists and engineers through supervisory (Mars rovers) or three-dimensional (3D) predictive direct tele-operation (lunar rovers). The concept of multilevel autonomy to realize robint, in particular, the Coupled-Layer Architecture for Robotic Autonomy developed for Mars rovers, is introduced. The challenging issues of intelligent perception (proprioception and exteroception), navigation, and motion control of rovers are discussed, where the terrains’ mechanical properties and wheel-terrain interaction mechanics are considered to be key. Double-level virtual simulation architecture to realize virtint is proposed. Key technologies of virtint are summarized: virtual planetary terrain modeling, virtual intelligent rover, and wheel-terrain interaction mechanics. This generalized three-layer intelligence framework is also applicable to other systems that require human intervention, such as space robotic arms, robonauts, unmanned deep-sea vehicles, and rescue robots, particularly when there is considerable time delay. © 2015, Science China Press and Springer-Verlag Berlin Heidelberg.","planetary exploration rovers; robot intelligence; three-layer architecture; virtual intelligence","Degrees of freedom (mechanics); Interplanetary spacecraft; Landforms; Mobile robots; Robotics; Robots; Time delay; Virtual reality; Wheels; Human Machine Interface; Planetary exploration rovers; Robot intelligences; Scientists and engineers; Threedimensional (3-d); Threelayer architecture; virtual intelligence; Wheeled Mobile Robots (WMRs); Intelligent robots",Article,"Final","",Scopus,2-s2.0-84938423557
"Hvannberg E.T.","6506621646;","Identifying and explicating knowledge on method transfer: a sectoral system of innovation approach",2015,"Universal Access in the Information Society","14","2",,"187","202",,4,"10.1007/s10209-013-0340-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929521949&doi=10.1007%2fs10209-013-0340-1&partnerID=40&md5=77021117ba303cabb14f56d8a7ee6792","University of Iceland, Hjardarhagi 2-6, Reykjavik, 101, Iceland","Hvannberg, E.T., University of Iceland, Hjardarhagi 2-6, Reykjavik, 101, Iceland","With the advances in information technology and its increasing impact on humans and society, there has been an expanding need to spread knowledge from domain to domain. This need is not least in the area of human–computer interaction, which includes a rich culture of carrying out usability evaluations in many different domains and technology platforms. This paper aims to show how transfer of methods takes place, by explicating and formalizing the process. It will contribute to the quest for knowledge on the constituents of the process of transferring methodological knowledge and their relationships. A sectoral system of innovation approach is used to analyse the constituents of a selected sector, crisis management, where training is essential and which is rapidly adopting technology for operations and training. Two case studies are described where heuristics evaluation and user testing were applied on simulation software that allows training for crisis management. The analysis results in a process model, describing the transfer of methodological knowledge within the sectoral system of innovation framework. © 2013, Springer-Verlag Berlin Heidelberg.","Crisis management; Heuristics evaluation; Method transfer; User testing","Computer software; Human computer interaction; Computer interaction; Crisis management; Heuristics evaluation; Method transfers; Methodological knowledge; Technology platforms; Usability evaluation; User testing; Software testing",Article,"Final","",Scopus,2-s2.0-84929521949
"Parijat P., Lockhart T.E., Liu J.","24833394100;7004975783;55705866300;","Effects of Perturbation-Based Slip Training Using a Virtual Reality Environment on Slip-induced Falls",2015,"Annals of Biomedical Engineering","43","4",,"958","967",,24,"10.1007/s10439-014-1128-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926187937&doi=10.1007%2fs10439-014-1128-z&partnerID=40&md5=144d81d9dcb0dcd13bfb2462148f812b","School of Biomedical Engineering and Science, Virginia Tech, Blacksburg, VA, United States; School of Biological and Health Systems Engineering, Arizona State University, Tempe, AZ, United States; Division of Applied Science and Technology, Marshall University, One John Marshall Drive, CB 212, Huntington, WV  25755, United States","Parijat, P., School of Biomedical Engineering and Science, Virginia Tech, Blacksburg, VA, United States; Lockhart, T.E., School of Biological and Health Systems Engineering, Arizona State University, Tempe, AZ, United States; Liu, J., Division of Applied Science and Technology, Marshall University, One John Marshall Drive, CB 212, Huntington, WV  25755, United States","The purpose of the current study was to design and evaluate the effectiveness of virtual reality training in improving recovery reactions and reducing fall frequency in older adults. Twenty-four older adults were recruited and randomly assigned to two groups (virtual reality training and control). Both groups underwent three sessions including baseline slip, training and transfer of training on slippery surface. Both groups experienced two slips, one during baseline and the other during the transfer of training trial. The training group underwent 12 simulated slips using a visual perturbation induced by tilting a virtual reality scene while walking on the treadmill and the control group performed normal walking during the training session. Kinematic and kinetic data were collected during all the sessions. Results demonstrated a reduced incidence of falls in the training group during the transfer of training trial as compared to the control group. The training group was able to transfer reactive control strategies learned during training to the second slip trial. The reactive adjustments included reduced slip distance. Additionally, gait parameters reflective of gait instability (stride length, step width, variability in stride velocity) reduced after walking in the VR environment for 15–20 min. The results indicated a beneficial effect of the virtual reality training in reducing slip severity and recovery kinematics in healthy older adults. © 2014, Biomedical Engineering Society.","Biomechanics; Elderly; Fall prevention training; Falls; Virtual reality","Accident prevention; Biomechanics; Gait analysis; Kinematics; Virtual reality; Beneficial effects; Elderly; Fall prevention; Falls; Recovery reactions; Transfer of trainings; Virtual reality training; Virtual-reality environment; E-learning; accident prevention; aged; Article; biomechanics; controlled clinical trial; controlled study; falling; female; gait; ground reaction force; human; kinematics; kinetics; male; movement therapy; normal human; priority journal; treadmill; virtual reality; virtual reality training; biological model; clinical trial; comparative study; computer interface; falling; prevention and control; very elderly; walking; Accidental Falls; Aged; Aged, 80 and over; Biomechanical Phenomena; Female; Humans; Male; Models, Biological; User-Computer Interface; Walking",Article,"Final","",Scopus,2-s2.0-84926187937
"Grotzer T.A., Powell M.M., M. Derbiszewska K., Courter C.J., Kamarainen A.M., Metcalf S.J., Dede C.J.","8202631400;56462063200;56462993700;56462938900;21934161300;37661865300;57207591224;","Turning Transfer Inside Out: The Affordances of Virtual Worlds and Mobile Devices in Real World Contexts for Teaching About Causality Across Time and Distance in Ecosystems",2015,"Technology, Knowledge and Learning","20","1",,"43","69",,14,"10.1007/s10758-014-9241-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925508593&doi=10.1007%2fs10758-014-9241-5&partnerID=40&md5=609ac80e3fc1d8523cb24d25b91eafbb","Harvard Graduate School of Education, Harvard University, 421 Longfellow Hall, Appian Way, Cambridge, MA  02138, United States; University of North Carolina at Wilmington, Wilmington, NC, United States","Grotzer, T.A., Harvard Graduate School of Education, Harvard University, 421 Longfellow Hall, Appian Way, Cambridge, MA  02138, United States; Powell, M.M., Harvard Graduate School of Education, Harvard University, 421 Longfellow Hall, Appian Way, Cambridge, MA  02138, United States; M. Derbiszewska, K., Harvard Graduate School of Education, Harvard University, 421 Longfellow Hall, Appian Way, Cambridge, MA  02138, United States; Courter, C.J., University of North Carolina at Wilmington, Wilmington, NC, United States; Kamarainen, A.M., Harvard Graduate School of Education, Harvard University, 421 Longfellow Hall, Appian Way, Cambridge, MA  02138, United States; Metcalf, S.J., Harvard Graduate School of Education, Harvard University, 421 Longfellow Hall, Appian Way, Cambridge, MA  02138, United States; Dede, C.J., Harvard Graduate School of Education, Harvard University, 421 Longfellow Hall, Appian Way, Cambridge, MA  02138, United States","Reasoning about ecosystems includes consideration of causality over temporal and spatial distances; yet learners typically focus on immediate time frames and local contexts. Teaching students to reason beyond these boundaries has met with some success based upon tests that cue students to the types of reasoning required. Virtual worlds offer an opportunity to assess what students actually do in a simulated context. Beyond this, mobile devices make it possible to scaffold and assess learning in the real world. Situating learning outside, in the target contexts, bypasses many of the challenges of transfer. A study investigated the learning of fifth and sixth graders (n = 38) while they used a virtual world called EcoMUVE, designed to support learning of ecosystems concepts and complex causal dynamics, and mobile broadband device (MBDs) components, designed to assess and support learning and transfer in a real pond ecosystem. The experiences of two classes were contrasted as reference populations; one class participated in the MBD experience first, followed by the learning components in EcoMUVE; the other participated in EcoMUVE first, followed by the MBD components. Rich and triangulated data was collected to illuminate how students experienced and responded to the curriculum components. Both classes made learning gains in EcoMUVE. Students who completed EcoMUVE prior to their MBD experience transferred concepts to their pond explorations. Both classes made learning gains at the pond following the MBD support and revealed more expert reasoning about the importance of change over time and distant drivers in ecosystem dynamics. © 2014, Springer Science+Business Media Dordrecht.","Change over time; Ecosystems causal dynamics; Mobile devices; Multi-user virtual environments; Spatial scale; Transfer","Dynamics; E-learning; Lakes; Mobile computing; Mobile telecommunication systems; Scaffolds; Students; Virtual reality; Change over time; Ecosystem dynamics; Mobile broadband; Multi-user virtual environment; Spatial scale; Support learning; Temporal and spatial; Transfer; Ecosystems",Article,"Final","",Scopus,2-s2.0-84925508593
"Sun G., Muneesawang P., Kyan M., Li H., Zhong L., Dong N., Elder B., Guan L.","36810742400;6603438525;6506086351;36440061500;56659631800;7005861053;16244749200;55679853000;","An advanced computational intelligence system for training of ballet dance in a cave virtual reality environment",2015,"Proceedings - 2014 IEEE International Symposium on Multimedia, ISM 2014",,, 7033015,"159","166",,7,"10.1109/ISM.2014.55","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930464608&doi=10.1109%2fISM.2014.55&partnerID=40&md5=4a5fc1c22ef0e6601101aa353616f80b","Communication University of China, China; Naresuan University, Thailand; Ryerson University, Canada; Guangdong University of Technology, China","Sun, G., Communication University of China, China; Muneesawang, P., Naresuan University, Thailand; Kyan, M., Ryerson University, Canada; Li, H., Communication University of China, China; Zhong, L., Guangdong University of Technology, China; Dong, N., Ryerson University, Canada; Elder, B., Ryerson University, Canada; Guan, L., Ryerson University, Canada","This paper presents a computer-based system for assessment and training of ballet dance in a CAVE virtual reality environment. The system utilizes Kinect sensor to capture student's dance and extracts features from skeleton joints. This system depends on a structured posture space, which comprises a set of dance elements that represent key moments - 'postures', that typically will be so briefly held as to experience as a fleeting moment in a flux - in the dance movements whose performance we are attempting to assess. The recording captured from the Kinect allows the parsing of dance movement into a structured posture space using the spherical self-organizing map (SSOM). From this, a unique descriptor can be obtained by following gesture trajectories through posture space on the SSOM, which appropriately reflects the subtleties of ballet dance movements. Consequently, the system can recognize the category of movement the student is attempting, and this allows us make a quantitative assessment of individual movements. Based on the experimental results, the proposed system appears to be very effective for recognition and offering generalization across instances of movement. Thus, it is possible for the construction of assessment and visualization of ballet dance movements performed by the student in an instructional, virtual reality setting. © 2014 IEEE.","CAVE virtual reality environment; dance assesment; dance traning system; gesture recognition; spherical-self-organizing map","Caves; Conformal mapping; E-learning; Gesture recognition; Self organizing maps; Students; Assesment; Computer-based system; dance traning system; Gesture trajectories; Kinect sensors; Quantitative assessments; Skeleton joints; Virtual-reality environment; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84930464608
"Freina L., Canessa A.","26665429300;57210766595;","Immersive vs desktop virtual reality in game based learning",2015,"Proceedings of the European Conference on Games-based Learning","2015-January",,,"195","202",,10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955151400&partnerID=40&md5=f62727021ff0a306eef5ab32c8a4bce7","CNR-ITD, Genova, Italy; BioLab - DIBRIS, Università degli Studi di Genova, Italy","Freina, L., CNR-ITD, Genova, Italy; Canessa, A., BioLab - DIBRIS, Università degli Studi di Genova, Italy","Virtual environments are recognized as more effective than other digital approaches for the acquisition of several abilities. This is because the brain recognizes the virtual world as real and this facilitates the transfer of the newly acquired skills to the real world. In this paper, we present a game that has been designed and developed with the aim of teaching spatial orientation abilities to teenagers with mild intellectual impairments. In particular, the game focuses on the training of two basic skills: Perspective taking and mental rotation. Perspective taking refers to the ability of imagining how the world looks like from another person's point of view, while mental rotation is the ability to mentally represent and manipulate physical objects in one's mind. The game, which takes place in a virtual environment, shows the player a scene with some objects on the table. The player has to choose among four provided alternatives, the one that shows how the scene would look like from a different side of the table. The game was first developed to be used with either a desktop pc monitor or an interactive touch table. In this case, a virtual world is represented, but the player is not completely immersed in it, he just looks at the scene from outside. A second version of the same game has then been developed using a Head Mounted Display (HMD), which makes the player feel immersed in the virtual environment, where he can freely move around just as if it was real. In this paper, we discuss both advantages and disadvantages of the immersive Virtual Reality (VR) compared to the desktop VR. In fact, on the one hand, having the possibility to ""dive"" into the virtual world allows the player to: Better build a mental model of the scene and the involved objects by freely moving around the table and examining the objects from all the possible perspectives; Manage by himself the amount of help needed: It is always possible, at any time of the game, to move to the other side of the table and see what the scene looks like. Increase his involvement in the game by exploring the virtual world as he pleases. Have a better learning transfer thanks to the similarities between the virtual and the real worlds. On the other hand, using a HMD can be tiring and cause sickness to some players. Furthermore, the presence of a complete environment in which to move and explore, can draw the attention away from the main task of the game and therefore influence learning negatively. Experiments are planned to verify the foreseen advantages and disadvantages involving young adults with mild intellective disabilities.","Innovative games-based learning; Mental rotation; Perspective taking; Virtual worlds","Helmet mounted displays; Interactive computer graphics; Personnel training; Sensory perception; Desktop virtual reality; Head mounted displays; Immersive virtual reality; Innovative games-based learning; Mental rotation; Perspective taking; Spatial orientations; Virtual worlds; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84955151400
"Chapoulie E., Tsandilas T., Oehlberg L., MacKay W., Drettakis G.","38662242200;6507282888;23991094100;7102699682;6603449604;","Finger-based manipulation in immersive spaces and the real world",2015,"2015 IEEE Symposium on 3D User Interfaces, 3DUI 2015 - Proceedings",,, 7131734,"109","116",,6,"10.1109/3DUI.2015.7131734","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939200619&doi=10.1109%2f3DUI.2015.7131734&partnerID=40&md5=e2a02c5e045bd8cb1a45d08de3dc4280","Inria, Univ Paris-Sud, France","Chapoulie, E., Inria, Univ Paris-Sud, France; Tsandilas, T., Inria, Univ Paris-Sud, France; Oehlberg, L., Inria, Univ Paris-Sud, France; MacKay, W., Inria, Univ Paris-Sud, France; Drettakis, G., Inria, Univ Paris-Sud, France","Immersive environments that approximate natural interaction with physical 3D objects are designed to increase the user's sense of presence and improve performance by allowing users to transfer existing skills and expertise from real to virtual environments. However, limitations of current Virtual Reality technologies, e.g., low-fidelity real-time physics simulations and tracking problems, make it difficult to ascertain the full potential of finger-based 3D manipulation techniques. This paper decomposes 3D object manipulation into the component movements, taking into account both physical constraints and mechanics. We fabricate five physical devices that simulate these movements in a measurable way under experimental conditions. We then implement the devices in an immersive environment and conduct an experiment to evaluate direct finger-based against ray-based object manipulation. The key contribution of this work is the careful design and creation of physical and virtual devices to study physics-based 3D object manipulation in a rigorous manner in both real and virtual setups. © 2015 IEEE.","Finger-based manipulation; Immersive Cube-like Displays; Real/virtual world comparison","Virtual reality; 3D object manipulations; Experimental conditions; Finger-based manipulation; Immersive; Immersive environment; Physical constraints; Real/virtual world comparison; Virtual reality technology; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-84939200619
"Abed H., Pernelle P., Carron T., Benamar C., Kechiche M., Baert P.","57069934400;36138922300;14631830600;25959856600;56108613500;55177962500;","Serious game framework focusing on industrial traing: Application to steel industry",2015,"Proceedings of the European Conference on Games-based Learning","2015-January",,,"1","9",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955134969&partnerID=40&md5=34cec6144ed65704c9435f52ce269e5f","LIP6, UPMC, Paris, France; DISP, University of Lyon 1, Villeurbanne, France; REGIM, ENI, Sfax, Tunisia; ENISE, Saint-etienne, France","Abed, H., LIP6, UPMC, Paris, France; Pernelle, P., DISP, University of Lyon 1, Villeurbanne, France; Carron, T., LIP6, UPMC, Paris, France; Benamar, C., REGIM, ENI, Sfax, Tunisia; Kechiche, M., ENISE, Saint-etienne, France; Baert, P., ENISE, Saint-etienne, France","Serious games are growing more and more in the context of lifelong training and initial education. They cover several areas (human science, engineering science, life science, ...) that are used for industrial or academic purposes. However, some fields induce specific issues. Thus, in the industrial area, the constraints inherent to the activity impact the development of a scenario and implementation of a serious gaming environment. Indeed, the objective of the industry training must both lead to the acquisition of knowledge and the transfer of skills. Moreover, the actual validation of these skills is paramount especially if their uses are located on an industrial site, where there are often risks associated with the security of persons and equipment. In many industries, some regulatory constraints impose an obligation of means for the training of staff. In the sector of production, the proliferation of interim requires inevitably targeted training. Finally, it should be noted that even for permanent staff, alternation and fragmentation of training periods seriously complicate the deep learning task. Finally, we can wonder if the serious game can bring relevant answers to specific problems of training in an industrial context? This article offers some answers to this question. Thus, in this work, we propose a serious game scripting framework adapted to the industrial context. This scripting framework is structured around two approaches: The first defines a global framework for scheduling a fun or playful scenario. Moreover, this framework allows to take into account the phases of availability of learners while maintaining motivation. The second approach defines an immersive framework for validating acquired and security compliance that is based on two complementary purposes: Use of alternate observation activities (games / real) and an immersive simulation (Virtual Reality) for security. In partnership with a company in the steel industry, we have developed a prototype of serious game in order to implement this scripting framework. The prototype is based on a generic game platform, on a tablet with use of RFID tag, and with an immersive virtual reality Head-Mounted-Display (HMD type Oculus®). In this article we will present the actions realized in the context of a professional activity related to the manipulation of a bridge crane.","Formatting; Interaction; Serious games; Virtual reality","Helmet mounted displays; Steelmaking; Virtual reality; Engineering science; Formatting; Head mounted displays; Immersive virtual reality; Interaction; Professional activities; Security compliance; Serious games; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-84955134969
"Nabioyuni M., Bowman D.A.","57218219407;7202508735;","An Evaluation of the Effects of Hyper-Natural Components of Interaction Fidelity on Locomotion Performance in Virtual Reality",2015,"International Conference on Artificial Reality and Telexistence and Eurographics Symposium on Virtual Environments, ICAT-EGVE 2015",,,,"167","174",,8,"10.2312/egve.20151325","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994865676&doi=10.2312%2fegve.20151325&partnerID=40&md5=f3db2d10ac35041de78cf07da799959e","Instittue Center for Human-Computer Interaction, Department of Computer Science, Virginia Tech, United States","Nabioyuni, M., Instittue Center for Human-Computer Interaction, Department of Computer Science, Virginia Tech, United States; Bowman, D.A., Instittue Center for Human-Computer Interaction, Department of Computer Science, Virginia Tech, United States","Virtual reality (VR) locomotion techniques that approximate real-world walking often have lower performance than fully natural real walking due to moderate interaction fidelity. Other techniques with moderate fidelity, however, are intentionally designedto enhance users'abilities beyond whatis possible in the realworld. We compared such hyper-natural techniques to their natural counterparts on a wide range of locomotion tasks for a variety of measures. The evaluation also considered two independent components of interaction fidelity: bio-mechanics and transfer function. The results show that hyper-natural transfer functions can improve locomotion speed and some aspects of user satisfaction, although this can come at the expense of accuracy for complicated path-following tasks. On the other hand, hyper-natural techniques designed to provide biomechanical assistance had lower performance and user acceptance than those based on natural walking movements. These results contribute to a deeper understanding of the effects of interaction fidelity and designer intent for VR interaction techniques. © The Eurographics Association 2015.",,"Biomechanics; Function evaluation; Transfer functions; Virtual reality; Independent components; Interaction techniques; Locomotion technique; Natural components; Path following; User acceptance; User satisfaction; Walking movements; Walking aids",Conference Paper,"Final","",Scopus,2-s2.0-84994865676
"Kim J.-S., Gračanin D., Yang T., Quek F.","15022803300;7003992400;7404656081;6701855935;","Action-transferred navigation technique design approach supporting human spatial learning",2015,"ACM Transactions on Computer-Human Interaction","22","6", 30,"","",,3,"10.1145/2811258","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942762189&doi=10.1145%2f2811258&partnerID=40&md5=001c0b4264e04d6d02042790adee9d3b","Department of Computer Science, Virginia Tech, Blacksburg, VA  24061, United States; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA  24061, United States; Department of Visualization, Texas A and M University, College Station, TX  77843, United States","Kim, J.-S., Department of Computer Science, Virginia Tech, Blacksburg, VA  24061, United States; Gračanin, D., Department of Computer Science, Virginia Tech, Blacksburg, VA  24061, United States; Yang, T., Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA  24061, United States; Quek, F., Department of Visualization, Texas A and M University, College Station, TX  77843, United States","We propose a new action-transferred design approach by which the benefits of embodied cognition and activity can be realized to enhance spatial learning and usability for navigating virtual spaces. The action-transferred design approach is supported by theories of learning, action-perception, and neuropsychology. These theories help us understand how human action can be transferred to different body parts for improving the usability of interaction techniques and why the acquired spatial knowledge using the transferred action may remain the same independent of the used body parts. The finger-walking-in-place (FWIP) navigation technique is used as a design example to demonstrate the concept of the action-transferred design approach. Leveraging 3D immersive virtual reality technology, we performed an empirical study to evaluate the performance of the action-transferred FWIP navigation technique in terms of spatial knowledge acquisition. The FWIP navigation technique was compared with a full-body-based walking-like (sensor-fusion walking in-place; SF-WIP) navigation technique and a well-known, convenient (Joystick) navigation technique using a common input device, that is, a wand with a joystick. Both the action-transferred and the full-body-based navigation techniques were more effective for spatial learning than the navigation technique using the common input device. However, only the action-transferred FWIP navigation technique can provide users with the convenience of navigating with their fingers. These results suggest that the action-transferred design approach is useful in designing a navigation technique supporting users' spatial learning performance more effectively and conveniently. Possible design implications for broader applications are discussed and indicate that the action-transferred design approach is worth further study. © 2015 ACM.","Action-transfer; Cognitive learning; Gesture; Interaction technique; Motor equivalence; Navigation technique; Spatial learning; Virtual environment","Cognitive systems; Design; Knobs; Knowledge management; Navigation; Virtual reality; Action-transfer; Cognitive learning; Gesture; Interaction techniques; Navigation techniques; Spatial learning; Air navigation",Article,"Final","",Scopus,2-s2.0-84942762189
"Mestre D.R.","7004066310;","On the usefulness of the concept of presence in Virtual Reality applications",2015,"Proceedings of SPIE - The International Society for Optical Engineering","9392",, 93920J,"","",,5,"10.1117/12.2075798","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928473664&doi=10.1117%2f12.2075798&partnerID=40&md5=c601907e8f7dda5bc906c334bb8df603","Aix-Marseille University, CNRS, Institute of Movement Sciences, Marseilles, France","Mestre, D.R., Aix-Marseille University, CNRS, Institute of Movement Sciences, Marseilles, France","Virtual Reality (VR) leads to realistic experimental situations, while enabling researchers to have deterministic control on these situations, and to precisely measure participants' behavior. However, because more realistic and complex situations can be implemented, important questions arise, concerning the validity and representativeness of the observed behavior, with reference to a real situation. One example is the investigation of a critical (virtually dangerous) situation, in which the participant knows that no actual threat is present in the simulated situation, and might thus exhibit a behavioral response that is far from reality. This poses serious problems, for instance in training situations, in terms of transfer of learning to a real situation. Facing this difficult question, it seems necessary to study the relationships between three factors: immersion (physical realism), presence (psychological realism) and behavior. We propose a conceptual framework, in which presence is a necessary condition for the emergence of a behavior that is representative of what is observed in real conditions. Presence itself depends not only on physical immersive characteristics of the Virtual Reality setup, but also on contextual and psychological factors. © 2015 SPIE-IS&T.","Behavior; Immersion; Presence; Virtual Reality","Optical engineering; Behavior; Behavioral response; Conceptual frameworks; Immersion; Presence; Psychological factors; Psychological realisms; Transfer of learning; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84928473664
"Levin Pt M.F., Weiss Ot P.L., Keshner Pt E.A.","56155750700;56540010800;7003942504;","Emergence of virtual reality as a tool for upper limb rehabilitation: Incorporation of motor control and motor learning Principles",2015,"Physical Therapy","95","3",,"415","425",,146,"10.2522/ptj.20130579","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924225097&doi=10.2522%2fptj.20130579&partnerID=40&md5=475a42ee88266a9711d56f0f2965dda1","School of Physical and Occupational Therapy, McGill University, 3654 Promenade Sir William Osler, Montreal, Quebec  H3G 1Y5, Canada; Centre for Interdisciplinary Research in Rehabilitation, Jewish Rehabilitation Hospital, Laval, QC, Canada; Department of Occupational Therapy, University of Haifa Mount Carmel, Haifa, Israel; Department of Physical Therapy, College of Health Professions and Social Work, Temple University, Philadelphia, PA, United States","Levin Pt, M.F., School of Physical and Occupational Therapy, McGill University, 3654 Promenade Sir William Osler, Montreal, Quebec  H3G 1Y5, Canada, Centre for Interdisciplinary Research in Rehabilitation, Jewish Rehabilitation Hospital, Laval, QC, Canada; Weiss Ot, P.L., Department of Occupational Therapy, University of Haifa Mount Carmel, Haifa, Israel; Keshner Pt, E.A., Department of Physical Therapy, College of Health Professions and Social Work, Temple University, Philadelphia, PA, United States","The primary focus of rehabilitation for individuals with loss of upper limb movement as a result of acquired brain injury is the relearning of specific motor skills and daily tasks. This relearning is essential because the loss of upper limb movement often results in a reduced quality of life. Although rehabilitation strives to take advantage of neuroplastic processes during recovery, results of traditional approaches to upper limb rehabilitation have not entirely met this goal. In contrast, enriched training tasks, simulated with a wide range of low-to high-end virtual reality-based simulations, can be used to provide meaningful, repetitive practice together with salient feedback, thereby maximizing neuroplastic processes via motor learning and motor recovery. Such enriched virtual environments have the potential to optimize motor learning by manipulating practice conditions that explicitly engage motivational, cognitive, motor control, and sensory feedback-based learning mechanisms. The objectives of this article are to review motor control and motor learning principles, to discuss how they can be exploited by virtual reality training environments, and to provide evidence concerning current applications for upper limb motor recovery. The limitations of the current technologies with respect to their effectiveness and transfer of learning to daily life tasks also are discussed. © 2015 American Physical Therapy Association.",,"arm; Brain Injuries; complication; computer interface; human; motor activity; pathophysiology; physiotherapy; psychomotor performance; Brain Injuries; Humans; Motor Activity; Physical Therapy Modalities; Psychomotor Performance; Upper Extremity; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84924225097
"Smith J., Veitch B., MacKinnon S.","56493414900;7003302037;7202865269;","Achieving competence in offshore emergency egress using virtual environment training",2015,"Proceedings of the International Conference on Offshore Mechanics and Arctic Engineering - OMAE","3",,,"","",,4,"10.1115/OMAE201541132","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947997563&doi=10.1115%2fOMAE201541132&partnerID=40&md5=edb4344baf3c9f01d7b7aa071141aced","Faculty of Engineering and Applied Science, Memorial University, St. John's, NL, Canada; Human Kinetics and Recreation, Memorial University, St. John's, NL, Canada","Smith, J., Faculty of Engineering and Applied Science, Memorial University, St. John's, NL, Canada; Veitch, B., Faculty of Engineering and Applied Science, Memorial University, St. John's, NL, Canada; MacKinnon, S., Human Kinetics and Recreation, Memorial University, St. John's, NL, Canada","As a precursor to simulation transfer studies, this research assessed the level of competence in basic offshore safety gained through a virtual environment training program and investigated the training time required to reach competence. The experiment demonstrated that the offshore egress learning objectives can be taught using the All-hands Virtual Emergency Response Trainer (AVERT) training program with some limitations. The two main findings were: 1. due to individual differences in spatial learning, some individuals required more exposure to the virtual setting to ensure knowledge retention; and 2. the procedural learning objectives required reinforcement during training scenarios to ensure knowledge acquisition. Overall, this research recommends modifications to the training and technology design in order to prepare for future transfer studies and offshore applications. © 2015 by ASME.",,"Arctic engineering; Safety engineering; Virtual reality; Individual Differences; Knowledge retention; Learning objectives; Offshore applications; Offshore emergencies; Procedural learning; Simulation transfer; Technology designs; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-84947997563
"Alfred M., Neyens D.M., Gramopadhye A.K.","56901101700;15045355400;7005569103;","The impact of training method on skill acquisition and transfer",2015,"Proceedings of the Human Factors and Ergonomics Society","2015-January",,,"1563","1567",,1,"10.1177/1541931215591338","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981717478&doi=10.1177%2f1541931215591338&partnerID=40&md5=ad531b4a2ae5b19f89fd2b1bfa2e7b04","Clemson University, United States","Alfred, M., Clemson University, United States; Neyens, D.M., Clemson University, United States; Gramopadhye, A.K., Clemson University, United States","Technology, such as simulations and virtual reality (VR), can be used for training students and employees. Using these tools may have implications for skills development and retention, specifically related to individual differences and technology's effectiveness as a learning tool. To explore this issue, a pilot study was used to evaluate how an individual's performance on a task (i.e., the building an electrical circuit), differs depending on the physical fidelity of the learning environment. In addition, this study examined the effects of cognitive ability and goal orientation on task performance. Specifically this study investigated different methods for practicing the building of electrical circuits using a 2D breadboard simulation, a 3D virtual breadboard, and a physical breadboard. The preliminary results of this pilot study found that physical fidelity of learning environment was a significant predictor of construction time and circuit accuracy. Cognitive ability and learning goal orientation were significant predictors of gain scores and diagram accuracy. Copyright 2015 Human Factors and Ergonomics Society.",,"Computer aided instruction; Electric network parameters; Ergonomics; Human engineering; Networks (circuits); Reconfigurable hardware; Virtual reality; Cognitive ability; Construction time; Electrical circuit; Individual Differences; Learning environments; Skill acquisition and transfers; Skills development; Virtual breadboards; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-84981717478
"Lu X., Davis S.R.","57157731400;7405958602;","How sounds influence people's safety decisions-human interaction with a virtual reality simulator",2015,"32nd International Symposium on Automation and Robotics in Construction and Mining: Connected to the Future, Proceedings",,,,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962811937&partnerID=40&md5=f03b03cdd1cb514a9a2b53d47faef246","School of Civil and Environmental Engineering, University of New South Wales, Australia","Lu, X., School of Civil and Environmental Engineering, University of New South Wales, Australia; Davis, S.R., School of Civil and Environmental Engineering, University of New South Wales, Australia","Safety decisions made by construction workers on-site directly affect the rate of accidents and injuries. Virtual Reality safety simulators have been created for training workers in site safety. This paper examines the effect that sound has on the realism of virtual reality simulators and the effect that virtual reality training has on subsequent behavior in the physical world. A Virtual Reality environment was built for the tests. Tests involved maneuvering a wheelbarrow around a construction site. Safe and unsafe routes were available. Participants were divided into two groups, those with background sounds in their simulation and those without. A physical environment was built to investigate if use of the virtual reality environment resulted in behavior changes. Participants also completed questionnaires after the tests to discover why participants acted the way they did. The paper is unique in testing users with and without sound in a construction safety simulator. Preliminary study results show that people are likely to perceive more risks when there is no background sound which results in fewer accidents. Results of the paper are useful for those creating virtual reality simulators. Limitations of the research are that it applies to a very specific problem and results need to be generalized over a larger set of problems. Future research is also required to determine what sound range (in terms of decibels) is best for virtual reality training.","Construction sounds; Safety decision; Virtual reality simulator","Accidents; Behavioral research; E-learning; Occupational risks; Robotics; Safety engineering; Safety testing; Simulators; Surveys; Construction safety; Construction sites; Construction workers; Human interactions; Physical environments; Virtual reality simulator; Virtual reality training; Virtual-reality environment; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84962811937
"Wijewickrema S., Ioannou I., Zhou Y., Piromchai P., Bailey J., Kennedy G., Oleary S.","16178559900;8948366800;53364848200;23994025400;7404350735;7201789195;57211220576;","Region-specific automated feedback in temporal bone surgery simulation",2015,"Proceedings - IEEE Symposium on Computer-Based Medical Systems","2015-July",, 7167506,"310","315",,6,"10.1109/CBMS.2015.13","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944202440&doi=10.1109%2fCBMS.2015.13&partnerID=40&md5=22d85f7e81ba3912c8d46c5f7a0c526a","Department of Otolaryngology, University of Melbourne, Australia; Department of Computing and Information Systems, University of Melbourne, Australia; Centre for the Study of Higher Education, University of Melbourne, Australia","Wijewickrema, S., Department of Otolaryngology, University of Melbourne, Australia; Ioannou, I., Department of Otolaryngology, University of Melbourne, Australia; Zhou, Y., Department of Computing and Information Systems, University of Melbourne, Australia; Piromchai, P., Department of Otolaryngology, University of Melbourne, Australia; Bailey, J., Department of Computing and Information Systems, University of Melbourne, Australia; Kennedy, G., Centre for the Study of Higher Education, University of Melbourne, Australia; Oleary, S., Department of Otolaryngology, University of Melbourne, Australia","The use of virtual reality simulators for surgical training has gained popularity in recent years, with an ever increasing body of evidence supporting the benefits and validity of simulation-based training. However, a crucial component of effective skill acquisition has not been adequately addressed, namely the provision of timely performance feedback. The utility of a surgical simulator is limited if it still requires the presence of experts to guide trainees. Automated feedback that emulates the advise provided by experts is necessary to facilitate independent learning. We propose an automated system that provides region-specific feedback on surgical technique within a temporal bone surgery simulator. The design of this system allows easy transfer of feedback models to multiple temporal bone specimens in the simulator. The system was validated by an expert otologist and was found to provide highly accurate and timely feedback. © 2015 IEEE.","Automated Feedback in Surgery Simulation; Simulation-Based Surgical Training; Virtual Reality Temporal Bone Surgery","Automation; Bone; Personnel training; Simulators; Surgery; Transplantation (surgical); Virtual reality; Independent learning; Performance feedback; Simulation-based training; Surgery simulations; Surgical techniques; Surgical training; Temporal bone surgery; Virtual reality simulator; Surgical equipment",Conference Paper,"Final","",Scopus,2-s2.0-84944202440
"Josan P.K., Singh-Derewa C., De Leon P., Inada B., Srivastava P.","57191542339;56287831300;16315695800;57191538742;57191545841;","Enhancing the human-machine interface using visr-An interactive 3d visualization/ desens1tization training tool in a variable gravity model",2015,"Proceedings of the International Astronautical Congress, IAC","6",,,"4205","4216",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991489707&partnerID=40&md5=929faade94c2cfb432e6c706c34b5eec","Department of Space Studies, University of North Dakota, United States; Systems Engineering Division, NASA-JPL, United States; University of North Dakota, United States; User Research and Interaction Design, NASA-JPL, United States; University of Michigan, Ann Arbor, United States","Josan, P.K., Department of Space Studies, University of North Dakota, United States; Singh-Derewa, C., Systems Engineering Division, NASA-JPL, United States; De Leon, P., University of North Dakota, United States; Inada, B., User Research and Interaction Design, NASA-JPL, United States; Srivastava, P., University of Michigan, Ann Arbor, United States","The human body is used to a 1-G environment and behaves differently in lower gravity. Mars gravity is about l/3rd of Earth's, asteroid and dwarf planets even less. Training for Extra Vehicular Activities (EVA) using rovers and spacesuits is challenging at best. Lower gravity planetary environments with distinctive terrain require trained space explorers with interactive human-machine compatibilities. Current visualization methods, such as Virtual Reality (VR) goggles, can be adapted to display a generalized view of planetary surface featuring a visual 3-D interface, yet lack a high-fidelity, immersive environment. Limited terrain mapping and limited methods for reflecting the variable gravitational conditions are two of the primary limitations. In order to better understand human behavior in alternate environments, it is important to study the psycho-physiological components of a subject in a near-Actual simulations. With the potential to augment planetary EVA procedures and address vital human factors associated with space planetary exploration, our team in partnership with the University of North Dakota (UND) and the Jet Propulsion Laboratory (JPL) have developed the concept of VISR (Visual Immersion for Simulated Robotics) system. VISR provides an immersive 3-D planetary Virtual Reality model utilizing high performance computing, image processing, 3-D rendering, powered by an expansive referential database. The software manipulates image processing speed with a variable gravity parameter as an input. VISR is compatible with multiple planetary bodies and asteroids whereas the current system applications are limited to the space station and Mars. VISR assists in the study of psycho-physiological effects (human limbs - eye coordination) associated with deep-space travel and low- gravity environments. VISR can be utilized to facilitate short range tele-robotic operation during actual missions. Mars has a vast, geologically complex terrain with existing environments models allowing topographical visualization. Image composition draws upon the significant wealth of information accumulated at JPL over 50 years interacting with solar system bodies. VISR users experience these features in an immersive and interactive environment enhancing human performance in real situations, and assisting scientists and mission planners in system and mission design. VISR integrates the UND developed planetary suit NDX-2, currently used as a simulation tool for 'astronaut training', the LEGACY database for planetary bodies at JPL, human factors and related Psychophysiological studies. The VISR system development will has seen different phases such as development of terrain maps, and their integration with visual device sensor, integration of the LEGACY terrain sysml model which can identify and import relevant physical parameters from available planetary databases, varying the speed of image output to the user by manipulating the gravity parameter, and integrating it with already developed terrain models. This device can be further used to feed real-Time physiological performance data to a separate sensor based system, and study the related effects on human subjects. VISR will be an effective tool which would equip the researchers, mission planners and space travelers for a future planetary manned mission.",,"Asteroids; Database systems; Fighter aircraft; Gravitation; Human computer interaction; Human engineering; Image processing; Interplanetary spacecraft; Landforms; Liquid sloshing; Manned space flight; Physiology; Planets; Planning; Reconfigurable hardware; Robotics; Space stations; Spacecraft; Three dimensional computer graphics; Training aircraft; Virtual reality; Visualization; Extravehicular activity; High performance computing; Human Machine Interface; Interactive 3d visualizations; Interactive Environments; Jet Propulsion Laboratory; University of North Dakota; Virtual reality modeling; Behavioral research",Conference Paper,"Final","",Scopus,2-s2.0-84991489707
"Walkowiak S., Foulsham T., Eardley A.F.","56515221300;8983741300;14038855900;","Individual differences and personality correlates of navigational performance in the virtual route learning task",2015,"Computers in Human Behavior","45",,,"402","410",,32,"10.1016/j.chb.2014.12.041","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922709203&doi=10.1016%2fj.chb.2014.12.041&partnerID=40&md5=fb498643b643780c1dbd0b11a3c7518c","Department of Psychology, University of Essex, Wivenhoe Park, Colchester, Essex, CO4 3SQ, United Kingdom; Department of Psychology, University of Westminster, 115 New Cavendish Street, London, W1W 6UW, United Kingdom","Walkowiak, S., Department of Psychology, University of Essex, Wivenhoe Park, Colchester, Essex, CO4 3SQ, United Kingdom; Foulsham, T., Department of Psychology, University of Essex, Wivenhoe Park, Colchester, Essex, CO4 3SQ, United Kingdom; Eardley, A.F., Department of Psychology, University of Westminster, 115 New Cavendish Street, London, W1W 6UW, United Kingdom","Research on the mechanisms and processes underlying navigation has traditionally been limited by the practical problems of setting up and controlling navigation in a real-world setting. Thanks to advances in technology, a growing number of researchers are making use of computer-based virtual environments to draw inferences about real-world navigation. However, little research has been done on factors affecting human-computer interactions in navigation tasks. In this study female students completed a virtual route learning task and filled out a battery of questionnaires, which determined levels of computer experience, wayfinding anxiety, neuroticism, extraversion, psychoticism and immersive tendencies as well as their preference for a route or survey strategy. Scores on personality traits and individual differences were then correlated with the time taken to complete the navigation task, the length of path travelled, the velocity of the virtual walk and the number of errors. Navigation performance was significantly influenced by wayfinding anxiety, psychoticism, involvement and overall immersive tendencies and was improved in those participants who adopted a survey strategy. In other words, navigation in virtual environments is effected not only by navigational strategy, but also an individual's personality, and other factors such as their level of experience with computers. An understanding of these differences is crucial before performance in virtual environments can be generalised to real-world navigational performance. © 2015 Elsevier Ltd. All rights reserved.","Anxiety; Personality traits; Psychoticism; Spatial cognition; Virtual environments; Wayfinding","Human computer interaction; Navigation; Surveys; Virtual reality; Anxiety; Personality traits; Psychoticism; Spatial cognition; Way-finding; E-learning",Article,"Final","",Scopus,2-s2.0-84922709203
"Shiban Y., Reichenberger J., Neumann I.D., Mühlberger A.","55533404000;56674467400;7005834935;6507375232;","Social conditioning and extinction paradigm: A translational study in virtual reality",2015,"Frontiers in Psychology","6","APR", 400,"","",,7,"10.3389/fpsyg.2015.00400","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930614663&doi=10.3389%2ffpsyg.2015.00400&partnerID=40&md5=9bd3522b84c570c4f8252951e8d7de3a","Department of Clinical Psychology and Psychotherapy, Institute of Psychology, University of Regensburg, Regensburg, Germany; Department of Behavioral and Molecular Neurobiology, Institute of Zoology, University of Regensburg, Regensburg, Germany","Shiban, Y., Department of Clinical Psychology and Psychotherapy, Institute of Psychology, University of Regensburg, Regensburg, Germany; Reichenberger, J., Department of Clinical Psychology and Psychotherapy, Institute of Psychology, University of Regensburg, Regensburg, Germany; Neumann, I.D., Department of Behavioral and Molecular Neurobiology, Institute of Zoology, University of Regensburg, Regensburg, Germany; Mühlberger, A., Department of Clinical Psychology and Psychotherapy, Institute of Psychology, University of Regensburg, Regensburg, Germany","In human beings, experiments investigating fear conditioning with social stimuli are rare. The current study aims at translating an animal model for social fear conditioning (SFC) to a human sample using an operant SFC paradigm in virtual reality. Forty participants actively (using a joystick) approached virtual male agents that served as conditioned stimuli (CS). During the acquisition phase, unconditioned stimuli (US), a combination of an air blast (5 bar, 10 ms) and a female scream (95 dB, 40 ms), were presented when participants reached a defined proximity to the agent with a contingency of 75% for CS+ agents and never for CS- agents. During the extinction and the test phases, no US was delivered. Outcome variables were pleasantness ratings and physiological reactions in heart rate (HR) and fear-potentiated startle. Additionally, the influence of social anxiety, which was measured with the Social Phobia Inventory scale, was evaluated. As expected after the acquisition phase the CS+ was rated clearly less pleasant than the CS-. This difference vanished during extinction. Furthermore, the HR remained high for the CS+, while the HR for the CS- was clearly lower after than before the acquisition. Furthermore, a clear difference between CS+ and CS- after the acquisition indicated successful conditioning on this translational measure. Contrariwise no CS+/CS- differences were observed in the physiological variables during extinction. Importantly, at the generalization test, higher socially fearful participants rated pleasantness of all agents as low whereas the lower socially fearful participants rated pleasantness as low only for the CS+. SFC was successfully induced and extinguished confirming operant conditioning in this SFC paradigm. These findings suggest that the paradigm is suitable to expand the knowledge about the learning and unlearning of social fears. Further studies should investigate the operant mechanisms of development and treatment of social anxiety disorder. © 2015 Shiban, Reichenberger, Neumann and Mühlberger.","Fear-potentiated startle; Heart rate; Operant conditioning paradigm; Social anxiety; Social fear conditioning; Virtual reality",,Article,"Final","",Scopus,2-s2.0-84930614663
"Rowe L.S., Jouriles E.N., McDonald R.","42361585400;6701796924;8526569500;","Reducing Sexual Victimization Among Adolescent Girls: A Randomized Controlled Pilot Trial of My Voice, My Choice",2015,"Behavior Therapy","46","3",,"315","327",,17,"10.1016/j.beth.2014.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947316081&doi=10.1016%2fj.beth.2014.11.003&partnerID=40&md5=8d046863fdbf09384115d8f71c7a5543","Southern Methodist University, United States","Rowe, L.S., Southern Methodist University, United States; Jouriles, E.N., Southern Methodist University, United States; McDonald, R., Southern Methodist University, United States","Despite extensive efforts to develop and implement programs to prevent sexual violence, few programs have empiricallydemonstrated efficacy. The primary exceptions are programs that emphasize risk-reduction skills; yet even these programs are not consistently effective. This study seeks to add to the literature by evaluating the effects of My Voice, My Choice (MVMC), a 90-minute assertive resistance training program that emphasizes skill practice in an immersive virtual environment (IVE). We hypothesized that MVMC would reduce male-to-female sexual victimization among adolescent girls over a 3-month follow-up period. We also examined whether these results would generalize to other forms of male-to-female relationship violence and to girls' psychological distress. Eighty-three female students from an urban public high school were randomized to MVMC (n = 47) or to a wait-list control condition (n = 36); 78 provided data over the 3-month follow-up period. Participants assigned to MVMC were less likely than control participants to report sexual victimization during the follow-up period. Our results also suggest that MVMC reduced risk for psychological victimization and for psychological distress among participants with greater prior victimization at baseline.The promising results of this pilot trial suggest that MVMC may help girls evade male-to-female relationship violence. © 2014 Association for Behavioral and Cognitive Therapies.","Assertiveness; Prevention; Sexual violence; Teen dating violence; Virtual reality","adolescent; child; clinical trial; controlled clinical trial; controlled study; female; follow up; girl; high school; human; major clinical study; male; mental stress; normal human; randomized controlled trial; resistance training; skill; student; voice; crime victim; decision making; persuasive communication; prevention and control; program evaluation; psychology; sexual behavior; sexual crime; Adolescent; Choice Behavior; Coercion; Crime Victims; Female; Humans; Male; Program Evaluation; Sex Offenses; Sexual Behavior; Stress, Psychological; Students",Article,"Final","",Scopus,2-s2.0-84947316081
"Welk A.K., Mayhorn C.B.","57105166400;6602271299;","All signals go: Investigating how individual differences and training affect performance on a medical diagnosis task designed to parallel a Signals intelligence analyst task",2015,"Proceedings of the Human Factors and Ergonomics Society","2015-January",,,"312","316",,,"10.1177/1541931215591065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981738907&doi=10.1177%2f1541931215591065&partnerID=40&md5=8a6ece2bb3886e51af91d4e1aae45162",,"Welk, A.K.; Mayhorn, C.B.","Signals intelligence analysts play a critical role in the United States government by providing information regarding potential national security threats to government leaders. Analysts perform complex decisionmaking tasks that involve gathering, sorting, and analyzing information. The current study evaluated how individual differences and training influence performance on an Internet search-based medical diagnosis task designed to simulate a signals analyst task. The implemented training emphasized the extraction and organization of relevant information and deductive reasoning. The individual differences of interest included working memory capacity and previous experience with elements of the task, specifically health literacy, prior experience using the Internet, and prior experience conducting Internet searches. Preliminary results indicated that the implemented training did not significantly affect performance, however, working memory significantly predicted performance on the implemented task. These results support previous research and provide additional evidence that working memory capacity influences performance on cognitively complex decision-making tasks, whereas experience with elements of the task may not. These findings suggest that working memory capacity should be considered when screening individuals for signals intelligence positions. Future research should aim to generalize these findings within a broader sample, and ideally utilize a task that directly replicates those performed by signals analysts. Copyright 2015 Human Factors and Ergonomics Society.",,"Decision making; Ergonomics; Human engineering; Information retrieval; Internet; National security; Search engines; World Wide Web; Complex decision; Deductive reasoning; Government leaders; Individual Differences; Internet searches; Predicted performance; Prior experience; Signals intelligence; Diagnosis",Conference Paper,"Final","",Scopus,2-s2.0-84981738907
"White C., Chuah J., Robb A., Lok B., Lampotang S., Lizdas D., Martindale J., Pi G., Wendling A.","7404153169;35104529300;55211963300;57203616548;35587861100;23569578100;36779565800;56862046400;26421874200;","Using a Critical Incident Scenario With Virtual Humans to Assess Educational Needs of Nurses in a Postanesthesia Care Unit",2015,"Journal of Continuing Education in the Health Professions","35","3",,"158","165",,5,"10.1002/chp.21302","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942040277&doi=10.1002%2fchp.21302&partnerID=40&md5=1a7d4d03614b48ff2c7aa29b97edbee5","University of Virginia School of Medicine, United States; Department of Computer and Information Sciences and Engineering, University of Florida, United States; University of Florida College of Medicine, United States","White, C., University of Virginia School of Medicine, United States; Chuah, J., Department of Computer and Information Sciences and Engineering, University of Florida, United States; Robb, A., Department of Computer and Information Sciences and Engineering, University of Florida, United States; Lok, B., Department of Computer and Information Sciences and Engineering, University of Florida, United States; Lampotang, S., University of Florida College of Medicine, United States; Lizdas, D., University of Florida College of Medicine, United States; Martindale, J., University of Virginia School of Medicine, United States; Pi, G., University of Florida College of Medicine, United States; Wendling, A., University of Florida College of Medicine, United States","Introduction: During critical incidents, teamwork failures can compromise patient safety. This study provides evidence that virtual humans can be used in simulated critical incidents to assess the learning needs of health professionals, and provide important information that can inform the development of continuing education programs in patient safety. We explored the effectiveness of information transfer during a devolving medical situation between postanesthesia care unit (PACU) nurses and a virtual attending physician. Methods: We designed a three-stage scenario: tutorial, patient transfer, and critical incident. We developed 2 checklists to assess information transfer: Critical Patient Information and Interprofessional Communication Skills. All participants were videotaped; 2 raters reviewed all videos and assessed performance using the checklists. Results: Participants (n = 43) who completed all 3 stages scored 62.3% correct on critical patient information transfer and 61.6% correct on interprofessional communication skills. Almost 87% missed a fatal drug error. The checklists measured each item on a 1/0 (done/not) calculation. Additionally, no relationship was found between years of nursing experience and performance on either checklist. Discussion: The PACU nurses in this study did not consistently share critical information with an attending (virtual) physician during a critical incident, and most missed a fatal dosage error. These findings strongly suggest a crucial need for additional structured team training among practicing health care teams, and they demonstrate the utility of using virtual humans to simulate team members. © 2015 The Alliance for Continuing Education in the Health Professions, the Society for Academic Continuing Medical Education, and the Council on CME, Association for Hospital Medical Education.","Simulation; Workplace learning","adult; clinical competence; female; human; interdisciplinary communication; male; middle aged; needs assessment; nurse; pilot study; postanesthesia nursing; procedures; psychology; questionnaire; standards; task performance; teaching; Adult; Clinical Competence; Female; Humans; Interdisciplinary Communication; Male; Middle Aged; Needs Assessment; Nurses; Patient Simulation; Pilot Projects; Postanesthesia Nursing; Surveys and Questionnaires; Task Performance and Analysis",Article,"Final","",Scopus,2-s2.0-84942040277
"Boatright C.D., Kapadia M., Shapira J.M., Badler N.I.","55496983000;25928381400;55983138300;57207599359;","Generating a multiplicity of policies for agent steering in crowd simulation",2015,"Computer Animation and Virtual Worlds","26","5",,"483","494",,12,"10.1002/cav.1572","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942836219&doi=10.1002%2fcav.1572&partnerID=40&md5=3b5f5203c47ed36f0f6918fc0067bea8","Grove City College, Computer Science, 100 Campus Drive, Grove City, PA  16127, United States; Computer and Information Science, University of Pennsylvania, United States","Boatright, C.D., Grove City College, Computer Science, 100 Campus Drive, Grove City, PA  16127, United States, Computer and Information Science, University of Pennsylvania, United States; Kapadia, M., Computer and Information Science, University of Pennsylvania, United States; Shapira, J.M., Computer and Information Science, University of Pennsylvania, United States; Badler, N.I., Computer and Information Science, University of Pennsylvania, United States","Pedestrian steering algorithms range from completely procedural to entirely data-driven, but the former grossly generalize across possible human behaviors and suffer computationally, whereas the latter are limited by the burden of ever-increasing data samples. Our approach seeks the balanced middle ground by deriving a collection of machine-learned policies based on the behavior of a procedural steering algorithm through the decomposition of the space of possible steering scenarios into steering contexts. The resulting algorithm scales well in the number of contexts, the use of new data sets to create new policies, and in the number of controlled agents as the policies become a simple evaluation of the rules asserted by the machine-learning process. We also explore the use of synthetic data from an ""oracle algorithm"" that serves as an as-needed source of samples, which can be stochastically polled for effective coverage. We observe that our approach produces pedestrian steering similar to that of the oracle steering algorithm, but with a significant performance boost. Runtime was reduced from hours under the oracle algorithm with 10 agents to on the order of 10 frames per second (FPS) with 3000 agents. We also analyze the nature of collisions in such a framework with no explicit collision avoidance. Copyright © 2014 John Wiley & Sons, Ltd.","crowd simulation; machine learning; steering; synthetic data","Artificial intelligence; Behavioral research; Learning algorithms; Learning systems; Software agents; Steering; Crowd Simulation; Data driven; Data sample; Frames per seconds; Human behaviors; Runtimes; Steering algorithms; Synthetic data; Algorithms",Article,"Final","",Scopus,2-s2.0-84942836219
"Wilkinson S., Bradbury G., Hanna S.","56193727300;55549595500;8524984200;","Reduced-order urban wind interference",2015,"SIMULATION","91","9",,"809","824",,1,"10.1177/0037549715595135","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943516461&doi=10.1177%2f0037549715595135&partnerID=40&md5=7cc649e91f14a113eff6c2d8b207cc9f","Institute for Environmental Design and Engineering, University College London, United Kingdom","Wilkinson, S., Institute for Environmental Design and Engineering, University College London, United Kingdom; Bradbury, G., Institute for Environmental Design and Engineering, University College London, United Kingdom; Hanna, S., Institute for Environmental Design and Engineering, University College London, United Kingdom","A novel approach is demonstrated to approximate the effects of complex urban interference on the wind-induced surface pressure of tall buildings. This is achieved by decomposition of the domain into two components: the obstruction model (OM) of the static large-scale urban context, for which a single computational fluid dynamics (CFD) simulation is run; and the principal model (PM) of the isolated tall building under design, for which repeatable reduced-order model (ROM) predictions can be made. The ROM is generated with an artificial neural network (ANN), using a set of feature vectors comprising an input of local shape descriptors and a range of wind speeds from a training geometry, and an output response of pressure. For testing, the OM CFD simulation provides the flow boundary condition wind speeds to the PM ROM prediction. The result is vertex-resolution surface pressure data for the PM mesh, intended for use within generative design exploration and optimisation. It is found that the mean absolute prediction error is around 5.0% (σ: 7.8%) with an on-line process time of 390 s, 27 times faster than conventional CFD simulation; considering full process time, only 3.2 design iterations are required for the ROM time to match CFD. Existing work in the literature focuses solely on creating generalised rules relating global configuration parameters and a global interference factor (IF). The work presented here is therefore a significantly alternative approach, with the advantages of increased geometric flexibility, output resolution, speed, and accuracy. © 2015, The Author(s). All rights reserved.","computational fluid dynamics; machine learning; wind interference","Artificial intelligence; Complex networks; Fluid dynamics; Interference suppression; Learning systems; Neural networks; Tall buildings; Wind; Computational fluid dynamics simulations; Flow boundary conditions; Generative design; Geometric flexibility; Global configuration; Interference factor; Mean absolute prediction error; Reduced order models; Computational fluid dynamics",Article,"Final","",Scopus,2-s2.0-84943516461
"Itoh Y., Klinker G.","56154865900;6603530980;","Performance and sensitivity analysis of INDICA: INteraction-Free DIsplay CAlibration for Optical See-Through Head-Mounted Displays",2014,"ISMAR 2014 - IEEE International Symposium on Mixed and Augmented Reality - Science and Technology 2014, Proceedings",,, 6948424,"171","176",,20,"10.1109/ISMAR.2014.6948424","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945128507&doi=10.1109%2fISMAR.2014.6948424&partnerID=40&md5=a5f7e94ab15349a3b47d9c354073238e","Technische Universität München, Germany","Itoh, Y., Technische Universität München, Germany; Klinker, G., Technische Universität München, Germany","An issue in AR applications with Optical See-Through Head-Mounted Display (OST-HMD) is to correctly project 3D information to the current viewpoint of the user. Manual calibration methods give the projection as a black box which explains observed 2D-3D relationships well (Fig. 1). Recently, we have proposed an INteraction-free DIsplay CAlibration method (INDICA) for OST-HMD, utilizing camera-based eye tracking [7]. It reformulates the projection in two ways: a black box with an actual eye model (Recycle Setup), and a combination of an explicit display model and an eye model (Full Setup). Although we have shown the former performs more stably than a repeated SPAAM calibration, we could not yet prove whether the same holds for the Full Setup. More importantly, it is still unclear how the error in the calibration parameters affects the final results. Thus, the users can not know how accurately they need to estimate each parameter in practice. We provide: (1) the fact that the Full Setup performs as accurately as the Recycle Setup under a marker-based display calibration, (2) an error sensitivity analysis for both SPAAM and INDICA over the on-/offline parameters, and (3) an investigation of the theoretical sensitivity on an OST-HMD justified by the real measurements. © 2014 IEEE.","augmented; H.5.1 [Information Interfaces and Presentation]; Multimedia Information Systems - Artificial; virtual realities","Augmented reality; Calibration; Recycling; Sensitivity analysis; Sensory perception; Street traffic control; Technology transfer; Virtual reality; augmented; Calibration parameters; Display calibrations; Error sensitivity analysis; H.5.1 [Information interfaces and presentation]; Manual calibration; Multimedia information systems-artificial; Optical see-through head-mounted displays; Helmet mounted displays",Conference Paper,"Final","",Scopus,2-s2.0-84945128507
"van den Brule R., Dotsch R., Bijlstra G., Wigboldus D.H.J., Haselager P.","55599300400;24074071100;33467538500;6602717972;24448040000;","Do Robot Performance and Behavioral Style affect Human Trust?: A Multi-Method Approach",2014,"International Journal of Social Robotics","6","4",,"519","531",,47,"10.1007/s12369-014-0231-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910000226&doi=10.1007%2fs12369-014-0231-5&partnerID=40&md5=fd054e7f467a2fa35a524c24834ef0c6","Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, Montessorilaan 3, Nijmegen, 6525 HR, Netherlands; Behavioural Science Institute, Radboud University Nijmegen, Montessorilaan 3, Nijmegen, 6525 HR, Netherlands","van den Brule, R., Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, Montessorilaan 3, Nijmegen, 6525 HR, Netherlands, Behavioural Science Institute, Radboud University Nijmegen, Montessorilaan 3, Nijmegen, 6525 HR, Netherlands; Dotsch, R., Behavioural Science Institute, Radboud University Nijmegen, Montessorilaan 3, Nijmegen, 6525 HR, Netherlands; Bijlstra, G., Behavioural Science Institute, Radboud University Nijmegen, Montessorilaan 3, Nijmegen, 6525 HR, Netherlands; Wigboldus, D.H.J., Behavioural Science Institute, Radboud University Nijmegen, Montessorilaan 3, Nijmegen, 6525 HR, Netherlands; Haselager, P., Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, Montessorilaan 3, Nijmegen, 6525 HR, Netherlands","An important aspect of a robot’s social behavior is to convey the right amount of trustworthiness. Task performance has shown to be an important source for trustworthiness judgments. Here, we argue that factors such as a robot’s behavioral style can play an important role as well. Our approach to studying the effects of a robot’s performance and behavioral style on human trust involves experiments with simulated robots in video human–robot interaction (VHRI) and immersive virtual environments (IVE). Although VHRI and IVE settings cannot substitute for the genuine interaction with a real robot, they can provide useful complementary approaches to experimental research in social human robot interaction. VHRI enables rapid prototyping of robot behaviors. Simulating human–robot interaction in IVEs can be a useful tool for measuring human responses to robots and help avoid the many constraints caused by real-world hardware. However, there are also difficulties with the generalization of results from one setting (e.g., VHRI) to another (e.g. IVE or the real world), which we discuss. In this paper, we use animated robot avatars in VHRI to rapidly identify robot behavioral styles that affect human trust assessment of the robot. In a subsequent study, we use an IVE to measure behavioral interaction between humans and an animated robot avatar equipped with behaviors from the VHRI experiment. Our findings reconfirm that a robot’s task performance influences its trustworthiness, but the effect of the behavioral style identified in the VHRI study did not influence the robot’s trustworthiness in the IVE study. © 2014, Springer Science+Business Media Dordrecht.","Immersive virtual environments; Social robotics; Trust; Video stimuli","Agricultural robots; Behavioral research; Virtual reality; Behavioral interactions; Experimental research; Immersive virtual environments; Multi-method approach; Social human-robot interactions; Social robotics; Trust; Video stimuli; Social robots",Article,"Final","",Scopus,2-s2.0-84910000226
"Miller J.L., Rambeck J.H., Snyder A.","57189592117;6507133175;13004000400;","Improving emergency preparedness system readiness through simulation and interprofessional education",2014,"Public Health Reports","129",,,"129","135",,21,"10.1177/00333549141296S417","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922247253&doi=10.1177%2f00333549141296S417&partnerID=40&md5=2ad7e0c8ff9c380e52deaffe7ad39c8a","University of Minnesota, Interprofessional Education and Resource Center, Academic Health Center Simulation Center, Minneapolis, MN, United States; University of Minnesota, Academic Health Center Office of Emergency Response, Minneapolis, MN, United States","Miller, J.L., University of Minnesota, Interprofessional Education and Resource Center, Academic Health Center Simulation Center, Minneapolis, MN, United States; Rambeck, J.H., University of Minnesota, Academic Health Center Office of Emergency Response, Minneapolis, MN, United States; Snyder, A., University of Minnesota, Interprofessional Education and Resource Center, Academic Health Center Simulation Center, Minneapolis, MN, United States","We applied emerging evidence in simulation science to create a curriculum in emergency response for health science students and professionals. Our research project was designed to (1) test the effectiveness of specific immersive simulations, (2) create reliable assessment tools for emergency response and team communication skills, and (3) assess participants’ retention and transfer of skills over time. We collected both quantitative and qualitative data about individual and team knowledge, skills, and attitudes. Content experts designed and pilot-tested scaled quantitative tools. Qualitative evaluations administered immediately after simulations and longitudinal surveys administered 6–12 months later measured student participants’ individual perceptions of their confidence, readiness for emergency response, and transfer of skills to their day-to-day experience. Results from 312 participants enrolled in nine workshops during a 24-month period indicated that the 10-hour curriculum is efficient (compared with larger-scale or longer training programs) and effective in improving skills. The curriculum may be useful for public health practitioners interested in addressing public health emergency preparedness competencies and Institute of Medicine research priority areas. © 2014, Association of Schools and Programs of Public Health.",,"Article; communication skill; curriculum development; emergency care; emergency health service; human; knowledge; medical student; normal human; planning; priority journal; qualitative research; quantitative analysis; safety; simulation; skill; student attitude; time; victim; vocational education; workshop; civil defense; curriculum; disaster planning; education; education; evidence based practice; interpersonal communication; organization and management; public health; standards; total quality management; United States; vocational education; Civil Defense; Communication; Curriculum; Disaster Planning; Education, Professional; Educational Measurement; Evidence-Based Practice; Humans; Public Health; Quality Improvement; United States",Article,"Final","",Scopus,2-s2.0-84922247253
"Powell W., Simmonds M.J.","35243433300;7103093809;","Virtual reality and musculoskeletal pain: Manipulating sensory cues to improve motor performance during walking",2014,"Cyberpsychology, Behavior, and Social Networking","17","6",,"390","396",,5,"10.1089/cyber.2014.0061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901952361&doi=10.1089%2fcyber.2014.0061&partnerID=40&md5=fd3741a64568e340ca0b65eba687d83d","University of Portsmouth, School of Creative Technologies, Eldon Building, Winston Churchill Avenue, Portsmouth P01 2DJ, United Kingdom; University of Texas HSC, San Antonio, TX, United States","Powell, W., University of Portsmouth, School of Creative Technologies, Eldon Building, Winston Churchill Avenue, Portsmouth P01 2DJ, United Kingdom; Simmonds, M.J., University of Texas HSC, San Antonio, TX, United States","Musculoskeletal pain (MSP) is the most expensive nonmalignant health problem and the most common reason for activity limitation. Treatment approaches to improve movement without aggravating pain are urgently needed. Virtual reality (VR) can decrease acute pain, as well as influence movement speed. It is not clear whether VR can improve movement speed in individuals with MSP without aggravating pain. This study investigated the extent to which different audio and optic flow cues in a VR environment influenced walking speed in people with and without MSP. A total of 36 subjects participated, 19 with MSP and 17 controls. All walked on a motorized self-paced treadmill interfaced with a three-dimensional virtual walkway. The audio tempo was scaled (75%, 100%, and 125%) from baseline cadence, and optic flow was either absent, or scaled to 50% or 100% of preferred walking speed. Gait speed was measured during each condition, and pain was measured before and after the experiment. Repeated measures analysis of variance showed that audio tempo above baseline cadence significantly increased walking speed in both groups, F(3, 99)=10.41, p<0.001. Walking speed increases of more than 25% occurred in both groups in the 125% audio tempo condition, without any significant increase in pain. There was also a trend toward increased walking speeds with the use of optic flow, but the results in this study did not achieve significance at the p<0.05 level, F(2, 66)=2.01, p=0.14. Further research is needed to establish the generalizability of increasing movement speed across different physical performance tasks in VR. © Copyright 2014, Mary Ann Liebert, Inc. 2014.",,"adult; article; association; controlled clinical trial; controlled study; female; gait; human; male; methodology; middle aged; motor performance; musculoskeletal pain; psychological aspect; virtual reality exposure therapy; walking; Adult; Cues; Female; Gait; Humans; Male; Middle Aged; Motor Skills; Musculoskeletal Pain; Virtual Reality Exposure Therapy; Walking",Article,"Final","",Scopus,2-s2.0-84901952361
"Connors E.C., Chrastil E.R., Sánchez J., Merabet L.B.","55363650600;36935391000;7403997772;6603146795;","Virtual environments for the transfer of navigation skills in the blind: A comparison of directed instruction vs. video game based learning approaches",2014,"Frontiers in Human Neuroscience","8","MAY", 223,"","",,34,"10.3389/fnhum.2014.00223","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899692409&doi=10.3389%2ffnhum.2014.00223&partnerID=40&md5=1b8c46d74a0cb5d4ae6dfc55b2edb3e7","The Laboratory for Visual Neuroplasticity, Department of Ophthalmology, Massachusetts Eye and Ear Infirmary, Harvard Medical School, Boston, MA, United States; Department of Psychology, Center for Memory and Brain, Boston University, Boston, MA, United States; Department of Computer Science, Center for Advanced Research in Education, University of Chile, Santiago, Chile","Connors, E.C., The Laboratory for Visual Neuroplasticity, Department of Ophthalmology, Massachusetts Eye and Ear Infirmary, Harvard Medical School, Boston, MA, United States; Chrastil, E.R., Department of Psychology, Center for Memory and Brain, Boston University, Boston, MA, United States; Sánchez, J., Department of Computer Science, Center for Advanced Research in Education, University of Chile, Santiago, Chile; Merabet, L.B., The Laboratory for Visual Neuroplasticity, Department of Ophthalmology, Massachusetts Eye and Ear Infirmary, Harvard Medical School, Boston, MA, United States","For profoundly blind individuals, navigating in an unfamiliar building can represent a significant challenge. We investigated the use of an audio-based, virtual environment called Audio-based Environment Simulator (AbES) that can be explored for the purposes of learning the layout of an unfamiliar, complex indoor environment. Furthermore, we compared two modes of interaction with AbES. In one group, blind participants implicitly learned the layout of a target environment while playing an exploratory, goal-directed video game. By comparison, a second group was explicitly taught the same layout following a standard route and instructions provided by a sighted facilitator. As a control, a third group interacted with AbES while playing an exploratory, goal-directed video game however, the explored environment did not correspond to the target layout. Following interaction with AbES, a series of route navigation tasks were carried out in the virtual and physical building represented in the training environment to assess the transfer of acquired spatial information. We found that participants from both modes of interaction were able to transfer the spatial knowledge gained as indexed by their successful route navigation performance. This transfer was not apparent in the control participants. Most notably, the game-based learning strategy was also associated with enhanced performance when participants were required to find alternate routes and short cuts within the target building suggesting that a ludic-based training approach may provide for a more flexible mental representation of the environment. Furthermore, outcome comparisons between early and late blind individuals suggested that greater prior visual experience did not have a significant effect on overall navigation performance following training. Finally, performance did not appear to be associated with other factors of interest such as age, gender, and verbal memory recall. We conclude that the highly interactive and immersive exploration of the virtual environment greatly engages a blind user to develop skills akin to positive near transfer of learning. Learning through a game play strategy appears to confer certain behavioral advantages with respect to how spatial information is acquired and ultimately manipulated for navigation. © 2014 Connors, Chrastil, Sánchez and Merabet.","Early blind; Games for learning; Late blind; Navigation; Near transfer of learning; Spatial cognition; Videogames; Virtual environment","adult; article; blindness; clinical article; cognition; comparative study; computer program; controlled study; explicit memory; female; human; male; navigation; recreation; self evaluation; simulation; spatial learning; task performance; verbal memory; virtual reality",Article,"Final","",Scopus,2-s2.0-84899692409
"Connors E.C., Chrastil E.R., Sánchez J., Merabet L.B.","55363650600;36935391000;7403997772;6603146795;","Action video game play and transfer of navigation and spatial cognition skills in adolescents who are blind",2014,"Frontiers in Human Neuroscience","8","MAR", 133,"","",,36,"10.3389/fnhum.2014.00133","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896989398&doi=10.3389%2ffnhum.2014.00133&partnerID=40&md5=04eb798757de38dc99f74a8326380b0f","The Laboratory for Visual Neuroplasticity, Department of Ophthalmology, Massachusetts Eye and Ear Infirmary, Harvard Medical School, Boston, MA, United States; Department of Psychological and Brain Sciences, Center for Memory and Brain, Boston University, Boston, MA, United States; Department of Computer Science, Center for Advanced Research in Education, University of Chile, Santiago, Chile","Connors, E.C., The Laboratory for Visual Neuroplasticity, Department of Ophthalmology, Massachusetts Eye and Ear Infirmary, Harvard Medical School, Boston, MA, United States; Chrastil, E.R., Department of Psychological and Brain Sciences, Center for Memory and Brain, Boston University, Boston, MA, United States; Sánchez, J., Department of Computer Science, Center for Advanced Research in Education, University of Chile, Santiago, Chile; Merabet, L.B., The Laboratory for Visual Neuroplasticity, Department of Ophthalmology, Massachusetts Eye and Ear Infirmary, Harvard Medical School, Boston, MA, United States","For individuals who are blind, navigating independently in an unfamiliar environment represents a considerable challenge. Inspired by the rising popularity of video games, we have developed a novel approach to train navigation and spatial cognition skills in adolescents who are blind. Audio-based Environment Simulator (AbES) is a software application that allows for the virtual exploration of an existing building set in an action video game metaphor. Using this ludic-based approach to learning, we investigated the ability and efficacy of adolescents with early onset blindness to acquire spatial information gained from the exploration of a target virtual indoor environment. Following game play, participants were assessed on their ability to transfer and mentally manipulate acquired spatial information on a set of navigation tasks carried out in the real environment. Success in transfer of navigation skill performance was markedly high suggesting that interacting with AbES leads to the generation of an accurate spatial mental representation. Furthermore, there was a positive correlation between success in game play and navigation task performance. The role of virtual environments and gaming in the development of mental spatial representations is also discussed. We conclude that this game based learning approach can facilitate the transfer of spatial knowledge and further, can be used by individuals who are blind for the purposes of navigation in real-world environments. © 2014 Connors, Chrastil, Sánchez and Merabet.","Adolescent; Early blind; Gaming for learning; Navigation; Serious videogames; Spatial cognition; Virtual environment","adolescent; article; Audio based Environment Simulator; blindness; clinical article; cognition; computer program; controlled study; data analysis software; female; game; human; neuronavigation; nonhuman; perception; social interaction; spatial learning; task performance; video game; virtual reality; working memory",Article,"Final","",Scopus,2-s2.0-84896989398
"Covaci A., Olivier A.-H., Multon F.","56419559200;15761037000;6602128151;","Third person view and guidance for more natural motor behaviour in immersive basketball playing",2014,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,,,"55","64",,19,"10.1145/2671015.2671023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911165254&doi=10.1145%2f2671015.2671023&partnerID=40&md5=96d2c2541f6beaa265768ac7208a6e8b","Middlesex University London, United Kingdom; Inria, France; M2S Lab, University Rennes2, Inria, France","Covaci, A., Middlesex University London, United Kingdom; Olivier, A.-H., Inria, France; Multon, F., M2S Lab, University Rennes2, Inria, France","The use of Virtual Reality (VR) in sports training is now widely studied with the perspective to transfer motor skills learned in virtual environments (VEs) to real practice. However precision motor tasks that require high accuracy have been rarely studied in the context of VE, especially in Large Screen Image Display (LSID) platforms. An example of such a motor task is the basketball free throw, where the player has to throw a ball in a 46cm wide basket placed at 4.2m away from her. In order to determine the best VE training conditions for this type of skill, we proposed and compared three training paradigms. These training conditions were used to compare the combinations of different user perspectives: first (1PP) and third-person (3PP) perspectives, and the effectiveness of visual guidance. We analysed the performance of eleven amateur subjects who performed series of free throws in a real and immersive 1:1 scale environment under the proposed conditions. The results show that ball speed at the moment of the release in 1PP was significantly lower compared to real world, supporting the hypothesis that distance is underestimated in large screen VEs. However ball speed in 3PP condition was more similar to the real condition, especially if combined with guidance feedback. Moreover, when guidance information was proposed, the subjects released the ball at higher - and closer to optimal - position (5-7% higher compared to no-guidance conditions). This type of information contributes to better understand the impact of visual feedback on the motor performance of users who wish to train motor skills using immersive environments. Moreover, this information can be used by exergames designers who wish to develop coaching systems to transfer motor skills learned in VEs to real practice. Copyright © 2014 by the Association for Computing Machinery, Inc (ACM).","Basketball training; Immersive room; Perception of distance in VR; Performance; Visual feedback","Virtual reality; Visual communication; Guidance feedbacks; Guidance information; Immersive; Immersive environment; Motor performance; Performance; Training conditions; Visual feedback; Sports",Conference Paper,"Final","",Scopus,2-s2.0-84911165254
"Kelly J.W., Hammel W.W., Siegel Z.D., Sjolund L.A.","55346243800;56095556100;56094810300;55547706500;","Recalibration of perceived distance in virtual environments occurs rapidly and transfers asymmetrically across scale",2014,"IEEE Transactions on Visualization and Computer Graphics","20","4", 6777445,"588","595",,35,"10.1109/TVCG.2014.36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897409643&doi=10.1109%2fTVCG.2014.36&partnerID=40&md5=20a9acf9c3a6fc0511fd9c4b60755273","Department of Psychology, Virtual Reality Application Center, Iowa State University, Ames, IA 50011, United States; Department of Psychology, Iowa State University, Ames, IA 50011, United States","Kelly, J.W., Department of Psychology, Virtual Reality Application Center, Iowa State University, Ames, IA 50011, United States; Hammel, W.W., Department of Psychology, Iowa State University, Ames, IA 50011, United States; Siegel, Z.D., Department of Psychology, Virtual Reality Application Center, Iowa State University, Ames, IA 50011, United States; Sjolund, L.A., Department of Psychology, Virtual Reality Application Center, Iowa State University, Ames, IA 50011, United States","Distance in immersive virtual reality is commonly underperceived relative to intended distance, causing virtual environments to appear smaller than they actually are. However, a brief period of interaction by walking through the virtual environment with visual feedback can cause dramatic improvement in perceived distance. The goal of the current project was to determine how quickly improvement occurs as a result of walking interaction (Experiment 1) and whether improvement is specific to the distances experienced during interaction, or whether improvement transfers across scales of space (Experiment 2). The results show that five interaction trials resulted in a large improvement in perceived distance, and that subsequent walking interactions showed continued but diminished improvement. Furthermore, interaction with near objects (1-2 m) improved distance perception for near but not far (4-5 m) objects, whereas interaction with far objects broadly improved distance perception for both near and far objects. These results have practical implications for ameliorating distance underperception in immersive virtual reality, as well as theoretical implications for distinguishing between theories of how walking interaction influences perceived distance. © 2014 IEEE.","Distance perception; recalibration; virtual reality","Depth perception; Experiments; Visual communication; Current projects; Distance perception; Immersive virtual reality; Improved distance; Perceived distances; Recalibrations; Visual feedback; Walking through; Virtual reality",Article,"Final","",Scopus,2-s2.0-84897409643
"Trojan J., Diers M., Fuchs X., Bach F., Bekrater-Bodmann R., Foell J., Kamping S., Rance M., Maaß H., Flor H.","56262402900;6603232814;56154824700;55695210800;42260980200;44760992500;6507437083;36791108000;7005301066;7006743137;","An augmented reality home-training system based on the mirror training and imagery approach",2014,"Behavior Research Methods","46","3",,"634","640",,28,"10.3758/s13428-013-0412-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904767056&doi=10.3758%2fs13428-013-0412-4&partnerID=40&md5=fe577624a9748b6fbfbe2bdb194b15b8","Department of Cognitive und Clinical Neuroscience, Central Institute of Mental Health, Heidelberg University, J 5, 68159 Mannheim, Germany; Department of Psychology, University of Koblenz-Landau, Landau, Germany; Institute of Applied Computer Science, Karlsruhe Institute of Technology, Karlsruhe, Germany; Department of Psychology, Florida State University, Tallahassee, FL, United States","Trojan, J., Department of Cognitive und Clinical Neuroscience, Central Institute of Mental Health, Heidelberg University, J 5, 68159 Mannheim, Germany, Department of Psychology, University of Koblenz-Landau, Landau, Germany; Diers, M., Department of Cognitive und Clinical Neuroscience, Central Institute of Mental Health, Heidelberg University, J 5, 68159 Mannheim, Germany; Fuchs, X., Department of Cognitive und Clinical Neuroscience, Central Institute of Mental Health, Heidelberg University, J 5, 68159 Mannheim, Germany; Bach, F., Institute of Applied Computer Science, Karlsruhe Institute of Technology, Karlsruhe, Germany; Bekrater-Bodmann, R., Department of Cognitive und Clinical Neuroscience, Central Institute of Mental Health, Heidelberg University, J 5, 68159 Mannheim, Germany; Foell, J., Department of Psychology, Florida State University, Tallahassee, FL, United States; Kamping, S., Department of Cognitive und Clinical Neuroscience, Central Institute of Mental Health, Heidelberg University, J 5, 68159 Mannheim, Germany; Rance, M., Department of Cognitive und Clinical Neuroscience, Central Institute of Mental Health, Heidelberg University, J 5, 68159 Mannheim, Germany; Maaß, H., Institute of Applied Computer Science, Karlsruhe Institute of Technology, Karlsruhe, Germany; Flor, H., Department of Cognitive und Clinical Neuroscience, Central Institute of Mental Health, Heidelberg University, J 5, 68159 Mannheim, Germany","Mirror training and movement imagery have been demonstrated to be effective in treating several clinical conditions, such as phantom limb pain, stroke-induced hemiparesis, and complex regional pain syndrome. This article presents an augmented reality home-training system based on the mirror and imagery treatment approaches for hand training. A head-mounted display equipped with cameras captures one hand held in front of the body, mirrors this hand, and displays it in real time in a set of four different training tasks: (1) flexing fingers in a predefined sequence, (2) moving the hand into a posture fitting into a silhouette template, (3) driving a ""Snake"" video game with the index finger, and (4) grasping and moving a virtual ball. The system records task performance and transfers these data to a central server via the Internet, allowing monitoring of training progress. We evaluated the system by having 7 healthy participants train with it over the course of ten sessions of 15-min duration. No technical problems emerged during this time. Performance indicators showed that the system achieves a good balance between relatively easy and more challenging tasks and that participants improved significantly over the training sessions. This suggests that the system is well suited to maintain motivation in patients, especially when it is used for a prolonged period of time. © 2013 The Author(s).","Augmented reality; Complex regional pain syndrome; Imagery; Mirror training; Phantom limb pain; Rehabilitation; Stroke; Virtual reality","adult; agnosia; article; cerebrovascular accident; complex regional pain syndrome; equipment design; female; finger; hand; hand strength; human; male; middle aged; movement (physiology); paresis; physiology; psychotherapy; recreation; reproducibility; young adult; Adult; Complex Regional Pain Syndromes; Equipment Design; Female; Fingers; Hand; Hand Strength; Humans; Imagery (Psychotherapy); Male; Middle Aged; Movement; Paresis; Phantom Limb; Reproducibility of Results; Stroke; Video Games; Young Adult",Article,"Final","",Scopus,2-s2.0-84904767056
"Ganier F., Hoareau C., Tisseau J.","6507178310;55975572000;6603486416;","Evaluation of procedural learning transfer from a virtual environment to a real situation: A case study on tank maintenance training",2014,"Ergonomics","57","6",,"828","843",,36,"10.1080/00140139.2014.899628","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901692802&doi=10.1080%2f00140139.2014.899628&partnerID=40&md5=d3e64acf6619d1cb4b87e64de8cc64fe","Lab-STICC, UMR 6285 CNRS, Université Européenne de Bretagne, Université de Bretagne Occidentale, European Center for Virtual Reality, Plouzané, France; Lab-STICC, UMR 6285 CNRS, Université Européenne de Bretagne, École Nationale d'Ingénieurs de Brest, European Center for Virtual Reality, Plouzané, France","Ganier, F., Lab-STICC, UMR 6285 CNRS, Université Européenne de Bretagne, Université de Bretagne Occidentale, European Center for Virtual Reality, Plouzané, France; Hoareau, C., Lab-STICC, UMR 6285 CNRS, Université Européenne de Bretagne, Université de Bretagne Occidentale, European Center for Virtual Reality, Plouzané, France; Tisseau, J., Lab-STICC, UMR 6285 CNRS, Université Européenne de Bretagne, École Nationale d'Ingénieurs de Brest, European Center for Virtual Reality, Plouzané, France","Virtual reality opens new opportunities for operator training in complex tasks. It lowers costs and has fewer constraints than traditional training. The ultimate goal of virtual training is to transfer knowledge gained in a virtual environment to an actual real-world setting. This study tested whether a maintenance procedure could be learnt equally well by virtual-environment and conventional training. Forty-two adults were divided into three equally sized groups: virtual training (GVT® [generic virtual training]), conventional training (using a real tank suspension and preparation station) and control (no training). Participants then performed the procedure individually in the real environment. Both training types (conventional and virtual) produced similar levels of performance when the procedure was carried out in real conditions. Performance level for the two trained groups was better in terms of success and time taken to complete the task, time spent consulting job instructions and number of times the instructor provided guidance. Practitioner Summary: A key issue for virtual environments for training (VETs) is the transfer of skills to real situations. An experiment investigated whether skills acquired in a VET could be applied in a real situation. Results suggest that a procedure can be successfully transferred from the virtual to the real. © 2014 © 2014 Taylor & Francis.","knowledge transfer; maintenance; procedural learning; virtual environments for training (VET); virtual reality","E-learning; Knowledge management; Maintenance; Tanks (containers); Virtual reality; Knowledge transfer; Maintenance procedures; Maintenance training; Operator training; Performance level; Procedural learning; Real environments; Virtual training; Personnel training; adult; comparative study; computer simulation; computer-assisted instruction; Female; Humans; Inservice Training; Maintenance; Male; Manufacturing Industry; methods; Teaching; Transfer (Psychology); User-Computer Interface; Weapons; Young Adult; Adult; Computer Simulation; Computer-Assisted Instruction; Female; Humans; Inservice Training; Maintenance; Male; Manufacturing Industry; Teaching; Transfer (Psychology); User-Computer Interface; Weapons; Young Adult",Article,"Final","",Scopus,2-s2.0-84901692802
"Hanna N., Richards D.","55618914400;57193711592;","Evaluation framework for 3D collaborative virtual environments (the core)",2014,"Proceedings - Pacific Asia Conference on Information Systems, PACIS 2014",,,,"","",,5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928647065&partnerID=40&md5=a651e2aacaaf34aa96f97eb4598c1bfc","Computing Department, Macquarie University, Sydney, NSW, Australia","Hanna, N., Computing Department, Macquarie University, Sydney, NSW, Australia; Richards, D., Computing Department, Macquarie University, Sydney, NSW, Australia","As a consequence of the increasing interest in Collaborative Virtual Environments (CVEs) and the complex nature of such systems, the need for a thorough evaluation framework has become necessary. The current evaluation frameworks suffer from limitations in assessment because they are either confined to evaluation of a specific type of CVE or they focus on a restricted aspect of CVE. This paper presents a framework for THorough Evaluation of COllaborative viRtual Environment (THE CORE). The proposed framework is structured in a four-layered architecture to assure evaluation of the multi-faceted aspects comprising a CVE. The layers evaluate the application usability, tool usability, companion interaction and collaboration outcome. Within each layer, key evaluation tools and factors are provided. In addition, the framework is designed to be generic to be suitable for different types of CVEs. In order to validate the proposed framework, a case study was conducted involving development and evaluation of a 3D CVE. The case study found the four-layered framework to be useful for evaluating both the technical and behavioural aspects of the 3D CVE. As future work, the generality of the framework will be further tested on different types of CVE, potentially leading to modifications and extensions.","Collaborative virtual environment; Evaluation framework; Human-agent interaction","Display devices; 3D collaborative virtual environments; Behavioural aspects; Collaborative virtual environment; Complex nature; Evaluation framework; Evaluation tool; Human agent interactions; Layered architecture; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84928647065
"Cetnarski R., Betella A., Prins H., Kouider S., Verschure P.F.M.J.","56185248500;23392196300;56159358200;57204347084;7006315557;","Subliminal response priming in mixed reality: The ecological validity of a classic paradigm of perception",2014,"Presence: Teleoperators and Virtual Environments","23","1",,"1","17",,7,"10.1162/PRES_a_00171","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901663790&doi=10.1162%2fPRES_a_00171&partnerID=40&md5=d2fa5bf92204caaba60ce0d7c0b7152d","Laboratory of Synthetic Perceptive Emotive and Cognitive Systems, Center of Autonomous Systems and Neurorobotics, Universitat Pompeu Fabra, Barcelona, Spain; Laboratoire de Sciences Cognitives et Psycholinguistique, EHESS/CNRS/ENS-DEC, Paris, France; ICREA-Institució Catalana de Recerca i Estudis Avançats, Barcelona, Spain","Cetnarski, R., Laboratory of Synthetic Perceptive Emotive and Cognitive Systems, Center of Autonomous Systems and Neurorobotics, Universitat Pompeu Fabra, Barcelona, Spain; Betella, A., Laboratory of Synthetic Perceptive Emotive and Cognitive Systems, Center of Autonomous Systems and Neurorobotics, Universitat Pompeu Fabra, Barcelona, Spain; Prins, H., Laboratoire de Sciences Cognitives et Psycholinguistique, EHESS/CNRS/ENS-DEC, Paris, France; Kouider, S., Laboratoire de Sciences Cognitives et Psycholinguistique, EHESS/CNRS/ENS-DEC, Paris, France; Verschure, P.F.M.J., Laboratory of Synthetic Perceptive Emotive and Cognitive Systems, Center of Autonomous Systems and Neurorobotics, Universitat Pompeu Fabra, Barcelona, Spain, ICREA-Institució Catalana de Recerca i Estudis Avançats, Barcelona, Spain","Subliminal stimuli can affect perception, decision-making, and action without being accessible to conscious awareness. Most evidence supporting this notion has been obtained in highly controlled laboratory conditions. Hence, its generalization to more realistic and ecologically valid contexts is unclear. Here, we investigate the impact of subliminal cues in an immersive navigation task using the so-called eXperience Induction Machine (XIM), a human accessible mixed-reality system. Subjects were asked to navigate through a maze at high speed. At irregular intervals, one group of subjects was exposed to subliminal aversive stimuli using the masking paradigm. We hypothesized that these stimuli would bias decision-making. Indeed, our results confirm this hypothesis and indicate that a subliminal channel of interaction exists between the user and the XIM. These results are relevant in our understanding of the bandwidth of communication that can be established between humans and their physical and social environment, thus opening up to new and powerful methods to interface humans and artefacts. © 2014 by the Massachusetts Institute of Technology.",,"Decision making; Virtual reality; Controlled laboratories; Ecological validity; High Speed; Induction machines; Mixed reality; Navigation tasks; Social environment; Subliminal channel; Telecommunication systems",Article,"Final","",Scopus,2-s2.0-84901663790
"Reiner M., Gelfeld T.M.","7005454900;35797166900;","Estimating mental workload through event-related fluctuations of pupil area during a task in a virtual world",2014,"International Journal of Psychophysiology","93","1",,"38","44",,28,"10.1016/j.ijpsycho.2013.11.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904747464&doi=10.1016%2fj.ijpsycho.2013.11.002&partnerID=40&md5=c3f8772295e9b21d05e844f238c4d117","Israel Institute of Technology, Israel","Reiner, M., Israel Institute of Technology, Israel; Gelfeld, T.M., Israel Institute of Technology, Israel","Monitoring mental load for optimal performance has become increasingly central with the recently evolving need to cope with exponentially increasing amounts of data. This paper describes a non-intrusive, objective method to estimate mental workload in an immersive virtual reality system, through analysis of frequencies of pupil fluctuations. We tested changes in mental workload with a number of task-repetitions, level of predictability of the task and the effect of prior experience in predictable task performance, on mental workload of unpredictable task performance. Two measures were used to calculate mental workload: the ratio of Low Frequency to High Frequency components of pupil fluctuations, and the High Frequency alone, all extracted from the Power Spectrum Density of pupil fluctuations. Results show that mental workload decreases with a number of repetitions, creating a mode in which the brain acts as an automatic controller. Automaticity during training occurs only after a minimal number of repetitions, which once achieved, resulted in further improvements in the performance of unpredictable motor tasks, following training in a predictable task. These results indicate that automaticity is a central component in the transfer of skills from highly predictable to low predictable motor tasks. Our results suggest a potentially applicable method to brain-computer-interface systems that adapt to human mental workload, and provide intelligent automated support for enhanced performance. © 2013 Elsevier B.V.","High/Low Frequency components; Mental workload; Power Spectral Density; Virtual word; Virtual-hand-illusion","adult; article; brain computer interface; comparative study; computer; computer program; controlled study; ecological validity; eye tracker; female; fundus camera; human; human experiment; male; medical device; mental load; normal human; power spectrum; pupil fluctuation; right handedness; stereoscopic vision; task performance; virtual reality; virtual reality modeling language; visual illusion; computer interface; evoked response; eye movement; illusion; learning; physiology; psychology; psychomotor performance; pupil; workload; young adult; Adult; Evoked Potentials; Eye Movements; Female; Humans; Illusions; Learning; Male; Psychomotor Performance; Pupil; User-Computer Interface; Workload; Young Adult",Article,"Final","",Scopus,2-s2.0-84904747464
"Larrue F., Sauzeon H., Wallet G., Foloppe D., Cazalets J.-R., Gross C., N'Kaoua B.","36139685200;7801452039;26425357400;55226000800;7003443071;7402265400;6603602499;","Influence of body-centered information on the transfer of spatial learning from a virtual to a real environment",2014,"Journal of Cognitive Psychology","26","8",,"906","918",,12,"10.1080/20445911.2014.965714","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911413165&doi=10.1080%2f20445911.2014.965714&partnerID=40&md5=41a995e0a6dd9f99b864c6b847a8c3b1","Université Bordeaux, Handicap et Système Nerveux, EA 4136, Bordeaux, F-33000, France; INSERM, IFR Handicap, Handicap et Système Nerveux, Bordeaux, F-33000, France; Inria, Equipe Phoenix, Talence, F-33400, France; Université Bordeaux, CNRS UMR 5287, Institut de Neurosciences Cognitives et Intégratives d'Aquitaine, Bordeaux, F-33000, France; Laboratoire de Psychologie des Pays de Loire (UPRES EA 4638), LUNAM Université, Université d'Angers, Angers, France","Larrue, F., Université Bordeaux, Handicap et Système Nerveux, EA 4136, Bordeaux, F-33000, France, INSERM, IFR Handicap, Handicap et Système Nerveux, Bordeaux, F-33000, France; Sauzeon, H., Université Bordeaux, Handicap et Système Nerveux, EA 4136, Bordeaux, F-33000, France, INSERM, IFR Handicap, Handicap et Système Nerveux, Bordeaux, F-33000, France, Inria, Equipe Phoenix, Talence, F-33400, France; Wallet, G., Université Bordeaux, Handicap et Système Nerveux, EA 4136, Bordeaux, F-33000, France; Foloppe, D., Laboratoire de Psychologie des Pays de Loire (UPRES EA 4638), LUNAM Université, Université d'Angers, Angers, France; Cazalets, J.-R., Université Bordeaux, CNRS UMR 5287, Institut de Neurosciences Cognitives et Intégratives d'Aquitaine, Bordeaux, F-33000, France; Gross, C., Université Bordeaux, CNRS UMR 5287, Institut de Neurosciences Cognitives et Intégratives d'Aquitaine, Bordeaux, F-33000, France; N'Kaoua, B., Université Bordeaux, Handicap et Système Nerveux, EA 4136, Bordeaux, F-33000, France, INSERM, IFR Handicap, Handicap et Système Nerveux, Bordeaux, F-33000, France, Inria, Equipe Phoenix, Talence, F-33400, France","This study investigated the effects of body-centred information on the transfer of spatial learning using a wayfinding task and tasks that specifically probe the route and survey strategies of navigation. The subject learned a route in either a real or a virtual environment (VE; 3D scale model of a Bordeaux neighbourhood) and then reproduced it in the real environment. The involvement of body-based information was manipulated across the spatial learning conditions in the VE: participants learned with full body-based information (treadmill with rotation), with the translational component only (treadmill without rotation) or without body-based information (joystick). In the wayfinding task, the results showed a significant effect of the learning environment with the best scores obtained in the real and treadmill with rotation conditions. There was no significant difference between these two conditions, but the real condition was significantly different from the treadmill without rotation and joystick conditions. Also, the visual flow was sufficient to successfully perform the two egocentric tasks used as well as a direction estimation task (a survey task), in so far as there is no significant difference between the joystick and the treadmill conditions. By contrast, the distance estimates were improved by the treadmill condition including the translational component (but not the rotational component). Finally, our results show that treadmill with rotation promotes the transfer of spatial learning from a virtual to a real environment (compared to joystick and treadmill without rotation). Moreover, body-centred informations are more involved in allocentric (distance estimates) than egocentric navigational strategies. © 2014 Taylor & Francis.","Body-based information; Spatial memory and navigation; Virtual reality; Walking interface","adult; Article; body centered information; controlled study; ego; environment; female; human; information; learning environment; male; normal human; optic flow; spatial learning; spatial memory; task performance; treadmill; virtual reality; walking; young adult; head movement; human experiment; priority journal; treadmill test",Article,"Final","",Scopus,2-s2.0-84911413165
"Arpaia P., Cimmino P., De Matteis E., D'Addio G.","7006199525;36887301200;36604132800;57218355354;","A low-cost force sensor-based posturographic plate for home care telerehabilitation exergaming",2014,"Measurement: Journal of the International Measurement Confederation","51","1",,"400","410",,15,"10.1016/j.measurement.2014.01.031","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899436156&doi=10.1016%2fj.measurement.2014.01.031&partnerID=40&md5=24a1ab460e3bad8f6ff53bdac9d7203a","Department of Engineering, University of Sannio, Corso Garibaldi, 107, 82100 Benevento, Italy; Foundation S. Maugeri, Bioengineering Department, Rehabilitation Institute of Telese, via Bagni Vecchi, 82037 Telese, BN, Italy","Arpaia, P., Department of Engineering, University of Sannio, Corso Garibaldi, 107, 82100 Benevento, Italy; Cimmino, P., Department of Engineering, University of Sannio, Corso Garibaldi, 107, 82100 Benevento, Italy; De Matteis, E., Department of Engineering, University of Sannio, Corso Garibaldi, 107, 82100 Benevento, Italy; D'Addio, G., Foundation S. Maugeri, Bioengineering Department, Rehabilitation Institute of Telese, via Bagni Vecchi, 82037 Telese, BN, Italy","A wireless architecture of posturographic plate, conceived as a physical interface between the patient at home and a semi-immersive virtual environment of telerehabilitation exergaming, is proposed. The design is aimed at maximizing cost reduction as well as hardware and software flexibility, for integrating third-party rehabilitation applications with the exergaming-oriented approach in a telemedicine open development platform. Apart general-purpose bodyweight exercises, rehabilitation protocols based on twofold exergaming tasks for recovering (i) proprioceptive and manual dexterity, using the board by hands for postural motor coordination, and (ii) lower limb proprioception, using by trunk or feet (from sitting and standing posture) to control static and dynamic balance, are provided. The plate was validated experimentally at functional level by means of posturographic and exergame tests, emulating the shots on goal for soccer penalties. Moreover, results of clinical tests in comparison with a force measuring plate of a high-cost professional state-of-the-art system for posturographic analysis, both in normal and in pathological subjects, with open and closed eyes, highlighted encouraging performance and fostered industrial transfer. © 2014 Elsevier B.V. All rights reserved.","Force sensors; Patient rehabilitation; Telemedicine","Application programs; Patient rehabilitation; Sensors; Sensory perception; Telemedicine; Virtual reality; Force sensor; Hardware and software; Industrial transfers; Motor co-ordination; Posturographic analysis; Rehabilitation protocols; State-of-the-art system; Wireless architectures; Cost benefit analysis",Article,"Final","",Scopus,2-s2.0-84899436156
"Martin-Suarez A., Benito J.C., Pérez-Blanco J.S., Millan M.D.C.G., Castañeda A.Z., Gomez H.Z., Martin C.M.","6602683855;56014523400;55269674400;9042640000;7101967944;56014260100;56014458500;","Scientific knowledge transfer training through a virtual world",2014,"Journal of Information Technology Research","7","2",,"24","35",,,"10.4018/jitr.2014040103","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928161931&doi=10.4018%2fjitr.2014040103&partnerID=40&md5=cac575449d60cebce5391ba0db1f63e2","Department of Pharmacy and Pharmaceutical Technology, University of Salamanca, Salamanca, Spain; Research Group in Interaction and ELearning (GRIAL), University of Salamanca, Salmanaca, Spain","Martin-Suarez, A., Department of Pharmacy and Pharmaceutical Technology, University of Salamanca, Salamanca, Spain; Benito, J.C., Research Group in Interaction and ELearning (GRIAL), University of Salamanca, Salmanaca, Spain; Pérez-Blanco, J.S., Department of Pharmacy and Pharmaceutical Technology, University of Salamanca, Salamanca, Spain; Millan, M.D.C.G., Department of Pharmacy and Pharmaceutical Technology, University of Salamanca, Salamanca, Spain; Castañeda, A.Z., Department of Pharmacy and Pharmaceutical Technology, University of Salamanca, Salamanca, Spain; Gomez, H.Z., Department of Pharmacy and Pharmaceutical Technology, University of Salamanca, Salamanca, Spain; Martin, C.M., Department of Pharmacy and Pharmaceutical Technology, University of Salamanca, Salamanca, Spain","The aim of this study was to use the virtual world Second Life (SL) to perform a knowledge transfer training to Pharmacy students. The presentation of assignments of different subjects was organized as scientific congress communications. The activities were carried out at the facilities created at the USALPHARMA Island in SL. The content and format of these works, together with their oral presentation and interventions in debates were evaluated. These experiences provided adequate learning results and a high level of student satisfaction. This teaching strategy can foster development of creativity, critical thinking, communication, co-teamwork and digital competence. Likewise, it can facilitate teacher-student relations and relations among the students themselves. It also implies significant savings in time and money, since real facilities and equipment and physical movement of people are not involved. All of this encourages us to recommend this platform to host all kinds of conferences or scientific conferences. Copyright © 2014, IGI Global.","Knowledge transfer training; Pharmaceutical education; Scientific presentations; Second life; Virtual world","Education; Information management; Knowledge management; Students; Teaching; Virtual reality; Knowledge transfer; Oral presentations; Physical movements; Scientific knowledge; Scientific presentations; Second Life; Student satisfaction; Virtual worlds; Interactive computer graphics",Article,"Final","",Scopus,2-s2.0-84928161931
"Hara K., Hori M., Takemura N., Iwai Y., Sato K.","55376188300;23388871000;23010851300;57201788506;56192879500;","Construction of an interpersonal interaction system using a real image-based avatar",2014,"IEEJ Transactions on Electronics, Information and Systems","134","1",,"102","111",,,"10.1541/ieejeiss.134.102","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891763622&doi=10.1541%2fieejeiss.134.102&partnerID=40&md5=477e441e7d32fc27da3796e7bf57aa1b","Graduate School of Engineering Science, Osaka University, 1-3, Machikaneyama, Toyonaka-shi, Osaka 560-8531, Japan; Graduate School of Engineering, Tottori University, 4-101, Koyamachominami, Tottori-shi, Tottori 680-8550, Japan","Hara, K., Graduate School of Engineering Science, Osaka University, 1-3, Machikaneyama, Toyonaka-shi, Osaka 560-8531, Japan; Hori, M., Graduate School of Engineering, Tottori University, 4-101, Koyamachominami, Tottori-shi, Tottori 680-8550, Japan; Takemura, N., Graduate School of Engineering Science, Osaka University, 1-3, Machikaneyama, Toyonaka-shi, Osaka 560-8531, Japan; Iwai, Y., Graduate School of Engineering, Tottori University, 4-101, Koyamachominami, Tottori-shi, Tottori 680-8550, Japan; Sato, K., Graduate School of Engineering Science, Osaka University, 1-3, Machikaneyama, Toyonaka-shi, Osaka 560-8531, Japan","We propose a method for constructing an interpersonal interaction system using a real image-based avatar. Humancomputer interaction is important when we communicate with computers. As a medium of an interpersonal interaction, communication robots are used commonly in the real world and CG avatar is used in the virtual world. On behalf of the communication robots, android robots that have a similar appearance to an actual person can effectively transfer the human presence. On the other hand, CG avatar has advantages of a cost and installation space as compared to communication robots. When we use a CG avatar for a communication, it is important to increase the reality of a speaker. In this paper, we construct a prototype of an interpersonal interaction system using a real image-based avatar. By generating the avatar from captured images, we can have a high realistic sensation similar to the interpersonal communication system such as a video conference system. In the proposed method, additionally, the movement of the avatar is smoothed by generating interpolated images. The interpolated images are generated by approximating avatar's each body part as an ellipsoid, using user's posture information. To verify the validity of the system, we have conducted the experiments of subjective evaluation. © 2014 The Institute of Electrical Engineers of Japan.","Avatar; Interpersonal interaction; Video communication; Wizard-of-Oz method","Communication; Robots; Virtual reality; Avatar; Inter-personal communications; Interaction systems; Interpersonal interaction; Subjective evaluations; Video communications; Video conference systems; Wizard of Oz; Interactive computer graphics",Article,"Final","",Scopus,2-s2.0-84891763622
"Akhtar K.S.N., Chen A., Standfield N.J., Gupte C.M.","24173166800;57216316518;6602620965;6602169843;","The role of simulation in developing surgical skills",2014,"Current Reviews in Musculoskeletal Medicine","7","2",,"155","160",,34,"10.1007/s12178-014-9209-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905733244&doi=10.1007%2fs12178-014-9209-z&partnerID=40&md5=c5174e2d116b3f1596460dfbd4a1258b","Orthopaedic Surgery, Imperial College, Charing Cross Hospital, Fulham Palace Road, Hammersmith, London W6 8RP, United Kingdom","Akhtar, K.S.N., Orthopaedic Surgery, Imperial College, Charing Cross Hospital, Fulham Palace Road, Hammersmith, London W6 8RP, United Kingdom; Chen, A., Orthopaedic Surgery, Imperial College, Charing Cross Hospital, Fulham Palace Road, Hammersmith, London W6 8RP, United Kingdom; Standfield, N.J., Orthopaedic Surgery, Imperial College, Charing Cross Hospital, Fulham Palace Road, Hammersmith, London W6 8RP, United Kingdom; Gupte, C.M., Orthopaedic Surgery, Imperial College, Charing Cross Hospital, Fulham Palace Road, Hammersmith, London W6 8RP, United Kingdom","Surgical training has followed the masterapprentice model for centuries but is currently undergoing a paradigm shift. The traditional model is inefficient with no guarantee of case mix, quality, or quantity. There is a growing focus on competency-based medical education in response to restrictions on doctors' working hours and the traditional mantra of ""see one, do one, teach one"" is being increasingly questioned. The medical profession is subject to more scrutiny than ever before and is facingmounting financial, clinical, and political pressures. Simulation may be a means of addressing these challenges. It provides a way for trainees to practice technical tasks in a protected environment without putting patients at risk and helps to shorten the learning curve. The evidence for simulation-based training in orthopedic surgery using synthetic models, cadavers, and virtual reality simulators is constantly developing, though further work is needed to ensure the transfer of skills to the operating theatre. © Springer Science+Business Media 2014.","Arthroscopy; Assessment; Boot camp; Cadaver; Competency; Education; Feedback; Patient safety; Phantom; Proficiency; Psychomotor; Simulation; Skills; Surgical training; Task performance; Training; Virtual reality","article; cadaver; clinical competence; clinical practice; disease model; evidence based medicine; human; learning curve; nonhuman; operating room; operation duration; orthopedic surgery; patient safety; phantom; priority journal; psychomotor performance; simulation; skill retention; surgical training; task performance; virtual reality; visual feedback; working time",Article,"Final","",Scopus,2-s2.0-84905733244
"Pluyter J.R., Rutkowski A.-F., Jakimowicz J.J.","35072825500;8047257300;35391591600;","Immersive training: Breaking the bubble and measuring the heat",2014,"Surgical Endoscopy","28","5",,"1545","1554",,10,"10.1007/s00464-013-3350-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900008462&doi=10.1007%2fs00464-013-3350-4&partnerID=40&md5=808a9ebe7f7c7cdc04eb911cd1680dac","Department of Information Systems and Management, Tilburg University, Warandelaan 2, 5037 AB Tilburg, Netherlands; Faculty of Industrial Design Engineering, Delft University of Technology, Landbergstraat 15, 2628 CE Delft, Netherlands; Department of Surgery/Research and Education, Catharina Hospital Eindhoven, Michelangelolaan 2, 5623 EJ Eindhoven, Netherlands","Pluyter, J.R., Department of Information Systems and Management, Tilburg University, Warandelaan 2, 5037 AB Tilburg, Netherlands; Rutkowski, A.-F., Department of Information Systems and Management, Tilburg University, Warandelaan 2, 5037 AB Tilburg, Netherlands; Jakimowicz, J.J., Faculty of Industrial Design Engineering, Delft University of Technology, Landbergstraat 15, 2628 CE Delft, Netherlands, Department of Surgery/Research and Education, Catharina Hospital Eindhoven, Michelangelolaan 2, 5623 EJ Eindhoven, Netherlands","Background: Minimal access surgery and, lately, single-incision laparoscopic procedures are challenging and demanding with regard to the skills of the surgeon performing the procedures. This article presents the results of an investigation of the performance and attention focus of 21 medical interns and surgical residents training in an immersive context. That is, training 'in situation', representing more realistically the demands imposed on the surgeons during minimal access surgery. Methods: Twenty-one medical interns and surgical residents participated in simulation trainings in an integrated operating room for laparoscopic surgery. Various physiological measures of body heat expenditure were gathered as indicators of mental strain and attention focus. Results: The results of the Mann-Whitney test indicated that participants with a poor performance in the two laparoscopic cholecystectomy cases had a significantly (U = 3, p = 0.038) higher heat flux at the start of the procedure (mean 107.08, standard deviation [SD] 24.34) than those who excelled in the two cases (mean 62.64, SD 23.41). Also, the average frontal head temperature of the participants who failed at the task was significantly lower (mean 33.27, SD 0.52) than those who performed well (mean 33.92, SD 0.27). Conclusions: Surgeons cannot operate in a bubble; thus, they should not be trained in one. Combining heat flux and frontal head temperature could be a good measure of deep involvement and attentional focus during performance of simulated surgical tasks. © 2014 Springer Science+Business Media.","Attention focus; Cognitive absorption; Immersive training; Mental strain; Simulation training","adult; article; attention; body temperature measurement; cholecystectomy; female; heat transfer; human; human experiment; laparoscopic surgery; male; mental stress; monitor; operating room; performance; priority journal; resident; simulation; simulator; surgical stress; surgical training; virtual reality; body temperature; clinical competence; cognition; computer simulation; education; heat; laparoscopy; medical education; medical education; operating room; physiology; procedures; psychology; workload; young adult; Adult; Attention; Body Temperature; Clinical Competence; Cognition; Computer Simulation; Education, Medical, Continuing; Female; Hot Temperature; Humans; Internship and Residency; Laparoscopy; Male; Operating Rooms; Workload; Young Adult",Article,"Final","",Scopus,2-s2.0-84900008462
"Pucher P.H., Batrick N., Taylor D., Chaudery M., Cohen D., Darzi A.","50162336700;18133430500;55851945195;16244070000;57214762952;14633357600;","Virtual-world hospital simulation for real-world disaster response: Design and validation of a virtual reality simulator for mass casualty incident management",2014,"Journal of Trauma and Acute Care Surgery","77","2",,"315","321",,29,"10.1097/TA.0000000000000308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905016019&doi=10.1097%2fTA.0000000000000308&partnerID=40&md5=536e68d549b8bb166c60a53d0a104048","Departments of Surgery and Cancer, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom; Emergency Medicine, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom","Pucher, P.H., Departments of Surgery and Cancer, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom; Batrick, N., Departments of Surgery and Cancer, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom, Emergency Medicine, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom; Taylor, D., Departments of Surgery and Cancer, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom; Chaudery, M., Departments of Surgery and Cancer, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom; Cohen, D., Departments of Surgery and Cancer, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom; Darzi, A., Departments of Surgery and Cancer, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom","BACKGROUND: Mass casualty incidents are unfortunately becoming more common. The coordination of mass casualty incident response is highly complex. Currently available options for training, however, are limited by either lack of realism or prohibitive expense and by a lack of assessment tools. Virtual worlds represent a potentially cost-effective, immersive, and easily accessible platform for training and assessment. The aim of this study was to assess feasibility of a novel virtual-worlds-based system for assessment and training in major incident response. METHODS: Clinical areas were modeled within a virtual, online hospital. A major incident, incorporating virtual casualties, allowed multiple clinicians to simultaneously respond with appropriate in-world management and transfer plans within limits of the hospital's available resources. Errors, delays, and completed actions were recorded, as well as Trauma-NOnTECHnical Skills (T-NOTECHS) score. Performance was compared between novice and expert clinician groups. RESULTS: Twenty-one subjects participated in three simulations: pilot (n = 7), novice (n = 8), and expert groups (n = 6). The novices committed more critical events than the experts, 11 versus 3, p = 0.006; took longer to treat patients, 560 (299) seconds versus 339 (321) seconds, p = 0.026; and achieved poorer T-NOTECHS scores, 14 (2) versus 21.5 (3.7), p = 0.003, and technical skill, 2.29 (0.34) versus 3.96 (0.69), p = 0.001. One hundred percent of the subjects thought that the simulation was realistic and superior to existing training options. CONCLUSION: A virtual-worlds-based model for the training and assessment of major incident response has been designed and validated. The advantages of customizability, reproducibility, and recordability combined with the low cost of implementation suggest that this potentially represents a powerful adjunct to existing training methods and may be applicable to further areas of surgery as well. © 2014 Lippincott Williams & Wilkins.","Distributed; Online; Simulation; Trauma; Virtual","article; clinical decision making; computer interface; computer program; disaster planning; emergency health service; emergency medicine; emergency treatment; emergency ward; female; general surgery; human; intensive care; intensive care unit; male; mass disaster; medical education; online system; operating room; performance measurement system; priority journal; questionnaire; reproducibility; resident; resource management; resuscitation; simulation; simulator; skill; training; traumatology; validation study; virtual reality; Disaster Medicine; Disaster Planning; Hospitalization; Humans; Mass Casualty Incidents; Reproducibility of Results; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84905016019
"Halfer D., Rosenheck M.","14024237900;55862967700;","Virtual education: Is it effective for preparing nurses for a hospital move?",2014,"Journal of Nursing Administration","44","10",,"535","540",,6,"10.1097/NNA.0000000000000112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84916219092&doi=10.1097%2fNNA.0000000000000112&partnerID=40&md5=6a9997abbeaf9ad3973ca5eb321643a9","Department of Clinical and Organizational Development, Ann and Robert H. Lurie Children's Hospital of Chicago, 225 E Chicago Ave, Chicago, IL  60611, United States; Cognitive Advisors LLC, Evanston, IL, United States","Halfer, D., Department of Clinical and Organizational Development, Ann and Robert H. Lurie Children's Hospital of Chicago, 225 E Chicago Ave, Chicago, IL  60611, United States; Rosenheck, M., Cognitive Advisors LLC, Evanston, IL, United States","OBJECTIVE: The objective of this study was to compare the effectiveness of using a virtual environment (VE) versus traditional paper floor plans (FPs) to prepare nurses for wayfinding in a new hospital building.BACKGROUND: This study was designed to control for variables such as task complexity and individual ability that have been missed in other media comparison studies.METHODS: Thirty nurses were assigned to the VE or FP condition using a randomized block experimental design. Subjects were blocked by alternate ranks on spatial/navigational ability and computer attitude/ experience and randomly assigned to conditions.Nurses received instruction with either a VE or FP condition. Wayfinding tasks were then completed with trained observers at the new hospital under construction.RESULTS: The investigators found no significant differences between thewayfinding performance or postintervention confidence levels of subjects. Instruction using both media improved wayfinding and navigation skills. Qualitative findings suggest that interactions of the instructional style, media, and learner influence information retention and transfer.CONCLUSIONS: Although the virtualmedia did not prove to bemore effective than FPs, it was equally effective for learning wayfinding and navigation skills in a new hospital. Nursing leaders may want to consider use of 3-dimensional VEs as an early method to provide repetitive practice for learning how to navigate a new large-scale space. © 2014 Wolters Kluwer Health.",,"adult; comparative study; computer interface; controlled study; education; female; health care facility; health services research; human; male; nursing staff; organization and management; pilot study; randomized controlled trial; spatial orientation; task performance; United States; Adult; Chicago; Female; Health Facility Moving; Humans; Male; Nursing Staff, Hospital; Organizational Case Studies; Pilot Projects; Spatial Navigation; Task Performance and Analysis; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84916219092
"Slade Shantz J.A., Leiter J.R.S., Gottschalk T., MacDonald P.B.","55240226400;15923485400;26031375100;7202038384;","The internal validity of arthroscopic simulators and their effectiveness in arthroscopic education",2014,"Knee Surgery, Sports Traumatology, Arthroscopy","22","1",,"33","40",,28,"10.1007/s00167-012-2228-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891663621&doi=10.1007%2fs00167-012-2228-7&partnerID=40&md5=d45d6451d2aa9f27c3f0a27f522d617d","Department of Orthopaedic Surgery, University of California, San Francisco, CA, United States; Department of Surgery, Section of Orthopedics, University of Manitoba, Winnipeg, Canada; Department of Human Anatomy and Cell Science, University of Manitoba, Winnipeg, Canada; Neil John Maclean Health Sciences Library, University of Manitoba, 239 Brodie Centre, 750 McDermot Ave, Winnipeg, MB, R3T 2N2, Canada; Pan Am Clinic, 75 Poseidon Bay, Winnipeg, MB, R3M 3E4, Canada; San Francisco General Hospital, Orthopaedic Trauma Institute, 2550 23rd Street, San Francisco, CA, 94110, United States","Slade Shantz, J.A., Department of Orthopaedic Surgery, University of California, San Francisco, CA, United States, Pan Am Clinic, 75 Poseidon Bay, Winnipeg, MB, R3M 3E4, Canada, San Francisco General Hospital, Orthopaedic Trauma Institute, 2550 23rd Street, San Francisco, CA, 94110, United States; Leiter, J.R.S., Department of Surgery, Section of Orthopedics, University of Manitoba, Winnipeg, Canada, Department of Human Anatomy and Cell Science, University of Manitoba, Winnipeg, Canada, Pan Am Clinic, 75 Poseidon Bay, Winnipeg, MB, R3M 3E4, Canada; Gottschalk, T., Neil John Maclean Health Sciences Library, University of Manitoba, 239 Brodie Centre, 750 McDermot Ave, Winnipeg, MB, R3T 2N2, Canada; MacDonald, P.B., Department of Surgery, Section of Orthopedics, University of Manitoba, Winnipeg, Canada, Pan Am Clinic, 75 Poseidon Bay, Winnipeg, MB, R3M 3E4, Canada","Purpose: The purpose of this systematic review was to identify standard procedures for the validation of arthroscopic simulators and determine whether simulators improve the surgical skills of users. Methods: Arthroscopic simulator validation studies and randomized trials assessing the effectiveness of arthroscopic simulators in education were identified from online databases, as well as, grey literature and reference lists. Only validation studies and randomized trials were included for review. Study heterogeneity was calculated and where appropriate, study results were combined employing a random effects model. Results: Four hundred and thirteen studies were reviewed. Thirteen studies met the inclusion criteria assessing the construct validity of simulators. A pooled analysis of internal validation studies determined that simulators could discriminate between novice and experts, but not between novice and intermediate trainees on time of completion of a simulated task. Only one study assessed the utility of a knee simulator in training arthroscopic skills directly and demonstrated that the skill level of simulator-trained residents was greater than non-simulator-trained residents. Conclusions: Excessive heterogeneity exists in the literature to determine the internal and transfer validity of arthroscopic simulators currently available. Evidence suggests that simulators can discriminate between novice and expert users, but discrimination between novice and intermediate trainees in surgical education should be paramount. International standards for the assessment of arthroscopic simulator validity should be developed to increase the use and effectiveness of simulators in orthopedic surgery. Level of evidence: Diagnostic study, Level III. © 2012 Springer-Verlag Berlin Heidelberg.","Arthroscopic simulators; Surgical education; Validation; Virtual reality","arthroscopy; article; clinical competence; computer simulation; education; human; knee; learning; medical education; orthopedics; reproducibility; task performance; Arthroscopy; Clinical Competence; Computer Simulation; Education, Medical, Continuing; Humans; Knee Joint; Orthopedics; Reproducibility of Results; Task Performance and Analysis; Transfer (Psychology)",Article,"Final","",Scopus,2-s2.0-84891663621
"Pedro M.S., Jiang Y., Paquette L., Baker R.S., Gobert J.","55397026200;57203598332;35262509400;8967971100;7007169230;","Identifying transfer of inquiry skills across physical science simulations using educational data mining",2014,"Proceedings of International Conference of the Learning Sciences, ICLS ","1","January",,"222","229",,4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937864161&partnerID=40&md5=c403939c099b83a57aab965a27a69700","Worcester Polytechnic Institute, 100 Institute Rd., Worcester, MA  01609, United States; Teachers College, 525 W. 120th St., New York, NY  10027, United States","Pedro, M.S., Worcester Polytechnic Institute, 100 Institute Rd., Worcester, MA  01609, United States; Jiang, Y., Teachers College, 525 W. 120th St., New York, NY  10027, United States; Paquette, L., Teachers College, 525 W. 120th St., New York, NY  10027, United States; Baker, R.S., Teachers College, 525 W. 120th St., New York, NY  10027, United States; Gobert, J., Worcester Polytechnic Institute, 100 Institute Rd., Worcester, MA  01609, United States","Students conducted inquiry using simulations within a rich learning environment for 4 science topics. By applying educational data mining to students' log data, assessment metrics were generated for two key inqury skills, testing stated hypotheses and designing controlled experiments. Three models were then developed to analyze the transfer of these inquiry skills between science topics. Model one, Classic Bayesian Knowledge Tracing, assumes that either complete transfer of skill occurs or no transfer occurs; model two (BKTPST), an extension of BKT, assumes partial transfer and tests that assumption; and model three, a variant of BKT-PST, assumes no transfer and tests this assumption. An analysis of models one and two suggest that transfer of these inquiry skills across topics did occur. This work makes contributions to methodological approaches for measuring fine-grained skills using log files, as well as to the literature on the domain-specificity vs. domain-generality of inquiry skills. © 2014 ISLS.",,"Computer aided instruction; Data mining; Education; Statistical tests; Assessment metrics; Bayesian knowledge tracings; Controlled experiment; Domain specificity; Educational data mining; Learning environments; Methodological approach; Physical science; Students",Conference Paper,"Final","",Scopus,2-s2.0-84937864161
"Botma Y.","6506227390;","Nursing student's perceptions on how immersive simulation promotes theory-practice integration",2014,"International Journal of Africa Nursing Sciences","1",,,"1","5",,16,"10.1016/j.ijans.2014.04.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919383531&doi=10.1016%2fj.ijans.2014.04.001&partnerID=40&md5=95dec7e7ea2b049c49d11bce69abf5b0","School of Nursing, University of the Free State, Bloemfontein, 9300, South Africa","Botma, Y., School of Nursing, University of the Free State, Bloemfontein, 9300, South Africa","The inability of nurses to transfer to the clinical setting what they have learned in class, may be because nurse educators do not use teaching strategies that promote transfer of learning. Unfortunately there is paucity of evidence as to which teaching strategies promote transfer of learning. Based on a qualitative descriptive study, this article attempts to answer the question about how simulation helps students to apply in practice what they have learned in class. Open coding of the data that were gathered through two focus group interviews and documents revealed that simulation promotes theory-practice integration, builds confidence, makes students aware of the aspects of care that need to be improved through deliberate practice, increases the motivation to learn and transfer their knowledge, and strengthens communication among team members. Knowledge on the benefits of simulation can guide nurse educators to harness the method to enhance transfer of learning. © 2014 The Author.","Deliberate practice; Simulation; Theory-practice integration; Transfer of learning","Article; clinical practice; discourse analysis; evidence based practice; human; interpersonal communication; interview; knowledge; learning; nursing student; perception; psychomotor performance; simulation; teaching; teamwork; theory-practice relationship; trust; validation process; work experience",Article,"Final","",Scopus,2-s2.0-84919383531
"Arora S., Cox C., Davies S., Kassab E., Mahoney P., Sharma E., Darzi A., Vincent C., Sevdalis N.","55156116900;7402112183;57198502609;35590030400;12808524800;55565675100;14633357600;57202463538;35293409500;","Towards the next frontier for simulation-based training: Full-hospital simulation across the entire patient pathway",2014,"Annals of Surgery","260","2",,"252","258",,20,"10.1097/SLA.0000000000000305","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905561932&doi=10.1097%2fSLA.0000000000000305&partnerID=40&md5=243e094c53a3ad11509d09dbfe46a8ce","Department of Surgery and Cancer, St Marys Hospital, Imperial College London, London W2 1NY, United Kingdom; Royal Wolverhampton NHS Trust, Wolverhampton, West Midlands, United Kingdom; University Hospital of North Staffordshire NHS Trust, Stokeon-Trent, Staffordshire, United Kingdom; RoyalCentre for DefenceMedicine, Birmingham, United Kingdom","Arora, S., Department of Surgery and Cancer, St Marys Hospital, Imperial College London, London W2 1NY, United Kingdom; Cox, C., Royal Wolverhampton NHS Trust, Wolverhampton, West Midlands, United Kingdom; Davies, S., University Hospital of North Staffordshire NHS Trust, Stokeon-Trent, Staffordshire, United Kingdom; Kassab, E., Department of Surgery and Cancer, St Marys Hospital, Imperial College London, London W2 1NY, United Kingdom; Mahoney, P., RoyalCentre for DefenceMedicine, Birmingham, United Kingdom; Sharma, E., Department of Surgery and Cancer, St Marys Hospital, Imperial College London, London W2 1NY, United Kingdom; Darzi, A., Department of Surgery and Cancer, St Marys Hospital, Imperial College London, London W2 1NY, United Kingdom; Vincent, C., Department of Surgery and Cancer, St Marys Hospital, Imperial College London, London W2 1NY, United Kingdom; Sevdalis, N., Department of Surgery and Cancer, St Marys Hospital, Imperial College London, London W2 1NY, United Kingdom","Objective: To evaluate the efficacy of an entire hospital simulation in imparting skills to expert healthcare providers, encompassing both retention and transfer to clinical practice. Background: Studies demonstrating the effectiveness of simulation do not concentrate upon expert multidisciplinary teams. Moreover, their focus is confined to a single clinical setting, thereby not considering the complex interactions across multiple hospital departments. Methods: A total of 288 participants (Attending surgeons, anesthesiologists, physicians, and nurses) completed this largest simulation study to date, set in the UK Defence Medical Services' Hospital Simulator and the conflict zone in Afghanistan. The simulator termed ""Hospital Exercise"" (HOSPEX) is a fully immersive live-in simulation experience that covers the entire environment of a military hospital with all departments. Participants undertook a 3-day training program within HOSPEX before deployment to war zones. Primary outcome measures were assessed with IMPAcT (the Imperial Military Personnel Assessment Tool). IMPAcT measures crisis management, trauma care, hospital environment, operational readiness, and transfer of skills to civilian practice. Reliability, skills learning, and retention in the conflict zone were assessed statistically. Results: Reliability in skills assessment was excellent (Cronbach α: nontechnical skills = 0.87-0.94; environment/patient skills = 0.83-0.95). Pre/post-HOSPEX comparisons revealed significant improvements in decision making (M = 4.98, SD = 1.20 to M = 5.39, SD = 0.91; P = 0.03), situational awareness (M = 5.44, SD = 1.04 to M = 5.74, SD = 0.92; P = 0.01), trauma care (M = 5.53, SD = 1.23 to M = 5.85, SD = 1.09; P = 0.05), and knowledge of hospital environment (M = 5.19, SD = 1.17 to M = 5.42, SD = 0.97; P = 0.04). No skills decayed over time when assessed several months later in the real conflict zone. All skills transferred to civilian clinical practice. Conclusions: This is the first study to describe the value of a full-hospital simulation across the entire patient pathway. Such macrosimulations may be the way forward for integrating the complex training needs of expert clinicians and testing organizational ""fitness for purpose"" of entire hospitals. Copyright © 2014 Lippincott Williams & Wilkins.","Nontechnical skills; Simulation; Surgery; Teamwork; Training","adult; Afghanistan; anesthesist; army; article; awareness; clinical competence; clinical decision making; clinical effectiveness; emergency health service; female; full hospital simulation; hospital department; human; Imperial Military Personnel Assessment Tool; interpersonal communication; leadership; male; nurse; outcome assessment; patient care; performance measurement system; physician; priority journal; professional knowledge; simulation; skill retention; staff training; surgeon; teamwork; traumatology; United Kingdom; adolescent; clinical competence; cross-sectional study; hospital management; hospital planning; in service training; middle aged; military medicine; organization and management; program evaluation; prospective study; teaching; Adolescent; Adult; Clinical Competence; Cross-Sectional Studies; Female; Great Britain; Hospital Administration; Hospital Planning; Humans; Inservice Training; Male; Middle Aged; Military Medicine; Patient Care Team; Patient Simulation; Program Evaluation; Prospective Studies",Article,"Final","",Scopus,2-s2.0-84905561932
"Casey T.W., Poropat A.","55812385600;15768162100;","Beauty is more than screen deep: Improving the web survey respondent experience through socially-present and aesthetically-pleasing user interfaces",2014,"Computers in Human Behavior","30",,,"153","163",,9,"10.1016/j.chb.2013.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883781088&doi=10.1016%2fj.chb.2013.08.001&partnerID=40&md5=e41dc3a5c54b1330114c828d09c04ca9","Sentis, PO Box 303, Morningside, QLD 4170, Australia; School of Psychology, Griffith University, Mt Gravatt Campus, Messines Ridge Road, Holland Park West, QLD 4121, Australia","Casey, T.W., Sentis, PO Box 303, Morningside, QLD 4170, Australia; Poropat, A., School of Psychology, Griffith University, Mt Gravatt Campus, Messines Ridge Road, Holland Park West, QLD 4121, Australia","Web surveys are rapidly becoming standard issue in many researchers' toolkits; however, measurement error has been shown to affect web surveys to a greater extent than paper-and-pencil surveys (Couper, 2000; Manfreda & Vehovar, 2002). Principles of aesthetic design and social presence have been applied to web surveys to reduce the prevalence of such error with promising results, which were further investigated in this research. A sample of 181 first-year psychology undergraduate students participated in this study. Participants were randomly allocated to view one of eight web survey interfaces, which varied by aesthetic quality and social presence. Exploratory structural equation modeling using the partial least squares method revealed that classical aesthetic quality and social presence were both positively related to perceived ease of use of the web survey interface and positive state affect; social presence and perceived ease of use were positively related to trust in the web survey researcher; classical aesthetic quality was negatively related to negative state affect; and, expressive aesthetic quality was negatively related to perceived ease of use and positively related to positive state affect. Interestingly, expressive aesthetic quality was also positively related to negative state affect. These relationships between aesthetic quality and social presence should inform best practice web survey design recommendations, and future empirical work should extend and test the generalizability of these findings. © 2013 Elsevier Ltd. All rights reserved.","Aesthetics; Human-computer interaction; Perceived ease of use; Trust; Web surveys","Aesthetics; Partial least-squares method; Perceived ease of use; Respondent experiences; Structural equation modeling; Trust; Undergraduate students; Web surveys; Human computer interaction; Interface states; Least squares approximations; Research; Students; User interfaces; Surveys",Article,"Final","",Scopus,2-s2.0-84883781088
"Cowan B., Kapralos B.","55411698800;55946696900;","Spatial sound rendering for dynamic virtual environments",2013,"2013 18th International Conference on Digital Signal Processing, DSP 2013",,, 6622815,"","",,2,"10.1109/ICDSP.2013.6622815","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888863809&doi=10.1109%2fICDSP.2013.6622815&partnerID=40&md5=b08e4c7a4470dd3a1dc65146ef7e12b7","Faculty of Business and Information Technology, University of Ontario, Institute of Technology, Oshawa, ON, Canada","Cowan, B., Faculty of Business and Information Technology, University of Ontario, Institute of Technology, Oshawa, ON, Canada; Kapralos, B., Faculty of Business and Information Technology, University of Ontario, Institute of Technology, Oshawa, ON, Canada","We present the details of a virtual sound rendering engine (VSRE) that is being developed for virtual environments and serious games. The VSRE incorporates innovative graphics processing unit - based methods to allow for the approximation of acoustical occlusion/diffraction and reverberation effects at interactive rates. In addition, the VSRE includes a GPU-based method that performs the one-dimensional convolution allowing for the incorporation of head-related transfer functions also at interactive rates. The VSRE is being developed as a research tool for examining multi-modal (audio-visual) interactions through the simple manipulation of the acoustic environment and audio parameters (sound quality), that will, through a series of human-based experiments, allow for the testing of the effect of varying these parameters may have on immersion, engagement, and visual fidelity perception within a virtual environment. Finally, we also provide a running time comparison of several one-dimensional convolution implementations. © 2013 IEEE.","3D sound; Graphics processing unit (GPU); Serious games; Spatial sound; Virtual environment","3D sound; Acoustic environment; Dynamic virtual environment; Graphics Processing Unit; Head related transfer function; Reverberation effects; Serious games; Spatial sound; Convolution; Digital signal processing; Program processors; Sound reproduction; Three dimensional computer graphics; Virtual reality; Computer graphics equipment",Conference Paper,"Final","",Scopus,2-s2.0-84888863809
"Chen S.-C., Hsu C.-W., Huang D.-Y., Lin S.-Y., Hung Y.-P.","54781137900;57198783917;55536530700;57026557500;26643286300;","TelePort: Virtual touring of Dun-Huang with a mobile device",2013,"Electronic Proceedings of the 2013 IEEE International Conference on Multimedia and Expo Workshops, ICMEW 2013",,, 6618406,"","",,3,"10.1109/ICMEW.2013.6618406","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888225852&doi=10.1109%2fICMEW.2013.6618406&partnerID=40&md5=fdee4b6bdc06c3299e013445ad291016","Dept. of Computer Science and Information Engineering, National Taiwan University, Taiwan; Graduate Institute of Networking and Multimedia, National Taiwan University, Taiwan","Chen, S.-C., Dept. of Computer Science and Information Engineering, National Taiwan University, Taiwan; Hsu, C.-W., Dept. of Computer Science and Information Engineering, National Taiwan University, Taiwan; Huang, D.-Y., Graduate Institute of Networking and Multimedia, National Taiwan University, Taiwan; Lin, S.-Y., Graduate Institute of Networking and Multimedia, National Taiwan University, Taiwan; Hung, Y.-P., Dept. of Computer Science and Information Engineering, National Taiwan University, Taiwan, Graduate Institute of Networking and Multimedia, National Taiwan University, Taiwan","Some of our daily encountering is the objects of pictures, antiques, sculptures or wall-paintings captured or moved from the source space to another media platform. For example, the Direct Mail advertising of house sale, the historical exhibit in the museum. In fact, few figures or text descriptions will never be able to provide us the rewarding experience unless people can actually visit the source space in person. Inspired by the Boo's doors in the Disney's cartoon of Monsters Inc. which are used as a pathway to different spaces, we propose the 'TelePort' as a gateway providing a virtual touring to the source space and achieve the prototype using a mobile device. To begin the TelePort, users first aim the object onto the mobile's screen. Subsequently, the screen view will immediately transfer to the view of the source space seamlessly as if users look into the space from the entrance gate. After transferring to the space, users can explore the source space and interact with the contents belonged to the space in reality through panorama visualization. To support the first person navigation, the viewpoint direction within the space can be detected by the mobile pose. This novel navigation interface can deliver to users an interesting and realistic experience as teleportation. Our contribution is to demonstrate an innovative experience for a virtual tour of the Mogao Caves using a mobile device. The 'Teleport' featuring the virtual gateway which brings users to the Cave not only attracts attention but also enhances the experience of space exploring. © 2013 IEEE.","HCI; interaction design; mobile; navigation; Touring","Direct mail advertising; First-person-navigation; Interaction design; Media platforms; mobile; Navigation interface; Touring; Virtual gateways; Exhibitions; Human computer interaction; Navigation; Mobile devices",Conference Paper,"Final","",Scopus,2-s2.0-84888225852
"Zmuda M.A., Wonser J.L., Bachmann E.R., Hodgson E.","55905032400;35729733600;7005745121;14053915200;","Optimizing constrained-environment redirected walking instructions using search techniques",2013,"IEEE Transactions on Visualization and Computer Graphics","19","11", 6520845,"1872","1884",,37,"10.1109/TVCG.2013.88","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884554083&doi=10.1109%2fTVCG.2013.88&partnerID=40&md5=091fedd90ee3852d2e41955d41a5eb1f","Department of Computer Science and Software Engineering, Miami University, 201D Benton Hall, Oxford, OH 45056, United States; Department of Psychology, Miami University, Oxford, OH 45056, United States","Zmuda, M.A., Department of Computer Science and Software Engineering, Miami University, 201D Benton Hall, Oxford, OH 45056, United States; Wonser, J.L., Department of Computer Science and Software Engineering, Miami University, 201D Benton Hall, Oxford, OH 45056, United States; Bachmann, E.R., Department of Computer Science and Software Engineering, Miami University, 201D Benton Hall, Oxford, OH 45056, United States; Hodgson, E., Department of Psychology, Miami University, Oxford, OH 45056, United States","A goal of redirected walking (RDW) is to allow large virtual worlds to be explored within small tracking areas. Generalized steering algorithms, such as steer-to-center, simply move the user toward locations that are considered to be collision free in most cases. The algorithm developed here, FORCE, identifies collision-free paths by using a map of the tracking area's shape and obstacles, in addition to a multistep, probabilistic prediction of the user's virtual path through a known virtual environment. In the present implementation, the path predictions describe a user's possible movements through a virtual store with aisles. Based on both the user's physical and virtual location/orientation, a search-based optimization technique identifies the optimal steering instruction given the possible user paths. Path prediction uses the map of the virtual world; consequently, the search may propose steering instructions that put the user close to walls if the user's future actions eventually lead away from the wall. Results from both simulated and real users are presented. FORCE identifies collision-free paths in 55.0 percent of the starting conditions compared to 46.1 percent for generalized methods. When considering only the conditions that result in different outcomes, redirection based on FORCE produces collision-free path 94.5 percent of the time. © 2013 IEEE.","Backtracking; motion compression; redirected walking; virtual reality","Backtracking; Collision-free paths; Generalized method; Motion compression; Optimization techniques; Probabilistic prediction; Redirected walkings; Steering algorithms; Algorithms; Interactive computer graphics; Virtual reality; Optimization; adult; algorithm; computer graphics; computer interface; computer simulation; environment; human; male; orientation; physiology; procedures; three dimensional imaging; walking; article; methodology; three dimensional imaging; walking; Adult; Algorithms; Computer Graphics; Computer Simulation; Environment; Humans; Imaging, Three-Dimensional; Male; Orientation; User-Computer Interface; Walking; Adult; Algorithms; Computer Graphics; Computer Simulation; Environment; Humans; Imaging, Three-Dimensional; Male; Orientation; User-Computer Interface; Walking",Article,"Final","",Scopus,2-s2.0-84884554083
"Chavez-Gamboa M., Herrera-Aguilar I., Sandoval-Gonzalez O., Malagon-Gonzalez F., Jacinto-Villegas J.M.","55811826400;34167892600;25031570600;55811873100;57192265005;","Anthropomorphic robotic system with 6 DOF for space positioning in the virtual reality applications for human machine interaction",2013,"23rd International Conference on Electronics, Communications and Computing, CONIELECOMP 2013",,, 6525788,"212","217",,,"10.1109/CONIELECOMP.2013.6525788","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881042480&doi=10.1109%2fCONIELECOMP.2013.6525788&partnerID=40&md5=c6c17a064e55f35c37b5b4a8f8a5204f","Technological Institute of Orizaba, Electronics Department, Orizaba, Veracruz, Mexico","Chavez-Gamboa, M., Technological Institute of Orizaba, Electronics Department, Orizaba, Veracruz, Mexico; Herrera-Aguilar, I., Technological Institute of Orizaba, Electronics Department, Orizaba, Veracruz, Mexico; Sandoval-Gonzalez, O., Technological Institute of Orizaba, Electronics Department, Orizaba, Veracruz, Mexico; Malagon-Gonzalez, F., Technological Institute of Orizaba, Electronics Department, Orizaba, Veracruz, Mexico; Jacinto-Villegas, J.M., Technological Institute of Orizaba, Electronics Department, Orizaba, Veracruz, Mexico","This paper presents a spatial hand tracking system using a 6 DOF anthropomorphic robot applied in human machine interaction. The main objective of this mechatronic system is to obtain information about the spatial position of a user's hand movements in order to be used like a skills trainer to accelerate the skills transfer from the machine to the human by integrating the laws of physics of virtual objects and adapting different design techniques and use of computer software for three-dimensional virtual reality © 2013 IEEE.","computational design; DOF; physical human-computer interaction; skills transfer; upper limbs; virtual reality","Computational design; Design technique; DOF; Human machine interaction; Mechatronic systems; skills transfer; Spatial positions; Upper limbs; Human computer interaction; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84881042480
"Sorita E., N'Kaoua B., Larrue F., Criquillon J., Simion A., Sauzéon H., Joseph P.-A., Mazaux J.-M.","55621593100;6603602499;36139685200;55788882300;37027168200;7801452039;7203027681;7007014695;","Do patients with traumatic brain injury learn a route in the same way in real and virtual environments?",2013,"Disability and Rehabilitation","35","16",,"1371","1379",,20,"10.3109/09638288.2012.738761","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879980435&doi=10.3109%2f09638288.2012.738761&partnerID=40&md5=9abf199c8665bae40daa42c2440a8e83","Rehabilitation Medicine Unit, University Hospital Pellegrin, 33076 Bordeaux, France; Research Group Handicap and Nervous System, University Bordeaux Segalen, Bordeaux, France","Sorita, E., Rehabilitation Medicine Unit, University Hospital Pellegrin, 33076 Bordeaux, France, Research Group Handicap and Nervous System, University Bordeaux Segalen, Bordeaux, France; N'Kaoua, B., Research Group Handicap and Nervous System, University Bordeaux Segalen, Bordeaux, France; Larrue, F., Research Group Handicap and Nervous System, University Bordeaux Segalen, Bordeaux, France; Criquillon, J., Rehabilitation Medicine Unit, University Hospital Pellegrin, 33076 Bordeaux, France; Simion, A., Rehabilitation Medicine Unit, University Hospital Pellegrin, 33076 Bordeaux, France; Sauzéon, H., Research Group Handicap and Nervous System, University Bordeaux Segalen, Bordeaux, France; Joseph, P.-A., Rehabilitation Medicine Unit, University Hospital Pellegrin, 33076 Bordeaux, France, Research Group Handicap and Nervous System, University Bordeaux Segalen, Bordeaux, France; Mazaux, J.-M., Rehabilitation Medicine Unit, University Hospital Pellegrin, 33076 Bordeaux, France, Research Group Handicap and Nervous System, University Bordeaux Segalen, Bordeaux, France","An increasing number of studies address the use of virtual environments (VE) in the cognitive assessment of spatial abilities. However, the differences between learning in a VE and a real environment (RE) remain controversial. Purpose: To compare the topographical behavior and spatial representations of patients with traumatic brain injury navigating in a real environment and in a virtual reproduction of this environment. Methods: Twenty-seven subjects with moderate to severe traumatic brain injury were consecutively included and allocated to one of two groups. The subjects were taught the same route in either the virtual environment or the real environment and had to recall it twice immediately after learning the route and once after a delay. At the end of these sessions, the subjects were asked to complete three representational tests: a map test, a map recognition test recognition and a scene arrangement test. Results: No significant difference was found between the two groups with regards to demographics, severity of brain injury or episodic memory. As a main result, the number of error rates did not significantly differ between the real and virtual environment [F (1, 25) = 0.679; p = 0.4176)]. Scores on the scene arrangement test were higher in the real environment [U = 32.5; p = 0.01]. Conclusions: Although spatial representations probably differ between the real and virtual environment, virtual reality remains a trusty assessment tool for spatial abilities. Implications for Rehabilitation The transfer of cognitive skills and strategy acquired during rehabilitation programs into daily life situations remains a matter of debate. Virtual reality might provide ecological and rehabilitation scenarios that can be used to look at the daily functioning of patients. The route learning performance after traumatic brain injury shows no significant difference between the real environment and its virtual reproduction in this study. © 2013 Informa UK, Ltd.","Cognitive rehabilitation; Topographical disorientation; Transfer; Virtual reality","adult; Brain Injuries; cognitive therapy; comparative study; computer simulation; depth perception; environment; female; human; learning; male; middle aged; neuropsychological test; physiology; recall; recognition; Adult; Brain Injuries; Cognitive Therapy; Computer Simulation; Environment; Female; Humans; Learning; Male; Mental Recall; Middle Aged; Neuropsychological Tests; Recognition (Psychology); Space Perception",Article,"Final","",Scopus,2-s2.0-84879980435
"Luboz V., Zhang Y., Johnson S., Song Y., Kilkenny C., Hunt C., Woolnough H., Guediri S., Zhai J., Odetoyinbo T., Littler P., Fisher A., Hughes C., Chalmers N., Kessel D., Clough P.J., Ward J., Phillips R., How T., Bulpitt A., John N.W., Bello F., Gould D.","22433444000;57203832077;55510533300;55762550800;49961557500;35113279400;6508339573;54405446400;35779486100;35778717900;22955734500;57193014467;57199279937;7007102058;7102689322;7004534518;36119465400;7404240954;7005647444;6603305265;7005876140;24329025000;7201621787;","ImaGiNe Seldinger: First simulator for Seldinger technique and angiography training",2013,"Computer Methods and Programs in Biomedicine","111","2",,"419","434",,19,"10.1016/j.cmpb.2013.05.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880035681&doi=10.1016%2fj.cmpb.2013.05.014&partnerID=40&md5=b9ca99554c0ed727c390b810bb6e42d1","Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom","Luboz, V., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Zhang, Y., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Johnson, S., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Song, Y., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Kilkenny, C., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Hunt, C., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Woolnough, H., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Guediri, S., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Zhai, J., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Odetoyinbo, T., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Littler, P., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Fisher, A., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Hughes, C., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Chalmers, N., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Kessel, D., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Clough, P.J., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Ward, J., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Phillips, R., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; How, T., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Bulpitt, A., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; John, N.W., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Bello, F., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom; Gould, D., Collaborators in Radiological Interventional Virtual Environments (CRaIVE), United Kingdom","In vascular interventional radiology, procedures generally start with the Seldinger technique to access the vasculature, using a needle through which a guidewire is inserted, followed by navigation of catheters within the vessels. Visual and tactile skills are learnt in a patient apprenticeship which is expensive and risky for patients. We propose a training alternative through a new virtual simulator supporting the Seldinger technique: ImaGiNe (imaging guided interventional needle) Seldinger. It is composed of two workstations: (1) a simulated pulse is palpated, in an immersive environment, to guide needle puncture and (2) two haptic devices provide a novel interface where a needle can direct a guidewire and catheter within the vessel lumen, using virtual fluoroscopy. Different complexities are provided by 28 real patient datasets. The feel of the simulation is enhanced by replicating, with the haptics, real force and flexibility measurements. A preliminary validation study has demonstrated training effectiveness for skills transfer. © 2013.","Haptics devices; Interventional radiology; Seldinger technique; Training; Vascular surgery; Virtual simulation","Haptics; Interventional radiology; Seldinger technique; Vascular surgery; Virtual simulations; Catheters; Haptic interfaces; Personnel training; Radiation; Radiology; Needles; angiography; article; catheter; catheterization; devices; needle; simulation; simulator; training; Haptics devices; Interventional radiology; Seldinger technique; Training; Vascular surgery; Virtual simulation; Algorithms; Angiography; Animals; Catheterization; Computer Simulation; Elasticity; Equipment Design; Fluoroscopy; Friction; Humans; Image Processing, Computer-Assisted; Models, Theoretical; Needles; Radiology, Interventional; Software; Swine; Task Performance and Analysis; User-Computer Interface; Vascular Diseases",Article,"Final","",Scopus,2-s2.0-84880035681
"Leeb R., Lancelle M., Kaiser V., Fellner D.W., Pfurtscheller G.","9940938400;53881535800;30467896100;6603799372;7103106088;","Thinking penguin: Multimodal brain-computer interface control of a VR game",2013,"IEEE Transactions on Computational Intelligence and AI in Games","5","2", 6418003,"117","128",,49,"10.1109/TCIAIG.2013.2242072","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879354288&doi=10.1109%2fTCIAIG.2013.2242072&partnerID=40&md5=5e3f109ac0827b40ece1c83d173b7f10","Center for Neuroprosthetics, École Polytechnique Fédérale de Lausanne (EPFL), Lausanne CH-1015, Switzerland; Nanyang Technological University, Singapore 639798, Singapore; Institute of Computer Graphics and Knowledge Visualization, Graz University of Technology, Graz A-8010, Austria; ETH Zürich, Zürich 8006, Switzerland; Laboratory of Brain Computer Interfaces, Institute for Knowledge Discovery, Graz University of Technology, Graz A-8010, Austria; Interactive Graphics Systems Group (GRIS), Technical University Darmstadt, Darmstadt 64289, Germany; Fraunhofer Institute for Applied Research in Visual Computing (IGD), Darmstadt 64283, Germany","Leeb, R., Center for Neuroprosthetics, École Polytechnique Fédérale de Lausanne (EPFL), Lausanne CH-1015, Switzerland; Lancelle, M., Nanyang Technological University, Singapore 639798, Singapore, Institute of Computer Graphics and Knowledge Visualization, Graz University of Technology, Graz A-8010, Austria, ETH Zürich, Zürich 8006, Switzerland; Kaiser, V., Laboratory of Brain Computer Interfaces, Institute for Knowledge Discovery, Graz University of Technology, Graz A-8010, Austria; Fellner, D.W., Institute of Computer Graphics and Knowledge Visualization, Graz University of Technology, Graz A-8010, Austria, Interactive Graphics Systems Group (GRIS), Technical University Darmstadt, Darmstadt 64289, Germany, Fraunhofer Institute for Applied Research in Visual Computing (IGD), Darmstadt 64283, Germany; Pfurtscheller, G., Laboratory of Brain Computer Interfaces, Institute for Knowledge Discovery, Graz University of Technology, Graz A-8010, Austria","In this paper, we describe a multimodal brain-computer interface (BCI) experiment, situated in a highly immersive CAVE. A subject sitting in the virtual environment controls the main character of a virtual reality game: a penguin that slides down a snowy mountain slope. While the subject can trigger a jump action via the BCI, additional steering with a game controller as a secondary task was tested. Our experiment profits from the game as an attractive task where the subject is motivated to get a higher score with a better BCI performance. A BCI based on the so-called brain switch was applied, which allows discrete asynchronous actions. Fourteen subjects participated, of which 50% achieved the required performance to test the penguin game. Comparing the BCI performance during the training and the game showed that a transfer of skills is possible, in spite of the changes in visual complexity and task demand. Finally and most importantly, our results showed that the use of a secondary motor task, in our case the joystick control, did not deteriorate the BCI performance during the game. Through these findings, we conclude that our chosen approach is a suitable multimodal or hybrid BCI implementation, in which the user can even perform other tasks in parallel. © 2013 IEEE.","brain switch; Brain-computer interfaces (BCI); game; hybrid BCI; multimodal; multitasking; virtual reality (VR)","game; Hybrid bci; Joystick control; Mountain slopes; Multi-modal; Secondary tasks; Virtual environment control; Visual complexity; Experiments; Interfaces (computer); Multitasking; Profitability; Virtual reality; Brain computer interface",Article,"Final","",Scopus,2-s2.0-84879354288
"Sodhi R., Poupyrev I., Glisson M., Israr A.","26424844100;6603553340;55347042000;15022614400;","AIREAL: Interactive tactile experiences in free air",2013,"ACM Transactions on Graphics","32","4", 134,"","",,172,"10.1145/2461912.2462007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880776379&doi=10.1145%2f2461912.2462007&partnerID=40&md5=7130f7d61e77b4ba44170aedef5f0b43","Disney Research, Pittsburgh, United States; University of Illinois, United States","Sodhi, R., Disney Research, Pittsburgh, United States, University of Illinois, United States; Poupyrev, I., Disney Research, Pittsburgh, United States; Glisson, M., Disney Research, Pittsburgh, United States; Israr, A., Disney Research, Pittsburgh, United States","AIREAL is a novel haptic technology that delivers effective and expressive tactile sensations in free air, without requiring the user to wear a physical device. Combined with interactive computers graphics, AIREAL enables users to feel virtual 3D objects, experience free air textures and receive haptic feedback on gestures performed in free space. AIREAL relies on air vortex generation directed by an actuated flexible nozzle to provide effective tactile feedback with a 75 degrees field of view, and within an 8.5cm resolution at 1 meter. AIREAL is a scalable, inexpensive and practical free air haptic technology that can be used in a broad range of applications, including gaming, mobile applications, and gesture interaction among many others. This paper reports the details of the AIREAL design and control, experimental evaluations of the device's performance, as well as an exploration of the application space of free air haptic displays. Although we used vortices, we believe that the results reported are generalizable and will inform the design of haptic displays based on alternative principles of free air tactile actuation. Copyright © ACM. Copyright © ACM 2013.","3D interfaces; Augmented reality; Augmented surfaces; Haptics; Tactile displays; Tangible interfaces; Touch interaction.","3D interface; Haptics; Tactile display; Tangible interfaces; Touch interaction; Augmented reality; Display devices; Haptic interfaces; Human computer interaction; Vortex flow",Article,"Final","",Scopus,2-s2.0-84880776379
"Taylor G.S., Barnett J.S.","25958441300;7201378608;","Evaluation of wearable simulation interface for military training",2013,"Human Factors","55","3",,"672","690",,17,"10.1177/0018720812466892","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878072143&doi=10.1177%2f0018720812466892&partnerID=40&md5=f36f9b5c70a6e8abbbcf6ba1db8eea25","University of Central Florida, Orlando FL, United States; U.S. Army Research Institute, ATTN: DAPE-ARI-IF, 12350 Research Parkway, Orlando FL 32826-3276, United States","Taylor, G.S., University of Central Florida, Orlando FL, United States; Barnett, J.S., U.S. Army Research Institute, ATTN: DAPE-ARI-IF, 12350 Research Parkway, Orlando FL 32826-3276, United States","Objective: This research evaluated the training effectiveness of a novel simulation interface, a wearable computer integrated into a soldier's load-bearing equipment. Background: Military teams often use game-based simulators on desktop computers to train squad-level procedures. A wearable computer interface that mimics the soldier's equipment was expected to provide better training through increased realism and immersion. Method: A heuristic usability evaluation and two experiments were conducted. Eight evaluators interacted with both wearable and desktop interfaces and completed a usability survey. The first experiment compared the training retention of the wearable interface with a desktop simulator and interactive training video. The second experiment compared the training transfer of the wearable and desktop simulators with a live training environment. Results: Results indicated the wearable interface was more difficult to use and elicited stronger symptoms of simulator sickness. There was no significant difference in training retention between the wearable, desktop, or interactive video training methods. The live training used in the second experiment provided superior training transfer than the simulator conditions, with no difference between the desktop and wearable. Conclusion: The wearable simulator interface did not provide better training than the desktop computer interface. It also had poorer usability and caused worse simulator sickness. Therefore, it was a less effective training tool. Application: This research illustrates the importance of conducting empirical evaluations of novel training technologies. New and innovative technologies are always coveted by users, but new does not always guarantee improvement.","computer interface; simulator; training; training effectiveness; training transfer; usability; wearable simulation interface","Empirical evaluations; Innovative technology; Interactive training; Significant differences; Training effectiveness; usability; Usability evaluation; Wearable interfaces; Experiments; Heuristic methods; Interfaces (computer); Personnel training; Wearable computers; Simulators; adult; article; computer interface; controlled clinical trial; controlled study; equipment design; female; human; learning; male; middle aged; military phenomena; randomized controlled trial; videorecording; Adult; Equipment Design; Female; Humans; Male; Middle Aged; Military Science; Transfer (Psychology); User-Computer Interface; Video Recording; Young Adult",Article,"Final","",Scopus,2-s2.0-84878072143
"Hodgins J.L., Veillette C.","55667637400;6602266454;","Arthroscopic proficiency: Methods in evaluating competency",2013,"BMC Medical Education","13","1", 61,"","",,29,"10.1186/1472-6920-13-61","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876793306&doi=10.1186%2f1472-6920-13-61&partnerID=40&md5=cfc2328bfb80defca07d7fe041561cbf","Division of Orthopaedics, Toronto Western Hospital, Toronto, Canada; University of Toronto Sports Medicine Program, Women's College Hospital, Toronto, Canada","Hodgins, J.L., Division of Orthopaedics, Toronto Western Hospital, Toronto, Canada; Veillette, C., Division of Orthopaedics, Toronto Western Hospital, Toronto, Canada, University of Toronto Sports Medicine Program, Women's College Hospital, Toronto, Canada","Background: The current paradigm of arthroscopic training lacks objective evaluation of technical ability and its adequacy is concerning given the accelerating complexity of the field. To combat insufficiencies, emphasis is shifting towards skill acquisition outside the operating room and sophisticated assessment tools. We reviewed (1) the validity of cadaver and surgical simulation in arthroscopic training, (2) the role of psychomotor analysis and arthroscopic technical ability, (3) what validated assessment tools are available to evaluate technical competency, and (4) the quantification of arthroscopic proficiency. Methods. The Medline and Embase databases were searched for published articles in the English literature pertaining to arthroscopic competence, arthroscopic assessment and evaluation and objective measures of arthroscopic technical skill. Abstracts were independently evaluated and exclusion criteria included articles outside the scope of knee and shoulder arthroscopy as well as original articles about specific therapies, outcomes and diagnoses leaving 52 articles citied in this review. Results: Simulated arthroscopic environments exhibit high levels of internal validity and consistency for simple arthroscopic tasks, however the ability to transfer complex skills to the operating room has not yet been established. Instrument and force trajectory data can discriminate between technical ability for basic arthroscopic parameters and may serve as useful adjuncts to more comprehensive techniques. There is a need for arthroscopic assessment tools for standardized evaluation and objective feedback of technical skills, yet few comprehensive instruments exist, especially for the shoulder. Opinion on the required arthroscopic experience to obtain proficiency remains guarded and few governing bodies specify absolute quantities. Conclusions: Further validation is required to demonstrate the transfer of complex arthroscopic skills from simulated environments to the operating room and provide objective parameters to base evaluation. There is a deficiency of validated assessment tools for technical competencies and little consensus of what constitutes a sufficient case volume within the arthroscopy community. © 2013 Hodgins and Veillette; licensee BioMed Central Ltd.","Arthroscopy; Competency; Surgical training; Task performance","arthroscopy; clinical competence; education; human; procedures; psychomotor performance; reproducibility; standards; arthroscopy; article; clinical competence; methodology; standard; Arthroscopy; Clinical Competence; Educational Measurement; Humans; Psychomotor Performance; Reproducibility of Results; Arthroscopy; Clinical Competence; Educational Measurement; Humans; Psychomotor Performance; Reproducibility of Results",Article,"Final","",Scopus,2-s2.0-84876793306
"Farra S., Miller E., Timm N., Schafer J.","54921506600;7404491434;16311140300;56545149400;","Improved Training for Disasters Using 3-D Virtual Reality Simulation",2013,"Western Journal of Nursing Research","35","5",,"655","671",,44,"10.1177/0193945912471735","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875670675&doi=10.1177%2f0193945912471735&partnerID=40&md5=a22f0258cd46e23cf434ae56cd42ab8e","Miami University Oxford, OH, United States; University of Cincinnati, OH, United States","Farra, S., Miami University Oxford, OH, United States; Miller, E., University of Cincinnati, OH, United States; Timm, N., University of Cincinnati, OH, United States; Schafer, J., University of Cincinnati, OH, United States","The purpose of this study was to examine the effects of virtual reality simulation (VRS) on learning outcomes and retention of disaster training. The study used a longitudinal experimental design using two groups and repeated measures. A convenience sample of associate degree nursing students enrolled in a disaster course was randomized into two groups; both groups completed web-based modules; the treatment group also completed a virtually simulated disaster experience. Learning was measured using a 20-question multiple-choice knowledge assessment pre/post and at 2 months following training. Results were analyzed using the generalized linear model. Independent and paired t tests were used to examine the between- and within-participant differences. The main effect of the virtual simulation was strongly significant (p&.0001). The VRS effect demonstrated stability over time. In this preliminary examination, VRS is an instructional method that reinforces learning and improves learning retention. © The Author(s) 2012.","disaster planning; education; mass casualty training; virtual reality","article; controlled clinical trial; controlled study; disaster planning; in service training; longitudinal study; nursing student; organization and management; randomized controlled trial; Disaster Planning; Inservice Training; Longitudinal Studies; Students, Nursing",Article,"Final","",Scopus,2-s2.0-84875670675
"Hayes A.T., Straub C.L., Dieker L.A., Hughes C.E., Hynes M.C.","55904744300;55925439900;8352122200;7401857048;36728914300;","Ludic learning: Exploration of TLE TeachLivE™ and effective teacher training",2013,"International Journal of Gaming and Computer-Mediated Simulations","5","2",,"20","33",,18,"10.4018/jgcms.2013040102","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887453745&doi=10.4018%2fjgcms.2013040102&partnerID=40&md5=4921bfb4e153c1c8e6fed8cbe71588c3","University of Central Florida, Orlando, FL, United States","Hayes, A.T., University of Central Florida, Orlando, FL, United States; Straub, C.L., University of Central Florida, Orlando, FL, United States; Dieker, L.A., University of Central Florida, Orlando, FL, United States; Hughes, C.E., University of Central Florida, Orlando, FL, United States; Hynes, M.C., University of Central Florida, Orlando, FL, United States","New and emerging technology in the field of virtual environments has permitted a certain malleability of learning milieus. These emerging environments allow learning and transfer through interactions that have been intentionally designed to be pleasurable experiences. TLE TeachLivE™ is just such an emerging environment that engages teachers in practice on pedagogical and content aspects of teaching in a simulator. The sense of presence, engagement, and ludus of TLE TeachLivE™ are derived from the compelling Mixed Reality that includes components of off-the shelf and emerging technologies. Some of the noted features that have been identified relevant to the ludic nature of TeachLivE include the flow, fidelity, unpredicability, suspension of disbelief, social presence, and gamelike elements. This article explores TLE TeachLivE™ in terms of the ludology, paideic user experience, the source of the ludus, and outcomes of the ludic nature of the experience. Copyright © 2013, IGI Global.","Engagement; Fidelity; Ludic Simulation; Mixed Reality; Serious Games; Suspension of Disbelief; Teacher Education; Virtual Environment","Engagement; Fidelity; Ludic Simulation; Mixed reality; Serious games; Teacher education; Personnel training; Suspensions (fluids); Virtual reality; Teaching",Article,"Final","",Scopus,2-s2.0-84887453745
"Hodgson E., Bachmann E.","14053915200;7005745121;","Comparing four approaches to generalized redirected walking: Simulation and live user data",2013,"IEEE Transactions on Visualization and Computer Graphics","19","4", 6479192,"634","643",,50,"10.1109/TVCG.2013.28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883482085&doi=10.1109%2fTVCG.2013.28&partnerID=40&md5=bf61425914579fff616f4a290bdfc967","Smale Interactive Visualization Center, Miami University, Ohio, United States; Computer Science and Software Engineering, HIVE, Miami University, Ohio, United States","Hodgson, E., Smale Interactive Visualization Center, Miami University, Ohio, United States; Bachmann, E., Computer Science and Software Engineering, HIVE, Miami University, Ohio, United States","Redirected walking algorithms imperceptibly rotate a virtual scene and scale movements to guide users of immersive virtual environment systems away from tracking area boundaries. These distortions ideally permit users to explore large and potentially unbounded virtual worlds while walking naturally through a physically limited space. Estimates of the physical space required to perform effective redirected walking have been based largely on the ability of humans to perceive the distortions introduced by redirected walking and have not examined the impact the overall steering strategy used. This work compares four generalized redirected walking algorithms, including Steer-to-Center, Steer-to-Orbit, Steer-to-Multiple-Targets and Steer-to- Multiple+Center. Two experiments are presented based on simulated navigation as well as live-user navigation carried out in a large immersive virtual environment facility. Simulations were conducted with both synthetic paths and previously-logged user data. Primary comparison metrics include mean and maximum distances from the tracking area center for each algorithm, number of wall contacts, and mean rates of redirection. Results indicated that Steer-to-Center out-performed all other algorithms relative to these metrics. Steer-to-Orbit also performed well in some circumstances. © 2013 IEEE.","Human computer interaction; Live users; Navigation; Redirected walking; Simulation; Virtual environments","Comparison metrics; Immersive virtual environments; Live users; Maximum distance; Redirected walkings; Simulation; Tracking areas; Virtual scenes; Human computer interaction; Navigation; Virtual reality; Algorithms; algorithm; article; association; comparative study; computer graphics; computer interface; evaluation; human; methodology; physiology; psychophysiology; three dimensional imaging; vision; walking; Algorithms; Biofeedback, Psychology; Computer Graphics; Cues; Humans; Imaging, Three-Dimensional; User-Computer Interface; Visual Perception; Walking",Article,"Final","",Scopus,2-s2.0-84883482085
"Patterson R.E., Pierce B.J., Boydstun A.S., Ramsey L.M., Shannan J., Tripp L., Bell H.","7403567089;7102438194;26648088800;55638955100;37085608000;26649196500;7102161146;","Training intuitive decision making in a simulated real-world environment",2013,"Human Factors","55","2",,"333","345",,10,"10.1177/0018720812454432","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875703880&doi=10.1177%2f0018720812454432&partnerID=40&md5=797c328caac7fb6af439995e0b9d4167","Air Force Research Laboratory, RHA/711 HPW, Wright-Patterson AFB, OH 45433, United States; Renaissance Sciences Corporation, Chandler, AZ, United States; L-3 Communications, Mesa, AR, United States; Air Force Research Laboratory, Mesa, AZ, United States","Patterson, R.E., Air Force Research Laboratory, RHA/711 HPW, Wright-Patterson AFB, OH 45433, United States; Pierce, B.J., Renaissance Sciences Corporation, Chandler, AZ, United States; Boydstun, A.S., L-3 Communications, Mesa, AR, United States; Ramsey, L.M., L-3 Communications, Mesa, AR, United States; Shannan, J., L-3 Communications, Mesa, AR, United States; Tripp, L., Air Force Research Laboratory, Mesa, AZ, United States; Bell, H., Air Force Research Laboratory, Mesa, AZ, United States","Objective: We investigated whether naturalistic, intuitive (pattern recognition-based) decision making can be developed via implicit statistical learning in a simulated real-world environment. Background: To our knowledge, no definitive studies have actually shown that implicit learning plays a causal role in the development of intuitive decision making when the latter is defined as pattern recognition of real-world, or simulated real-world, environmental situations. Method: The simulated environment was presented dynamically so as to induce a sense of simulated locomotion through the scene and over sequences of objects on the ground. During training, participants passively viewed the objects sequences; during test, participants made intuitive decisions about related or unrelated sequences. Results: Intuitive decision making can be developed via implicit learning. Articulatory suppression, which affects working memory, exerted a significant inhibitory effect on the training of intuitive decision making. Intuitive decision making trained in the simulated environment fully transferred to a flat display (but not vice versa). Conclusion: Intuitive decision making is developed by an implicit learning process that is engaged by the meaning inherent in naturalistic scenes. Application: Implicit learning can be used for training intuitive decision making. Copyright © 2012, Human Factors and Ergonomics Society.","artificial grammar learning; immersive environment; implicit learning; intuitive decision making; pattern recognition","Grammar learning; Immersive environment; Implicit learning; Inhibitory effect; Real world environments; Simulated environment; Statistical learning; Working memory; Pattern recognition; Decision making; adult; article; automated pattern recognition; controlled clinical trial; controlled study; decision making; human; information processing; learning; physiology; randomized controlled trial; short term memory; task performance; Adult; Data Display; Decision Making; Humans; Learning; Memory, Short-Term; Pattern Recognition, Automated; Task Performance and Analysis; Transfer (Psychology); Young Adult",Article,"Final","",Scopus,2-s2.0-84875703880
"Mongeon D., Blanchet P., Messier J.","25651823400;55412790100;6701376943;","Impact of Parkinson's disease and dopaminergic medication on adaptation to explicit and implicit visuomotor perturbations",2013,"Brain and Cognition","81","2",,"271","282",,21,"10.1016/j.bandc.2012.12.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872252190&doi=10.1016%2fj.bandc.2012.12.001&partnerID=40&md5=013afd29bcd1e5adae9341fd2472fc0c","Département de Kinésiologie, Université de Montréal, Montréal, QC, Canada; Département de Stomatologie, Université de Montréal, Montréal, QC, Canada; Services de neurologie du Centre Hospitalier de l'Université de Montréal, Montréal, QC, Canada; Institut universitaire de gériatrie de Montréal, Université de Montréal, Montréal, QC, Canada","Mongeon, D., Département de Kinésiologie, Université de Montréal, Montréal, QC, Canada, Institut universitaire de gériatrie de Montréal, Université de Montréal, Montréal, QC, Canada; Blanchet, P., Département de Stomatologie, Université de Montréal, Montréal, QC, Canada, Services de neurologie du Centre Hospitalier de l'Université de Montréal, Montréal, QC, Canada; Messier, J., Département de Kinésiologie, Université de Montréal, Montréal, QC, Canada, Institut universitaire de gériatrie de Montréal, Université de Montréal, Montréal, QC, Canada","The capacity to learn new visuomotor associations is fundamental to adaptive motor behavior. Evidence suggests visuomotor learning deficits in Parkinson's disease (PD). However, the exact nature of these deficits and the ability of dopamine medication to improve them are under-explored. Previous studies suggested that learning driven by large and small movement errors engaged distinct neural mechanisms. Here, we investigated whether PD patients have a generalized impairment in visuomotor learning or selective deficits in learning from large explicit errors which engages cognitive strategies or small imperceptible movement errors involving primarily implicit learning processes. Visuomotor learning skills of non-medicated and medicated patients were assessed in two reaching tasks in which the size of visuospatial errors experienced during learning was manipulated using a novel three-dimensional virtual reality environment. In the explicit perturbation task, the visuomotor perturbation was applied suddenly resulting in large consciously detected initial spatial errors, whereas in the implicit perturbation task, the perturbation was gradually introduced in small undetectable steps such that subjects never experienced large movement errors. A major finding of this study was that PD patients in non-medicated and medicated conditions displayed slower learning rates and smaller adaptation magnitudes than healthy subjects in the explicit perturbation task, but performance similar to healthy controls in the implicit perturbation task. Also, non-medicated patients showed an average reduced deadaptation relative to healthy controls when exposed to the large errors produced by the sudden removal of the perturbation in both the explicit and implicit perturbation tasks. Although dopaminergic medication consistently improved motor signs, it produced a variable impact on learning the explicit perturbation and deadaptation and unexpectedly worsened performance in some patients. Considered together, these results indicate that PD selectively impairs the ability to learn from large consciously detected visuospatial errors. This finding suggests that basal ganglia-related circuits are important neural structures for adaptation to sudden perturbations requiring awareness and high-cost action selection. Dopaminergic treatment may selectively compromise the ability to learn from large explicit movement errors for reasons that remain to be elucidated. © 2012 Elsevier Inc.","3D reaching movements; Basal ganglia; Virtual reality; Visuomotor learning","dopamine receptor stimulating agent; adaptation; adult; aged; article; clinical article; depth perception; dopaminergic activity; drug mechanism; drug targeting; female; human; learning; male; motor performance; Parkinson disease; priority journal; psychomotor performance; stimulus response; task performance; virtual reality exposure therapy; visual adaptation; visual stimulation; visuomotor adaptation; visuomotor coordination; Adaptation, Physiological; Aged; Antiparkinson Agents; Biomechanics; Cognition; Female; Humans; Learning; Male; Middle Aged; Movement; Neuropsychological Tests; Parkinson Disease; Psychomotor Performance",Article,"Final","",Scopus,2-s2.0-84872252190
"Schütz C., Schack T.","51664008900;22635455800;","Prospective and retrospective effects in a virtual pointing task",2013,"Acta Psychologica","142","3",,"314","322",,4,"10.1016/j.actpsy.2013.01.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873948126&doi=10.1016%2fj.actpsy.2013.01.005&partnerID=40&md5=09976a3c3465e2d730cbd75818dfb769","Faculty of Psychology and Sports Science, Bielefeld University, Universitätsstrasse 25, 33615 Bielefeld, Germany; Cognitive Interaction Technology, Center of Excellence, Bielefeld University, Universitätsstrasse 25, 33615 Bielefeld, Germany; CoR-Lab, Research Institute for Cognition and Robotics, Bielefeld University, Universitätsstrasse 25, 33615 Bielefeld, Germany","Schütz, C., Faculty of Psychology and Sports Science, Bielefeld University, Universitätsstrasse 25, 33615 Bielefeld, Germany; Schack, T., Faculty of Psychology and Sports Science, Bielefeld University, Universitätsstrasse 25, 33615 Bielefeld, Germany, Cognitive Interaction Technology, Center of Excellence, Bielefeld University, Universitätsstrasse 25, 33615 Bielefeld, Germany, CoR-Lab, Research Institute for Cognition and Robotics, Bielefeld University, Universitätsstrasse 25, 33615 Bielefeld, Germany","Over two decades ago prospective and retrospective effects of posture selection in a sequential task were described for the first time. Since then, both effects have been reproduced in a number of reaching studies. We asked (1) whether retrospective effects would also be found in a sequential pointing task and (2) whether pro/retrospective effects of posture selection would transfer to the end-effector position in the absence of haptic feedback. To this end, we created a sequential, perceptual-motor task in a virtual environment. Participants had to point to a row of targets in the frontal plane in sequential order. In a control experiment, physical targets were placed at the same locations. Results showed that kinematic parameters were similar in the virtual and real environment. Retrospective effects of posture/position were found in neither environment, indicating that pointing movements require lower cognitive planning costs than reaching movements. Prospective effects of posture were found both in the virtual and real environment. Prospective effects of position, on the other hand, were present in the virtual but not in the real environment, indicating that the absence of haptic feedback may result in unconscious shifts of the end-effector position. © 2013 Elsevier B.V.","Motor control; Pointing; Prospective effects; Retrospective effects; Virtual reality","adult; article; biomechanics; body posture; computer interface; feedback system; female; human; male; movement (physiology); psychomotor performance; Adult; Biomechanical Phenomena; Feedback; Female; Humans; Male; Movement; Posture; Psychomotor Performance; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84873948126
"Díaz F.J.B., Vega A.L., Cepeda A.A., Aparicio F.B.","56747221700;56747325700;56747550600;56747580100;","Introducing BIM into ACCIONA, an international construction company: Actual real-case examples",2013,"Proceedings, Annual Conference - Canadian Society for Civil Engineering","1","January",,"584","592",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938366500&partnerID=40&md5=f90565dd91978fe12ac65f5b6606a865","International Area, R and D and Innovation Technology Centre, ACCIONA Infrastructure, United States; ICT, Automation and 3D Area, R and D and Innovation Technology Centre, ACCIONA Infrastructure, United States","Díaz, F.J.B., International Area, R and D and Innovation Technology Centre, ACCIONA Infrastructure, United States; Vega, A.L., ICT, Automation and 3D Area, R and D and Innovation Technology Centre, ACCIONA Infrastructure, United States; Cepeda, A.A., ICT, Automation and 3D Area, R and D and Innovation Technology Centre, ACCIONA Infrastructure, United States; Aparicio, F.B., ICT, Automation and 3D Area, R and D and Innovation Technology Centre, ACCIONA Infrastructure, United States","This article is about the implementation process of BIM Methodology into ACCIONA, an international construction company, and the necessity to improve traditional flows in different departments, and the need to coordinate and manage corporately the company implementation. Realcase examples such as New Airport Terminal of Leon, Fine Arts University or The Penitentiary Center in Teruel, which are the first Spanish projects to be managed on site using BIM methodology, will be discussed. These first projects set up the basis for the implementation of the methodology at a global scale. Lessons-learnt and transfer of knowledge processes during the implementation will also be discussed. In addition, this paper shows several experiences adapting BIM methodology in departments like Design, Engineering, Quality or Tender. The main challenge was the necessity to adapt this methodology to local workflows or to create corporative Guidelines to improve the management of BIM models. Moreover, it was also necessary to create and change roles to adapt them to the new BIM workflows. Due to the necessity to improve the flow of information and decision making process, the teams worked on collaborative virtual reality rooms. The models included in the stereoscopic systems were obtained directly from BIM models. This involved the creation of exchange protocols to ensure interoperability of the both systems and the integration of BIM information into immersive environments. It was necessary to create different configurations of immersive portable systems for implementation on site. Conclusions and results of this case studio will be presented.",,"Construction industry; Decision making; Interoperability; Knowledge management; Stereo image processing; Technology transfer; Virtual reality; Collaborative virtual reality; Decision making process; Exchange protocols; Immersive environment; Implementation process; International construction; Stereoscopic systems; Transfer of knowledge; Architectural design",Conference Paper,"Final","",Scopus,2-s2.0-84938366500
"Wright W.G.","57212443990;","Using virtual reality to induce cross-axis adaptation of postural control: Implications for rehabilitation",2013,"2013 International Conference on Virtual Rehabilitation, ICVR 2013",,, 6662095,"289","294",,4,"10.1109/ICVR.2013.6662095","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892694486&doi=10.1109%2fICVR.2013.6662095&partnerID=40&md5=c77bf236854424b491f0605da49191f7","Temple University, Dept. of Physical Therapy, Philadelphia, PA, United States","Wright, W.G., Temple University, Dept. of Physical Therapy, Philadelphia, PA, United States","Adaptation of sensorimotor processes has been studied for over a century. However, rigorous experimental approaches require controlling as many variables as possible to study the phenomenon, which limits generalizability. Conversely testing adaptation in an unconstrained ecologically valid situation makes it difficult to identify what parameters affect this process. This study utilizes virtual environments (VE) to create complex, but controlled environments to test visual, vestibular, and sensorimotor adaptation of whole-body posture. Findings show automatic postural processes can be adapted to unusual and discordant sensory environments, suggesting its lability would be advantageous when employing the kind of sensorimotor rehabilitation therapy VE affords. © 2013 IEEE.","Insert; Posture; Sensorimotor adaptation; Style; Styling","Insert; Posture; Sensorimotor adaptation; Style; Styling; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84892694486
"Medeiros D., Teixeira L., Carvalho F., Santos I., Raposo A.","55428540900;57212518247;23396260500;7102671754;6603721426;","A tablet-based 3D interaction tool for virtual engineering environments",2013,"Proceedings - VRCAI 2013: 12th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry",,,,"211","218",,14,"10.1145/2534329.2534349","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891519598&doi=10.1145%2f2534329.2534349&partnerID=40&md5=fac54922eb295c032efdb5293a9c8806","Tecgraf/PUC-Rio, Brazil; Petrobras, Brazil","Medeiros, D., Tecgraf/PUC-Rio, Brazil; Teixeira, L., Tecgraf/PUC-Rio, Brazil; Carvalho, F., Tecgraf/PUC-Rio, Brazil; Santos, I., Petrobras, Brazil; Raposo, A., Tecgraf/PUC-Rio, Brazil","Three-dimensional computer-aided design (3D CAD) modeling and reviewing is one of the most common engineering project tools. Interaction in these environments is characterized by the need for a high precision level to execute specific tasks. Generally this kind of task uses specific interaction devices with 4 or more degrees of freedom, such as 3D mice. Currently applications involving 3D interaction use interaction devices for object modeling or for the implementation of navigation, selection and manipulation techniques in a virtual environment. A related problem is the need to control naturally non-immersive tasks, such as symbolic input (e.g., text, photos). In addition, the steep learning curve to handle such non-conventional devices is a recurring problem. The addition of sensors and the popularization of smart-phones and tablets, allowed the use of such devices in virtual engineering environments. These devices, differs to other devices by the possibility of including additional information and performing naturally non-immersive tasks. This work presents a 3D interaction tablet-based tool, which allows the aggregation of all major 3D interaction topics, such as navigation, selection, manipulation, system control and symbolic input. To validate the proposed tool, the SimUEP-Ambsim application was chosen, an oil and gas simulator that has the complexity needed and which allows the use of all techniques implemented. Then, the tool was tested in another application, a photo-voltaic solar plant simulator, in order to evaluate the generality of this work concept. © 2013 ACM.","3D interaction; mobile devices; virtual engineering environments; virtual reality","Computer aided design; Interactive computer graphics; Mobile devices; Tools; Virtual reality; 3D interactions; Engineering project; Interaction devices; Manipulation techniques; Specific interaction; Specific tasks; Steep learning curve; Virtual engineering; Three dimensional",Conference Paper,"Final","",Scopus,2-s2.0-84891519598
"Alaraj A., Charbel F.T., Birk D., Tobin M., Luciano C., Banerjee P.P., Rizzi S., Sorenson J., Foley K., Slavin K., Roitberg B.","15838807800;16945837000;14120930700;55550172100;7004699651;35580367600;16310730600;8690246600;7102856392;7006065355;33968027300;","Role of cranial and spinal virtual and augmented reality simulation using immersive touch modules in neurosurgical training",2013,"Neurosurgery","72","SUPPL. 1",,"A115","A123",,64,"10.1227/NEU.0b013e3182753093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872064481&doi=10.1227%2fNEU.0b013e3182753093&partnerID=40&md5=b9581c8c6bde510488311acc4dda173d","Department of Neurosurgery, College of Medicine, University of Illinois at Chicago, 912 S Wood St, Chicago, IL 60612-7329, United States; Department of Mechanical and Industrial Engineering, University of Illinois at Chicago, College of Engineering, Chicago, IL, United States; Section of Neurosurgery, University of Chicago, Chicago, IL, United States; Medical Education and Research Institute, Memphis, TN, United States","Alaraj, A., Department of Neurosurgery, College of Medicine, University of Illinois at Chicago, 912 S Wood St, Chicago, IL 60612-7329, United States; Charbel, F.T., Department of Neurosurgery, College of Medicine, University of Illinois at Chicago, 912 S Wood St, Chicago, IL 60612-7329, United States; Birk, D., Department of Neurosurgery, College of Medicine, University of Illinois at Chicago, 912 S Wood St, Chicago, IL 60612-7329, United States; Tobin, M., Department of Neurosurgery, College of Medicine, University of Illinois at Chicago, 912 S Wood St, Chicago, IL 60612-7329, United States; Luciano, C., Department of Mechanical and Industrial Engineering, University of Illinois at Chicago, College of Engineering, Chicago, IL, United States; Banerjee, P.P., Department of Mechanical and Industrial Engineering, University of Illinois at Chicago, College of Engineering, Chicago, IL, United States, Section of Neurosurgery, University of Chicago, Chicago, IL, United States; Rizzi, S., Department of Mechanical and Industrial Engineering, University of Illinois at Chicago, College of Engineering, Chicago, IL, United States; Sorenson, J., Medical Education and Research Institute, Memphis, TN, United States; Foley, K., Medical Education and Research Institute, Memphis, TN, United States; Slavin, K., Department of Neurosurgery, College of Medicine, University of Illinois at Chicago, 912 S Wood St, Chicago, IL 60612-7329, United States; Roitberg, B., Section of Neurosurgery, University of Chicago, Chicago, IL, United States","Recent studies have shown that mental script-based rehearsal and simulation-based training improve the transfer of surgical skills in various medical disciplines. Despite significant advances in technology and intraoperative techniques over the last several decades, surgical skills training on neurosurgical operations still carries significant risk of serious morbidity or mortality. Potentially avoidable technical errors are well recognized as contributing to poor surgical outcome. Surgical education is undergoing overwhelming change, as a result of the reduction of work hours and current trends focusing on patient safety and linking reimbursement with clinical outcomes. Thus, there is a need for adjunctive means for neurosurgical training, which is a recent advancement in simulation technology. ImmersiveTouch is an augmented reality system that integrates a haptic device and a high-resolution stereoscopic display. This simulation platform uses multiple sensory modalities, re-creating many of the environmental cues experienced during an actual procedure. Modules available include ventriculostomy, bone drilling, percutaneous trigeminal rhizotomy, and simulated spinal modules such as pedicle screw placement, vertebroplasty, and lumbar puncture. We present our experience with the development of such augmented reality neurosurgical modules and the feedback from neurosurgical residents. Copyright © 2012 by the Congress of Neurological Surgeons.","Neurosurgical training; Spinal instrumentation; Surgical Simulation; Ventriculostomy; Virtual reality","anastomosis; article; bone drilling; human; lumbar puncture; neurosurgery; pedicle screw; percutaneous trigeminal rhizotomy; percutaneous vertebroplasty; priority journal; rhizotomy; skull surgery; surgical training; virtual reality; Central Nervous System Diseases; Competency-Based Education; Computer Simulation; Craniotomy; Education, Medical, Graduate; Feedback; Humans; Imaging, Three-Dimensional; Internship and Residency; Medical Errors; Neurosurgical Procedures; Rhizotomy; Spinal Fusion; Spinal Puncture; Touch; Trigeminal Neuralgia; User-Computer Interface; Ventriculostomy; Vertebroplasty",Article,"Final","",Scopus,2-s2.0-84872064481
"Pedram S., Perez P., Dowsett B.","56429736400;7201902645;57215433274;","Impact of virtual training on safety and productivity in the mining industry",2013,"Proceedings - 20th International Congress on Modelling and Simulation, MODSIM 2013",,,,"64","70",,4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057965178&partnerID=40&md5=aff4ab85ef72c01863665093b8e4b7ff","SMART Infrastructure Facility, University of WollongongNSW, Australia; Coal Services Pty Ltd, Argenton, NSW, Australia","Pedram, S., SMART Infrastructure Facility, University of WollongongNSW, Australia; Perez, P., SMART Infrastructure Facility, University of WollongongNSW, Australia; Dowsett, B., Coal Services Pty Ltd, Argenton, NSW, Australia","Best practice in the mining industry includes extensive initial and professional training for staff involved in field operations. While changes in mining technology and operations accelerate to improve productivity, health and safety standards have to be continuously evaluated and improved, putting more pressure on training deliveries. Borrowing from Defence and Airspace industries, training in the mining industry is increasingly relying on immersive virtual reality to simulate complex operations and procedures in potentially dangerous environments. Coal Services Pty Ltd is at the forefront of modern training facilities in Australia. This paper presents a qualitative and quantitative research framework designed to analyse the impact of past and current training sessions on staff's ability to better perform their tasks, overall safety standards and mine productivity. It is relatively difficult to benchmark training techniques or programs in the mining industry as the very nature of the industry prevents from experimental comparisons with a control group. Hence, we have chosen to use diachronic methods to evaluate the effective impact of IVR-based training on worker's competences. In particular, our interviews with managers and access to relevant industry records will help us to identify two periods: before and after the introduction of IVR-based training. Another more qualitative approach will consist in interviewing personnel who have undertaken during their career at least two types of training programs, including IVR-based ones. The framework uses interviews with trainees, trainers and managers, alongside session recordings, to qualitatively evaluate levels of knowledge transfer and aptitudes to perform in a real environment. Then, a cost-benefit analysis is to be used to evaluate the added-value of virtual reality-based on technological and operational costs weighed against overall productivity of the mine being negatively affected by any safety issue. © International Congress on Modelling and Simulation, MODSIM 2013.All right reserved.","Mining industry; Safety; Simulation; Training; Virtual reality","Accident prevention; Cost benefit analysis; E-learning; Knowledge management; Managers; Mineral industry; Operations research; Productivity; Virtual reality; Complex operations; Experimental comparison; Immersive virtual reality; Professional training; Qualitative approach; Quantitative research; Simulation; Training techniques; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-85057965178
"Moya S., Grau S., Tost D.","36091427300;24337715400;6602117681;","Assisted navigation for 3D serious games training",2013,"Actas del XIV Congreso Internacional de Interaccion Persona-Ordenador, INTERACCION 2013",,,,"3","9",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088699580&partnerID=40&md5=449ddbc86a82d5073b41361a3e71dcc4","CREB-UPC, Spain","Moya, S., CREB-UPC, Spain; Grau, S., CREB-UPC, Spain; Tost, D., CREB-UPC, Spain","Serious games in 3D virtual environments are becoming a popular tool for professional training activities as well as for rehabilitation. Navigation in 3D is recognized as one of the activity which is more difficult to master in this envi- ronments. In particular, elder users, less familiar with 3D games often do not know how to walk through these envi- ronments. They get puzzled without having been able to address the real purpose of the game. In this paper, we pro- pose different enhancement methods to make navigation in 3D easier, and we describe the design and implementation of an automatic navigation mode, usable when navigation is needed to reach objects in the 3D world but is not a goal of the game by itself. We compare the results of an eval- uation test of these different methods. We conclude that, for non-usual gamers, automatic navigation is the faster and preferred mode, whereas gamers prefer to control navigation themselves. For non-automatic navigation, the performance is better when the cursor is fixed in the view center point during locomotion. On the contrary, for still positions, a free cursor is preferable. Finally, restriction of the pitch an- gle in a solid angle that encompasses the objects related to the task is better than a free pitch angle rotation for still positions. During locomotion, fixing the pitch angle at the horizontal level enhances the navigation. © 2013 Actas del XIV Congreso Internacional de Interaccion Persona-Ordenador, INTERACCION 2013. All rights reserved.","Camera Control; Navigation; Usability; Virtual Worlds","Human computer interaction; Navigation; Technology transfer; 3-D virtual environment; Assisted navigations; Automatic navigation; Center points; Design and implementations; Pitch angle; Professional training; Solid angle; Serious games",Conference Paper,"Final","",Scopus,2-s2.0-85088699580
"Miranda L., Alves P., Morais C.","49864068900;55834442100;49863980800;","Assessment of virtual learning environments by higher education teachers and students",2013,"Proceedings of the European Conference on e-Learning, ECEL",,,,"311","318",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899542392&partnerID=40&md5=79b153b44e178e3a9d31a08c728c8fe7","Instituto Politécnico de Bragança, Bragança, Portugal","Miranda, L., Instituto Politécnico de Bragança, Bragança, Portugal; Alves, P., Instituto Politécnico de Bragança, Bragança, Portugal; Morais, C., Instituto Politécnico de Bragança, Bragança, Portugal","This research focuses on the problematic of the use of virtual learning environments in a higher education institution in the north of Portugal. In this study, we set the scientific and pedagogical background of virtual learning environments, and we analyze the responses obtained from an online questionnaire conducted to 536 subjects, all teachers and students at that same higher education institution, namely 347 students and 189 teachers. The research questions of this study were set out in order to assess the frequency with which the higher education students and teachers of that institution access virtual learning environments, the value they assign to those environments as well as to their integrated tools, and also to assess the influence of users' computer skills on their access to virtual learning environments. Considering the computer skills classification of each subject of this study, three independent categories were created, both for teachers and students, associated with basic skills, intermediate skills and advanced skills, respectively. In this paper we adopt a descriptive and inferential data analysis, using the recommended statistical procedures. Results show that the majority of teachers and students access the institution's virtual environment on a daily basis. However, there are significant differences between teachers who have intermediate computer skills and those who have basic skills, as the percentage of teachers with intermediate skills accessing the virtual learning environment everyday is higher than that of the teachers who have basic computer skills. No significant differences were found among students as far as the relation between virtual learning environment access and computer skills is concerned. With regard to the assessment of the virtual learning environment, more than 80% of the teachers consider that the use of the institution's virtual learning environment is valuable to send messages or notices to students, provide the teacher's office attendance hours, provide a schedule of activities, provide students' assessment, provide the plan of students' activities, and allow students to access resources and submit assignments online. The aspects valued by more than 80% of the students were: checking exam results and receiving messages or notices from teachers. The importance of this study is mainly related to knowledge sharing with the scientific community concerned with the implementation of virtual learning environments, based on the assessment of a specific situation which involved higher education students and teachers. Although the results cannot be generalized within the scope of other institutions as the sample belongs to one institution only, the study provides indicators which may represent an asset for future studies concerning the assessment and use of virtual learning environments and the digital tools they provide in the higher education context, as well as for the understanding of the relation between the use of these environments and their users' computer skills.","Digital resources; e-learning; Higher education; Tools; Virtual learning environments","Computer aided instruction; Digital devices; E-learning; Teaching; Tools; Virtual reality; Digital resources; Higher education; Higher education institutions; Higher education students; Online questionnaire; Research questions; Scientific community; Virtual learning environments; Students",Conference Paper,"Final","",Scopus,2-s2.0-84899542392
"George B.C., Teitelbaum E.N., DaRosa D.A., Hungness E.S., Meyerson S.L., Fryer J.P., Schuller M., Zwischenberger J.B.","55440908600;55207655800;7004055601;6603792983;7004034295;20234194500;45061238100;35449881300;","Duration of faculty training needed to ensure reliable or performance ratings",2013,"Journal of Surgical Education","70","6",,"703","708",,31,"10.1016/j.jsurg.2013.06.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892787989&doi=10.1016%2fj.jsurg.2013.06.015&partnerID=40&md5=c6021b5d500dae4fa7afaa4310d7160e","Department of Surgery, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Department of Surgery, Northwestern University Feinberg School of Medicine, Chicago, IL, United States; Department of Surgery, University of Kentucky College of Medicine, Lexington, KY, United States","George, B.C., Department of Surgery, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Teitelbaum, E.N., Department of Surgery, Northwestern University Feinberg School of Medicine, Chicago, IL, United States; DaRosa, D.A., Department of Surgery, Northwestern University Feinberg School of Medicine, Chicago, IL, United States; Hungness, E.S., Department of Surgery, Northwestern University Feinberg School of Medicine, Chicago, IL, United States; Meyerson, S.L., Department of Surgery, Northwestern University Feinberg School of Medicine, Chicago, IL, United States; Fryer, J.P., Department of Surgery, Northwestern University Feinberg School of Medicine, Chicago, IL, United States; Schuller, M., Department of Surgery, Northwestern University Feinberg School of Medicine, Chicago, IL, United States; Zwischenberger, J.B., Department of Surgery, University of Kentucky College of Medicine, Lexington, KY, United States","OBJECTIVES: The American Board of Surgery has mandated intraoperative assessment of general surgery residents, yet the time required to train faculty to accurately and reliably complete operating room performance evaluation forms is unknown. Outside of surgical education, frame-of-reference (FOR) training has been shown to be an effective training modality to teach raters the specific performance indicators associated with each point on a rating scale. Little is known, however, about what form and duration of FOR training is needed to accomplish reliable ratings among surgical faculty. DESIGN: Two groups of surgical faculty separately underwent either an accelerated 1-hour (n = 10) or immersive four-hour (n = 34) FOR faculty development program. Both programs included a formal presentation and a facilitated discussion of sample behaviors for each point on the Zwisch operating room performance rating scale (see DaRosa et al.8). The immersive group additionally participated in a small group exercise that included additional practice. After training, both groups were tested using 10 video clips of trainees at various levels. Responses were scored against expert consensus ratings. The 2-sided Mann-Whitney U test was used to compare between group means. SETTING AND PARTICIPANTS: All trainees were faculty members in the Department of Surgery of a large midwestern private medical school. RESULTS: Faculty undergoing the 1-hour FOR training program did not have a statistically different mean correct response rate on the video test when compared with those undergoing the 4-hour training program (88% vs 80%; p = 0.07). CONCLUSIONS: One-hour FOR training sessions are likely sufficient to train surgical faculty to reliably use a simple evaluation instrument for the assessment of intra-operative performance. Additional research is needed to determine how these results generalize to different assessment instruments. (J Surg 70:703-708. © 2013 Association of Program Directors in Surgery. Published by Elsevier Inc. All rights reserved.).","Evaluation; Faculty development; Frame-of-reference training; Measurement; Rater training; Surgical education","accuracy; clinical article; conference paper; consensus; curriculum; exercise; feedback system; female; general surgery; human; learning; male; medical school; operating room; priority journal; rating scale; surgical training; videorecording; evaluation; faculty development; frame-of-reference training; measurement; Medical Knowledge; rater training; surgical education; Adult; Clinical Competence; Computer Simulation; Curriculum; Education, Medical, Graduate; Educational Measurement; Faculty, Medical; Female; General Surgery; Humans; Internship and Residency; Male; Middle Aged; Operating Rooms; Program Evaluation; Quality Improvement; Statistics, Nonparametric; Time Factors; United States",Conference Paper,"Final","",Scopus,2-s2.0-84892787989
"Creutzfeldt J., Hedman L., Felländer-Tsai L.","16308631900;7007166091;6603715643;","Effects of pre-training using serious game technology on CPR performance - an exploratory quasi-experimental transfer study",2012,"Scandinavian Journal of Trauma, Resuscitation and Emergency Medicine","20",, 79,"","",,29,"10.1186/1757-7241-20-79","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870473541&doi=10.1186%2f1757-7241-20-79&partnerID=40&md5=0db5d6dc09262eb941637d1e17123c8b","Department of Clinical Science, Intervention and Technology, Karolinska Institutet, K32, Stockholm, 141 86, Sweden; Center for Advanced Medical Simulation and Training, Karolinska Institutet and Karolinska University Hospital, Stockholm, Sweden; Department of Psychology, Umeå University, Umeå, Sweden","Creutzfeldt, J., Department of Clinical Science, Intervention and Technology, Karolinska Institutet, K32, Stockholm, 141 86, Sweden, Center for Advanced Medical Simulation and Training, Karolinska Institutet and Karolinska University Hospital, Stockholm, Sweden; Hedman, L., Department of Clinical Science, Intervention and Technology, Karolinska Institutet, K32, Stockholm, 141 86, Sweden, Department of Psychology, Umeå University, Umeå, Sweden; Felländer-Tsai, L., Department of Clinical Science, Intervention and Technology, Karolinska Institutet, K32, Stockholm, 141 86, Sweden, Center for Advanced Medical Simulation and Training, Karolinska Institutet and Karolinska University Hospital, Stockholm, Sweden","Background: Multiplayer virtual world (MVW) technology creates opportunities to practice medical procedures and team interactions using serious game software. This study aims to explore medical students' retention of knowledge and skills as well as their proficiency gain after pre-training using a MVW with avatars for cardio-pulmonary resuscitation (CPR) team training.Methods: Three groups of pre-clinical medical students, n = 30, were assessed and further trained using a high fidelity full-scale medical simulator: Two groups were pre-trained 6 and 18 months before assessment. A reference control group consisting of matched peers had no MVW pre-training. The groups consisted of 8, 12 and 10 subjects, respectively. The session started and ended with assessment scenarios, with 3 training scenarios in between. All scenarios were video-recorded for analysis of CPR performance.Results: The 6 months group displayed greater CPR-related knowledge than the control group, 93 (±11)% compared to 65 (±28)% (p < 0.05), the 18 months group scored in between (73 (±23)%).At start the pre-trained groups adhered better to guidelines than the control group; mean violations 0.2 (±0.5), 1.5 (±1.0) and 4.5 (±1.0) for the 6 months, 18 months and control group respectively. Likewise, in the 6 months group no chest compression cycles were delivered at incorrect frequencies whereas 54 (±44)% in the control group (p < 0.05) and 44 (±49)% in 18 months group where incorrectly paced; differences that disappeared during training.Conclusions: This study supports the beneficial effects of MVW-CPR team training with avatars as a method for pre-training, or repetitive training, on CPR-skills among medical students. © 2012 Creutzfeldt et al.; licensee BioMed Central Ltd.","Assessment; Avatars; Cardiopulmonary resuscitation; e-learning; Educational technology; MVW; Patient simulation; Students; Virtual learning environments; Young adults","adult; article; clinical competence; computer interface; computer program; female; human; learning; long term memory; male; medical education; medical student; methodology; psychomotor performance; resuscitation; teaching; Adult; Cardiopulmonary Resuscitation; Clinical Competence; Education, Medical, Undergraduate; Female; Humans; Learning; Male; Patient Simulation; Psychomotor Performance; Retention (Psychology); Software; Students, Medical; Teaching; User-Computer Interface; Young Adult",Article,"Final","",Scopus,2-s2.0-84870473541
"Abidi M.H., Ahmad A., El-Tamimi A.M., Al-Ahmari A.M.","55582207400;8244331200;6602969118;6603483674;","Development and evaluation of a virtual assembly trainer",2012,"Proceedings of the Human Factors and Ergonomics Society",,,,"2560","2564",,5,"10.1177/1071181312561532","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873428457&doi=10.1177%2f1071181312561532&partnerID=40&md5=2c751e3a0f27e4a7ad81d9fcbe6eb07f","Princess Fatima Alnijris's Research Department for Advanced Manufacturing Technology (FARCAMT), Industrial Engineering Department, King Saud University, Riyadh, Saudi Arabia","Abidi, M.H., Princess Fatima Alnijris's Research Department for Advanced Manufacturing Technology (FARCAMT), Industrial Engineering Department, King Saud University, Riyadh, Saudi Arabia; Ahmad, A., Princess Fatima Alnijris's Research Department for Advanced Manufacturing Technology (FARCAMT), Industrial Engineering Department, King Saud University, Riyadh, Saudi Arabia; El-Tamimi, A.M., Princess Fatima Alnijris's Research Department for Advanced Manufacturing Technology (FARCAMT), Industrial Engineering Department, King Saud University, Riyadh, Saudi Arabia; Al-Ahmari, A.M., Princess Fatima Alnijris's Research Department for Advanced Manufacturing Technology (FARCAMT), Industrial Engineering Department, King Saud University, Riyadh, Saudi Arabia","This paper discusses the development and evaluation of a virtual assembly training system for the first Saudi Arabian car prototype (Gazal-1) fender assembly. An evaluation study was conducted to compare 3 training scenarios: Traditional Engineering (TE), Computer Aided Design Environment (CADE), and immersive virtual reality (IVR). 15 students from King Saud University were randomly assigned to the different training conditions. After that, transfer of training to the actual assembly was evaluated. Performance measures used to assess transfer of training include time to complete task and number of frustration points during task. The results of the evaluation study suggest that the participants of IVR training condition performed better than the other two conditions. Therefore, virtual assembly simulation using virtual reality systems might be useful for training operators who will be conducting assembly operations. Copyright 2012 by Human Factors and Ergonomics Society, Inc. All rights reserved.",,"Assembly operations; Evaluation study; Immersive virtual reality; Performance measure; Training conditions; Training operators; Training scenario; Training Systems; Virtual assembly; Virtual assembly simulations; Virtual reality system; Computer aided design; Virtual reality; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-84873428457
"Zellmann S., Aumüller M., Lang U.","55658645800;57221322452;7006119097;","Image-based remote real-Time volume rendering â Decoupling rendering from view point updates",2012,"Proceedings of the ASME Design Engineering Technical Conference","2","PARTS A AND B",,"1385","1394",,5,"10.1115/DETC2012-70811","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884604894&doi=10.1115%2fDETC2012-70811&partnerID=40&md5=c78a66607df7fe82794084cb5634eca5","Department of Computer Science, University of Cologne, Cologne, 50931, Germany","Zellmann, S., Department of Computer Science, University of Cologne, Cologne, 50931, Germany; Aumüller, M.; Lang, U., Department of Computer Science, University of Cologne, Cologne, 50931, Germany","Remote rendering is employed when the visualization task is too challenging for the hardware used to display a dataset or when it is too time consuming to transfer the complete dataset. Volume visualization with its dataset sizes growing with the 3rd power of their spatial resolution is such a task. Since remote rendering introduces additional sources of latency, its applicability to virtual environments is limited because of the required low delays from user action to displayed image. We counter these latencies with image-based rendering techniques: color image data along with additional depth information is warped, while new data has not been completely received. Using these approximate images, it is possible to decouple the cheap display phase from rendering. While depth values are trivially deduced for polygons, we contribute heuristics for volumetric datasets with varying transparency. Copyright © 2012 by ASME.",,"Color images; Data set size; Depth information; Image-Based Rendering; Remote rendering; Spatial resolution; Volume visualization; Volumetric data sets; Image reconstruction; Virtual reality; Visualization; Volume rendering; Design",Conference Paper,"Final","",Scopus,2-s2.0-84884604894
"Natarajan U., Kirchgessner M., Ketelhut D.J.","57196672963;55232817500;16233512400;","A design strategy for scaling up implementations in virtual environments",2012,"Proceedings of the European Conference on Games-based Learning",,,,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897805462&partnerID=40&md5=37a7d83c95ef634ce5554bc1135f8ac3","SAVE Science, Curriculum, Instruction and Technology in Education (CITE), Temple University College of Education, Philadelphia, United States; Temple University College of Education, Philadelphia, United States; Science, Technology and Mathematics Education, PI, United States; SAVE Science, University of Maryland College of Education, Teaching and Learning, Policy and Leadership Department, United States","Natarajan, U., SAVE Science, Curriculum, Instruction and Technology in Education (CITE), Temple University College of Education, Philadelphia, United States; Kirchgessner, M., Temple University College of Education, Philadelphia, United States; Ketelhut, D.J., Science, Technology and Mathematics Education, PI, United States, SAVE Science, University of Maryland College of Education, Teaching and Learning, Policy and Leadership Department, United States","According to Coburn (2003), ""scaling up"" educational innovations involve four interrelated dimensions: depth, sustainability, spread and shift in ownership. A technology innovation requires a design that can adapted in different contexts and robust enough to retain effectiveness in settings that lack its conditions for success (Clarke and Dede, 2009). Sustainability of innovations is the ability of the innovation to extend beyond the time that researchers are involved in classrooms by developing the capacity for sustaining the change (Penuel et al, 2011). According to Dede (2011), technology-based innovation designs should aid learning in classrooms, while also working to evolve in design and ensure that teachers can integrate without much difficulty. Researchers Clarke, Dede, Ketelhut, & Nelson (2006) identified the various factors that were critical to successful implementation and scalability of the River City project. Two of those conditions for success were related to teacher preparation. Clarke and Dede (2006) reviewed literature related to identifying the key contextual variables necessary for scaling up educational innovations. They compiled a list of various teacher level variables, among which teacher professional development related to innovation, teacher ownership, teacher comfort level and technology are critical. In this paper, we describe one of the approaches for scalability that attempts to address key teacher preparation variables: the design of a robust web-based portal called ""SAVE Science Dashboard"". This portal particularly addresses ""Spread"", referring to the infrastructure necessary for expansion of the innovation to more classrooms and schools, and ""Shift"", referring to the transfer of ownership and responsibility for implementation from designers to teachers and school community. The dashboard's design and implementation is discussed in the context of a large scale project called ""Situated Assessments Using Virtual Environments for Science Content and Inquiry: SAVE Science.","Dashboard; Immersive virtual environments; Scientific inquiry; Technology implementation","Dashboard; Design and implementations; Educational innovations; Immersive virtual environments; Scientific inquiry; Teacher professional development; Technology implementation; Technology-based innovations; Design; Scalability; Sustainable development; Teaching; Virtual reality; Innovation",Conference Paper,"Final","",Scopus,2-s2.0-84897805462
"Stork A., Sevilmis N., Weber D., Gorecky D., Stahl C., Loskyll M., Michel F.","56234965900;8879416000;57135495000;36095668000;57213242480;42761907200;57196560681;","Enabling virtual assembly training in and beyond the automotive industry",2012,"Proceedings of the 2012 18th International Conference on Virtual Systems and Multimedia, VSMM 2012: Virtual Systems in the Information Society",,, 6365944,"347","352",,30,"10.1109/VSMM.2012.6365944","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872014955&doi=10.1109%2fVSMM.2012.6365944&partnerID=40&md5=8a75643145301603c789009ddcdd5c1d","Interactive Engineering Technologies, Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany; Innovative Factory Systems, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany; Augmented Vision, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany","Stork, A., Interactive Engineering Technologies, Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany; Sevilmis, N., Interactive Engineering Technologies, Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany; Weber, D., Interactive Engineering Technologies, Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany; Gorecky, D., Innovative Factory Systems, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany; Stahl, C., Innovative Factory Systems, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany; Loskyll, M., Innovative Factory Systems, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany; Michel, F., Augmented Vision, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany","Virtual assembly training systems show a high potential to complement or even replace physical setups for training of assembly processes in and beyond the automotive industry. The precondition for the breakthrough of virtual training is that it overcomes the problems of former approaches. The paper presents the design approach taken during the development of a game-based, virtual training system for procedural assembly knowledge in the EU-FP7 project VISTRA. One key challenge to address when developing virtual assembly training is the extensive authoring effort for setting up virtual environments. Although knowledge from the product and manufacturing design is available and could be used for virtual training, a concept for integration of this data is still missing. This paper presents the design of a platform which transfers available enterprise data into a unified model for virtual training and thus enables virtual training of workers at the assembly line before the physical prototypes exist. The data requirements and constraints stemming from industrial partners involved in the project will be discussed. A second hurdle for virtual training is the insufficient user integration and acceptance. In this context, the paper introduces an innovative hardware set-up for game-based user interaction, which has been chosen to enhance user involvement and acceptance of virtual training. © 2012 IEEE.","Data Integration; Industrial Training; PLM; User-Interaction; Virtual Reality","Assembly line; Assembly process; Data integration; Data requirements; Design approaches; Enterprise data; High potential; Industrial partners; Industrial training; Manufacturing design; PLM; Still missing; Training Systems; Unified model; User integration; User involvement; User-Interaction; Virtual assembly; Virtual training; Assembly; Automotive industry; Information science; Product design; Virtual reality; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-84872014955
"Wang Y., Wang J., Mei L., Li Q.","35769965000;56421700700;25825333600;56142382600;","A virtual-learning service platform and its API based programming learning and design refinement",2012,"Proceedings of 2012 IEEE International Conference on Service Operations and Logistics, and Informatics, SOLI 2012",,, 6273567,"383","388",,,"10.1109/SOLI.2012.6273567","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867207596&doi=10.1109%2fSOLI.2012.6273567&partnerID=40&md5=2bddcf2a72222b84353e7752f81d741a","IBM Research - China, China","Wang, Y., IBM Research - China, China; Wang, J., IBM Research - China, China; Mei, L., IBM Research - China, China; Li, Q., IBM Research - China, China","The evolution of 3D internet technologies has opened a whole new range of opportunities for enhanced learning, and has offered new support in programming learning fields. In this paper, we present a framework for the virtual-learning service platform over 3D virtual worlds. Our framework provides a set of fundamental services that can effectively help to reduce the learning curve in learning programming on a new specific platform and improve the targeted platform development work. The proposed framework is a generalization of our experience gained in developing of a fully immersive 3D e-learning system which has been tested and used for customer training. © 2012 IEEE.",,"E-learning systems; Enhanced learning; Immersive; Internet technology; Learning curves; Learning programming; Platform development; Programming learning; Service platforms; Virtual worlds; Application programming interfaces (API); Information science; Three dimensional computer graphics; Virtual reality; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-84867207596
"Harter D., Lu S., Sintupan P., Kotturu P.","7005776620;55017156300;55328157000;55327796200;","How controller embodiment affects task performance in computer simulated training",2012,"Proceedings of the IASTED International Conference on Human-Computer Interaction, HCI 2012",,,,"211","217",,,"10.2316/P.2012.772-026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864589151&doi=10.2316%2fP.2012.772-026&partnerID=40&md5=f7c250ec16999537b473be036e616cc5","Department of Computer Science, Texas A and M University - Commerce, Commerce, TX, United States; Department of Psychology, Texas A and M University - Commerce, Commerce, TX, United States","Harter, D., Department of Computer Science, Texas A and M University - Commerce, Commerce, TX, United States; Lu, S., Department of Psychology, Texas A and M University - Commerce, Commerce, TX, United States; Sintupan, P., Department of Psychology, Texas A and M University - Commerce, Commerce, TX, United States; Kotturu, P., Department of Psychology, Texas A and M University - Commerce, Commerce, TX, United States","Common coding theory [1] and grounded or situated theories of cognition [2] have as a fundamental assumption that perceptual codes and action plans share a common representational format. This shared coding has implications for learning and training of real-world tasks in computer simulated environments (CSE). For instance, more natural sensory-motor contingencies in terms of the controllers or environment display should be expected to more readily tap into existing sensory-motor codes, and thus result in better training transfer. In this research report, we compare a standard mouse controller to a WiiMote controller for performing a simple everyday action-oriented task in a CSE. Users show differences on task performance depending on the type of controller, but more so in the timing of performing the task rather then the accuracy or correctness of task performance. Not surprisingly, users take longer to plan and execute tasks with the WiiMote controller, which we claim has more natural sensory-motor contingencies for our task than a mouse controller and thus trigger user to act with caution in the context of a potentially risky task. We report these differences and discuss implications of the results to training in computer simulated environments, as well as insights into theories of grounded cognition.","Common coding theory; Computer based learning; Grounded cognition; Interaction devices and tools","Action plan; Coding Theory; Computer-based learning; Grounded cognition; Interaction devices; Learning and training; Mouse controller; Real-world task; Research reports; Simulated environment; Simulated trainings; Task performance; Computer programming; Human computer interaction; Information theory",Conference Paper,"Final","",Scopus,2-s2.0-84864589151
"Meier A.H., Boehler M.L., McDowell C.M., Schwind C., Markwell S., Roberts N.K., Sanfey H.","35293115900;6701717783;37117325800;6603678166;6701603727;22036517400;8574247600;","A surgical simulation curriculum for senior medical students based on TeamSTEPPS",2012,"Archives of Surgery","147","8",,"761","766",,23,"10.1001/archsurg.2012.1340","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865606479&doi=10.1001%2farchsurg.2012.1340&partnerID=40&md5=77ddac1de7f088ea4fb0d5ac13a9b8c6","Department of Surgery, Southern Illinois University School of Medicine, Springfield, IL, United States; Department of Medical Education, Southern Illinois University School of Medicine, Springfield, IL, United States; Division of Pediatric Surgery, Department of Surgery, SUNY Upstate Medical University, 725 Irving Ave, Ste 401, Syracuse, NY 13210-2306, United States","Meier, A.H., Department of Surgery, Southern Illinois University School of Medicine, Springfield, IL, United States, Division of Pediatric Surgery, Department of Surgery, SUNY Upstate Medical University, 725 Irving Ave, Ste 401, Syracuse, NY 13210-2306, United States; Boehler, M.L., Department of Surgery, Southern Illinois University School of Medicine, Springfield, IL, United States; McDowell, C.M., Department of Surgery, Southern Illinois University School of Medicine, Springfield, IL, United States; Schwind, C., Department of Surgery, Southern Illinois University School of Medicine, Springfield, IL, United States; Markwell, S., Department of Surgery, Southern Illinois University School of Medicine, Springfield, IL, United States; Roberts, N.K., Department of Medical Education, Southern Illinois University School of Medicine, Springfield, IL, United States; Sanfey, H., Department of Surgery, Southern Illinois University School of Medicine, Springfield, IL, United States","Objective: To investigate whether the existing Team Strategies and Tools to Enhance Performance and Patient Safety (TeamSTEPPS) curriculum can effectively teach senior medical students team skills. Design: Single-group preintervention and postintervention study. Setting and Intervention: We integrated a TeamSTEPPS module into our existing resident readiness elective. The curriculum included interactive didactic sessions, discussion groups, role-plays, and videotaped immersive simulation scenarios. Main Outcome Measures: Improvement of self-assessment scores, multiple-choice examination scores, and performance ratings of videotaped simulation scenarios before and after intervention. The videos were rated by masked reviewers on the basis of a global rating instrument (TeamSTEPPS) and a more detailed nontechnical skills evaluation tool (NOTECHS). Participants: Seventeen students participated and completed the study. Results: The self-evaluation scores improved from 12.76 to 16.06 (P < .001). The increase was significant for all of the TeamSTEPPS competencies and highest for leadership skills (from 2.2 to 3.2; P < .001). The multiple-choice score rose from 84.9% to 94.1% (P < .01). The postintervention video ratings were significantly higher for both instruments (TeamSTEPPS, from 2.99 to 3.56; P < .01; and NOTECHS, from 4.07 to 4.59; P < .001). Conclusions: The curriculum led to improved self-evaluation and multiple-choice scores as well as improved team skills during simulated immersive patient encounters. The TeamSTEPPS framework may be suitable for teaching medical students teamwork concepts and improving their competencies. Larger studies using this framework should be considered to further evaluate the generalizability of our results and the effectiveness of TeamSTEPPS for medical students. ©2012 American Medical Association. All rights reserved.",,"article; competence; curriculum; health care personnel; human; interpersonal communication; leadership; medical education; medical student; multidisciplinary team; patient safety; priority journal; rating scale; scoring system; self evaluation; skill; surgical training; task performance; Team Strategies and Tools to Enhance Performance and Patient Safety; teamwork; videorecording; Clinical Competence; Curriculum; Female; General Surgery; Humans; Internship and Residency; Interprofessional Relations; Male; Models, Educational; Patient Care Team",Article,"Final","",Scopus,2-s2.0-84865606479
"Hsu C.-C., Ho C.-C.","7404947474;54996772000;","The design and implementation of a competency-based intelligent mobile learning system",2012,"Expert Systems with Applications","39","9",,"8030","8043",,16,"10.1016/j.eswa.2012.01.130","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858332953&doi=10.1016%2fj.eswa.2012.01.130&partnerID=40&md5=c94fd60b46174e72a3ac61af3edf4f4a","Department of Computer Science and Information Engineering, Fu-Jen Catholic University, 510, Chung Cheng Rd., Hsinchuang, New Taipei City 24205, Taiwan","Hsu, C.-C., Department of Computer Science and Information Engineering, Fu-Jen Catholic University, 510, Chung Cheng Rd., Hsinchuang, New Taipei City 24205, Taiwan; Ho, C.-C., Department of Computer Science and Information Engineering, Fu-Jen Catholic University, 510, Chung Cheng Rd., Hsinchuang, New Taipei City 24205, Taiwan","Mobile learning provides a ubiquitous learning context for the learners to select appropriate learning paths and learning objects. Adaptive learning methods and correct learning path planning can help to achieve the goal of learning anytime and anywhere. Moreover, the display ability of mobile learning devices has become a key factor affecting the interest and acquisition time of learners. Achieving the desired functionality is currently an important topic in the field of mobile learning. This paper uses competency-based learning as the basis to evaluate the knowledge deficiency that the learner must overcome. We then use carrier selection, fuzzy interpolation computation, and ant-genetic algorithm techniques to select the appropriate learning paths and objects. Finally, we use NFC's point-to-point technology to transfer the learning content in the learning device to a larger screen with NFC capability in the user's environment to display the same content, thus providing a complete learning system. © 2012 Elsevier Ltd. All rights reserved.","Competency-based learning; Learning path selection; Mobile learning","Acquisition time; Adaptive learning method; Competency-based learning; Fuzzy interpolation; Key factors; Learning contents; Learning objects; Learning paths; Mobile learning; Mobile-learning system; Ubiquitous learning; Display devices; Motion planning; Learning systems",Article,"Final","",Scopus,2-s2.0-84858332953
"Legault I., Faubert J.","23091685400;7003902219;","Perceptual-cognitive training improves biological motion perception: Evidence for transferability of training in healthy aging",2012,"NeuroReport","23","8",,"469","473",,26,"10.1097/WNR.0b013e328353e48a","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861098668&doi=10.1097%2fWNR.0b013e328353e48a&partnerID=40&md5=38187712671c8d65d7082bba7ff6cab2","Visual Psychophysics Perception Laboratory, School of Optometry, University of Montréal, Montreal, QC H3T 1P1, Canada","Legault, I., Visual Psychophysics Perception Laboratory, School of Optometry, University of Montréal, Montreal, QC H3T 1P1, Canada; Faubert, J., Visual Psychophysics Perception Laboratory, School of Optometry, University of Montréal, Montreal, QC H3T 1P1, Canada","In our everyday life, processing complex dynamic scenes such as crowds and traffic is of critical importance. Further, it is well documented that there is an age-related decline in complex perceptual-cognitive processing, which can be reversed with training. It has been suggested that a specific dynamic scene perceptual-cognitive training procedure [the three-dimensional multiple object tracking speed task (3D-MOT)] helps observers manage socially relevant stimuli such as human body movements as seen in crowds or during sports activities. Here, we test this assertion by assessing whether training older observers on 3D-MOT can improve biological motion (BM) perception. Research has shown that healthy older adults require more distance in virtual space between themselves and a point-light walker to integrate BM information than younger adults. Their performances decreased markedly at a distance as far away as 4 m (critical for collision avoidance), whereas performance in young adults remained constant up to 1 m. We trained observers between 64 and 73 years of age on the 3D-MOT speed task and looked at BM perception at 4 and 16 m distances in virtual space. We also had a control group trained on a visual task and a third group without training. The perceptual-cognitive training eliminated the difference in BM perception between 4 and 16 m after only a few weeks, whereas the two control groups showed no transfer. This demonstrates that 3D-MOT training could be a good generic process for helping certain observers deal with socially relevant dynamic scenes. © 2012 Wolters Kluwer Health | Lippincott Williams & Wilkins.","aging; biological motion; perceptual-cognitive training; three-dimensional multiple object tracking speed task; transferability","adult; aged; aging; article; biological motion perception; clinical article; cognition; collisionally activated dissociation; controlled study; human; motion analysis system; movement perception; observer variation; perceptual cognitive training; priority journal; sociology; task performance; three dimensional multiple object tracking speed task; velocity; vision; visual stimulation; walking speed; Aged; Aging; Cognition; Female; Humans; Male; Middle Aged; Motion Perception; Photic Stimulation; Transfer (Psychology); Visual Perception",Article,"Final","",Scopus,2-s2.0-84861098668
"Jensen A.M.D., Jensen M.M., Korsager A.S., Ong M.-S., Magrabi F., Coiera E.","57213480382;57206713300;55207280400;36653094200;6602783750;7003453209;","Using virtual worlds to train healthcare workers - A case study using second life to improve the safety of inpatient transfers",2012,"Electronic Journal of Health Informatics","7","1", e7,"","",,5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860546396&partnerID=40&md5=02a71d6842600503b04e987c40473fa1","Medical Informatics Group, Department of Health Science and Technology, Aalborg University, Aalborg, Denmark; Centre for Health Informatics, Australian Institute for Health Innovation, University of New South Wales, Sydney, Australia","Jensen, A.M.D., Medical Informatics Group, Department of Health Science and Technology, Aalborg University, Aalborg, Denmark; Jensen, M.M., Medical Informatics Group, Department of Health Science and Technology, Aalborg University, Aalborg, Denmark; Korsager, A.S., Medical Informatics Group, Department of Health Science and Technology, Aalborg University, Aalborg, Denmark; Ong, M.-S., Centre for Health Informatics, Australian Institute for Health Innovation, University of New South Wales, Sydney, Australia; Magrabi, F., Centre for Health Informatics, Australian Institute for Health Innovation, University of New South Wales, Sydney, Australia; Coiera, E., Centre for Health Informatics, Australian Institute for Health Innovation, University of New South Wales, Sydney, Australia","Virtual worlds such as Second Life may offer a new environment to deliver simulation-based safety training to clinicians. The objective of this study was to design and implement a simulation of inpatient transfers in the virtual world of Second Life, and to undertake a preliminary evaluation of its usability as an educational tool. A simulation of inpatient transfer was developed using the Linden Scripting Language in Second Life. A virtual hospital was built and four scenarios of inpatient transfer varying in mode of transport (bed, trolley or wheelchair) and infection control precautions (no-infection, droplet, contact or airborne infection) were implemented. System usability was assessed using a "" think aloud"" protocol in combination with surveys and interviews with 15 participants who found the simulation environment easy to use, and fit for purpose. The novelty of using a virtual world was regarded as an advantage over other training methods, as was the opportunity to learn and practice inpatient transfers while receiving instant feedback during the process. Participants agreed that simulation has potential to improve awareness about hand hygiene and prevent errors. Second Life was able to support the development of a virtual environment for patient safety training. Results from preliminary usability tests indicate acceptance of the simulation environment. Further investigation is required to evaluate usability with a representative group and determine if training porters in a virtual world will reduce errors in the real world.","Computer simulation; Computer-assisted instruction/methods; Online systems; Patient transfer; Virtual systems",,Article,"Final","",Scopus,2-s2.0-84860546396
"Kotranza A., Lind D.S., Lok B.","15061513400;7004808046;57203616548;","Real-time evaluation and visualization of learner performance in a mixed-reality environment for clinical breast examination",2012,"IEEE Transactions on Visualization and Computer Graphics","18","7", 5963665,"1101","1114",,10,"10.1109/TVCG.2011.132","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861462426&doi=10.1109%2fTVCG.2011.132&partnerID=40&md5=1e7979649708e7d7bc9698d84ce512b8","Department of Computer and Information Science and Engineering, University of Florida, E301 CSE Building, PO Box 116120, Gainesville, FL 32611, United States; Department of Surgery, Medical College of Georgia, BB 4514, Augusta, GA 30912, United States","Kotranza, A., Department of Computer and Information Science and Engineering, University of Florida, E301 CSE Building, PO Box 116120, Gainesville, FL 32611, United States; Lind, D.S., Department of Surgery, Medical College of Georgia, BB 4514, Augusta, GA 30912, United States; Lok, B., Department of Computer and Information Science and Engineering, University of Florida, E301 CSE Building, PO Box 116120, Gainesville, FL 32611, United States","We investigate the efficacy of incorporating real-time feedback of user performance within mixed-reality environments (MREs) for training real-world tasks with tightly coupled cognitive and psychomotor components. This paper presents an approach to providing real-time evaluation and visual feedback of learner performance in an MRE for training clinical breast examination (CBE). In a user study of experienced and novice CBE practitioners (n = 69), novices receiving real-time feedback performed equivalently or better than more experienced practitioners in the completeness and correctness of the exam. A second user study (n = 8) followed novices through repeated practice of CBE in the MRE. Results indicate that skills improvement in the MRE transfers to the real-world task of CBE of human patients. This initial case study demonstrates the efficacy of MREs incorporating real-time feedback for training real-world cognitive-psychomotor tasks. © 2012 IEEE.","information visualization; life and medical sciences; Mixed and augmented reality","Human patients; Information visualization; Life and medical science; Mixed-reality environment; Real-time feedback; Real-world task; Tightly-coupled; User performance; User study; Visual feedback; Augmented reality; Information systems; Visual communication; Visualization; article; audiovisual equipment; breast; computer graphics; computer interface; female; human; medical informatics; methodology; palpation; physiology; pressure; sensory feedback; teaching; Breast; Computer Graphics; Computer-Assisted Instruction; Feedback, Sensory; Female; Humans; Medical Informatics Applications; Models, Anatomic; Palpation; Pressure; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84861462426
"Pollock B., Winer E., Gilbert S., De La Cruz J.","55104919600;7004856151;14041448900;7101860523;","LVC interaction within a mixed-reality training system",2012,"Proceedings of SPIE - The International Society for Optical Engineering","8289",, 82890K,"","",,4,"10.1117/12.912193","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899065085&doi=10.1117%2f12.912193&partnerID=40&md5=e886c669076106a972cfa4f02e52ff43","Iowa State University, Ames, IA, United States; Army RDECOM - STTC, Orlando, FL, United States","Pollock, B., Iowa State University, Ames, IA, United States; Winer, E., Iowa State University, Ames, IA, United States; Gilbert, S., Iowa State University, Ames, IA, United States; De La Cruz, J., Army RDECOM - STTC, Orlando, FL, United States","The United States military is increasingly pursuing advanced live, virtual, and constructive (LVC) training systems for reduced cost, greater training flexibility, and decreased training times. Combining the advantages of realistic training environments and virtual worlds, mixed reality LVC training systems can enable live and virtual trainee interaction as if co-located. However, LVC interaction in these systems often requires constructing immersive environments, developing hardware for live-virtual interaction, tracking in occluded environments, and an architecture that supports real-time transfer of entity information across many systems. This paper discusses a system that overcomes these challenges to empower LVC interaction in a reconfigurable, mixed reality environment. This system was developed and tested in an immersive, reconfigurable, and mixed reality LVC training system for the dismounted warfighter at ISU, known as the Veldt, to overcome LVC interaction challenges and as a test bed for cuttingedge technology to meet future U.S. Army battlefield requirements. Trainees interact physically in the Veldt and virtually through commercial and developed game engines. Evaluation involving military trained personnel found this system to be effective, immersive, and useful for developing the critical decision-making skills necessary for the battlefield. Procedural terrain modeling, model-matching database techniques, and a central communication server process all live and virtual entity data from system components to create a cohesive virtual world across all distributed simulators and game engines in real-time. This system achieves rare LVC interaction within multiple physical and virtual immersive environments for training in real-time across many distributed systems. © 2012 SPIE-IS&T.","Distributed Systems; LVC; Military Simulation; Mixed Reality; Training","Equipment testing; Human computer interaction; Interactive computer graphics; Personnel training; Virtual reality; Communication servers; Cutting edge technology; Distributed systems; LVC; Military simulation; Mixed reality; Mixed-reality environment; Procedural terrain modeling; Distributed database systems",Conference Paper,"Final","",Scopus,2-s2.0-84899065085
"Xia P., Lopes A.M., Restivo M.T., Yao Y.","13404322900;55905624500;7004694449;55722539100;","A new type haptics-based virtual environment system for assembly training of complex products",2012,"International Journal of Advanced Manufacturing Technology","58","1-4",,"379","396",,58,"10.1007/s00170-011-3381-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855678280&doi=10.1007%2fs00170-011-3381-8&partnerID=40&md5=2b46f472228a26ac2011d883fee986e4","IDMEC-Polo FEUP, Faculty of Engineering, Porto University, Porto, Portugal; School of Mechanical and Electrical Engineering, Harbin Institute of Technology, Harbin, China","Xia, P., IDMEC-Polo FEUP, Faculty of Engineering, Porto University, Porto, Portugal; Lopes, A.M., IDMEC-Polo FEUP, Faculty of Engineering, Porto University, Porto, Portugal; Restivo, M.T., IDMEC-Polo FEUP, Faculty of Engineering, Porto University, Porto, Portugal; Yao, Y., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, Harbin, China","Virtual reality (VR)-based assembly training has been an interesting topic for the last decades. Generally, there are two shortcomings for nowadays virtual assembly training systems. One is that the operators cannot move around the virtual environment in a natural way as people activity in the real world: they are constrained in a fixed position or can only move in a limited space. The other is that most of the virtual assembly training systems are based on geometry constraint modeling only, which lacks haptics feedback. A new type haptics-based virtual environment system for assembly training of complex products is described in this paper. A new low-cost motion simulator is designed and integrated with the virtual environment to realize free walking by human. An automatic data integration interface is developed to transfer geometry, topology, assembly, and physics information from a computer-aided design system to a VR application, and a hierarchical constraint-based data model is rebuilt to construct the virtual assembly environment. Physics-based modeling and haptics feedback are undertaken to simulate the realistic assembly operations. The application examples and evaluation experiments demonstrate that both motion simulator and haptics have great value for training of assembly processes. © Springer-Verlag London Limited 2011.","Assembly training; Haptics; Motion simulator; Physics-based modeling; Virtual reality","Application examples; Assembly operations; Assembly process; Complex products; Computer-aided design systems; Constraint-based; Data integration; Evaluation experiments; Geometry constraints; Haptics; Limited space; Motion simulator; Physics-based modeling; Training Systems; Virtual assembly; Virtual environments; VR applications; Computer aided design; E-learning; Simulators; Topology; Virtual reality; Assembly",Article,"Final","",Scopus,2-s2.0-84855678280
"Silva P.M., Pappas T.N., Atkins J., West J.E., Hartmann W.M.","47062047800;35566614500;36627852700;7402746449;23000892000;","Acoustic-tactile rendering of visual information",2012,"Proceedings of SPIE - The International Society for Optical Engineering","8291",, 82910M,"","",,,"10.1117/12.916166","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859460653&doi=10.1117%2f12.916166&partnerID=40&md5=f6cf6653e6f66a07301fbe7b65853d66","EECS Department, Northwestern University, Evanston, IL 60201, United States; ECE Department, Johns Hopkins University, Baltimore, MD 21218, United States; Physics and Astronomy Department, Michigan State University, East Lansing, MI 48824, United States","Silva, P.M., EECS Department, Northwestern University, Evanston, IL 60201, United States; Pappas, T.N., EECS Department, Northwestern University, Evanston, IL 60201, United States; Atkins, J., ECE Department, Johns Hopkins University, Baltimore, MD 21218, United States; West, J.E., ECE Department, Johns Hopkins University, Baltimore, MD 21218, United States; Hartmann, W.M., Physics and Astronomy Department, Michigan State University, East Lansing, MI 48824, United States","In previous work, we have proposed a dynamic, interactive system for conveying visual information via hearing and touch. The system is implemented with a touch screen that allows the user to interrogate a two-dimensional (2-D) object layout by active finger scanning while listening to spatialized auditory feedback. Sound is used as the primary source of information for object localization and identification, while touch is used both for pointing and for kinesthetic feedback. Our previous work considered shape and size perception of simple objects via hearing and touch. The focus of this paper is on the perception of a 2-D layout of simple objects with identical size and shape. We consider the selection and rendition of sounds for object identification and localization. We rely on the head-related transfer function for rendering sound directionality, and consider variations of sound intensity and tempo as two alternative approaches for rendering proximity. Subjective experiments with visually-blocked subjects are used to evaluate the effectiveness of the proposed approaches. Our results indicate that intensity outperforms tempo as a proximity cue, and that the overall system for conveying a 2-D layout is quite promising. © 2012 Copyright Society of Photo-Optical Instrumentation Engineers (SPIE).","HRTF; immersive environments; virtual reality; visual substitution; visually impaired","Audition; Human computer interaction; Virtual reality; Head related transfer function; HRTF; Immersive environment; Kinesthetic feedback; Object identification; Subjective experiments; Two Dimensional (2 D); Visually impaired; Touch screens",Conference Paper,"Final","",Scopus,2-s2.0-84859460653
"Goulding J., Nadim W., Petridis P., Alshawi M.","9639808300;35275652400;36128917500;6603579234;","Construction industry offsite production: A virtual reality interactive training environment prototype",2012,"Advanced Engineering Informatics","26","1",,"103","116",,85,"10.1016/j.aei.2011.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-83555162497&doi=10.1016%2fj.aei.2011.09.004&partnerID=40&md5=b2db4a47453b082275bbb6fb701a5aaa","School of Built and Natural Environment, University of Central Lancashire (UCLan), United Kingdom; Department of Architecture, British University in Egypt (BUE), Egypt; Serious Games Institute, Coventry University, United Kingdom; College of Science and Technology, University of Salford, United Kingdom","Goulding, J., School of Built and Natural Environment, University of Central Lancashire (UCLan), United Kingdom; Nadim, W., Department of Architecture, British University in Egypt (BUE), Egypt; Petridis, P., Serious Games Institute, Coventry University, United Kingdom; Alshawi, M., College of Science and Technology, University of Salford, United Kingdom","The 'traditional' construction industry has constantly been challenged to improve its inherent problematic practices. Offsite production (OSP), under the umbrella of modern methods of construction (MMC), has been acknowledged as a means to help improve construction industry performance as well as meet new market demands through the provision of improved, adaptable, and sustainable buildings. However, the deployment of OSP systems, if not managed properly, may adversely affect the end result and be counterproductive. It is therefore imperative that the construction industry stakeholders learn and appreciate the specifics, merits, as well as the risks associated with OSP systems in order to achieve the desired outcomes and consequently improve industry performance. On-the-job-training (OJT) is usually sought to facilitate 'experiential' learning, which is argued to be particularly effective where a great deal of independence is granted to the task performer. However, OJT has been criticised for being expensive, limited, and sometimes devoid of the actual training context. In order to address the problems encountered with OJT, several virtual reality (VR) solutions have been proposed. This paper introduces one such VR solution prototype, in order to provide a risk-free environment for learning without the 'do-or-die' consequences often faced on real construction projects. The proffered solution provides a unique VR environment for practicing new working conditions associated with OSP practices. While the 'scenes' of the VR environment take place on a construction site, the environment predominantly targets professionals, such as project managers, construction managers, architects, designers, suppliers and manufacturers, to allow multidisciplinary learning to occur, and hence overcome 'knowledge silos' or 'knowledge compartmentation'. The VR environment enables unforeseen problems often caused by professionals' decisions, faulty work, and health and safety issues to occur; where the implications of which can be evaluated in respect of time, cost and resources. The VR environment proposed does not aim to resolve problems associated with OSP per se, rather aims to allow 'things to go wrong' and consequently allows users not only to 'experience' the resulting implications but also to reflect on those implications as part of the learning process. This paper discusses and presents the prototype for the first development phase of the VR interactive training environment. While the prototype was tested and validated with domain experts from industry, the research community, and academia from different EU countries, the data used in developing the prototype was constrained to one project in the UK which may limit the generalisability of results. © 2011 Elsevier Ltd. All rights reserved.","Construction industry; Game engines; Offsite production; Simulation; Training; Virtual environment","Compartmentation; Construction manager; Construction projects; Construction sites; Development phase; Domain experts; EU countries; Game Engine; Health and safety; Interactive training; Learning process; Market demand; Modern methods of constructions; Off-site production; On the job trainings; Project managers; Research communities; Simulation; Sustainable building; Virtual environments; Working conditions; Construction industry; E-learning; Health risks; Intelligent buildings; Managers; Personnel training; Virtual reality; Project management",Article,"Final","",Scopus,2-s2.0-83555162497
"Hummel J., Wolff R., Dodiya J., Gerndt A., Kuhlen T.","55211775000;8719300800;24478235300;6507002255;6602984500;","Short paper: Towards interacting with force-sensitive thin deformable virtual objects",2012,"JVRC12: Joint Virtual Reality Conference of ICAT - EGVE - EuroVR 2012, Proceedings",,,,"17","20",,2,"10.2312/EGVE/JVRC12/017-020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891873719&doi=10.2312%2fEGVE%2fJVRC12%2f017-020&partnerID=40&md5=ffbae39cbfe143635235431b0d62aa3e","German Aerospace Center (DLR), Germany; Virtual Reality Group, RWTH Aachen University, Germany","Hummel, J., German Aerospace Center (DLR), Germany; Wolff, R., German Aerospace Center (DLR), Germany; Dodiya, J., German Aerospace Center (DLR), Germany; Gerndt, A., German Aerospace Center (DLR), Germany; Kuhlen, T., Virtual Reality Group, RWTH Aachen University, Germany","The selection of the right input devices for 3D interaction methods is important for a successful VR system. While natural direct interaction is often preferred, research has shown that indirect interaction can be beneficial. This paper focuses on an immersive simulation and training environment, in which one sub-task it is to carefully grasp and move a force-sensitive thin deformable foil without damaging it. In order to ensure transfer of training it was necessary to inform the user of the fact of gentle grasping and moving the foil. We explore the potential of three simple and light-weight interaction methods that each map interaction to a virtual hand in a distinct way. We used a standard tracked joystick with an indirect mapping, a standard finger tracking device with direct mapping based on finger position, and a novel enhanced finger tracking device, which additionally allowed pinch force input. The results of our summative user study show that the task performance did not show a significant difference among the three interaction methods. The simple position based mapping using finger tracking was most preferred, although the enhanced finger tracking device with direct force input offered the most natural interaction mapping. Our findings show that both a direct and indirect input method have potential to interact with force-sensitive thin deformable objects, while the direct method is preferred. © The Eurographics Association 2012.",,"Deformation; Mapping; Virtual reality; Deformable object; Direct interactions; Indirect interactions; Interaction methods; Natural interactions; Simulation and training; Tracking devices; Transfer of trainings; Palmprint recognition",Conference Paper,"Final","",Scopus,2-s2.0-84891873719
"Bellotti F., Berta R., De Gloria A., D'Ursi A., Fiore V.","55890888700;6701751695;7004620974;57190408589;57190413463;","A serious game model for cultural heritage",2012,"Journal on Computing and Cultural Heritage","5","4", 17,"","",,91,"10.1145/2399180.2399185","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979824728&doi=10.1145%2f2399180.2399185&partnerID=40&md5=ae14260e039349912c996214da945d52","ELIOS Lab, DITEN, University of Genoa, Via Opera Pia 11/a, 16145 Genova, Italy; DIRAS, Via Balbi, 4, 16126, Genova, Italy","Bellotti, F., ELIOS Lab, DITEN, University of Genoa, Via Opera Pia 11/a, 16145 Genova, Italy; Berta, R., ELIOS Lab, DITEN, University of Genoa, Via Opera Pia 11/a, 16145 Genova, Italy; De Gloria, A., ELIOS Lab, DITEN, University of Genoa, Via Opera Pia 11/a, 16145 Genova, Italy; D'Ursi, A., ELIOS Lab, DITEN, University of Genoa, Via Opera Pia 11/a, 16145 Genova, Italy; Fiore, V., ELIOS Lab, DITEN, University of Genoa, Via Opera Pia 11/a, 16145 Genova, Italy, DIRAS, Via Balbi, 4, 16126, Genova, Italy","Serious games present a promising opportunity for learning, but the genre still lacks methodologies and tools for efficient and low-cost production, particularly for teacher and domain experts. This article gives an authoring framework that aims to provide structured support, from content design to final implementation. In particular, we have abstracted a conceptual model-the SandBox Serious Game - which relies on a generalization of task-based learning theory. The model invites players to perform cognitive tasks contextually while exploring information-rich virtual environments.We consider it particularly suited for cultural heritage entertainment applications. The model defines games that are set in realistic virtual worlds enriched with embedded educational tasks, which we have implemented as minigames. This approach simplifies the authoring work, which can easily be supported by visual authoring tools for ontology-based urban 3D modeling and implementation tasks, thus allowing an approach similar to the mind-maps concept. We propose a top-down methodology for content preparation, starting from a citylevel analysis down to the single points of interest and associated tasks, which are instances of simple predefined minigame/quiz typologies. We provide examples and discuss criteria for selecting task typologies according to the authors' cognitive targets. Finally, we discuss the results of a user test, which took place in a lab, aimed at verifying the acquisition of cultural heritage knowledge in a pleasant and engaging way. Games appear particularly suited for supporting the study of images, especially of iconography. Compared to reading text, a game forces the player to focus more strongly on problems, which favors knowledge acquisition and retention. Learning complex concepts requires an investigative attitude, which can be spurred by well-designed games. Good design involves usability, graphic appeal, appropriate content, and the presence of connections which a player must discover in the content. Players should be asked to pay attention to and reason about their whole game activity - including the relationships between the game content, the brief introduction, and concluding texts. More comprehensive tests are needed to better investigate the educational effectiveness-however, the first results are promising, especially in terms of user motivation and creation of new opportunities for learning about CH. © 2012 ACM.","Content authoring; Cultural heritage; Game-based learning; Serious games; Task-based learning; User experience; User testing; Virtual reality","Knowledge acquisition; Content authoring; Cultural heritages; Game-based Learning; Serious games; Task-based learning; User experience; User testing; Virtual reality",Article,"Final","",Scopus,2-s2.0-84979824728
"Farley H., Gregory S., Grant S., Butler D., Jacka L., Orwin L., Jones J.K.","55343752600;56432208900;55925611200;36126068500;55516808500;55515729500;55488165300;","An informal community of practice: The case of the DEHub Virtual Worlds Working Group",2012,"ASCILITE 2012 - Annual conference of the Australian Society for Computers in Tertiary Education",,,,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912544226&partnerID=40&md5=3f24edd27d24319069c189aae1c570e4","Australian Digital Futures Institute, University of Southern Queensland, Australia; School of Education, University of New England, Australia; Monash University, Australia; Queensland University of Technology, Australia; School of Education, Southern Cross University, Australia; University of Southern Queensland, Australia","Farley, H., Australian Digital Futures Institute, University of Southern Queensland, Australia; Gregory, S., School of Education, University of New England, Australia; Grant, S., Monash University, Australia; Butler, D., Queensland University of Technology, Australia; Jacka, L., School of Education, Southern Cross University, Australia; Orwin, L., University of Southern Queensland, Australia; Jones, J.K., University of Southern Queensland, Australia","The DEHub Virtual Worlds Working Group has an informal membership of nearly 200 members with an interest in education and virtual worlds within the Australian and New Zealand context. Members come from a variety of academic disciplines and may be teaching or research academics, Research Higher Degree candidates, project managers, virtual world builders and developers. The group acts as an informal Community of Practice, facilitating learning and the transfer of skills through social contact, opportunities to collaborate on projects and publications, and through the sharing of knowledge and experience. This poster provides a snapshot of the activity of this highly active group. © 2012 Helen Farley, Sue Gregory, Scott Grant, Des Butler, Lisa Jacka, Lindy Orwin, Janice Jones.","Community of practice; Informal learning; Social learning","Education; Virtual reality; Community of practice; Informal learning; Knowledge and experience; Project managers; Social contacts; Social learning; Virtual worlds; Working groups; Interactive computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-84912544226
"Weller J.M., Nestel D., Marshall S.D., Brooks P.M., Conn J.J.","7101771038;7004284801;57006061800;35374555300;7101673511;","Simulation in clinical teaching and learning",2012,"Medical Journal of Australia","196","9",,"1","5",,116,"10.5694/mja10.11474","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861607851&doi=10.5694%2fmja10.11474&partnerID=40&md5=af036888c51b957d9ff2b2eb91bc624c","Centre for Medical and Health Sciences Education, University of Auckland, Auckland, NZ, New Zealand; Gippsland Medical School, Monash University, Churchill, VIC, Australia; Simulation and Skills Centre, Southern Health and Monash University, Monash Medical Centre, Melbourne, VIC, Australia; Australian Health Workforce Institute, University of Melbourne, Melbourne, VIC, Australia; Department of Medicine, Royal Melbourne Hospital, University of Melbourne, Melbourne, VIC, Australia","Weller, J.M., Centre for Medical and Health Sciences Education, University of Auckland, Auckland, NZ, New Zealand; Nestel, D., Gippsland Medical School, Monash University, Churchill, VIC, Australia; Marshall, S.D., Simulation and Skills Centre, Southern Health and Monash University, Monash Medical Centre, Melbourne, VIC, Australia; Brooks, P.M., Australian Health Workforce Institute, University of Melbourne, Melbourne, VIC, Australia; Conn, J.J., Department of Medicine, Royal Melbourne Hospital, University of Melbourne, Melbourne, VIC, Australia","Simulation-based education (SBE) is a rapidly developing method of supplementing and enhancing the clinical education of medical students. • Clinical situations are simulated for teaching and learning purposes, creating opportunities for deliberate practice of new skills without involving real patients. • Simulation takes many forms, from simple skills training models to computerised full-body mannequins, so that the needs of learners at each stage of their education can be targeted. • Emerging evidence supports the value of simulation as an educational technique; to be effective it needs to be integrated into the curriculum in a way that promotes transfer of the skills learnt to clinical practice. • Currently, SBE initiatives in Australia are fragmented and depend on local enthusiasts; Health Workforce Australia is driving initiatives to develop a more coordinated national approach to optimise the benefits of simulation.",,"article; audiovisual equipment; Australia; clinical competence; clinical decision making; clinical education; clinical practice; computer simulation; curriculum development; education program; educational theory; feedback system; full body mannequin; hybrid stimulators; interdisciplinary communication; learning; learning environment; medical education; medical student; part task trainer; patient safety; simulated patient; simulation; simulation based education; simulator; teamwork; audiovisual equipment; computer simulation; curriculum; educational model; human; methodology; standard; teaching; Australia; Clinical Competence; Computer Simulation; Curriculum; Education, Medical; Humans; Models, Anatomic; Models, Educational; Patient Safety; Patient Simulation",Article,"Final","",Scopus,2-s2.0-84861607851
"Guillén-Nieto V., Aleson-Carbonell M.","50461451400;50461089200;","Serious games and learning effectiveness: The case of It's a Deal!",2012,"Computers and Education","58","1",,"435","448",,160,"10.1016/j.compedu.2011.07.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052826083&doi=10.1016%2fj.compedu.2011.07.015&partnerID=40&md5=49bc6285581176933ef6bc0da147a0cb","Departamento de Filología Inglesa, Universidad de Alicante, Facultad de Filosofía y Letras, Campus de San Vicente del Raspeig, s/n, Apdo 99, 03080 San Vicente del Raspeig, Alicante, Spain","Guillén-Nieto, V., Departamento de Filología Inglesa, Universidad de Alicante, Facultad de Filosofía y Letras, Campus de San Vicente del Raspeig, s/n, Apdo 99, 03080 San Vicente del Raspeig, Alicante, Spain; Aleson-Carbonell, M., Departamento de Filología Inglesa, Universidad de Alicante, Facultad de Filosofía y Letras, Campus de San Vicente del Raspeig, s/n, Apdo 99, 03080 San Vicente del Raspeig, Alicante, Spain","Although the value of serious games in education is undeniable and the potential benefits of using video games as ideal companions to classroom instruction is unquestionable, there is still little consensus on the game features supporting learning effectiveness, the process by which games engage learners, and the types of learning outcomes that can be achieved through game play. Our aim in this discussion is precisely to advance in this direction by providing evidence of some of the factors influencing the learning effectiveness of a serious game called It's a Deal! This serious game was created for the purpose of teaching intercultural business communication between Spaniards and Britons in business settings in which English is used as the lingua franca. This paper hypothesizes that the immersive, all-embracing and interactive learning environment provided by the video game to its users may contribute to develop and enhance their intercultural communicative competence. The study attempts to answer three main research questions: (a) after playing It's a Deal!, did the students sampled improve their intercultural awareness, intercultural knowledge and intercultural communicative competence in business English? (b) If they improved their intercultural learning, what are the factors influencing such improvement? And (c) if they did not improve their intercultural learning, what are the factors influencing such failure? The game participants who volunteered to take part in the study were all students of English Studies at the University of Alicante in the academic year 2010-2011. One hundred and six students completed both the pre-test and the post-test questionnaires, and played It's a Deal! A sample of fifty students was selected randomly for the empirical study. The results obtained in the tests performed were compared and contrasted intra-group, both qualitatively and quantitatively, for the purpose of finding any statistically significant difference that may confirm whether or not there was an improvement in the students' intercultural communicative competence in business English as a result of the implementation of the It's a Deal! serious game. Findings of this study demonstrate that the video game is an effective learning tool for the teaching of intercultural communication between Spaniards and Britons in business settings in which English is used as the lingua franca. In particular, whereas the game had a small learning effect on intercultural awareness and a medium learning effect on intercultural knowledge, it had a large learning effect on intercultural communicative competence. The study also documents correlating factors that make serious games effective, since it shows that the learning effectiveness of It's a Deal! stems from the correct balance of the different dimensions involved in the creation of serious games, specifically instructional content, game dimensions, game cycle, debriefing, perceived educational value, transfer of learnt skills and intrinsic motivation. © 2011 Elsevier Ltd. All rights reserved.","Adult learning; Cross-cultural projects; Interactive learning environments; Interdisciplinary projects; Simulations","Adult learning; Cross-cultural projects; Interactive learning environment; Interdisciplinary project; Simulations; Communication; Education computing; Interactive computer graphics; Learning systems; Students; Surveys; Teaching; Human computer interaction",Article,"Final","",Scopus,2-s2.0-80052826083
"Watanuki K., Hou L.","7005697643;55729883700;","Virtual reality-based lathe skills transfer based on brain activity assessment using functional near-infrared spectroscopy",2011,"Proceedings of the ASME Design Engineering Technical Conference","2","PARTS A AND B",,"927","933",,,"10.1115/DETC2011-48992","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863586471&doi=10.1115%2fDETC2011-48992&partnerID=40&md5=4c29eeaf1f30141216215584996fae0b","Graduate School of Science and Engineering, Saitama University, Saitama University Brain Science Institute, 255 Shimo-okubo, Sakura-ku, Saitama-shi, Saitama 338-8570, Japan; Graduate School of Science and Engineering, Saitama University, 255 Shimo-okubo, Sakura-ku, Saitama-shi, Saitama 338-8570, Japan","Watanuki, K., Graduate School of Science and Engineering, Saitama University, Saitama University Brain Science Institute, 255 Shimo-okubo, Sakura-ku, Saitama-shi, Saitama 338-8570, Japan; Hou, L., Graduate School of Science and Engineering, Saitama University, 255 Shimo-okubo, Sakura-ku, Saitama-shi, Saitama 338-8570, Japan","Here, we propose a new virtual reality-based job training program for human resource development. In our proposed system, the educational content is displayed in the immersive virtual environment with haptic information, very similar to the way a trainee may experience work in the virtual site operation. The brain functional activities of the trainee under virtual and real skills training are measured using near-infrared spectroscopy, and the characteristics of the activity patterns are analyzed in detail. © 2011 by ASME.",,"Activity patterns; Brain activity; Educational contents; Functional activities; Functional-near infrared; Human resource development; Immersive virtual environments; Site operations; Skills training; Training program; Brain; Design; Textiles; Virtual reality; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-84863586471
"Watanuki K., Hou L.","7005697643;55729883700;","Virtual reality-based lathe operation training based on brain activity assessment using functional near-infrared spectroscopy",2011,"Advanced Concurrent Engineering",,,,"301","308",,,"10.1007/978-0-85729-799-0_35","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870222404&doi=10.1007%2f978-0-85729-799-0_35&partnerID=40&md5=09b1df96bef283aeac619b29df3e01d1","School of Science and Engineering, Saitama University, Japan; Saitama University Brain Science Institute, Japan; Graduate School of Science and Engineering, Saitama University, Japan","Watanuki, K., School of Science and Engineering, Saitama University, Japan, Saitama University Brain Science Institute, Japan; Hou, L., Graduate School of Science and Engineering, Saitama University, Japan","This paper proposes a new virtual reality-based lathe operation training and human resource development. In our proposed system, the education content is displayed in the immersive virtual environment with haptic information, whereby a trainee may experience work in the virtual site operation. The brain functional activities of the worker under virtual and real skills training are measured using near-infrared spectroscopy, and the characteristics of these activities are analyzed in detail. © 2011 Springer-Verlag London Limited.","Brain activity analysis; Lathe operation; Near-infrared spectroscopy; Skills transfer; Virtual reality","Brain activity; Brain activity analysis; Functional activities; Functional-near infrared; Human resource development; Immersive virtual environments; Site operations; Skills training; Skills transfer; Brain; Concurrent engineering; Lathes; Personnel training; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84870222404
"Harter D., Lu S., Kotturu P., Pierce D.","7005776620;55017156300;55327796200;36119152900;","An immersive virtual environment for varying risk and immersion for effective training",2011,"ASME 2011 World Conference on Innovative Virtual Reality, WINVR 2011",,,,"301","307",,3,"10.1115/WINVR2011-5522","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881453775&doi=10.1115%2fWINVR2011-5522&partnerID=40&md5=47f9f5e5b2e0153b80da492362375d9a","Department of Computer Science and Information Systems, Artificial Intelligence and Robotics Laboratory, Texas A and M University, Commerce, TX 75429, United States; Department of Psychology, Cognitive Science Laboratory, Texas A and M University, Commerce, TX, 75429, United States","Harter, D., Department of Computer Science and Information Systems, Artificial Intelligence and Robotics Laboratory, Texas A and M University, Commerce, TX 75429, United States; Lu, S., Department of Psychology, Cognitive Science Laboratory, Texas A and M University, Commerce, TX, 75429, United States; Kotturu, P., Department of Psychology, Cognitive Science Laboratory, Texas A and M University, Commerce, TX, 75429, United States; Pierce, D., Department of Psychology, Cognitive Science Laboratory, Texas A and M University, Commerce, TX, 75429, United States","We present an immersive virtual environment being developed to study questions of risk perception and their impacts on effective training. Immersion is known to effect the quality of training in virtual environments, and the successful transfer of skills to real world situations. However, the level of perceived immersiveness that an environment invokes is an ill defined concept, and effects of different types of immersion are known to have greater and lesser influences on training outcomes. We concentrate on how immersiveness effects perceived risk in virtual environments, and how risk impacts training effectiveness. Simulated risk can invoke an alief of danger in subjects using a virtual environment. Alief is a concept useful in virtual training that describes situations where the person experiencing a simulated scenario knows it is not real, but suspends disbelief (willingly or unwillingly). This suspension of belief (alief can cause the person to experience the same sorts of autonomic reactions as if they were experiencing the situation in real life (for example, think of fear invoked on amusement park rides). Alief of risk or danger has been proposed as one phenomenon that can influence training outcomes, like the experience of immersion, when training in virtual environments. In this paper we present work on developing a low-cost virtual environment for the manipulation of immersion and risk for cognitive studies. In this environment we provide several alternative input modalities, from mouse to Wii remote interactivity, to control a virtual avatar's hand and arm for performing risky every day tasks. Immersion can be manipulated in several ways, as well as the type and risk associated with tasks. Typical tasks include performing kitchen preparation work (using knives or hot items), or wood or metal working tasks (involving manipulation of dangerous tools). This paper describes the development and technologies used to create the virtual environment, and how we vary risk perception and immersion of users for various cognitive tasks. The capabilities and manipulations of immersiveness and risk are presented together with some findings on using Wii motes as input devices in several ways for virtual environments. The paper concludes with some preliminary results of varying perceived risk on cognitive task performance in the developed environment. Copyright © 2011 by ASME.",,"Alternative input; Amusement-park rides; Cognitive task; Development and technology; Immersive virtual environments; Real world situations; Training effectiveness; Virtual training; Risk perception; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84881453775
"Steinicke F., Lécuyer A., Mohler B., Whitton M.C.","8883314100;6601917415;10239373300;6604019357;","Perceptually inspired methods for naturally navigating virtual worlds",2011,"SIGGRAPH Asia 2011 Courses, SA'11",,, 18,"","",,,"10.1145/2077434.2077449","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855696741&doi=10.1145%2f2077434.2077449&partnerID=40&md5=a396a60d6c7905555bcc45f86cdc793c","Immersive Media Group, University of Würzburg, Germany; BUNRAKU Research Team, INRIA, Rennes, France; Perception and Action in Virtual Environments, MPI for Biological Cybernetics, Germany; Department of Computer Science, University of North Carolina, Chapel Hill, United States","Steinicke, F., Immersive Media Group, University of Würzburg, Germany; Lécuyer, A., BUNRAKU Research Team, INRIA, Rennes, France; Mohler, B., Perception and Action in Virtual Environments, MPI for Biological Cybernetics, Germany; Whitton, M.C., Department of Computer Science, University of North Carolina, Chapel Hill, United States","In recent years many advances have enabled users to more and more naturally navigate large-scale graphical worlds. The entertainment industry is increasingly providing visual and body-based cues to their users to increase the naturalness of their navigational experience. However, so far none of the existing solutions fully supports the most natural ways of locomotion through virtual worlds, and thus techniques and technologies have to be considered, which take advantage of insights into human perceptual sensitivity. In this context, by far the most natural way to move through the real world is via a full body experience where we receive sensory stimulation to all of our senses, i.e., when walking, running, biking or driving. With some exciting technological advances, people are now beginning to get this same full body sensory experience when navigating computer generated three-dimensional environments [11]. Enabling such an active and dynamic ability to navigate through large-scale virtual scenes is of great interest for many 3D applications demanding locomotion, such as video games, edutainment, simulation, rehabilitation, military, tourism or architecture. Today it is still mostly impossible to freely navigate through computer generated environments in exactly the same way as in the real world [1] and instead rather unnatural and artificial approaches are usually applied, which provide only visual sensation of self-motion. However, while moving in the real world, sensory information such as vestibular, proprioceptive, as well as visual information create consistent multi-sensory cues that indicate ones own motion, i. e., acceleration, speed and direction of travel [5]. Computer graphics environments were initially restricted to visual displays, combined with interaction devices, e. g. joystick or mouse, for providing (often unnatural) inputs to generate self-motion [2]. Today, more and more interaction devices, e. g., Nintendos Wii, Microsofts Kinect or Sonys EyeToy, enable intuitive and natural interaction. In this context many research groups are investigating natural, multimodal methods of generating self-motion in virtual worlds based on these consumer hardware. An obvious approach is to transfer the users tracked head movements to changes of the camera in the virtual world by means of a one-to-one mapping. Then, one meter movement in the real world is mapped to one meter movement of the virtual camera in the corresponding direction in the virtual environment (VE). This technique has the drawback that the users movements are restricted by a limited range of the tracking sensors, e. g. optical cameras, and usually a rather small workspace in the real world [2]. The size of the virtual world often differs from the size of the tracked space so that a straightforward implementation of omni-directional and unlimited walking is not possible [12, 2]. Thus, creative virtual locomotion methods (i. e. redirected walking, walking in place, chairs as joysticks, visual indications of natural movement) have been used that enable the experience of traveling over large distances in the virtual world while remaining within a relatively small space in the real world [7, 6]. In recent years, two omni-directional treadmills have been built and are used in the research community (University of Louisiana and Max Planck Institute for Biological Cybernetics). These scientists can now explore infinite virtual worlds while choosing to navigate in any direction. Using these treadmills scientists can determine what about the body-based senses are important for different aspects of entertainment, training and learning. In this course we will present an overview about the development of locomotion interfaces for computer generated virtual environments ranging from desktop-based camera manipulations simulating walking, and different walking metaphors for virtual reality (VR)-based environments to state-of-the-art hardware-based solutions that enable omni-directional and unlimited real locomotion through virtual worlds. As the computer graphics industry advances towards increasingly more natural interaction, computer graphics researchers and professionals will benefit from this course by increasing their understanding of human perception and how this knowledge can apply to enabling the most natural interaction technique of all, navigating through the world. © 2011 ACM.",,"3D application; Biological cybernetics; Edutainment; Entertainment industry; Full body; Head movements; Human perception; Interaction devices; Locomotion interfaces; Louisiana; Max Planck Institute; Multi-modal; Natural interactions; Natural movements; Omni-directional; One-to-one mappings; Optical camera; Research communities; Research groups; Self motion; Sensory information; Sensory stimulation; Technological advances; Three-dimensional environment; Video game; Virtual camera; Virtual environments; Virtual locomotion; Virtual scenes; Virtual worlds; Visual display; Visual information; Walking-in-place; Cameras; Computer hardware; Curricula; Display devices; Human computer interaction; Interactive computer graphics; Military applications; Navigation; Research; Sporting goods; Three dimensional; Three dimensional computer graphics; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84855696741
"Legény J., Abad R.V., Lécuyer A.","57213298912;8203882800;6601917415;","Navigating in virtual worlds using a self-paced ssvep-based brain-computer interface with integrated stimulation and real-time feedback",2011,"Presence: Teleoperators and Virtual Environments","20","6",,"529","544",,19,"10.1162/PRES_a_00075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859389226&doi=10.1162%2fPRES_a_00075&partnerID=40&md5=67e7aac4b857a7300910d6c35409c3a1","INRIA Rennes, Campus de Beaulieu, 35042 Rennes Cedex, France; Telecommunication Engineering Department, University of Jaén, Spain; INRIA Bretagne-Atlantique, Campus de Beaulieu, 35042 Rennes Cedex, France","Legény, J., INRIA Rennes, Campus de Beaulieu, 35042 Rennes Cedex, France; Abad, R.V., Telecommunication Engineering Department, University of Jaén, Spain; Lécuyer, A., INRIA Bretagne-Atlantique, Campus de Beaulieu, 35042 Rennes Cedex, France","An open question in research nowadays is the usability of brain-computer interfaces (BCI) conceived to extend human capabilities of interaction within a virtual environment. Several paradigms are used for BCI, but the steady-state visual-evoked potential (SSVEP) stands out as it provides a higher information transfer rate while requiring less training. It is an electroencephalographic response detectable when the user looks at a flickering visual stimulus. This research proposes a novel approach for SSVEP-based BCI controller used here for navigation within a 3D virtual environment. For the first time, the flickering stimuli were integrated into virtual objects as a part of the virtual scene in a more transparent and ecological way. As an example, when navigating inside a virtual natural outdoor scene, we could embed the SSVEP flashes in the wings of virtual butterflies surrounding the user. We could also introduce the use of animated and moving stimulations when using SSVEP-based BCI, as the virtual butterflies were left with the possibility of moving and flying in front of the user. Moreover, users received real-time feedback of their mental activity and were thus aware of their detected SSVEP directly and continuously. An experiment has been conducted to assess the influence of both the feedback and the integrated controller on navigation performance and subjective preference. We found that the usage of a controller integrated within the virtual scene along with the feedback seems to improve subjective preference and feeling of presence, despite reduced performance in terms of speed. This suggests that SSVEP-based BCI interfaces for virtual environments could move on from static targets and use integrated and animated stimuli presented in an ecological way for controls in systems where performance demands could be relaxed to benefit an improvement in interaction naturalness. © 2012 by the Massachusetts Institute of Technology.",,"3-D virtual environment; Brain-computer interfaces (BCI); Controller-integrated; Human capability; Information transfer rate; Integrated controllers; Mental activity; Navigation performance; Outdoor scenes; Real-time feedback; Steady-state visual-evoked potentials; Virtual objects; Virtual scenes; Virtual worlds; Visual stimulus; Ecology; Flickering; Integration; Interfaces (computer); Virtual reality; Brain computer interface",Article,"Final","",Scopus,2-s2.0-84859389226
"Chen M., AlRegib G., Juang B.-H.","56957317100;6506443965;7005536765;","An integrated framework for universal motion control",2011,"Proceedings of VRCAI 2011: ACM SIGGRAPH Conference on Virtual-Reality Continuum and its Applications to Industry",,,,"513","518",,3,"10.1145/2087756.2087854","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863044643&doi=10.1145%2f2087756.2087854&partnerID=40&md5=92327f7e7f4a7ad8a7a2d2d903ed012d","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332, United States","Chen, M., School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332, United States; AlRegib, G., School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332, United States; Juang, B.-H., School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332, United States","The advance of the motion tracking and 3D display technologies impacts the input and output devices of the general human-computer interaction framework nowadays. The motion sensing devices can provide great tracking accuracy at relatively low prices, which make motion-based interactions affordable and popular for general use. Taking into account all the general interactions required on graphic user interfaces, we propose an integrated framework for motion control, which seamlessly supports 2D, 3D and motion gesture interactions. We categorize the general tasks and define four corresponding operating modes: 2D cursor, 3D manipulation, 3D navigation, and motion gesture. Trade-offs are made between generality, performance, and usability. With a careful design of mapping, we believe the generality of the motion control can outweigh the compromise in performance. In the implementation, a hybrid framework of optical and inertial sensing is used to achieve precise 6 DOF motion tracking. We develop two interesting applications to demonstrate the usability of the integrated motion control framework between the first three operating modes. The motion gesture mode is proposed but not covered in this work. © 2011 ACM.","3D interaction; 3D user interface; Motion control; Motion gesture; Universal user interface","3D display technologies; 3D interactions; 3D manipulation; 3D navigation; 3D user interface; Control framework; Gesture interaction; Graphic user interface; Hybrid framework; Inertial sensing; Input and outputs; Integrated frameworks; Interaction framework; Motion gesture; Motion sensing; Motion tracking; Operating modes; Tracking accuracy; Display devices; Human computer interaction; Integration; Interactive computer graphics; Motion control; Sensors; Three dimensional; Virtual reality; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-84863044643
"Bernhard M., Grosse K., Wimmer M.","36633791800;54880797000;7103054284;","Bimodal task-facilitation in a virtual traffic scenario through spatialized sound rendering",2011,"ACM Transactions on Applied Perception","8","4", 24,"","",,4,"10.1145/2043603.2043606","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855213891&doi=10.1145%2f2043603.2043606&partnerID=40&md5=d0c12e5e5510b519150a7ac34b38c028","Vienna University of Technology, Austria","Bernhard, M., Vienna University of Technology, Austria; Grosse, K., Vienna University of Technology, Austria; Wimmer, M., Vienna University of Technology, Austria","Audio rendering is generally used to increase the realism of virtual environments (VE). In addition, audio rendering may also improve the performance in specific tasks carried out in interactive applications such as games or simulators. In this article we investigate the effect of the quality of sound rendering on task performance in a task which is inherently vision-dominated. The task is a virtual traffic gap-crossing scenario with two elements: first, to discriminate crossable and uncrossable gaps in oncoming traffic, and second, to find the right timing to start crossing the street without an accident. A study was carried out with 48 participants in an immersive virtual environment setup with a large screen and headphones. Participants were grouped into three different scenarios. In the first one, spatialized audio rendering with head-related transfer function (HRTF) filtering was used. The second group was tested with conventional stereo rendering, and the remaining group ran the experiment in a mute condition. Our results give a clear evidence that spatialized audio improves task performance compared to the unimodal mute condition. Since all task-relevant information was in the participants' field-of-view, we conclude that an enhancement of task performance results from a bimodal advantage due to the integration of visual and auditory spatial cues. © 2011 ACM.","Audio-visual perception; Bimodal; Human-computer interaction; Pedestrian safety; Pedestrian simulator; Spatialized audio rendering; Task facilitation; Virtual environments","Audio rendering; Bimodal; Field of views; Head related transfer function; Immersive virtual environments; Interactive applications; Large screen; Quality of sounds; Second group; Spatial cues; Spatialized audio; Spatialized sound; Specific tasks; Task facilitation; Task performance; Unimodal; Virtual environments; Human computer interaction; Pedestrian safety; Sensory perception; Sound reproduction; Virtual reality; Audio acoustics",Article,"Final","",Scopus,2-s2.0-84855213891
"Hodgson E., Bachmann E., Waller D.","14053915200;7005745121;7203026309;","Redirected walking to explore virtual environments: Assessing the potential for spatial interference",2011,"ACM Transactions on Applied Perception","8","4", 22,"","",,46,"10.1145/2043603.2043604","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855243871&doi=10.1145%2f2043603.2043604&partnerID=40&md5=849f0a43f0fe124fd20cbdb756064998","Department of Psychology, 90 N. Patterson Ave., Oxford, OH 45056, United States; Department of Computer Science, Benton Hall, Oxford, OH 45056, United States","Hodgson, E., Department of Psychology, 90 N. Patterson Ave., Oxford, OH 45056, United States; Bachmann, E., Department of Computer Science, Benton Hall, Oxford, OH 45056, United States; Waller, D., Department of Psychology, 90 N. Patterson Ave., Oxford, OH 45056, United States","Redirected walking has gained popularity in recent years as a way of enhancing the safety of users immersed in a virtual reality simulation and of extending the amount of space that can be simulated in a virtual environment (VE). Limits imposed by the available physical space and functional tracking area are overcome by inducing immersed users to veer imperceptibly in a way that prevents them from leaving the confines of the tracking space. Redirected walking has been shown to be feasible at levels below noticeable thresholds and to function without increasing the incidence of simulator sickness. The present studies demonstrate that redirected walking can function without negatively impacting memory for spatial locations of landmarks in a VE, despite introducing discrepancies between various spatial senses and distorting the spatial mapping of movement onto the environment. Additionally, the present studies implement what, to our knowledge, is the first generalized redirected walking algorithm that is independent of any task or environment structure, and can adaptively steer users in real time as they engage in spontaneous, unconstrained navigation. The studies also demonstrate that such an algorithm can be implemented successfully in a gymnasium-sized space. © 2011 ACM.","3D interfaces; Human computer interaction; Multimodal sensory integration; Redirected walking; Spatial cognition; Spatial memory; Spatial senses; Virtual reality","3D interface; Multi-modal; Redirected walking; Spatial cognition; Spatial memory; Spatial senses; Algorithms; Human computer interaction; Virtual reality",Article,"Final","",Scopus,2-s2.0-84855243871
"Ma H.-I., Hwang W.-J., Fang J.-J., Kuo J.-K., Wang C.-Y., Leong I.-F., Wang T.-Y.","7403095847;35083606700;35757300300;47761344300;48461995300;8363852400;12780328200;","Effects of virtual reality training on functional reaching movements in people with Parkinson's disease: A randomized controlled pilot trial",2011,"Clinical Rehabilitation","25","10",,"892","902",,31,"10.1177/0269215511406757","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053935167&doi=10.1177%2f0269215511406757&partnerID=40&md5=f77f24f6c3e937201db85e5cccdc4458","Department of Occupational Therapy, College of Medicine, National Cheng Kung University, 1 University Road, Tainan 701, Taiwan; Department of Neurology, College of Medicine, National Cheng Kung University, Tainan, Taiwan; Department of Mechanical Engineering, College of Engineering, National Cheng Kung University, Tainan, Taiwan","Ma, H.-I., Department of Occupational Therapy, College of Medicine, National Cheng Kung University, 1 University Road, Tainan 701, Taiwan; Hwang, W.-J., Department of Neurology, College of Medicine, National Cheng Kung University, Tainan, Taiwan; Fang, J.-J., Department of Mechanical Engineering, College of Engineering, National Cheng Kung University, Tainan, Taiwan; Kuo, J.-K., Department of Mechanical Engineering, College of Engineering, National Cheng Kung University, Tainan, Taiwan; Wang, C.-Y., Department of Occupational Therapy, College of Medicine, National Cheng Kung University, 1 University Road, Tainan 701, Taiwan; Leong, I.-F., Department of Mechanical Engineering, College of Engineering, National Cheng Kung University, Tainan, Taiwan; Wang, T.-Y., Department of Occupational Therapy, College of Medicine, National Cheng Kung University, 1 University Road, Tainan 701, Taiwan","Objective: To investigate whether practising reaching for virtual moving targets would improve motor performance in people with Parkinson's disease.Design: Randomized pretest-posttest control group design.Setting: A virtual reality laboratory in a university setting.Participants: Thirty-three adults with Parkinson's disease.Interventions: The virtual reality training required 60 trials of reaching for fast-moving virtual balls with the dominant hand. The control group had 60 practice trials turning pegs with their non-dominant hand.Main outcome measures: Pretest and posttest required reaching with the dominant hand to grasp real stationary balls and balls moving at different speeds down a ramp. Success rates and kinematic data (movement time, peak velocity and percentage of movement time for acceleration phase) from pretest and posttest were recorded to determine the immediate transfer effects.Results: Compared with the control group, the virtual reality training group became faster (F=9.08, P=0.005) and more forceful (F=9.36, P=0.005) when reaching for real stationary balls. However, there was no significant difference in success rate or movement kinematics between the two groups when reaching for real moving balls.Conclusion: A short virtual reality training programme improved the movement speed of discrete aiming tasks when participants reached for real stationary objects. However, the transfer effect was minimal when reaching for real moving objects. © The Author(s) 2011.","context; cueing; motor performance; Parkinson's disease; rehabilitation","article; association; clinical trial; computer assisted therapy; computer interface; controlled clinical trial; controlled study; female; human; male; methodology; middle aged; motor performance; Parkinson disease; pilot study; randomized controlled trial; reaction time; Cues; Female; Humans; Male; Middle Aged; Motor Skills; Parkinson Disease; Pilot Projects; Reaction Time; Therapy, Computer-Assisted; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-80053935167
"Shepherd I.D.H., Bleasdale-Shepherd I.D.","7006459882;36162886400;","The design-by-adaptation approach to universal access: Learning from videogame technology",2011,"Universal Access in the Information Society","10","3",,"319","336",,2,"10.1007/s10209-010-0204-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960646197&doi=10.1007%2fs10209-010-0204-x&partnerID=40&md5=ce01bbecaea5ced46fb9791b6301f5dd","Department of Marketing and Enterprise, Middlesex University, The Burroughs, London NW4 4BT, United Kingdom; Valve Software, 10900 NE 4th St., Suite 500, Bellevue, WA 98004, United States","Shepherd, I.D.H., Department of Marketing and Enterprise, Middlesex University, The Burroughs, London NW4 4BT, United Kingdom; Bleasdale-Shepherd, I.D., Valve Software, 10900 NE 4th St., Suite 500, Bellevue, WA 98004, United States","This paper proposes an alternative approach to the design of universally accessible interfaces to that provided by formal design frameworks applied ab initio to the development of new software. This approach, design-byadaptation, involves the transfer of interface technology and/or design principles from one application domain to another, in situations where the recipient domain is similar to the host domain in terms of modelled systems, tasks and users. Using the example of interaction in 3D virtual environments, the paper explores how principles underlying the design of videogame interfaces may be applied to a broad family of visualization and analysis software which handles geographical data (virtual geographic environments, or VGEs). One of the motivations behind the current study is that VGE technology lags some way behind videogame technology in the modelling of 3D environments, and has a less-developed track record in providing the variety of interaction methods needed to undertake varied tasks in 3D virtual worlds by users with varied levels of experience. The current analysis extracted a set of interaction principles from videogames which were used to devise a set of 3D task interfaces that have been implemented in a prototype VGE for formal evaluation. © 2010 Springer-Verlag.","Adaptation; GIS; Transfer; User interfaces; Videogames; Virtual geographical environments","3-D environments; 3-D virtual environment; Ab initio; Adaptation; Alternative approach; Application domains; Current analysis; Design Principles; Formal design; Geographical data; Interaction methods; Interface technology; Task interface; Track record; Transfer; Universal access; Video game; Virtual geographic environments; Virtual geographical environments; Virtual worlds; Visualization and analysis; Data visualization; Formal methods; Geographic information systems; Interactive computer graphics; Technology; Three dimensional; User interfaces; Virtual reality; Visualization; Design",Article,"Final","",Scopus,2-s2.0-79960646197
"Wallet G., Sauzéon H., Pala P.A., Larrue F., Zheng X., N'Kaoua B.","26425357400;7801452039;45761441400;36139685200;45761597200;6603602499;","Virtual/real transfer of spatial knowledge: Benefit from visual fidelity provided in a virtual environment and impact of active navigation",2011,"Cyberpsychology, Behavior, and Social Networking","14","7-8",,"417","423",,33,"10.1089/cyber.2009.0187","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960547754&doi=10.1089%2fcyber.2009.0187&partnerID=40&md5=d30ce2d7a9ecd2a456344939808d7a43","Université Victor Segalen Bordeaux II, Laboratoire Cognition et Facteurs Humains (EA-487), Bâtiment 1A, 146 Rue Léo Saignat, 33076 Bordeaux Cedex, France, France; Beijing Normal University, Beijing, China","Wallet, G., Université Victor Segalen Bordeaux II, Laboratoire Cognition et Facteurs Humains (EA-487), Bâtiment 1A, 146 Rue Léo Saignat, 33076 Bordeaux Cedex, France, France; Sauzéon, H., Université Victor Segalen Bordeaux II, Laboratoire Cognition et Facteurs Humains (EA-487), Bâtiment 1A, 146 Rue Léo Saignat, 33076 Bordeaux Cedex, France, France; Pala, P.A., Université Victor Segalen Bordeaux II, Laboratoire Cognition et Facteurs Humains (EA-487), Bâtiment 1A, 146 Rue Léo Saignat, 33076 Bordeaux Cedex, France, France; Larrue, F., Université Victor Segalen Bordeaux II, Laboratoire Cognition et Facteurs Humains (EA-487), Bâtiment 1A, 146 Rue Léo Saignat, 33076 Bordeaux Cedex, France, France; Zheng, X., Beijing Normal University, Beijing, China; N'Kaoua, B., Université Victor Segalen Bordeaux II, Laboratoire Cognition et Facteurs Humains (EA-487), Bâtiment 1A, 146 Rue Léo Saignat, 33076 Bordeaux Cedex, France, France","The purpose of this study was to evaluate the effect the visual fidelity of a virtual environment (VE) (undetailed vs. detailed) has on the transfer of spatial knowledge based on the navigation mode (passive vs. active) for three different spatial recall tasks (wayfinding, sketch mapping, and picture sorting). Sixty-four subjects (32 men and 32 women) participated in the experiment. Spatial learning was evaluated by these three tasks in the context of the Bordeaux district. In the wayfinding task, the results indicated that the detailed VE helped subjects to transfer their spatial knowledge from the VE to the real world, irrespective of the navigation mode. In the sketch-mapping task, the detailed VE increased performances compared to the undetailed VE condition, and allowed subjects to benefit from the active navigation. In the sorting task, performances were better in the detailed VE; however, in the undetailed version of the VE, active learning either did not help the subjects or it even deteriorated their performances. These results are discussed in terms of appropriate perceptive-motor and/or spatial representations for each spatial recall task. © 2011, Mary Ann Liebert, Inc. 2011.",,"adult; article; behavior; computer interface; depth perception; environment; female; human; knowledge; learning; male; orientation; problem solving; vision; Adult; Environment; Female; Humans; Knowledge; Learning; Male; Orientation; Problem Solving; Space Perception; Spatial Behavior; Transfer (Psychology); User-Computer Interface; Visual Perception",Article,"Final","",Scopus,2-s2.0-79960547754
"Harrington M.C.R.","36836717500;","Empirical evidence of priming, transfer, reinforcement, and learning in the real and virtual trillium trails",2011,"IEEE Transactions on Learning Technologies","4","2", 5539765,"175","186",,21,"10.1109/TLT.2010.20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81855200302&doi=10.1109%2fTLT.2010.20&partnerID=40&md5=2a5c97a19384afb2be7a113cea8d572e","Department of Computer Science, Slippery Rock University, Slippery Rock, PA 16057, United States","Harrington, M.C.R., Department of Computer Science, Slippery Rock University, Slippery Rock, PA 16057, United States","Over the past 20 years, there has been a debate on the effectiveness of virtual reality used for learning with young children, producing many ideas but little empirical proof. This empirical study compared learning activity in situ of a real environment (Real) and a desktop virtual reality (Virtual) environment, built with video game technology, for discovery-based learning. The experiences were in the form of two field trips featuring statistically identical wildflower reserves. While the results support that the Real is superior for learning activity, they also show that the Virtual is useful for priming and reinforcing in-curriculum material, or for situations when the real environment is inaccessible. Offering the Virtual first primes for learning activity in the Real; if used second, it reinforces the Real experience, as supporting evidence shows significant transfer effects. Thus, the Virtual may serve educational goals, if used appropriately, and can come close to the Real. As informal learning environments, such as field trips and video games, are accepted as motivational, an attitudinal survey was conducted postexperiences to capture motivational factors at play, to aid in comparison and contrast, and to provide context to the empirical results on learning activity in situ; however, more work is needed. © 2008 IEEE.","child-computer interface; Child-computer-environment interaction; discovery-based learning; educational simulation; evaluation/ methodology; human factors in software design; human information processing; human-computer interaction; informal learning; intrinsic learning; modeling; salient events; serious games; simulation; software psychology; user interfaces; user-centered design; virtual reality; visualization","child-computer interface; Child-computer-environment interaction; Discovery-based learning; Educational simulations; evaluation/ methodology; human factors in software design; Human information processing; Human-computer; Informal learning; intrinsic learning; salient events; Serious games; simulation; software psychology; User centered designs; Bionics; Curricula; Data processing; Human computer interaction; Human engineering; Interactive computer graphics; Knowledge management; Reinforcement; Software design; User interfaces; Visualization; Virtual reality",Article,"Final","",Scopus,2-s2.0-81855200302
"Rezazadeh I.M., Wang X., Firoozabadi M., Hashemi Golpayegani M.R.","15844046500;8945580300;6506647252;15843404600;","Using affective human-machine interface to increase the operation performance in virtual construction crane training system: A novel approach",2011,"Automation in Construction","20","3",,"289","298",,59,"10.1016/j.autcon.2010.10.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952624201&doi=10.1016%2fj.autcon.2010.10.005&partnerID=40&md5=3b3261e268baa37c5a20c027201e52ae","Department of Biomedical Eng., Science and Research Branch, Islamic Azad University, Tehran, Iran; Faculty of Built Environment, University of New South Wales, Australia; Department of Housing and Interior Design, Kyung Hee University, Seoul, South Korea; School of Medical Sciences, Tarbiat Modares University, Tehran, Iran; Department of Biomedical Eng., Amir Kabir University of Technology, Tehran, Iran","Rezazadeh, I.M., Department of Biomedical Eng., Science and Research Branch, Islamic Azad University, Tehran, Iran; Wang, X., Faculty of Built Environment, University of New South Wales, Australia, Department of Housing and Interior Design, Kyung Hee University, Seoul, South Korea; Firoozabadi, M., Department of Biomedical Eng., Science and Research Branch, Islamic Azad University, Tehran, Iran, School of Medical Sciences, Tarbiat Modares University, Tehran, Iran; Hashemi Golpayegani, M.R., Department of Biomedical Eng., Science and Research Branch, Islamic Azad University, Tehran, Iran, Department of Biomedical Eng., Amir Kabir University of Technology, Tehran, Iran","In the construction industry, some progress have been achieved by researchers to design and implement environments for task training using VR technology and its derivatives such as Augmented and Mixed Reality. Although, these developments have been well recognized at the application level, however crucial to the virtual training system is the effective and reliable measurement of training performance of the particular skill and handling the experiment for long-run. It is known that motor skills cannot be measured directly, but only inferred by observing behaviour or performance measures. The typical way of measuring performance is through measuring task completion time and accuracy, but can be supported by indirect measurement of some other factors. In this paper, a virtual crane training system has been developed which can be controlled using control commands extracted from facial gestures and is capable to lift up loads/materials in the virtual construction sites. Then, we integrate affective computing concept into the conventional VR training platform for measuring the cognitive load and level of satisfaction during performance using human's forehead bioelectric-signals. By employing the affective measures and our novel control scheme, the designed interface could be adapted to user's affective status during the performance in real-time. This adaptable user interface approach helps the trainee to cope with the training for long-run performance, leads to gaining more expertise and provides more effective transfer of learning to other operation environments. The detailed methodology of the affective control is presented in the paper. The results and future applications of the proposed method for disabled users, especially from neck down are discussed. © 2010 Elsevier B.V. All rights reserved.","Affective computing; Affective measures; Construction training; Facial bioelectric-signals; Virtual Reality","Adaptable user interfaces; Affective Computing; Affective measures; Application level; Cognitive loads; Construction training; Control command; Facial bioelectric-signals; Facial gestures; Future applications; Human Machine Interface; Indirect measurements; Level of satisfaction; Long-run performance; Measuring performance; Mixed reality; Motor skills; Novel control scheme; Operation performance; Performance measure; Reliable measurement; Task completion time; Training platform; Training Systems; Transfer of learning; Virtual construction; Virtual construction site; Virtual training; VR technology; Construction industry; Cranes; Human computer interaction; Man machine systems; User interfaces; Virtual reality; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-79952624201
"Rilling S., Wechselberger U.","36810440400;34870912400;","A framework to meet didactical requirements for serious game design",2011,"Visual Computer","27","4",,"287","297",,6,"10.1007/s00371-011-0550-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955789920&doi=10.1007%2fs00371-011-0550-6&partnerID=40&md5=b6604a602f2f78716c0907523e60e8db","Institute for Computational Visualistics, University of Koblenz, Koblenz, Germany","Rilling, S., Institute for Computational Visualistics, University of Koblenz, Koblenz, Germany; Wechselberger, U., Institute for Computational Visualistics, University of Koblenz, Koblenz, Germany","Interest in game-based training is growing within the industry. In this article, we present an interdisciplinary work on the application of computer game principles and techniques within an automation industry training scenario. A data flow-based component architecture forms the technical foundation of our system and enables us to exploit the capabilities of available middleware components like game or physics engines. An interactive simulation of a real automation plant is built as a combination of state-based and physical object behavior. A training scenario founded on didactical principles of video game is built with the help of our implemented system. © Springer-Verlag 2011.","Data Flow architecture; Object behavior; Serious games; Training simulation","Automation industry; Component architectures; Computer game; Dataflow architecture; Interactive simulations; Interdisciplinary work; Middleware components; Object behavior; Physical objects; Physics engine; Serious games; State-based; Training scenario; Training simulation; Video game; Computer applications; Data transfer; Middleware; User interfaces; Human computer interaction",Conference Paper,"Final","",Scopus,2-s2.0-79955789920
"White S.A., Prachyabrued M., Chambers T.L., Borst C.W., Reiners D.","55452526400;18936813700;7202454867;9736479200;6507129285;","Low-cost simulated MIG welding for advancement in technical training",2011,"Virtual Reality","15","1",,"69","81",,9,"10.1007/s10055-010-0162-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951950718&doi=10.1007%2fs10055-010-0162-x&partnerID=40&md5=4949d7a5a2faa7342746e263e141d8e2","University of Louisiana at Lafayette, 537 Cajundome Boulevard, Lafayette, LA 70506, United States","White, S.A., University of Louisiana at Lafayette, 537 Cajundome Boulevard, Lafayette, LA 70506, United States; Prachyabrued, M., University of Louisiana at Lafayette, 537 Cajundome Boulevard, Lafayette, LA 70506, United States; Chambers, T.L., University of Louisiana at Lafayette, 537 Cajundome Boulevard, Lafayette, LA 70506, United States; Borst, C.W., University of Louisiana at Lafayette, 537 Cajundome Boulevard, Lafayette, LA 70506, United States; Reiners, D., University of Louisiana at Lafayette, 537 Cajundome Boulevard, Lafayette, LA 70506, United States","The simulated MIG lab (sMIG) is a training simulator for Metal Inert Gas (MIG) welding. It is based on commercial off the shelf (COTS) components and targeted at familiarizing beginning students with the MIG equipment and best practices to follow to become competent and effective MIG welders. To do this, it simulates the welding process as realistically as possible using standard welding hardware components (helmet, gun) for input and by using head-tracking and a 3D-capable low-cost monitor and standard speakers for output. We developed a simulation to generate realistic audio and visuals based on numerical heat transfer methods and verified the accuracy against real welds. sMIG runs in real time producing a realistic, interactive, and immersive welding experience while maintaining a low installation cost. In addition to being realistic, the system provides instant feedback beyond what is possible in a traditional lab. This help students avoid learning (and unlearning) incorrect movement patterns. © 2010 Springer-Verlag London Limited.","Acoustics; Finite difference; Simulation; Virtual reality; Welding","Best-practices; Commercial off-the-shelf components; Finite difference; Hardware components; Immersive; Installation costs; Metal inert gas welding; MIG welding; Movement pattern; Numerical heat transfer; Real time; Simulation; Technical training; Training simulator; Welding process; Electric welding; Heat transfer; Inert gas welding; Inert gases; Numerical methods; Virtual reality",Article,"Final","",Scopus,2-s2.0-79951950718
"Arora S., Lamb B., Undre S., Kneebone R., Darzi A., Sevdalis N.","55156116900;30467833700;12779144300;7004625073;14633357600;35293409500;","Framework for incorporating simulation into urology training",2011,"BJU International","107","5",,"806","810",,35,"10.1111/j.1464-410X.2010.09563.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952254664&doi=10.1111%2fj.1464-410X.2010.09563.x&partnerID=40&md5=8137e43d9d29806bad8841a99e1aa221","Department of Surgery and Cancer, Imperial College London, London, United Kingdom; Department of Surgery and Cancer, QEQM Building, St Marys Hospital, Praed Street, London W2 1NY, United Kingdom","Arora, S., Department of Surgery and Cancer, Imperial College London, London, United Kingdom, Department of Surgery and Cancer, QEQM Building, St Marys Hospital, Praed Street, London W2 1NY, United Kingdom; Lamb, B., Department of Surgery and Cancer, Imperial College London, London, United Kingdom; Undre, S., Department of Surgery and Cancer, Imperial College London, London, United Kingdom; Kneebone, R., Department of Surgery and Cancer, Imperial College London, London, United Kingdom; Darzi, A., Department of Surgery and Cancer, Imperial College London, London, United Kingdom; Sevdalis, N., Department of Surgery and Cancer, Imperial College London, London, United Kingdom","Study Type - Therapy (case series) Level of Evidence 4 What's known on the subject? and What does the study add? Simulation-based training can provide urology trainees with the opportunity to develop their technical and non-technical skills in a safe and structured environment. Despite its promised benefits, incorporation of simulation into current curricula remains minimal. This paper provides a comprehensive review of the current status of simulation for both technical and non-technical skills training as it pertains to urology. It provides a novel framework with contextualised examples of how simulation could be incorporated into a stage-specific curriculum for trainees through to experienced urologists, thus aiding its integration into current training programmes. OBJECTIVES Changes to working hours, new technologies and increased accountability have rendered the need for alternative training environments for urologists. Simulation offers a promising arena for learning to take place in a safe, realistic setting. Despite its benefits, the incorporation of simulation into urological training programmes remains minimal. The current status and future directions of simulation for training in technical and non-technical skills are reviewed as they pertain to urology. A framework is presented for how simulation-based training could be incorporated into the entire urological curriculum. MATERIALS AND METHODS The literature on simulation in technical and non-technical skills training is reviewed, with a specific focus upon urology. RESULTS To fully integrate simulation into a training curriculum, its possibilities for addressing all the competencies required by a urologist must be realized. At an early stage of training, simulation has been used to develop basic technical skills and cognitive skills, such as decision-making and communication. At an intermediate stage, the studies focus upon more advanced technical skills learnt with virtual reality simulators. Non-technical skills training would include leadership and could be delivered with in situ models. At the final stage, experienced trainees can practise technical and non-technical skills in full crisis simulations situated within a fully-simulated operating rooms. CONCLUSIONS Simulation can provide training in the technical and non-technical skills required to be a competent urologist. The framework presented may guide how best to incorporate simulation into training curricula. Future work should determine whether acquired skills transfer to clinical practice and improve patient care. © 2010 BJU International.","clinical competence; simulation; surgery; teamwork; urology; virtual reality","article; communication skill; computer simulation; curriculum; decision making; education program; educational technology; human; leadership; medical education; medical student; priority journal; simulation; simulator; urology; virtual reality; Clinical Competence; Computer Simulation; Education, Medical; Humans; Urology",Article,"Final","",Scopus,2-s2.0-79952254664
"Ruffaldi E., Filippeschi A., Avizzano C.A., Bardy B., Gopher D., Bergamasco M.","15023001900;26666003000;6603815755;7004216646;7004504162;7003907071;","Feedback, affordances, and accelerators for training sports in virtual environments",2011,"Presence: Teleoperators and Virtual Environments","20","1",,"33","46",,29,"10.1162/pres_a_00034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955678321&doi=10.1162%2fpres_a_00034&partnerID=40&md5=5dfab471c95b5218641a712f4214b05e","PERCRO Lab, Scuola Superiore S. Anna, 56100 Pisa, Italy; M2H EuroMov, Montpellier University, France; Technion Haifa, Israel","Ruffaldi, E., PERCRO Lab, Scuola Superiore S. Anna, 56100 Pisa, Italy; Filippeschi, A., PERCRO Lab, Scuola Superiore S. Anna, 56100 Pisa, Italy; Avizzano, C.A., PERCRO Lab, Scuola Superiore S. Anna, 56100 Pisa, Italy; Bardy, B., M2H EuroMov, Montpellier University, France; Gopher, D., Technion Haifa, Israel; Bergamasco, M., PERCRO Lab, Scuola Superiore S. Anna, 56100 Pisa, Italy","The use of virtual environments (VE) for training sports is quite natural when considering strategic or cognitive aspects. Using VE for sensorimotor training is more challenging, in particular with the difficulty of transferring the task learned in the virtual world to the real. Of special concern for the successful transfer is the adequate combination of training experience protocols and the delivery modes of multimodal feedback. Analyzing feedback in terms of information exchange, this work discusses different feedback combinations and their application to virtual reality training of rowing skills. © 2011 by the Massachusetts Institute of Technology.",,"Affordances; Cognitive aspects; Delivery modes; Information exchanges; Multimodal feedback; Training experiences; Virtual environments; Virtual reality training; Virtual worlds; Virtual reality; E-learning",Article,"Final","",Scopus,2-s2.0-79955678321
"Dunston P.S., Wang X.","6602079727;8945580300;","An iterative methodology for mapping mixed reality technologies to AEC operations",2011,"Electronic Journal of Information Technology in Construction","16",,,"509","528",,10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955676092&partnerID=40&md5=1ede6b41610c1588946eff5c359ea4b4","School of Civil Engineering, Purdue University, United States; Construction Management and Property Program, Faculty of the Built Environment, University of New South Wales, Australia","Dunston, P.S., School of Civil Engineering, Purdue University, United States; Wang, X., Construction Management and Property Program, Faculty of the Built Environment, University of New South Wales, Australia","Mixed Reality (MR) technology can create an environment where objects from the digital and real worlds can be combined together in a real time manner. The practical contribution of this paper is a structured and iterative methodology developed for mapping appropriate Mixed Reality technology to a specific architecture, engineering, and construction (AEC) task. To increase the likelihood of success in technology transfer, this methodology for developing user-centered, performance enhancing MR-based systems is formulated, where AEC tasks are generically analyzed and categorized according to common functional features, which could be mapped to a collection of suitable or required MR-related technology strategies. Also, a technology selection process is identified to choose appropriate technology characteristics including information representations, interaction methods and, tracking technology for a specific task category. Such a thorough mapping methodology can be used to guide new MR-based system design as well as to help evaluate existing systems. © 2011 The authors.","AEC; Augmented Reality; Mixed Reality; Specification; Technology-task mapping","AEC; Appropriate technologies; Architecture , engineering , and constructions; Existing systems; Functional features; Information representation; Interaction methods; Iterative methodology; Mapping methodology; Mixed Reality; Mixed reality technologies; Performance enhancing; Real time; Specific tasks; System design; Technology selection; Technology strategies; Tracking technology; User-centered; Augmented reality; Mapping; Specifications; Systems analysis; Technology transfer; Virtual reality",Article,"Final","",Scopus,2-s2.0-79955676092
"Adler M.D., Vozenilek J.A., Trainor J.L., Eppich W.J., Wang E.E., Beaumont J.L., Aitchison P.R., Pribaz P.J., Erickson T., Edison M., McGaghie W.C.","8245721500;10142925700;7004141045;13907300100;9336560100;7102153197;18042001200;36626164000;7005246717;6603798571;7006333986;","Comparison of checklist and anchored global rating instruments for performance rating of simulated pediatric emergencies",2011,"Simulation in Healthcare","6","1",,"18","24",,26,"10.1097/SIH.0b013e318201aa90","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951811051&doi=10.1097%2fSIH.0b013e318201aa90&partnerID=40&md5=947f044f9e48bc00809542e787b7a165","Department of Pediatrics, Feinberg School of Medicine, Chicago, IL, United States; Department of Emergency Medicine, Feinberg School of Medicine, Chicago, IL, United States; Department of Medical Social Sciences, Feinberg School of Medicine, Chicago, IL, United States; Center for Simulation Technology and Immersive Learning, Feinberg School of Medicine, Chicago, IL, United States; Augusta Webster, MD; Office of Medical Education and Faculty Development, Northwestern University Feinberg School of Medicine, Chicago, IL, United States; Department of Emergency Medicine, University of Illinois at Chicago School of Medicine, Chicago, IL, United States; Department of Medical Education, University of Illinois at Chicago School of Medicine, Chicago, IL, United States; Department of Emergency Medicine, University of Chicago Pritzker School of Medicine, Chicago, IL, United States","Adler, M.D., Department of Pediatrics, Feinberg School of Medicine, Chicago, IL, United States; Vozenilek, J.A., Department of Emergency Medicine, Feinberg School of Medicine, Chicago, IL, United States, Center for Simulation Technology and Immersive Learning, Feinberg School of Medicine, Chicago, IL, United States; Trainor, J.L., Department of Pediatrics, Feinberg School of Medicine, Chicago, IL, United States; Eppich, W.J., Department of Pediatrics, Feinberg School of Medicine, Chicago, IL, United States; Wang, E.E., Department of Emergency Medicine, University of Chicago Pritzker School of Medicine, Chicago, IL, United States; Beaumont, J.L., Department of Medical Social Sciences, Feinberg School of Medicine, Chicago, IL, United States; Aitchison, P.R., Department of Emergency Medicine, University of Chicago Pritzker School of Medicine, Chicago, IL, United States; Pribaz, P.J., Center for Simulation Technology and Immersive Learning, Feinberg School of Medicine, Chicago, IL, United States; Erickson, T., Department of Emergency Medicine, University of Illinois at Chicago School of Medicine, Chicago, IL, United States; Edison, M., Department of Medical Education, University of Illinois at Chicago School of Medicine, Chicago, IL, United States; McGaghie, W.C., Augusta Webster, MD; Office of Medical Education and Faculty Development, Northwestern University Feinberg School of Medicine, Chicago, IL, United States","PURPOSE: To compare the psychometric performance of two rating instruments used to assess trainee performance in three clinical scenarios. METHODS: This study was part of a two-phase, randomized trial with a wait-list control condition assessing the effectiveness of a pediatric emergency medicine curriculum targeting general emergency medicine residents. Residents received 6 hours of instruction either before or after the first assessment. Separate pairs of raters completed either a dichotomous checklist for each of three cases or the Global Performance Assessment Tool (GPAT), an anchored multidimensional scale. A fully crossed person x rater x case generalizability study was conducted. The effect of training year on performance is assessed using multivariate analysis of variance. RESULTS: The person and person x case components accounted for most of the score variance for both instruments. Using either instrument, scores demonstrated a small but significant increase as training level increased when analyzed using a multivariate analysis of variance. The inter-rater reliability coefficient was >0.9 for both instruments. CONCLUSIONS: We demonstrate that our checklist and anchored global rating instrument performed in a psychometrically similar fashion with high reliability. As long as proper attention is given to instrument design and testing and rater training, checklists and anchored assessment scales can produce reproducible data for a given population of subjects. The validity of the data arising for either instrument type must be assessed rigorously and with a focus, when practicable, on patient care outcomes. © 2011 Lippincott Williams & Wilkins, Inc.","Checklists; Global assessment; Performance assessment","article; audiovisual equipment; checklist; clinical competence; clinical trial; computer simulation; controlled clinical trial; controlled study; education; emergency medicine; human; medical education; methodology; pediatrics; psychometry; randomized controlled trial; Checklist; Clinical Competence; Computer Simulation; Educational Measurement; Emergency Medicine; Humans; Internship and Residency; Manikins; Pediatrics; Psychometrics",Article,"Final","",Scopus,2-s2.0-79951811051
"Alexandrova I.V., Rall M., Breidt M., Kloos U., Tullius G., Bülthoff H.H., Mohler B.J.","36456712500;35612164200;8211384100;16166543500;8417432100;35511854700;10239373300;","Animations of medical training scenarios in immersive virtual environments",2011,"Proceedings - Workshop on Digital Media and Digital Content Management, DMDCM 2011",,, 5959667,"9","12",,3,"10.1109/DMDCM.2011.64","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051820803&doi=10.1109%2fDMDCM.2011.64&partnerID=40&md5=2352a040f7e81e09eebd80b818b4c552","Max Planck Institute for Biological Cybernetics, Germany; TuPASS, Center for Patient Safety and Simulation, University of Tübingen Medical School, Germany; Reutlingen University, Germany; Dept. of Brain and Cognitive Engineering, Korea University, South Korea","Alexandrova, I.V., Max Planck Institute for Biological Cybernetics, Germany; Rall, M., TuPASS, Center for Patient Safety and Simulation, University of Tübingen Medical School, Germany; Breidt, M., Max Planck Institute for Biological Cybernetics, Germany; Kloos, U., Reutlingen University, Germany; Tullius, G., Reutlingen University, Germany; Bülthoff, H.H., Max Planck Institute for Biological Cybernetics, Germany, Dept. of Brain and Cognitive Engineering, Korea University, South Korea; Mohler, B.J., Max Planck Institute for Biological Cybernetics, Germany","Medical training centers often provide various simulations for students and professionals. Their goal is not only to make trainees practice specific scenarios but also to help them effectively transfer the acquired skills to the real world. Having in mind that virtual environments have already been acknowledged for their potential to improve the medical training process, we propose an approach for rapid generation of animated medical scenarios, which can be used as an additional training tool that fits into the time frame of a semester training program. © 2011 IEEE.","medical simulation; motion capture; virtual humans","Digital storage; E-learning; Virtual reality; Immersive virtual environments; Medical simulations; Medical training; Motion capture; Rapid generations; Training program; Training tools; Virtual humans; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-80051820803
"Bordnick P.S., Carter B.L., Traylor A.C.","6602137534;7203070626;8914734300;","What virtual reality research in addictions can tell us about the future of obesity assessment and treatment",2011,"Journal of Diabetes Science and Technology","5","2",,"265","271",,37,"10.1177/193229681100500210","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858704402&doi=10.1177%2f193229681100500210&partnerID=40&md5=0595f5878135caa7a3066d115c855a03","Graduate College of Social Work, University of Houston, Houston, TX, United States; School of Social Work, University of Alabama, Tuscaloosa, AL, United States","Bordnick, P.S., Graduate College of Social Work, University of Houston, Houston, TX, United States; Carter, B.L., Graduate College of Social Work, University of Houston, Houston, TX, United States; Traylor, A.C., School of Social Work, University of Alabama, Tuscaloosa, AL, United States","Virtual reality (VR), a system of human-computer interaction that allows researchers and clinicians to immerse people in virtual worlds, is gaining considerable traction as a research, education, and treatment tool. Virtual reality has been used successfully to treat anxiety disorders such as fear of flying and post-traumatic stress disorder, as an aid in stroke rehabilitation, and as a behavior modification aid in the treatment of attention deficit disorder. Virtual reality has also been employed in research on addictive disorders. Given the strong evidence that drug-dependent people are highly prone to use and relapse in the presence of environmental stimuli associated with drug use, VR is an ideal platform from which to study this relationship. Research using VR has shown that drug-dependent people react with strong craving to specific cues (e.g., cigarette packs, liquor bottles) as well as environments or settings (e.g., bar, party) associated with drug use. Virtual reality has also been used to enhance learning and generalization of relapse prevention skills in smokers by reinforcing these skills in lifelike environments. Obesity researchers and treatment professionals, building on the lessons learned from VR research in substance abuse, have the opportunity to adapt these methods for investigating their own research and treatment questions. Virtual reality is ideally suited to investigate the link between food cues and environmental settings with eating behaviors and self-report of hunger. In addition, VR can be used as a treatment tool for enhancing behavior modification goals to support healthy eating habits by reinforcing these goals in life-like situations. © Diabetes Technology Society.","Addictions; Food cues; Obesity; Technology; Virtual reality","addiction; anxiety disorder; association; attention deficit disorder; behavior modification; behavior therapy; cerebrovascular accident; clinical assessment; conference paper; drug use; eating habit; fear; feeding behavior; human computer interaction; learning; liquid; medical research; obesity; patient education; posttraumatic stress disorder; rehabilitation care; reinforcement; scientist; self report; smoking; substance abuse; virtual reality; addiction; cognitive therapy; computer interface; computer simulation; equipment design; health behavior; human; methodology; obesity; recreation; review; stroke; Behavior Therapy; Cognitive Therapy; Computer Simulation; Equipment Design; Health Behavior; Humans; Obesity; Stroke; Substance-Related Disorders; User-Computer Interface; Video Games",Conference Paper,"Final","",Scopus,2-s2.0-84858704402
"Mason L.L., Jeon T.K., Blair P., Glomb N.","39061658300;39061497800;39061126100;6507903172;","Virtual tutor training: Learning to teach in a multi-user virtual environment",2011,"International Journal of Gaming and Computer-Mediated Simulations","3","1",,"51","67",,2,"10.4018/jgcms.2011010104","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79956151984&doi=10.4018%2fjgcms.2011010104&partnerID=40&md5=99ae89a3a530d7bd2b9639bf01ac1cd4","Utah State University, United States","Mason, L.L., Utah State University, United States; Jeon, T.K., Utah State University, United States; Blair, P., Utah State University, United States; Glomb, N., Utah State University, United States","In this study, the experiences and beliefs of volunteer tutors using a multi-user virtual environment to teach literacy instruction are examined to get a better understanding of the benefits and challenges of learning within this environment. Literacy tutors who were teaching adults with poor reading skills served as participants. During the study, participants delivered direct instruction reading lessons to researchers in Second Life and adult learners during live face-to-face tutoring sessions. Immediately following each session in Second Life, tutors were provided with corrective feedback on specific teaching behaviors. Data on rate of acquisition and generalization from the virtual environment to the natural environment was collected for each participant. At the conclusion of the study, tutors were asked to describe their experiences of learning to teach in a multiuser virtual environment. Results indicate that effective teaching behaviors trained in a virtual environment generalize to face-to-face instruction. However, tutors tended to disagree with the researchers 'perceptions of what constitutes effective teaching practices. Copyright © 2011, IGI Global.","Adult literacy; Distance education; Multi-user virtual environment; Second life; Simulation; Transfer of training; Virtual learning environments","Adult literacy; Multi-user virtual environment; Second life; Simulation; Transfer of training; Virtual learning environments; E-learning; Teaching; Virtual reality",Article,"Final","",Scopus,2-s2.0-79956151984
"Hall V., Conboy-Hill S., Taylor D.","7007164275;6507306360;55851945195;","Using virtual reality to provide health care information to people with intellectual disabilities: Acceptability, usability, and potential utility",2011,"Journal of Medical Internet Research","13","4", e91,"","",,34,"10.2196/jmir.1917","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81855173629&doi=10.2196%2fjmir.1917&partnerID=40&md5=8dd3d695f6429265d3b2e36017a61a81","Centre for Health Research, University of Brighton, 265 Mayfield House, Falmer Brighton, BN1 9PH, United Kingdom; Research and Development, Sussex Partnership NHS Foundation Trust, Hove, United Kingdom; Division of Surgery, Imperial College, London, United Kingdom","Hall, V., Centre for Health Research, University of Brighton, 265 Mayfield House, Falmer Brighton, BN1 9PH, United Kingdom; Conboy-Hill, S., Research and Development, Sussex Partnership NHS Foundation Trust, Hove, United Kingdom; Taylor, D., Division of Surgery, Imperial College, London, United Kingdom","Background: People with intellectual disabilities have poor access to health care, which may be further compromised by a lack of accessible health information. To be effective, health information must be easily understood and remembered. People with intellectual disabilities learn better from multimodal information sources, and virtual reality offers a 3-dimensional (3D) computer-generated environment that can be used for providing information and learning. To date, research into virtual reality experiences for people with intellectual disabilities has been limited to skill-based training and leisure opportunities within the young to mid age ranges. Objective: This study assessed the acceptability, usability, and potential utility of a virtual reality experience as a means of providing health care-related information to people with intellectual disabilities. We designed a prototype multimodal experience based on a hospital scenario and situated on an island in the Second Life 3D virtual world. We wanted to know how people of different ages and with varying levels of cognitive function would participate in the customized virtual environment, what they understood from being there, and what they remembered a week later. Methods: The study drew on qualitative data. We used a participatory research approach that involved working alongside people with intellectual disabilities and their supporters in a community setting. Cognitive function was assessed, using the Matrix Analogies Test and the British Picture Vocabulary Scale, to describe the sample. Participants, supported by facilitators, were video recorded accessing and engaging with the virtual environment. We assessed recall 1 week later, using a specialized interview technique. Data were downloaded into NVivo 8 and analyzed using the framework analysis technique. Results: Study participants were 20 people aged between 20 and 80 years with mild to severe intellectual disabilities. All participants were able to access the environment and voluntarily stayed there for between 23 and 57 minutes. With facilitator support, all participants moved the avatar themselves. Participants engaged with the scenario as if they were actually there, indicating cognitive presence. Some referred back to previous medical experiences, indicating the potential for experiential knowledge to become the foundation of new learning and retention of knowledge. When interviewed, all participants remembered some aspects of the environment. Conclusions: A sample of adults with intellectual disabilities of all ages, and with varying levels of cognitive function, accessed and enjoyed a virtual-world environment that drew on a health care-related scenario, and remembered aspects of it a week later. The small sample size limits generalizability of findings, but the potential shown for experiential learning to aid retention of knowledge on which consent is based appears promising. Successfully delivering health care-related information in a non-National Health Service setting indicates potential for delivery in institutional, community, or home settings, thereby widening access to the information. © Valerie Hall, Suzanne Conboy-Hill, Dave Taylor.","Capacity to consent; Health information; Intellectual disabilities; Learning disabilities; Participatory research; Presence; Virtual reality","achievement; adult; aged; article; computer interface; computer simulation; female; health care delivery; human; intellectual impairment; Internet; knowledge; learning; male; middle aged; patient attitude; psychological aspect; United Kingdom; validation study; Achievement; Adult; Aged; Aged, 80 and over; Computer Simulation; Delivery of Health Care; Female; Great Britain; Humans; Intellectual Disability; Internet; Knowledge; Learning; Male; Middle Aged; Patient Acceptance of Health Care; User-Computer Interface; Young Adult",Article,"Final","",Scopus,2-s2.0-81855173629
"Ranilla J.C., González V.E., Molías L.M., Cervera M.G., Barranco I.A., Barahona B.E.V., Erazo G.N.S.","44460949500;56486058200;35272725800;36843936800;56289829200;56290393200;56289490800;","SIMUL@: 3D spaces to learn generic skills. A pilot study with education students",2011,"Proceedings of the International Conference on e-Learning, ICEL",,,,"324","334",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904721036&partnerID=40&md5=bf19eb4fbfe5f2eca80afed97d76c6d4","Universitat Rovira i Virgili, Tarragona, Spain; Escuela Politécnica de Chimborazo, Riobamba, Ecuador","Ranilla, J.C., Universitat Rovira i Virgili, Tarragona, Spain; González, V.E., Universitat Rovira i Virgili, Tarragona, Spain; Molías, L.M., Universitat Rovira i Virgili, Tarragona, Spain; Cervera, M.G., Universitat Rovira i Virgili, Tarragona, Spain; Barranco, I.A., Universitat Rovira i Virgili, Tarragona, Spain; Barahona, B.E.V., Escuela Politécnica de Chimborazo, Riobamba, Ecuador; Erazo, G.N.S., Escuela Politécnica de Chimborazo, Riobamba, Ecuador","The content of this document is explaining the organization of a didactic proposal that takes place in a virtual world to improve the generic skills of Team-working and Self-management. The virtual world is a simulation of certain space; it is a three-dimensional representation of real environments where interactions between users can be done. This didactic proposal consists of the Pilot project that is implemented in the development of a research project named Simul@ (Ref. EDU2008-01479). The project details are explained further on. The design of technological environments that simulate professional roles and work situations is possible today, however it is convenient to prove the efficiency of these systems, taking into account not only the end result of learning, but also time and effort required the students to complete the skills training. The technology promotes designing learning environment to simulate workplace activity; this is the setting where the generic skills can be developed in terms of transfer and integrative learning. The technology allows the recreation of work situations where cross-curricular competencies can be activated. For the development of this test has chosen to use SL. SL allows interaction of simulations and games, social networking where you create and share knowledge, collaborative work environments, use different media to meet different learning needs. Through SLOODLE, which is a module of learning activities represented as objects of SL, we can integrate SL to Moodle. The student performs the activities in SL and the teacher has Moodle registration in a transparent manner. In order to test the use of 3D tools for working with student teachers acquire the skills of self-management and teamwork has designed a pilot with 12 students. For this pilot, the teacher has designed an activity to be conducted in Second Life (SL) and is organizing an ""Olympiad School"". These students are distributed to work in groups of three and must compete for the best organization of the event. In order to develop this paper, we have organized the contents up through the following structure: first we make a brief theoretical overview about key concepts as 3D learning environments and generic skills, secondly we explain the context where the experience takes place and third section contains the description of the specific experience organization.","Generic skills; Second Life; Skills assessment; Teamwork and self-management skills","Computer aided instruction; E-learning; Engineering education; Human resource management; Interactive computer graphics; Virtual reality; 3D learning environment; Generic skills; Integrative learning; Learning environments; Second Life; Self management; Skills assessment; Technological environment; Students",Conference Paper,"Final","",Scopus,2-s2.0-84904721036
"Pantano E.","24481493600;","Virtual cultural heritage consumption: A 3D learning experience",2011,"International Journal of Technology Enhanced Learning","3","5",,"482","495",,12,"10.1504/IJTEL.2011.042100","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869856359&doi=10.1504%2fIJTEL.2011.042100&partnerID=40&md5=11c7d2ad1167008ecb4dc081b5492be6","Department of Linguistics, University of Calabria, via P. Bucci, Cubo 17 b, 87036 Arcavacata di Rende, Italy","Pantano, E., Department of Linguistics, University of Calabria, via P. Bucci, Cubo 17 b, 87036 Arcavacata di Rende, Italy","Current advances in technology are developing new tools capable of supporting and facilitating the diffusion of knowledge for a wide range of final user. Web-based technologies offer new powerful tools for accessing knowledge and educational contents related to the field of cultural heritage in an easy and interactive way. As a consequence, there is an increasing effort in digitising museum collections and exhibitions, as well as in diffusing digital educational content throughout the web. In this way, a new vision of cultural heritage accessed via computer is emerging: virtual cultural heritage. The aim of this paper is to investigate the consumption process of virtual cultural heritage, by examining the main characteristics of its consumers and how they make use of digital educational content, in order to more deeply understand the link between consumption experience and virtual cultural heritage. Copyright © 2011 Inderscience Enterprises Ltd.","Consumer behaviour; Edutainment; Knowledge transfer; Learning; Virtual cultural heritage; Virtual reality",,Article,"Final","",Scopus,2-s2.0-84869856359
"Hulin T., Schmirgel V., Yechiam E., Zimmermann U.E., Preusche C., Pöhler G.","23008567500;57199627082;55892873800;7201909731;6602947104;57220760440;","Evaluating exemplary training accelerators for programming-by-demonstration",2010,"Proceedings - IEEE International Workshop on Robot and Human Interactive Communication",,, 5598611,"440","445",,8,"10.1109/ROMAN.2010.5598611","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649872096&doi=10.1109%2fROMAN.2010.5598611&partnerID=40&md5=855a0146c91be5af1131171d337aab81","KUKA Roboter GmbH, Germany; Faculty of Industrial Engineering and Management, Technion, Israel; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Otto-von-Guericke University, Magdeburg, Germany","Hulin, T., Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Schmirgel, V., KUKA Roboter GmbH, Germany; Yechiam, E., Faculty of Industrial Engineering and Management, Technion, Israel; Zimmermann, U.E., KUKA Roboter GmbH, Germany; Preusche, C., Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Pöhler, G., Otto-von-Guericke University, Magdeburg, Germany","Robot Programming by Demonstration requires comprehending the usage of a robotic system. This article is about accelerating the training of these skills, using the example of a DLR/KUKA light-weight robot. An augmented reality and a virtual reality setup are presented that aim to demonstrate and evaluate skills transfer of two different sub-tasks of this system: Avoiding robot singularities and setting correct compliance parameters. For this purpose training accelerators are introduced for visualising robot singularities, exploring robot singularities and feeling compliance parameters. An evaluation procedure for all three accelerators is suggested and has been performed on the first two. As interesting evaluation result a contrast to the Cognitive Theory of Multimedia Learning hypothesis could be observed: Additional visual information on the robot singularities impairs the participants' performance. © 2010 IEEE.",,"Cognitive theory of multimedia learning; Evaluation results; Light weight; Robot programming by demonstration; Robotic systems; Subtasks; Visual information; Augmented reality; Human computer interaction; Programmable robots; Virtual reality; Visual communication; Robot programming",Conference Paper,"Final","",Scopus,2-s2.0-78649872096
"Wilson A.D., Benko H.","57199229209;9737287100;","Combining multiple depth cameras and projectors for interactions on, above, and between surfaces",2010,"UIST 2010 - 23rd ACM Symposium on User Interface Software and Technology",,,,"273","282",,231,"10.1145/1866029.1866073","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649585148&doi=10.1145%2f1866029.1866073&partnerID=40&md5=5bceaf938460583857db498370f28297","Microsoft Research, One Microsoft Way, Redmond, WA, United States","Wilson, A.D., Microsoft Research, One Microsoft Way, Redmond, WA, United States; Benko, H., Microsoft Research, One Microsoft Way, Redmond, WA, United States","Instrumented with multiple depth cameras and projectors, LightSpace is a small room installation designed to explore a variety of interactions and computational strategies related to interactive displays and the space that they inhabit. LightSpace cameras and projectors are calibrated to 3D real world coordinates, allowing for projection of graphics correctly onto any surface visible by both camera and projector. Selective projection of the depth camera data enables emulation of interactive displays on un-instrumented surfaces (such as a standard table or office desk), as well as facilitates mid-air interactions between and around these displays. For example, after performing multi-touch interactions on a virtual object on the tabletop, the user may transfer the object to another display by simultaneously touching the object and the destination display. Or the user may ""pick up"" the object by sweeping it into their hand, see it sitting in their hand as they walk over to an interactive wall display, and ""drop"" the object onto the wall by touching it with their other hand. We detail the interactions and algorithms unique to LightSpace, discuss some initial observations of use and suggest future directions.","Augmented reality; Depth cameras; Interactive spaces; Surface computing; Ubiquitous computing","Computational strategy; Depth camera; Future directions; Interactive display; Interactive spaces; Multi-touch; Small rooms; Surface computing; Virtual objects; World coordinates; Augmented reality; Cameras; User interfaces; Virtual reality; Ubiquitous computing",Conference Paper,"Final","",Scopus,2-s2.0-78649585148
"Mania K., Badariah S., Coxon M., Watten P.","6602471750;10240878700;12790137700;6506615337;","Cognitive transfer of spatial awareness states from immersive virtual environments to reality",2010,"ACM Transactions on Applied Perception","7","2",,"","",,27,"10.1145/1670671.1670673","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872409581&doi=10.1145%2f1670671.1670673&partnerID=40&md5=98491225a5534b5c6b72286852e4c6e7","Department of Electronic and Computer Engineering, Technical University of Crete, Kounoupidiana, 73100, Chania, Crete, Greece; University of Sussex UK, Brighton, BN1 9QJ, United Kingdom; York St John University, Lord Mayor's Walk, York, YO31 7EX, United Kingdom","Mania, K., Department of Electronic and Computer Engineering, Technical University of Crete, Kounoupidiana, 73100, Chania, Crete, Greece, University of Sussex UK, Brighton, BN1 9QJ, United Kingdom; Badariah, S., University of Sussex UK, Brighton, BN1 9QJ, United Kingdom; Coxon, M., York St John University, Lord Mayor's Walk, York, YO31 7EX, United Kingdom; Watten, P., University of Sussex UK, Brighton, BN1 9QJ, United Kingdom","An individual's prior experience will influence how new visual information in a scene is perceived and remembered. Accuracy of memory performance per se is an imperfect reflection of the cognitive activity (awareness states) that underlies performance in memory tasks. The aim of this research is to investigate the effect of varied visual fidelity of training environments on the transfer of training to the real world after exposure to immersive simulations representing a real-world scene. A between groups experiment was carried out to explore the effect of rendering quality on measurements of location-based recognition memory for objects and associated states of awareness. The immersive simulation consisted of one room that was either rendered flat-shaded or using radiosity rendering. The simulation was displayed on a stereo head-tracked head mounted display. Post exposure to the synthetic simulation, participants completed a memory recognition task conducted in a real-world scene by physically arranging objects in their physical form in a real-world room. Participants also reported one of four states of awareness following object recognition. They were given several options of awareness states that reflected the level of visual mental imagery involved during retrieval, the familiarity of the recollection and related guesses. The scene incorporated objects that ""fitted"" into the specific context of the real-world scene, referred to as consistent objects, and objects that were not related to the specific context of the real-world scene, referred to as inconsistent objects. A follow-up studywas conducted a week after the initial test. Interestingly, results revealed a higher proportion of correct object recognition associated with mental imagery when participants were exposed to low-fidelity flat-shaded training scenes rather than the radiosity rendered ones. Memory psychology indicates that awareness states based on visual imagery require stronger attentional processing in the first instance than those based on familiarity. A tentative claim would, therefore, be that those immersive environments that are distinctive because of their variation from ""real,"" such as flat-shaded environments, recruit stronger attentional resources. This additional attentional processing may bring about a change in participants' subjective experiences of ""remembering"" when they later transfer the training from that environment into a real-world situation. © 2010 ACM.","Human-computer interaction; Perceptual graphics","Cognitive activities; Head mounted displays; Immersive environment; Immersive virtual environments; Perceptual graphics; Real world situations; Subjective experiences; Transfer of trainings; Human computer interaction; Sensory perception; Virtual reality; Object recognition",Article,"Final","",Scopus,2-s2.0-84872409581
"Loureiro A.","36662433400;","Building knowledge in virtual environments - Influence of interpersonal relationships: The outlined research",2010,"CEUR Workshop Proceedings","709",,,"43","48",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890136077&partnerID=40&md5=81a0df24f25b4bfd50317d20a1db1fbc","CIDTFF, UIPS - ESE - Polytechnics Institute of Santarém, University of Aveiro, Portugal","Loureiro, A., CIDTFF, UIPS - ESE - Polytechnics Institute of Santarém, University of Aveiro, Portugal","This article presents a PhD research project that will determine how to enhance learning, at the university level, based on implemented experiences in immersive collaborative virtual environments. Today's students belong to a networked and multitasking generation, and today's teaching strategy does not, in many situations, embrace their needs and perspectives. They need to gather competences in order to become motivated, communicative, knowledge builders. It is our belief that educators can take advantage of virtual environments to develop those competences and transfer them to real-world learning contexts.","Collaborative virtual environments; Connectivism; Interpersonal relationships; Knowledge building; Second life; Technology enhanced learning","Collaborative virtual environment; Connectivism; Interpersonal relationship; Knowledge building; Second Life; Technology enhanced learning; Virtual reality; Research",Conference Paper,"Final","",Scopus,2-s2.0-84890136077
"Cohen M.","55333984600;","Under-explored dimensions in spatial sound",2010,"Proceedings - VRCAI 2010, ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Application to Industry",,,,"95","102",,4,"10.1145/1900179.1900199","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951840057&doi=10.1145%2f1900179.1900199&partnerID=40&md5=cd78381eaf29eb4e9d60c17c7d4f5728","University of Aizu, Japan","Cohen, M., University of Aizu, Japan","An introduction to spatial sound in the context of hypermedia, interactive multimedia, and virtual reality is presented. Basic principals of relevant physics and psychophysics are reviewed (ITDs: interaural time differences, IIDs: interaural intensity differences, and frequency-dependent attenuation capturable by transfer functions). Modeling of sources and sinks (listeners) elaborates such models to include such as intensity, radiation, distance attenuation & filtering, and reflections & reverberation. Display systems - headphones and headsets, loudspeakers, nearphones, stereo, home theater and other surround systems, discrete speaker systems, speaker arrays, WFS (wave field synthesis), and spatially immersive displays - are described. Distributed applications are surveyed, including stereotelephony, chat-spaces, and massively multiplayer online role-playing games (MMORPGs), with references to immersive virtual environments. Copyright © 2010 by the Association for Computing Machinery, Inc.","Ambient media; Awareware; Impulse response; Narrowcasting; Pervasive computing; Transfer function; Ubicomp (ubiquitous computing); Virtual auditory display; Wearware; Whereware","Ambient media; Auditory display; Awareware; Narrowcasting; Pervasive computing; Ubicomp; Wearware; Whereware; Display devices; Human computer interaction; Impulse response; Interactive computer graphics; Interactive computer systems; Loudspeakers; Multimedia systems; Social networking (online); Speech processing; Transfer functions; Virtual reality; Ubiquitous computing",Conference Paper,"Final","",Scopus,2-s2.0-79951840057
"Xie L., Zhao W., Zhou X., Tian X., Li B., Sun N., Zhao Y., Zhang Y.","35294300000;36916181200;36916266000;36783718900;55755594800;36915828300;36916183400;56075029000;","Speech and auditory interfaces for ubiquitous, immersive and personalized applications",2010,"Proceedings - Symposia and Workshops on Ubiquitous, Autonomic and Trusted Computing in Conjunction with the UIC 2010 and ATC 2010 Conferences, UIC-ATC 2010",,, 5667124,"503","505",,,"10.1109/UIC-ATC.2010.59","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651450538&doi=10.1109%2fUIC-ATC.2010.59&partnerID=40&md5=35b5ae7dfdeebfb407256529fa35411a","Shaanxi Provincial Key Laboratory of Speech and Image Information Processing, School of Computer Science, Northwestern Polytechnical University, Xi'an, China","Xie, L., Shaanxi Provincial Key Laboratory of Speech and Image Information Processing, School of Computer Science, Northwestern Polytechnical University, Xi'an, China; Zhao, W., Shaanxi Provincial Key Laboratory of Speech and Image Information Processing, School of Computer Science, Northwestern Polytechnical University, Xi'an, China; Zhou, X., Shaanxi Provincial Key Laboratory of Speech and Image Information Processing, School of Computer Science, Northwestern Polytechnical University, Xi'an, China; Tian, X., Shaanxi Provincial Key Laboratory of Speech and Image Information Processing, School of Computer Science, Northwestern Polytechnical University, Xi'an, China; Li, B., Shaanxi Provincial Key Laboratory of Speech and Image Information Processing, School of Computer Science, Northwestern Polytechnical University, Xi'an, China; Sun, N., Shaanxi Provincial Key Laboratory of Speech and Image Information Processing, School of Computer Science, Northwestern Polytechnical University, Xi'an, China; Zhao, Y., Shaanxi Provincial Key Laboratory of Speech and Image Information Processing, School of Computer Science, Northwestern Polytechnical University, Xi'an, China; Zhang, Y., Shaanxi Provincial Key Laboratory of Speech and Image Information Processing, School of Computer Science, Northwestern Polytechnical University, Xi'an, China","In this demonstration, we introduce our recent progress on speech and auditory technologies for potential ubiquitous, immersive and personalized applications. The first demo shows an intelligent spoken question answering system, which enables users to interact with a talking avatar via natural speech dialogues. The prototype system demonstrates our latest development on automatic speech recognition, keyword spotting, personalized text-to-speech synthesis and visual speech synthesis. The second demo exhibits a virtual concert with immersive audio effects. Through our virtual auditory technology, wearing simple earphones, listeners are able to experience immersive concert audio effects from an ordinary music file. We believe the technologies shown in the two demos can be easily deployed in many significant applications. © 2010 IEEE.","Head related transfer functions; Human-computer interaction; Keyword spotting; Question answering; Speech recognition; Speech synthesis; Spoken dialogue system; Talking face; Virtual auditory; Visual speech synthesis","Head related transfer function; Keyword spotting; Question Answering; Spoken dialogue system; Talking face; Virtual auditory; Visual speech synthesis; Audio acoustics; Character recognition; Face recognition; Human computer interaction; Knowledge management; Speech processing; Speech synthesis; Transfer functions; Ubiquitous computing; Virtual reality; Speech recognition",Conference Paper,"Final","",Scopus,2-s2.0-78651450538
"Anderson E.F., McLoughlin L., Liarokapis F., Peters C., Petridis P., de Freitas S.","34976300400;26656832500;7801416785;26425154400;36128917500;57203045925;","Developing serious games for cultural heritage: A state-of-the-art Review",2010,"Virtual Reality","14","4",,"255","275",,173,"10.1007/s10055-010-0177-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649514858&doi=10.1007%2fs10055-010-0177-3&partnerID=40&md5=74e34a16c358fff2a58b9ec302a3ab56","Interactive Worlds Applied Research Group (iWARG), Coventry University, Coventry, United Kingdom; The National Centre for Computer Animation (NCCA), Bournemouth University, Bournemouth, United Kingdom; Serious Games Institute (SGI), Coventry University, Coventry, United Kingdom","Anderson, E.F., Interactive Worlds Applied Research Group (iWARG), Coventry University, Coventry, United Kingdom; McLoughlin, L., The National Centre for Computer Animation (NCCA), Bournemouth University, Bournemouth, United Kingdom; Liarokapis, F., Interactive Worlds Applied Research Group (iWARG), Coventry University, Coventry, United Kingdom; Peters, C., Interactive Worlds Applied Research Group (iWARG), Coventry University, Coventry, United Kingdom; Petridis, P., Serious Games Institute (SGI), Coventry University, Coventry, United Kingdom; de Freitas, S., Serious Games Institute (SGI), Coventry University, Coventry, United Kingdom","Although the widespread use of gaming for leisure purposes has been well documented, the use of games to support cultural heritage purposes, such as historical teaching and learning, or for enhancing museum visits, has been less well considered. The state-of-the-art in serious game technology is identical to that of the state-of-the-art in entertainment games technology. As a result, the field of serious heritage games concerns itself with recent advances in computer games, real-time computer graphics, virtual and augmented reality and artificial intelligence. On the other hand, the main strengths of serious gaming applications may be generalised as being in the areas of communication, visual expression of information, collaboration mechanisms, interactivity and entertainment. In this report, we will focus on the state-of-the-art with respect to the theories, methods and technologies used in serious heritage games. We provide an overview of existing literature of relevance to the domain, discuss the strengths and weaknesses of the described methods and point out unsolved problems and challenges. In addition, several case studies illustrating the application of methods and technologies used in cultural heritage are presented. © 2010 Springer-Verlag London Limited.","Computer games technology; Cultural heritage; Serious games","Collaboration mechanisms; Computer game; Computer games technology; Cultural heritage; Cultural heritages; Interactivity; Real time computer graphics; Serious games; Serious gaming; State-of-the-art reviews; Teaching and learning; Unsolved problems; Virtual and augmented reality; Artificial intelligence; Augmented reality; Computer software; Human computer interaction; Virtual reality; Technology",Article,"Final","",Scopus,2-s2.0-78649514858
"Chen B., Huang F., Lin H., Hu M.","57198480645;13612507800;36071585400;24070765600;","VCUHK: Integrating the real into a 3D campus in networked virtual worlds",2010,"Proceedings - 2010 International Conference on Cyberworlds, CW 2010",,, 5655003,"302","308",,5,"10.1109/CW.2010.25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78751557871&doi=10.1109%2fCW.2010.25&partnerID=40&md5=b175443a4a1daa9e9624e7f2f72ceef7","Institute of Remote Sensing and Geographic Information System, Peking University, Beijing, China; Institute of Space and Earth Information Science, Chinese University of Hong Kong, Shatin, N.T., Hong Kong","Chen, B., Institute of Remote Sensing and Geographic Information System, Peking University, Beijing, China; Huang, F., Institute of Remote Sensing and Geographic Information System, Peking University, Beijing, China; Lin, H., Institute of Space and Earth Information Science, Chinese University of Hong Kong, Shatin, N.T., Hong Kong; Hu, M., Institute of Space and Earth Information Science, Chinese University of Hong Kong, Shatin, N.T., Hong Kong","The rapid development of World Wide Web and the dominance of networked computers for information transfer and communication have enabled the rise of virtual worlds (e.g. Second Life™). This paper introduces our virtual campus-Virtual CUHK (VCUHK) project which builds a 3D virtual campus of the Chinese University of Hong Kong (CUHK) in networked virtual worlds. VCUHK is a 3D shared networked virtual world of the real campus of CUHK built with OpenSimulator platform, an open source virtual world server project that has an adaptation of the basic server functionality of the Second Life™ servers. The real CUHK campus occupies approximately the area of 2 square km with hilly terrain and diverse and unique landscape, and has a great number of buildings with very sophisticated architecture. By using Second Life™ viewer (an open source 3D virtual world viewer) or other compatible viewers, users can access VCUHK from any Internet-connected personal computer running MS windows or Linux. Users can immerse in VCUHK being anything with the form of 3D modeling avatar and experience virtual education and other diverse campus activities. © 2010 IEEE.","3D modeling; OpenSimulator; Virtual campus; Virtual world","3-d modeling; 3d virtual worlds; Chinese universities; Hong-kong; Information transfers; Networked computers; Open sources; OpenSimulator; Rapid development; Second Life; Virtual campus; Virtual education; Virtual worlds; Computer operating systems; Interactive computer graphics; Personal computers; Servers; Social networking (online); Three dimensional computer graphics; Virtual reality; World Wide Web; Three dimensional",Conference Paper,"Final","",Scopus,2-s2.0-78751557871
"Müller S.M.T., Celeste W.C., Bastos-Filho T.F., Sarcinelli-Filho M.","24169516700;23049374700;6602380721;6602453322;","Brain-computer interface based on visual evoked potentials to command autonomous robotic wheelchair",2010,"Journal of Medical and Biological Engineering","30","6",,"407","416",,52,"10.5405/jmbe.765","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78751511193&doi=10.5405%2fjmbe.765&partnerID=40&md5=c859f70752714acd13416302f8b588c0","Computer Engineering Department, Northern Center, Federal University of Espírito Santo (UFES), Rodovia BR 101 Norte, Km. 60, Bairro Litorâneo, São Mateus-ES CEP 29932-540, Brazil; Electrical Engineering Department, Federal University of Espírito Santo (UFES), Av. Fernando Ferrari, 514, Goiabeiras, Vitória-ES CEP 29075-910, Brazil","Müller, S.M.T., Computer Engineering Department, Northern Center, Federal University of Espírito Santo (UFES), Rodovia BR 101 Norte, Km. 60, Bairro Litorâneo, São Mateus-ES CEP 29932-540, Brazil; Celeste, W.C., Computer Engineering Department, Northern Center, Federal University of Espírito Santo (UFES), Rodovia BR 101 Norte, Km. 60, Bairro Litorâneo, São Mateus-ES CEP 29932-540, Brazil; Bastos-Filho, T.F., Electrical Engineering Department, Federal University of Espírito Santo (UFES), Av. Fernando Ferrari, 514, Goiabeiras, Vitória-ES CEP 29075-910, Brazil; Sarcinelli-Filho, M., Electrical Engineering Department, Federal University of Espírito Santo (UFES), Av. Fernando Ferrari, 514, Goiabeiras, Vitória-ES CEP 29075-910, Brazil","This paper proposes the integration of two systems: a brain-computer interface (BCI) based on steady-state visual evoked potentials (SSVEPs) and an autonomous robotic wheelchair, with the former being used to command the latter. The signals used in this work come from individuals who are visually stimulated. The stimuli are black-and-white checkerboards, like stripes, flickering at different frequencies. Four experiments were performed for the BCI development. For all experiments, the volunteers were asked to watch a stimulation screen with a central stripe or to watch a stimulation screen with four stripes presented simultaneously, one at each side, one at the top and one at the bottom. The EEG signal analysis consists of two steps: feature extraction, performed using a statistic test, and classification, performed by a rule-based classifier. This kind of classifier obtains good results in a short time and does not demand any training. The result is a system with high classification rate (up to 96%), high information transfer rate (ITR) (up to 101.66 bits/min), and processing time of about 120 ms for each incremental analysis. Each frequency value can be associated to a user command or a user feeling. The user, who is seated on the wheelchair, can thus choose a specific place to move to. Upon such choice, the control system onboard the wheelchair generates reference paths with low risk of collision, connecting the current position to the chosen one. Therefore, a system to allow people with severe motor disfunction to have the quality of their lives improved is the proposal of the work.","Brain-computer interface (BCI); Robotic wheelchair; Steady-state visual evoked potential (SSVEP)","Autonomous robotics; Classification rates; Different frequency; Incremental analysis; Information transfer rate; Processing Time; Reference path; Robotic wheelchair; Rule-based classifier; Steady-state visual evoked potentials; User commands; Visual evoked potential; Bioelectric potentials; Classifiers; Electrophysiology; Experiments; Feature extraction; Interfaces (computer); Robotics; Robots; Wheelchairs; Brain computer interface; adult; article; autonomous robotic wheelchair; brain computer interface; control system; electroencephalography; evoked visual response; female; human; male; powered wheelchair; quality of life; robotics; steady state; stimulus response; visual stimulation",Article,"Final","",Scopus,2-s2.0-78751511193
"Keefe D.F., Sotiropoulos F., Interrante V., Runesha H.B., Coffey D., Staker M., Lin C., Sun Y., Borazjani I., Le T., Rowe N., Erdman A.","7101683249;7003581647;6701782618;6603177432;35730766900;36613804300;36613465500;55737845700;23003805400;36613342100;36613677000;7007082404;","A process for design, verification, validation, and manufacture of medical devices using immersive VR environments",2010,"Journal of Medical Devices, Transactions of the ASME","4","4", 045002,"","",,12,"10.1115/1.4002561","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78049521962&doi=10.1115%2f1.4002561&partnerID=40&md5=a5eef285041d016c39db37dea6c81f73","Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN 55455, United States; Saint Anthony Falls Laboratory, University of Minnesota, Minneapolis, MN 55414, United States; Minnesota Supercomputing Institute, University of Minnesota, Minneapolis, MN 55455, United States; Medical Devices Center and Department of Mechanical Engineering, University of Minnesota, Minneapolis, MN 55455, United States","Keefe, D.F., Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN 55455, United States; Sotiropoulos, F., Saint Anthony Falls Laboratory, University of Minnesota, Minneapolis, MN 55414, United States; Interrante, V., Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN 55455, United States; Runesha, H.B., Minnesota Supercomputing Institute, University of Minnesota, Minneapolis, MN 55455, United States; Coffey, D., Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN 55455, United States; Staker, M., Medical Devices Center and Department of Mechanical Engineering, University of Minnesota, Minneapolis, MN 55455, United States; Lin, C., Medical Devices Center and Department of Mechanical Engineering, University of Minnesota, Minneapolis, MN 55455, United States; Sun, Y., Medical Devices Center and Department of Mechanical Engineering, University of Minnesota, Minneapolis, MN 55455, United States; Borazjani, I., Saint Anthony Falls Laboratory, University of Minnesota, Minneapolis, MN 55414, United States; Le, T., Saint Anthony Falls Laboratory, University of Minnesota, Minneapolis, MN 55414, United States; Rowe, N., Minnesota Supercomputing Institute, University of Minnesota, Minneapolis, MN 55455, United States; Erdman, A., Medical Devices Center and Department of Mechanical Engineering, University of Minnesota, Minneapolis, MN 55455, United States","This paper presents a framework and detailed vision for using immersive virtual reality (VR) environments to improve the design, verification, validation, and manufacture of medical devices. Major advances in medical device design and manufacture currently require extensive and expensive product cycles that include animal and clinical trials. The current design process limits opportunities to thoroughly understand and refine current designs and to explore new high-risk, high-payoff designs. For the past 4 years, our interdisciplinary research group has been working toward developing strategies to dramatically increase the role of simulation in medical device engineering, including linking simulations with visualization and interactive design. Although this vision aligns nicely with the stated goals of the FDA and the increasingly important role that simulation plays in engineering, manufacturing, and science today, the interdisciplinary expertise needed to realize a simulation-based visual design environment for real-world medical device design problems makes implementing (and even generating a system-level design for) such a system extremely challenging. In this paper, we present our vision for a new process of simulation-based medical device engineering and the impact it can have within the field. We also present our experiences developing the initial components of a framework to realize this vision and applying them to improve the design of replacement mechanical heart valves. Relative to commercial software packages and other systems used in engineering research, the vision and framework described are unique in the combined emphasis on 3D user interfaces, ensemble visualization, and incorporating state-of-the-art custom computational fluid dynamics codes. We believe that this holistic conception of simulation-based engineering, including abilities to not just simulate with unprecedented accuracy but also to visualize and interact with simulation results, is critical to making simulation-based engineering practical as a tool for major innovation in medical devices. Beyond the medical device arena, the framework and strategies described may well generalize to simulation-based engineering processes in other domains that also involve simulating, visualizing, and interacting with data that describe spatially complex time-varying phenomena. © 2010 American Society of Mechanical Engineers.","Fluid dynamics; Heart valve; Human-computer interaction; Mechanical engineering; Medical devices; Simulation; Simulation-based engineering; Visualization","3D user interface; Clinical trial; Commercial software; Computational Fluid Dynamics codes; Design process; Developing strategy; Engineering process; Expensive products; Heart valve; Immersive virtual reality; Immersive VR; Interactive design; Interdisciplinary research; Mechanical heart valves; Medical device design; Medical Devices; New high; New process; Real-world; Simulation; Simulation result; Simulation-based; System level design; Time varying; Visual design; Biomedical engineering; Computational fluid dynamics; Design; Economic analysis; Fluid dynamics; Fluids; Human computer interaction; Innovation; Knowledge management; Manufacture; Mechanical engineering; Medical problems; User interfaces; Valves (mechanical); Virtual reality; Visualization; Industrial applications; article; biomedical engineering; clinical research; computational fluid dynamics; computer aided design; computer assisted tomography; computer program; drug delivery system; food and drug administration; heart valve prosthesis; heart valve regurgitation; heart valve replacement; human; human computer interaction; immersion; medical instrumentation; nonhuman; nuclear magnetic resonance imaging; process design; risk assessment; simulation; validation process; virtual reality",Article,"Final","",Scopus,2-s2.0-78049521962
"Slater M., Spanlang B., Sanchez-Vives M.V., Blanke O.","7202932472;25723936000;35605402100;7004111524;","First person experience of body transfer in virtual reality",2010,"PLoS ONE","5","5", e10564,"","",,457,"10.1371/journal.pone.0010564","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956543868&doi=10.1371%2fjournal.pone.0010564&partnerID=40&md5=0fe6c0aa7c63eedb80abb8d20c266483","Institució Catalana Recerca i Estudis Avançats (ICREA), Universitat de Barcelona, Barcelona, Spain; Facultat de Psicologia, Universitat de Barcelona, Barcelona, Spain; Department of Computer Science, University College London, London, United Kingdom; Departament de LSI, Universitat Politècnica de Catalunya, Barcelona, Spain; Institut d'Investigacions Biomèdiques August Pii Sunyer (IDIBAPS), Barcelona, Spain; Brain-Mind Institute, Ecole Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland","Slater, M., Institució Catalana Recerca i Estudis Avançats (ICREA), Universitat de Barcelona, Barcelona, Spain, Facultat de Psicologia, Universitat de Barcelona, Barcelona, Spain, Department of Computer Science, University College London, London, United Kingdom; Spanlang, B., Facultat de Psicologia, Universitat de Barcelona, Barcelona, Spain, Departament de LSI, Universitat Politècnica de Catalunya, Barcelona, Spain; Sanchez-Vives, M.V., Institució Catalana Recerca i Estudis Avançats (ICREA), Universitat de Barcelona, Barcelona, Spain, Institut d'Investigacions Biomèdiques August Pii Sunyer (IDIBAPS), Barcelona, Spain; Blanke, O., Brain-Mind Institute, Ecole Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland","Background: Altering the normal association between touch and its visual correlate can result in the illusory perception of a fake limb as part of our own body. Thus, when touch is seen to be applied to a rubber hand while felt synchronously on the corresponding hidden real hand, an illusion of ownership of the rubber hand usually occurs. The illusion has also been demonstrated using visuomotor correlation between the movements of the hidden real hand and the seen fake hand. This type of paradigm has been used with respect to the whole body generating out-of-the-body and body substitution illusions. However, such studies have only ever manipulated a single factor and although they used a form of virtual reality have not exploited the power of immersive virtual reality (IVR) to produce radical transformations in body ownership. Principal Findings: Here we show that a first person perspective of a life-sized virtual human female body that appears to substitute the male subjects' own bodies was sufficient to generate a body transfer illusion. This was demonstrated subjectively by questionnaire and physiologically through heart-rate deceleration in response to a threat to the virtual body. This finding is in contrast to earlier experimental studies that assume visuotactile synchrony to be the critical contributory factor in ownership illusions. Our finding was possible because IVR allowed us to use a novel experimental design for this type of problem with three independent binary factors: (i) perspective position (first or third), (ii) synchronous or asynchronous mirror reflections and (iii) synchrony or asynchrony between felt and seen touch. Conclusions: The results support the notion that bottom-up perceptual mechanisms can temporarily override top down knowledge resulting in a radical illusion of transfer of body ownership. The research also illustrates immersive virtual reality as a powerful tool in the study of body representation and experience, since it supports experimental manipulations that would otherwise be infeasible, with the technology being mature enough to represent human bodies and their motion. © 2010 Slater et al.",,"adult; article; body image; controlled study; head movement; heart rate; human; human experiment; male; normal human; perception; questionnaire; scoring system; touch; virtual reality; Adult; Body Image; Heart Rate; Humans; Male; Questionnaires; User-Computer Interface; Visual Perception",Article,"Final","",Scopus,2-s2.0-77956543868
"Jung Y., Webelt S., Olbrich M., Drevensek T., Franke T., Roth M., Fellner D.","16304340400;36457367100;26531589600;35182893700;15135342700;57188584352;6603799372;","Interactive textures as spatial user interfaces in X3D",2010,"Web3D Symposium Proceedings",,,,"147","150",,1,"10.1145/1836049.1836071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956236591&doi=10.1145%2f1836049.1836071&partnerID=40&md5=3a7984cd5fd3819f662dfc46226084e1","Fraunhofer IGD, TU Darmstadt, Darmstadt, Germany","Jung, Y., Fraunhofer IGD, TU Darmstadt, Darmstadt, Germany; Webelt, S., Fraunhofer IGD, TU Darmstadt, Darmstadt, Germany; Olbrich, M., Fraunhofer IGD, TU Darmstadt, Darmstadt, Germany; Drevensek, T., Fraunhofer IGD, TU Darmstadt, Darmstadt, Germany; Franke, T., Fraunhofer IGD, TU Darmstadt, Darmstadt, Germany; Roth, M., Fraunhofer IGD, TU Darmstadt, Darmstadt, Germany; Fellner, D., Fraunhofer IGD, TU Darmstadt, Darmstadt, Germany","3D applications, e.g. in the context of visualization or interactive design review, can require complex user interaction to manipulate certain elements, a typical task which requires standard user interface elements. However, there are still no generalized methods for selecting and manipulating objects in 3D scenes and 3D GUI elements often fail to gather support for reasons of simplicity, leaving developers encumbered to replicate interactive elements themselves. Therefore, we present a set of nodes that introduce different kinds of 2D user interfaces to X3D. We define a base type for these user interfaces called ""InteractiveTexture"", which is a 2D texture node implementing slots for input forwarding. From this node we derive several user interface representations to enable complex user interaction suitable for both, desktop and immersive interaction. © 2010 ACM.","3D UI; Interaction; Texturing; Virtual reality; X3D","2D textures; 3D application; 3D scenes; 3D UI; Generalized method; Immersive; Interaction; Interactive design; Interactive elements; Interface elements; Spatial user interfaces; User interaction; X3D; Textures; Three dimensional; Virtual reality; Visualization; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-77956236591
"Kartiko I., Kavakli M., Cheng K.","35185198900;6602420178;7402998367;","Learning science in a virtual reality application: The impacts of animated-virtual actors' visual complexity",2010,"Computers and Education","55","2",,"881","891",,34,"10.1016/j.compedu.2010.03.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953144820&doi=10.1016%2fj.compedu.2010.03.019&partnerID=40&md5=46d81efc9d661e55d46b5e439629d6b2","Department of Computing, Macquarie University, North Ryde, Sydney, NSW 2109, Australia; Department of Brain, Behaviour and Evolution, Macquarie University, North Ryde, Sydney, NSW 2109, Australia","Kartiko, I., Department of Computing, Macquarie University, North Ryde, Sydney, NSW 2109, Australia; Kavakli, M., Department of Computing, Macquarie University, North Ryde, Sydney, NSW 2109, Australia; Cheng, K., Department of Brain, Behaviour and Evolution, Macquarie University, North Ryde, Sydney, NSW 2109, Australia","As the technology in computer graphics advances, Animated-Virtual Actors (AVAs) in Virtual Reality (VR) applications become increasingly rich and complex. Cognitive Theory of Multimedia Learning (CTML) suggests that complex visual materials could hinder novice learners from attending to the lesson properly. On the other hand, previous studies have shown that visual complexity correlates with presence and may increase the perceived affective quality of the virtual world, towards an optimal experience or flow. Increasing these in VR applications may promote enjoyment and higher cognitive engagement for better learning outcomes. While visually complex materials could be motivating and pleasing to attend to, would they affect learning adversely? We developed a series of VR presentations to teach second-year psychology students about the navigational behaviour of Cataglyphis ants with flat, cartoon, or lifelike AVAs. To assess learning outcomes, we used Program Ratings, which measured perception of learning and perceived difficulty, and retention and transfer tests. The results from 200 students did not reveal any significant differences in presence, perceived affective quality, or learning outcomes as a function of the AVA's visual complexity. While the results showed positive correlations between presence, perceived affective quality and perception of learning, none of these correlates with perceived difficulty, retention, or transfer scores. Nevertheless, our simulation produced significant improvements on retention and transfer scores in all conditions. We discuss possible explanations and future research directions. © 2010 Elsevier Ltd. All rights reserved.","Applications of animated-virtual actors; Evaluation of CAL systems; Human-computer interface; Multimedia/hypermedia systems; Virtual reality","Evaluation of CAL systems; Human computer interfaces; Multimedia/hypermedia systems; Virtual actors; Computer supported cooperative work; Virtual reality",Article,"Final","",Scopus,2-s2.0-77953144820
"Gruzelier J., Inoue A., Smart R., Steed A., Steffert T.","7004536505;36611844400;36612395100;18435050200;24725819800;","Acting performance and flow state enhanced with sensory-motor rhythm neurofeedback comparing ecologically valid immersive VR and training screen scenarios",2010,"Neuroscience Letters","480","2",,"112","116",,62,"10.1016/j.neulet.2010.06.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954533066&doi=10.1016%2fj.neulet.2010.06.019&partnerID=40&md5=9797bd8bb41075d4eaf4b5025731db59","Department of Psychology, Goldsmiths, University of London, Lewisham Way, London SE14 6NW, United Kingdom; Department of Drama, Goldsmiths, University of London, United Kingdom; Department of Computer Science, University College London, United Kingdom","Gruzelier, J., Department of Psychology, Goldsmiths, University of London, Lewisham Way, London SE14 6NW, United Kingdom; Inoue, A., Department of Psychology, Goldsmiths, University of London, Lewisham Way, London SE14 6NW, United Kingdom; Smart, R., Department of Drama, Goldsmiths, University of London, United Kingdom; Steed, A., Department of Computer Science, University College London, United Kingdom; Steffert, T., Department of Psychology, Goldsmiths, University of London, Lewisham Way, London SE14 6NW, United Kingdom","Actors were trained in sensory-motor rhythm (SMR) neurofeedback interfaced with a computer rendition of a theatre auditorium. Enhancement of SMR led to changes in the lighting while inhibition of theta and high beta led to a reduction in intrusive audience noise. Participants were randomised to a virtual reality (VR) representation in a ReaCTor, with surrounding image projection seen through glasses, or to a 2D computer screen, which is the conventional neurofeedback medium. In addition there was a no-training comparison group. Acting performance was evaluated by three experts from both filmed, studio monologues and Hamlet excerpts on the stage of Shakespeare's Globe Theatre. Neurofeedback learning reached an asymptote earlier as did identification of the required mental state following training in the ReaCTor training compared with the computer screen, though groups reached the same asymptote. These advantages were paralleled by higher ratings of acting performance overall, well-rounded performance, and especially the creativity subscale including imaginative expression, conviction and characterisation. On the Flow State scales both neurofeedback groups scored higher than the no-training controls on self-ratings of sense of control, confidence and feeling at-one. This is the first demonstration of enhancement of artistic performance with eyes-open neurofeedback training, previously demonstrated only with eyes-closed slow-wave training. Efficacy is attributed to psychological engagement through the ecologically relevant learning context of the acting-space, putatively allowing transfer to the real world otherwise achieved with slow-wave training through imaginative visualisation. The immersive VR technology was more successful than a 2D rendition. © 2010 Elsevier Ireland Ltd.","Acting performance; Flow state; Neurofeedback; Virtual reality","adult; alpha rhythm; article; beta rhythm; controlled study; creativity; electroencephalogram; evaluation; feedback system; female; human; human experiment; image display; imagination; intermethod comparison; learning; male; normal human; performance; performing artist; performing arts; priority journal; rating scale; sensorimotor integration; sensory motor rhythm neurofeedback; theta rhythm; training; virtual reality; art; comparative study; electroencephalography; learning; neuropsychological test; periodicity; psychophysiology; randomized controlled trial; Art; Biofeedback, Psychology; Electroencephalography; Female; Humans; Male; Neuropsychological Tests; Periodicity; Practice (Psychology); Art; Biofeedback, Psychology; Electroencephalography; Female; Humans; Male; Neuropsychological Tests; Periodicity; Practice (Psychology)",Article,"Final","",Scopus,2-s2.0-77954533066
"Brydges R., Carnahan H., Rose D., Dubrowski A.","56962707200;7004489168;24759658400;6602597937;","Comparing self-guided learning and educator-guided learning formats for simulation-based clinical training",2010,"Journal of Advanced Nursing","66","8",,"1832","1844",,40,"10.1111/j.1365-2648.2010.05338.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955131316&doi=10.1111%2fj.1365-2648.2010.05338.x&partnerID=40&md5=c2c70ccc115aed7e164a2c67296c9eba","The Wilson Centre, University of Toronto, Ontario, Canada; Centre for Health Education Scholarship, University of British Columbia, Vancouver, Canada; Department of Occupational Science and Occupational Therapy, University of Toronto, Ontario, Canada; School of Nursing, Ryerson University, Toronto, ON, Canada; Learning Institute, Hospital for Sick Children, University of Toronto, Ontario, Canada","Brydges, R., The Wilson Centre, University of Toronto, Ontario, Canada, Centre for Health Education Scholarship, University of British Columbia, Vancouver, Canada; Carnahan, H., Department of Occupational Science and Occupational Therapy, University of Toronto, Ontario, Canada; Rose, D., School of Nursing, Ryerson University, Toronto, ON, Canada; Dubrowski, A., Learning Institute, Hospital for Sick Children, University of Toronto, Ontario, Canada","Aim.: In this paper, we tested the over-arching hypothesis that progressive self-guided learning offers equivalent learning benefit vs. proficiency-based training while limiting the need to set proficiency standards. Background.: We have shown that self-guided learning is enhanced when students learn on simulators that progressively increase in fidelity during practice. Proficiency-based training, a current gold-standard training approach, requires achievement of a criterion score before students advance to the next learning level. Methods.: Baccalaureate nursing students (n = 15/group) practised intravenous catheterization using simulators that differed in fidelity (i.e. students' perceived realism). Data were collected in 2008. Proficiency-based students advanced from low- to mid- to high-fidelity after achieving a proficiency criterion at each level. Progressive students self-guided their progression from low- to mid- to high-fidelity. Yoked control students followed an experimenter-defined progressive practice schedule. Open-ended students moved freely between the simulators. One week after practice, blinded experts evaluated students' skill transfer on a standardized patient simulation. Group differences were examined using analyses of variance. Results.: Proficiency-based students scored highest on the high-fidelity post-test (effect size = 1·22). An interaction effect showed that the Progressive and Open-ended groups maintained their performance from post-test to transfer test, whereas the Proficiency-based and Yoked control groups experienced a significant decrease (P < 0·05). Surprisingly, most Open-ended students (73%) chose the progressive practice schedule. Conclusion.: Progressive training and proficiency-based training resulted in equivalent transfer test performance, suggesting that progressive students effectively self-guided when to transition between simulators. Students' preference for the progressive practice schedule indicates that educators should consider this sequence for simulation-based training. © 2010 Blackwell Publishing Ltd.","Clinical training; Educator-guided learning; Nurse education; Proficiency-based training; Self assessment; Self-directed learning; Simulation","adult; analysis of variance; article; catheterization; clinical competence; clinical trial; computer simulation; controlled clinical trial; controlled study; education; human; learning; methodology; middle aged; nursing education; nursing student; psychological aspect; randomized controlled trial; standard; teaching; Adult; Analysis of Variance; Catheterization; Clinical Competence; Computer Simulation; Computer-Assisted Instruction; Education, Nursing, Baccalaureate; Educational Measurement; Faculty, Nursing; Humans; Learning; Middle Aged; Nursing Education Research; Patient Simulation; Programmed Instruction as Topic; Students, Nursing; Teaching; Young Adult",Article,"Final","",Scopus,2-s2.0-77955131316
"Sánchez J., Sáenz M., Pascual-Leone A., Merabet L.","7403997772;12240898000;7103180976;6603146795;","Enhancing navigation skills through audio gaming",2010,"Conference on Human Factors in Computing Systems - Proceedings",,,,"3991","3996",,15,"10.1145/1753846.1754091","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953113794&doi=10.1145%2f1753846.1754091&partnerID=40&md5=1ebc7f73a1837a11c760efe08ee2c9e6","Department of Computer Science, Center for Advanced Research in Education (CARE), University of Chile, Blanco Encalada 2120, Santiago, Chile; Berenson-Allen Center for Noninvasive Brain Stimulation, Department of Neurology, Harvard Medical School, United States","Sánchez, J., Department of Computer Science, Center for Advanced Research in Education (CARE), University of Chile, Blanco Encalada 2120, Santiago, Chile; Sáenz, M., Department of Computer Science, Center for Advanced Research in Education (CARE), University of Chile, Blanco Encalada 2120, Santiago, Chile; Pascual-Leone, A., Berenson-Allen Center for Noninvasive Brain Stimulation, Department of Neurology, Harvard Medical School, United States; Merabet, L., Berenson-Allen Center for Noninvasive Brain Stimulation, Department of Neurology, Harvard Medical School, United States","We present the design, development and initial cognitive evaluation of an Audio-based Environment Simulator (AbES). This software allows a blind user to navigate through a virtual representation of a real space for the purposes of training orientation and mobility skills. Our findings indicate that users feel satisfied and self-confident when interacting with the audio-based interface, and the embedded sounds allow them to correctly orient themselves and navigate within the virtual world. Furthermore, users are able to transfer spatial information acquired through virtual interactions into real world navigation and problem solving tasks. © 2010 Copyright is held by the author/owner(s).","Audio games; Orientation and mobility; Videogames; Virtual environment; Visual impairment","Audio-based; Blind users; Environment simulators; Mobility skills; Real-space; Spatial informations; Video game; Virtual environments; Virtual interactions; Virtual representations; Virtual worlds; Visual impairment; Human engineering; Motion compensation; Navigation; Virtual reality; Audio acoustics",Conference Paper,"Final","",Scopus,2-s2.0-77953113794
"Ha T., Woo W.","15020792200;35575439600;","An empirical evaluation of virtual hand techniques for 3D object manipulation in a tangible augmented reality environment",2010,"3DUI 2010 - IEEE Symposium on 3D User Interfaces 2010, Proceedings",,, 5444713,"91","98",,25,"10.1109/3DUI.2010.5444713","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953077148&doi=10.1109%2f3DUI.2010.5444713&partnerID=40&md5=bad2d4402b928dfdb6ba9ae1862ffaaa","GIST U-VR Lab., 500-712, South Korea","Ha, T., GIST U-VR Lab., 500-712, South Korea; Woo, W., GIST U-VR Lab., 500-712, South Korea","In this paper, we present a Fitts' law-based formal evaluation process and the corresponding results for 3D object manipulation techniques based on a virtual hand metaphor in a tangible augmented reality (TAR) environment. Specifically, we extend the design parameters of the 1D scale Fitts' law to 3D scale and then refine an evaluation model in order to bring generality and ease of adaptation to various TAR applications. Next, we implement and compare standard TAR manipulation techniques using a cup, a paddle, a cube, and a proposed extended paddle prop. Most manipulation techniques were well-modeled in terms of linear regression according to Fitts' law, with a correlation coefficient value of over 0.9. Notably, the throughput by ISO 9241-9 of the extended paddle technique peaked at around 1.39 to 2 times higher than in the other techniques, due to the instant 3D positioning of the 3D objects. In the discussion, we subsequently examine the characteristics of the TAR manipulation techniques in terms of stability, speed, comfort, and understanding. As a result, our evaluation process, results, and analysis can be useful in guiding the design and implementation of future TAR interfaces. ©2010 IEEE.","3D object manipulation; Augmented reality; Empirical evaluation; Fitts' law; H.5.1 [Information Interfaces and Presentation]: Multimedia information systems - Artificial, augmented, and virtual realities; H.5.2 [Information Interfaces and Presentation]: User interfaces - Input interaction styles; Tangible user interface; Virtual hand technique","3D object; 3D object manipulation; Empirical evaluations; Fitts' law; H.5.1 [information interfaces and presentation]: multimedia information systems - Artificial , augmented , and virtual realities; Interaction styles; Tangible user interfaces; Virtual hand; Augmented reality; Environmental regulations; Information systems; Tar; Three dimensional; Three dimensional computer graphics; Virtual reality; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-77953077148
"Wallet G., Sauzéon H., Rodrigues J., Larrue F., N'Kaoua B.","26425357400;7801452039;26425235600;36139685200;6603602499;","Virtual/real transfer of spatial learning: Impact of activity according to the retention delay",2010,"Annual Review of CyberTherapy and Telemedicine","8","1",,"115","118",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952895771&partnerID=40&md5=df3edf1dbc29de17edda2d427e4d54cd","Laboratoire Cognition et Facteurs Humains, Bordeaux, 33000, France","Wallet, G., Laboratoire Cognition et Facteurs Humains, Bordeaux, 33000, France; Sauzéon, H., Laboratoire Cognition et Facteurs Humains, Bordeaux, 33000, France; Rodrigues, J., Laboratoire Cognition et Facteurs Humains, Bordeaux, 33000, France; Larrue, F., Laboratoire Cognition et Facteurs Humains, Bordeaux, 33000, France; N'Kaoua, B., Laboratoire Cognition et Facteurs Humains, Bordeaux, 33000, France","Within the framework of cognitive rehabilitation using virtual reality (VR), one of the major challenges is to study beforehand the effectiveness of the virtual-real transfer of learning and to define cognitive aids. The aim of this experiment was to verify if, after learning spatial knowledge (i.e., a route) in VR, performances can be transferred to reality, then maintained in real time, and improved with the aid of an active navigation (i.e., using a joystick). Ninety student volunteers from the University of Bordeaux 2 (45 men and 45 women) participated in the experiment. The virtual environment (VE) used for learning was a replica of an area of Bordeaux. The factors tested were retention delay (Immediate vs. 48 hours) and type of navigation (Passive virtual vs. Active virtual vs. Real), using three recall tasks: wayfinding, freehand sketch and photograph classification. Our results showed that the virtual-real transfer was not degraded by a retention delay of 48 hours and that active navigation allowed performances to be optimized.","Exploration mode; Knowledge transfer; Retention delay, recall tasks; Spatial cognition; Virtual reality","adult; article; cognition; controlled study; female; human; human experiment; knowledge; learning; male; scoring system; task performance; virtual reality",Article,"Final","",Scopus,2-s2.0-77952895771
"Londero A., Viaud-Delmon I., Baskind A., Delerue O., Bertet S., Bonfils P., Warusfel O.","7006173947;6603053540;36116591700;6603122142;24381797100;7006269708;14057179800;","Auditory and visual 3D virtual reality therapy for chronic subjective tinnitus: Theoretical framework",2010,"Virtual Reality","14","2",,"143","151",,8,"10.1007/s10055-009-0135-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952882596&doi=10.1007%2fs10055-009-0135-0&partnerID=40&md5=a3af5206416452faaef2471a7847a1e8","Service d'ORL et Chirurgie Cervico-Faciale Hôpital Européen Georges Pompidou, Paris, France; Laboratoire de Recherche sur les Systèmes Sensori-Moteurs (LNRS) Unité CNRS UMR 7060, Faculté de Médecine René, Descartes Université Paris V, Paris, France; IRCAM, Paris, France; CNRS UMR 9912, Paris, France","Londero, A., Service d'ORL et Chirurgie Cervico-Faciale Hôpital Européen Georges Pompidou, Paris, France, Laboratoire de Recherche sur les Systèmes Sensori-Moteurs (LNRS) Unité CNRS UMR 7060, Faculté de Médecine René, Descartes Université Paris V, Paris, France; Viaud-Delmon, I., IRCAM, Paris, France, CNRS UMR 9912, Paris, France; Baskind, A., Laboratoire de Recherche sur les Systèmes Sensori-Moteurs (LNRS) Unité CNRS UMR 7060, Faculté de Médecine René, Descartes Université Paris V, Paris, France; Delerue, O., IRCAM, Paris, France; Bertet, S., IRCAM, Paris, France; Bonfils, P., Service d'ORL et Chirurgie Cervico-Faciale Hôpital Européen Georges Pompidou, Paris, France, Laboratoire de Recherche sur les Systèmes Sensori-Moteurs (LNRS) Unité CNRS UMR 7060, Faculté de Médecine René, Descartes Université Paris V, Paris, France; Warusfel, O., IRCAM, Paris, France, CNRS UMR 9912, Paris, France","It is estimated that ~10% of the adult population in developed countries is affected by subjective tinnitus. Physiopathology of subjective tinnitus remains incompletely explained. Nevertheless, subjective tinnitus is thought to result from hyperactivity and neuroplastic reorganization of cortical and subcortical networks following acoustic deafferentation induced by cochlear or auditory nerve damage. Involvement of both auditory and non-auditory central nervous pathways explains the conscious perception of tinnitus and also the potentially incapacitating discomfort experienced by some patients (sound hypersensitivity, sleep disorders, attention deficit, anxiety or depression). These clinical patterns are similar to those observed in chronic pain following amputation where conditioning techniques using virtual reality have been shown both to be theoretically interesting and effectively useful. This analogy led us to develop an innovative setup with dedicated auditory and visual 3D virtual reality environments in which unilateral subjective tinnitus sufferers are given the possibility to voluntarily manipulate an auditory and visual image of their tinnitus (tinnitus avatar). By doing so, the patients will be able to transfer their subjective auditory perception to the tinnitus avatar and to gain agency on this multimodal virtual percept they hear, see and spatially control. Repeated sessions of such virtual reality immersions are then supposed to contribute to tinnitus treatment by promoting cerebral plasticity. This paper describes the theoretical framework and setup adjustments required by this very first attempt to adapt virtual reality techniques to subjective tinnitus treatment. Therapeutic usefulness will be validated by a further controlled clinical trial. © 2009 The Author(s).","Neuroplasticity; Tinnitus; Virtual reality","3D virtual reality; Adult populations; Attention deficit; Auditory nerves; Auditory perception; Chronic pain; Clinical trial; Developed countries; Multi-modal; Neuroplasticity; Physiopathology; Setup adjustments; Sleep disorders; Theoretical framework; Visual image; Neurophysiology; Three dimensional; Virtual reality",Article,"Final","",Scopus,2-s2.0-77952882596
"Fong K.N.K., Chow K.Y.Y., Chan B.C.H., Lam K.C.K., Lee J.C.K., Li T.H.Y., Yan E.W.H., Wong A.T.Y.","14119428500;36100962600;36101103800;56332495000;36101284200;36101162400;36101952000;36101832300;","Usability of a virtual reality environment simulating an automated teller machine for assessing and training persons with acquired brain injury",2010,"Journal of NeuroEngineering and Rehabilitation","7","1", 19,"","",,23,"10.1186/1743-0003-7-19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951541583&doi=10.1186%2f1743-0003-7-19&partnerID=40&md5=862df39812c55fd9b464bd23cb8dd916","Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong, Hong Kong; Occupational Therapy Department, Kowloon Hospital, Hong Kong, Hong Kong","Fong, K.N.K., Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong, Hong Kong; Chow, K.Y.Y., Occupational Therapy Department, Kowloon Hospital, Hong Kong, Hong Kong; Chan, B.C.H., Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong, Hong Kong; Lam, K.C.K., Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong, Hong Kong; Lee, J.C.K., Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong, Hong Kong; Li, T.H.Y., Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong, Hong Kong; Yan, E.W.H., Occupational Therapy Department, Kowloon Hospital, Hong Kong, Hong Kong; Wong, A.T.Y., Occupational Therapy Department, Kowloon Hospital, Hong Kong, Hong Kong","Objective. This study aimed to examine the usability of a newly designed virtual reality (VR) environment simulating the operation of an automated teller machine (ATM) for assessment and training. Design. Part I involved evaluation of the sensitivity and specificity of a non-immersive VR program simulating an ATM (VR-ATM). Part II consisted of a clinical trial providing baseline and post-intervention outcome assessments. Setting. A rehabilitation hospital and university-based teaching facilities were used as the setting. Participants. A total of 24 persons in the community with acquired brain injury (ABI) - 14 in Part I and 10 in Part II - made up the participants in the study. Interventions. In Part I, participants were randomized to receive instruction in either an ""early"" or a ""late"" VR-ATM program and were assessed using both the VR program and a real ATM. In Part II, participants were assigned in matched pairs to either VR training or computer-assisted instruction (CAI) teaching programs for six 1-hour sessions over a three-week period. Outcome Measures. Two behavioral checklists based on activity analysis of cash withdrawals and money transfers using a real ATM were used to measure average reaction time, percentage of incorrect responses, level of cues required, and time spent as generated by the VR system; also used was the Neurobehavioral Cognitive Status Examination. Results. The sensitivity of the VR-ATM was 100% for cash withdrawals and 83.3% for money transfers, and the specificity was 83% and 75%, respectively. For cash withdrawals, the average reaction time of the VR group was significantly shorter than that of the CAI group (p = 0.021). We found no significant differences in average reaction time or accuracy between groups for money transfers, although we did note positive improvement for the VR-ATM group. Conclusion. We found the VR-ATM to be usable as a valid assessment and training tool for relearning the use of ATMs prior to real-life practice in persons with ABI. © 2010 Fong et al; licensee BioMed Central Ltd.",,"adult; article; brain injury; clinical trial; computer assisted therapy; computer interface; controlled clinical trial; controlled study; daily life activity; female; human; instrumentation; male; methodology; middle aged; randomized controlled trial; reaction time; sensitivity and specificity; Activities of Daily Living; Adult; Brain Injuries; Female; Humans; Male; Middle Aged; Reaction Time; Sensitivity and Specificity; Therapy, Computer-Assisted; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-77951541583
"Bullinger H.-J., Bauer W., Wenzel G., Blach R.","7004916256;35483043700;23399167200;15057595400;","Towards user centred design (UCD) in architecture based on immersive virtual environments",2010,"Computers in Industry","61","4",,"372","379",,55,"10.1016/j.compind.2009.12.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953232146&doi=10.1016%2fj.compind.2009.12.003&partnerID=40&md5=9cd7462cf1f0f9ebfdeb8bed14e24920","Fraunhofer Headquarter, Hansastraße 27c, 80686 Munich, Germany; Fraunhofer Institute for Industrial Engineering IAO, Nobelstr. 12, 70569 Stuttgart, Germany","Bullinger, H.-J., Fraunhofer Headquarter, Hansastraße 27c, 80686 Munich, Germany; Bauer, W., Fraunhofer Institute for Industrial Engineering IAO, Nobelstr. 12, 70569 Stuttgart, Germany; Wenzel, G., Fraunhofer Institute for Industrial Engineering IAO, Nobelstr. 12, 70569 Stuttgart, Germany; Blach, R., Fraunhofer Institute for Industrial Engineering IAO, Nobelstr. 12, 70569 Stuttgart, Germany","This paper describes a generic concept of how to combine the experience of user centred design (UCD) in the field of Human Computer Interaction (HCI) with the traditional approach of participatory design (PD) in an architectural design process. Even if some basic requirements of this generic method are not available yet, this paper will also describe an approach, which enables planners even now to involve end users by using virtual environments (VE) as immersive and spatial prototype. It will be described and illustrated by the way of example using the building project Centre of Virtual Engineering of the Fraunhofer Institute for Industrial Engineering (IAO) in Stuttgart. It demonstrates that the transfer of the UCD approach to architectural planning combined with the provision of an adequate prototype can make a significant contribution towards an increase in quality and performance in building and construction projects. © 2010 Elsevier B.V. All rights reserved.","Architectural design; User centred design; Virtual environments","Building projects; End users; Fraunhofer; Generic method; Immersive; Immersive virtual environments; In-buildings; Participatory design; User centred design; Virtual engineering; Virtual environments; Architectural design; Construction industry; Structural design; Virtual reality; Human computer interaction",Article,"Final","",Scopus,2-s2.0-77953232146
"Fiorentino M., Uva A.E., Dellisanti Fabiano M., Monno G.","56350129000;6505665039;25959581000;6603171537;","Improving bi-manual 3D input in CAD modelling by part rotation optimisation",2010,"CAD Computer Aided Design","42","5",,"462","470",,13,"10.1016/j.cad.2008.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950187544&doi=10.1016%2fj.cad.2008.12.002&partnerID=40&md5=e61c41c9c14f64dc1a291aa2324fafb6","DIMEG, Politecnico di Bari, Viale Japigia 182, 70126 Bari, Italy","Fiorentino, M., DIMEG, Politecnico di Bari, Viale Japigia 182, 70126 Bari, Italy; Uva, A.E., DIMEG, Politecnico di Bari, Viale Japigia 182, 70126 Bari, Italy; Dellisanti Fabiano, M., DIMEG, Politecnico di Bari, Viale Japigia 182, 70126 Bari, Italy; Monno, G., DIMEG, Politecnico di Bari, Viale Japigia 182, 70126 Bari, Italy","Part modelling in a CAD environment requires a bi-manual 3D input interface to fully exploit its potentialities. In this research we provide extensive user tests on bi-manual modelling using different devices to control 3D model's rotation. Our results suggest that a simple trackball device is effective when the user task is mostly limited to rotation control (i.e. when modelling parts in a CAD environment). In our tests, performances are even better than those achieved with a specifically designed device. Since the task of rotating a CAD part often shows the need of flipping the controlled object, we introduce a non linear transfer function which combines the precision of a zero order control mode with the ability to recognise fast movements. This new modality shows a significant improvement in the user's performances and candidates itself for integration in next generation CAD interfaces. © 2008 Elsevier Ltd. All rights reserved.","3D input; Bimanual interaction; Human computer interface; Part modelling; VR CAD","3D models; Bi-manual interaction; CAD interfaces; Controlled objects; Fast movement; Human computer interfaces; Input interface; New modality; Non-linear; Optimisations; Rotation control; Trackballs; User tests; Zero order; Human computer interaction; Interfaces (computer); Rotation; Three dimensional",Article,"Final","",Scopus,2-s2.0-77950187544
"Vasudevan R., Lobaton E., Kurillo G., Bajcsy R., Bernardin T., Hamann B., Nahrstedt K.","55405414900;24450724500;16426116000;7006078015;14322934400;7005775949;7006456800;","A methodology for remote virtual interaction in teleimmersive environments",2010,"MMSys'10 - Proceedings of the 2010 ACM SIGMM Conference on Multimedia Systems",,,,"281","291",,9,"10.1145/1730836.1730871","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951269465&doi=10.1145%2f1730836.1730871&partnerID=40&md5=5cd8dca9665f580955749a82dca322b0","Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Hearst Mining Bldg. #475, Berkeley, CA 94720-1764, United States; Institute for Data Analysis and Visualization (IDAV), University of California, Davis, One Shields Ave, Davis, CA 95616, United States; Department of Computer Science, University of Illinois at Urbana-Champaign, 201 N. Goodwin Avenue, Urbana, IL 61801-2302, United States","Vasudevan, R., Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Hearst Mining Bldg. #475, Berkeley, CA 94720-1764, United States; Lobaton, E., Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Hearst Mining Bldg. #475, Berkeley, CA 94720-1764, United States; Kurillo, G., Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Hearst Mining Bldg. #475, Berkeley, CA 94720-1764, United States; Bajcsy, R., Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Hearst Mining Bldg. #475, Berkeley, CA 94720-1764, United States; Bernardin, T., Institute for Data Analysis and Visualization (IDAV), University of California, Davis, One Shields Ave, Davis, CA 95616, United States; Hamann, B., Institute for Data Analysis and Visualization (IDAV), University of California, Davis, One Shields Ave, Davis, CA 95616, United States; Nahrstedt, K., Department of Computer Science, University of Illinois at Urbana-Champaign, 201 N. Goodwin Avenue, Urbana, IL 61801-2302, United States","Though the quality of imaging devices, the accuracy of algorithms that construct 3D data, and the hardware available to render such data have all improved, the algorithms available to calibrate, reconstruct, and then visualize such data are difficult to use, extremely noise sensitive, and unreasonably slow. In this paper, we describe a multi-camera system that creates a highly accurate (on the order of a centimeter), 3D reconstruction of an environment in real time (under 30 ms) that allows for remote interaction between users. The paper addresses the aforementioned deficiencies by featuring an overview of the technology and algorithms used to calibrate, reconstruct, and render objects in the system. The algorithm produces partial 3D meshes, instead of dense point clouds, which are combined on the renderer to create a unified model of the environment. The chosen representation of the data allows for high compression ratios for transfer to remote sites. We demonstrate the accuracy and speed of our results on a variety of benchmarks and data collected from our own system. Copyright 2010 ACM.","3D teleimmersion; 3D video; Human-computer interaction; Real time; Stereo reconstruction; Virtual reality; Visualization","3d tele-immersion; 3D video; Real time; Real time stereo; Stereo reconstruction; Algorithms; Human computer interaction; Image reconstruction; Knowledge management; Multimedia systems; Repair; Three dimensional computer graphics; Virtual reality; Visualization; Three dimensional",Conference Paper,"Final","",Scopus,2-s2.0-77951269465
"Young G.","18439037900;","Virtually real emotions and the paradox of fiction: Implications for the use of virtual environments in psychological research",2010,"Philosophical Psychology","23","1",,"1","21",,11,"10.1080/09515080903532274","https://www.scopus.com/inward/record.uri?eid=2-s2.0-76149134346&doi=10.1080%2f09515080903532274&partnerID=40&md5=09bfd8f79bfbc78c7e764366f46f11f0","Nottingham Trent University-Psychology, Chaucer Building, Goldsmith Street, Nottingham, Nottinghamshire NG1 5LT, United Kingdom","Young, G., Nottingham Trent University-Psychology, Chaucer Building, Goldsmith Street, Nottingham, Nottinghamshire NG1 5LT, United Kingdom","Many of the psychological studies carried out within virtual environments are motivated by the idea that virtual research findings are generalizable to the non-virtual world. This idea is vulnerable to the paradox of fiction, which questions whether it is possible to express genuine emotion toward a character (or event) known to be fictitious. As many of these virtual studies are designed to elicit, broadly speaking, emotional responses through interactions with fictional characters (avatars) or objects/places, the issue raised by the paradox seems particularly apt. This paper assesses the extent to which the paradox of fiction constitutes a legitimate challenge to psychological research within virtual environments, and argues that any alleged conflict is in fact a product of an overly simplistic view of emotions which a more complete understanding resolves. Moreover, through a more detailed analysis of why the paradox cannot be sustained, one finds justification for the claim that emotions elicited through interactions with virtual (fictitious) objects/events are valid. However, their generalizability to the non-virtual world must still be treated with caution. © 2010 Taylor & Francis.","Affect program; Paradox of fiction; Quasi-emotions; Virtual psychology; Virtual reality",,Article,"Final","",Scopus,2-s2.0-76149134346
"Wallet G., Sauzéon H., Rodrigues J., Larrue F., N'kaoua B.","26425357400;7801452039;26425235600;36139685200;6603602499;","Virtual/real transfer of spatial learning: Impact of activity according to the retention delay",2010,"Studies in Health Technology and Informatics","154",,,"145","149",,10,"10.3233/978-1-60750-561-7-145","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954609123&doi=10.3233%2f978-1-60750-561-7-145&partnerID=40&md5=aeafac012e6e3e11d68001d55853b7bb","Laboratoire Cognition et Facteurs Humains (EA-487), Université Victor Segalen Bordeaux II, France","Wallet, G., Laboratoire Cognition et Facteurs Humains (EA-487), Université Victor Segalen Bordeaux II, France; Sauzéon, H., Laboratoire Cognition et Facteurs Humains (EA-487), Université Victor Segalen Bordeaux II, France; Rodrigues, J., Laboratoire Cognition et Facteurs Humains (EA-487), Université Victor Segalen Bordeaux II, France; Larrue, F., Laboratoire Cognition et Facteurs Humains (EA-487), Université Victor Segalen Bordeaux II, France; N'kaoua, B., Laboratoire Cognition et Facteurs Humains (EA-487), Université Victor Segalen Bordeaux II, France","Within the framework of cognitive rehabilitation using virtual reality (VR), one of the major challenges is to study beforehand the effectiveness of the virtual-real transfer of learning and to define cognitive aids. The aim of this experiment was to verify if, after learning spatial knowledge (i.e., a route) in VR, performances can be transferred to reality, then maintained in real time, and improved with the aid of an active navigation (i.e., using a joystick). Ninety student volunteers from the University of Bordeaux 2 (45 men and 45 women) participated in the experiment. The virtual environment (VE) used for learning was a replica of an area of Bordeaux. The factors tested were retention delay (Immediate vs. 48 hours) and type of navigation (Passive virtual vs. Active virtual vs. Real), using three recall tasks: wayfinding, freehand sketch and photograph classification. Our results showed that the virtual-real transfer was not degraded by a retention delay of 48 hours and that active navigation allowed performances to be optimized. © 2010 The Interactive Media Institute and IOS Press. All rights reserved.","exploration mode; knowledge transfer; recall tasks; retention delay; spatial cognition; Virtual reality","Knowledge management; Navigation; Virtual reality; Cognitive rehabilitation; Knowledge transfer; recall tasks; Retention delays; Spatial cognition; Spatial knowledge; Student volunteers; Transfer of learning; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-77954609123
"De Freitas S., Rebolledo-Mendez G., Liarokapis F., Magoulas G., Poulovassilis A.","57203045925;24832441800;7801416785;26642991300;7003984218;","Learning as immersive experiences: Using the four-dimensional framework for designing and evaluating immersive learning experiences in a virtual world",2010,"British Journal of Educational Technology","41","1",,"69","85",,179,"10.1111/j.1467-8535.2009.01024.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-73149108424&doi=10.1111%2fj.1467-8535.2009.01024.x&partnerID=40&md5=24e9d7ce0e30cffb0ef4fe698a2f2e33","Serious Games Institute, Coventry University, United Kingdom; London Knowledge Lab, University of London, Birkbeck, United Kingdom","De Freitas, S., Serious Games Institute, Coventry University, United Kingdom; Rebolledo-Mendez, G., Serious Games Institute, Coventry University, United Kingdom; Liarokapis, F., Serious Games Institute, Coventry University, United Kingdom; Magoulas, G., London Knowledge Lab, University of London, Birkbeck, United Kingdom; Poulovassilis, A., London Knowledge Lab, University of London, Birkbeck, United Kingdom","Traditional approaches to learning have often focused upon knowledge transfer strategies that have centred on textually-based engagements with learners, and dialogic methods of interaction with tutors. The use of virtual worlds, with text-based, voice-based and a feeling of 'presence' naturally is allowing for more complex social interactions and designed learning experiences and role plays, as well as encouraging learner empowerment through increased interactivity. To unpick these complex social interactions and more interactive designed experiences, this paper considers the use of virtual worlds in relation to structured learning activities for college and lifelong learners. This consideration necessarily has implications upon learning theories adopted and practices taken up, with real implications for tutors and learners alike. Alongside this is the notion of learning as an ongoing set of processes mediated via social interactions and experiential learning circumstances within designed virtual and hybrid spaces. This implies the need for new methodologies for evaluating the efficacy, benefits and challenges of learning in these new ways. Towards this aim, this paper proposes an evaluation methodology for supporting the development of specified learning activities in virtual worlds, based upon inductive methods and augmented by the four-dimensional framework reported in a previous study. The study undertaken aimed to test the efficacy of the proposed evaluation methodology and framework, and to evaluate the broader uses of a virtual world for supporting lifelong learners specifically in their educational choices and career decisions. The paper presents the findings of the study and considers that virtual worlds are reorganising significantly how we relate to the design and delivery of learning. This is opening up a transition in learning predicated upon the notion of learning design through the lens of 'immersive learning experiences' rather than sets of knowledge to be transferred between tutor and learner. The challenges that remain for tutors rest with the design and delivery of these activities and experiences. The approach advocated here builds upon an incremental testing and evaluation of virtual world learning experiences. © 2009 Becta.",,"Approaches to learning; Evaluation methodologies; Experiential learning; Immersive; Immersive learning; Inductive method; Interactivity; Knowledge transfer; Learning Activity; Learning designs; Learning experiences; Learning Theory; Life-long learners; Role play; Social interactions; Structured learning; Testing and evaluation; Through the lens; Virtual worlds; Complexation; Knowledge management; Virtual reality; Interactive computer graphics",Article,"Final","",Scopus,2-s2.0-73149108424
"Danilicheva P., Klimenko S., Baturin Y., Serebrov A.","35226263400;7101864397;6603102121;35273061100;","Education in virtual worlds: Virtual storytelling",2009,"2009 International Conference on CyberWorlds, CW '09",,, 5279531,"333","338",,20,"10.1109/CW.2009.57","https://www.scopus.com/inward/record.uri?eid=2-s2.0-72349095655&doi=10.1109%2fCW.2009.57&partnerID=40&md5=1e32755c357e46d22ed238f6737359b5","Institute of Computing for Physics and Technology, Protvino, Moscow region, Russian Federation","Danilicheva, P., Institute of Computing for Physics and Technology, Protvino, Moscow region, Russian Federation; Klimenko, S., Institute of Computing for Physics and Technology, Protvino, Moscow region, Russian Federation; Baturin, Y., Institute of Computing for Physics and Technology, Protvino, Moscow region, Russian Federation; Serebrov, A., Institute of Computing for Physics and Technology, Protvino, Moscow region, Russian Federation","This paper is dedicated to the idea of studying in virtual worlds and discusses how virtual storytelling technology (VST) can provide an educational process. We try to answer the question - is it possible to substitute a real learning environment with a fully immersive 3D virtual space? And if so, what role should a virtual teacher play and what skills should he have? We describe several advantages that virtual environment (VE) has as compared to an ordinary classroom. It enables children to explore a phenomenon involved and gives them a strong incentive to study. Further, in VE we can transfer a lesson to inaccessible places and carry out demonstrations and experiments that are unrealizable on Earth. We consider the relationship between VST and game-like environments. We present some particular educational applications developed at our institute on the basis of Avango VR-system. Finally, we discuss the future of educational virtual environments and virtual storytelling. © 2009 IEEE.","Education in virtual worlds; Interactive narrative; Lessons from space; Virtual storytelling","3D virtual spaces; Educational Applications; Educational process; Educational virtual environments; Immersive; Interactive narrative; Learning environments; Virtual environments; Virtual storytelling; Virtual worlds; Teaching; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-72349095655
"Hoang T.N., Porter S.R., Thomas B.H.","14819594500;35180376500;55467685600;","Augmenting Image Plane AR 3D Interactions for Wearable Computers",2009,"Conferences in Research and Practice in Information Technology Series","93",,,"9","16",,3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873305889&partnerID=40&md5=b5f50b20260cd223906abc6ff078b773","Wearable Computer Lab, School of Computer and Information Science, University of South Australia, Australia","Hoang, T.N., Wearable Computer Lab, School of Computer and Information Science, University of South Australia, Australia; Porter, S.R., Wearable Computer Lab, School of Computer and Information Science, University of South Australia, Australia; Thomas, B.H., Wearable Computer Lab, School of Computer and Information Science, University of South Australia, Australia","This paper presents a set of large object manipulation techniques implemented in a wearable augmented reality computer system that are optimised for the outdoor setting. These techniques supplement the current image plane approach, to provide a comprehensive solution to 3D object manipulation in an augmented reality outdoor environment. The three extended manipulation techniques, Revolve, Xscale, and Ground plane translation, are focused on using what we determined to be the best coordinate system for object rotation, scaling and translation. This paper goes on to present the generalised plane technique for the constrained translation of graphical objects on arbitrary planes to enable more complex translation operations. The paper presents the techniques from both the user interface and software development perspectives. © 2009, Australian Computer Society, Inc.","3D object manipulation; And virtual environments; Outdoor augmented reality; User interfaces","3D interactions; 3D object; Co-ordinate system; Current image; Graphical objects; Ground planes; Image plane; Manipulation techniques; Object manipulation; Outdoor augmented reality; Outdoor environment; Rotation , scaling and translations; Augmented reality; Three dimensional; Three dimensional computer graphics; Virtual reality; Wearable computers; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-84873305889
"Monclús E., Díaz J., Navazo I., Vázquez P.-P.","24830689800;57210775298;6602822050;7006479983;","The virtual magic lantern: An interaction metaphor for enhanced medical data inspection",2009,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,,,"119","122",,16,"10.1145/1643928.1643955","https://www.scopus.com/inward/record.uri?eid=2-s2.0-74949100110&doi=10.1145%2f1643928.1643955&partnerID=40&md5=2c37a8dc23933977e50a75278b06e809","MOVING Group, Universitat Politècnica de Catalunya, Spain","Monclús, E., MOVING Group, Universitat Politècnica de Catalunya, Spain; Díaz, J., MOVING Group, Universitat Politècnica de Catalunya, Spain; Navazo, I., MOVING Group, Universitat Politècnica de Catalunya, Spain; Vázquez, P.-P., MOVING Group, Universitat Politècnica de Catalunya, Spain","In Volume Rendering, it is difficult to simultaneously visualize interior and exterior structures. Several approaches have been developed to solve this problem, such as cut-away or exploded views. Nevertheless, in most cases, those algorithms usually require either a preprocess of the data, or an accurate determination of the region of interest, previous to data inspection. In this paper we present the Virtual Magic Lantern (VML), an interaction tool tailored to facilitate volumetric data inspection. It behaves like a lantern whose virtual illumination cone provides the focal region which is visualized using a secondary transfer function or different rendering style. This may be used for simple visual inspection, surgery planning, or injure diagnosis. The VML is a particularly friendly and intuitive interaction tool suitable for an immersive Virtual Reality setup with a large screen, where the user moves a Wanda device, like a lantern pointing to the model. We show that this inspection metaphor can be efficiently and easily adapted to a GPU ray casting volume visualization algorithm. We also present the Virtual Magic Window (VMW) metaphor as an efficient collateral implementation of the VML, that can be seen as a restricted case where the lantern illuminates following the viewing direction, through a virtual window created as the intersection of the virtual lantern (guided by the Wanda device) and the bounding box of the volume. Copyright © 2009 by the Association for Computing Machinery, Inc.","Interaction; Medical models; Virtual reality","Bounding box; Focal regions; Illumination cone; Immersive virtual reality; Interaction; Interaction metaphors; Interaction tools; Intuitive interaction; Large screen; Medical data; Medical models; Preprocess; Ray casting; Region of interest; Surgery planning; Visual inspection; Volume visualization; Volumetric data; Computer software; Virtual reality; Visual communication; Volume rendering; Volumetric analysis; Windows; Inspection",Conference Paper,"Final","",Scopus,2-s2.0-74949100110
"Berberich M., Amburn P., Moorhead R., Dyer J., Brill M.","36025051600;57213961315;7006526147;7202228406;23491677200;","Geospatial visualization using hardware accelerated real-time volume rendering",2009,"MTS/IEEE Biloxi - Marine Technology for Our Future: Global and Local Challenges, OCEANS 2009",,, 5422170,"","",,5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951564335&partnerID=40&md5=1654cd008b732ef4b5f41b06d8b3dc8c","Geosystems Research Institute, Mississippi State University, Mississippi State, MS 39762, United States; Geosciences Department, Mississippi State University, Mississippi State, MS 39762, United States; Computer Science and Microsystems Technology Department, University of Applied Sciences Kaiserslautern, Zweibruecken, 66482, Germany","Berberich, M., Computer Science and Microsystems Technology Department, University of Applied Sciences Kaiserslautern, Zweibruecken, 66482, Germany; Amburn, P., Geosystems Research Institute, Mississippi State University, Mississippi State, MS 39762, United States; Moorhead, R., Geosystems Research Institute, Mississippi State University, Mississippi State, MS 39762, United States; Dyer, J., Geosciences Department, Mississippi State University, Mississippi State, MS 39762, United States; Brill, M., Computer Science and Microsystems Technology Department, University of Applied Sciences Kaiserslautern, Zweibruecken, 66482, Germany","We present a visualization framework using direct volume rendering techniques that achieves real-time performance and high image quality. The visualization program runs on a desktop as well as in an immersive environment. The application is named HurricaneVis, and it uses OpenGL, GLSL and VTK. For immersive visualization VRJuggler is added. To achieve real-time rendering rates for 4D scalar data we use the programmability of the GPU and in particular store the transfer functions as well as the 3D volume of scalar data on the GPU in texture memory. The initial use was visualization of scalar data from numerical weather model simulations of tropical cyclones, namely Hurricanes Isabelle and Lili. We are expanding that to include visualization of other types of data sets. We conducted a user study to compare the implemented volume rendering technique with state-of-the-art isosurface rendering. The subjects were students in the Dynamic Meteorology II and Physical Meteorology classes in the Department of Geosciences at Mississippi State University. The results establish that both volume rendering and isosurface visualizations are effective in examining data from computer simulations of hurricanes. Because of the higher image quality and the higher frame rates, direct volume rendering using ray-casting or view-aligned texture slicing was preferred. ©2009 MTS.",,"Data sets; Direct volume rendering; Frame rate; Geosciences; Geospatial visualization; Hardware-accelerated; High image quality; Immersive environment; Immersive visualization; Isabelle; Iso surface; Mississippi State University; Numerical weather model; Programmability; Raycasting; Real time performance; Real-time rendering; Scalar data; Texture memory; Texture slicing; Tropical cyclone; User study; Visualization framework; Computer graphics equipment; Computer simulation; Data transfer rates; Hurricanes; Image quality; Marine engineering; Oceanography; Textures; Visualization; Volume rendering; Data visualization",Conference Paper,"Final","",Scopus,2-s2.0-77951564335
"Hale K.S., Stanney K.M., Malone L.","35373227800;7004487266;7005055452;","Enhancing virtual environment spatial awareness training and transfer through tactile and vestibular cues",2009,"Ergonomics","52","2",,"187","203",,13,"10.1080/00140130802376000","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650394226&doi=10.1080%2f00140130802376000&partnerID=40&md5=077200d2ceb99f541fdd2b0c373a81b0","Design Interactive, Inc., 1221 E. Broadway, Oviedo, FL 32765, United States; University of Central Florida, 4000 Central Florida Blvd., Orlando, FL 32816, United States","Hale, K.S., Design Interactive, Inc., 1221 E. Broadway, Oviedo, FL 32765, United States; Stanney, K.M., Design Interactive, Inc., 1221 E. Broadway, Oviedo, FL 32765, United States, University of Central Florida, 4000 Central Florida Blvd., Orlando, FL 32816, United States; Malone, L., University of Central Florida, 4000 Central Florida Blvd., Orlando, FL 32816, United States","Haptic interaction has been successfully incorporated into a variety of virtual environment (VE) systems, yet designing multimodal VE training systems remains challenging as each cue incorporated during training should maximise learning and training transfer. This study examined the impact of incorporating two independent, spatialised tactile cues and vestibular cues into a military VE training environment with the goal of empirically examining whether such cues could enhance performance within the training environment and also that knowledge and skills gained during training could transfer to another environment. The results showed that tactile cues enhanced spatial awareness and performance during both repeated training and within a transfer environment, yet there were costs associated when two independent tactile cues were presented during training. In addition, results suggest that spatial awareness benefits from a tactile point indicator may be impacted by vestibular cues, as performance benefits were seen when tactile cues were paired with head tracking. To fully realise training potential, it is essential to determine how best to leverage multimodal capacity of VE training systems by identifying how multimodal training cues may advance knowledge, skills and attitudes of trainees. Results from this study provide design guidelines for incorporating tactile cues in VE training environments to enhance spatial awareness. © 2009 Taylor & Francis.","Haptics; Multimodal; Tactile; Training; Virtual environment","Design guidelines; Haptic interactions; Haptics; Head tracking; Learning and training; Multi-modal; Performance benefits; Spatial awareness; Tactile cues; Training Systems; Vestibular cues; Virtual environments; Knowledge management; Virtual reality; accuracy; adult; article; attitude; awareness; female; human; human experiment; knowledge; learning; male; skill; stimulus response; tactile stimulation; task performance; training; vestibular stimulation; adolescent; association; cohort analysis; computer interface; depth perception; discrimination learning; military phenomena; psychomotor performance; touch; United States; Adolescent; Adult; Cohort Studies; Cues; Discrimination Learning; Female; Humans; Male; Military Science; Psychomotor Performance; Space Perception; Touch; Touch Perception; United States; User-Computer Interface; Young Adult",Article,"Final","",Scopus,2-s2.0-67650394226
"Moura D., Riecke B.E.","35180048700;6603396361;","Is seeing a virtual environment like seeing the real thing?",2009,"Proceedings - APGV 2009: Symposium on Applied Perception in Graphics and Visualization",,,,"131","",,1,"10.1145/1620993.1621025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70450177638&doi=10.1145%2f1620993.1621025&partnerID=40&md5=cfe77d1795a5271a97ea93dca4ffc17a","Simon Fraser University, Canada","Moura, D., Simon Fraser University, Canada; Riecke, B.E., Simon Fraser University, Canada","Introduction: Immersive virtual environments (IVE) are increasingly used in both fundamental research like experimental psychology and applications such as training, phobia therapy, or entertainment. Ideally, people should be able to perceive and behave in such IVEs as naturally and effectively as in real environments - especially if real-world transfer is desired. Being inherently mobile species, enabling natural spatial orientation and cognition in IVEs is essential. Here, we investigated whether seeing a virtual environment has a similar effect on our spatial cognition and mental spatial representation as a comparable real-world stimulus does - if it does not, how could we assume real-world transfer? Methods: To tackle this question, we closely replicated a realworld study [Riecke and McNamara 2007] in an equivalent virtual environment. In this real world study, Riecke and McNamara asked participants to learn the layout of 15 irregularly arranged target objects in a small rectangular office from one of three different learning orientations (αlearn = 0°, 120°, or 240°). Participants were then blindfolded, disoriented, and wheeled to a different-looking rectangular test room that did not contain any of the target objects. After removing the blindfold, participants were seated to face test orientations αtest = 0°, 120°, or 240° and performed judgement of relative direction tasks: (1) imagine being in the learning room; (2) facing ""X"" (corresponding to To-Be-Imagined facing directions αTBI = 0°, 120°, or 240°); (3) point to ""Y"" (one of the 15 target objects). Analysis of response times and pointing errors indicated that perspective switches were significantly facilitated when (a) to-be-imagined orientations were aligned with the main reference axis of the to-be-imagined room (0°), i.e., αTBI = 0°; (b) to-beimagined orientations matched participants' learning orientation, i.e., αTBI = αlearn; and (c) to-be-imagined orientations matched participants' actual orientation in the test room αTBI = αtest. That is, although the test room did not contain any of the learning objects, facing for example αtest = 120° in the test room facilitated imagining the corresponding orientation αTBI = 120° in the learning room, and interfered specifically with imagining the other orientations αTBI = 240° or αTBI = 0°. To test if we would find similar response patterns (a), (b), and (c) in a comparable virtual environment, we closely replicated this procedure, but used a virtual test room presented on a spherical 180° × 150° video projection (Elumens vision station), as depicted in Figure 1. Twelve naive participants learned the object layout facing αlearn = 120° in a real learning room and were tested with three different orientations αtest = 0°, 120°, and 240° with respect to the virtual test room. Results and Discussion: The data are plotted in Figure 2. As expected, hypothesis (a) and (b) were confirmed: Perspective switches were facilitated when (a) αTBI = 0° and (b) α TBI = αlearn = 120°, corroborating the importance of (a) the room reference axis and (b) the learning orientation in the retrieval of spatial relations from memory. Surprisingly, however, while one's physical orientation in the test room in [Riecke and McNamara 2007] clearly determined which orientations were easier or harder to imagine, we found no such effect when the test room was only visually simulated as an IVE. This suggests that a real-world stimulus has a stronger impact on our mental representation and specifically the retrieval of spatial relations from memory than stimuli presented in immersive virtual reality, at least for the current setup and procedure. We are planning further studies to test if using different IVE displays and 3D models could help to increase the effectiveness of the virtual reality stimulus to real-world levels. In conclusion, despite the immersiveness and large field of view of the current setup, seeing a virtual environment did not have the same effect on our spatial cognition and mental spatial representation as a corresponding real-world stimulus. This suggests that human spatial perception/cognition in real and virtual environments is not necessarily the same. On the one hand, this challenges the often simply assumed effectiveness of current IVE technology. On the other hand, our research can motivate and ideally guide the development of more effective human-computer interfaces that allows for more natural perception and behavior. © 2009 ACM.",,"3D models; Fundamental research; Human computer interfaces; Immersive virtual environments; Immersive virtual reality; Immersiveness; Large field of views; Learning objects; Learning orientation; Mental representations; Mobile species; Pointing errors; Real environments; Real-world; Reference axis; Response patterns; Response time; Spatial cognition; Spatial orientations; Spatial relations; Spatial representations; Target object; Test room; Video projections; Virtual environments; Virtual tests; Education; Facings; Human computer interaction; Targets; Testing; Three dimensional; User interfaces; Visualization; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-70450177638
"Watanuki K.","7005697643;","VR Mediated Skill Transfer",2009,"2008 Proceedings of the ASME International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, DETC 2008","3","PART B",,"1201","1206",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349231311&partnerID=40&md5=1801e164dca2357f0119daf0dedbb256","Department ot Mechanical engineering, Graduate School of Science and Engineering, Saitama University, 255 Shimo-okubo, Sakura-ku, Saitama-shi, Saitama 338-8570, Japan","Watanuki, K., Department ot Mechanical engineering, Graduate School of Science and Engineering, Saitama University, 255 Shimo-okubo, Sakura-ku, Saitama-shi, Saitama 338-8570, Japan","This paper proposes a new virtual reality mediated skill transfer and human resource development system for manufacturing technology and skill, which are composed of the explicit and tacit knowledge transfer systems using synchronized multimedia and the knowledge internalization system using portable virtual environment. In our proposed system, the education content is displayed in the immersive virtual environment, whereby a trainee may experience work in the virtual site operation. Provided that the trainee has gained explicit and tacit knowledge of casting through the multimedia-based knowledge transfer system, the immersive virtual environment catalyzes the internalization of knowledge and also enables the trainee to gain tacit knowledge before undergoing on-the-job training at a real-time operation site. Copyright © 2008 by ASME.",,"Explicit and tacit knowledge; Human resource development; Immersive virtual environments; Knowledge transfer; Manufacturing technologies; On-the-job training; Real-time operation; Site operations; Skill transfer; Tacit knowledge; Virtual environments; Knowledge management; Personnel training; Virtual reality; Multimedia systems",Conference Paper,"Final","",Scopus,2-s2.0-70349231311
"Wuheng Xu Baihua Z., He Y., Zhilin F.","35173940600;57199204941;16178583300;","Effect of navigation aids and landmarks on acquisition of spatial knowledge in virtual environments",2009,"Proceedings - 2009 1st International Workshop on Database Technology and Applications, DBTA 2009",,, 5207823,"30","32",,1,"10.1109/DBTA.2009.152","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449553618&doi=10.1109%2fDBTA.2009.152&partnerID=40&md5=c1d96c197a23b1169928f05c8f31e63a","Psychology Department, Zhejiang University, Hangzhou, China; Zhijiang College, Zhejiang University of Technology, Hangzhou, China","Wuheng Xu Baihua, Z., Psychology Department, Zhejiang University, Hangzhou, China; He, Y., Psychology Department, Zhejiang University, Hangzhou, China; Zhilin, F., Zhijiang College, Zhejiang University of Technology, Hangzhou, China","The effect of navigation aids and landmarks on spatial learning was investigated when participants repeatedly navigated four complex three-dimensional virtual mazes. The study was divided into two main phases: learning and a test of learning transfer. The learning phase consisted of participants directly navigating in one of the four virtual mazes with or without navigation aids and landmarks. Learning transfer was examined by testing navigation tasks in the environment without the use of the navigation aids. Findings show that the combined impact of both navigation aids and landmarks on spatial knowledge acquisition in navigation tasks. © 2009 IEEE.","Navigation; Spatial knowledge; Virtual mazes","Learning phase; Learning Transfer; Navigation aids; Navigation tasks; Spatial knowledge; Spatial learning; Virtual environments; Virtual mazes; Education; Knowledge acquisition; Virtual reality; Navigation",Conference Paper,"Final","",Scopus,2-s2.0-70449553618
"Kaphingst K.A., Persky S., McCall C., Lachance C., Loewenstein J., Beall A.C., Blascovich J.","6602375694;23006054100;18037830200;36798249400;24341813000;7103222399;7003855290;","Testing the effects of educational strategies on comprehension of a genomic concept using virtual reality technology",2009,"Patient Education and Counseling","77","2",,"224","230",,9,"10.1016/j.pec.2009.03.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350084951&doi=10.1016%2fj.pec.2009.03.029&partnerID=40&md5=d2b745ff61e10f600dbb102b967e492e","Social and Behavioral Research Branch, National Human Genome Research Institute, Bethesda, United States; Department of Psychology, University of California-Santa Barbara, Santa Barbara, United States","Kaphingst, K.A., Social and Behavioral Research Branch, National Human Genome Research Institute, Bethesda, United States; Persky, S., Social and Behavioral Research Branch, National Human Genome Research Institute, Bethesda, United States; McCall, C., Department of Psychology, University of California-Santa Barbara, Santa Barbara, United States; Lachance, C., Social and Behavioral Research Branch, National Human Genome Research Institute, Bethesda, United States; Loewenstein, J., Social and Behavioral Research Branch, National Human Genome Research Institute, Bethesda, United States; Beall, A.C., Department of Psychology, University of California-Santa Barbara, Santa Barbara, United States; Blascovich, J., Department of Psychology, University of California-Santa Barbara, Santa Barbara, United States","Objective: Applying genetic susceptibility information to improve health will likely require educating patients about abstract concepts, for which there is little existing research. This experimental study examined the effect of learning mode on comprehension of a genomic concept. Methods: 156 individuals aged 18-40 without specialized knowledge were randomly assigned to either a virtual reality active learning or didactic learning condition. The outcome was comprehension (recall, transfer, mental models). Results: Change in recall was greater for didactic learning than for active learning (p < 0.001). Mean transfer and change in mental models were also higher for didactic learning (p < 0.0001 and p < 0.05, respectively). Believability was higher for didactic learning (p < 0.05), while ratings for motivation (p < 0.05), interest (p < 0.0001), and enjoyment (p < 0.0001) were higher for active learning, but these variables did not mediate the association between learning mode and comprehension. Conclusion: These results show that learning mode affects comprehension, but additional research is needed regarding how and in what contexts different approaches are best for educating patients about abstract concepts. Practice implications: Didactic, interpersonal health education approaches may be more effective than interactive games in educating patients about abstract, unfamiliar concepts. These findings indicate the importance of traditional health education approaches in emerging areas like genomics.","Genetic communication; Genetics; Learning approaches; Patient education","adult; article; attitude to health; comprehension; controlled study; education program; female; genetic susceptibility; happiness; health education; human; knowledge; learning; male; medical research; motivation; normal human; patient education; priority journal; recall; virtual reality; Adolescent; Adult; Analysis of Variance; Comprehension; Computer-Assisted Instruction; Female; Humans; Linear Models; Male; Mental Recall; Models, Educational; Patient Education as Topic; Risk Factors; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-70350084951
"Ziemer C.J., Plumert J.M., Cremer J.F., Kearney J.K.","57203775068;6701849760;7102717840;7101792387;","Estimating distance in real and virtual environments: Does order make a difference?",2009,"Attention, Perception, and Psychophysics","71","5",,"1095","1106",,39,"10.3758/APP.71.5.1096","https://www.scopus.com/inward/record.uri?eid=2-s2.0-68949170650&doi=10.3758%2fAPP.71.5.1096&partnerID=40&md5=02a4c788f67f7c620b0f58d307950d81","University of Iowa, Iowa City, Iowa, United States","Ziemer, C.J., University of Iowa, Iowa City, Iowa, United States; Plumert, J.M., University of Iowa, Iowa City, Iowa, United States; Cremer, J.F., University of Iowa, Iowa City, Iowa, United States; Kearney, J.K., University of Iowa, Iowa City, Iowa, United States","In this investigation, we examined how the order in which people experience real and virtual environments influences their distance estimates. Participants made two sets of distance estimates in one of the following conditions: (1) real environment first, virtual environment second; (2) virtual environment first, real environment second; (3) real environment first, real environment second; or (4) virtual environment first, virtual environment second. In Experiment 1, the participants imagined how long it would take to walk to targets in real and virtual environments. The participants' first estimates were significantly more accurate in the real than in the virtual environment. When the second environment was the same as the first environment (real-real and virtual- virtual), the participants' second estimates were also more accurate in the real than in the virtual environment. When the second environment differed from the first environment (real-virtual and virtual-real), however, the participants' second estimates did not differ significantly across the two environments. A second experiment, in which the participants walked blindfolded to targets in the real environment and imagined how long it would take to walk to targets in the virtual environment, replicated these results. These subtle yet persistent order effects suggest that memory can play an important role in distance perception. © 2009 The Psychonomic Society, Inc.",,"adult; article; computer interface; decision making; distance perception; ego; female; human; imagination; learning; male; orientation; pattern recognition; perceptive discrimination; sensory deprivation; short term memory; walking; Discrimination (Psychology); Distance Perception; Female; Generalization (Psychology); Humans; Imagination; Judgment; Male; Memory, Short-Term; Orientation; Pattern Recognition, Visual; Reality Testing; Reversal Learning; Sensory Deprivation; User-Computer Interface; Walking; Young Adult",Article,"Final","",Scopus,2-s2.0-68949170650
"Kaphingst K.A., Persky S., McCall C., Lachance C., Beall A.C., Blascovich J.","6602375694;23006054100;18037830200;36798249400;7103222399;8914893700;","Testing communication strategies to convey genomic concepts using virtual reality technology",2009,"Journal of Health Communication","14","4",,"384","399",,18,"10.1080/10810730902873927","https://www.scopus.com/inward/record.uri?eid=2-s2.0-67651097625&doi=10.1080%2f10810730902873927&partnerID=40&md5=db7de873613b167f55dad0029ced61d1","National Human Genome Research Institute, Bethesda, MD, United States; University of California, Santa Barbara, CA, United States; National Human Genome Research Institute, Building 31, MSC 2073, 31 Center Drive, Bethesda, MD 20892, United States","Kaphingst, K.A., National Human Genome Research Institute, Bethesda, MD, United States, National Human Genome Research Institute, Building 31, MSC 2073, 31 Center Drive, Bethesda, MD 20892, United States; Persky, S., National Human Genome Research Institute, Bethesda, MD, United States; McCall, C., University of California, Santa Barbara, CA, United States; Lachance, C., National Human Genome Research Institute, Building 31, MSC 2073, 31 Center Drive, Bethesda, MD 20892, United States; Beall, A.C., University of California, Santa Barbara, CA, United States; Blascovich, J., University of California, Santa Barbara, CA, United States","Health professionals need to be able to communicate information about genomic susceptibility in understandable and usable ways, but substantial challenges are involved. We developed four learning modules that varied along two factors: (1) learning mode (active learning vs. didactic learning) and (2) metaphor (risk elevator vs. bridge) and tested them using a 22 between-subjects, repeated measures design. The study used an innovative virtual reality technology experimental platform; four virtual worlds were designed to convey the concept that genetic and behavioral factors interact to affect common disease risk. The primary outcome was comprehension (recall, transfer). Study participants were 42 undergraduates aged 19-23. The results indicated that the elevator metaphor better supported learning of the concept than the bridge metaphor. Mean transfer score was significantly higher for the elevator metaphor (p0.05). Mean change in recall was significantly higher for didactic learning than active learning (p0.05). Mean ratings for variables posited to be associated with better learning (e.g., motivation), however, were generally higher for the active learning worlds. The results suggested that active learning might not always be more effective than didactic learning in increasing comprehension of health information. The findings also indicated that less complex metaphors might convey abstract concepts more effectively.LLC.",,"adult; article; building; clinical article; comprehension; female; genetic risk; genetic susceptibility; genomics; human; learning; literature; male; medical information; motivation; priority journal; recall; virtual reality; Adolescent; Computer-Assisted Instruction; Female; Genetic Predisposition to Disease; Genetics, Medical; Health Education; Humans; Male; User-Computer Interface; Young Adult",Article,"Final","",Scopus,2-s2.0-67651097625
"Persky S., Kaphingst K.A., McCall C., Lachance C., Beall A.C., Blascovich J.","23006054100;6602375694;18037830200;36798249400;7103222399;8914893700;","Presence relates to distinct outcomes in two virtual environments employing different learning modalities.",2009,"Cyberpsychology & behavior : the impact of the Internet, multimedia and virtual reality on behavior and society","12","3",,"263","268",,25,"10.1089/cpb.2008.0262","https://www.scopus.com/inward/record.uri?eid=2-s2.0-68949170691&doi=10.1089%2fcpb.2008.0262&partnerID=40&md5=7ff2969f0b92f9d84cc86850cabfcd5e","National Human Genome Research Institute, Bethesda, Maryland  20892, United States","Persky, S., National Human Genome Research Institute, Bethesda, Maryland  20892, United States; Kaphingst, K.A., National Human Genome Research Institute, Bethesda, Maryland  20892, United States; McCall, C., National Human Genome Research Institute, Bethesda, Maryland  20892, United States; Lachance, C., National Human Genome Research Institute, Bethesda, Maryland  20892, United States; Beall, A.C., National Human Genome Research Institute, Bethesda, Maryland  20892, United States; Blascovich, J., National Human Genome Research Institute, Bethesda, Maryland  20892, United States","Presence in virtual learning environments (VLEs) has been associated with a number of outcome factors related to a user's ability and motivation to learn. The extant but relatively small body of research suggests that a high level of presence is related to better performance on learning outcomes in VLEs. Different configurations of form and content variables such as those associated with active (self-driven, interactive activities) versus didactic (reading or lecture) learning may, however, influence how presence operates and on what content it operates. We compared the influence of presence between two types of immersive VLEs (i.e., active versus didactic techniques) on comprehension and engagement-related outcomes. The findings revealed that the active VLE promoted greater presence. Although we found no relationship between presence and learning comprehension outcomes for either virtual environment, presence was related to information engagement variables in the didactic immersive VLE but not the active environment. Results demonstrate that presence is not uniformly elicited or effective across immersive VLEs. Educational delivery mode and environment complexity may influence the impact of presence on engagement.",,"adolescent; adult; article; attitude to computers; comprehension; computer interface; computer program; cultural anthropology; ego; female; health behavior; health education; human; learning; male; methodology; motivation; questionnaire; risk assessment; social environment; teaching; Adolescent; Adult; Attitude to Computers; Comprehension; Computer-Assisted Instruction; Culture; Female; Health Behavior; Health Education; Humans; Male; Motivation; Probability Learning; Questionnaires; Reality Testing; Risk Assessment; Social Environment; Software Design; Transfer (Psychology); User-Computer Interface; Young Adult",Article,"Final","",Scopus,2-s2.0-68949170691
"Bröker T., Kornadt O.","56033950100;7005304752;","Purposeful problem generation in simulation games - an approach to extend the target group of complex simulation games in engineering education",2009,"Proceedings of the European Conference on Games-based Learning","2009-January",,,"62","67",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938559283&partnerID=40&md5=d4f61550f69d58e0e8f8a4c410094502","Bauhaus-Universität Weimar, Germany","Bröker, T., Bauhaus-Universität Weimar, Germany; Kornadt, O., Bauhaus-Universität Weimar, Germany","Understanding and overseeing complex, interdisciplinary planning correlations in engineering is a difficult task; mastering them is an essential key to successful engineering. Nevertheless discussion of didactic approaches to mediate the necessary skills is quite new to engineering education. While there are implementations of alternative learning methods here and there, a media-compatible integration within the scope of e-learning has been developed only partially. Existing educational software and application of conventional software cover always only parts of the demands on alternative learning scenarios. Contemporary computer games seem to overcome these limitations offering situated learning in authentic contexts. In the course of a literature research today's demands on engineering skills, as well as didactic approaches to achieve them, have been determined. An important aspect here is the differentiation into targeted learning of scientific engineering fundamentals and the complex interrelations in advanced engineering. To transfer these approaches to elearning, contemporary software and its suitability have been examined and compared to the educational aspects of computer games. While computer games combine the advantages and compensate the disadvantages of existing software, they mean an enormous effort of development facing specialised and rather small target groups. This paper outlines an approach to focus certain problems within the simulation core of a computer game. Making them accessible for targeted learning of engineering fundamentals. Using knowledge structure maps, activity of the underlying interactive structure can be guided to the generation of purposeful problems. This way complex simulation games cannot only be applied in graduate but also in undergraduate engineering courses.","Educational use of simulation games; Engineering education; Engineering skills; Ill-structured problem solving; Situated learning","Application programs; Computer games; Computer software; E-learning; Education; Problem solving; Engineering fundamentals; Engineering skills; Ill-structured problem solving; Interdisciplinary planning; Scientific engineering; Simulation games; Situated learning; Undergraduate engineering course; Engineering education",Conference Paper,"Final","",Scopus,2-s2.0-84938559283
"Gordon C.J., Buckley T.","35298827900;7101745351;","The effect of high-fidelity simulation training on medical-surgical graduate nurses' perceived ability to respond to patient clinical emergencies",2009,"Journal of Continuing Education in Nursing","40","11",,"491","498",,95,"10.3928/00220124-20091023-06","https://www.scopus.com/inward/record.uri?eid=2-s2.0-73949112206&doi=10.3928%2f00220124-20091023-06&partnerID=40&md5=2ff928f883a9ac11e437413e5f84b284","Faculty of Nursing, Midwifery and Health, University of Technology, Sydney, NSW, Australia; Faculty of Nursing and Midwifery, University of Sydney, Sydney, NSW, Australia","Gordon, C.J., Faculty of Nursing, Midwifery and Health, University of Technology, Sydney, NSW, Australia; Buckley, T., Faculty of Nursing and Midwifery, University of Sydney, Sydney, NSW, Australia","Background: Recognition of and early intervention for patients with acutely deteriorating conditions is often the responsibility of medical-surgical nurses. Tins study examined the effect of simulation on medical-surgical graduate nurses' perceived ability and confidence in responding to patient clinical emergencies. Method: Fifty medical-surgical graduate students participated in high-fidelity immersive simulations. Questionnaires completed before and after simulation asked participants to rate their perceived ability and confidence. Results: After simulation, participants reported increased confidence in their ability to perform both technical and nontechnical aspects of responding to patient clinical emergencies. Ninety-four percent of participants identified formal debriefing as the most useful aspect of the simulation experience. Conclusion: Medical-surgical graduate nurses' confidence and perceived technical and nontechnical skills during patient clinical emergencies are enhanced following simulation. The ability of graduates to transfer the increased confidence and perceived advanced resuscitation skills following simulation to the clinical environment needs to be investigated.",,"adult; article; Australia; clinical competence; computer interface; education; emergency; evaluation; female; health care quality; health personnel attitude; human; internal medicine; male; methodology; middle aged; nursing; nursing discipline; nursing education; nursing methodology research; nursing student; perioperative nursing; psychological aspect; questionnaire; resuscitation; self concept; standard; teaching; Adult; Attitude of Health Personnel; Cardiopulmonary Resuscitation; Clinical Competence; Computer-Assisted Instruction; Education, Nursing, Graduate; Emergencies; Female; Humans; Internal Medicine; Male; Middle Aged; New South Wales; Nursing Education Research; Nursing Methodology Research; Perioperative Nursing; Program Evaluation; Questionnaires; Self Efficacy; Specialties, Nursing; Students, Nursing; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-73949112206
"Winterbottom C., Blake E.","10045558800;7006460560;","Constructivism, virtual reality and tools to support design",2008,"Proceedings of the Conference on Designing Interactive Systems: Processes, Practices, Methods, and Techniques, DIS",,,,"230","239",,6,"10.1145/1394445.1394470","https://www.scopus.com/inward/record.uri?eid=2-s2.0-57549105879&doi=10.1145%2f1394445.1394470&partnerID=40&md5=c767905b5fc4c5bdd0abe0b36aa586eb","Collaborative Visual Computing Lab., Department of Computer Science, University of Cape Town","Winterbottom, C., Collaborative Visual Computing Lab., Department of Computer Science, University of Cape Town; Blake, E., Collaborative Visual Computing Lab., Department of Computer Science, University of Cape Town","This paper describes a process for creating a design tool, which is based in constructivism. The process is described for the creation of a tool to help novices in designing virtual environment interactions, however it can be generalized to other design domains. The process consists of four steps: first constructivist values of atomic simplicity, multiplicity, exploration, control and reflection are distilled. Next, expert practices are researched and reframed in terms of the constructivist values. Thirdly, novice processes are examined and understood in constructivist terms. Lastly, prototypes are created and shown to target users. These steps are iterated until the designed tool is satisfactory. Copyright 2008 ACM.","Design,; Human Factor","Design domains; Design tools; Human Factor; Support designs; Virtual environments; Human engineering; Virtual reality; Design",Conference Paper,"Final","",Scopus,2-s2.0-57549105879
"Watanuki K.","7005697643;","VR mediated skill transfer",2008,"Proceedings of the ASME Design Engineering Technical Conference","3","PARTS A AND B",,"1201","1206",,,"10.1115/DETC2008-50153","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81155151261&doi=10.1115%2fDETC2008-50153&partnerID=40&md5=389843d2abb564099c06685d883feeeb","Department of Mechanical Engineering, Graduate School of Science and Engineering, Saitama University, 255 Shimo-okubo, Sakura-ku, Saitama-shi, Saitama 338-8570, Japan","Watanuki, K., Department of Mechanical Engineering, Graduate School of Science and Engineering, Saitama University, 255 Shimo-okubo, Sakura-ku, Saitama-shi, Saitama 338-8570, Japan","This paper proposes a new virtual reality mediated skill transfer and human resource development system for manufacturing technology and skill, which are composed of the explicit and tacit knowledge transfer systems using synchronized multimedia and the knowledge internalization system using portable virtual environment. In our proposed system, the education content is displayed in the immersive virtual environment, whereby a trainee may experience work in the virtual site operation. Provided that the trainee has gained explicit and tacit knowledge of casting through the multimedia-based knowledge transfer system, the immersive virtual environment catalyzes the internalization of knowledge and also enables the trainee to gain tacit knowledge before undergoing on-the-job training at a real-time operation site. Copyright © 2008 by ASME.",,"Explicit and tacit knowledge; Human resource development; Immersive virtual environments; Knowledge transfer; Manufacturing technologies; On-the-job training; Real-time operation; Site operations; Skill transfer; Tacit knowledge; Design; Knowledge management; Manufacture; Multimedia systems; Personnel training; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-81155151261
"Kurillo G., Vasudevan R., Lobaton E., Bajcsy R.","16426116000;55405414900;24450724500;7006078015;","A framework for collaborative real-time 3D teleimmersion in a geographically distributed environment",2008,"Proceedings - 10th IEEE International Symposium on Multimedia, ISM 2008",,, 4741155,"111","118",,20,"10.1109/ISM.2008.32","https://www.scopus.com/inward/record.uri?eid=2-s2.0-62949111967&doi=10.1109%2fISM.2008.32&partnerID=40&md5=6d378870718796b3c7115f15f594a261","Department of Electrical Engineering and Computer Science, University of California, Berkeley, United States","Kurillo, G., Department of Electrical Engineering and Computer Science, University of California, Berkeley, United States; Vasudevan, R., Department of Electrical Engineering and Computer Science, University of California, Berkeley, United States; Lobaton, E., Department of Electrical Engineering and Computer Science, University of California, Berkeley, United States; Bajcsy, R., Department of Electrical Engineering and Computer Science, University of California, Berkeley, United States","In this paper, we present a framework for immersive 3D video conferencing and geographically distributed collaboration. Our multi-camera system performs a full-body 3D reconstruction of users in real time and renders their image in a virtual space allowing remote interaction between users and the virtual environment. The paper features an overview of the technology and algorithms used for calibration, capturing, and reconstruction. We introduce stereo mapping using adaptive triangulation which allows for fast (under 25 ms) and robust real-time 3D reconstruction. The chosen representation of the data provides high compression ratios for transfer to a remote site. The algorithm produces partial 3D meshes, instead of dense point clouds, which are combined on the renderer to create a unified model of the user. We have successfully demonstrated the use of our system in various applications such as remote dancing and immersive Tai Chi learning. © 2008 IEEE.",,"3-D reconstruction; 3D meshes; 3d tele immersions; 3d video conferencing; Chosen representations; Distributed collaborations; Distributed environments; Full bodies; High compression ratios; Immersive; Multi-camera systems; Point clouds; Real time; Real-time 3D reconstruction; Remote interactions; Remote sites; Stereo mappings; Unified models; Virtual environments; Virtual spaces; Data compression; Image reconstruction; Restoration; Three dimensional; Video conferencing; Virtual reality; Three dimensional computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-62949111967
"Wallet G., Sauzéon H., Rodrigues J., N'Kaoua B.","26425357400;7801452039;26425235600;6603602499;","Use of virtual reality for spatial knowledge transfer: Effects of passive/active exploration mode in simple and complex routes for three different recall tasks",2008,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,,,"175","178",,16,"10.1145/1450579.1450616","https://www.scopus.com/inward/record.uri?eid=2-s2.0-63449111218&doi=10.1145%2f1450579.1450616&partnerID=40&md5=7279e09ccb4ba787ab482edebafc0561","Laboratoire Cognition et Facteurs Humains, EA 487, Institut de Cognitique, Universitś Victor Segalen Bordeaux II, France","Wallet, G., Laboratoire Cognition et Facteurs Humains, EA 487, Institut de Cognitique, Universitś Victor Segalen Bordeaux II, France; Sauzéon, H., Laboratoire Cognition et Facteurs Humains, EA 487, Institut de Cognitique, Universitś Victor Segalen Bordeaux II, France; Rodrigues, J., Laboratoire Cognition et Facteurs Humains, EA 487, Institut de Cognitique, Universitś Victor Segalen Bordeaux II, France; N'Kaoua, B., Laboratoire Cognition et Facteurs Humains, EA 487, Institut de Cognitique, Universitś Victor Segalen Bordeaux II, France","The use of virtual reality in the area of spatial cognition raises the question of the quality of learning transfer from a virtual to a real environment. Among the challenges, one is to determine the best cognitive aids to improve the quality of transfer and the conditions in which this is best achieved. The purpose of this study was to investigate the impact of passive and active exploration mode on quality of transfer in three different spatial recall tasks when the route was simple or complex. Ninety subjects (45 men and 45 women) participated in the experiment. Spatial learning was evaluated by 3 tasks: Wayfinding (route reproduction in reality), Sketch-mapping (free hand drawing) and Scene-classification (make a series of pictures in chronological order) in the context of the district of Bordeaux. In the Wayfinding task, active learning in a Virtual Environment (VE) increased performances compared to the passive learning condition, irrespective of the route complexity factor. In the Sketch-mapping task, active learning in a VE induced better performances than the passive condition, but only for complex routes. In the Picture classification task, no benefit was observed from active learning with both simple and complex routes. These results are discussed in terms of the functional demands of the three tasks and the route complexity dimension. Copyright 2008 ACM.","Exploration mode; Knowledge transfer; Recall tasks; Route complexity; Spatial cognition; Virtual reality","Exploration mode; Knowledge transfer; Recall tasks; Route complexity; Spatial cognition; Education; Knowledge management; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-63449111218
"Quarles J., Lampotang S., Fischler I., Fishwick P., Lok B.","55868360300;35587861100;35588972600;56252883400;57203616548;","A mixed reality approach for merging abstract and concrete knowledge",2008,"Proceedings - IEEE Virtual Reality",,, 4480746,"27","34",,24,"10.1109/VR.2008.4480746","https://www.scopus.com/inward/record.uri?eid=2-s2.0-50349097941&doi=10.1109%2fVR.2008.4480746&partnerID=40&md5=e541bedde2a5a643d1d30ad169d0dd8d","Dept. of CISE, University of Florida; Dept. of Anesthesiology, University of Florida; Dept. of Psychology, University of Florida","Quarles, J., Dept. of CISE, University of Florida; Lampotang, S., Dept. of Anesthesiology, University of Florida; Fischler, I., Dept. of Psychology, University of Florida; Fishwick, P., Dept. of CISE, University of Florida; Lok, B., Dept. of CISE, University of Florida","Mixed reality's (MR) ability to merge real and virtual spaces is applied to merging different knowledge types, such as abstract and concrete knowledge. To evaluate whether the merging of knowledge types can benefit learning, MR was applied to an interesting problem in anesthesia machine education. The Virtual Anesthesia Machine (VAM) is an interactive, abstract 2D transparent reality [14] simulation of the internal components and invisible gas flows of an anesthesia machine. It is widely used in anesthesia education. However when presented with an anesthesia machine, some students have difficulty transferring abstract VAM knowledge to the concrete real device. This paper presents the Augmented Anesthesia Machine (AAM). The AAM applies a magic-lens approach to combine the VAM simulation and a real anesthesia machine. The AAM allows students to interact with the real anesthesia machine while visualizing how these interactions affect the internal components and invisible gas flows in the real world context. To evaluate the AAM's learning benefits, a user study was conducted. Twenty participants were divided into either the VAM (abstract only) or AAM (concrete+abstract) conditions. The results of the study show that MR can help users bridge their abstract and concrete knowledge, thereby improving their knowledge transfer into real world domains. © 2008 IEEE.","Anesthesiology; Mixed reality; Modeling and simulation; Psychology; User studies","Gas flowing; Interesting problem; Knowledge transfer; Knowledge types; Mixed reality; Modeling and simulation; Psychology; Real-world; Real-world domains; User studies; Virtual spaces; Abstracting; Aerodynamics; Anesthesiology; Concrete construction; Education; Flow of gases; Gas dynamics; Information management; Knowledge management; Merging; Students; Virtual reality; Machine components",Conference Paper,"Final","",Scopus,2-s2.0-50349097941
"Dias P., Campos G., Santos V., Casaleiro R., Seco R., Santos B.S.","22333370800;8603962700;35616433200;24477040900;24477807400;7006476948;","3D reconstruction and Auralisation of the ""painted dolmen"" of antelas",2008,"Proceedings of SPIE - The International Society for Optical Engineering","6805",, 68050Y,"","",,2,"10.1117/12.766607","https://www.scopus.com/inward/record.uri?eid=2-s2.0-47949110073&doi=10.1117%2f12.766607&partnerID=40&md5=8cf6b741616e6b2cc561071a4c67c4e0","DETI - Dep. de Electrónica, Telecomunicações e Informática, Univ. of Aveiro, Portugal; IEETA - Instituto de Engenharia Electrónica e Telemática de Aveiro, Portugal; Departamento de Engenharia Mecânica, Univ. of Aveiro, Aveiro, Portugal","Dias, P., DETI - Dep. de Electrónica, Telecomunicações e Informática, Univ. of Aveiro, Portugal, IEETA - Instituto de Engenharia Electrónica e Telemática de Aveiro, Portugal; Campos, G., DETI - Dep. de Electrónica, Telecomunicações e Informática, Univ. of Aveiro, Portugal, IEETA - Instituto de Engenharia Electrónica e Telemática de Aveiro, Portugal; Santos, V., Departamento de Engenharia Mecânica, Univ. of Aveiro, Aveiro, Portugal; Casaleiro, R., DETI - Dep. de Electrónica, Telecomunicações e Informática, Univ. of Aveiro, Portugal; Seco, R., DETI - Dep. de Electrónica, Telecomunicações e Informática, Univ. of Aveiro, Portugal; Santos, B.S., DETI - Dep. de Electrónica, Telecomunicações e Informática, Univ. of Aveiro, Portugal, IEETA - Instituto de Engenharia Electrónica e Telemática de Aveiro, Portugal","This paper presents preliminary results on the development of a 3D audiovisual model of the Anta Pintada (painted dolmen) of Antelas, a Neolithic chamber tomb located in Oliveira de Frades and listed as Portuguese national monument. The final aim of the project is to create a highly accurate Virtual Reality (VR) model of this unique archaeological site, capable of providing not only visual but also acoustic immersion based on its actual geometry and physical properties. The project started in May 2006 with in situ data acquisition. The 3D geometry of the chamber was captured using a Laser Range Finder. In order to combine the different scans into a complete 3D visual model, reconstruction software based on the Iterative Closest Point (ICP) algorithm was developed using the Visualization Toolkit (VTK). This software computes the boundaries of the room on a 3D uniform grid and populates its interior with ""free-space nodes"", through an iterative algorithm operating like a torchlight illuminating a dark room. The envelope of the resulting set of ""free-space nodes"" is used to generate a 3D iso-surface approximating the interior shape of the chamber. Each polygon of this surface is then assigned the acoustic absorption coefficient of the corresponding boundary material. A 3D audiovisual model operating in real-time was developed for a VR Environment comprising head-mounted display (HMD) I-glasses SVGAPro, an orientation sensor (tracker) InterTrax 2 with 3 Degrees Of Freedom (3DOF) and stereo headphones. The auralisation software is based on a geometric model. This constitutes a first approach, since geometric acoustics have well-known limitations in rooms with irregular surfaces. The immediate advantage lies in their inherent computational efficiency, which allows real-time operation. The program computes the early reflections forming the initial part of the chamber's impulse response (IR), which carry the most significant cues for source localisation. These early reflections are processed through Head Related Transfer Functions (HRTF) updated in real-time according to the orientation of the user's head, so that sound waves appear to come from the correct location in space, in agreement with the visual scene. The late-reverberation tail of the IR is generated by an algorithm designed to match the reverberation time of the chamber, calculated from the actual acoustic absorption coefficients of its surfaces. The sound output to the headphones is obtained by convolving the IR with anechoic recordings of the virtual audio source. © 2008 SPIE-IS&T.","3D acquisition; Augmented reality; Auralisation; Laser range finder; Virtual reality","Absorption; Acoustic wave absorption; Acoustics; Architectural acoustics; Audio acoustics; Computational efficiency; Display devices; Energy absorption; Functions; Headphones; Helmet mounted displays; Image reconstruction; Imaging systems; Impulse response; Lasers; Loudspeakers; Medical imaging; Mergers and acquisitions; Range finders; Range finding; Reflection; Restoration; Reverberation; Surfaces; Three dimensional computer graphics; Virtual reality; 3D acquisition; 3D geometries; 3D reconstructions; 3d visual models; Acoustic absorption coefficients; Archaeological sites; Audio sources; Audio visuals; Augmented reality; Auralisation; Dark rooms; Geometric acoustics; Geometric models; Head Related Transfer Functions; In-situ; Irregular surfaces; Iterative algorithms; Iterative Closest points; Laser range finder; Orientation sensors; Reconstruction softwares; Reverberation times; Software computes; Sound waves; Source localisation; Stereo headphones; Uniform grids; Visual scenes; Visualization toolkits; Three dimensional",Conference Paper,"Final","",Scopus,2-s2.0-47949110073
"Schwebel D.C., Gaines J., Severson J.","6603681532;16549524400;13403919100;","Validation of virtual reality as a tool to understand and prevent child pedestrian injury",2008,"Accident Analysis and Prevention","40","4",,"1394","1400",,121,"10.1016/j.aap.2008.03.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-46249129438&doi=10.1016%2fj.aap.2008.03.005&partnerID=40&md5=93cd98c52a030d9e3a160d4a32866cb3","Department of Psychology, University of Alabama at Birmingham, 1300 University Boulevard, CH 415, Birmingham, AL 35294, United States; Digital Artefacts, LLC, Iowa City, IA, United States","Schwebel, D.C., Department of Psychology, University of Alabama at Birmingham, 1300 University Boulevard, CH 415, Birmingham, AL 35294, United States; Gaines, J., Department of Psychology, University of Alabama at Birmingham, 1300 University Boulevard, CH 415, Birmingham, AL 35294, United States; Severson, J., Digital Artefacts, LLC, Iowa City, IA, United States","In recent years, virtual reality has emerged as an innovative tool for health-related education and training. Among the many benefits of virtual reality is the opportunity for novice users to engage unsupervised in a safe environment when the real environment might be dangerous. Virtual environments are only useful for health-related research, however, if behavior in the virtual world validly matches behavior in the real world. This study was designed to test the validity of an immersive, interactive virtual pedestrian environment. A sample of 102 children and 74 adults was recruited to complete simulated road-crossings in both the virtual environment and the identical real environment. In both the child and adult samples, construct validity was demonstrated via significant correlations between behavior in the virtual and real worlds. Results also indicate construct validity through developmental differences in behavior; convergent validity by showing correlations between parent-reported child temperament and behavior in the virtual world; internal reliability of various measures of pedestrian safety in the virtual world; and face validity, as measured by users' self-reported perception of realism in the virtual world. We discuss issues of generalizability to other virtual environments, and the implications for application of virtual reality to understanding and preventing pediatric pedestrian injuries. © 2008 Elsevier Ltd. All rights reserved.","Children; Pedestrian injury; Pedestrian safety; Simulation; Validity; Virtual reality","Correlation methods; Health; Pedestrian safety; Weight control; Child pedestrians; Construct validity; Convergent validity; Education and training; Elsevier (CO); Generalizability; Immersive; Pedestrian injuries; Real environments; Real world; Virtual environment (VE); Virtual environments (VE); Virtual world (VW); Virtual reality; adolescent; adult; article; child; child behavior; clinical trial; computer interface; controlled clinical trial; controlled study; distance perception; female; health education; human; injury; male; methodology; middle aged; randomized controlled trial; reproducibility; task performance; traffic accident; walking; Accidents, Traffic; Adolescent; Adult; Child; Child Behavior; Distance Perception; Female; Health Education; Humans; Male; Middle Aged; Reproducibility of Results; Task Performance and Analysis; User-Computer Interface; Walking; Wounds and Injuries",Article,"Final","",Scopus,2-s2.0-46249129438
"Lietsch S., Zabel H., Berssenbruegge J.","15136225100;15137714700;24340966700;","Computational steering of interactive and distributed Virtual Reality applications",2008,"2007 Proceedings of the ASME International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, DETC2007","2 PART B",,,"1023","1032",,2,"10.1115/DETC2007-34550","https://www.scopus.com/inward/record.uri?eid=2-s2.0-44849094437&doi=10.1115%2fDETC2007-34550&partnerID=40&md5=7035f6d83c381144f0fccf1277dd3d06","Paderborn Center for Parallel Computing, University of Paderborn, Paderborn, NRW 33102, Germany; C-Lab, University of Paderborn, Paderborn, NRW 33102, Germany; Heinz Nixdorf Institute, University of Paderborn, Paderborn, NRW 33102, Germany","Lietsch, S., Paderborn Center for Parallel Computing, University of Paderborn, Paderborn, NRW 33102, Germany; Zabel, H., C-Lab, University of Paderborn, Paderborn, NRW 33102, Germany; Berssenbruegge, J., Heinz Nixdorf Institute, University of Paderborn, Paderborn, NRW 33102, Germany","In this paper we present a system that transfers the well-known computational steering paradigm to interactive and distributed Virtual Reality applications. Those are often used in areas like rapid prototyping and all kinds of vehicle simulation. The distribution has many different purposes and affects various subsystems of a VR application. Most of the currently existing systems are very specialized and have a proprietary design for data-exchange and coupling of the components. We propose a more flexible approach by designing a computational steering framework that is well-adapted to the needs of highly interactive and distributed VR systems. Thereby we achieve higher reusability and scalability for the steering component itself as well as the possibility to exchange and compare subsystems. As a proof-of-concept we adapted an existing driving simulator to the proposed computational steering framework and discuss the advantages and difficulties in the second part of the paper. Copyright © 2007 by ASME.",,"Computational steering; Data exchange (DX); Distributed virtual reality; Driving simulators; Existing systems; International designs; Proof-of-concept (POC); prototyping; Technical conferences; vehicle simulation; VR systems; Architectural design; Automobile parts and equipment; Automobile simulators; Automobile steering equipment; Computational methods; Computer networks; Computers; Concurrent engineering; Engineering; Job analysis; Paper; Product development; Rapid prototyping; Steering; Virtual reality; Technology",Conference Paper,"Final","",Scopus,2-s2.0-44849094437
"Rosen K.R.","35546116600;","The history of medical simulation",2008,"Journal of Critical Care","23","2",,"157","166",,242,"10.1016/j.jcrc.2007.12.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-44449132188&doi=10.1016%2fj.jcrc.2007.12.004&partnerID=40&md5=f756ae03e80d631a594d0476ad1d2d05","Department of Anesthesiology, Case Western Reserve University School of Medicine, Cleveland, OH 44106, United States","Rosen, K.R., Department of Anesthesiology, Case Western Reserve University School of Medicine, Cleveland, OH 44106, United States","The historical roots of simulation might be described with the broadest definition of medical simulation: ""an imitation of some real thing, state of affairs, or process"" for the practice of skills, problem solving, and judgment. From the first ""blue box"" flight simulator to the military's impetus in the transfer of modeling and simulation technology to medicine, worldwide acceptance of simulation training is growing. Large collaborative simulation centers support the expectation of increases in multidisciplinary, interprofessional, and multimodal simulation training. Virtual worlds, both immersive and Web-based, are at the frontier of innovation in medical education. © 2008 Elsevier Inc. All rights reserved.","Flight simulation; Link trainer; Manikin; Mannequin; Medical simulation; Patient simulation; Programmed patient; Standardized patient; Virtual reality; Web-based simulation","article; aviation; computer program; education program; human; medical education; problem solving; professional competence; simulation; training; virtual reality; Education, Medical; History, 20th Century; History, 21st Century; Manikins; Patient Simulation; United States",Article,"Final","",Scopus,2-s2.0-44449132188
"Bossard C., Kermarrec G., Buche C., Tisseau J.","14041141200;6507390430;8349259000;6603486416;","Transfer of learning in virtual environments: A new challenge?",2008,"Virtual Reality","12","3",,"151","161",,38,"10.1007/s10055-008-0093-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-51549098199&doi=10.1007%2fs10055-008-0093-y&partnerID=40&md5=15bf4f1b075d8df2e6176ea6eac87bbf","LISyC UEB UBO-ENIB-ENSIETA, European Center for Virtual Reality, 25 rue Claude Chappe, 38, Plouzané 29280, France","Bossard, C., LISyC UEB UBO-ENIB-ENSIETA, European Center for Virtual Reality, 25 rue Claude Chappe, 38, Plouzané 29280, France; Kermarrec, G., LISyC UEB UBO-ENIB-ENSIETA, European Center for Virtual Reality, 25 rue Claude Chappe, 38, Plouzané 29280, France; Buche, C., LISyC UEB UBO-ENIB-ENSIETA, European Center for Virtual Reality, 25 rue Claude Chappe, 38, Plouzané 29280, France; Tisseau, J., LISyC UEB UBO-ENIB-ENSIETA, European Center for Virtual Reality, 25 rue Claude Chappe, 38, Plouzané 29280, France","The aim of all education is to apply what we learn in different contexts and to recognise and extend this learning to new situations. Virtual learning environments can be used to build skills. Recent research in cognitive psychology and education has shown that acquisitions are linked to the initial context. This provides a challenge for virtual reality in education or training. A brief overview of transfer issues highlights five main ideas: (1) the type of transfer enables the virtual environment (VE) to be classified according to what is learned; (2) the transfer process can create conditions within the VE to facilitate transfer of learning; (3) specific features of VR must match and comply with transfer of learning; (4) transfer can be used to assess a VE's effectiveness; and (5) future research on transfer of learning must examine the singular context of learning. This paper discusses how new perspectives in cognitive psychology influence and promote transfer of learning through the use of VEs. © Springer-Verlag London Limited 2008.","Learning models; Training; Transfer of learning; Virtual environment","Virtual reality; Learning models; Training; Transfer of learning; Virtual environment; Education",Article,"Final","",Scopus,2-s2.0-51549098199
"Rive P., Thomassen A., Billinghurst M., Lyons M.","26022096200;35086965300;7006142663;26021931200;","Face to face with the white rabbit - Sharing ideas in second life",2008,"IEEE International Professional Communication Conference",,, 4610236,"","",,4,"10.1109/ipcc.2008.4610236","https://www.scopus.com/inward/record.uri?eid=2-s2.0-58649124511&doi=10.1109%2fipcc.2008.4610236&partnerID=40&md5=f5e8c7b28949bd1b0763a8199f45c008","Victoria University, Wellington, New Zealand; University of Canterbury, New Zealand","Rive, P., Victoria University, Wellington, New Zealand; Thomassen, A., Victoria University, Wellington, New Zealand; Billinghurst, M., University of Canterbury, New Zealand; Lyons, M., Victoria University, Wellington, New Zealand","The popular virtual world, Second Life, presents a number of opportunities and limitations for the sharing of ideas in the information economy. In this paper w e ask the question, 'to what extent can Second Life simulate an actual face-to-face meeting?' Many authors have written that tacit knowledge transfer requires face-to-face meetings, however, virtual reality technology can provide tools that enable people to show facial expressions, body language and concepts in graphical form. In this way it is possible to use computer mediated communication to convey nonverbal information that would no rmally be very difficult to share remotely. In this paper we explore how closely Second Life can simulate actual face-to-face communication. We give examples of lessons learned from students learning in Second Life, and make recommendations on how to support natural communication in online environments. © 2008 IEEE.","Nonverbal communications; Presence; Second Life; Tacit knowledge; Virtual world","Knowledge management; Virtual reality; Non-verbal communications; Presence; Second Life; Tacit knowledge; Virtual worlds; Interactive computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-58649124511
"Watanuki K.","7005697643;","Virtual reality-based casting skill transfer and human resource development",2007,"Proceedings 17th International Conference on Artificial Reality and Telexistence, ICAT 2007",,, 4414664,"316","317",,,"10.1109/ICAT.2007.60","https://www.scopus.com/inward/record.uri?eid=2-s2.0-48349099324&doi=10.1109%2fICAT.2007.60&partnerID=40&md5=ce4c36970f0577001d058a30a0cfa1ea","Department of Mechanical Engineering, Graduate School of Science and Engineering, Saitama University","Watanuki, K., Department of Mechanical Engineering, Graduate School of Science and Engineering, Saitama University","This paper proposes a new virtual reality-based skill transfer and human resource development system for casting design, which is composed of the explicit and tacit knowledge transfer systems using synchronized multimedia and the knowledge internalization system using portable virtual environment. In our proposed system, the education content is displayed in the immersive virtual environment, whereby a trainee may experience work in the virtual site operation. Provided that the trainee has gained explicit and tacit knowledge of casting through the multimedia-based knowledge transfer system, the immersive virtual environment catalyzes the internalization of knowledge and also enables the trainee to gain tacit knowledge before undergoing onthe-job training at a real-time operation site. © 2007 IEEE.",,"Casting designs; Human resource development; Immersive virtual environment; International conferences; Knowledge internalization; Knowledge transfer; Real-time operations; Skill transfer; Tacit knowledge; Virtual environment; Information management; Knowledge management; Multimedia systems; Personnel; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-48349099324
"Yang Z., Wu W., Nahrstedt K., Kurillo G., Bajcsy R.","57203490399;23135785500;7006456800;16426116000;7006078015;","ViewCast: View dissemination and management for multi-party 3d tele-immersive environments",2007,"Proceedings of the ACM International Multimedia Conference and Exhibition",,,,"882","891",,37,"10.1145/1291233.1291434","https://www.scopus.com/inward/record.uri?eid=2-s2.0-37849007588&doi=10.1145%2f1291233.1291434&partnerID=40&md5=563342bbc5b2828f23d8d80e54184f65","University of Illinois at Urbana-Champaign, Department of Computer Science, 201 N. Goodwin, Urbana, IL 61801, United States; University of California at Berkeley, Department of Electrical Engineering and Computer Sciences, 253 Cory Hall, Berkeley, CA 94720, United States","Yang, Z., University of Illinois at Urbana-Champaign, Department of Computer Science, 201 N. Goodwin, Urbana, IL 61801, United States; Wu, W., University of Illinois at Urbana-Champaign, Department of Computer Science, 201 N. Goodwin, Urbana, IL 61801, United States; Nahrstedt, K., University of Illinois at Urbana-Champaign, Department of Computer Science, 201 N. Goodwin, Urbana, IL 61801, United States; Kurillo, G., University of California at Berkeley, Department of Electrical Engineering and Computer Sciences, 253 Cory Hall, Berkeley, CA 94720, United States; Bajcsy, R., University of California at Berkeley, Department of Electrical Engineering and Computer Sciences, 253 Cory Hall, Berkeley, CA 94720, United States","Real-time distributed multi-party/multi-stream systems are becoming more popular in many areas such as 3D tele-immersion, multi-camera conferencing and security surveillance. However, the construction of such systems in large scale is impeded by the huge demand of computing and networking resources and the lack of a simple yet powerful networking model to handle interconnection, scalability and quality of service (QoS) guarantees. We make two main contributions in the paper: (1) we propose a novel generalized ViewCast model for multi-party/multi-stream video-mediated systems that fills the gap between high-level user interest and low level per-stream management, and (2) we demonstrate the ViewCast model by applying it to the multi-party 3D Tele-Immersive (3DTI) collaboration among geographically dispersed users. More specifically, we show how the ViewCast model is used in supporting stream data dissemination, coordination and QoS management among multiple 3D tele-immersive environments. We present our experimental results in both real implementation and simulation to show that our ViewCast-based solution achieves high efficiency, scalability, and quality in supporting multi-party 3DTI collaboration. Copyright 2007 ACM.","3D tele-immersion; Adaptation; Coordination; Distributed application; Multicast; Network protocols","Computer simulation; Information management; Multicasting; Network protocols; Quality of service; Scalability; 3D teleimmersion; Distributed application; Security surveillance; ViewCast model; Information dissemination",Conference Paper,"Final","",Scopus,2-s2.0-37849007588
"Samur E., Wang F., Spaelter U., Bleuler H.","15078751300;57208612746;24342359800;6603849726;","Generic and systematic evaluation of haptic interfaces based on testbeds",2007,"IEEE International Conference on Intelligent Robots and Systems",,, 4399522,"2113","2119",,32,"10.1109/IROS.2007.4399522","https://www.scopus.com/inward/record.uri?eid=2-s2.0-51449118588&doi=10.1109%2fIROS.2007.4399522&partnerID=40&md5=0d4f95213f433f42affddc4d28565721","Laboratory of Robotic Systems, Ecole Polytechnique Fédérale de Lausanne (EPFL), Switzerland","Samur, E., Laboratory of Robotic Systems, Ecole Polytechnique Fédérale de Lausanne (EPFL), Switzerland; Wang, F., Laboratory of Robotic Systems, Ecole Polytechnique Fédérale de Lausanne (EPFL), Switzerland; Spaelter, U., Laboratory of Robotic Systems, Ecole Polytechnique Fédérale de Lausanne (EPFL), Switzerland; Bleuler, H., Laboratory of Robotic Systems, Ecole Polytechnique Fédérale de Lausanne (EPFL), Switzerland","The purpose of evaluation procedures is to achieve both qualitative and quantitative statements on haptic rendering realism and performance. Since a haptic interface provides an interaction between a user and a virtual environment, fidelity of a haptic interface directly affects the performance. To our knowledge, a standard, generic and reusable validation method which comprehensively addresses all the attributes of haptic feedback has not been realized yet. Despite the large number of human factor studies, only few of them have been proposed as well for haptic interface performance measurements. For this reason, we review validation procedures for haptic rendering and propose an evaluation method based on testbeds to obtain a systematic haptic interface assessment. We integrated the approaches of human factor studies into the testbeds to obtain a simple and yet complete measure of human-machine interaction performance. The testbeds were tested on a haptic interface, the IHP of Xitact SA, and performance results are presented. In the testbeds, performance metrics for generic haptic interaction tasks are expressed in terms of information transfer (bits) and sensory thresholds which are indeed device specific benchmark metrics. Thus, the suitability of a haptic interface for a defined task can be verified, device comparisons become possible and the obtained information can be used to identify possible improvements. ©2007 IEEE.",,"Flow interactions; Human engineering; Intelligent robots; Intelligent systems; Robotics; Virtual reality; Test-beds; Haptic interfaces",Conference Paper,"Final","",Scopus,2-s2.0-51449118588
"Tichon J.G.","6603714327;","Using presence to improve a virtual training environment",2007,"Cyberpsychology and Behavior","10","6",,"781","787",,29,"10.1089/cpb.2007.0005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-37249061332&doi=10.1089%2fcpb.2007.0005&partnerID=40&md5=e58ec17a6ee1504ce8eae0304ecbc29d","Perception and Motor Systems Laboratory, University of Queensland, Brisbane, QLD, Australia; Perception and Motor Systems Laboratory, University of Queensland, Building 26, Brisbane, QLD 4072, Australia","Tichon, J.G., Perception and Motor Systems Laboratory, University of Queensland, Brisbane, QLD, Australia, Perception and Motor Systems Laboratory, University of Queensland, Building 26, Brisbane, QLD 4072, Australia","In the rail industry, drivers must be trained to operate complex heavy machinery while responding appropriately to rapidly unfolding events in environments that are expensive and often dangerous to replicate in the real world. Virtual training environments (VTEs) can deliver stress exposure training to improve the decision-making skills of train drivers. Higher levels of recallable knowledge in the real world have been linked directly to the degree to which trainees have been engrossed in their VTE, an experience often measured through the concept of ""presence."" This paper reports on the use of presence to guide improvements to a VTE developed to deliver driver training in degraded track conditions. Two surveys were used to collect data on train drivers' introspective feedback on the level of presence created by the virtual rail environment and the simulator's effectiveness in generating immersion across a range of presence causal factors. Results indicate that using presence to investigate VTEs has practical significance. Outcomes provide direct information on where future improvements and modifications to the VTE can be made. © 2007 Mary Ann Liebert, Inc.",,"adult; article; computer simulation; driving ability; human; introspection; male; normal human; railway; stress management; training; virtual reality; Accidents, Occupational; Adult; Attention; Computer Simulation; Computer-Assisted Instruction; Humans; Male; Middle Aged; Practice (Psychology); Railroads; Safety Management; Transfer (Psychology); User-Computer Interface",Article,"Final","",Scopus,2-s2.0-37249061332
"Dekker A., Champion E.","35241961600;13006810600;","Please biofeed the zombies: Enhancing the gameplay and display of a horror game using biofeedback",2007,"3rd Digital Games Research Association International Conference: ""Situated Play"", DiGRA 2007",,,,"550","558",,58,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-52249118221&partnerID=40&md5=25d3a297e36c945a31b818294abd26dc","Interaction Design, School of ITEE, University of Queensland, Ipswich, Australia; Media Arts, COFA, UNSW, PO Box 259, Paddington, NSW 2021, Australia","Dekker, A., Interaction Design, School of ITEE, University of Queensland, Ipswich, Australia; Champion, E., Media Arts, COFA, UNSW, PO Box 259, Paddington, NSW 2021, Australia","This paper describes an investigation into how real-time but low-cost biometric information can be interpreted by computer games to enhance gameplay without fundamentally changing it. We adapted a cheap sensor, (the Lightstone mediation sensor device by Wild Divine), to record and transfer biometric information about the player (via sensors that clip over their fingers) into a commercial game engine, Half-Life 2. During game play, the computer game was dynamically modified by the player's biometric information to increase the cinematically augmented ""horror"" affordances. These included dynamic changes in the game shaders, screen shake, and the creation of new spawning points for the game's non-playing characters (zombies), all these features were driven by the player's biometric data. To evaluate the usefulness of this biofeedback device, we compared it against a control group of players who also had sensors clipped on their fingers, but for the second group the gameplay was not modified by the biometric information of the players. While the evaluation results indicate biometric data can improve the situated feeling of horror, there are many design issues that will need to be investigated by future research, and the judicious selection of theme and appropriate interaction is vital. © 2007 Authors & Digital Games Research Association (DiGRA).","Biofeedback; Cinematics; Gameplay; Horror; Shaders","Affordances; Biometric data; Biometric informations; Cinematics; Computer game; Control groups; Design issues; Dynamic changes; Evaluation results; Game Engine; Gameplay; Horror; Second group; Sensor device; Shaders; Biofeedback; Biometrics; Computer software; Digital storage; Human computer interaction; Research; Sensors; Interactive computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-52249118221
"Stevens J.A.","56329868600;","Visualization of complex automotive data: A tutorial",2007,"IEEE Computer Graphics and Applications","27","6",,"80","86",,7,"10.1109/MCG.2007.161","https://www.scopus.com/inward/record.uri?eid=2-s2.0-37549027218&doi=10.1109%2fMCG.2007.161&partnerID=40&md5=1e38247e7aa31179a4aeb4fc119dde14","General Motors Corp.","Stevens, J.A., General Motors Corp.","Making complicated data easier to understand has always been a challenge. Four types of visualization applications (CAD, generalized, specialized, and custom) have successfully been used by automotive manufacturers such as General Motors to help meet this goal. Here are some ways that common processes can be developed for all types of visualization. © 2007 IEEE.","Automotive model rendering; Multi-resolution modeling; Visualization","Automotive model rendering; Automotive industry; Computer aided design; Mathematical models; Multiresolution analysis; Volume rendering; Visualization; car; computer aided design; computer assisted diagnosis; computer graphics; computer interface; computer simulation; equipment design; factual database; information retrieval; methodology; review; theoretical model; three dimensional imaging; Automobiles; Computer Graphics; Computer Simulation; Computer-Aided Design; Databases, Factual; Equipment Design; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Information Storage and Retrieval; Models, Theoretical; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-37549027218
"Ieronutti L., Chittaro L.","6507168127;7004119007;","Employing virtual humans for education and training in X3D/VRML worlds",2007,"Computers and Education","49","1",,"93","109",,62,"10.1016/j.compedu.2005.06.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846491809&doi=10.1016%2fj.compedu.2005.06.007&partnerID=40&md5=72b0939bb3209509b6f9ba37613071ac","HCI Laboratory, Department of Math and Computer Science, University of Udine, via delle Scienze 206, 33100 Udine, Italy","Ieronutti, L., HCI Laboratory, Department of Math and Computer Science, University of Udine, via delle Scienze 206, 33100 Udine, Italy; Chittaro, L., HCI Laboratory, Department of Math and Computer Science, University of Udine, via delle Scienze 206, 33100 Udine, Italy","Web-based education and training provides a new paradigm for imparting knowledge; students can access the learning material anytime by operating remotely from any location. Web3D open standards, such as X3D and VRML, support Web-based delivery of Educational Virtual Environments (EVEs). EVEs have a great potential for learning and training purposes, by allowing one to circumvent physical, safety, and cost constraints. Unfortunately, EVEs often leave to the user the onus of taking the initiative both in exploring the environment and interacting with its parts. A possible solution to this problem is the exploitation of virtual humans acting as informal coaches or more formal instructors. For example, virtual humans can be employed to show and explain maintenance procedures, allowing learners to receive more practical explanations which are easier to understand. However, virtual humans are rarely used in Web3D EVEs, since the programming effort to develop and re-use them in different environments can be considerable. In this paper, we present a general architecture that allows content creators to easily integrate virtual humans into Web3D EVEs. To test the generality of our solution, we present two practical examples showing how the proposed architecture has been used in different educational contexts. © 2005 Elsevier Ltd. All rights reserved.","Distance education and telelearning; Human-computer interface; Interactive learning environments; Virtual Reality","Human computer interaction; Interactive computer graphics; Learning systems; Virtual reality; World Wide Web; Cost constraints; Interactive learning environments; Telelearning; Virtual humans; Distance education",Article,"Final","",Scopus,2-s2.0-33846491809
"Jimeno A., Puerta A.","57200400092;17435762700;","State of the art of the virtual reality applied to design and manufacturing processes",2007,"International Journal of Advanced Manufacturing Technology","33","9-10",,"866","874",,51,"10.1007/s00170-006-0534-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547241548&doi=10.1007%2fs00170-006-0534-2&partnerID=40&md5=dd83223015082c2a38dae7cb28c99106","Department of Computer Technology and Computation, Alicante University, San Vicente del Raspeig s/n, 03001 Alicante, Spain","Jimeno, A., Department of Computer Technology and Computation, Alicante University, San Vicente del Raspeig s/n, 03001 Alicante, Spain; Puerta, A., Department of Computer Technology and Computation, Alicante University, San Vicente del Raspeig s/n, 03001 Alicante, Spain","The idea that technology can transfer a person to a different environment without any physical movement and create the illusion of interaction with the artificial environment is not new. Scientists and engineers have been dedicating their efforts to its progressive development over the last fifty years. However, most of the technological advances have been made in the last ten years, undoubtedly thanks to improvements in computer efficiency and the miniaturization of sensorization devices. Nowadays, virtual reality is successfully applied in different fields, such as telemedicine, robotics or cinematography. Following on from this success, the question arises of whether we are ready to apply it to industrial design and manufacturing processes. The lack of recent reviews on this technology applied to CAD/CAM, together with its rapid evolution over the last decade, have been the primary motivations for carrying out this study. © 2006 Springer-Verlag London Limited.","Virtual environments; Virtual prototyping; Virtual reality","Computer aided design; Computer aided manufacturing; Photography; Robotics; Technology transfer; Telemedicine; Sensorization devices; Virtual prototyping; Virtual reality",Article,"Final","",Scopus,2-s2.0-34547241548
"Richardson A.R., Waller D.","55418762900;7203026309;","Interaction with an immersive virtual environment corrects users' distance estimates",2007,"Human Factors","49","3",,"507","517",,78,"10.1518/001872007X200139","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34249060033&doi=10.1518%2f001872007X200139&partnerID=40&md5=73e04dca28393a44f1ee912e20a16e94","Miami University, Oxford, OH, United States; Boeing Company, P. O. Box 3707, Seattle, WA 98124, United States; Boeing Company, Seattle, WA, United States; Psychology Department, Miami University, United States","Richardson, A.R., Miami University, Oxford, OH, United States, Boeing Company, P. O. Box 3707, Seattle, WA 98124, United States, Boeing Company, Seattle, WA, United States; Waller, D., Miami University, Oxford, OH, United States, Psychology Department, Miami University, United States","Objective: Two experiments examined whether prior interaction within an immersive virtual environment (VE) enabled people to improve the accuracy of their distance judgments and whether an improved ability to estimate distance generalized to other means of estimating distances. Background: Prior literature has consistently found that users of immersive VEs underestimate distances by approximately 50%. Method: In each of the two experiments, 16 participants viewed objects in an immersive VE and estimated their distance to them by means of blindfolded walking tasks before and after interacting with the VE. Results: The interaction task significantly corrected users' underestimation bias to nearly veridical. Differences between pre- and postinteraction mean distance estimation accuracy were large (d = 4.63), and significant (p < .001), and they generalized across response task. Conclusion: This finding limits the generality of the underestimation effect in VEs and suggests that distance underestimation in VEs may not be a roadblock to the development of VE applications. Application: Potential or actual applications of this research include the improvement of VE systems requiring accurate spatial awareness. Copyright © 2007, Human Factors and Ergonomics Society. All rights reserved.",,"Distance judgments; Response tasks; Spatial awareness; Distance measurement; Human engineering; Virtual reality; accuracy; adult; article; awareness; depth perception; female; human; human experiment; human factors research; male; normal human; spatial orientation; task performance; virtual reality; walking; Adult; Distance Perception; Female; Humans; Male; Maze Learning; Orientation; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-34249060033
"Tichon J.","6603714327;","Training cognitive skills in virtual reality: Measuring performance",2007,"Cyberpsychology and Behavior","10","2",,"286","289",,18,"10.1089/cpb.2006.9957","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34249054433&doi=10.1089%2fcpb.2006.9957&partnerID=40&md5=22e4725f173aa31e03b882f166ce94a0","Perception and Motor Systems Laboratory, School of Human Movement Studies, University of Queensland, St. Lucia, QLD, Australia; Perception and Motor Systems Laboratory, School of Human Movement Studies, University of Queensland, St. Lucia, QLD 4072, Australia","Tichon, J., Perception and Motor Systems Laboratory, School of Human Movement Studies, University of Queensland, St. Lucia, QLD, Australia, Perception and Motor Systems Laboratory, School of Human Movement Studies, University of Queensland, St. Lucia, QLD 4072, Australia","Across a variety of operational environments, virtual reality (VR) is being increasingly used as a means of simulating hazardous work conditions in order to allow trainees to practice advanced cognitive skills such as problem-solving and decision-making. Replicating dangerous conditions particularly involving heavy machinery in the real world can be dangerous and costly. The use of VR is therefore appealing across many industries such as aviation, mining, and rail. However, while the number of training prototypes increase less focus is being given to appropriate evaluation of the training provided via this technology. Increasing skills acquisition and performance does not depend solely on the appropriate design of simulation training. Of equal importance are strong performance measures which can ultimately feedback on the success or otherwise of training and highlight any deficits to guide ongoing improvements. To ensure cognitive skills acquired in a virtual training environment (VTE) are transferable to the real world, training objectives need to be tied directly to realistic scenario events which in turn are directly linked to measures of specific required behaviors. © Mary Ann Liebert, Inc.",,"article; aviation; behavior; decision making; human; machine; measurement; mining; performance; problem solving; railway; skill; technology; training; virtual reality; Computer Simulation; Computer-Assisted Instruction; Decision Making; Feedback, Psychological; Humans; Inservice Training; Practice (Psychology); Problem Solving; Safety Management; Transfer (Psychology); User-Computer Interface",Article,"Final","",Scopus,2-s2.0-34249054433
"Hua H., Ahuja N., Gao C.","7103212541;35515078200;7402617624;","Design analysis of a high-resolution panoramic camera using conventional imagers and a mirror pyramid",2007,"IEEE Transactions on Pattern Analysis and Machine Intelligence","29","2",,"356","361",,10,"10.1109/TPAMI.2007.33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247232623&doi=10.1109%2fTPAMI.2007.33&partnerID=40&md5=e5a05868149499e1659c87aea257f917","College of Optical Sciences, The University of Arizona, 1630 E University Blvd., Tucson, AZ 85721, United States; Beckman Institute, University of Illinois at Urbana-Champaign, 450 N Mathews Ave., Urbana, IL 61801, United States","Hua, H., College of Optical Sciences, The University of Arizona, 1630 E University Blvd., Tucson, AZ 85721, United States; Ahuja, N., Beckman Institute, University of Illinois at Urbana-Champaign, 450 N Mathews Ave., Urbana, IL 61801, United States; Gao, C., Beckman Institute, University of Illinois at Urbana-Champaign, 450 N Mathews Ave., Urbana, IL 61801, United States","Wide field of view (FOV) and high-resolution image acquisition is highly desirable in many vision-based applications. Several systems have reported the use of reflections off mirror pyramids to capture high-resolution, single-viewpoint, and wide-FOV images. Using a dual mirror pyramid (DMP) panoramic camera as an example, in this paper, we examine how the pyramid geometry, and the selection and placement of imager clusters can be optimized to maximize the overall panoramic FOV, sensor utilization efficiency, and image uniformity. The analysis can be generalized and applied to other pyramid-based designs. © 2007 IEEE.","Catadioptric systems; Mirror pyramids; Omnidirectional imaging; Panoramic camera","Cameras; Geometry; Image sensors; Mirrors; Optimization; Reflection; Catadioptric systems; High-resolution image acquisition; Mirror pyramids; Omnidirectional imaging; Panoramic camera; Wide field of view (FOV); Image analysis; algorithm; article; computer aided design; computer assisted diagnosis; computer simulation; equipment; equipment design; image enhancement; instrumentation; methodology; optical instrumentation; photography; theoretical model; Algorithms; Computer Simulation; Computer-Aided Design; Equipment Design; Equipment Failure Analysis; Image Enhancement; Image Interpretation, Computer-Assisted; Lenses; Models, Theoretical; Photography",Article,"Final","",Scopus,2-s2.0-34247232623
"Fink P.W., Foo P.S., Warren W.H.","7101805360;7004202886;7202784806;","Obstacle Avoidance During Walking in Real and Virtual Environments",2007,"ACM Transactions on Applied Perception","4","1",,"2","",,73,"10.1145/1227134.1227136","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84980025512&doi=10.1145%2f1227134.1227136&partnerID=40&md5=5c76da40635f56d3f0055f7c40814ce6","Center for Complex Systems and Brain Sciences, Florida Atlantic University, Boca Raton, Florida 33431, United States; Department of Psychology, University of North Carolina at Asheville, North Cardina 28801, Asheville, United States; Department of Cognitive and Linguistic Sciences, Brown University, Rhode Island 02912, Providence, United States","Fink, P.W., Center for Complex Systems and Brain Sciences, Florida Atlantic University, Boca Raton, Florida 33431, United States; Foo, P.S., Department of Psychology, University of North Carolina at Asheville, North Cardina 28801, Asheville, United States; Warren, W.H., Department of Cognitive and Linguistic Sciences, Brown University, Rhode Island 02912, Providence, United States","Immersive virtual environments are a promising research tool for the study of perception and action, on the assumption that visual–motor behavior in virtual and real environments is essentially similar. We investigated this issue for locomotor behavior and tested the generality of Fajen and Warren's [2003] steering dynamics model. Participants walked to a stationary goal while avoiding a stationary obstacle in matched physical and virtual environments. There were small, but reliable, differences in locomotor paths, with a larger maximum deviation (Δ = 0.16 m), larger obstacle clearance (Δ = 0.16 m), and slower walking speed (Δ = 0.13 m/s) in the virtual environment. Separate model fits closely captured the mean virtual and physical paths (R2 > 0.98). Simulations implied that the path differences are not because of walking speed or a 50% distance compression in virtual environments, but might be a result of greater uncertainty about the egocentric location of virtual obstacles. On the other hand, paths had similar shapes in the two environments with no difference in median curvature and could be modeled with a single set of parameter values (R2 > 0.95). Fajen and Warren's original parameters successfully generalized to new virtual and physical object configurations (R2 > 0.95). These results justify the use of virtual environments to study locomotor behavior. © 2007, ACM. All rights reserved.","Experimentation; Human Factors; Locomotion; modeling; Perception; virtual reality",,Article,"Final","",Scopus,2-s2.0-84980025512
"Aziz E.-S., Chang C., Arango F., Esche S.K., Chassapis C.","24721014000;57212663666;57200918668;6603892215;7004391468;","Linking computer game engines with remote experiments",2007,"ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE)","7",,,"413","420",,13,"10.1115/IMECE2007-41969","https://www.scopus.com/inward/record.uri?eid=2-s2.0-44249116421&doi=10.1115%2fIMECE2007-41969&partnerID=40&md5=168bc728a79dfd5d0a64de48c5e2722b","Stevens Institute of Technology, Department of Mechanical Engineering, Hoboken, NJ  07030, United States","Aziz, E.-S., Stevens Institute of Technology, Department of Mechanical Engineering, Hoboken, NJ  07030, United States; Chang, C., Stevens Institute of Technology, Department of Mechanical Engineering, Hoboken, NJ  07030, United States; Arango, F., Stevens Institute of Technology, Department of Mechanical Engineering, Hoboken, NJ  07030, United States; Esche, S.K., Stevens Institute of Technology, Department of Mechanical Engineering, Hoboken, NJ  07030, United States; Chassapis, C., Stevens Institute of Technology, Department of Mechanical Engineering, Hoboken, NJ  07030, United States","Recently, the potential of using commercially available computer game engines to implement virtual engineering experiments (which represent pure computer simulations) has been explored by various educational institutions. Using a game engine in conjunction with a corresponding software development kit, it is possible for educators to replace the content of an existing computer game with educational content, thus creating virtual laboratory environments. The utilization of game engines for educational purposes is expected to increase the degree of immersive presence of the students engaging in such game-based laboratory exercises as well as the level of interactivity between the students. This paper will discuss the integration of a game-based virtual laboratory environment with remote experiments conducted using actual physical devices. In particular, the paper will focus on possible ways in which the data transfer between a computer game engine and an existing remote laboratory experiment can be accomplished. Strategies for the extraction of laboratory experiment data and for the conversion of data formats are discussed. Possible methods by which the laboratory experiment output data is accessed and displayed are also addressed. Some of the key questions affecting the possible process flows are if and at what point the laboratory experiment mode of interaction should switch from the game engine to the remote laboratory experiment and then switch back to the game engine, and whether or not the user should know that and when it occurred. Finally, the paper will present a sample implementation of a virtual laboratory, into which a specific remote experiment was integrated. Copyright © 2007 by ASME.","3ds Max; Collaborative virtual environment; Game engine; Half-Life 2; Laboratory education; MaxScript; Remote laboratory; Source game engine; Virtual experiment; Virtual laboratory; Virtual reality","Computer games; Data handling; Data transfer; Education; Laboratories; Software design; Students; Virtual reality; Societies and institutions; Software engineering; Students; Three dimensional computer graphics; Virtual reality; 3ds max; Collaborative virtual environment; Game Engine; Half lives; Laboratory education; MaxScript; Remote laboratories; Virtual experiments; Virtual laboratories; Collaborative virtual environments; Game engines; Remote laboratories; Source game engines; Virtual experiment; Virtual laboratories; Distance education; Animation",Conference Paper,"Final","",Scopus,2-s2.0-44249116421
"Bakdash J.Z., Augustyn J.S., Proffitt D.R.","6504035313;25821912500;7005887383;","Large displays enhance spatial knowledge of a virtual environment",2006,"Proceedings - APGV 2006: Symposium on Applied Perception in Graphics and Visualization",,,,"59","62",,19,"10.1145/1140491.1140503","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250722532&doi=10.1145%2f1140491.1140503&partnerID=40&md5=d7b070ea83b474ecf26e91d5d0c72921","Department of Psychology, University of Virginia, United States; U.S. Army Natick Soldier Systems Center, United States","Bakdash, J.Z., Department of Psychology, University of Virginia, United States; Augustyn, J.S., U.S. Army Natick Soldier Systems Center, United States; Proffitt, D.R., Department of Psychology, University of Virginia, United States","Previous research has found performance for several egocentric tasks to be superior on physically large displays relative to smaller ones, even when visual angle is held constant. This finding is believed to be due to the more immersive nature of large displays. In our experiment, we examined if using a large display to learn a virtual environment (VE) would improve egocentric knowledge of the target locations. Participants learned the location of five targets by freely exploring a desktop large-scale VE of a city on either a small (25'' diagonally) or large (72'' diagonally) screen. Viewing distance was adjusted so that both displays subtended the same viewing angle. Knowledge of the environment was then assessed using a head-mounted display in virtual reality, by asking participants to stand at each target and paint at the other unseen targets. Angular pointing error was significantly lower when the environment was learned on a 72'' display. Our results suggest that large displays are superior for learning a virtual environment and the advantages of learning an environment on a large display may transfer to navigation in the real world. Copyright © 2006 by the Association for Computing Machinery, Inc.","Display size; Immersion; Navigation; Presence; Virtual reality","Angular pointing error; Egocentric tasks; Immersive nature; Spatial knowledge; Data acquisition; Helmet mounted displays; Knowledge acquisition; Target tracking; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-34250722532
"Hatfield D., Shaffer D.W.","55750849400;7103303182;","Press play: Designing an epistemic game engine for journalism",2006,"ICLS 2006 - International Conference of the Learning Sciences, Proceedings","1",,,"236","242",,16,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884386223&partnerID=40&md5=7081bc96d623e7adb3889acb9a604861","University of Wisconsin, 1025 W. Johnson St., Madison, WI 53706, United States","Hatfield, D., University of Wisconsin, 1025 W. Johnson St., Madison, WI 53706, United States; Shaffer, D.W., University of Wisconsin, 1025 W. Johnson St., Madison, WI 53706, United States","Epistemic games are one approach to creating educational games that give players skills that transfer beyond the game world by helping young people become fluent in valuable social practices. Epistemic games are immersive, technology-enhanced, role-playing games where players learn to become-and thus to think like-doctors, lawyers, engineers, architects, and other members of important practices and professions. In what follows we look at the design of Byline, an epistemic game engine behind science.net, an epistemic game of science journalism. In particular, we argue that rather than simply recreating the technological conditions of the profession, an epistemic game engine like Byline can encode key elements of a professional practicum and thus help young people learn through participation in simulations of the training practices of socially valued professions such as science journalism.",,"Educational game; Game Engine; Immersive; Key elements; Role-playing game; Social practices; Technological conditions; Young peoples; Interactive computer graphics; Learning systems; Personnel training; Engineering education",Conference Paper,"Final","",Scopus,2-s2.0-84884386223
"Steinicke F., Hinrichs K.","8883314100;7004845251;","Grab-and-throw metaphor: Adapting desktop-based interaction paradigms to virtual reality",2006,"3DUI 2006: IEEE Symposium on 3D User Interfaces 2006 - Proceedings","2006",, 1647512,"83","86",,4,"10.1109/VR.2006.65","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750798526&doi=10.1109%2fVR.2006.65&partnerID=40&md5=2c7b23cf53d6a8e0bf0cfdd66825a1d0","Institut für Informatik, Westfälische Wilhelms-Universität Münster, Einsteinstraße 62, 48149 Münster, Germany","Steinicke, F., Institut für Informatik, Westfälische Wilhelms-Universität Münster, Einsteinstraße 62, 48149 Münster, Germany; Hinrichs, K., Institut für Informatik, Westfälische Wilhelms-Universität Münster, Einsteinstraße 62, 48149 Münster, Germany","The drag-and-drop metaphor is one of the most common direct interaction metaphors used in desktop-based environments. This direct interaction paradigm enables an intuitive method to apply actions by associating iconic representation of objects to each other. Since dragging of these iconic representations is the most time-consuming subtask of the drag-and-drop metaphor, many extensions of this approach have been proposed to enhance this process. However, a transfer of these concepts to virtual reality (VR) systems has not been realized. In this paper we propose the grab-and-throw metaphor which is a VR-based analogon to the drag-and-drop metaphor. The proposed concepts enable users to select a virtual object by grabbing it and to throw the object within a virtual environment (VE) in the direction of another object. As soon as the object hits another object, an associated action is performed. The trajectory of the thrown object is based on physical motions adapted from the real-world. In order to ease hitting a desired target object, snapping strategies are used such that the aimed object attracts the thrown object. We give a technical description of the grab-and-throw metaphor and discuss example application scenarios which benefit from the usage of the described metaphor. © 2006 IEEE.",,"Graphical user interfaces; Interactive computer systems; Object recognition; Personal computers; Virtual reality; Adapting desktop based interaction paradigms; Grab and throw metaphor; Iconic representations; Virtual reality (VR) systems; Adaptive systems",Conference Paper,"Final","",Scopus,2-s2.0-33750798526
"Steed A.","18435050200;","Towards a general model for selection in virtual environments",2006,"3DUI 2006: IEEE Symposium on 3D User Interfaces 2006 - Proceedings","2006",, 1647515,"103","110",,42,"10.1109/VR.2006.134","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750812463&doi=10.1109%2fVR.2006.134&partnerID=40&md5=0262d76e8f21cb5424ce7ae58cdaecb5","Department of Computer Science, University College London, United Kingdom","Steed, A., Department of Computer Science, University College London, United Kingdom","Selection is one of the fundamental building blocks of all interactive virtual environment systems. Selection is the ability of the user to specify which object, or sub-part of an object in the environment, is the target for subsequent actions. Examples include selecting 3D buttons thus invoking an action or selecting a target upon which an action will occur. Selection is also an implicit or explicit part of manipulation techniques. In a virtual environment selection can be performed in many different ways. In this paper we develop a generalized model of how interaction is and could be performed in virtual environments using 3D gestures. The purpose of this model is to highlight some potential areas for development and evaluation of novel selection techniques. The model is based on an analysis of the complexity of selection. We develop a model for selection that is based on time-varying scalar fields (TVSFs) that encompasses a very broad range of existing techniques. This model will be abstract, in that a direct implementation will be prohibitively complex, but we show how some standard implementation strategies are good approximations to the formal model. © 2006 IEEE.","3D interaction; Selection; Virtual environments","Interactive virtual environment systems; Three dimensional gestures; Three dimensional interaction; Virtual environment selection; Abstracting; Mathematical models; Object recognition; Selection; Three dimensional computer graphics; User interfaces; Virtual reality; Interactive computer systems",Conference Paper,"Final","",Scopus,2-s2.0-33750812463
"Steinicke F., Hinrichs K.","8883314100;7004845251;","Grab-and-throw metaphor: Adapting desktop-based interaction paradigms to virtual reality",2006,"Proceedings - IEEE Virtual Reality","2006",, 1624166,"128","",,,"10.1109/VR.2006.65","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750104816&doi=10.1109%2fVR.2006.65&partnerID=40&md5=c61a4b6afc75e3f7dc3cb465818c6c20","Institut für Informatik, Westfälische Wilhelms-Universität Münster, Einsteinstraße 62, 48149 Münster, Germany","Steinicke, F., Institut für Informatik, Westfälische Wilhelms-Universität Münster, Einsteinstraße 62, 48149 Münster, Germany; Hinrichs, K., Institut für Informatik, Westfälische Wilhelms-Universität Münster, Einsteinstraße 62, 48149 Münster, Germany","The drag-and-drop metaphor is one of the most common direct interaction metaphors used in desktop-based environments. This direct interaction paradigm enables an intuitive method to apply actions by associating iconic representation of objects to each other. Since dragging of these iconic representations is the most time-consuming subtask of the drag-and-drop metaphor, many extensions of this approach have been proposed to enhance this process. However, a transfer of these concepts to virtual reality (VR) systems has not been realized. In this paper we propose the grab-and-throw metaphor which is a VR-based analogon to the drag-and-drop metaphor. The proposed concepts enable users to select a virtual object by grabbing it and to throw the object within a virtual environment (VE) in the direction of another object. As soon as the object hits another object, an associated action is performed. The trajectory of the thrown object is based on physical motions adapted from the real-world. In order to ease hitting a desired target object, snapping strategies are used such that the aimed object attracts the thrown object. We give a technical description of the grab-and-throw metaphor and discuss example application scenarios which benefit from the usage of the described metaphor. © 2006 IEEE.",,"Computer selection and evaluation; Graphical user interfaces; Human computer interaction; Object recognition; Personal computers; Targets; Grab and throw metaphors; Iconic representations; Interaction paradigms; Target objects; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-33750104816
"Steed A.","18435050200;","Towards a general model for selection in virtual environments",2006,"Proceedings - IEEE Virtual Reality","2006",, 1624169,"131","",,9,"10.1109/VR.2006.134","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750121589&doi=10.1109%2fVR.2006.134&partnerID=40&md5=5d01929678a1bcb442e6d80311923d1f","Department of Computer Science, University College London, United Kingdom","Steed, A., Department of Computer Science, University College London, United Kingdom","Selection is one of the fundamental building blocks of all interactive virtual environment systems. Selection is the ability of the user to specify which object, or sub-part of an object in the environment, is the target for subsequent actions. Examples include selecting 3D buttons thus invoking an action or selecting a target upon which an action will occur. Selection is also an implicit or explicit part of manipulation techniques. In a virtual environment selection can be performed in many different ways. In this paper we develop a generalized model of how interaction is and could be performed in virtual environments using 3D gestures. The purpose of this model is to highlight some potential areas for development and evaluation of novel selection techniques. The model is based on an analysis of the complexity of selection. We develop a model for selection that is based on time-varying scalar fields (TVSFs) that encompasses a very broad range of existing techniques. This model will be abstract, in that a direct implementation will be prohibitively complex, but we show how some standard implementation strategies are good approximations to the formal model. © 2006 IEEE.","3D interaction; Selection; Virtual environments","3D interaction; Manipulation; Virtual environment selection; Virtual environment systems; Computational complexity; Computer selection and evaluation; Graphical user interfaces; Human computer interaction; Mathematical models; Three dimensional computer graphics; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-33750121589
"Yao Y.X., Xia P.J., Liu J.S., Li J.G.","55722539100;13404322900;8205876700;22953365000;","A pragmatic system to support interactive assembly planning and training in an immersive virtual environment (I-VAPTS)",2006,"International Journal of Advanced Manufacturing Technology","30","9-10",,"959","967",,28,"10.1007/s00170-005-0069-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749988080&doi=10.1007%2fs00170-005-0069-y&partnerID=40&md5=861bf3a23684c5ac29951dee2427c6fb","School of Mechanical and Electrical Engineering, Harbin Institute of Technology, Harbin, 150001, China","Yao, Y.X., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, Harbin, 150001, China; Xia, P.J., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, Harbin, 150001, China; Liu, J.S., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, Harbin, 150001, China; Li, J.G., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, Harbin, 150001, China","Assembly planning for complex products is a difficult task requiring both intensive knowledge and experience. Computer aided assembly planning (CAAP) systems have been the subject of considerable research in recent years without achieving a wide application in manufacturing industry. In this paper an alternative approach to the generation of an optimal assembly planning scheme is presented based on the adoption of immersive virtual reality. A product is assembled from CAD models by providing a CAD interface to transfer assembly constraint information from the CAD system to a virtual environment. In the virtual environment an efficient dynamic recognition and management method based on surface geometry is employed, and a process-oriented assembly task model is established to support interactive assembly planning and evaluation. The system is implemented using an object oriented methodology, and has been successfully applied to train and guide the assembly workers in a pump assembly process. © Springer-Verlag London Limited 2006.","Assembly planning and training; CAD; Virtual reality","Assembly planning; Assembly planning and training; Computer aided assembly planning (CAAP); Assembly machines; Computer aided design; Interactive computer systems; Knowledge engineering; Strategic planning; Virtual reality; Industrial management",Article,"Final","",Scopus,2-s2.0-33749988080
"Min Y.-K.I., Chung S.-C., You J.I.-H., Yi J.-H., Lee B., Tack G.-R., Chun J.-H., Park M.-S., Min B.-C.","8586349000;55976631100;57220880823;7402736699;55994767200;6701791158;15064113900;36871215800;7202932062;","Young adult drivers' sensitivity to changes in speed and driving mode in a simple vehicle simulator",2006,"Perceptual and Motor Skills","103","1",,"197","209",,9,"10.2466/PMS.103.1.197-209","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33751063569&doi=10.2466%2fPMS.103.1.197-209&partnerID=40&md5=c08a988243170219440183035a0c95f8","Chungnam National University, South Korea; Konkuk University, South Korea; Chungang University, South Korea; Hanbat National University, South Korea; Department of Biomedical Engineering, Konkuk University, 322 Danwall-dong, Chungju, Chungbuk, 380-701, South Korea","Min, Y.-K.I., Chungnam National University, South Korea; Chung, S.-C., Konkuk University, South Korea, Department of Biomedical Engineering, Konkuk University, 322 Danwall-dong, Chungju, Chungbuk, 380-701, South Korea; You, J.I.-H., Konkuk University, South Korea; Yi, J.-H., Konkuk University, South Korea; Lee, B., Konkuk University, South Korea; Tack, G.-R., Konkuk University, South Korea; Chun, J.-H., Konkuk University, South Korea; Park, M.-S., Chungang University, South Korea; Min, B.-C., Hanbat National University, South Korea","The study was done to check replication of changes in sensitivity with a simple simulator as had been obtained in an experiment using the real road situation. Another purpose was to control simulator sickness which could have confounded data from testing with a simulator or in actual driving. Sensitivity of the drivers (72 healthy young adults, M age=24 yr., SD=5) while performing the driving task was measured in terms of subjective ratings of simulator sickness and affect, and physiological measures (i.e., galvanic skin responses and skin temperature) at different driving speeds and in driving mode conditions, using a simple vehicle simulator. Analysis showed measures of drivers' state, including simulator sickness, physiological indices, and subjective reports, increased with driving speed (30→90→120 km/hr.) and driving mode change from the regular speed to sudden increasing to sudden decreasing speeds. Particularly, the results suggest that the increased autonomic nervous activation induces increase of rated simulator sickness. Based upon the same tendency in change of the simulator sickness and physiological state with driving speed and driving mode conditions, it was concluded that, if the results obtained from the simulator experiment can be generalized to the real situation, the simulator sickness must be considered a confounding factor. The results also suggest that the changes in human sensitivity are dependent upon aspects related to speed of a vehicle and driving mode. © Perceptual and Motor Skills 2006.",,"acceleration; adult; article; attention; attitude; car driving; computer interface; female; human; male; motor vehicle; psychological aspect; psychomotor performance; Acceleration; Adult; Attention; Attitude; Automobile Driving; Female; Humans; Male; Motor Vehicles; Psychomotor Performance; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-33751063569
"Glencross M., Chalmers A.G., Lin M.C., Otaduy M.A., Gutierrez D.","12790427400;7102938771;57202428958;6507451572;7005194565;","Exploiting perception in high-fidelity virtual environments",2006,"SIGGRAPH 2006 - ACM SIGGRAPH 2006 Courses",,, 1,"","",,10,"10.1145/1185657.1185814","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961784838&doi=10.1145%2f1185657.1185814&partnerID=40&md5=17070b6b6b5e67e8db5422cb0547eee0",,"Glencross, M.; Chalmers, A.G.; Lin, M.C.; Otaduy, M.A.; Gutierrez, D.","The objective of this course is to provide an introduction to the issues that must be considered when building high-fidelity 3D engaging shared virtual environments. The principles of human perception guide important development of algorithms and techniques in collaboration, graphical, auditory, and haptic rendering. We aim to show how human perception is exploited to achieve realism in high fidelity environments within the constraints of available finite computational resources. In this course we address the challenges faced when building such high-fidelity engaging shared virtual environments, especially those that facilitate collaboration and intuitive interaction. We present real applications in which such high-fidelity is essential. With reference to these, we illustrate the significant need for the combination of high-fidelity graphics in real time, better modes of interaction, and appropriate collaboration strategies. After introducing the concept of high-fidelity virtual environments and why these convey important information to the user, we cover the main issues in two parts linked by the common thread of exploiting human perception. First we explore perceptually driven techniques that can be employed to achieve high-fidelity graphical rendering in real-time, and how incorporating authentic lighting effects helps to convey a sense of realism and scale in virtual re-constructions of historical sites. Secondly, we examine how intuitive interaction between participants, and with objects in the environment, also plays a key role in the overall experience. How perceptual methods can be used to guide interest management and distribution choices, is considered with an emphasis on avoiding potential pitfalls when distributing physically-based simulations. An analysis of real network conditions and the implications of these for distribution strategies that facilitate collaboration is presented. Furthermore, we describe technologies necessary to provide intuitive interaction in virtual environments, paying particular attention to engaging multiple sensory modalities, primarily through physically-based sound simulation and perceptually high-fidelity haptic interaction. The combination of realism and intuitive compelling interaction can lead to engaging virtual environments capable of exhibiting skills transfer, an illusive goal of many virtual environment applications.","Collaborative environments; Haptics; High-fidelity rendering; Human-computer interaction; Multi-user; Networked applications; Perception; Virtual reality","Computer graphics; Curricula; Distributed computer systems; Haptic interfaces; Human computer interaction; Interactive computer graphics; Sensory perception; Virtual addresses; Collaborative environments; Haptics; High-fidelity renderings; Multi-user; Networked applications; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84961784838
"Brown L.D., Hua H.","56362429100;7103212541;","Magic lenses for augmented virtual environments",2006,"IEEE Computer Graphics and Applications","26","4",,"64","73",,34,"10.1109/MCG.2006.84","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746172973&doi=10.1109%2fMCG.2006.84&partnerID=40&md5=6d24ed9eb3b57f1ea89b9a44acb30945","Department of Computer Science, The University of Arizona, Tucson, AZ, United States; College of Optical Sciences, Department of Computer Science, The University of Arizona, Tucson, AZ, United States","Brown, L.D., Department of Computer Science, The University of Arizona, Tucson, AZ, United States; Hua, H., College of Optical Sciences, Department of Computer Science, The University of Arizona, Tucson, AZ, United States","The authors developed a Magic Lens framework for Scape, an augmented virtual environment (AVE). They generalize the functional characteristics of Magic Lenses in terms of 3D visualization in AVEs and present two tangible Magic Lens-enabled devices with complementary interface capabilities. The authors also demonstrate their Magic Lens devices through testbed applications relevant to urban planning and medical training. © 2006 IEEE.",,"Computer graphics; Lenses; Optical devices; Three dimensional; Augmented virtual environment; Magic lenses; Testbed applications; Three dimensional visualization; Virtual reality; algorithm; article; computer assisted diagnosis; computer graphics; computer interface; computer program; computer simulation; environment; methodology; optical instrumentation; photography; theoretical model; three dimensional imaging; Algorithms; Computer Graphics; Computer Simulation; Environment; Image Interpretation, Computer-Assisted; Imaging, Three-Dimensional; Lenses; Models, Theoretical; Photogrammetry; Software; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-33746172973
"Sturz B.R., Bodily K.D., Katz J.S.","14011868600;14013229400;57199104434;","Evidence against integration of spatial maps in humans",2006,"Animal Cognition","9","3",,"207","217",,17,"10.1007/s10071-006-0022-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745028881&doi=10.1007%2fs10071-006-0022-y&partnerID=40&md5=216387a228a0410d41ce9aaf1d69d5ad","Department of Psychology, 226 Thach Hall, Auburn University, Auburn, AL 36849, United States","Sturz, B.R., Department of Psychology, 226 Thach Hall, Auburn University, Auburn, AL 36849, United States; Bodily, K.D., Department of Psychology, 226 Thach Hall, Auburn University, Auburn, AL 36849, United States; Katz, J.S., Department of Psychology, 226 Thach Hall, Auburn University, Auburn, AL 36849, United States","A dynamic 3-D virtual environment was constructed for humans as an open-field analogue of Blaisdell and Cook's (2005) pigeon foraging task to determine if humans, like pigeons, were capable of integrating separate spatial maps. Participants used keyboard keys and a mouse to search for a hidden goal in a 4×4 grid of raised cups. During Phase 1 training, a goal was consistently located between two landmarks (Map 1: blue T and red L). During Phase 2 training, a goal was consistently located down and left of a single landmark (Map 2: blue T). Transfer trials were then conducted in which participants were required to make choices in the presence of the red L alone. Cup choices during transfer assessed participants' strategies: association (from Map 1), generalization (from Map 2), or integration (combining Map 1 and 2). During transfer, cup choices increased to a location which suggested an integration strategy and was consistent with results obtained with pigeons. However, additional analyses of the human data suggested participants initially used a generalization strategy followed by a progressive shift in search behavior away from the red L. This shift in search behavior during transfer was responsible for the changes in cup choices across transfer trials and was confirmed by a control condition. These new analyses offer an alternative explanation to the spatial integration account proposed for pigeons.","Cognitive Map; Human; Integration; Spatial; Virtual Environment","adult; article; behavior; computer graphics; computer interface; depth perception; human; learning; male; orientation; problem solving; reference value; Adult; Association Learning; Computer Graphics; Humans; Male; Orientation; Problem Solving; Reference Values; Space Perception; Spatial Behavior; User-Computer Interface; Columba",Article,"Final","",Scopus,2-s2.0-33745028881
"Merians A.S., Poizner H., Boian R., Burdea G., Adamovich S.","6603018031;7005963417;6603659582;35612697900;6603916707;","Sensorimotor training in a virtual reality environment: Does it improve functional recovery poststroke?",2006,"Neurorehabilitation and Neural Repair","20","2",,"252","267",,167,"10.1177/1545968306286914","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646536087&doi=10.1177%2f1545968306286914&partnerID=40&md5=f8c1c430902d6561ec66dced59014fd4","Graduate Programs in Physical Therapy, University of Medicine and Dentistry of New Jersey, School of Health Related Professions, Newark, NJ, United States; Institute for Neural Computation, University of California, San Diego, San Diego, CA, United States; Center for Advanced Information Processing, Rutgers University, Piscataway, NJ, United States; Department of Biomedical Engineering, New Jersey Institute of Technology, Newark, NJ, United States; University of Medicine and Dentistry of New Jersey, 65 Bergen Street, Newark, NJ 07107, United States","Merians, A.S., Graduate Programs in Physical Therapy, University of Medicine and Dentistry of New Jersey, School of Health Related Professions, Newark, NJ, United States, University of Medicine and Dentistry of New Jersey, 65 Bergen Street, Newark, NJ 07107, United States; Poizner, H., Institute for Neural Computation, University of California, San Diego, San Diego, CA, United States; Boian, R., Center for Advanced Information Processing, Rutgers University, Piscataway, NJ, United States; Burdea, G., Center for Advanced Information Processing, Rutgers University, Piscataway, NJ, United States; Adamovich, S., Department of Biomedical Engineering, New Jersey Institute of Technology, Newark, NJ, United States","Objective. To investigate the effectiveness of computerized virtual reality (VR) training of the hemiparetic hand of patients poststroke using a system that provides repetitive motor reeducation and skill reacquisition. Methods. Eight subjects in the chronic phase poststroke participated in a 3-week program using their hemiparetic hand in a series of interactive computer games for 13 days of training, weekend breaks, and pretests and posttests. Each subject trained for about 2 to 2.5 h per day. Outcome measures consisted of changes in the computerized measures of thumb and finger range of motion, thumb and finger velocity, fractionation (the ability to move fingers independently), thumb and finger strength, the Jebsen Test of Hand Function, and a Kinematic reach to grasp test. Results. Subjects as a group improved in fractionation of the fingers, thumb and finger range of motion, and thumb and finger speed, retaining those gains at the 1-week retention test. Transfer of these improvements was demonstrated through changes in the Jebsen Test of Hand Function and a decrease after the therapy in the overall time from hand peak velocity to the moment when an object was lifted from the table. Conclusions. It is difficult in current service delivery models to provide the intensity of practice that appears to be needed to effect neural reorganization and functional changes poststroke. Computerized exercise systems may be a way to maximize both the patients' and the clinicians' time. The data in this study add support to the proposal to explore novel technologies for incorporation into current practice. Copyright © 2006 The American Society of Neurorehabilitation.","Haptics; Motor learning; Recovery; Rehabilitation; Stroke; Virtual reality","adult; aged; article; clinical article; female; hand function; hemiparesis; human; male; motor activity; range of motion; sensorimotor function; stroke; virtual reality; Aged; Aged, 80 and over; Cerebrovascular Accident; Exercise; Female; Hand; Humans; Male; Middle Aged; Paresis; Psychomotor Performance; Recovery of Function; Treatment Outcome; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-33646536087
"Liu J.-S., Yao Y.-X., Pahlovy S.A., Li J.-G.","8205876700;55722539100;12784389300;22953365000;","A novel data decomposition and information translation method from CAD system to virtual assembly application",2006,"International Journal of Advanced Manufacturing Technology","28","3-4",,"395","402",,16,"10.1007/s00170-004-2284-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33644697493&doi=10.1007%2fs00170-004-2284-3&partnerID=40&md5=b89e6abdaaad36067009bae9e3ee9395","School of Mechanical and Electrical Engineering, Harbin Institute of Technology, P.O. 422, Harbin, 150001, China","Liu, J.-S., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, P.O. 422, Harbin, 150001, China; Yao, Y.-X., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, P.O. 422, Harbin, 150001, China; Pahlovy, S.A., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, P.O. 422, Harbin, 150001, China; Li, J.-G., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, P.O. 422, Harbin, 150001, China","Virtual assembly (VA) is a key technology for virtual manufacturing systems. So far, CAD systems are still the main modeling tools for the VA system. There isn't a standard data exchange criterion to transfer the data directly from CAD systems to VA applications, consequently an original data decomposition and information translation method (DDITM) was timely proposed to achieve the decomposition and translation. The information of the assembly bodies in the CAD system was divided into geometry information, topology information, and assembly information, etc., which were transferred to the VA application separately. The geometry information including the surface information was translated by the data translation interface (DTI) developed, the topology information was translated by a five-hierarchy topology structure (FHTS) constructed, and the assembly information was translated with database technology. A systematic architecture was formed with the interaction between the geometry information and the topology information, and the assembly information and the topology. Finally an experimental VA system was set up to verify the DDITM, and an assembly simulation was implemented to verify the assembly information further, which proves the translated information is precise and sufficient.","CAD; Data decomposition; Information translation; Virtual assembly","Data reduction; Data transfer; Database systems; Interfaces (computer); Virtual reality; Data decomposition; Information translation; Virtual assembly (VA); Computer aided design",Article,"Final","",Scopus,2-s2.0-33644697493
"Cannon W.D., Eckhoff D.G., Garrett Jr. W.E., Hunter R.E., Sweeney H.J.","7103266235;7005571011;7102162248;9335699700;7004380961;","report of a group developing a virtual reality simulator for arthroscopic surgery of the knee joint",2006,"Clinical Orthopaedics and Related Research",,"442",,"21","29",,59,"10.1097/01.blo.0000197080.34223.00","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33645073700&doi=10.1097%2f01.blo.0000197080.34223.00&partnerID=40&md5=2bbc9f4a0d50a62704ef03a5390242ea","Department of Orthopedic Surgery, University of California at San Francisco, San Francisco, CA, United States; Department of Orthopedics, University of Colorado Health Sciences, Denver, CO, United States; Division of Orthopedic Surgery, Duke University Medical Center, Durham, NC, United States; Sports Medicine Section, University of Arizona, Tucson, AZ, United States; Northwestern University Feinberg School of Medicine, Department of Orthopedic Surgery, Evanston, Northwestern Healthcare, Evanston, IL, United States; UCSF, Department of Orthopedic Surgery, PO Box 0728, San Francisco, CA 94143, United States","Cannon, W.D., Department of Orthopedic Surgery, University of California at San Francisco, San Francisco, CA, United States, UCSF, Department of Orthopedic Surgery, PO Box 0728, San Francisco, CA 94143, United States; Eckhoff, D.G., Department of Orthopedics, University of Colorado Health Sciences, Denver, CO, United States; Garrett Jr., W.E., Division of Orthopedic Surgery, Duke University Medical Center, Durham, NC, United States; Hunter, R.E., Sports Medicine Section, University of Arizona, Tucson, AZ, United States; Sweeney, H.J., Northwestern University Feinberg School of Medicine, Department of Orthopedic Surgery, Evanston, Northwestern Healthcare, Evanston, IL, United States","Apprenticeship training of surgical skills is time consuming and can lead to surgical errors. Our group is developing an arthroscopic virtual reality knee simulator for training orthopaedic residents in arthroscopic surgery before live-patient operating room experience. The simulator displays realistic human knee anatomy derived from the Visible Human Dataset developed by the National Library of Medicine and incorporates active force-feedback haptic technology. Our premise is that postgraduate year 2 residents completing a formal virtual education program who are trained to reach a proficiency standard in the techniques and protocol for an arthroscopic knee examination will complete a diagnostic arthroscopy on an actual patient in less time with greater accuracy, less iteration of movement of the arthroscope, and less damage to the patient's tissue compared with residents in the control group learning and practicing the arthroscopic knee examination procedures through the residency program's established education and training program. The validation study, done at eight orthopaedic residency programs, will commence in early 2006 and will take one year to complete. We anticipate that proficiency obtained on the simulator will transfer to surgical skills in the operating room. © 2006 Lippincott Williams & Wilkins.",,"arthroscopic surgery; conference paper; education program; feedback system; human; knee arthroscopy; operating room; priority journal; residency education; resident; skill; surgical anatomy; surgical error; surgical training; tactile stimulation; virtual reality; visible human project; arthroscopy; article; clinical competence; computer interface; computer program; computer simulation; education; knee; medical education; methodology; orthopedics; teaching; Arthroscopy; Clinical Competence; Computer Simulation; Computer-Assisted Instruction; Education, Medical, Graduate; Humans; Internship and Residency; Knee Joint; Orthopedics; Software; User-Computer Interface",Conference Paper,"Final","",Scopus,2-s2.0-33645073700
"Vogel J.J., Greenwood-Ericksen A., Cannon-Bowers J., Bowers C.A.","7403035148;24331357900;35578473300;7202781568;","Using virtual reality with and without gaming attributes for academic achievement",2006,"Journal of Research on Technology in Education","39","1",,"105","118",,63,"10.1080/15391523.2006.10782475","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008823539&doi=10.1080%2f15391523.2006.10782475&partnerID=40&md5=3b940ce6726bef222369b84631cb9fed","University of Central Florida, Florida State University, United States; University of Central Florida, United States","Vogel, J.J., University of Central Florida, Florida State University, United States; Greenwood-Ericksen, A., University of Central Florida, United States; Cannon-Bowers, J., University of Central Florida, United States; Bowers, C.A., University of Central Florida, United States","A subcategory of computer-assisted instruction (CAI), games have additional attributes such as motivation, reward, interactivity, score, and challenge. This study used a quasi-experimental design to determine if previous findings generalize to non simulation-based game designs. Researchers observed significant improvement in the overall population for math skills in the non-game CAI control condition, but not in the game-based experimental condition. The study found no meaningful significant differences in language arts skills in any of the conditions. This finding has implications for the design of future learning games, suggesting that a simulation-based approach should be integrated into the gaming technology. © 2006 Taylor & Francis Group, LLC. All rights reserved.","CAI; Education; Games; Motivation; Simulation",,Article,"Final","",Scopus,2-s2.0-85008823539
"Dähne P., Seibert H.","6507191408;7004142744;","Managing data flow in interactive MR environments",2005,"13th International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision 2005, WSCG'2005 - In Co-operation with EUROGRAPHICS, Full Papers",,,,"173","176",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861040059&partnerID=40&md5=5eedd27a43dd6ca2aa4205bbdb8e5fc9","Computer Graphics Center (ZGDV), Fraunhoferstraße 5, D-64283 Darmstadt, Germany","Dähne, P., Computer Graphics Center (ZGDV), Fraunhoferstraße 5, D-64283 Darmstadt, Germany; Seibert, H., Computer Graphics Center (ZGDV), Fraunhoferstraße 5, D-64283 Darmstadt, Germany","In this paper the concept and design of a software framework which provides a transparent data flow for interactive Mixed Reality (MR) applications is discussed. The design was affected by our demands on platform independency, simplicity, network transparency, maximum performance and availability of runtime debugging facilities. Our software framework tries to simplify the development of MR applications by using the concept of a data flow graph. The developer builds such a graph from a library of small software components that communicate via the edges of the graph. Copyright UNION Agency - Science Press.","Augmented reality; Device management; Interaction; Mixed Reality; Tracking; Virtual reality","Data flow; Device management; Interaction; Mixed reality; Runtimes; Software component; Software frameworks; Augmented reality; Computer programming; Data flow analysis; Data flow graphs; Data transfer; Surface discharges; Virtual reality; Visualization; Computer vision",Conference Paper,"Final","",Scopus,2-s2.0-84861040059
"Fuhrmann A.L., Splechtna R.C., Mroz L., Hauser H.","7004448962;55481478800;6603388015;7202841889;","Distributed software-based volume visualization in a virtual environment",2005,"9th International Workshop on Immersive Projection Technology - 11th Eurographics Symposium on Virtual Environments, IPT/EGVE 2005",,,,"129","139",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878689138&partnerID=40&md5=8471fd68a6473911e998e41b5587efad","VRVis Research Center, Austria; TIANI MedGraph, Austria","Fuhrmann, A.L., VRVis Research Center, Austria; Splechtna, R.C., VRVis Research Center, Austria; Mroz, L., TIANI MedGraph, Austria; Hauser, H., VRVis Research Center, Austria","In this paper we present our integration of volume rendering into virtual reality, combining a fast and flexible software implementation of direct volume rendering with the intuitive manipulation and navigation techniques of a virtual environment. By distributing the visualization and interaction tasks to two low-end PCs we managed to realize a highly interactive, yet inexpensive set-up. The volume objects are seamlessly integrated into the polygonal virtual environment through image-based rendering. The interaction techniques include scalar parameterization of transfer functions, direct 3D selection, 3D highlighting of volume objects and clipping cubes and cutting planes. These methods combined with the interaction and display devices of virtual reality form a powerful yet intuitive environment for the investigation of volume data sets. As main application areas we propose training and education. © The Eurographics Association 2005.",,"Direct volume rendering; Image-Based Rendering; Interaction techniques; Navigation techniques; Software implementation; Training and education; Volume data sets; Volume visualization; Display devices; Image reconstruction; Optical projectors; Sensory perception; Visualization; Volume rendering; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84878689138
"Del Río A., Fischer J., Köbele M., Bartz D., Straßer W.","55393205800;8345270000;55758712600;56031275800;7004523663;","Augmented reality interaction for semiautomatic volume classification",2005,"9th International Workshop on Immersive Projection Technology - 11th Eurographics Symposium on Virtual Environments, IPT/EGVE 2005",,,,"113","120",,6,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878735362&partnerID=40&md5=07f911d08719b4b9fe156487f81e3046","WSI/GRIS-VCM, University of Tübingen, Germany","Del Río, A., WSI/GRIS-VCM, University of Tübingen, Germany; Fischer, J., WSI/GRIS-VCM, University of Tübingen, Germany; Köbele, M., WSI/GRIS-VCM, University of Tübingen, Germany; Bartz, D., WSI/GRIS-VCM, University of Tübingen, Germany; Straßer, W., WSI/GRIS-VCM, University of Tübingen, Germany","In the visualization of 3D medical data, the appropriateness of the achieved result is highly dependent on the application. Therefore, an intuitive interaction with the user is of utter importance in order to determine the particular aim of the visualization. In this paper, we present a novel approach for the visualization of 3D medical data with volume rendering combined with AR-based user interaction. The utilization of augmented reality (AR), with the assistance of a set of simple tools, allows the direct manipulation in 3D of the rendered data. The proposed method takes into account regions of interest defined by the user and employs this information to automatically generate an adequate transfer function. Machine learning techniques are utilized for the automatic creation of transfer functions, which are to be used during the classification stage of the rendering pipeline. The validity of the proposed approach for medical applications is illustrated. © The Eurographics Association 2005.",,"Automatic creations; Direct manipulation; Intuitive interaction; Machine learning techniques; Regions of interest; Rendering pipelines; User interaction; Volume classifications; Augmented reality; Learning systems; Medical applications; Optical projectors; Transfer functions; Virtual reality; Visualization; Volume rendering; Data visualization",Conference Paper,"Final","",Scopus,2-s2.0-84878735362
"Dang G., Cheng Z.-Q., Jin S.-Y., Yang T., Wu T.","7006971944;7401815259;7401822532;57197380025;57191505635;","A service-oriented architecture for tele-immersion",2005,"Proceedings - 2005 IEEE International Conference on e-Technology, e-Commerce and e-Service, EEE-05",,,,"646","649",,3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-30944442258&partnerID=40&md5=da282022ce720ac7fd426f88af612a41","Computer School, National University of Defense Technology, Changsha, Hunan Province (410073), China","Dang, G., Computer School, National University of Defense Technology, Changsha, Hunan Province (410073), China; Cheng, Z.-Q., Computer School, National University of Defense Technology, Changsha, Hunan Province (410073), China; Jin, S.-Y., Computer School, National University of Defense Technology, Changsha, Hunan Province (410073), China; Yang, T., Computer School, National University of Defense Technology, Changsha, Hunan Province (410073), China; Wu, T., Computer School, National University of Defense Technology, Changsha, Hunan Province (410073), China","Sharing virtual environments with the remote collaborators as well as the topic of the collaboration may be better than collaborating with them in person. In this paper we will discuss our ongoing work to enable effective collabo-ration between remote participants within tele-immersion based on Web Service implemented by Microsoft Visual Studio.Net. We will discuss the architecture of the tele-immersion system created, the implemented methodology, the technology driving our current research, and the lessons learned. Our focus is on the service-oriented architecture taking of the web service and COM+ technology. © 2005 IEEE.",,"Computer systems; Groupware; Technology transfer; Telecommunication services; Virtual reality; Websites; COM+ technology; Remote collaborators; Tele-immersion; Web service; Computer architecture",Conference Paper,"Final","",Scopus,2-s2.0-30944442258
"Al-Hudhud G., Ayesh A., Istance H., Turner M.","8671121600;14059468900;6602493995;57192279844;","Simulation and visualization of a large scale real time multi-robot system",2005,"Theory and Practice of Computer Graphics 2005, TPCG 2005 - Eurographics UK Chapter Proceedings",,,,"147","154",,6,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878284301&partnerID=40&md5=73084a71b2f43410e58203621fb13825","De Montfort University, United Kingdom; University of Manchester, United Kingdom; Centre for Computational Intelligence and Virtual Environment Centre, United Kingdom; Manchester Visualization Centre, Manchester Computing, United Kingdom","Al-Hudhud, G., De Montfort University, United Kingdom; Ayesh, A., De Montfort University, United Kingdom; Istance, H., De Montfort University, United Kingdom, Centre for Computational Intelligence and Virtual Environment Centre, United Kingdom; Turner, M., University of Manchester, United Kingdom, Manchester Visualization Centre, Manchester Computing, United Kingdom","This paper describes the software implementation and the visualization aspects of an interaction-communication protocol within a large scalable multi-robot system. It investigates the current communication protocols within multi-agent systems and the feasibility to transfer them into a virtual environment system that performs a specified task intelligently, embedding human capability into the control system software. The proposed system allows dynamic changes, i.e. the user may be able to continuously issue commands, or modify tasks. The work presented exploits the Virtual Environment Centre VEC. The semi-immersive full scale environment within the VEC allows the user to better understand the robots' behaviour and in turn test whether they simulate the expected behaviour. The use of a semi-immersive full-scale environment also gives an increased level of presence enabling the user to believe they are within their own simulation. It also presents a prototype for a robot automatic fire extinguishing system as a test application area. © The Eurographics Association 2005.",,"Control system software; Fire-extinguishing systems; Human capability; Multi agent system (MAS); Multi-robot systems; Simulation and visualizations; Software implementation; Test applications; Multi agent systems; Multipurpose robots; Robot learning; Virtual reality; Visualization",Conference Paper,"Final","",Scopus,2-s2.0-84878284301
"Badariah S., Mania K.","10240878700;6602471750;","The effect of visual fidelity on transfer of training and awareness states",2005,"Proceedings - APGV 2005: 2nd Symposium on Applied Perception in Graphics and Visualization",,,,"173","",,1,"10.1145/1080402.1080457","https://www.scopus.com/inward/record.uri?eid=2-s2.0-29344448673&doi=10.1145%2f1080402.1080457&partnerID=40&md5=4eaee9e2d5ec2a8c0a763c86dade31ca","University of Sussex, United Kingdom","Badariah, S., University of Sussex, United Kingdom; Mania, K., University of Sussex, United Kingdom","This research investigates the effect of rendering quality and scene context on transfer of training with an immersive Virtual Environment (VE). 24 participants across two visual conditions of varying shadow information (absence/presence of shadows) were exposed to a simulated real-world scene and subsequently completed an object-based memory recognition task in the real world environment simulated. Results revealed a higher proportion of recollections associated with mental imagery after training in the flat-shaded condition. These findings comply with similar paradoxical effects revealed in three earlier studies which demonstrated that low interaction fidelity 3D interfaces provoked a higher proportion of recognitions based on visual mental images. Copyright © 2005 by the Association for Computing Machinery, Inc.",,"Computer simulation; Image quality; Imaging systems; Interfaces (computer); Object recognition; Object-based memory recognition; Paradoxical effects; Visual fidelity; Visual mental images; Image analysis",Conference Paper,"Final","",Scopus,2-s2.0-29344448673
"Neulight N.R., Kafai Y.B.","16233977000;35616562500;","What happens if you catch whypox? Children's learning experiences of infectious disease in a multi-user virtual environment",2005,"Proceedings of DiGRA 2005 Conference: Changing Views - Worlds in Play",,,,"","",8,4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873361217&partnerID=40&md5=9453cae55a3ec2322c72997dcb71f9f2","University of California, Los Angeles, 2128 Moore Hall, Los Angeles, CA 90095-1521, United States; University of California, Los Angeles, 2331 Moore Hall 951521, Los Angeles, CA 90095-1521, United States","Neulight, N.R., University of California, Los Angeles, 2128 Moore Hall, Los Angeles, CA 90095-1521, United States; Kafai, Y.B., University of California, Los Angeles, 2331 Moore Hall 951521, Los Angeles, CA 90095-1521, United States","This study investigated students' understanding of a virtual infectious disease in relation to their understanding of natural infectious diseases. Two sixth grade classrooms of students between the ages 10 to 12 (46 students) participated in a participatory simulation of a virtual infectious disease as part of their science curriculum that took place in a university-laboratory school in Los Angeles, California. The results from our analyses revealed that the immersive components of the simulation afforded students the opportunity to discuss their understandings of natural disease and to compare them to their experiences with the virtual disease. We found that while the virtual disease capitalized on students' knowledge of natural infectious disease through virtual symptoms, these symptoms and a missing curricular piece of computational viruses may have led students to think of its transfer more as an observable or mechanical event rather than as a biological process. These findings provide helpful indicators to science educators and educational designers interested in creating and implementing such online simulations to further students' conceptual understanding. © 2005 Authors & Digital Games Research Association DiGRA.","Multi-user virtual environment; Science education; Simulation","Biological process; California; Conceptual understanding; Immersive; Infectious disease; Learning experiences; Los angeles; Multi-user virtual environment; Online simulation; Participatory simulations; Science curriculum; Science education; Simulation; Curricula; Virtual reality; Viruses; Students",Conference Paper,"Final","",Scopus,2-s2.0-84873361217
"Koh C.L., Weiss S., Peterson J.M., Bharitkar S.","9632946200;7403677811;56321295700;6602125553;","Self-orthogonalizing overlap-save GSC",2005,"Conference Record - Asilomar Conference on Signals, Systems and Computers","2005",, 1600057,"1687","1691",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847626382&partnerID=40&md5=4b2a5da298d7bc1406a21c45e7906744","Communications Research Group, School of Electronics and Computer Science, University of Southampton, United Kingdom; Immersive Audio Laboratory, USC Viterbi School of Engineering, University of Southern California, Los Angeles, CA, United States; Audyssey Laboratories, Los Angeles, CA, United States","Koh, C.L., Communications Research Group, School of Electronics and Computer Science, University of Southampton, United Kingdom; Weiss, S., Communications Research Group, School of Electronics and Computer Science, University of Southampton, United Kingdom; Peterson, J.M., Immersive Audio Laboratory, USC Viterbi School of Engineering, University of Southern California, Los Angeles, CA, United States; Bharitkar, S., Audyssey Laboratories, Los Angeles, CA, United States","This paper discusses a computationally inexpensive and fast converging approach to broadband beamforming. Exemplarily utilising the generalised sidelobe canceller (GSC), accurate low-cost implementations in the DFT domain based on overlap-save techniques have been previously suggested, which however suffer from slow convergence when used in combination with the least mean squares algorithm. To overcome this limitation, the beamformer proposed here exploits decorrelation of the input signal within the overlap-save architecture. By inclusion of a self-orthogonalizing component into the adaptive algorithm, the eigen-value spread of the covariance matrix of the input signal is reduced, thereby increasing the adaptation rate. Simulation results indicate that the convergence speed of the proposed beamformer is comparable to a time domain realisation, albeit at a much reduced cost. © 2005 IEEE.",,"Generalised sidelobe canceller (GSC); Least mean squares algorithm; Overlap-save techniques; Computer simulation; Convergence of numerical methods; Eigenvalues and eigenfunctions; Signal processing; Time domain analysis; Broadband networks",Conference Paper,"Final","",Scopus,2-s2.0-33847626382
"Latoschik M.E., Biermann P., Wachsmuth I.","6602976914;7004339578;35581983300;","Knowledge in the loop: Semantics representation for multimodal simulative environments",2005,"Lecture Notes in Computer Science","3638",,,"25","39",,23,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-26944478544&partnerID=40&md5=49f52a7d20aa888858a2f71f106530a4","AI and VR Lab., University of Bielefeld, Germany","Latoschik, M.E., AI and VR Lab., University of Bielefeld, Germany; Biermann, P., AI and VR Lab., University of Bielefeld, Germany; Wachsmuth, I., AI and VR Lab., University of Bielefeld, Germany","This article describes the integration of knowledge based techniques into simulative Virtual Reality (VR) applications. The approach is motivated using multimodal Virtual Construction as an example domain. An abstract Knowledge Representation Layer (KRL) is proposed which is expressive enough to define all necessary data for diverse simulation tasks and which additionally provides a base formalism for the integration of Artificial Intelligence (AI) representations. The KRL supports two different implementation methods. The first method uses XSLT processing to transform the external KRL format into the representation formats of the diverse target systems. The second method implements the KRL using a functionally extendable semantic network. The semantic net library is tailored for real time simulation systems where it interconnects the required simulation modules and establishes access to the knowledge representations inside the simulation loop. The KRL promotes a novel object model for simulated objects called Semantic Entities which provides a uniform access to the KRL and which allows extensive system modularization. The KRL approach is demonstrated in two simulation areas. First, a generalized scene graph representation is presented which introduces an abstract definition and implementation of geometric node interrelations. It supports scene and application structures which can not be expressed using common scene hierarchies or field route concepts. Second, the KRL's expressiveness is demonstrated in the design of multimodal interactions. Here, the KRL defines the knowledge particularly required during the semantic analysis of muitimodal user utterances. © Springer-Verlag Berlin Heidelberg 2005.",,"Knowledge representation layer (KRL); Object models; Semantic network; Virtual construction; Computer simulation; Data reduction; Graph theory; Knowledge based systems; Mathematical models; Modal analysis; Virtual reality; Semantics",Conference Paper,"Final","",Scopus,2-s2.0-26944478544
"Mulavara A.P., Richards J.T., Ruttley T., Marshburn A., Nomura Y., Bloomberg J.J.","6603007909;7403706715;8986681300;8986681400;14423791300;7003940093;","Exposure to a rotating virtual environment during treadmill locomotion causes adaptation in heading direction",2005,"Experimental Brain Research","166","2",,"210","219",,26,"10.1007/s00221-005-2356-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-26044454890&doi=10.1007%2fs00221-005-2356-0&partnerID=40&md5=7deee95ce08944fe8fdf720ee322db31","Neuroscience Laboratory, Baylor College of Medicine, National Space Biomedical Research Institute, 2101 NASA Parkway, Houston, TX 77058, United States; Wyle Life Sciences Inc., Houston, TX 77058, United States; NASA Johnson Space Center, Houston, TX 77058, United States; Nihon University, School of Medicine, Tokyo 173-8610, Japan","Mulavara, A.P., Neuroscience Laboratory, Baylor College of Medicine, National Space Biomedical Research Institute, 2101 NASA Parkway, Houston, TX 77058, United States; Richards, J.T., Wyle Life Sciences Inc., Houston, TX 77058, United States; Ruttley, T., NASA Johnson Space Center, Houston, TX 77058, United States; Marshburn, A., NASA Johnson Space Center, Houston, TX 77058, United States; Nomura, Y., Nihon University, School of Medicine, Tokyo 173-8610, Japan; Bloomberg, J.J., NASA Johnson Space Center, Houston, TX 77058, United States","The objective of this study was to investigate the adaptive effects of variation in the direction of optic flow, experienced during linear treadmill walking, on modifying locomotor trajectory. Subjects (n=30) walked on a motorized linear treadmill at 4.0 km h-1 for 24 min while viewing the interior of a 3D virtual scene projected on to a screen 1.5 m in front of them. The virtual scene depicted constant self-motion equivalent to either (1) walking around the perimeter of a room to one's left (Rotating Room group) or (2) walking down the center of a hallway (Infinite Corridor group). The scene was static for the first 4 min and then constant rate self-motion was simulated for the remaining 20 min. Before and after the treadmill locomotion adaptation period subjects performed five stepping trials. In each trial they marched in place to the beat of a metronome at 90 steps min-1 for a total of 100 steps while blindfolded in a quiet room. The subject's final heading direction (deg) and final X (fore-aft, cm) and final Y (medio-lateral, cm) positions were measured for each trial. During the treadmill locomotion adaptation period subjects' 3D torso position was measured. We found that subjects in the Rotating Room group, as compared with the Infinite Hallway group: (1) showed significantly greater deviation during post-exposure testing in the heading direction and Y position opposite to the direction of optic flow experienced during treadmill walking; and (2) showed a significant monotonically increasing torso yaw angular rotation bias in the direction of optic flow during the treadmill adaptation exposure period. Subjects in both groups showed greater forward translation (in the +X direction) during the post-treadmill stepping task that differed significantly from their pre-exposure performance. Subjects in both groups reported no perceptual deviation in position during the stepping tasks. We infer that viewing simulated rotary self-motion during treadmill locomotion causes adaptive modification of sensorimotor integration in the control of position and trajectory during locomotion, which functionally reflects adaptive changes in the integration of visual, vestibular, and proprioceptive cues. Such an adaptation in the control of position and heading direction during locomotion, because of the congruence of sensory information, demonstrates the potential for adaptive transfer between sensorimotor systems and suggests a common neural site for processing and self-motion perception and concurrent adaptation in motor output. © Springer-Verlag 2005.",,"adaptation; adult; article; association; head movement; human; human experiment; locomotion; normal human; optics; perception; priority journal; proprioception; rotation; sensorimotor function; sensory stimulation; treadmill; trunk; vestibular stimulation; virtual reality; vision; walking; Adaptation, Physiological; Adult; Biomechanics; Humans; Motion Perception; Photic Stimulation; Posture; Psychomotor Performance; Rotation; User-Computer Interface; Walking",Article,"Final","",Scopus,2-s2.0-26044454890
"Grossman T., Wigdor D., Balakrishnan R.","7003520062;6507569914;7006221860;","Exploring interaction with 3D volumetric displays",2005,"Proceedings of SPIE - The International Society for Optical Engineering","5664",, 35,"323","331",,2,"10.1117/12.587714","https://www.scopus.com/inward/record.uri?eid=2-s2.0-21944443996&doi=10.1117%2f12.587714&partnerID=40&md5=673ea419c25b0f8f5ebb26f8176ed2c3","Dept. of Computer Science, Univ. of Toronto, 40 St. George St, Toronto, Ont. M5S 3G4, Canada","Grossman, T., Dept. of Computer Science, Univ. of Toronto, 40 St. George St, Toronto, Ont. M5S 3G4, Canada; Wigdor, D., Dept. of Computer Science, Univ. of Toronto, 40 St. George St, Toronto, Ont. M5S 3G4, Canada; Balakrishnan, R., Dept. of Computer Science, Univ. of Toronto, 40 St. George St, Toronto, Ont. M5S 3G4, Canada","Volumetric displays generate true volumetric 3D images by actually illuminating points in 3D space. As a result, viewing their contents is similar to viewing physical objects in the real world. These displays provide a 360 degree field of view, and do not require the user to wear hardware such as shutter glasses or head-trackers. These properties make them a promising alternative to traditional display systems for viewing imagery in 3D. Because these displays have only recently been made available commercially (e.g., www.actuality-systems.com), their current use tends to be limited to non-interactive output-only display devices. To take full advantage of the unique features of these displays, however, it would be desirable if the 3D data being displayed could be directly interacted with and manipulated. We investigate interaction techniques for volumetric display interfaces, through the development of an interactive 3D geometric model building application. While this application area itself presents many interesting challenges, our focus is on the interaction techniques that are likely generalizable to interactive applications for other domains. We explore a very direct style of interaction where the user interacts with the virtual data using direct finger manipulations on and around the enclosure surrounding the displayed 3D volumetric image. © 2005 SPIE and IS&T.","3D interaction; Multi-finger and two-handed gestural input; Volumetric display","Image quality; Liquid crystal displays; Mathematical models; Stereo vision; Three dimensional; Virtual reality; Microscopic patterns; Multi-finger and two-handed gestural input; Three dimensional (3D) interaction; Volumetric display; Image processing",Conference Paper,"Final","",Scopus,2-s2.0-21944443996
"Lange M., Cooper M., Duong V., Bourgois M.","16642976300;57210523033;55754702300;19336846700;","Interactive & immersive 3D visualization for ATC",2005,"4th EUROCONTROL Innovative Research Workshop and Exhibition: Envisioning the Future",,,,"27","42",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84916607518&partnerID=40&md5=cdedc48301aefc96858bd9f0126078b0","NVIS, ITN, University of Linköping, Campus Norrköping, Norrköping, 601 74, Sweden; Eurocontrol Innovative Research Group, Eurocontrol Experimental Research Centre, Brétigny-sur-Orge, France","Lange, M., NVIS, ITN, University of Linköping, Campus Norrköping, Norrköping, 601 74, Sweden; Cooper, M., NVIS, ITN, University of Linköping, Campus Norrköping, Norrköping, 601 74, Sweden; Duong, V., Eurocontrol Innovative Research Group, Eurocontrol Experimental Research Centre, Brétigny-sur-Orge, France; Bourgois, M., Eurocontrol Innovative Research Group, Eurocontrol Experimental Research Centre, Brétigny-sur-Orge, France","NVIS has been working with Eurocontrol's INO group for the last five years to explore the usability of 3D display and 'Virtual Reality' technologies in the sphere of Air Traffic Management and Control. NVIS' task has been to explore the potential of this approach from the viewpoint of information visualization and interaction and has produced five versions, each building on the experiences with previous development, of an interactive, semi-immersive 3D visualization system for evaluation by INO. Apart from the many internal changes made to the software to extend and improve its function, common to any large software development which is under constant redesign and extension, the work over the last year has focussed on two main areas: improvements in the information display and extensions and improvements in the interaction mechanisms present in the system. One particular extension, which is not visible to the user, is the extension and generalization of the inter-process communication scheme to control configuration and use of interaction devices. This new scheme makes it possible to combine and use multiple interaction devices with a running instance of the system or for more than one user to work within the same space producing a truly collaborative environment. We are also exploring the use of the same inter-process communication features to permit the interconnection of multiple instances of the visualization application to permit a networked collaborative environment. The major additions visible to the user this year are in the introduction of sophisticated new tools for interaction, such as the moded tablet interface, and the data reduction mechanisms which reduce the visual clutter and make the system more usable in the high traffic density scenarios towards which the system is targeted.",,"Air traffic control; Information systems; Process control; Software design; Virtual reality; Visualization; 3-D visualization systems; Air Traffic Management; Collaborative environments; Control configuration; Information visualization; Interaction mechanisms; Interprocess communication; Visualization application; Three dimensional computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-84916607518
"Chung J.-M., Han S.-W., George M.L., Zhang Y., Natarajan T.S.","7404002526;7405943359;7401952389;8383838600;8383838700;","A wireless instructor system for Computer-Supported Collaborative Learning Requiring Immersive Presence (CSCLIP)",2005,"Information Systems Frontiers","7","1",,"85","102",,1,"10.1007/s10796-005-5340-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-17444399009&doi=10.1007%2fs10796-005-5340-0&partnerID=40&md5=a98e44920954dad5eb429f5fa63e001a","ACSEL and OCLNB Laboratories, Oklahoma State University, Stillwater, OK 74078, United States","Chung, J.-M., ACSEL and OCLNB Laboratories, Oklahoma State University, Stillwater, OK 74078, United States; Han, S.-W., ACSEL and OCLNB Laboratories, Oklahoma State University, Stillwater, OK 74078, United States; George, M.L., ACSEL and OCLNB Laboratories, Oklahoma State University, Stillwater, OK 74078, United States; Zhang, Y., ACSEL and OCLNB Laboratories, Oklahoma State University, Stillwater, OK 74078, United States; Natarajan, T.S., ACSEL and OCLNB Laboratories, Oklahoma State University, Stillwater, OK 74078, United States","The Computer-Supported Collaborative Learning Requiring Immersive Presence (CSCLIP) concept has been established with the objective of extending and enhancing thee-learning experience of distance education, especially for classes that involve laboratory (lab) experiments. The CSCLIP concept defines ""immersive presence"" as an inherent requirement that enables cognitive, affective, and most importantly psychomotor learning objectives to integrate into designs and concepts for next generation e-learning systems (Sharda et~al., 2003). Within the CSCLIP architectural framework, the Wireless Instructor (WI) system has been conceptualized and developed as an essential device to effectively support ""teaching while roaming"" instructional features for both local and distance students. The WI system provides cost effective means to establish a real-time immersive presence for the distance learning (DL) student and his/her lab group peers. The technical design and system architecture to create a WI system are introduced in this paper. The objective of the WI system is to make the learning experience more vivid and interactive by enabling the DL students, as well as the local students that are not in the same room with the instructor(s) at the same time, to be able to flexibly interact with the instructor(s) in real-time. With this system the students can experience real-time or non-real-time virtual tours with the instructor(s), enabling the students to visit places that may not be easily accessible due to distance, limited space and/or time, cost, or possible danger. The WI system consists of two major sub-components. First is a wireless audio and video (AV) system, which transfers real-time AV signals to and from the instructor(s) to all students. Second is the wireless instructor locator & data assistant system. These two systems can be combined into one WI unit, but as the applied development technologies are somewhat distinct, their features and architectural designs will be described separately throughout this paper. Integration of the two systems will enable further capabilities. © 2005 Springer Science+Business Media, Inc.","Bluetooth; Computer-Supported Collaborative Learning Requiring Immersive Presence (CSCLIP); Distance Learning (DL); Immersive Virtual Environments (IVE); Personal DigitalAssistant (PDA); Virtual Laboratory (VLab); Wireless Instructor (WI)","Cognitive systems; Data acquisition; Distance education; Learning systems; Local area networks; Personal digital assistants; Real time systems; Wireless telecommunication systems; Bluetooth; Immersive Virtual Environments (IVE); LAN Access Point (LAP); Virtual Laboratory (VLab); Wireless Instructor (WI); Computer supported cooperative work",Article,"Final","",Scopus,2-s2.0-17444399009
"Streit A., Christie R., Boud A.","8948758200;57215471529;6505890731;","Understanding next-generation VR: Classifying commodity clusters for immersive virtual reality",2004,"Proceedings GRAPHITE 2004 - 2nd International Conference on Computer Graphics and Interactive Techniques in Australasia and Southeast Asia",,,,"222","229",,5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-12344255082&partnerID=40&md5=36507f2a5412384f9e9974519a3be5f0","QUT, Australia; VR Solutions, Australia","Streit, A., QUT, Australia; Christie, R., QUT, Australia; Boud, A., VR Solutions, Australia","Commodity clusters offer the ability to deliver higher performance computer graphics at lower prices than traditional graphics supercomputers. Immersive virtual reality systems demand notoriously high computational requirements to deliver adequate real-time graphics, leading to the emergence of commodity clusters for immersive virtual reality. Such clusters deliver the graphics power needed by leveraging the combined power of several computers to meet the demands of real-time interactive immersive computer graphics. However, the field of commodity cluster-based virtual reality is still in early stages of development and the field is currently adhoc in nature and lacks order. There is no accepted means for comparing approaches and implementers are left with instinctual or trial-and-error means for selecting an approach. This paper provides a classification system that facilitates understanding not only of the nature of different clustering systems but also the interrelations between them. The system is built from a new model for generalized computer graphics applications, which is based on the flow of data through a sequence of operations over the entire context of the application. Prior models and classification systems have been too focused in context and application whereas the system described here provides a unified means for comparison of works within the field.","Computer Clusters; Real-time Graphics; Virtual and Augmented reality","Classification systems; Computer clusters; Real-time graphics; Scalable capacity; Classification (of information); Computer graphics; Computer hardware; Data acquisition; Interactive computer systems; Mathematical models; Supercomputers; User interfaces; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-12344255082
"Yao Y.X., Xia P.J., Liu J.S., Li J.G.","55722539100;13404322900;8205876700;22953365000;","A pragmatic system to support interactive assembly planning and training in immersive virtual environment (I-VAPTS)",2004,"Advances in e-Engineering and Digital Enterprise Technology - I. Proceedings of the Fourth International Conference on e-Engineering and Digital Enterprise Technology",,,,"285","295",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-32444449587&partnerID=40&md5=d47a67ad34e2d2e093dfb4652f87b5ea","School of Mechanical and Electrical Engineering, Harbin Institute of Technology, China","Yao, Y.X., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, China; Xia, P.J., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, China; Liu, J.S., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, China; Li, J.G., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, China","Assembly planning for complex product is a difficult task with which both intensive knowledge and experience are needed. Computer aided assembly planning (CAAP) systems have been the subject of considerable research in recent years without achieving a wide application in manufacture industry. An alternative approach based on the adoption of immersive virtual reality is presented to generate optimal assembly planning scheme in this paper. A product is assembled from CAD models by providing a CAD interface to transfer assembly constraint information from CAD system to virtual environment; In virtual environment an efficient geometry constraint dynamic recognition and management method based on geometry surface is present, and a process-oriented assembly task model is established to support interactive assembly planning and evaluation. The system is implemented using object oriented methodology, and has been successfully applied to train and guide the assembly workers in a pump assembly process.","Assembly planning and training; CAD; Virtual reality","Assembly; Computer aided design; Mathematical models; Object oriented programming; Planning; Virtual reality; Assembly planning; Computer aided assembly planning (CAAP); Process-oriented assembly; Interactive computer systems",Conference Paper,"Final","",Scopus,2-s2.0-32444449587
"Lindeman R.W., Page R., Yanagida Y., Sibert J.L.","7006360047;8590672100;7007057059;7004270269;","Towards full-body haptic feedback: The design and deployment of a spatialized vibrotactile feedback system",2004,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,,,"146","149",,67,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-21644452820&partnerID=40&md5=cdbf05359f1cf9e22437ff7cf68ec1c2","Department of Computer Science, George Washington University, 801 22nd St., NW, Washington, DC 20052, United States; Code 5511, Naval Research Laboratory, 4555 Overlook Ave., SW, Washington, DC 20375, United States; ATR International, MIS Labs, IRC Labs, Keihanna Sci. City, Kyoto 619-0288, Japan","Lindeman, R.W., Department of Computer Science, George Washington University, 801 22nd St., NW, Washington, DC 20052, United States, ATR International, MIS Labs, IRC Labs, Keihanna Sci. City, Kyoto 619-0288, Japan; Page, R., Code 5511, Naval Research Laboratory, 4555 Overlook Ave., SW, Washington, DC 20375, United States; Yanagida, Y., ATR International, MIS Labs, IRC Labs, Keihanna Sci. City, Kyoto 619-0288, Japan; Sibert, J.L., Department of Computer Science, George Washington University, 801 22nd St., NW, Washington, DC 20052, United States","This paper presents work we have done on the design and implementation of an untethered system to deliver haptic cues for use in immersive virtual environments through a body-worn garment. Our system can control a large number of body-worn vibration units, each with individually controllable vibration intensity. Several design iterations have helped us to refine the system and improve such aspects as robustness, ease of donning and doffing, weight, power consumption, cable management, and support for many different types of feedback units, such as pager motors, solenoids, and muffin fans. In addition, experience integrating the system into an advanced virtual reality system has helped define some of the design constraints for creating wearable solutions, and to further refine our implementation. Copyright 2004 ACM.","CQB; Full-body; Haptic feedback; Virtual reality","Ethers; Haptic interfaces; Product design; Technology transfer; Vibrations (mechanical); Virtual reality; CQB; Full-body; Haptic feedback; Vibrotactile feedback system; Feedback control",Conference Paper,"Final","",Scopus,2-s2.0-21644452820
"Mania K.","6602471750;","Simulating perception with interactive virtual environments",2004,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics","3",,,"2770","2776",,1,"10.1109/ICSMC.2004.1400752","https://www.scopus.com/inward/record.uri?eid=2-s2.0-15744384180&doi=10.1109%2fICSMC.2004.1400752&partnerID=40&md5=36dc03e7212642f9136db0fd49217f5f","Department of Informatics, University of Sussex, Falmer, Brighton BN1 9QT, United Kingdom","Mania, K., Department of Informatics, University of Sussex, Falmer, Brighton BN1 9QT, United Kingdom","Computer graphics algorithms have for long dealt with simulation of physics: simulation of the geometry of a real-world space, simulation of the light propagation in a real environment and simulation of motor actions with appropriate tracking. Perception principles have subsequently been incorporated into rendering algorithms in order to save rendering computation and produce photorealistic images from a human rather than a machine point of view. With Virtual Environment (VE) simulator technologies simulating real-world task situations mainly for transfer of training, the research community is challenged to produce a complex system. Furthermore, accurate simulation of physics is often not required in order to 'induce' reality. Much less detail is adequate. This paper is going to review research literature exploring behavioral fidelity and reality benchmarking in interactive VEs focusing on results from two studies aiming to simulate perceptual processes. Study 1 investigates spatial awareness based on merging episodic information with spatial preconceptions and Study 2 looks at subjective impressions of illumination. © 2004 IEEE.","Computer graphics imulations; Illumination; Perceptually-based fidelity metrics","Computer graphics imulations; Functional realism; Human visual systems (HVS); Perceptually-based fidelity metrics; Benchmarking; Computer simulation; Illuminating engineering; Large scale systems; Lighting; Psychology computing; Virtual reality; Visibility; Vision; Interactive computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-15744384180
"Chen L., Chen G.-C., Chen H., Xu X.-L., Chen C.","57193157981;14038605200;57050571900;55706162800;56174479100;","Study on effects of network characteristics on cooperation performance in a desktop CVE system",2004,"CSCWD 2004 - 8th International Conference on Computer Supported Cooperative Work in Design - Proceedings","1",,,"121","126",,1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-15544379568&partnerID=40&md5=89e8f7b3ee0931fcae9b13c5ef6948f7","Coll. of Comp. Sci. and Technology, Zhejiang University, Hangzhou 310027, China","Chen, L., Coll. of Comp. Sci. and Technology, Zhejiang University, Hangzhou 310027, China; Chen, G.-C., Coll. of Comp. Sci. and Technology, Zhejiang University, Hangzhou 310027, China; Chen, H., Coll. of Comp. Sci. and Technology, Zhejiang University, Hangzhou 310027, China; Xu, X.-L., Coll. of Comp. Sci. and Technology, Zhejiang University, Hangzhou 310027, China; Chen, C., Coll. of Comp. Sci. and Technology, Zhejiang University, Hangzhou 310027, China","The influences of network characteristics (e.g. latency, packet loss) on the task performance in desktop Collaborative Virtual Environment (CVE) systems were studied In the experiment, two remote partners worked together to manipulate shared virtual objects over a network, and a network emulator was utilized to simulate the real network. The task in the experiment was to minimize the time to transfer a frame through a rod with no collisions. The performance of human subjects was measured and analyzed quantitatively as a function of network latency and packet loss rate. The experiment results show that the delay had little effect on the task performance while the network latency was less than 200 ms and it was acceptable while the network latency was less than 500 ms; the packet loss had no effect on the task performance while there were 20 state update messages received and it was acceptable while there were more than 10 state update messages received. ©2003 IEEE.",,"Algorithms; Bandwidth; Jitter; Knowledge based systems; Multimedia systems; Network protocols; Quality of service; Real time systems; Collaborative virtual environment (CVE) systems; Cooperative interaction; Network impairments; Network latency; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-15544379568
"Repperger D.W.","7005489754;","Adaptive displays and controllers using alternative feedback",2004,"Cyberpsychology and Behavior","7","6",,"645","652",,6,"10.1089/cpb.2004.7.645","https://www.scopus.com/inward/record.uri?eid=2-s2.0-12744279340&doi=10.1089%2fcpb.2004.7.645&partnerID=40&md5=4e5c639c4467bfcd327d4c1cfa2435d8","Air Force Research Laboratory, Wright-Patterson Air Force Base, Dayton, OH, United States; Air Force Research Laboratory, AFRL/HECP, Wright-Patterson Air Force Base, Dayton, OH 45433-7022, United States","Repperger, D.W., Air Force Research Laboratory, Wright-Patterson Air Force Base, Dayton, OH, United States, Air Force Research Laboratory, AFRL/HECP, Wright-Patterson Air Force Base, Dayton, OH 45433-7022, United States","Investigations on the design of haptic (force reflecting joystick or force display) controllers were conducted by viewing the display of force information within the context of several different paradigms. First, using analogies from electrical and mechanical systems, certain schemes of the haptic interface were hypothesized which may improve the human-machine interaction with respect to various criteria. A discussion is given on how this interaction benefits the electrical and mechanical system. To generalize this concept to the design of human-machine interfaces, three studies with haptic mechanisms were then synthesized and analyzed.",,"article; electricity; feedback system; force; image display; information processing; man machine interaction; mechanics; virtual reality; Computer Terminals; Electricity; Engineering; Feedback; Humans; Mechanics; Models, Theoretical; User-Computer Interface; Vibration",Article,"Final","",Scopus,2-s2.0-12744279340
"Bailenson J.N., Beall A.C., Blascovich J., Rex C.","6602840468;7103222399;8914893700;36793975700;","Examining virtual busts: Are photogrammetrically generated head models effective for person identification?",2004,"Presence: Teleoperators and Virtual Environments","13","4",,"416","427",,20,"10.1162/1054746041944858","https://www.scopus.com/inward/record.uri?eid=2-s2.0-4744352771&doi=10.1162%2f1054746041944858&partnerID=40&md5=2a9125b63187a3ff11619bf93b31fdb6","Virtual Human Interaction Lab., Department of Communication, Stanford University, Stanford, CA 94305-2050, United States; Res. Ctr. Virtual Environ. Behavior, Department of Psychology, Univ. of California at Santa Barbara, Santa Barbara, CA 93106, United States","Bailenson, J.N., Virtual Human Interaction Lab., Department of Communication, Stanford University, Stanford, CA 94305-2050, United States; Beall, A.C., Res. Ctr. Virtual Environ. Behavior, Department of Psychology, Univ. of California at Santa Barbara, Santa Barbara, CA 93106, United States; Blascovich, J., Res. Ctr. Virtual Environ. Behavior, Department of Psychology, Univ. of California at Santa Barbara, Santa Barbara, CA 93106, United States; Rex, C., Res. Ctr. Virtual Environ. Behavior, Department of Psychology, Univ. of California at Santa Barbara, Santa Barbara, CA 93106, United States","We examined the effectiveness of using 3D, visual, digital representations of human heads and faces (i.e., virtual busts) for person identification. In a series of 11 studies, participants learned a number of human faces from analog photographs. We then crafted virtual busts from those analog photographs, and compared recognition of photographs of the virtual busts to the original analog photographs, We demonstrated that the accuracy of person identification using photographs of virtual busts is high in an absolute sense, but not as high as using the original analog photographs. We present a paradigm for comparing the similarity, both structural (objectively similar in shape) and subjective (subjectively in the eyes of a viewer) of virtual busts to analog photographs, with the goal of beginning the discussion of a uniform standard for assessing the fidelity of digital models of human faces.",,"Analog photographs; Bihavioural science; Human faces; Psychological process; Design; Error analysis; Human computer interaction; Human engineering; Photogrammetry; Photomapping; Technology transfer; Three dimensional; Visualization; Virtual reality",Article,"Final","",Scopus,2-s2.0-4744352771
"Raskar R., Van Baar J., Willwacher T., Rao S.","6602886524;6603929342;57190524639;36142023900;","Quadric transfer for immersive curved screen displays",2004,"Computer Graphics Forum","23","3 SPEC. ISS.",,"451","460",,39,"10.1111/j.1467-8659.2004.00776.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-4644299559&doi=10.1111%2fj.1467-8659.2004.00776.x&partnerID=40&md5=271e197e6e2d94520a825cadae83d8c9","Mitsubishi Electric Research Labs., Cambridge, MA, United States","Raskar, R., Mitsubishi Electric Research Labs., Cambridge, MA, United States; Van Baar, J., Mitsubishi Electric Research Labs., Cambridge, MA, United States; Willwacher, T., Mitsubishi Electric Research Labs., Cambridge, MA, United States; Rao, S., Mitsubishi Electric Research Labs., Cambridge, MA, United States","Curved screens are increasingly being used for high-resolution immersive visualization environments. We describe a new technique to display seamless images using overlapping projectors on curved quadric surfaces such as spherical or cylindrical shape. We exploit a quadric image transfer function and show how it can be used to achieve sub-pixel registration while interactively displaying two or three-dimensional datasets for a head-tracked user. Current techniques for automatically registered seamless displays have focused mainly on planar displays. On the other hand, techniques for curved screens currently involve cumbersome manual alignment to make the installation conform to the intended design. We show a seamless real-time display system and discuss our methods for smooth intensity blending and efficient rendering.",,"Computer simulation; Data acquisition; Display devices; Imaging techniques; Optical projectors; Parameter estimation; Technology; Three dimensional; Virtual reality; Visualization; Blending parameters; Display system; Overlapping projectors; Screen displays; Computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-4644299559
"Zhou Z., Cheok A.D., Yang X., Qiu Y.","23986510500;7003447496;22236065700;36724983800;","An experimental study on the role of 3D sound in augmented reality environment",2004,"Interacting with Computers","16","6",,"1043","1068",,23,"10.1016/j.intcom.2004.06.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-9944230931&doi=10.1016%2fj.intcom.2004.06.016&partnerID=40&md5=c593a65389cf3e596874fc1cfe187c82","Department of Electrical Engineering, National University of Singapore, Singapore 119260, Singapore","Zhou, Z., Department of Electrical Engineering, National University of Singapore, Singapore 119260, Singapore; Cheok, A.D., Department of Electrical Engineering, National University of Singapore, Singapore 119260, Singapore; Yang, X., Department of Electrical Engineering, National University of Singapore, Singapore 119260, Singapore; Qiu, Y., Department of Electrical Engineering, National University of Singapore, Singapore 119260, Singapore","Investigation of augmented reality (AR) environments has become a popular research topic for engineers, computer and cognitive scientists. Although application oriented studies focused on audio AR environments have been published, little work has been done to vigorously study and evaluate the important research questions of the effectiveness of three-dimensional (3D) sound in the AR context, and to what extent the addition of 3D sound would contribute to the AR experience. Thus, we have developed two AR environments and performed vigorous experiments with human subjects to study the effects of 3D sound in the AR context. The study concerns two scenarios. In the first scenario, one participant must use vision only and vision with 3D sound to judge the relative depth of augmented virtual objects. In the second scenario, two participants must cooperate to perform a joint task in a game-based AR environment. Hence, the goals of this study are (1) to access the impact of 3D sound on depth perception in a single-camera AR environment, (2) to study the impact of 3D sound on task performance and the feeling of 'human presence and collaboration', (3) to better understand the role of 3D sound in human-computer and human-human interactions, (4) to investigate if gender can affect the impact of 3D sound in AR environments. The outcomes of this research can have a useful impact on the development of audio AR systems, which provide more immersive, realistic and entertaining experiences by introducing 3D sound. Our results suggest that 3D sound in AR environment significantly improves the accuracy of depth judgment and improves task performance. Our results also suggest that 3D sound contributes significantly to the feeling of human presence and collaboration and helps the subjects to 'identify spatial objects'. © 2004 Elsevier B.V. All rights reserved.","3D sound; Augmented reality; User study","Acoustic waves; Cameras; Cognitive systems; Feedback; Human computer interaction; Multiprocessing systems; Three dimensional; Three dimensional computer graphics; Transfer functions; Head related transfer functions (HRTF); Human-human interactions; Three-dimensional (3D) sound; User study; Virtual reality",Article,"Final","",Scopus,2-s2.0-9944230931
"Gross M., Würmlin S., Naef M., Lamboray E., Spagno C., Kunz A., Koller-Meier E., Svoboda T., Van Gool L., Lang S., Strehlke K., Moere A.V., Staadt O.","7403745074;7801645956;7004639110;56633827500;6507617717;7005939819;7801399931;35085537600;22735702300;23028281500;13008773800;55664476700;6602657927;","Blue-c: A spatially immersive display and 3D video portal for telepresence",2003,"ACM SIGGRAPH 2003 Papers, SIGGRAPH '03",,,,"819","827",,138,"10.1145/1201775.882350","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953981472&doi=10.1145%2f1201775.882350&partnerID=40&md5=5ad977f7fc3eb33223c3575ded586eb9","ETH Zürich, Switzerland; University of California, Davis, CA, United States","Gross, M., ETH Zürich, Switzerland; Würmlin, S., ETH Zürich, Switzerland; Naef, M., ETH Zürich, Switzerland; Lamboray, E., ETH Zürich, Switzerland; Spagno, C., ETH Zürich, Switzerland; Kunz, A., ETH Zürich, Switzerland; Koller-Meier, E., ETH Zürich, Switzerland; Svoboda, T., ETH Zürich, Switzerland; Van Gool, L., ETH Zürich, Switzerland; Lang, S., ETH Zürich, Switzerland; Strehlke, K., ETH Zürich, Switzerland; Moere, A.V., ETH Zürich, Switzerland; Staadt, O., ETH Zürich, Switzerland, University of California, Davis, CA, United States","We present blue-c, a new immersive projection and 3D video acquisition environment for virtual design and collaboration. It combines simultaneous acquisition of multiple live video streams with advanced 3D projection technology in a CAVE#8482;-like environment, creating the impression of total immersion. The blue-c portal currently consists of three rectangular projection screens that are built from glass panels containing liquid crystal layers. These screens can be switched from a whitish opaque state (for projection) to a transparent state (for acquisition), which allows the video cameras to ""look through"" the walls. Our projection technology is based on active stereo using two LCD projectors per screen. The projectors are synchronously shuttered along with the screens, the stereo glasses, active illumination devices, and the acquisition hardware. From multiple video streams, we compute a 3D video representation of the user in real time. The resulting video inlays are integrated into a networked virtual environment. Our design is highly scalable, enabling blue-c to connect to portals with less sophisticated hardware. © 2003 ACM.","3D Video; graphics hardware; real-time graphics; spatially immersive displays; virtual environments","3D video; Graphics hardware; Immersive display; Real time graphics; Virtual environments; Glass; Interactive computer graphics; Liquid crystal displays; Liquid crystals; Mergers and acquisitions; Projection systems; Technology transfer; Three dimensional; Video cameras; Video recording; Video streaming; Virtual reality; Visual communication; Projection screens",Conference Paper,"Final","",Scopus,2-s2.0-77953981472
"Raskar R., Van Baar J., Beardsley P., Willwacher T., Rao S., Forlines C.","6602886524;6603929342;7005022858;57190524639;36142023900;8594330700;","iLamps: Geometrically aware and self-configuring projectors",2003,"ACM SIGGRAPH 2003 Papers, SIGGRAPH '03",,,,"809","818",,120,"10.1145/1201775.882349","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953997133&doi=10.1145%2f1201775.882349&partnerID=40&md5=ddeec34fea4160ab956debbdf3cf0255","Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, United States","Raskar, R., Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, United States; Van Baar, J., Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, United States; Beardsley, P., Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, United States; Willwacher, T., Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, United States; Rao, S., Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, United States; Forlines, C., Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, United States","Projectors are currently undergoing a transformation as they evolve from static output devices to portable, environment-aware, communicating systems. An enhanced projector can determine and respond to the geometry of the display surface, and can be used in an ad-hoc cluster to create a self-configuring display. Information display is such a prevailing part of everyday life that new and more flexible ways to present data are likely to have significant impact. This paper examines geometrical issues for enhanced projectors, relating to customized projection for different shapes of display surface, object augmentation, and co-operation between multiple units.We introduce a new technique for adaptive projection on nonplanar surfaces using conformal texture mapping. We describe object augmentation with a hand-held projector, including interaction techniques. We describe the concept of a display created by an ad-hoc cluster of heterogeneous enhanced projectors, with a new global alignment scheme, and new parametric image transfer methods for quadric surfaces, to make a seamless projection. The work is illustrated by several prototypes and applications. © 2003 ACM.","ad-hoc clusters; augmented reality; calibration; projector; quadric transfer; seamless display","ad-hoc clusters; Display surface; Global alignment; Hand-held projectors; Information display; Interaction techniques; Non-planar surfaces; Parametric image; Quadric surfaces; Self-configuring; Significant impacts; Static output; Texture mapping; Augmented reality; Calibration; Interactive computer graphics; Software prototyping; Virtual reality; Flexible displays",Conference Paper,"Final","",Scopus,2-s2.0-77953997133
"Stephenson P., Encarnação L.M., Branco P., Tesch J., Zeltzer D.","57203270064;6603063224;7005118624;57191993914;6701417238;","StudyDesk: Semi-immersive volumetric data analysis",2003,"Proceedings of the 1st International Conference on Computer Graphics and Interactive Techniques in Australasia and South East Asia, GRAPHITE '03",,,,"251","252",,2,"10.1145/604471.604520","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953183448&doi=10.1145%2f604471.604520&partnerID=40&md5=9caa0a9f66b8fd52d997a0e1357c3f80","Fraunhofer CRCG, United States","Stephenson, P., Fraunhofer CRCG, United States; Encarnação, L.M., Fraunhofer CRCG, United States; Branco, P., Fraunhofer CRCG, United States; Tesch, J., Fraunhofer CRCG, United States; Zeltzer, D., Fraunhofer CRCG, United States","The StudyDesk system provides a workbench environment that is well suited to work with multi-dimensional volumetric data in a semi-immersive virtual-reality setting. Using the StudyDesk system, we have implemented two example volume-rendering applications. The first visualises medical volumetric data using its implicit correspondence to physical space. The second is used to visualise and analyse sonar data described by time, range, bearing and frequency dimensions, in which correlations between sub-volumes is important. Therefore an abstract representation of the dataset is used to identify important regions in the data, which are then analysed using more traditional volume visualisation techniques. Interaction is implemented through the use of personal interaction props based on a pen and pad metaphor. Props include a transparent pen and pad that carry virtual shapes and a PDA system that is also used to transfer data and contexts between various systems. © 2003 ACM.","Acoustic visualization; Human-computer interaction; Information visualization; Medical imaging; Scientific visualization; Volume visualization","Abstract representation; Data sets; Frequency dimensions; Immersive; Information visualization; Personal interaction; Scientific visualizations; Sonar data; Volume visualisation; Volume visualization; Volumetric data; Data reduction; Graphite; Information analysis; Information systems; Interactive computer graphics; Knowledge management; Medical imaging; Underwater acoustics; Visualization; Volumetric analysis; Human computer interaction",Conference Paper,"Final","",Scopus,2-s2.0-77953183448
"Mantovani F., Castelnuovo G., Gaggioli A., Riva G.","7006190897;6603562167;6603138127;56962750600;","Virtual reality training for health-care professionals",2003,"Cyberpsychology and Behavior","6","4",,"389","395",,119,"10.1089/109493103322278772","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041384533&doi=10.1089%2f109493103322278772&partnerID=40&md5=77a35283a9eadb04f9bf5fa966225618","Appl. Technol. Neuro-Psychol. Lab., Istituto Auxologico Italiano, Milan, Italy; Department of Psychology, Universita Cattolica del Sacro Cuore, Milan, Italy; Department of Psychology, Catholic University of Milan, Milan, Italy","Mantovani, F., Appl. Technol. Neuro-Psychol. Lab., Istituto Auxologico Italiano, Milan, Italy, Department of Psychology, Universita Cattolica del Sacro Cuore, Milan, Italy, Department of Psychology, Catholic University of Milan, Milan, Italy; Castelnuovo, G., Appl. Technol. Neuro-Psychol. Lab., Istituto Auxologico Italiano, Milan, Italy; Gaggioli, A., Appl. Technol. Neuro-Psychol. Lab., Istituto Auxologico Italiano, Milan, Italy; Riva, G., Appl. Technol. Neuro-Psychol. Lab., Istituto Auxologico Italiano, Milan, Italy, Department of Psychology, Universita Cattolica del Sacro Cuore, Milan, Italy","Emerging changes in health-care delivery are having a significant impact on the structure of health-care professionals' education. Today it is recognized that medical knowledge doubles every 6-8 years, with new medical procedures emerging everyday. While the half-life of medical information is so short, the average physician practices 30 years and the average nurse 40 years. Continuing education thus represents an important challenge to face. Recent advances in educational technology are offering an increasing number of innovative learning tools. Among these, Virtual Reality represents a promising area with high potential of enhancing the training of health-care professionals. Virtual Reality Training can provide a rich, interactive, engaging educational context, thus supporting experiential learning-by-doing; it can, in fact, contribute to raise interest and motivation in trainees and to effectively support skills acquisition and transfer, since the learning process can be settled within an experiential framework. Current virtual training applications for health-care differ a lot as to both their technological/multimedia sophistication and to the types of skills trained, varying for example from telesurgical applications to interactive simulations of human body and brain, to virtual worlds for emergency training. Other interesting applications include the development of immersive 3D environments for training psychiatrists and psychologists in the treatment of mental disorders. This paper has the main aim of discussing the rationale and main benefits for the use of virtual reality in health-care education and training. Significant research and projects carried out in this field will also be presented, followed by discussion on key issues concerning current limitations and future development directions.",,"computer simulation; conference paper; continuing education; health care delivery; health care personnel; human; medical education; medical informatics; mental disease; multimedia; nurse; psychiatrist; psychologist; skill; staff training; treatment planning; validation process; virtual reality; Computer Simulation; Computer-Assisted Instruction; Education, Professional; Educational Technology; Forecasting; Health Personnel; Humans; User-Computer Interface",Conference Paper,"Final","",Scopus,2-s2.0-0041384533
"Weiss P.L.T., Naveh Y., Katz N.","55435137100;7004434627;7202995938;","Design and testing of a virtual environment to train stroke patients with unilateral spatial neglect to cross a street safely",2003,"Occupational Therapy International","10","1",,"39","55",,71,"10.1002/oti.176","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0038441657&doi=10.1002%2foti.176&partnerID=40&md5=ff665a14606eecfca9e6d549c4887d2b","Department of Occupational Therapy, Fac. of Social Welfare/Hlth. Studies, University of Haifa, Mount Carmel, Haifa 31905, Israel; School of Occupational Therapy, Hadassah-Hebrew University, Jerusalem, Israel","Weiss, P.L.T., Department of Occupational Therapy, Fac. of Social Welfare/Hlth. Studies, University of Haifa, Mount Carmel, Haifa 31905, Israel; Naveh, Y., School of Occupational Therapy, Hadassah-Hebrew University, Jerusalem, Israel; Katz, N., School of Occupational Therapy, Hadassah-Hebrew University, Jerusalem, Israel","Virtual reality (VR) entails the use of advanced technologies, including computers and various multimedia peripherals, to produce a simulated (that is, virtual) environment that users perceive as comparable to real world objects and events. In recent years, virtual reality technologies have begun to be used as an assessment and treatment tool in occupational therapy, in part because of the ability to create environments that provide patients with opportunities to engage in meaningful, purposeful tasks that are related to real-life interests and activities. The objective of this study was to determine the suitability and feasibility of using a PC-based, non-immersive, VR system (that is, a system in which the user has a reduced sense of actual presence in and control over the simulated environment) for training individuals with unilateral spatial neglect to cross streets in a safe and vigilant manner. A virtual environment, consisting of a typical city street, was programmed using Superscape's™ 3D-Webmaster, a 3D web-authoring tool. Twelve subjects, aged 55 to 75 years, participated in the initial feasibility study and, to date, a further eight subjects have participated in the intervention study. Six of the initial subjects and all eight of the intervention subjects had sustained a right hemispheric stroke at least 6 weeks prior to the study. The remaining subjects were healthy age-matched adults who were independently mobile and had no difficulty in crossing streets. The results show that this virtual environment was suitable in both its cognitive and motor demands for the targeted population and indicate that the virtual reality training is likely to prove beneficial to people who have difficulty with crossing streets. The generalizability of these results, and recommendations regarding the use of virtual reality as an occupational therapy intervention, must be substantiated by further studies using a range of VR platforms with people with different cognitive and motor disabilities.","Stroke rehabilitation; Unilateral spatial neglect; Virtual reality","adult; aged; alertness; article; automation; body equilibrium; cerebrovascular accident; clinical article; cognition; cognitive defect; computer interface; computer program; controlled study; daily life activity; depth perception; disorientation; environmental planning; equipment design; feasibility study; female; human; Internet; male; mass medium; medical technology; mobilization; motor coordination; motor dysfunction; motor performance; nausea; occupational therapy; pathophysiology; right hemisphere; safety; stroke; traffic accident; training; urban area; virtual reality; visual impairment; walking; Accidents, Traffic; Activities of Daily Living; Aged; Cerebrovascular Accident; Feasibility Studies; Female; Humans; Male; Middle Aged; Space Perception; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-0038441657
"Brooks B.M., Rose F.D.","7201573008;7102651672;","The use of virtual reality in memory rehabilitation: Current findings and future directions",2003,"NeuroRehabilitation","18","2",,"147","157",,50,"10.3233/nre-2003-18207","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037810473&doi=10.3233%2fnre-2003-18207&partnerID=40&md5=aad776e020b6113e772dd1d8409762eb","University of East London, London, E15 4LZ, United Kingdom; School of Psychology, University of East London, Romford Road, London E15 4LZ, United Kingdom","Brooks, B.M., University of East London, London, E15 4LZ, United Kingdom, School of Psychology, University of East London, Romford Road, London E15 4LZ, United Kingdom; Rose, F.D., University of East London, London, E15 4LZ, United Kingdom","There is considerable potential for using virtual reality (VR) in memory rehabilitation which is only just beginning to be realized. PC-based virtual environments are probably better suited for this purpose than more immersive virtual environments because they are relatively inexpensive and portable, and less frightening to patients. Those exploratory studies that have so far been performed indicate that VR involvement would be usefully directed towards improving assessments of memory impairments and in memory remediation using reorganization techniques. In memory assessment, the use of VR could provide more comprehensive, ecologically-valid, and controlled evaluations of prospective, incidental, and spatial memory in a rehabilitation setting than is possible using standardized assessment tests. The additional knowledge gained from these assessments could more effectively direct rehabilitation towards specific impairments of individual patients. In memory remediation, VR training has been found to promote procedural learning in people with memory impairments, and this learning has been found to transfer to improved real-world performance. Future research should investigate ways in which the procedural knowledge gained during VR interaction can be adapted to offset the many disabilities which result from different forms of memory impairment.","Memory; Rehabilitation; Virtual reality","article; cognition; computer system; cost benefit analysis; evaluation; human; learning; memory disorder; mental deficiency; spatial memory; technique; treatment outcome; validation process; virtual reality",Article,"Final","",Scopus,2-s2.0-0037810473
"Hernández L., Taibo J., Seoane A., López R., López R.","55511555400;6507592553;7003406149;57213074028;55578883100;","The empty museum. Multi-user interaction in an immersive and physically walkable VR space",2003,"Proceedings - 2003 International Conference on Cyberworlds, CW 2003",,, 1253488,"446","452",,5,"10.1109/CYBER.2003.1253488","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946202504&doi=10.1109%2fCYBER.2003.1253488&partnerID=40&md5=170c016c3b0fe366e21be66f6dd98f7a","Architecture and Urban Design Visualisation Group, VideaLAB, Universidade Da Coruña, E.T.S. de Ingenieros de Caminos, Canales y Puertos, Campus de Elviña, Spain","Hernández, L., Architecture and Urban Design Visualisation Group, VideaLAB, Universidade Da Coruña, E.T.S. de Ingenieros de Caminos, Canales y Puertos, Campus de Elviña, Spain; Taibo, J., Architecture and Urban Design Visualisation Group, VideaLAB, Universidade Da Coruña, E.T.S. de Ingenieros de Caminos, Canales y Puertos, Campus de Elviña, Spain; Seoane, A., Architecture and Urban Design Visualisation Group, VideaLAB, Universidade Da Coruña, E.T.S. de Ingenieros de Caminos, Canales y Puertos, Campus de Elviña, Spain; López, R., Architecture and Urban Design Visualisation Group, VideaLAB, Universidade Da Coruña, E.T.S. de Ingenieros de Caminos, Canales y Puertos, Campus de Elviña, Spain; López, R., Architecture and Urban Design Visualisation Group, VideaLAB, Universidade Da Coruña, E.T.S. de Ingenieros de Caminos, Canales y Puertos, Campus de Elviña, Spain","Until quite recently, virtual reality systems consisted of fixed devices which enabled the user to feel immersed in a spot of the virtual space by means of the adequate hardware. The recent emergence of wireless systems for motion capture, together with the increase in graphic power of laptops, and the generalisation of wireless networks has allowed the appearance of the first systems in which at last the user is able to walk physically within a given space framed in the real one, and containing the objects and elements of the virtual space [2][5][6]. Some examples of this hybrid space have already been accomplished worldwide. However, beyond the technical problems with the development of these systems, we must bear in mind the types of contents to be shown, making the most of the possibilities offered by the fact that the user him/herself is the pointer in this kind of virtual reality, while the space itself is the interface. The authors have recently developed a system similar to the ones described. This is a totally immersive, walkable and wireless system called the Empty Museum [7]. This paper outlines its enlargement with the purpose of making it simultaneously usable by several persons. Besides, an example of content is provided which has been specifically designed in order to be experienced in multi-user mode with this equipment: the Virtual Art Gallery. © 2003 IEEE.",,"Virtual reality; Wireless networks; First systems; Generalisation; Motion capture; Multi-user interaction; Virtual art gallery; Virtual reality system; Virtual spaces; Wireless systems; Museums",Conference Paper,"Final","",Scopus,2-s2.0-84946202504
"Kaufmann H., Schmalstieg D.","7203004662;55101019100;","Mathematics and geometry education with collaborative augmented reality",2003,"Computers and Graphics (Pergamon)","27","3",,"339","345",,298,"10.1016/S0097-8493(03)00028-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037681614&doi=10.1016%2fS0097-8493%2803%2900028-1&partnerID=40&md5=add781c3fa93f1470a43aaaef5034eaf","Interactive Media Systems Group, Vienna University of Technology, Favoritenstrasse 9-11/188, Vienna A-1040, Austria","Kaufmann, H., Interactive Media Systems Group, Vienna University of Technology, Favoritenstrasse 9-11/188, Vienna A-1040, Austria; Schmalstieg, D., Interactive Media Systems Group, Vienna University of Technology, Favoritenstrasse 9-11/188, Vienna A-1040, Austria","Construct3D is a 3D geometric construction tool specifically designed for mathematics and geometry education. It is based on the mobile collaborative augmented reality system ""Studierstube"". We describe our efforts in developing a system for the improvement of spatial abilities and maximization of transfer of learning. In order to support various teacher-student interaction scenarios we implemented flexible methods for context and user dependent rendering of parts of the construction. Together with hybrid hardware setups they allow the use of Construct3D in today's classrooms and provide a testbed for future evaluations. Means of application and integration in mathematics and geometry education at high school as well as university level are being discussed. Anecdotal evidence supports our claim that Construct3D is easy to learn, encourages experimentation with geometric constructions and improves spatial skills. © 2003 Elsevier Science Ltd. All rights reserved.","Augmented reality; Geometry education; Mathematics education; Spatial intelligence","Education; Learning systems; Societies and institutions; Students; Geometry education; Computer supported cooperative work",Conference Paper,"Final","",Scopus,2-s2.0-0037681614
"Smith J.D., Twombly I.A., Maese A.C., Cagle Y., Boyle R.","56909047500;6508302129;55529315700;8941957800;7202685709;","The virtual glovebox: Emerging simulation technology for space station experiment design, development, training and troubleshooting",2003,"AIAA Space 2003 Conference and Exposition",,,,"","",,1,"10.2514/6.2003-6341","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088723367&doi=10.2514%2f6.2003-6341&partnerID=40&md5=5414b669ce187e0e772ee1beb9ac0b6d","NASA Ames Research Center, Moffett Field, CA 94035, United States; University Space Research Association, Moffett Field, CA 94035, United States; NASA Johnson Space Center, Houston, TX 77058, United States","Smith, J.D., NASA Ames Research Center, Moffett Field, CA 94035, United States; Twombly, I.A., University Space Research Association, Moffett Field, CA 94035, United States; Maese, A.C., NASA Ames Research Center, Moffett Field, CA 94035, United States; Cagle, Y., NASA Johnson Space Center, Houston, TX 77058, United States; Boyle, R., NASA Ames Research Center, Moffett Field, CA 94035, United States","The International Space Station demonstrates the greatest capabilities of human ingenuity, international cooperation and technology development. The complexity of this space structure is unprecedented; and training astronaut crews to maintain all its systems, as well as perform a multitude of research experiments, requires the most advanced training tools and techniques. Computer simulation and virtual environments are currently used by astronauts to train for robotic arm manipulations and extravehicular activities; but now, with the latest computer technologies and recent successes in areas of medical simulation, the capability exists to train astronauts for more hands-on research tasks using immersive virtual environments. We have developed a new technology, the Virtual Glovebox (VGX), for simulation of experimental tasks that astronauts will perform aboard the Space Station. The VGX may also be used by crew support teams for design of experiments, testing equipment integration capability and optimizing the procedures astronauts will use. This is done through the 3D, desk-top sized, reach-in virtual environment that can simulate the microgravity environment in space. Additional features of the VGX allow for networking multiple users over the internet and operation of tele-robotic devices through an intuitive user interface. Although the system was developed for astronaut training and assisting support crews, Earthbound applications, many emphasizing homeland security, have also been identified. Examples include training experts to handle hazardous biological and/or chemical agents in a safe simulation, operation of telerobotic systems for assessing and diffusing threats such as bombs, and providing remote medical assistance to field personnel through a collaborative virtual environment. Thus, the emerging VGX simulation technology, while developed for spacebased applications, can serve a dual use facilitating homeland security here on Earth. © 2003 by the American Institute of Aeronautics and Astronautics, Inc.",,"Biohazards; Bioinformatics; Design of experiments; E-learning; Integration testing; International cooperation; Manned space flight; National security; Personnel training; Robotics; Security systems; Space stations; Technology transfer; User interfaces; Collaborative virtual environment; Extra vehicular activities; Immersive virtual environments; International Space stations; Intuitive user interface; Microgravity environments; Simulation technologies; Space station experiments; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85088723367
"Borst C.W., Volz R.A.","9736479200;7006417396;","Observations on and modifications to the Rutgers Master to support a mixture of passive haptics and active force feedback",2003,"Proceedings - 11th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, HAPTICS 2003",,, 1191335,"430","437",,7,"10.1109/HAPTIC.2003.1191335","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954276679&doi=10.1109%2fHAPTIC.2003.1191335&partnerID=40&md5=4dc4d991d30d98941bb35b782014074f","Center for Advanced Computer Studies, University of Louisiana at Lafayette, Lafayette, LA  70504, United States; Department of Computer Science, Texas A and M University, College Station, TX  77843, United States","Borst, C.W., Center for Advanced Computer Studies, University of Louisiana at Lafayette, Lafayette, LA  70504, United States; Volz, R.A., Department of Computer Science, Texas A and M University, College Station, TX  77843, United States","We are researching the use of haptic feedback during user interactions with a virtual control panel. One approach we consider is a combination of passive haptics and active force feedback. We use a static panel for the passive component and a Rutgers Master system for the active component. This mixed approach requires higher spatial accuracy and haptic quality than has been required by previous applications of force-feedback gloves. We relate the capabilities and limitations of the device to the requirements of our approach and describe a number of developments that result in a successful mix of passive haptics and active force feedback. These are useful for other applications of the device, and some can be generalized to other equipment. © 2003 IEEE.","Application software; Computer science; Control systems; Displays; Force control; Force feedback; Haptic interfaces; Software systems; Virtual environment; Virtual reality","Application programs; Computer control systems; Computer science; Computer software; Control systems; Display devices; Force control; Mice (computer peripherals); Remote control; Virtual reality; Active components; Force feedback; Haptic feedbacks; Mixed approach; Software systems; Spatial accuracy; User interaction; Virtual control; Haptic interfaces",Conference Paper,"Final","",Scopus,2-s2.0-77954276679
"Schulze J.P., Lang U.","24460807500;57220486048;","The parallelized perspective shear-warp algorithm for volume rendering",2003,"Parallel Computing","29","3",,"339","354",,6,"10.1016/S0167-8191(02)00250-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037362973&doi=10.1016%2fS0167-8191%2802%2900250-8&partnerID=40&md5=7da02f39091e463cc455fc2c01332a58","High Perf. Comp. Center Stuttgart, HLRS, Allmandring 30, 70550 Stuttgart, Germany","Schulze, J.P., High Perf. Comp. Center Stuttgart, HLRS, Allmandring 30, 70550 Stuttgart, Germany; Lang, U., High Perf. Comp. Center Stuttgart, HLRS, Allmandring 30, 70550 Stuttgart, Germany","The shear-warp algorithm for volume rendering is among the fastest volume rendering algorithms. It is an object-order algorithm, based on the idea of the factorization of the view matrix into a 3D shear and a 2D warp component. Thus, the compositing can be done in sheared object space, which allows the algorithm to take advantage of data locality. Although the idea of a perspective projection shear-warp algorithm is not new, it is not widely used so far. That may be because it is slower than the parallel projection algorithm and often slower than hardware supported approaches. In this paper, we present a new parallelized version of the perspective shear-warp algorithm. The parallelized algorithm was designed for distributed memory machines using MPI. The new algorithm takes advantage of the idea that the warp can be done in most computers' graphics hardware very fast, so that the remote parallel computer only needs to do the compositing. Our algorithm uses this idea to do the compositing on the remote machine, which transfers the resulting 2D intermediate image to the display machine. Even though the display machine can be a mid range PC or laptop computer, it can be used to display complex volumetric data, provided there is a network connection to a high performance parallel computer. Furthermore, remote rendering could be used to drive virtual environments, which typically require perspective projection and high frame rates for stereo projection and multiple screens. © 2002 Elsevier Science B.V. All rights reserved.","Remote computing; Shear-warp algorithm; Volume rendering","Computer hardware; Computer networks; Data storage equipment; Display devices; Laptop computers; Virtual reality; Volume rendering; Parallel algorithms",Article,"Final","",Scopus,2-s2.0-0037362973
"Akgunduz A., Banerjee P.","57203259871;35580367600;","A supervisory data-traffic controller in collaborative virtual reality simulations",2002,"American Society of Mechanical Engineers, Manufacturing Engineering Division, MED","13",,,"71","78",,,"10.1115/IMECE2002-32470","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0348144609&doi=10.1115%2fIMECE2002-32470&partnerID=40&md5=252611062ea2bba9d86d63b0ed909a53","Analyst-Res./Devmt. Info. Syst. D., United Airlines, P.O. Box 66100, Chicago, IL 60666-0100, United States; Department of Mechanical Engineering, 2039 Engineering Research Facility, University of Illinois at Chicago, 842 W. Taylor St., Chicago, IL 60607, United States","Akgunduz, A., Analyst-Res./Devmt. Info. Syst. D., United Airlines, P.O. Box 66100, Chicago, IL 60666-0100, United States; Banerjee, P., Department of Mechanical Engineering, 2039 Engineering Research Facility, University of Illinois at Chicago, 842 W. Taylor St., Chicago, IL 60607, United States","In this paper an efficient technique for distributing the data in collaborative virtual reality is presented. The described technique incorporates the culling and level of detail concepts in virtual reality to obtain cell based bounding volumes in each virtual environment. Defined bounding volumes are utilized in filtering the data that is transferred between different virtual environments in the simulation system. To orchestrate the communication between virtual environments and their bounding volumes, a supervisory control system is presented in the paper.",,"Data traffic controllers; Real time simulation; Algorithms; Computer simulation; Computer workstations; Control system analysis; Data acquisition; Data transfer; Internet; Personnel training; Product design; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-0348144609
"Schulze J.P., Lang U.","24460807500;57220486048;","The parallelization of the perspective shear-warp volume rendering algorithm",2002,"Eurographics Workshop on Parallel Graphics and Visualization",,,,"61","69",,12,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036988154&partnerID=40&md5=6c44bfd4164f63f6dfe7861cdfc5d672","High Perf. Comp. Center Stuttgart, HLRS, Allmandring 30, 70550 Stuttgart, Germany","Schulze, J.P., High Perf. Comp. Center Stuttgart, HLRS, Allmandring 30, 70550 Stuttgart, Germany; Lang, U., High Perf. Comp. Center Stuttgart, HLRS, Allmandring 30, 70550 Stuttgart, Germany","The shear-warp algorithm for volume rendering is among the fastest volume rendering algorithms. It is an object-order algorithm, based on the idea of the factorization of the view matrix into a 3D shear and a 2D warp component. Thus, the compositing can be done in sheared object space, which allows the algorithm to take advantage of data locality. Although the idea of a perspective projection shear-warp algorithm is not new, it is not widely used. That may be because it is slower than the parallel projection algorithm and often slower than hardware supported approaches. In this paper, we present a new parallelized version of the perspective shear-warp algorithm. The parallelized algorithm was designed for distributed memory machines using MPI. The new algorithm takes advantage of the idea that the warp can be done in most computers' graphics hardware very fast, so that the remote parallel computer only needs to do the compositing. Our algorithm uses this idea to do the compositing on the remote machine, which transfers the resulting 2D intermediate image to the actual display machine. Even though the display machine could be a moderately equipped PC or laptop computer, it can be used to display complex volumetric data, provided there is a network connection to a high performance parallel computer. Furthermore, remote rendering could be used to drive virtual environments, which typically require perspective projection and high frame rates for stereo projection and multiple screens.",,"Algorithms; Computer hardware; Data reduction; Personal computers; Three dimensional computer graphics; Virtual reality; Volume rendering algorithms; Parallel processing systems",Conference Paper,"Final","",Scopus,2-s2.0-0036988154
"Rose F.D., Brooks B.M., Attree E.A.","7102651672;7201573008;6603053737;","An exploratory investigation into the usability and usefulness of training people with learning disabilities in a virtual environment",2002,"Disability and Rehabilitation","24","11-12",,"627","633",,32,"10.1080/09638280110111405","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037142868&doi=10.1080%2f09638280110111405&partnerID=40&md5=0b350e839b02ae69c5fb916a59549196","School of Psychology, University of East London, London E15 4LZ, United Kingdom","Rose, F.D., School of Psychology, University of East London, London E15 4LZ, United Kingdom; Brooks, B.M., School of Psychology, University of East London, London E15 4LZ, United Kingdom; Attree, E.A., School of Psychology, University of East London, London E15 4LZ, United Kingdom","Purpose: Two studies sought to answer the following questions. Are people with learning disabilities capable of using a virtual environment? Are they motivated to learn using this training method? Do they show any benefit from using a virtual environment? Does any benefit transfer to improved real world performance? Method: In the first study, 30 students with learning disabilities were sequentially allocated to an active or a passive experimental group. Active participants explored a virtual bungalow searching for a toy car. Passive participants watched the exploration undertaken by the preceding active participant and searched for the toy car. All participants then performed spatial and object recognition tests of their knowledge of the virtual environment. In the second study, the errors of 45 participants on a real steadiness tester task were noted before they were randomly allocated to three groups-a real training group, a virtual training group and a no training group. After training, the participants performed a second test trial on the real steadiness tester. Results: The students were capable of using a virtual environment and were motivated to use this training method. Active exploration of a virtual environment was found to enhance their memory of the spatial layout of the bungalow but not their memory of the virtual objects. In the second study, virtual training was found to transfer to real task performance. Conclusions: These two laboratory-based studies provide answers to four important questions concerning virtual training of people with learning disabilities. Hopefully, the findings will encourage this training aid to be used more widely.",,"adolescent; adult; article; clinical trial; computer program; computer simulation; controlled clinical trial; controlled study; female; human; learning disorder; major clinical study; male; motivation; priority journal; psychologic test; randomized controlled trial; recognition; spatial memory; student; task performance; virtual reality; vocational education; Achievement; Adolescent; Adult; Cohort Studies; Education, Special; Educational Measurement; Female; Great Britain; Humans; Learning Disorders; Male; Middle Aged; Program Evaluation; Sampling Studies; Task Performance and Analysis; Teaching; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-0037142868
"Yang U., Kim G.J.","7006006027;7403061980;","Implementation and evaluation of ""just follow me"": An immersive, VR-based, motion-training system",2002,"Presence: Teleoperators and Virtual Environments","11","3",,"304","323",,91,"10.1162/105474602317473240","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036625537&doi=10.1162%2f105474602317473240&partnerID=40&md5=5a670f3cffae5bb3c1b2a98769e0a833","Virtual Reality Laboratory, Dept. of Comp. Sci. and Engineering, Pohang Univ. of Sci. and Technology, San 31 Hyoja-dong, Pohang, Kyungbuk 790-784, South Korea","Yang, U., Virtual Reality Laboratory, Dept. of Comp. Sci. and Engineering, Pohang Univ. of Sci. and Technology, San 31 Hyoja-dong, Pohang, Kyungbuk 790-784, South Korea; Kim, G.J., Virtual Reality Laboratory, Dept. of Comp. Sci. and Engineering, Pohang Univ. of Sci. and Technology, San 31 Hyoja-dong, Pohang, Kyungbuk 790-784, South Korea","Training is usually regarded as one of the most natural application areas of virtual reality (VR). To date, most VR-based training systems have been situation based, but this paper examines the utility of VR for a different class of training: learning to execute exact motions, which are often required in sports and the arts. In this paper, we propose an interaction method, called Just Follow Me (JFM), that uses an intuitive ""ghost"" metaphor and a first-person viewpoint for effective motion training. Using the ghost metaphor (GM), JFM visualizes the motion of the trainer in real time as a ghost (initially superimposed on the trainee) that emerges from one's own body. The trainee who observes the motion from the first-person viewpoint ""follows"" the ghostly master as closely as possible to learn the motion. Our basic hypothesis is that such a VR system can help a student learn motion effectively and quickly, comparably to the indirect real-world teaching methods. Our evaluation results show that JFM produces training and transfer effects as good as - and, in certain situations, better than - in the real world. We believe that this is clue to the more direct and correct transfer of proprioceptive information from the trainer to the trainee.",,"Ghost metaphor; Human computer interaction; Motion planning; Personnel training; Students; Virtual reality",Article,"Final","",Scopus,2-s2.0-0036625537
"Hartling P., Bierbaum A., Cruz-Neira C.","6507457478;6602548125;57203797818;","Virtual reality interfaces using Tweek",2002,"ACM SIGGRAPH 2002 Conference Abstracts and Applications, SIGGRAPH 2002",,,,"278","",,7,"10.1145/1242073.1242291","https://www.scopus.com/inward/record.uri?eid=2-s2.0-32644461902&doi=10.1145%2f1242073.1242291&partnerID=40&md5=900161c3c17e448628671b4d451d6150","Virtual Reality Applications Center (VRAC), Iowa State University, United States","Hartling, P., Virtual Reality Applications Center (VRAC), Iowa State University, United States; Bierbaum, A., Virtual Reality Applications Center (VRAC), Iowa State University, United States; Cruz-Neira, C., Virtual Reality Applications Center (VRAC), Iowa State University, United States","Developers of virtual environments often face a difficult problem: users must have some way to interact with the virtual world. The application developers must determine how to map available inputs (buttons, gestures, etc.) to actions within the virtual environment (VE). As a result, user interfaces may be limited by the input hardware available with a given virtual reality (VR) system. To address such limitations, we have developed Tweek, a middleware tool that presents users with an extensible Java graphical user interface (GUI) capable of communicating with VR applications. Tweek can run on desktop computers, on palmtop computers in projection-based virtual reality systems, or in a three-dimensional virtual space. We use Tweek to address some limitations of input and interaction within virtual environments (VEs) by designing GUIs that utilize familiar two-dimensional (2D) components. Interaction techniques that require fine-grained control or high-precision input are often better suited to 2D interfaces than the use of gestures or buttons on a wand [Hill 2000]. The use of Java-based GUIs for interaction within VEs has been investigated in previous works at the VRAC. The first such work investigated the usability of a palmtop system with a Java GUI to interact with and manipulate a virtual space [Hill 2000]. Tweek extends this research by generalizing the interaction capabilities and the dynamic GUI component loading. Tweek is a collection of multiple technologies: C++, Java, JavaBeans, and CORBA. Combined, these allow a Java GUI composed of plug-ins to communicate with a C++ application. Our implementation aims to simplify the inter-language communication so that programmers can make use of Tweek in their VR applications without knowing all the details of the individual technologies. At the heart of the inter-language communication is CORBA, the Common Object Request Broker Architecture [OMG 2001]. It provides a cross-platform, language-independent method for distributed objects to communicate. In Tweek, it manages all communication between the Java GUI and the C++ VR application. Because CORBA is language-independent, there exists the potential for use of other languages besides Java and C++. The Java GUI itself is a generalized framework that loads JavaBeans [JavaSoft 1997] dynamically using XML-based descriptions. The JavaBeans may encapsulate any functionality, but those that extend the GUI are crucial to the use of Tweek in a VE. Such graphical JavaBeans are written by the VR application developers and are customized for use with a given application. Dynamic extension of the GUI allows the VR application to add components to the interface while the user is active within the virtual space. Through dynamically extensible input, we can explore new possibilities for interactivity in VEs.",,"C++ (programming language); Common object request broker architecture (CORBA); Computational linguistics; Computer graphics; Fasteners; Graphical user interfaces; Interactive computer graphics; Middleware; Personal computers; User interfaces; Virtual addresses; Virtual reality; Application developers; Individual technology; Interaction techniques; Java graphical user interface; Language communication; Two Dimensional (2 D); Virtual reality interfaces; Virtual reality system; Java programming language",Conference Paper,"Final","",Scopus,2-s2.0-32644461902
"Kaufmann H., Schmalstieg D.","7203004662;55101019100;","Mathematics and geometry education with collaborative augmented reality",2002,"ACM SIGGRAPH 2002 Conference Abstracts and Applications, SIGGRAPH 2002",,,,"37","41",,79,"10.1145/1242073.1242086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945962878&doi=10.1145%2f1242073.1242086&partnerID=40&md5=cd3ae11246c24f1a573439d80740e178","Vienna University of Technology, Austria","Kaufmann, H., Vienna University of Technology, Austria; Schmalstieg, D., Vienna University of Technology, Austria","Construct3D is a three-dimensional geometric construction tool specifically designed for mathematics and geometry education. It is based on the mobile collaborative augmented reality system ""Studierstube."" We describe our efforts in developing a system for the improvement of spatial abilities and maximization of transfer of learning. In order to support various teacher-student interaction scenarios we implemented flexible methods for context and user dependent rendering of parts of the construction. Together with hybrid hardware setups they allow the use of Construct3D in today's classrooms and provide a test bed for future evaluations. Means of application and integration in mathematics and geometry education at the high school, as well as the university, level are being discussed. Anecdotal evidence supports our claim that Construct3D is easy to learn, encourages experimentation with geometric constructions, and improves spatial skills.","Augmented reality; Geometry education; Mathematics education; Spatial intelligence","Augmented reality; Computer graphics; Geometry; Interactive computer graphics; Teaching; Anecdotal evidences; Collaborative augmented realities; Geometric construction; Mathematics education; Spatial abilities; Spatial intelligence; Student interactions; Transfer of learning; Education",Conference Paper,"Final","",Scopus,2-s2.0-84945962878
"Williams A.M., Ward P., Knowles J.M., Smeeton N.J.","35580552000;56745348700;7203054639;7003756741;","Anticipation skill in a real-world task: Measurement, training, and transfer in tennis",2002,"Journal of Experimental Psychology: Applied","8","4",,"259","270",,265,"10.1037/1076-898X.8.4.259","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036982692&doi=10.1037%2f1076-898X.8.4.259&partnerID=40&md5=283502f82e615bd90a82d1b5233724da","Liverpool John Moores University, United Kingdom; Res. Inst. Sport and Exercise Sci., Liverpool John Moores University, Liverpool, United Kingdom; Res. Inst. Sport and Exercise Sci., Liverpool John Moores University, Henry Cotton Building, 15-21 Webster Street, Liverpool L3 2ET, United Kingdom","Williams, A.M., Liverpool John Moores University, United Kingdom, Res. Inst. Sport and Exercise Sci., Liverpool John Moores University, Liverpool, United Kingdom, Res. Inst. Sport and Exercise Sci., Liverpool John Moores University, Henry Cotton Building, 15-21 Webster Street, Liverpool L3 2ET, United Kingdom; Ward, P., Liverpool John Moores University, United Kingdom, Res. Inst. Sport and Exercise Sci., Liverpool John Moores University, Liverpool, United Kingdom; Knowles, J.M., Liverpool John Moores University, United Kingdom, Res. Inst. Sport and Exercise Sci., Liverpool John Moores University, Liverpool, United Kingdom; Smeeton, N.J., Liverpool John Moores University, United Kingdom, Res. Inst. Sport and Exercise Sci., Liverpool John Moores University, Liverpool, United Kingdom","Anticipation skill in tennis was examined using realistic film simulations, movement-based response measures, and a portable eye movement recording system. Skilled players were faster than their less skilled counterparts in anticipating the direction of opponents' tennis strokes, with this superior performance being based, at least in part, on more effective visual search behaviors. The processes mediating superior performance were then modeled in groups of recreational tennis players using video simulation, instruction, and feedback. Players who received perceptual training improved their performance on laboratory- and field-based tests of anticipation when compared with matched placebo and control groups that did not receive any instruction regarding expert performance strategies. The approach used may have practical utility in a variety of performance contexts.",,"adult; article; eye movement; human; learning; male; motor performance; teaching; tennis; vision; Adult; Eye Movements; Humans; Learning; Male; Motor Skills; Teaching; Tennis; Visual Perception",Article,"Final","",Scopus,2-s2.0-0036982692
"Jansson J., Vergeest J.S.M.","57197464872;7003883586;","A discrete mechanics model for deformable bodies",2002,"CAD Computer Aided Design","34","12",,"913","928",,33,"10.1016/S0010-4485(01)00146-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036778825&doi=10.1016%2fS0010-4485%2801%2900146-4&partnerID=40&md5=4fad7fe3bada5bcd273e7d87a330256b","Faculty of Design, Engineering and Production, Delft University of Technology, Delft, Netherlands","Jansson, J., Faculty of Design, Engineering and Production, Delft University of Technology, Delft, Netherlands; Vergeest, J.S.M., Faculty of Design, Engineering and Production, Delft University of Technology, Delft, Netherlands","This paper describes the theory and implications of a discrete mechanics model for deformable bodies, incorporating behavior such as motion, collision, deformation, etc. The model is fundamentally based on inter-atomic interaction, and recursively reduces resolution by approximating collections of many high-resolution elements with fewer lower-resolution elements. The model can be viewed as an extended mass-spring model. We begin by examining the domain of conceptual design, and find there is a need for physics based simulation, both for interactive shape modeling and analysis. We then proceed with describing a theoretical base for our model, as well as pragmatic additions. Applications in both interactive physics based shape modeling and analysis are presented. The model is aimed at conceptual mechanical design, rapid prototyping, or similar areas where adherence to physical principles, generality and simplicity are more important than metric correctness. © 2002 Elsevier Science Ltd. All rights reserved.","Collison; Conceptual design; Deformable bodies; Deformation; Geometric modeling; Mechanics model; Virtual claying","Computational geometry; Computer simulation; Deformation; Product design; Discrete mechanics model; Computer aided design",Article,"Final","",Scopus,2-s2.0-0036778825
"Kauff P., Fehn C., Cooke E., Schreer O.","55897026000;35577120600;9239906800;6603359258;","Advanced incomplete 3D representation of video objects using trilinear warping for novel view synthesis",2001,"22nd Picture Coding Symposium",,,,"429","432",,5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035786166&partnerID=40&md5=bf48c16234532b655bf78f7095a27729","Heinrich-Hertz-Institut, Einsteinufer 37, D-10587 Berlin, Germany","Kauff, P., Heinrich-Hertz-Institut, Einsteinufer 37, D-10587 Berlin, Germany; Fehn, C., Heinrich-Hertz-Institut, Einsteinufer 37, D-10587 Berlin, Germany; Cooke, E., Heinrich-Hertz-Institut, Einsteinufer 37, D-10587 Berlin, Germany; Schreer, O., Heinrich-Hertz-Institut, Einsteinufer 37, D-10587 Berlin, Germany","We present a synthesis method for arbitrary virtual views in a multi-view camera set-up. This method generates a view adaptable reconstruction of a 3-dimensional, (3D), object taken from at least two cameras. In this method, we exploit the recently developed Incomplete 3D, (IC3D), algorithm, a compact disparity-based representation of stereo images. Previously, only virtual views inside the baseline of a parallel stereo rig capturing a mainly convex 3D object could be described by IC3D. Hence, the field of applications in virtual environments (VE) was restricted. Thus, to be able to create virtual views of generic 3D objects for camera positions outside the baseline of a convergent multiview set-up, we extended the original IC3D approach towards a more generalised approach, using rectification, trilinear warping, image-based rendering and hidden layer techniques to synthesise new virtual camera views.",,"Algorithms; Cameras; Image reconstruction; Motion pictures; Real time systems; Virtual reality; Image-based rendering; Image processing",Conference Paper,"Final","",Scopus,2-s2.0-0035786166
"Patterson P.E.","7201502940;","Employing 3D virtual reality games to develop ANN for device control: A pilot study",2001,"Biomedical Sciences Instrumentation","37",,,"475","478",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035031919&partnerID=40&md5=acec96bb583f7f78bff483b0e855f6ff","College of Engineering, Iowa State University, Ames, IA 50011, United States","Patterson, P.E., College of Engineering, Iowa State University, Ames, IA 50011, United States","Non-immersive virtual reality (VR) game scenarios were developed to aid in the collection of EMG parameters from the biceps and triceps while subjects performed a sequenced series of tasks in the virtual environment. For each subject the best ANN configuration (combination of hidden layers and transfer functions) was chosen, with the resulting optimized algorithms used to classify the sequence of contractions and the function type of the subjects while playing new game scenarios. The wide variety of individually configured ANN developed show why it is difficult to train new users of myoelectric devices with a single algorithm. The use of VR-based games shows promise as a training technique for individuals needing to develop control for prosthetic limbs.","Myoelectric signal; Pattern recognition; Prosthetic control","Algorithms; Biomechanics; Computer simulation; Electromyography; Muscle; Neural networks; Virtual reality; Non immersive virtual reality; Myoelectrically controlled prosthetics; adult; algorithm; artificial neural network; conference paper; device; electromyogram; game; human; human experiment; male; pattern recognition; virtual reality; Adult; Artificial Limbs; Electromyography; Games, Experimental; Humans; Male; Muscle Contraction; Muscle, Skeletal; Neural Networks (Computer); Patient Education; Pilot Projects; User-Computer Interface",Conference Paper,"Final","",Scopus,2-s2.0-0035031919
"Mania K., Chalmers A.","6602471750;7102938771;","The effects of levels of immersion on memory and presence in virtual environments: A reality centered approach",2001,"Cyberpsychology and Behavior","4","2",,"247","264",,119,"10.1089/109493101300117938","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035025714&doi=10.1089%2f109493101300117938&partnerID=40&md5=26852521731b4b257f035d8219dcfc28","University of Bristol, Bristol, United Kingdom","Mania, K., University of Bristol, Bristol, United Kingdom; Chalmers, A., University of Bristol, Bristol, United Kingdom","Simulation fidelity is characterized as the extent to which a Virtual Environment (VE) and relevant interactions with it are indistinguishable from a user's interaction with a real environment. The growing number of VE training applications which target a high level of simulation fidelity mainly for transfer of training in the real world have made it crucial to examine the manner in which these particular implementations and designs are evaluated. The methodology presented in this study focuses on real versus simulated virtual worlds comparing participants' level of presence task performance and cognition state employed to complete a memory task. A 15-minute seminar was presented in four different conditions including real 3D desktop 3D Head Mounted Display (HMD) and Audio-only (between-subjects design). Four independent groups of 18 participants took part in the experiment which investigated the effects of levels of immersion on participants' memory recall and memory awareness state (relevant to episodic and semantic memory types) as well as on their perception of the experimental space and sense of presence for every condition. The level of reported presence was not positively associated with accurate memory recall in all conditions although the scores for both presence and seminar memory recall in the ""real"" condition were statistically higher. Memory awareness states' analysis gave a invaluable insight into ""how"" participants remembered both communicated information and space as opposed to ""what, "" most interestingly across specific conditions where results for presence and accurate memory recall were not proven to be significant.",,"article; auditory stimulation; awareness; cognition; female; human; human experiment; image display; immersion; male; memory; normal human; recall; simulation; task performance; virtual reality; Adult; Female; Humans; Internet; Male; Memory; Motion Sickness; Questionnaires; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-0035025714
"Frank A.O., Twombly I.A., Barth T.J., Smith J.D.","7401661096;6508302129;56232127500;56909047500;","Finite element methods for real-time haptic feedback of soft-tissue models in virtual reality simulators",2001,"Proceedings - Virtual Reality Annual International Symposium",,,,"257","263",,26,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035064610&partnerID=40&md5=16a8d20384aa3c0242662856bcfdf398","Center for Bioinformatics, NASA Ames Research Center, Moffet Field, CA 94035, United States","Frank, A.O., Center for Bioinformatics, NASA Ames Research Center, Moffet Field, CA 94035, United States; Twombly, I.A., Center for Bioinformatics, NASA Ames Research Center, Moffet Field, CA 94035, United States; Barth, T.J., Center for Bioinformatics, NASA Ames Research Center, Moffet Field, CA 94035, United States; Smith, J.D., Center for Bioinformatics, NASA Ames Research Center, Moffet Field, CA 94035, United States","We have applied the linear elastic finite element method to compute haptic force feedback and domain deformations of soft tissue models for use in virtual reality simulators. Our results show that, for virtual object models of high-resolution 3D data (> 10, 000 nodes), haptic real time computations (> 500 Hz) are not currently possible using traditional methods. Current research efforts are focused in the following areas: 1) efficient implementation of fully adaptive multi-resolution methods and 2) multi-resolution methods with specialized basis functions to capture the singularity at the haptic interface (point loading). To achieve real time computations, we propose parallel processing of a Jacobi preconditioned conjugate gradient method applied to a reduced system of equations resulting from surface domain decomposition. This can effectively be achieved using reconfigurable computing systems such as field programmable gate arrays (FPGA), thereby providing a flexible solution that allows for new FPGA implementations as improved algorithms become available. The resulting soft tissue simulation system would meet NASA Virtual Glovebox requirements and, at the same time, provide a generalized simulation engine for any immersive environment application, such as biomedical/surgical procedures or interactive scientific applications.",,"Algorithms; Computation theory; Computer simulation; Feedback; Field programmable gate arrays; Finite element method; Haptic interfaces; Parallel processing systems; Real time systems; Conjugate gradient methods; Soft-tissue models; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-0035064610
"Elkind J.S., Rubin E., Rosenthal S., Skoff B., Prather P.","6603963465;37093791700;57192665431;57192663131;7003715620;","A simulated reality scenario compared with the computerized Wisconsin Card Sorting Test: An analysis of preliminary results",2001,"Cyberpsychology and Behavior","4","4",,"489","496",,54,"10.1089/109493101750527042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034802753&doi=10.1089%2f109493101750527042&partnerID=40&md5=d44aeeb14865dd4bd8b67b6db86ae95b","Jewish Family and Children’s Service, Boston, MA, United States; Center for Counseling and Student Development, Northeastern University, Boston, MA, United States; Massachusetts School of Professional Psychology, West Roxbury, MA, United States; North Shore Children’s Hospital, Salem, MA, United States; Educational Enhancement Center, Department of Neurology and Neuropsychology, Boston University School of Medicine, Boston, MA, United States","Elkind, J.S., Jewish Family and Children’s Service, Boston, MA, United States; Rubin, E., Center for Counseling and Student Development, Northeastern University, Boston, MA, United States; Rosenthal, S., Massachusetts School of Professional Psychology, West Roxbury, MA, United States; Skoff, B., North Shore Children’s Hospital, Salem, MA, United States; Prather, P., Educational Enhancement Center, Department of Neurology and Neuropsychology, Boston University School of Medicine, Boston, MA, United States","Neuropsychologists and other clinicians often comment on the minimal relationship that frequently exists between formal assessments of executive functions, analysis of findings, recommendations, and the person’s real-life functioning. The authors’ believe that current assessments of executive functions do not transfer easily to real-world behavior. There are limitations in the current examinations and in the settings in which they are given. The tests are artificial and the test settings lack the usual stresses, distractions, and multiple demands common to real life. The interactions are unlike what they experience in everyday life. The examiner often, but unintentionally orients the participant to relevant information that in turn can help the person compensate for the difficulties with executive control processes and bias the findings. We believe that virtual reality (VR) more closely approximates real life settings, the distractions, and the common interchanges (VR) provides a ""life-like,"" three-dimensional (3-D) highly interactive environment, and safety from potential dangers that could arise in actual situations. VR can increase motivation because of its gaming, interactive, and immersive qualities and features are easily modified and allow for multiple applications. Our goal is to develop VR assessments that can be administered under controlled and safe conditions, but which are more sensitive to difficulties with executive control processes critical to safe, independent living. This initial study compares several functions assessed by the Wisconsin Card Sorting Test (WCST) with our three-dimensional, stereographic scenario, Look for a Match (LFAM) Study participants completed questionnaires, alternately began with either the WCST or LFAM, and then took the second test. All participants completed motion sickness and follow-up questionnaires. The results demonstrated that the study participants found LFAM to be more enjoyable and interesting, but found the WCST to be easier. While there is an effect of order with participants doing relatively better on the assessment tool administered second, overall the LFAM performance was inferior to that on the WCST. However, even considering the order effect, LFAM seemed to be more difficult than the WCST.",,"article; cognition; computer; experience; human; motion sickness; motivation; neuropsychological test; neuropsychology; psychologic assessment; questionnaire; safety; virtual reality; wisconsin card sorting test; Adolescent; Adult; Aged; Attitude to Computers; Computer Systems; Diagnosis, Computer-Assisted; Female; Humans; Imaging, Three-Dimensional; Male; Middle Aged; Neuropsychological Tests; Psychometrics; Reproducibility of Results; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-0034802753
"Söderman M.","56439297700;","Product representations: Exploring computer-based technologies and customers' understanding of product concepts",2001,"Doktorsavhandlingar vid Chalmers Tekniska Hogskola",,"1771",,"1","65",,1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035196824&partnerID=40&md5=b561449350322748634ca69ec87ae84f","Dept. of Product and Production Dev., Division of Human Factors Eng., Chalmers University of Technology, Göteborg 2001, Sweden","Söderman, M., Dept. of Product and Production Dev., Division of Human Factors Eng., Chalmers University of Technology, Göteborg 2001, Sweden","A large proportion of new products does not succeed on the market. One explanation is that companies have misinterpreted, or not succeeded in identifying the needs and requirements of their customers. A focus on the customer, especially in the early stages in the product development, has been argued to improve product quality and customer satisfaction. A prerequisite of achieving knowledge about the customer is that developers and customers communicate on the basis of a shared understanding. For this purpose, product representations, e.g. sketches, mock-ups and virtual reality representations can function as communication tools. The demands for efficient product development have resulted in an interest in new computer-based technologies and arguments that virtual reality can replace costly physical prototypes. However, little is known about what customers understand of product concepts through different product representations. Thus, knowledge of product representations can be of importance to manage a product concept evaluation in an efficient way. This thesis has aimed at gaining knowledge for an efficient use of product representations in communication with customers. One question concerned the use of product representations in industry for communication with customers. The studies indicated that product representations were used between the developers for evaluations of technical matters and not used as tools in communication with customers. Moreover, virtual reality was widely considered as very effective for the understanding of product concepts, even though most companies had not used virtual reality in product development. Thus, the conception of virtual reality reflected high expectations rather than actual experiences. The main question in this research concerned computer-based technologies' and conventional product representations' effect on customers' understanding of product concepts. A series of exploratory studies revealed that an increasing degree of realism in the product representations was not always reflected in an increased understanding of the products. This implies that the information provided by a product representation was not necessarily the information required by the participants for enhanced understanding. Certain product aspects were more important than others for enhanced understanding, in this case, tactile interaction and scale. This thesis argues that customers' understanding of product concepts through product representations is determined by several interrelating factors and that the type of product representation is but one factor. Other important factors are the participants' product knowledge and the participants' product representation knowledge.","Customer communication; Product concepts; Product development; Product knowledge; Product representation knowledge; Product representations; Understanding","Computer aided engineering; Customer satisfaction; Marketing; Quality control; Technology transfer; Virtual reality; Customer communication; Product concepts; Product knowledge; Product representations; Product development",Article,"Final","",Scopus,2-s2.0-0035196824
"Gourlay D., Lun K.C., Lee Y.N., Tay J.","15739566700;7004523484;15739807900;57196704926;","Virtual reality for relearning daily living skills",2000,"International Journal of Medical Informatics","60","3",,"255","261",,42,"10.1016/S1386-5056(00)00100-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034532146&doi=10.1016%2fS1386-5056%2800%2900100-3&partnerID=40&md5=e662b908faaf96c9ec30e221d781378e","Medical Informatics Programme, Department of Community, Occupational and Family Medicine, National University of Singapore, Lower Kent Ridge Road, 119260 Singapore, Singapore","Gourlay, D., Medical Informatics Programme, Department of Community, Occupational and Family Medicine, National University of Singapore, Lower Kent Ridge Road, 119260 Singapore, Singapore; Lun, K.C., Medical Informatics Programme, Department of Community, Occupational and Family Medicine, National University of Singapore, Lower Kent Ridge Road, 119260 Singapore, Singapore; Lee, Y.N., Medical Informatics Programme, Department of Community, Occupational and Family Medicine, National University of Singapore, Lower Kent Ridge Road, 119260 Singapore, Singapore; Tay, J., Medical Informatics Programme, Department of Community, Occupational and Family Medicine, National University of Singapore, Lower Kent Ridge Road, 119260 Singapore, Singapore","The explosive increase in the power of computers has enabled the creation of fast, interactive 3D environments, sometimes called virtual reality (VR). This technology, often associated with arcade games, is increasingly being used for more serious applications. This paper describes research showing transfer of skills from a virtual environment to the real world. We then describe our VR authoring tool and an application to help cognitively impaired individuals relearn important daily living skills. Additionally we describe the development of a prototype networked system to enable a doctor to monitor remotely the rehabilitation of a group of patients. © 2000 Elsevier Science Ireland Ltd.",,"Computer applications; Health care; Patient monitoring; Patient rehabilitation; Telemedicine; Head mounted display; Traumatic brain injury; Virtual reality; cognitive defect; computer; daily life activity; human; learning; patient monitoring; physician attitude; priority journal; rehabilitation medicine; review; technology; virtual reality; Activities of Daily Living; Brain Injuries; Cerebrovascular Accident; Cognition Disorders; Humans; Learning; Therapy, Computer-Assisted",Article,"Final","",Scopus,2-s2.0-0034532146
"Biocca F.","6701454382;","New media technology and youth: Trends in the evolution of new media",2000,"Journal of Adolescent Health","27","2 SUPPL.",,"22","29",,27,"10.1016/S1054-139X(00)00136-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034255822&doi=10.1016%2fS1054-139X%2800%2900136-1&partnerID=40&md5=379aeb571d6a6ed2c6d67b7f67aac7f3","Media Interface/Network Des. Labs, Michigan State University, 409 Commun. Arts and Sci. Building, East Lansing, MI 48824-1292, United States","Biocca, F., Media Interface/Network Des. Labs, Michigan State University, 409 Commun. Arts and Sci. Building, East Lansing, MI 48824-1292, United States","An information environment is emerging from the simultaneous, rapid, and interconnected evolution of transmission systems, interfaces, and content quantity, quality, and structure. It will be easy to underestimate the collective impact of the sum of these changes on how young people communicate and absorb information. Ultimately, it will be more important to understand how these technologies will facilitate, amplify, or alter the cognitive processes and/or social behavior of the Internet generation. The article analyzes the impact of the following trends on media use and cognition among youthful users: Information expansion and overload: Accessible networked information will continue to grow at a rapid pace for at least the next 10-20 years. Rapid increase in interface diffusion: The number of access points into the Internet is expanding in number, variety, and mobility. Evolution toward more embodied computing: Interfaces are evolving to use more of the sensorimotor system to transfer information to and from the user. The evolution of more intelligent sensors to interpret use behavior and intentions. Evolution toward anthropomorphic agent techniques: Computers are evolving to use more social and interpersonal communication techniques to interact with the user. Copyright (C) 2000 Society for Adolescent Medicine.","Evolution of technology; Human-computer interaction; Internet; Media and cognitive development; Virtual reality","adolescent; computer; conference paper; environment; human; information processing; Internet; juvenile; mass communication; priority journal; technology; Adolescent; Child; Female; Forecasting; Humans; Information Science; Internet; Male; Mass Media; Policy Making; Research Design; Technology; United States; User-Computer Interface",Conference Paper,"Final","",Scopus,2-s2.0-0034255822
"Rose F.D., Attree E.A., Brooks B.M., Parslow D.M., Penn P.R.","7102651672;6603053737;7201573008;6603112047;7004825531;","Training in virtual environments: Transfer to real world tasks and equivalence to real task training",2000,"Ergonomics","43","4",,"494","511",,208,"10.1080/001401300184378","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033998093&doi=10.1080%2f001401300184378&partnerID=40&md5=7384a9e1602bfb8d9eab17626a26382d","Department of Psychology, University of East London, Romford Road, London, E15 4LZ, United Kingdom","Rose, F.D., Department of Psychology, University of East London, Romford Road, London, E15 4LZ, United Kingdom; Attree, E.A., Department of Psychology, University of East London, Romford Road, London, E15 4LZ, United Kingdom; Brooks, B.M., Department of Psychology, University of East London, Romford Road, London, E15 4LZ, United Kingdom; Parslow, D.M., Department of Psychology, University of East London, Romford Road, London, E15 4LZ, United Kingdom; Penn, P.R., Department of Psychology, University of East London, Romford Road, London, E15 4LZ, United Kingdom","Virtual environments (VEs) are extensively used in training but there have been few rigorous scientific investigations of whether and how skills learned in a VE are transferred to the real world. This research aimed to measure and evaluate what is transferring from training a simple sensorimotor task in a VE to real world performance. In experiment 1, real world performances after virtual training, real training and no training were compared. Virtual and real training resulted in equivalent levels of post-training performance, both of which significantly exceeded task performance without training. Experiments 2 and 3 investigated whether virtual and real trained real world performances differed in their susceptibility to cognitive and motor interfering tasks (experiment 2) and in terms of spare attentional capacity to respond to stimuli and instructions which were not directly related to the task (experiment 3). The only significant difference found was that real task performance after training in a VE was less affected by concurrently performed interference tasks than was real task performance after training on the real task. This finding is discussed in terms of the cognitive load characteristics of virtual training. Virtual training therefore resulted in equivalent or even better real world performance than real training in this simple sensorimotor task, but this finding may not apply to other training tasks. Future research should be directed towards establishing a comprehensive knowledge of what is being transferred to real world performance in other tasks currently being trained in VEs and investigating the equivalence of virtual and real trained performances in these situations. © 2000 Taylor & Francis Group, LLC.","Training; Transfer; Virtual reality","Computer aided instruction; Personnel training; Virtual reality; Sensorimotor task; Virtual training; Human computer interaction; adult; article; attention; cognition; female; human; human experiment; male; motor coordination; normal human; sensorimotor function; task performance; training; virtual reality",Article,"Final","",Scopus,2-s2.0-0033998093
"Diplas C.N., Pintelas P.E.","25030106400;6701867219;","Design of interactivity in virtual reality applications with emphasis on educational software using formal interaction specification",2000,"Education and Information Technologies","5","4",,"291","304",,2,"10.1023/A:1012053507785","https://www.scopus.com/inward/record.uri?eid=2-s2.0-52849109877&doi=10.1023%2fA%3a1012053507785&partnerID=40&md5=f73eb5a3356b480b7ffee8d7ace4d11a","Educational Software Development Laboratory, Department of Mathematics, University of Patra, Greece; ESDLab., University of Patra, P.O. BOX 1399, 265 00, Patra, Greece","Diplas, C.N., Educational Software Development Laboratory, Department of Mathematics, University of Patra, Greece, ESDLab., University of Patra, P.O. BOX 1399, 265 00, Patra, Greece; Pintelas, P.E., Educational Software Development Laboratory, Department of Mathematics, University of Patra, Greece","Virtual Reality (VR) technology has already entered into the area of the educational software and delivers systems where the trainees can use interactive virtual microworlds and benefit by transfer of experience, interacting directly with the learning domain. This paper describes the Virtual Multi Flow Graph (Virtual-MFG) graphical formal model and the Interaction Specification Workspace (ISW) software architecture for the interaction specification and design of VR applications with emphasis on educational software. The interaction designer specifies the interaction issues of the final system formally, using the tools of ISW The virtual microworld's objects database is updated with these interaction specifications which include both the virtual objects' dynamic properties and their tutoring capabilities. The model is validated by applying it on an existing VR educational software (EIKON). The Virtual-MFG graphs specifying a learning scenario of EIKON along with the application of ISW on EIKON are also presented. © 2000 Kluwer Academic Publishers.","Educational software; Formal specification; Interaction design; Interaction specification; Virtual reality",,Article,"Final","",Scopus,2-s2.0-52849109877
"McGee J.S., Van Der Zaag C., Buckwalter J.G., Thiebaux M., Van Rooyen A., Neumann U., Sisemore D., Rizzo A.A.","7102023121;6507558646;7103071789;6701770846;6701803717;7103378063;55297389800;57189943380;","Issues for the assessment of visuospatial skills in older adults using virtual environment technology",2000,"Cyberpsychology and Behavior","3","3",,"469","482",,26,"10.1089/10949310050078931","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033922544&doi=10.1089%2f10949310050078931&partnerID=40&md5=1fcd853f3831221f78ca63d182897805","Andrus Gerontology Center, University of Southern California, Los Angeles, CA, United States; Integrated Media Systems Center, University of Southern California, Los Angeles, CA, United States; Information Sciences Institute, University of Southern California, Los Angeles, CA, United States; Grad. Sch. Psychol. Fuller Theol. S., Pasadena, CA, United States; Integrated Media Systems Center, University of Southern California, 3715 McClintock Avenue, Los Angeles, CA 90089-0191, United States","McGee, J.S., Andrus Gerontology Center, University of Southern California, Los Angeles, CA, United States, Grad. Sch. Psychol. Fuller Theol. S., Pasadena, CA, United States; Van Der Zaag, C., Andrus Gerontology Center, University of Southern California, Los Angeles, CA, United States; Buckwalter, J.G., Andrus Gerontology Center, University of Southern California, Los Angeles, CA, United States; Thiebaux, M., Information Sciences Institute, University of Southern California, Los Angeles, CA, United States; Van Rooyen, A., Grad. Sch. Psychol. Fuller Theol. S., Pasadena, CA, United States; Neumann, U., Integrated Media Systems Center, University of Southern California, Los Angeles, CA, United States; Sisemore, D., Andrus Gerontology Center, University of Southern California, Los Angeles, CA, United States; Rizzo, A.A., Andrus Gerontology Center, University of Southern California, Los Angeles, CA, United States, Integrated Media Systems Center, University of Southern California, Los Angeles, CA, United States, Integrated Media Systems Center, University of Southern California, 3715 McClintock Avenue, Los Angeles, CA 90089-0191, United States","Virtual Environment (VE) technology offers clinical assessment and rehabilitation options that are currently not available using traditional neuropsychological methods. Advancements in this type of immersive information technology could produce tools that enhance the scientific study of human cognitive/functional processes and improve our capacity to more accurately assess and treat impairments found in persons with central nervous system (CNS) dysfunction. Through the creation of dynamic three-dimensional (3D) stimulus environments, in which all behavioral responding can be recorded, VE technology offers the possibility to more sensitively address a range of age-related CNS disorders including Alzheimer's Disease, Vascular Dementia, Parkinson's Disease, and stroke. Advances in this area could impact quality of life issues for an increasingly aging world population. The VE Laboratory at the University of Southern California has developed a suite of ImmersaDesk-format, 3D projection-based VEs. These scenarios target assessment of visuospatial skills including visual field-specific reaction time, depth perception, 3D field dependency (virtual rod and frame test), static and dynamic manual target tracking in 3D space, and spatial rotation. The current project tested healthy older adults (ages of 65 and 92). Participants were administered a standard neuropsychological battery and a suite of VE-delivered visuospatial tasks. Issues addressed in this project include: the occurrence of VE-related side effects in healthy older adults; the relationship between performance on VE measures and standard neuropsychological tests; the assessment of gender specific performance differences; the relationship between immersive tendencies, presence ratings, and VE performance in older adults; learning and generalization; and VE visuospatial performance differences between younger and older participants. This article will address the motivation, rationale, and relevant issues for use of VEs with older adults. A description of our VE system/methodology in the context of a recent study targeting assessment and possible rehabilitation of visuospatial skills with this population will then be detailed.",,"Alzheimer disease; central nervous system; conference paper; depth perception; information; neuropsychological test; psychologic assessment; rating scale; reaction time; virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-0033922544
"Rekimoto J., Saitoh M.","6603848632;7201721667;","Augmented surfaces: A spatially continuous work space for hybrid computing environments",1999,"Conference on Human Factors in Computing Systems - Proceedings",,,,"378","385",,383,"10.1145/302979.303113","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032642174&doi=10.1145%2f302979.303113&partnerID=40&md5=945f2727194e9adc96c4f418db896c99","Sony Computer Science Laboratories Inc., 3-14-13 Higashigotanda, Shinagawa-ku, Tokyo 14 l-0022, Japan; Department of Computer Science, Keio University, 3-14-1 Hiyoshi, Kohoku-ku, Yokohama, Kanagawa 223, Japan","Rekimoto, J., Sony Computer Science Laboratories Inc., 3-14-13 Higashigotanda, Shinagawa-ku, Tokyo 14 l-0022, Japan; Saitoh, M., Department of Computer Science, Keio University, 3-14-1 Hiyoshi, Kohoku-ku, Yokohama, Kanagawa 223, Japan","This paper describes our design and implementation of a computer augmented environment that allows users to smoothly interchange digital information among their portable computers, table and wall displays, and other physical objects. Supported by a camera-based object recognition system, users can easily integrate their portable computers with the pre-installed ones in the environment. Users can use displays projected on tables and walls as a spatially continuous extension of their portable computers. Using an interaction technique called hyperdragging, users can transfer information from one computer to another, by only knowing the physical relationship between them. We also provide a mechanism for attaching digital data to physical objects, such as a videotape or a document folder, to link physical and digital spaces. Copyright © 2012 ACM, Inc.","Architectural media; Augmented reality; Multiple device user interfaces; Physical space; Portable computers; Table-sized displays; Ubiquitous computing; Wall-sized displays","Architectural media; Multiple devices; Physical space; Portable computers; Wall-sized displays; Augmented reality; Computer systems; Copyrights; Microcomputers; Object recognition; Portable equipment; Ubiquitous computing; User interfaces; Cameras; Display devices; Graphical user interfaces; Pattern recognition systems; Virtual reality; Display devices; Human computer interaction; Hybrid computing environments; Multiple device user interfaces",Conference Paper,"Final","",Scopus,2-s2.0-0032642174
"Williams A.M., Grant A.","35580552000;21534342100;","Training perceptual skill in sport",1999,"International Journal of Sport Psychology","30","2",,"194","220",,136,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033114432&partnerID=40&md5=5c76a5cb932aad8935403a27c9d2788e","Res. Inst. for Sport/Exercise Sci., Liverpool John Moores University, Henry Cotton Campus, 15-21 Webster Street, Liverpool L3 2ET, United Kingdom","Williams, A.M., Res. Inst. for Sport/Exercise Sci., Liverpool John Moores University, Henry Cotton Campus, 15-21 Webster Street, Liverpool L3 2ET, United Kingdom; Grant, A.","This review considers whether there are any potential training methods to enhance the development of perceptual skill in sport. The efficacy of generalized visual skills training programs and more cognitively-based interventions are considered. Although research has neglected to examine whether improvements in perceptual skill transfer to the performance context, sport-specific training programs which develop the knowledge base underlying skilled perception are likely to be more effective than clinically-based visual skills training programs. Video technology or simulation may be particularly effective, when coupled with appropriate instructional techniques, in developing perceptual expertise in sport. Several practical and theoretical issues related to the design, implementation, and evaluation of perceptual training programs in sport are discussed and future research directions highlighted.","Anticipation; Expertise; Practice; Simulation; Transfer",,Article,"Final","",Scopus,2-s2.0-0033114432
"Jayaram Sankar, Wang Yong, Jayaram Uma, Lyons Kevin, Hart Peter","7006370060;56790199700;6603551395;7102474056;57214383101;","Virtual assembly design environment",1999,"Proceedings - Virtual Reality Annual International Symposium",,,,"172","179",,47,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032651028&partnerID=40&md5=6d316de6778c5067cc7947b3e7ee0ebc","Washington State Univ, Pullman, United States","Jayaram, Sankar, Washington State Univ, Pullman, United States; Wang, Yong, Washington State Univ, Pullman, United States; Jayaram, Uma, Washington State Univ, Pullman, United States; Lyons, Kevin, Washington State Univ, Pullman, United States; Hart, Peter, Washington State Univ, Pullman, United States","The Virtual Assembly Design Environment (VADE) is a Virtual Reality (VR) based engineering application which allows engineers to evaluate, analyze, and plan the assembly of mechanical systems. This system focuses on utilizing an immersive virtual environment tightly coupled with commercial Computer Aided Design (CAD) systems. Salient features of VADE include: 1) data integration (two-way) with a parametric CAD system, 2) realistic interaction of user with parts in the virtual environment, 3) creation of valued design information in the virtual environment, 4) reverse data transfer of design information back to the CAD system, 5) significant interactivity in the virtual environment, 6) collision detection, and 7) physically-based modeling. This paper describes the functionality and applications of VADE. A discussion of the limitations of virtual assembly and a comparison with automated assembly planning systems are presented. Experiments conducted using real-world engineering models are also described.",,"Assembly; Computer aided design; Data transfer; Planning; Collision detection; Virtual assembly design environment; Virtual reality",Article,"Final","",Scopus,2-s2.0-0032651028
"Nemire K.","6602500249;","Individual combatant simulator for tactics training and mission rehearsal",1998,"Proceedings of SPIE - The International Society for Optical Engineering","3295",,,"435","441",,1,"10.1117/12.307192","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032224291&doi=10.1117%2f12.307192&partnerID=40&md5=fb459fea6a57d3716ddbdcbb1bd3e990","Interface Technologies Corporation, 1840 Forty-First Avenue, Suite 102, Capitola, CA 95010, United States","Nemire, K., Interface Technologies Corporation, 1840 Forty-First Avenue, Suite 102, Capitola, CA 95010, United States","This individual combatant simulator (ICS) provides ground force leaders opportunities to practice tactical skills on the simulated battlefield by directing dismounted computer-generated forces in combatant and non-combatant exercises. Integrated hardware and software systems allow leaders to operate on the simulated battlefield as they would on the physical battlefield using combinations of voice commands, arm signals, virtual tools, and virtual weapons. Hardware components include image generator, head-mounted display, 3-D sound, spatial tracking, instrumented glove, synthesized speech, and voice recognition systems. The training simulator can be operated on a network. Four types of evaluations, including performance of authentic tasks and subjective evaluations, were conducted using dismounted infantry soldiers and university students as participants. The results indicated that the ICS was easy to learn and use, could be used to conduct training exercises, supported skillful performance in training exercises, and was engaging and compelling for the users. These initial evaluations indicated ease of learning and use of the simulator, as well as the potential for training effectiveness.","Dismounted infantry; Electronic battlefield; Immersive; Mission rehearsal; Simulator; Training; Virtual","Computer hardware; Data transfer; Decision making; Interoperability; Military applications; Simulators; Speech recognition; User interfaces; Individual combatant simulator; Tactics training; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-0032224291
"Pollard S., Hayes S.","57197700914;36853283400;","View synthesis by edge transfer with application to the generation of immersive video objects",1998,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,,,"91","98",,8,"10.1145/293701.293713","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0043262239&doi=10.1145%2f293701.293713&partnerID=40&md5=174e313565dcdf6e37c3139e4b808274","Hewlett-Packard Laboratories, Filton Road, StokeGifford, Bristol, BS34 8QZ, United Kingdom","Pollard, S., Hewlett-Packard Laboratories, Filton Road, StokeGifford, Bristol, BS34 8QZ, United Kingdom; Hayes, S., Hewlett-Packard Laboratories, Filton Road, StokeGifford, Bristol, BS34 8QZ, United Kingdom","This paper presents a novel automatic method for view synthesis (or image transfer) from a number of uncalibrated images based on edge transfer. The edge-based technique is of general practical relevance because it overcomes most of the problems encountered in other approaches that either rely upon dense correspondence, work in projective space or need explicit camera calibration. The method has been used to generate immersive video objects which we call 3D video sprites. They consists of a number of synchronous video streams and mark up information that allows virtual viewpoints with respect to a live action video to be rendered and combined with traditional 3D virtual environments. © 1998 ACM.",,"Motion compensation; Video streaming; 3-D virtual environment; Automatic method; Camera calibration; Dense correspondences; Edge-based technique; Image transfer; Projective spaces; Uncalibrated images; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-0043262239
"Mouchtaris A., Lim J.-S., Holman T., Kyriakakis C.","6602611014;7403454149;7005598991;7004689290;","Head-related transfer function synthesis for immersive audio",1998,"1998 IEEE 2nd Workshop on Multimedia Signal Processing","1998-December",,,"155","160",,6,"10.1109/MMSP.1998.738928","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871622816&doi=10.1109%2fMMSP.1998.738928&partnerID=40&md5=d87d06b8590f112dceb9c97bbee89668","Integrated Media Syst. Center, Univ. of Southern California, 3740 McClintock Ave., Los Angeles, CA  90089-2564, United States","Mouchtaris, A., Integrated Media Syst. Center, Univ. of Southern California, 3740 McClintock Ave., Los Angeles, CA  90089-2564, United States; Lim, J.-S., Integrated Media Syst. Center, Univ. of Southern California, 3740 McClintock Ave., Los Angeles, CA  90089-2564, United States; Holman, T., Integrated Media Syst. Center, Univ. of Southern California, 3740 McClintock Ave., Los Angeles, CA  90089-2564, United States; Kyriakakis, C., Integrated Media Syst. Center, Univ. of Southern California, 3740 McClintock Ave., Los Angeles, CA  90089-2564, United States","Immersive audio systems are being envisioned for applications that include teleconferencing and telepresence; augmented and virtual reality for manufacturing and entertainment; air traffic control, pilot warning, and guidance systems; displays for the visually-or aurally-impaired; home entertainment; distance learning; and professional sound and picture editing for television and film. The principal function of such systems is to synthesize, manipulate, and render sound fields in real time. In this paper we examine the limitations that are inherent in spatial sound delivery over loudspeakers and propose a method that generates virtual sound sources based on synthetic head-related transfer functions with the same spectral characteristics as those of the real source. © 1998 IEEE.",,"Acoustic fields; Air navigation; Air traffic control; Audio acoustics; Audio systems; Distance education; Multimedia signal processing; Real time systems; Teleconferencing; Television applications; Television systems; Virtual reality; Visual communication; Augmented and virtual realities; Guidance system; Head related transfer function; Home entertainment; Immersive audio; Principal functions; Spectral characteristics; Virtual sound sources; Transfer functions",Conference Paper,"Final","",Scopus,2-s2.0-84871622816
"Wang Yue, Xuan Jianhua, Sesterhenn Isabell A., Hayes Wendelin S., Ebert David, Lynch John H., Mun Seong K.","55584806908;7004718083;35392562500;7202648856;35361180100;57189634195;7101645460;","Statistical modeling and visualization of localized prostate cancer",1997,"Proceedings of SPIE - The International Society for Optical Engineering","3031",,,"73","84",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031355207&partnerID=40&md5=f991db99b1883393cad753757d50900e","Catholic Univ. of America and, Georgetown Univ. Medical Cent.,, Catholic Univ, DC, USA","Wang, Yue, Catholic Univ. of America and, Georgetown Univ. Medical Cent.,, Catholic Univ, DC, USA; Xuan, Jianhua, Catholic Univ. of America and, Georgetown Univ. Medical Cent.,, Catholic Univ, DC, USA; Sesterhenn, Isabell A., Catholic Univ. of America and, Georgetown Univ. Medical Cent.,, Catholic Univ, DC, USA; Hayes, Wendelin S., Catholic Univ. of America and, Georgetown Univ. Medical Cent.,, Catholic Univ, DC, USA; Ebert, David, Catholic Univ. of America and, Georgetown Univ. Medical Cent.,, Catholic Univ, DC, USA; Lynch, John H., Catholic Univ. of America and, Georgetown Univ. Medical Cent.,, Catholic Univ, DC, USA; Mun, Seong K., Catholic Univ. of America and, Georgetown Univ. Medical Cent.,, Catholic Univ, DC, USA","In this paper, a statistically significant master model of localized prostate cancer is developed with pathologically- proven surgical specimens to spatially guide specific points in the biopsy technique for a higher rate of prostate cancer detection and the best possible representation of tumor grade and extension. Based on 200 surgical specimens of the prostates, we have developed a surface reconstruction technique to interactively visualize in the clinically significant objects of interest such as the prostate capsule, urethra, seminal vesicles, ejaculatory ducts and the different carcinomas, for each of these cases. In order to investigate the complex disease pattern including the tumor distribution, volume, and multicentricity, we created a statistically significant master model of localized prostate cancer by fusing these reconstructed computer models together, followed by a quantitative formulation of the 3D finite mixture distribution. Based on the reconstructed prostate capsule and internal structures, we have developed a technique to align all surgical specimens through elastic matching. By labeling the voxels of localized prostate cancer by '1' and the voxels of other internal structures by '0', we can generate a 3D binary image of the prostate that is simply a mutually exclusive random sampling of the underlying distribution f cancer to gram of localized prostate cancer characteristics. In order to quantify the key parameters such as distribution, multicentricity, and volume, we used a finite generalized Gaussian mixture to model the histogram, and estimate the parameter values through information theoretical criteria and a probabilistic self-organizing mixture. Utilizing minimally-immersive and stereoscopic interactive visualization, an augmented reality can be developed to allow the physician to virtually hold the master model in one hand and use the dominant hand to probe data values and perform a simulated needle biopsy. An adaptive self- organizing vector quantization method is developed to determine the optimal locations of selective biopsies where maximum likelihood of cancer detection and the best possible representation of tumor grade and extension can be achieved theoretically, thus allowing a comprehensive analysis of pathological information. The preliminary results show that a statistical pattern of localized prostate cancer exists, and a better understanding of disease patterns associated with tumor volume, distribution, and multicentricity of prostate carcinoma can be obtained from the computerized master model.",,"Computer simulation; Elasticity; Image reconstruction; Oncology; Statistical methods; Surgery; Visualization; Maximum likelihood; Prostate cancer; Tumor detection; Medical imaging",Conference Paper,"Final","",Scopus,2-s2.0-0031355207
"Szalavári Z., Gervautz M.","6507879085;6701389426;","The personal interaction panel - A two-handed interface for augmented reality",1997,"Computer Graphics Forum","16","3",,"C335","C346",,124,"10.1111/1467-8659.00171","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031552897&doi=10.1111%2f1467-8659.00171&partnerID=40&md5=f9ff4637f6c8a299b478e6d5e0613cc3","Institute of Computer Graphics, Vienna University of Technology, Karlsplatz 13/186/2, A-1040 Vienna, Austria","Szalavári, Z., Institute of Computer Graphics, Vienna University of Technology, Karlsplatz 13/186/2, A-1040 Vienna, Austria; Gervautz, M., Institute of Computer Graphics, Vienna University of Technology, Karlsplatz 13/186/2, A-1040 Vienna, Austria","This paper describes the introduction of a new interaction paradigm to augmented reality applications. The everyday tool handling experience of working with pen and notebooks is extended to create a three dimensional two-handed interface, that supports easy-to-understand manipulation tasks in augmented and virtual environments. In the design step we take advantage from the freedom, given by our very low demands on hardware and augment form and functionality to this device. On the basis of examples from object manipulation, augmented research environments and scientific visualization we show the generality of applicability. Although being in the first stages implementation, we consider the wide spectrum of suitability for different purposes.","3D user interface; Augmented reality; Two handed interaction","Interactive computer graphics; Personal computers; Three dimensional computer graphics; User interfaces; Virtual reality; Visualization; Augmented reality; Object manipulation; Two handed interaction; Human computer interaction",Article,"Final","",Scopus,2-s2.0-0031552897
"Taylor Valerie E., Chen Jian, Disz Terrence L., Papka Michael E., Stevens Rick","7103021424;57206950347;6602403487;6603782792;7403202225;","Interactive virtual reality in simulations: Exploring lag time",1996,"IEEE computational science & engineering","3","4",,"46","54",,9,"10.1109/99.556512","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030408292&doi=10.1109%2f99.556512&partnerID=40&md5=3a32d9f6580627f6943422219173d258","Northwestern Univ, Evanston, United States","Taylor, Valerie E., Northwestern Univ, Evanston, United States; Chen, Jian, Northwestern Univ, Evanston, United States; Disz, Terrence L., Northwestern Univ, Evanston, United States; Papka, Michael E., Northwestern Univ, Evanston, United States; Stevens, Rick, Northwestern Univ, Evanston, United States","Virtual reality (VR) is increasingly being used as an immersive simulation tool in a wide range of engineering processes, such as virtual prototyping and product testing. However, the reliability of VR systems is strongly influenced by end-to-end lag or the delay between a user action and then display of the result of that action. Too much lag prevents interactivity and makes it difficult for users to control system behavior. The different components of lag, namely: tracking lag, simulation lag, synchronization lag, rendering lag, frame-rate-induced lag and network lag, are discussed.",,"Computer networks; Computer simulation; Computer software; Data communication systems; Data transfer; Graphical user interfaces; Interactive computer systems; Rapid prototyping; Synchronization; Three dimensional computer graphics; End to end lag time; Interactive virtual reality; Virtual reality",Article,"Final","",Scopus,2-s2.0-0030408292
"Parker Elizabeth, Narayanan Mysore","36957416800;57198095339;","Virtual reality",1996,"Wescon Conference Record",,,,"542","546",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030410734&partnerID=40&md5=23bda5d1ddb64e831acbe163bd8beffd","Miami Univ, Oxford, United States","Parker, Elizabeth, Miami Univ, Oxford, United States; Narayanan, Mysore, Miami Univ, Oxford, United States","Virtual reality is an immersive, interactive simulation of realistic or imaginary environments. It is a breakthrough in technology allowing one to actually step inside a computer screen into a 3-D artificial world. In the past two years, although virtual reality has gained a lot of attention, very few people have actually experienced the simulation. This article presents the different types of reality that can be experienced.",,"Computational geometry; Computer simulation; Computer software; Human computer interaction; Interactive computer graphics; Television; Transfer functions; User interfaces; Video cameras; Heat transfer function; Interactive; Telepresence; Virtual sound; Virtual sports; Virtual television; Virtual touch; Virtual vision; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-0030410734
"Nemire Kenneth","6602500249;","Evaluating visual and auditory enhancements to a virtual object- manipulation task",1996,"Proceedings of SPIE - The International Society for Optical Engineering","2653",,,"249","260",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029709617&partnerID=40&md5=abcd4bdef78dba494d05dd3205db9e08","Interface Technologies Corp.,, Capitola, CA, USA, United States","Nemire, Kenneth, Interface Technologies Corp.,, Capitola, CA, USA, United States","Most off-the-shelf immersive virtual environment (IVE) systems do not provide adequate depth cues to allow quick and accurate manual interactions with virtual objects. Studies of teleoperation tasks show that using stereoscopic displays improves performance, especially in situations with increased scene complexity and decreased object visibility. However, many aspects of these studies prevent generalization of the results to IVE systems. Further, the additional costs of high-resolution stereoscopic displays preclude their widespread use in business and educational settings. In this paper, the effects of various visual and auditory display enhancements were evaluated to determine whether they may replace depth peg in one location and placed it on a virtual target in another location, provided a common test situation in which to compare various enhancements. Participants wore a commercial head-mounted display and spatial trackers on the head and hand. Results indicated conditions under which visual and auditory enhancements to monocular displays resulted in performance that was not different from using stereoscopic displays. Theoretical foundations for the findings and implications of the results for other tasks in VEs are discussed.",,"Auditory enhancement; Head-mounted displays; Stereoscopic displays; Virtual environments; Audition; Binocular vision; Display devices; Image enhancement; Performance; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-0029709617
"Fitzsimmons E.A., Fletcher J.D.","6604035711;7402938094;","Beyond DoD: Non-Defense Training and Education Applications of DIS",1995,"Proceedings of the IEEE","83","8",,"1179","1187",,3,"10.1109/5.400457","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029357249&doi=10.1109%2f5.400457&partnerID=40&md5=1283e9d5769061426238c395cbc5f426","Office of Science and Technology Policy, The Executive Office of the President, The White House, Washington, DC 20500, United States; Science and Technology Division, Institute for Defense Analyses, Alexandria, VA 22311, United States","Fitzsimmons, E.A., Office of Science and Technology Policy, The Executive Office of the President, The White House, Washington, DC 20500, United States; Fletcher, J.D., Science and Technology Division, Institute for Defense Analyses, Alexandria, VA 22311, United States","Networked simulation for education and training is discussed as a functional capability though which Distributed Interactive Simulation (DIS) may find application in the non-Defense world. Effectiveness of networked simulation in Defense education and training applications has yet to be conclusively demonstrated, but studies completed thus far have yielded positive results. Results from non-Defense applications are also likely to be positive. The characteristics of networked simulation that are relevant to its transfer to non-Defense applications include a focus on group performance, physical dispersion of participants, requirements for real-time response, emergent task environments, visual task environments, accessible performance data, provisions for practice, immersive realism, and interactions with many entities. These characteristics are matched with potential, non-Defense applications of networked simulation such as training for crews, teams, and units, edutainment, education, training, school-to-work transitions, and lifelong learning. Remaining issues include further development of technical standards, legal standards, research and development, fiscal and regulatory policies, and development of the communications infrastructure. © 1995 IEEE",,"Data communication systems; Engineering education; Industrial applications; Performance; Personnel training; Public policy; Research and development management; Standards; Distributed interactive simulation; Edutainment; Nondefense application; Computer simulation",Article,"Final","",Scopus,2-s2.0-0029357249
"Bailey John H., Witmer Bob G.","57199422740;6602988544;","Learning and transfer of spatial knowledge in a virtual environment",1994,"Proceedings of the Human Factors and Ergonomics Society","2",,,"1158","1162",,36,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028752107&partnerID=40&md5=4c3b1eb73f1cee9d6271bf5baa2b2397","U.S. Army Research Inst, Orlando, United States","Bailey, John H., U.S. Army Research Inst, Orlando, United States; Witmer, Bob G., U.S. Army Research Inst, Orlando, United States","Two experiments were conducted to investigate route and configurational knowledge acquisition in a virtual environment (VE). The results indicate that route knowledge can be acquired in a VE and that it transfers to the real world. Furthermore, although it was not explicitly trained, participants acquired some configurational knowledge. Higher levels of interactive exposure to the VE resulted in better route knowledge than less interactive exposure. There was some evidence that more reported presence was correlated with better performance on spatial knowledge tests, while more reported simulator sickness was correlated with worse performance. Finally, performance during VE rehearsals was a strong, consistent correlate of performance on spatial knowledge tests.",,"Computer applications; Computer architecture; Data acquisition; Diseases; Display devices; Knowledge based systems; Performance; Personnel training; User interfaces; Immersive tendencies questionnaire; Interactive exposure; Knowledge acquisition; Presence; Video game joystick; Virtual environment; Virtual environment building; Human engineering",Conference Paper,"Final","",Scopus,2-s2.0-0028752107
"Paasch R., Van Dam A., Bryson S., Robinett W.","56895926900;7005933490;35744574400;8647587600;","Tutorial: Implementing virtual reality",1994,"Conference on Human Factors in Computing Systems - Proceedings","1994-April",,,"399","400",,,"10.1145/259963.260525","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943539346&doi=10.1145%2f259963.260525&partnerID=40&md5=72e40e3245d093103345b3d96eb90f5e","Computer Science Department, Thornton Hall, University of Virginia, Charlottesville, VA  22903-2442, United States; Brown University, United States; CSC/NASA Ames, United States","Paasch, R., Computer Science Department, Thornton Hall, University of Virginia, Charlottesville, VA  22903-2442, United States; Van Dam, A., Brown University, United States; Bryson, S., CSC/NASA Ames, United States; Robinett, W.","While virtual reality systems seem to hold great promise for facilitating the use of computers, actual virtual reality development is fraught with difficulties. These difficulties include limited hardware, uncertain interface paradigms and the integration of various components and concepts into a high-performance system. This course addresses these and other difficulties. We begin with an introduction to the virtual reality field, both in reference to computer graphics and in terms of the current state of the art. Interface hardware will be surveyed, emphasizing the performance limitations of current products. The human factors impact of the limited interface devices will be discussed on both a theoretical and phenomenological level. After setting this background, the external design of a virtual environment will be discussed from the point of view of how that environment is experienced by the user. The objects that populate a virtual environment will be discussed both in the abstract and through examples. The implications of the interactive user interface on system performance will be a primary focus. The actual implementation of the virtual environment will be addressed, discussing both the software platform and the overall system. The course will end with a discussion of virtual reality development on a budget and lessons learned about how to get a virtual reality project going from start to a useful application. By the end of the tutorial, attendees should be comfortable with the major issues involved in starting a VR lab and creating a complete, working VR system. These issues include limited hardware, uncertain interface paradigms and the integration of various components and concepts into a high-performance system. We begin with an introduction to the virtual reality field, both in reference to computer graphics and in terms of the current state of the art. Interface hardware will be surveyed, emphasizing the performance limitations of current products. The human factors impact of the limited interface devices will be discussed on both a theoretical and phenomenological level. After setting this background, the external design of a virtual environment will be discussed from the point of view of how that environment is experienced by the user. The objects that populate a virtual environment will be discussed both in the abstract and through examples. The implications of the interactive user interface on system performance will be a primary focus. The actual implementation of the virtual environment will be addressed, discussing both the software platform and the overall system. The course will end with a discussion of virtual reality development on a budget and lessons learned about how to get a virtual reality project going from start to a useful application. This course is intended for those who wish to know how to design and implement working high performance immersive interactive virtual environments. Moderate maturity in three-dimensional graphics programming is assumed, including transformation matrices, use of graphics libraries and basic cartesian geometry. No knowledge of virtual reality is required. After taking this course, the attendee will have a greater understanding of how to develop a fully immersive interactive virtual reality system. The attendee will know how to select the hardware for a particular virtual environment, outline the appropriate software structure, and implement that structure in a way which will give the greatest possible performance. © 1994 ACM.","Computer graphics; Human factors; Immersive environments; Software development environments; Virtual reality","Budget control; Computer graphics; Computer hardware; Computer software; Curricula; Hardware; Human engineering; Linear transformations; Software design; Surveys; Teaching; Technology transfer; User interfaces; High performance systems; Immersive environment; Interactive user interfaces; Interactive virtual environments; Interactive virtual reality; Software development environment; Three-dimensional graphics; Transformation matrices; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84943539346
