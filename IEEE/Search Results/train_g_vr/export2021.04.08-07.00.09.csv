"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"STEM collaboration in virtual world academy","L. Divine; R. Williams","Virtual Reality Academy Deputy Director, Tec^Edge Innovation and Collaboration Center, Dayton, Ohio, United States; AFRL Discovery Lab Director, Tec^Edge Innovation and Collaboration Center, Dayton, Ohio, United States","2013 International Conference on Collaboration Technologies and Systems (CTS)","25 Jul 2013","2013","","","569","575","There is general agreement about the importance of increasing the number of students choosing career fields in Science, Technology, Engineering, and Mathematics (STEM). However most of the initiatives designed to get students interested in STEM fields are constrained by floor space, budget, or driving distance. These factors, in combination, act to limit the affordability and accessibility of research opportunities in STEM fields to students in schools faced with increasingly limited budgets or lacking access to experienced STEM teachers. Since a trained STEM workforce is crucial to tackling research challenges of importance to the Air Force and the nation, the Air Force Research Laboratory (AFRL) Discovery Lab program has developed a Virtual Reality Academy (VRA) program utilizing open source virtual reality software, Open Simulator, to create a virtual collaboration environment called Virtual (reality) Discovery Center (VDC). This 16-region VDC is the key to the Discovery Lab's 1,000 Student Outreach initiative designed to greatly expand the Discovery Lab's ability to make project-based “hands-on” research experience accessible to students across the country via the Open Simulator collaboration technologies. This paper highlights many of the successful efforts to establish VDC Virtual Learning Academies in areas such as Biology, Nanotechnology, Computer Vision, and Mobile Computing (smartphone apps). This paper is not a scientific study of Open Simulator as a collaboration tool for STEM but rather a descriptive overview of its successful implementation locally and nationally - suggesting its potential as a game-changer in STEM education and research.","","978-1-4673-6404-1","10.1109/CTS.2013.6567288","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6567288","","Collaboration;Solid modeling;Dinosaurs;Avatars;Educational institutions;Space shuttles","computer aided instruction;engineering education;groupware;public domain software;teaching;virtual reality","STEM collaboration;science-technology-engineering-mathematics;STEM fields;driving distance;floor space;STEM teachers;STEM workforce;Air Force Research Laboratory Discovery Lab program;Virtual Reality Academy program;VRA program;open source virtual reality software;virtual collaboration environment;Virtual Discovery Center;16-region VDC;project-based hands-on research experience;Open Simulator collaboration technologies;virtual learning academies","","1","","6","","25 Jul 2013","","","IEEE","IEEE Conferences"
"Integration of force-position control and haptic interface facilities for a virtual excavator simulator","H. I. Torres-Rodriguez; V. Parra-Vega; F. J. Ruiz-Sanchez","Electr. Eng. Dept., CINVESTAV-IPN, Mexico; Electr. Eng. Dept., CINVESTAV-IPN, Mexico; Electr. Eng. Dept., CINVESTAV-IPN, Mexico","ICAR '05. Proceedings., 12th International Conference on Advanced Robotics, 2005.","19 Sep 2005","2005","","","761","768","In this paper we present the advances in the design and develop of a system used to simplify the excavator digging tasks based in a dynamical model of an excavator an anthropomorphic auto-balanced haptic interface and a force-position control law. The objective of this system is to reduce the training period and simplify the execution of digging tasks. This system makes possible the kinesthetic coupling between the operator and the machine providing information to the operator about the interaction forces between the excavator and the soil. The dynamical models of the excavator and the haptic devise were calculated employing the Euler-Lagrange formalism. With this formalism we obtain a new general dynamical model of an excavator including the dynamical effects of the hydraulic actuators. We present simulation results of the closed loop system considering the interaction between the haptic devise and the excavator","","0-7803-9178-0","10.1109/ICAR.2005.1507494","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1507494","","Force control;Haptic interfaces;Costs;Soil;Construction industry;Industrial training;Electrical equipment industry;Stress;Automation;Control systems","closed loop systems;digital simulation;excavators;force control;haptic interfaces;hydraulic actuators;position control;virtual reality","force control;position control;virtual excavator simulator;excavator digging;anthropomorphic autobalanced haptic interface;kinesthetic coupling;interaction force;soil;dynamical model;haptic devise;Euler-Lagrange formalism;hydraulic actuators;closed loop system","","2","","10","","19 Sep 2005","","","IEEE","IEEE Conferences"
"Implementation and evaluation of a collaborative learning, training and networking environment for start-up entrepreneurs in virtual 3D worlds","C. Gütl; J. Pirker","Institute for Information Systems and Computer Media, Graz University of Technology, Austria; Institute for Information Systems and Computer Media, Graz University of Technology, Austria","2011 14th International Conference on Interactive Collaborative Learning","27 Oct 2011","2011","","","58","66","Exchange of knowledge and ideas, building up a social network and gaining the specific expertise are the first most important steps before starting an own business or enterprise. Business incubator programs and also university innovation courses try to provide these services and impart the according knowledge to start-up entrepreneurs. Especially for potential entrepreneurs already in workforce who want to study further it is hard to find time for training sessions or workshops offered by incubators. Virtual 3D Worlds can support the needs of start-up entrepreneurs who cannot participate at local meetings, so that they can build up social contacts to peers, experts and also to potential financiers, but have also the possibility to participate in virtual seminars and workshops to gain the required knowledge. This paper focuses on identifying advantages of using Virtual 3D Worlds to enhance the imparting of the required expertise to start a business and points out ways to improve learning effects. Within this framework a Virtual 3D World especially for incubation services is implemented followed by an evaluation by students, domain experts and also pedagogical and cognitive science experts. Two different and independent studies were used to identify issues and potentials of the designed Virtual Incubator World and should also help to generalize the findings to the field of research.","","978-1-4577-1747-5","10.1109/ICL.2011.6059548","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6059548","Collaborative Learning Environment;Virtual 3D Worlds;Open Wonderland;Virtual Incubator;Start-Up Entrepreneurship;E-Learning","Business;Collaboration;Conferences;Seminars;Electronic learning;Three dimensional displays;Educational institutions","computer based training;human computer interaction;management education;virtual reality","collaborative learning environment;collaborative training environment;collaborative networking environment;start-up entrepreneurs;virtual 3D worlds;knowledge exchange;university innovation courses;business incubator programs;social contacts;incubation services;virtual incubator world","","6","","16","","27 Oct 2011","","","IEEE","IEEE Conferences"
"Virtual classrooms to improve the teaching-learning process in Systems Engineering courses at a University from Lima North.","J. V. Paragulla; L. Andrade-Arenas; M. C. Caceres","Universidad de Ciencias y Humanidades,Facultad de Ciencias e Ingeniería,Lima,Perú; Universidad de Ciencias y Humanidades,Facultad de Ciencias e Ingeniería,Lima,Perú; Universidad de Ciencias y Humanidades,Facultad de Ciencias e Ingeniería,Lima,Perú","2020 IEEE World Conference on Engineering Education (EDUNINE)","27 Jul 2020","2020","","","1","4","Access to information, thanks to internet, is simple and abundant. However, in a teaching-learning process the information must be ordered and focused to achieve a good academic performance. Fortunately, there are information technologies that allow you to manage the information of a learning process on virtual platforms. The University of Sciences and Humanities has implemented a virtual platform with Moodle to improving the teaching-learning process. The teacher manages the information ordered and in sequence according to the scope of his course, considering materials of theory, practice, laboratory, readings, videos, reference links accompanied by evaluative activities such as questionnaires, forums, tasks. The student accesses this information with any device with internet access and at any time and place. This has allowed to improve the teaching-learning process with evident improvements in the general averages of the students generating satisfaction and motivation for their University training.","","978-1-7281-6638-4","10.1109/EDUNINE48860.2020.9149500","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9149500","internet;virtual platform;Moodle;teaching-learning process","Training;Task analysis;Videos;Face;Information and communication technology","computer based training;educational courses;Internet;teaching;virtual reality","teaching-learning process;information technologies;virtual platform;virtual classrooms;Systems Engineering courses;Lima North;Internet;University of Sciences and Humanities;University training;Moodle","","1","","9","","27 Jul 2020","","","IEEE","IEEE Conferences"
"Focus of attention and dynamic postural control in individuals post-stroke","D. McEwen; M. Bilodeau; H. Sveistrup","School of Rehabilitation Sciences, University of Ottawa, Canada; School of Rehabilitation Sciences, University of Ottawa, Canada; School of Rehabilitation Sciences, University of Ottawa, Canada","2017 International Conference on Virtual Rehabilitation (ICVR)","14 Aug 2017","2017","","","1","2","Maintaining an external focus of attention (FA), as with virtual reality exercise gaming, may be effective in encouraging greater dynamic lateral movements and greater weight bearing for individuals post stroke. This study sought to compare center of pressure movements for individuals post-stroke under three conditions (internal FA, external FA, virtual reality) and compare these differences to healthy older and younger adults. The post-stroke group had greater average weight bearing on the paretic limb during VR tasks than the internal and external FA tasks. The PS group had consistently lower values on all dynamic postural variables compared with both YA and OA groups. However, all three groups showed a similar FA effect, with generally greater range in the VR compared with the internal FA task.","2331-9569","978-1-5090-3053-8","10.1109/ICVR.2017.8007478","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007478","Center of Pressure;Stroke;Dynamic Stability","Force;Virtual environments;Training;Software;Standards;Analysis of variance","biomechanics;computer games;medical computing;patient rehabilitation;virtual reality","focus of attention;dynamic postural control;post-stroke individuals;virtual reality exercise gaming;dynamic lateral movements;weight bearing;center of pressure movements;internal FA;external FA;paretic limb;VR tasks;dynamic postural variables","","","","5","","14 Aug 2017","","","IEEE","IEEE Conferences"
"Key techniques of haptic related computation in virtual liver surgery","Y. Shi; Y. Xiong; X. Hua; K. Tan; X. Pan","School of Computer Science, National University of Defense Technology, Changsha, China; School of Computer Science, National University of Defense Technology, Changsha, China; School of Electronic Science and Engineering, National University of Defense Technology, Changsha, China; Educational Technology Center, The PLA General Hospital, Beijing, China; Educational Technology Center, The PLA General Hospital, Beijing, China","2015 8th International Conference on Biomedical Engineering and Informatics (BMEI)","11 Feb 2016","2015","","","355","359","With or without a realistic haptic effect is the key difference between virtual surgery and the traditional training methods. On the real-time operation stage, users contact with the virtual scene and implement the operation by manipulating the haptic interaction device. Obviously, haptic related computation is the most important part for a virtual surgery system. This paper studied the haptic related computation of the virtual liver surgery, including the mechanism of haptic computation in liver virtual surgery, liver cutting area delineation and liver parenchyma splitting simulation. We developed two novel methods to simulate the delineation and splitting on the virtual liver surface. Results show our techniques can not only provide a realistic effect in our virtual surgery system, but also can be used in other simulation and geometry fields.","","978-1-5090-0022-7","10.1109/BMEI.2015.7401529","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7401529","virtual liver surgery;haptic computation;simulation","Liver;Surgery;Haptic interfaces;Computational modeling;Training;Real-time systems;Solid modeling","haptic interfaces;liver;medical computing;surgery","virtual liver parenchyma splitting simulation;haptic computation mechanism;haptic interaction device;virtual liver surgery","","6","","8","","11 Feb 2016","","","IEEE","IEEE Conferences"
"The effect of sound on visual realism perception and task completion time in a cel-shaded serious gaming virtual environment","D. Rojas; B. Cowan; B. Kapralos; K. Colllins; A. Dubrowski","Institute of Medical Science, University of Toronto, Toronto, Canada; Faculty of Business and IT, University of Ontario Institute of Technology, Oshawa, Ontario, Canada; Faculty of Business and IT, University of Ontario Institute of Technology, Oshawa, Ontario, Canada; The Games Institute, University of Waterloo, Waterloo, Ontario, Canada; Faculty of Medicine, Memorial University. St. John's, Newfoundland, Canada","2015 Seventh International Workshop on Quality of Multimedia Experience (QoMEX)","6 Jul 2015","2015","","","1","6","Here we investigate the effect of sound on the perception of visual realism and the time required to complete a simple navigation-based task within a serious gaming (virtual) environment under various sound and visual conditions. Results indicate that the perception of visual realism and task completion time can be affected by sound. Designers and developers of serious games (and virtual environments in general) should be aware of the effects of sound on a user's perception of the visual scene and on task completion time, and they should thus ensure that sound is carefully considered when creating such environments.","","978-1-4799-8958-4","10.1109/QoMEX.2015.7148136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7148136","Serious games;virtual simulation;multi-modal interactions;audio-visual interaction;realism","Visualization;Games;White noise;Surgery;Three-dimensional displays;Virtual environments;Training","human computer interaction;serious games (computing);virtual reality","cel-shaded serious gaming;visual realism perception;navigation-based task;virtual environment;sound conditions;visual conditions;task completion time;user perception;visual scene","","3","","22","","6 Jul 2015","","","IEEE","IEEE Conferences"
"Gesture recognition for virtual reality applications using data gloves and neural networks","J. Weissmann; R. Salomon","Dept. of Comput. Sci., Zurich Univ., Switzerland; NA","IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339)","6 Aug 2002","1999","3","","2043","2046 vol.3","Explores the use of hand gestures as a means of human-computer interactions for virtual reality applications. For the application, specific hand gestures, such as ""fist"", ""index finger"" and ""victory sign"", have been defined. Most existing approaches use various camera-based recognition systems, which are rather costly and very sensitive to environmental changes. In contrast, this paper explores a data glove as the input device, which provides 18 measurement values for the angles of different finger joints. The paper compares the performance of different neural network models, such as backpropagation and radial-basis functions, which are used by the recognition system to recognize the actual gesture. Some network models achieve a recognition rate (training as well a generalization) of up to 100% over a number of test subjects. Due to its good performance, this recognition system is the first step towards virtual reality applications in which program execution is controlled by a sign language.","1098-7576","0-7803-5529-6","10.1109/IJCNN.1999.832699","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=832699","","Virtual reality;Data gloves;Neural networks;Application software;Fingers;Wrist;Mice;Image recognition;Computer science;Testing","gesture recognition;virtual reality;data gloves;backpropagation;radial basis function networks","neural networks;hand gestures;human-computer interactions;fist;index finger;victory sign;radial-basis functions;sign language","","28","1","8","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Development of electro pneumatic trainer embedded with Programmable Integrated Circuit (PIC) and graphical user interface (GUI) for educational applications","I. Burhan; R. Othman; A. A. Azman","Aircraft Maintenance Department, Politeknik Banting Selangor (PBS), Banting, Selangor, Malaysia; Aircraft Maintenance Department, Politeknik Banting Selangor (PBS), Banting, Selangor, Malaysia; Electrical Engineering Faculty, University Technology of Mara (UiTM), Shah Alam, Selangor, Malaysia","2016 IEEE International Conference on Automatic Control and Intelligent Systems (I2CACIS)","27 Mar 2017","2016","","","1","6","Electro Pneumatic Trainer for educational applications is developed as supporting tools towards the existing typical teaching and learning process. The main objective is to improve the learning outcome towards student's cognitive knowledge and practical skill where the existing teaching and learning for electro pneumatic courses conducted in the classroom without emphasizing on simulation and complex practical aspect. Generally, computer graphic or simulation can reduce the unsuccessful of practical implementation during the practical session through installation error. Visual Basic (VB) was used as the platform for graphical user interface (GUI) and using Programmable Integrated Circuit (PIC) as the interface between the GUI and hardware of Electro Pneumatic Trainer. The development of Electro Pneumatic Trainer interfacing between PIC and VB has been designed and improved by involving various types of electro pneumatics instruments such as single acting cylinder, double acting cylinder, semi rotary motor, air motor, and linear drive. Newly developed Electro Pneumatic Trainer controller interface are able to be re-programme for numerous combination of tasks. Based on Practical Work Assessment Form evaluated by the lecturers, there is an average marks of 40% and 40% of improvement on teaching and learning (cognitive) and practical's skill respectively when newly developed Electro Pneumatic Trainer were used by students during the teaching and learning process. It is also user friendly and embedded with systematics graphical diagram inspiring students for conducting the practical session.","","978-1-5090-4186-2","10.1109/I2CACIS.2016.7885279","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7885279","Electro Pneumatic Trainer;Programmable Integrated Circuit (PIC);Graphical User Interface;Teaching and Learning","Education;Graphical user interfaces;Relays;Programming;Power supplies;Electrical engineering;Conferences","cognition;computer based training;computer graphics;educational courses;electrical engineering computing;electrical engineering education;embedded systems;graphical user interfaces;programmable circuits;teaching","electro pneumatic trainer development;programmable integrated circuit;graphical user interface;educational applications;PIC;GUI;VB;teaching process;learning process;student cognitive knowledge;practical skill;computer graphic;visual basic;electro pneumatic instruments;electro pneumatic trainer controller interface;electro pneumatic courses","","1","","10","","27 Mar 2017","","","IEEE","IEEE Conferences"
"Automated manual training using adaptive neuro-controllers","R. Wai; K. KrishnaKumar","Dept. of Aerosp. Eng., Alabama Univ., Tuscaloosa, AL, USA; Dept. of Aerosp. Eng., Alabama Univ., Tuscaloosa, AL, USA","1995 IEEE International Conference on Systems, Man and Cybernetics. Intelligent Systems for the 21st Century","6 Aug 2002","1995","3","","2312","2317 vol.3","This paper presents an application of artificial neural networks in automated manual training. The idea of an automated manual trainer is to train a human to operate a complex system automatically with limited human interaction. An automated helicopter training system was used to demonstrate the feasibility of this study. Neuro-controllers in conjunction with critic models are used to implement the automated helicopter trainer to perform hover maneuvers. The simulation results indicate that the automated helicopter trainer is capable of performing the hover maneuvers. To verify the concept of the automated trainer, a simple one axis manual control cart-pole system was used. Two groups of four students each were used in the experiment with one being the experimental group which was trained with the automated trainer, and the other being the control group which was trained with no automated trainer. The experimental results show that the automated manual trainer did not ""mess up"" the training process, but no further conclusions can be drawn since the experimental group is too small to generalize the results. Further study in this area is recommended.","","0-7803-2559-1","10.1109/ICSMC.1995.538126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=538126","","Helicopters;Automatic control;Neural networks;Human factors;Control systems;Manipulators;Optimal control;Electronic mail;Artificial neural networks;Control system synthesis","aircraft control;helicopters;neurocontrollers;computer based training;learning (artificial intelligence);computer aided instruction;adaptive control;closed loop systems;bang-bang control;linear quadratic control","automated manual training;adaptive neuro-controllers;artificial neural networks;complex system;limited human interaction;automated helicopter training system;critic models;hover maneuvers;one axis manual control cart-pole system","","","","5","","6 Aug 2002","","","IEEE","IEEE Conferences"
"A virtual environment for realistic testing and training of face detection and recognition systems","M. Correa; J. Ruiz-del-Solar; I. Parra-Tsunekawa","Elec. Eng. Dept. - Universidad de Chile, Chile; Elec. Eng. Dept. - Universidad de Chile, Chile; Elec. Eng. Dept. - Universidad de Chile, Chile","19th International Symposium in Robot and Human Interactive Communication","11 Oct 2010","2010","","","69","75","In this article, a virtual environment for realistic testing and training of face detection and recognition systems under uncontrolled conditions is proposed. The key elements of this tool are a simulator and real face and background images taken under real-world conditions with different acquisition conditions. Inside the simulated environment, an observing agent, the one with the ability to recognize faces, can navigate and observe the real face images, at different distances, angles and with indoor or outdoor illumination. During the face recognition process, the agent can actively change its viewpoint and relative distance to the faces in order to improve the recognition results. The virtual environment provides all behaviors to the agent (navigation, positioning, face's image composing under different angles, etc.), except the ones related with the recognition of faces. This tool could be of high interest in HRI applications related with the visual recognition of humans. It allows comparing and quantifying the face recognition capabilities of service robots, and in general intelligent machines, under exactly equal working conditions. The applicability of the proposed tool is validated in the comparison of state of the art face detection and recognition methods.","1944-9437","978-1-4244-7990-0","10.1109/ROMAN.2010.5598673","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5598673","","Face;Face recognition;Databases;Lighting;Testing;Detectors;Face detection","face recognition;human-robot interaction;robot vision;service robots;virtual reality","virtual environment;realistic testing;realistic training;face detection systems;face recognition systems;human-robot interaction;service robots;intelligent machines","","1","","30","","11 Oct 2010","","","IEEE","IEEE Conferences"
"The impact of motion in virtual environments on memorization performance","P. Häfner; C. Vinke; V. Häfner; J. Ovtcharova; W. Schotte","Institute for Information, Management in Engineering, Karlsruhe Institute of Technology, Zirkel 2, 76131, Germany; Institute for Information, Management in Engineering, Karlsruhe Institute of Technology, Zirkel 2, 76131, Germany; Institute for Information, Management in Engineering, Karlsruhe Institute of Technology, Zirkel 2, 76131, Germany; Institute for Information, Management in Engineering, Karlsruhe Institute of Technology, Zirkel 2, 76131, Germany; High Performance Computing Center Stuttgart, University of Stuttgart, Nobelstr. 19, 70569, Germany","2013 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA)","3 Oct 2013","2013","","","104","109","Virtual environments are more and more used for educational and training purposes. In order to design virtual environments for these applications in particular, it is very important to get a deep understanding of the relevant design features supporting the user's process of learning and comprehension. Relevance and implementation of these features as well as the benefits of virtual learning environments over traditional educational approaches in general are rarely explored. Focusing on modes of interaction in this work, we examined the effect of different motion types on the knowledge acquisition of users in various virtual environments. For our study we chose a simple memorization task as approximation of low cognitive knowledge acquirement. We hypothesized motion types and immersion levels influence memorization performance in virtual environments. The memorization task was conducted in two virtual environments with different levels of immersion: A high-immersive Cave Automatic Virtual Environment (CAVE) and a low-immersive desktop virtual environment. Two motion types in virtual environments were explored: Physical and virtual walking. In the CAVE physical walking was implemented by using motion capturing and virtual walking was realized using a joystick-like input device. The results indicate neither motion types nor immersion levels in virtual environments affect memorization performance significantly.","2377-9322","978-1-4673-4703-7","10.1109/CIVEMSA.2013.6617404","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6617404","cognition;human computer interaction;learning;memory;motion;virtual environment;virtual reality","Virtual environments;Navigation;Legged locomotion;Tutorials;Stereo vision;Educational institutions","computer aided instruction;human computer interaction;human factors;interactive devices;virtual reality","training;education;CAVE physical walking;virtual walking;low-immersive desktop virtual environment;high-immersive CAVE automatic virtual environment;hypothesized motion types;cognitive knowledge acquirement;user knowledge acquisition;virtual learning environments;user process;virtual environment design;training purposes;memorization performance","","4","","12","","3 Oct 2013","","","IEEE","IEEE Conferences"
"Can mobile virtual fitness apps replace human fitness trainer?","R. Kwok Chi-Wai; S. Hui Sai-Chuen; T. Mak So-Ning; P. Wu Ka-Shun; K. Lee Wing-Kuen; C. Wong Choi-Ki","Department of Information Systems, City University of Hong Kong, Hong Kong SAR, China; Department of Sports Science and Physical Education, The Chinese University of Hong Kong, Hong Kong SAR, China; Department of Information Systems, City University of Hong Kong, Hong Kong SAR, China; Student Development Services City University of Hong Kong, Hong Kong SAR, China; Department of Information Systems, City University of Hong Kong, Hong Kong SAR, China; Student Development Services City University of Hong Kong, Hong Kong SAR, China","The 5th International Conference on New Trends in Information Science and Service Science","1 Dec 2011","2011","1","","56","63","The increased need in promoting fitness activity and rapid growth of smart-phones has urged the development of mobile virtual fitness apps (MVFA). Yet, evaluation on these MVFA has been limited and, therefore, this study attempts to conduct preliminary evaluation on randomly sampled MVFA based on our proposed system workflow using theories of social support and persuasive technology, and the American College of Sports Medicine (ACSM) guidelines for exercise professionals. Results indicated the sampled MVFA mainly covered the stages 2 and 3 of our proposed ACSM-based training workflow. In terms of social support and persuasiveness of MVFA, the average scores of these two aspects were relatively low, thus resulting in a generally low average quality of coverage scores. Therefore, MVFA cannot replace human fitness trainers, but serve as assistant to trainers and trainees. Explanations and implications to trainers, trainees and MVFA developers are presented.","","978-89-88678-50-3","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6093392","","Training;Monitoring;Educational institutions;Instruments;Mobile communication;Appraisal;History","medical computing;mobile computing;virtual reality","mobile virtual fitness application;human fitness trainer;social support theory;persuasive technology;American College of Sports Medicine guideline;ACSM-based training workflow","","1","","28","","1 Dec 2011","","","IEEE","IEEE Conferences"
"Video game experience and basic robotic skills","A. Tanaka; R. Smith; C. Hughes","The Nicholson Center, Florida Hospital, Celebration, US; The Nicholson Center, Florida Hospital, Celebration, US; Department of Computer Science, The University of Central Florida, Orlando, US","2016 IEEE International Conference on Serious Games and Applications for Health (SeGAH)","10 Oct 2016","2016","","","1","6","Virtual reality simulators have emerged as valuable tools for standardized and objective robotic surgery skill training and assessments. In recent years the idea of using video game technology in surgical education for laparoscopy has also been explored, however few have attempted to make a connection between video game experience and robotic surgical skills. Thus, the current study aims to examine the performance of video gamers in a virtual reality robotic surgery simulator. Furthermore, the video gamers' performance was compared to that of medical students, expert robotic surgeons, and “laypeople.” The purpose of this study is to demonstrate that video gamers acquire perceptual and psychomotor skills through video game play, similar to those used by robotic surgeons. Subjects completed a demographic questionnaire and performed three computer-based perceptual tests: a Flanker compatibility task, a subsidizing task, and a Multiple Object Tracking test. Participants then performed two warm-up exercises and eight trials of two core exercises on a robotic surgery simulator. After completing all trials, participants completed a post-questionnaire regarding their experience with the system. Expert video gamers (n=40), medical students (n=24), laypeople (n=42) and expert robotic surgeons (n=16) were recruited. Medical students and gamers were significantly faster than experts in the Flanker Task. The experts were significantly slower than the all other groups in the subsidizing task. Experts scored significantly higher, were significantly more efficient, and were significantly faster than laypeople, medical students, and gamers in the first trial of Ring & Rail 1 and Suture Sponge. In trial eight of the simulation exercises, the experts performed significantly better than most groups in all of the metrics. Contrary to prior literature in laparoscopy, this study was unable to validate enhanced abilities of video gamers in a robotic surgery simulator. This study does further demonstrate that the transfer of skills developed through video game play is relevant to the surgical technique. This may be due to the differences of the systems and how the users interact within them. In a society where video games have become an integral past time, it is important to determine the role that video games play in the perceptual and psychomotor development of users. These findings can be generalized to domains outside of medicine that utilize robotic and computer-controlled systems, speaking to the scope of the gamers' abilities and pointing to the capacity within these systems.","","978-1-5090-2210-6","10.1109/SeGAH.2016.7586262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586262","","Surgery;Robots;Measurement;Games;Training;Rails;Cameras","biomedical education;computer aided instruction;computer games;educational robots;human-robot interaction;medical computing;medical robotics;surgery;virtual reality","video game experience;basic robotic skills;virtual reality robotic surgery simulator;standardized robotic surgery skill training;objective robotic surgery skill training;standardized robotic surgery skill assessment;objective robotic surgery skill assessment;surgical education;laparoscopy;video game technology;perceptual skill acquisition;psychomotor skill acquisition;computer-based perceptual tests;flanker compatibility task;subsidizing task;multiple object tracking test;computer-controlled systems","","1","","17","","10 Oct 2016","","","IEEE","IEEE Conferences"
"Virtual heart: Simulation-based cardiac physiolgy for education","V. Hurmusiadis","Primal Pictures Ltd, London, UK","2007 Computers in Cardiology","9 Jan 2009","2007","","","65","68","An investigation into the technical feasibility of computer based interactive simulation of the heart was conducted. The project is currently at prototype development phase, which is focused on the development of a virtual heart organ. The prototype will be customized for clinical skills training for interventional cardiology and electrophysiology, as well as for general cardiology education. Further development will incorporate an interface for handling catheter insertion for cardiac ablation and pacing.","2325-8853","978-1-4244-2533-4","10.1109/CIC.2007.4745422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4745422","","Heart","bioelectric phenomena;biomedical education;cardiology;catheters;prosthetics;virtual reality","virtual heart;simulation-based cardiac physiology;computer based interactive simulation;interventional cardiology;electrophysiology;general cardiology education;catheter insertion;cardiac ablation;cardiac pacing","","6","1","10","","9 Jan 2009","","","IEEE","IEEE Conferences"
"Augmented virtuality for the next generation production intelligence","I. J. Rudas","Óbuda University, Budapest, Hungary","2017 IEEE 14th International Scientific Conference on Informatics","29 Mar 2018","2017","","","12","12","Several compelling IT trends of the past few years show us how the next possible paradigm change in business intelligence could remodel everything in production informatics. Along the example of Virtual Reality and a community-based granulated software ecosystem, namely the Node.js world and its interference with the System of Systems and Internet of Anything concepts, the presentation will uncover a really powerful future of Industrial software systems. Evolution of the Node.js world started back in 2008, when Google released the powerful V8 JavaScript engine and Ryan Dahl began using it as a general purpose virtual machine allowing millions of JS developers to create server-side or practically any computer applications for all purposes using common web technologies. Thanks to many beneficial conjunctions like the GitHub and Npm communities as well as the Node friendly PaaS (e.g., MS Azure, Google Cloud, IBM Bluemix, Heroku) today Node.js-based technologies aspire to be a common language of large-scale distributed Internet of Anything systems considering the non mission critical layers. Our research team investigates new ideas to connect distributed Industrial system elements (sensors, actuators, control logic, intelligent machines, data logging and data mining) to each other and represents them in a Virtual World forming a general purpose information pool which allows for large-scale heterogeneous production systems. The last part of the presentation summarizes the results and ideas of a newly developed software engine, called MAXWHERE that provides effective working environments with spatial (Virtual Reality) multimedia arrangement and Intelligent System of Systems connectivity. The fundamental idea behind MAXWHERE is the generalization of the Document Object Model (DOM) introducing the Where Object Model (WOM) concept that covers the conventional WEB contents as well as the VR/AR building blocks in a coherent way empowered by the newest generation web APIs. Typical applications of MAXWHERE includes industrial monitoring and facility support, context-based collaborative working environment, industrial training, and Interactive live presentations.","","978-1-5386-0889-0","10.1109/INFORMATICS.2017.8327213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8327213","","Informatics;Service robots;Production;Internet;Cybernetics;Computational intelligence","application program interfaces;cloud computing;data mining;Java;production engineering computing;software engineering;virtual machines;virtual reality","control logic;intelligent machines;data logging;data mining;general purpose information pool;large-scale heterogeneous production systems;spatial multimedia arrangement;virtual world;virtual reality;web APIs;Node.js;industrial system elements;V8 JavaScript engine;node friendly PaaS;common language;Google Cloud;JS developers;general purpose virtual machine;Node.js world;granulated software ecosystem;production informatics;business intelligence;generation production intelligence;augmented virtuality;Where Object Model concept","","","","","","29 Mar 2018","","","IEEE","IEEE Conferences"
"Virtual reality visual data mining with nonlinear discriminant neural networks: application to leukemia and Alzheimer gene expression data","J. J. Valdes; A. J. Barton","Inst. for Inf. Technol., Nat. Res. Council, Ottawa, Ont., Canada; Inst. for Inf. Technol., Nat. Res. Council, Ottawa, Ont., Canada","Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.","27 Dec 2005","2005","4","","2475","2480 vol. 4","A hybrid stochastic-deterministic approach for solving NDA problems on very high dimensional biological data is investigated. It is based on networks trained with a combination of simulated annealing and conjugate gradient within a broad scale, high throughput computing data mining environment. High quality networks from the point of view of both discrimination and generalization capabilities are discovered. The NDA mappings generated by these networks, together with unsupervised representations of the data, lead to a deeper understanding of complex high dimensional data like leukemia and Alzheimer gene expression microarray experiments.","2161-4407","0-7803-9048-2","10.1109/IJCNN.2005.1556291","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1556291","","Virtual reality;Data mining;Neural networks;Gene expression;Biological system modeling;Computational modeling;Simulated annealing;Throughput;Biology computing;Computer networks","virtual reality;medical computing;data mining;neural nets;diseases;simulated annealing;gradient methods","Alzheimer gene expression data;leukemia;nonlinear discriminant neural networks;virtual reality visual data mining;hybrid stochastic-deterministic approach;simulated annealing;conjugate gradient","","6","","15","","27 Dec 2005","","","IEEE","IEEE Conferences"
"Towards a Machine-Learning Approach for Sickness Prediction in 360° Stereoscopic Videos","N. Padmanaban; T. Ruban; V. Sitzmann; A. M. Norcia; G. Wetzstein",Stanford Electrical Engineering Department; Stanford Electrical Engineering Department; Stanford Electrical Engineering Department; Stanford Psychology Department; Stanford Electrical Engineering Department,"IEEE Transactions on Visualization and Computer Graphics","19 Mar 2018","2018","24","4","1594","1603","Virtual reality systems are widely believed to be the next major computing platform. There are, however, some barriers to adoption that must be addressed, such as that of motion sickness - which can lead to undesirable symptoms including postural instability, headaches, and nausea. Motion sickness in virtual reality occurs as a result of moving visual stimuli that cause users to perceive self-motion while they remain stationary in the real world. There are several contributing factors to both this perception of motion and the subsequent onset of sickness, including field of view, motion velocity, and stimulus depth. We verify first that differences in vection due to relative stimulus depth remain correlated with sickness. Then, we build a dataset of stereoscopic 3D videos and their corresponding sickness ratings in order to quantify their nauseogenicity, which we make available for future use. Using this dataset, we train a machine learning algorithm on hand-crafted features (quantifying speed, direction, and depth as functions of time) from each video, learning the contributions of these various features to the sickness ratings. Our predictor generally outperforms a naïve estimate, but is ultimately limited by the size of the dataset. However, our result is promising and opens the door to future work with more extensive datasets. This and further advances in this space have the potential to alleviate developer and end user concerns about motion sickness in the increasingly commonplace virtual world.","1941-0506","","10.1109/TVCG.2018.2793560","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8267239","Virtual reality;simulator sickness;vection;machine learning","Videos;Stereo image processing;Three-dimensional displays;Visualization;Virtual environments;Machine learning algorithms;Trajectory","human factors;image motion analysis;learning (artificial intelligence);medical image processing;stereo image processing;video signal processing;virtual reality;visual perception","sickness ratings;commonplace virtual world;virtual reality systems;stereoscopic videos;sickness prediction;machine-learning approach;machine learning algorithm;stereoscopic 3D videos;relative stimulus depth;motion velocity;motion sickness","Adult;Algorithms;Computer Graphics;Databases, Factual;Depth Perception;Female;Humans;Machine Learning;Male;Middle Aged;Motion Sickness;User-Computer Interface;Video Recording;Virtual Reality;Young Adult","18","","40","","23 Jan 2018","","","IEEE","IEEE Journals"
"A consistency model for evaluating distributed virtual environments","Suiping Zhou; Wentong Cai; S. J. Turner; Hanfeng Zhao","Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore; Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore; Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore; Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore","Proceedings. 2003 International Conference on Cyberworlds","8 Jan 2004","2003","","","85","91","A distributed virtual environment (DVE) enables geographically distributed clients to interact with each other in a simulated environment. Due to the distributed architecture of DVEs, it is generally not easy to evaluate the performance of DVEs. In this paper, we propose a consistency model based on a metric called time-space inconsistency. The model relates a human participant's perception to the characteristic parameters of a DVE. Based on the model, the performance of a DVE can be easily evaluated without the actual execution of the DVE application, which is especially useful in the designing stage of a DVE. A ping-pong game is developed to verify the proposed model. Experiment results show that the model is effective in evaluating the performance of the game.","","0-7695-1922-9","10.1109/CYBER.2003.1253439","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1253439","","Virtual environment;Distributed computing;Computational modeling;Computer simulation;Computer architecture;Human factors;Virtual reality;Collaborative work;Large-scale systems;Industrial training","distributed programming;virtual reality;computer games;software reliability;programming environments","distributed virtual environment;DVE;geographically distributed client;simulated environment;distributed architecture;time-space inconsistency","","1","","12","","8 Jan 2004","","","IEEE","IEEE Conferences"
"xR-EgoPose: Egocentric 3D Human Pose From an HMD Camera","D. Tome; P. Peluse; L. Agapito; H. Badino",UCL; Facebook; University College London; Facebook,"2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","7727","7737","We present a new solution to egocentric 3D body pose estimation from monocular images captured from a downward looking fish-eye camera installed on the rim of a head mounted virtual reality device. This unusual viewpoint, just 2 cm away from the user's face, leads to images with unique visual appearance, characterized by severe self-occlusions and strong perspective distortions that result in a drastic difference in resolution between lower and upper body. Our contribution is two-fold. Firstly, we propose a new encoder-decoder architecture with a novel dual branch decoder designed specifically to account for the varying uncertainty in the 2D joint locations. Our quantitative evaluation, both on synthetic and real-world datasets, shows that our strategy leads to substantial improvements in accuracy over state of the art egocentric pose estimation approaches. Our second contribution is a new large-scale photorealistic synthetic dataset - xR-EgoPose - offering 383K frames of high quality renderings ofpeople with a diversity of skin tones, body shapes, clothing, in a variety of backgrounds and lighting conditions, performing a range of actions. Our experiments show that the high variability in our new synthetic training corpus leads to good generalization to real world footage and to state of the art results on real world datasets with ground truth. Moreover, an evaluation on the Human3.6M benchmark shows that the performance of our method is on par with top performing approaches on the more classic problem of 3D human pose from a third person viewpoint.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.00782","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010983","","Three-dimensional displays;Cameras;Pose estimation;Two dimensional displays;Training;Resists;Uncertainty","cameras;helmet mounted displays;image capture;image motion analysis;image sensors;pose estimation;realistic images;rendering (computer graphics);solid modelling;video signal processing;virtual reality","xR-EgoPose;HMD camera;monocular images;fish-eye camera;unique visual appearance;encoder-decoder architecture;2D joint locations;large-scale photorealistic synthetic dataset;high quality renderings;head mounted virtual reality device;dual branch decoder design;egocentric 3D human body pose estimation","","3","","61","","27 Feb 2020","","","IEEE","IEEE Conferences"
"High tech aviation security program in Africa - a model for technology transfer","K. B. Sample; D. K. Taylor; E. Rao",NA; NA; NA,"38th Annual 2004 International Carnahan Conference on Security Technology, 2004.","14 Mar 2005","2004","","","270","277","This paper focuses on the US Department of Transportation's (DOT) international airport security initiative in Nigeria. Recently, the aviation leadership of Africa, recognizing the need to take aviation security to a higher level, has been working with DOT under the Nigeria Transportation Project (NTP) since 1998. The NTP initiative, a special Nigerian Airport Security Program has been implemented since 2001 using various security technologies as test beds and program enhancements to aviation security. The impact of these technologies are to ensure that Nigerian Airport Security Program will be brought to compliance with existing and post 911 International Civil Aviation Organization (ICAO) security standards and regulations. The concept of intermediate technologies and mature technologies transfer to emerging countries will be described. The critical security issues facing the aviation security in the uses of technologies, their operations and training will be covered. The technology transfer concept with the uses of a test-bed approach will be detailed. The security technologies covered include perimeter security, passenger screening, immigration/passport document screening, carry-on baggage screening, checked baggage screening and cargo screening. The current, on going and new initiatives on various security measures such as passenger-baggage tracking and reconciling, radio-frequency identification device (RFID) technology, access controls etc., are also be outlined. Also, training using ICAO's aviation security training packages (ASTP), and best practices gained through on-site computer-based training (CBT) of screeners for all related ICAO-type classroom courses, carried out in the NTP are described. Complexity of training of screeners/supervisors for checkpoints, that mirror US checkpoints, taking into account religious, language and political differences, which made this task challenging, are addressed. These include technician training; screener and supervisor training for: X-ray machine - carry-on baggage, checked baggage and cargo, primary and secondary walk-through metal detector, explosive trace detectors (ETD), passenger passport/visa identification/verification systems etc. Insight gained and successes on the deployed security equipment from both technology and process points of view are covered. The impact to aviation security and airports program in specific and to the Federal Airport Authority in Nigeria (FAAN) in general are also addressed. Finally, the inter-governmental technology transfer and intra-governmental lessons learned are summarized.","","0-7803-8506-3","10.1109/CCST.2004.1405404","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1405404","","Security;Africa;Technology transfer;Airports;US Department of Transportation;Testing;Radiofrequency identification;X-ray detection;X-ray detectors;Standards organizations","technology transfer;security;airports;travel industry;standards;computer based training","high tech aviation security program;US Department of Transportation;international airport security initiative;Nigeria Transportation Project;Nigerian airport security program;International Civil Aviation Organization;security standards;security regulations;perimeter security;passenger screening;document screening;carry-on baggage screening;checked baggage screening;cargo screening;passenger-baggage tracking;radio-frequency identification device technology;access controls;Aviation Security Training Packages;computer-based training;US checkpoints;technician training;X-ray machine;walk-through metal detector;explosive trace detectors;passenger passport identification;Visa identification;verification systems;security equipment;airports program;Federal Airport Authority;inter-governmental technology transfer;intra-governmental lessons","","1","","","","14 Mar 2005","","","IEEE","IEEE Conferences"
"Design of Cyber-Human Frameworks for Immersive Learning","A. Gupta; J. Cecil; O. Tapia; M. Sweet-Darter","Oklahoma State University,Center for Cyber-Physical Systems,Stillwater,USA; Oklahoma State University,Co-Director, Center for Cyber-Physical Systems,Stillwater,USA; Oklahoma State University,Center for Cyber-Physical Systems,Stillwater,USA; Director, Anselm Center, Edmond,Oklahoma,USA","2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)","28 Nov 2019","2019","","","1563","1568","This paper focuses on the creation of information centric Cyber-Human Learning Frameworks involving Virtual Reality based mediums. A generalized framework is proposed, which is adapted for two educational domains: one to support education and training of residents in orthopedic surgery and the other focusing on science learning for children with autism. Users, experts and technology based mediums play a key role in the design of such a Cyber-Human framework. Virtual Reality based immersive and haptic mediums were two of the technologies explored in the implementation of the framework for these learning domains. The proposed framework emphasizes the importance of Information-Centric Systems Engineering (ICSE) principles which emphasizes a user centric approach along with formalizing understanding of target subjects or processes for which the learning environments are being created.","2577-1655","978-1-7281-4569-3","10.1109/SMC.2019.8914205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8914205","Virtual Reality;Human-Computer Interaction;Virtual Learning","Haptic interfaces;Surgery;Human computer interaction;Training;Solid modeling","biomedical education;computer aided instruction;handicapped aids;medical computing;surgery;virtual reality","immersive learning;generalized framework;educational domains;science learning;technology based mediums;immersive mediums;haptic mediums;information-centric systems engineering principles;user centric approach;learning environments;cyber-human framework;virtual reality based mediums;information centric cyber-human learning frameworks","","","","48","","28 Nov 2019","","","IEEE","IEEE Conferences"
"Gamification in CPR - a Review of Game Dynamics and Mechanics","I. Santos; C. Sa-Couto; P. Vieira-Marques","Universidade do Porto, Sousa Faculdade de Medicina da Universidade do Porto and Faculdade de Ciências da, Porto, Portugal; Faculty of Medicine of University of Porto, Center for Health Technology and Services Research (CINTESIS), Biomedical Simulation Center Porto, Portugal; Faculty of Medicine of University of Porto, Center for Health Technology and Services Research (CINTESIS), Porto, Portugal","2019 14th Iberian Conference on Information Systems and Technologies (CISTI)","15 Jul 2019","2019","","","1","4","In sudden cardiac arrest, early cardiopulmonary resuscitation, with emphasis on chest compressions, is a fundamental step in the Chain of Survival. It is of most importance to have good technique to increase the success rate. According to some studies, CPR is less effective because people don't often train their skills. The objective of this work is to identify what game elements have been used to build serious games and gamification approaches for CPR training, and how this may influence the user's learning. From 3 repositories 307 articles were returned from the query, only 33 of these obeyed the inclusion criteria set for the study. The studies should be directed at the general population or health professionals; describes a system/method related to CPR or BLS training and using a gamified approach. Results show that, most of the games are digital; single player and don't use any external hardware. Regarding game elements, simple scoring is the most common feature. The main purpose of training CPR systems focuses more on knowledge acquisition and less on actual practice of CPR skill.","2166-0727","978-9-8998-4349-3","10.23919/CISTI.2019.8760603","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8760603","CPR;serious games;gamification","Games;Training;Hardware;Information systems;Cardiac arrest;Sociology","biomedical education;cardiology;computer based training;knowledge acquisition;medical computing;serious games (computing)","game elements;CPR systems;CPR skill;game dynamics;sudden cardiac arrest;chest compressions;serious games;gamification approaches;CPR training;BLS training;gamified approach;cardiopulmonary resuscitation;knowledge acquisition","","","","46","","15 Jul 2019","","","IEEE","IEEE Conferences"
"Cellphone Augmented Reality Game-based Rehabilitation for Improving Motor Function and Mental State after Stroke","X. Song; L. Ding; J. Zhao; J. Jia; P. Shull","State Key Laboratory of Mechanical System and Vibration, Shanghai Jiaotong University, Shanghai, China; Department of Rehabilitation Medicine, Huashan Hospital, Fudan University, Shanghai, China; Nanjing University of Chinese Medicine, Nanjing, China; Department of Rehabilitation Medicine, Huashan Hospital, Fudan University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiaotong University, Shanghai, China","2019 IEEE 16th International Conference on Wearable and Implantable Body Sensor Networks (BSN)","25 Jul 2019","2019","","","1","4","Effective stroke rehabilitation typically involves improving both motor function and mental state. Traditional rehabilitation systems are generally expensive, not portable and difficult to operate. As a first step toward overcoming these existing shortcomings, we developed a cellphone augmented reality (AR) rehabilitation system for stroke rehabilitation. Three serious games for upper limb motor function and cognitive training were developed in which patients move their arms to touch virtual targets generated in the three-dimensional AR environment. Patients received visual and vibration feedback after successfully touching each target. Eight stroke patients with upper limb dysfunction performed pilot validation testing with the cellphone AR system. Motor function performance was evaluated based on performance in the AR games and mental state was evaluated via questionnaires self-reporting various aspects of mental state. Results showed that motor performance improved by the last trial as compared to the first trial (p<;0.05). In addition, the majority of patients reported that they felt `relaxed' and `happy' while playing the AR rehabilitation games. These results demonstrate the potential of cellphone AR rehabilitation to improve upper-limb motor function and mental state for stroke patients and lay a foundation for a future home-based rehabilitation paradigm.","2376-8894","978-1-5386-7477-2","10.1109/BSN.2019.8771093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8771093","stroke;upper-limb rehabilitation;mental state;cellphone;serious AR games","Games;Stroke (medical condition);Training;Robot sensing systems;Hospitals;Color","augmented reality;biomechanics;computer games;feedback;medical robotics;neurophysiology;patient rehabilitation;patient treatment","motor function performance;mental state;motor performance;AR rehabilitation games;upper-limb motor function;stroke patients;future home-based rehabilitation paradigm;reality game-based rehabilitation;effective stroke rehabilitation;traditional rehabilitation systems;cellphone augmented reality rehabilitation system;serious games;upper limb motor function;upper limb dysfunction performed pilot validation testing","","2","","24","","25 Jul 2019","","","IEEE","IEEE Conferences"
"Teaching and training of network protocols with DEVS-suite","A. Zengin; H. Sarjoughian","Department of Computer Science Education, Sakarya University, Serdivan, Turkey; Arizona Center for Integrative Modeling and Simulation, Department of Computer Science and Engineering, Arizona State University, Tempe, USA","2009 International Symposium on Performance Evaluation of Computer & Telecommunication Systems","28 Aug 2009","2009","41","","104","111","This paper presents a robust simulation environment targeted for teaching and learning the complex dynamics of computer networks. The general-purpose DEVS-suite simulator supports animation with I/O and state trajectories of computer network models developed using parallel DEVS modeling approach. The simulator offers high-level model abstraction as compared with simulators such as NS-2. The combined capabilities afforded by the robust DEVS-suite simulator assists in understanding the fundamentals of computer network topologies and the logics of communication protocols. This newly developed DEVS-Suite offers an expressive, yet relatively simple to use, simulation environment for students and educators to develop and experiment with computer network models.","","978-1-4244-4165-5","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5224139","DEVS-Suite;Education;Computer Networks;ns-2;OSPF","Protocols;Computational modeling;Computer simulation;Computer networks;Computer science education;Robustness;Network topology;Discrete event simulation;Routing;Animation","computer networks;computer science education;protocols;teaching;training","teaching;network protocol;general-purpose DEVS-suite simulator;high-level model abstraction;DEVS modeling approach;NS-2 simulator;computer network topologies;communication protocol","","","","30","","28 Aug 2009","","","IEEE","IEEE Conferences"
"The Umbra simulation framework as applied to building HLA federates","E. J. Gottlieb; M. J. McDonald; F. J. Oppel; J. B. Rigdon; P. G. Xavier","Orion Int. Technol. Inc., Albuquerque, NM, USA; NA; NA; NA; NA","Proceedings of the Winter Simulation Conference","29 Jan 2003","2002","1","","981","989 vol.1","Sandia's Umbra modular simulation framework was designed to enable the modeling of robots for manufacturing, military, and security system concept evaluation. Umbra generalizes data-flow-based simulation to enable modeling of heterogeneous interaction phenomena via a multiple worlds abstraction. This and other features make Umbra particularly suitable for developing simulation federates. Umbra's HLA interface library utilizes DMSO's HLA Run Time Infrastructure 1.3-Next Generation (RTI 1.3-NG) software library to federate Umbra-based models into HLA environments. Examples draw on a first application that provides component technologies for the US Army JPSD's Joint Virtual Battlespace (JVB) simulation environment for Objective Force concept analysis.","","0-7803-7614-5","10.1109/WSC.2002.1172990","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1172990","","Analytical models;Software libraries;Robot sensing systems;Virtual manufacturing;Mobile robots;Computer architecture;Unmanned aerial vehicles;Data security;Application software;Computational geometry","military computing;digital simulation;computer based training;software agents;multi-agent systems;robots","Umbra modular simulation framework;robots;manufacturing;military;security system concept evaluation;data-flow-based simulation;heterogeneous interaction phenomena;multiple worlds abstraction;simulation federates;high-level architecture interface library;HLA Run Time Infrastructure 1.3-Next Generation software library;US Army Joint Virtual Battlespace simulation environment;Objective Force concept analysis","","7","1","13","","29 Jan 2003","","","IEEE","IEEE Conferences"
"Accessibility of Immersive Serious Games for Persons with Cognitive Disabilities","P. Guitton; H. Sauzéon; P. Cinquin",University of Bordeaux; University of Bordeaux; University of Bordeaux,"2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","443","447","E-learning systems are still not very accessible for persons with disabilities, particularly those with cognitive impairments. It's well known that the training deficit is one of the cause of lower employment rates. In the past, we have addressed this issue by working on the accessibility of MOOCs. We have developed Aiana, a MOOC player with accessibility features based on the fragmentation of information streams and enabling user interface self-configuration. We are starting a new research program focused on the accessibility of immersive Serious Games for persons with cognitive impairments by first transposing some of Aiana's design principles. We believe that immersive Serious Games can provide effective assistance to learning for PWDs and we want to demonstrate this rigorously through large field studies. More generally, we wonder about the questions raised by the accessibility of Mixed Reality tools in immersive e-learning systems.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951894","accessibility;e-learning;serious-games;immersion","Augmented reality","cognition;computer based training;educational courses;handicapped aids;human computer interaction;serious games (computing);virtual reality","immersive serious games;cognitive impairments;training deficit;employment rates;MOOC player;immersive e-learning systems;Aiana design principles;user interface self-configuration;person with cognitive disabilities;information stream fragmentation;PWDs;mixed reality tools","","","","31","","9 Jan 2020","","","IEEE","IEEE Conferences"
"MIND - An EEG Neurofeedback Multitasking Game","W. L. Lim; O. Sourina; L. Wang","Fraunhofer IDM @ NTU, Nanyang Technol. Univ., Singapore, Singapore; Fraunhofer IDM @ NTU, Nanyang Technol. Univ., Singapore, Singapore; Sch. of Electr. & Electron. Eng., Nanyang Technol. Univ., Singapore, Singapore","2015 International Conference on Cyberworlds (CW)","4 Feb 2016","2015","","","169","172","Multitasking is a prevalent phenomenon in our daily lives. Certain occupations, especially in the aviation industry, consider proficient multitasking as a key skill set in their hiring process for pilot or air traffic controller candidates. There is a growing interest in the testing and training of the multitasking ability, with in house software or commercial psychological products, usually implemented in a static task battery format. In this paper, we propose a 3D game, Multitask In Neurofeedback Driving (MIND) for training and testing of the multitasking ability. The game is developed using the Unreal 3 game engine and incorporates neurofeedback, a technique used in the training of human cognitive abilities, to further enhance the potential benefits of the training procedure. The tasks used in the multitasking condition are inspired by various psychological tests and implemented in a manner that attempts to simulate the general cognitive processes required for multitasking while driving a vehicle or piloting an aircraft. The game comes in three variants, single task condition, multitasking condition and multitasking with neurofeedback condition, for the purpose of validating the training outcomes in future studies.","","978-1-4673-9403-1","10.1109/CW.2015.39","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7398410","EEG;Neurofeedback training;Neurofeedback game;multitasking;game design","Games;Multitasking;Neurofeedback;Training;Electroencephalography;Roads;Testing","aerospace computing;air traffic control;cognition;computer based training;computer games;electroencephalography;psychology","EEG neurofeedback multitasking game;aviation industry;hiring process;air traffic controller;multitasking ability testing;multitasking ability training;psychological products;static task battery format;3D game;multitask in neurofeedback driving;MIND;Unreal 3 game engine;human cognitive abilities;training procedure;psychological tests;aircraft;single task condition;multitasking condition;neurofeedback condition","","5","","18","","4 Feb 2016","","","IEEE","IEEE Conferences"
"A Design and Analysis of a Hybrid Multicast Transport Protocol for the Haptic Virtual Reality Tracheotomy Tele-Surgery Application","A. Boukerche; H. Maamar; A. Hossain","PARADISE Research Laboratory SITE, University of Ottawa; PARADISE Research Laboratory SITE, University of Ottawa; PARADISE Research Laboratory SITE, University of Ottawa","2007 IEEE International Parallel and Distributed Processing Symposium","11 Jun 2007","2007","","","1","6","Nowadays, distributed collaborative virtual environments are used in many scenarios such as tele-surgery, gaming, and industrial training, however several challenging issues remain to be resolved before haptic virtual reality based class of applications become a common place. In this paper, we focus upon a tracheotomy tele-surgery application that is based on closely coupled and highly synchronized haptic tasks that require a high-level of coordination among the participants. We also propose a hybrid protocol that is able to satisfy all the collaborative and haptic virtual environment requirements in general and tracheotomy tele-surgery in particular. We discuss our C-HAVE tracheotomy tele-surgery framework and report on the performance results we have obtained to evaluate our protocol using an extensive set of experiments.","1530-2075","1-4244-0909-8","10.1109/IPDPS.2007.370592","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4228320","","Multicast protocols;Transport protocols;Haptic interfaces;Virtual reality;Virtual environment;Collaboration;Industrial training;Delay;Scalability;Region 7","groupware;medical computing;multicast protocols;surgery;telemedicine;transport protocols;virtual reality","hybrid multicast transport protocol;haptic virtual reality tracheotomy telesurgery application;distributed collaborative virtual environments","","","","10","","11 Jun 2007","","","IEEE","IEEE Conferences"
"Poster: Updating an obsolete trainer using passive haptics and pressure sensors","M. Wurpts","Southwest Research Institute®, USA","2009 IEEE Symposium on 3D User Interfaces","7 Apr 2009","2009","","","155","156","Training systems based on hardware mockups provide physical fidelity at the expense of flexibility. Maintaining concurrency in these mock-ups can be time-consuming and expensive. Over the past several years, Southwest Research Institute (SwRIreg) has worked with the United States Air Force to develop a generalized approach which uses purely virtual assets to provide training in a flexible environment in which configuration changes are made solely through software modifications. While a purely virtual approach has proven effective and flexible, it lacks the realistic interactions supported by the physical constraints present in mock-ups. This paper describes a novel approach to provide a more realistic interface while also extending the useful life of a training system which might otherwise be rendered obsolete. The technique combines virtual and real assets to provide haptic feedback. The interaction technique uses precision finger tracking combined with tactile sensors attached to the finger tip.","","978-1-4244-3965-2","10.1109/3DUI.2009.4811233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811233","","Haptic interfaces;Fingers;Light emitting diodes;Switches;Military aircraft;Force sensors;Virtual environment;Displays;Optical feedback;Sensor systems","aerospace computing;haptic interfaces;pressure sensors;tactile sensors","passive haptics;pressure sensor;training system;haptic feedback;precision finger tracking;tactile sensor","","5","","1","","7 Apr 2009","","","IEEE","IEEE Conferences"
"Work in progress — Portable Student Labs implementation","P. Seeling",University of Wisconsin-Stevens,"2010 IEEE Frontiers in Education Conference (FIE)","23 Dec 2010","2010","","","F2F-1","F2F-3","While experiential learning through hands-on laboratory units can improve student learning outcomes, traditionally the provisioning and maintenance of dedicated computer laboratories is a costly and time-intensive undertaking. Virtualization can alleviate some of the associated problems, especially when the lab units under consideration are software-based. While virtualization has attracted a great deal of research and implementations to date, some its potential benefits are not utilized when institutions have to provide and maintain fully virtualized environments. In this paper, we introduce Portable Student Labs (PSLabs) based on the QEMU virtualization environment. PSLabs are fully portable virtualized environments that students obtain and afterwards execute either in common computing facilities available on-campus or on their individual computing equipment, thus eliminating the need for dedicated (lab-specific) computing hardware or virtual environments. In addition to the general functionality, we describe typical considerations for the process of creating the PSLabs and its delivery to students.","2377-634X","978-1-4244-6262-9","10.1109/FIE.2010.5673330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5673330","Computer-based training;virtualization initiative;computer lab;portability","Computers;Operating systems;Linux;Random access memory;Laboratories;Media","computer based training;laboratories;virtual reality","portable student labs implementation;experiential learning;hands-on laboratory units;computer laboratories;QEMU virtualization environment","","","","6","","23 Dec 2010","","","IEEE","IEEE Conferences"
"RoboTHOR: An Open Simulation-to-Real Embodied AI Platform","M. Deitke; W. Han; A. Herrasti; A. Kembhavi; E. Kolve; R. Mottaghi; J. Salvador; D. Schwenk; E. VanderBilt; M. Wallingford; L. Weihs; M. Yatskar; A. Farhadi",University of Washington; PRIOR @ Allen Institute for AI; PRIOR @ Allen Institute for AI; PRIOR @ Allen Institute for AI; University of Washington; PRIOR @ Allen Institute for AI; PRIOR @ Allen Institute for AI; University of Washington; PRIOR @ Allen Institute for AI; PRIOR @ Allen Institute for AI; PRIOR @ Allen Institute for AI; University of Washington; PRIOR @ Allen Institute for AI; PRIOR @ Allen Institute for AI; University of Washington,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","3161","3171","Visual recognition ecosystems (e.g. ImageNet, Pascal, COCO) have undeniably played a prevailing role in the evolution of modern computer vision. We argue that interactive and embodied visual AI has reached a stage of development similar to visual recognition prior to the advent of these ecosystems. Recently, various synthetic environments have been introduced to facilitate research in embodied AI. Notwithstanding this progress, the crucial question of how well models trained in simulation generalize to reality has remained largely unanswered. The creation of a comparable ecosystem for simulation-to-real embodied AI presents many challenges: (1) the inherently interactive nature of the problem, (2) the need for tight alignments between real and simulated worlds, (3) the difficulty of replicating physical conditions for repeatable experiments, (4) and the associated cost. In this paper, we introduce RoboTHOR to democratize research in interactive and embodied visual AI. RoboTHOR offers a framework of simulated environments paired with physical counterparts to systematically explore and overcome the challenges of simulation-to-real transfer, and a platform where researchers across the globe can remotely test their embodied models in the physical world. As a first benchmark, our experiments show there exists a significant gap between the performance of models trained in simulation when they are tested in both simulations and their carefully constructed physical analogs. We hope that RoboTHOR will spur the next stage of evolution in embodied computer vision.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00323","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157346","","Robots;Navigation;Artificial intelligence;Task analysis;Computational modeling;Visualization;Training","artificial intelligence;computer vision;image recognition;interactive systems;public domain software;robot vision;virtual reality","interactive visual AI;open simulation-to-real embodied AI platform;embodied visual AI;embodied computer vision;simulation-to-real transfer;simulated environments;RoboTHOR;visual recognition ecosystems","","1","","79","","5 Aug 2020","","","IEEE","IEEE Conferences"
"Skill generalization relevant to robotic neuro-rehabilitation","D. Bansal; R. Kenyon; J. L. Patton","University of Illinois-Chicago, USA; University of Illinois-Chicago, USA; University of Illinois-Chicago, USA","2010 Annual International Conference of the IEEE Engineering in Medicine and Biology","11 Nov 2010","2010","","","2250","2254","Upper limb extremity rehabilitation practices are increasingly involving robotic interaction for repetitive practice, and there is increasing skepticism whether such systems can provide the relevant practice that can be generalized (or transferred) to functional activities in the real world. Most importantly, will patients be able to generalize in three critical ways: (1) to unpracticed directions, (2) to unpracticed movement distances, and (3) to unpracticed weight-eliminated conditions? Rather than presuming that patients could generalize in three conditions, this study tested whether there was any evidence of such generalization ability in healthy individuals. We found that there was some evidence in all conditions except for the ability of healthy subjects to generalize to large movements after practicing small. Such results suggest that larger robotic systems are advantageous for training the functional motions that can include large actions.","1558-4615","978-1-4244-4123-5","10.1109/IEMBS.2010.5627308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5627308","","Training;Gravity;Visualization;Virtual reality;Performance evaluation;Robot sensing systems","medical robotics;neurophysiology;patient rehabilitation;robot kinematics;virtual reality","skill generalization;robotic neuro-rehabilitation;upper limb extremity rehabilitation;robotic interaction;repetitive practice;unpracticed directions;unpracticed movement distances;unpracticed weight-eliminated condition","Activities of Daily Living;Adult;Algorithms;Arm Injuries;Equipment Design;Female;Humans;Male;Motor Activity;Movement;Movement Disorders;Nervous System;Robotics;Upper Extremity","","","19","","11 Nov 2010","","","IEEE","IEEE Conferences"
"Attention-Based Autism Spectrum Disorder Screening With Privileged Modality","S. Chen; Q. Zhao",University of Minnesota; University of Minnesota,"2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","1181","1190","This paper presents a novel framework for automatic and quantitative screening of autism spectrum disorder (ASD). It is motivated to address two issues in the current clinical settings: 1) short of clinical resources with the prevalence of ASD (1.7% in the United States), and 2) subjectivity of ASD screening. This work differentiates itself with three unique features: first, it proposes an ASD screening with privileged modality framework that integrates information from two behavioral modalities during training and improves the performance on each single modality at testing. The proposed framework does not require overlap in subjects between the modalities. Second, it develops the first computational model to classify people with ASD using a photo-taking task where subjects freely explore their environment in a more ecological setting. Photo-taking reveals attentional preference of subjects, differentiating people with ASD from healthy people, and is also easy to implement in real-world clinical settings without requiring advanced diagnostic instruments. Third, this study for the first time takes advantage of the temporal information in eye movements while viewing images, encoding more detailed behavioral differences between ASD people and healthy controls. Experiments show that our ASD screening models can achieve superior performance, outperforming the previous state-of-the-art methods by a considerable margin. Moreover, our framework using diverse modalities demonstrates performance improvement on both the photo-taking and image-viewing tasks, providing a general paradigm that takes in multiple sources of behavioral data for a more accurate ASD screening. The framework is also applicable to various scenarios where one-to-one pairwise relationship is difficult to obtain across different modalities.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.00127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010066","","Task analysis;Variable speed drives;Visualization;Computational modeling;Training;Testing;Biological system modeling","cognition;eye;feature extraction;handicapped aids;human computer interaction;learning (artificial intelligence);medical computing;medical disorders","diverse modalities;ASD screening models;ASD people;real-world clinical settings;photo-taking reveals attentional preference;photo-taking task;single modality;behavioral modalities;privileged modality framework;clinical resources;clinical settings;quantitative screening;automatic screening;autism spectrum disorder screening","","1","","37","","27 Feb 2020","","","IEEE","IEEE Conferences"
"Anisotropic elasticity and force extrapolation to improve realism of surgery simulation","G. Picinbono; J. -. Lombardo; H. Delingette; N. Ayache","Inst. Nat. de Recherche en Inf. et Autom., Sophia-Antipolis, France; NA; NA; NA","Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065)","6 Aug 2002","2000","1","","596","602 vol.1","We describe the latest developments of the minimally invasive hepatic surgery simulator prototype developed at INRIA. The goal of this simulator is to provide a realistic training test-bed for performing laparoscopic procedures. Therefore, its main functionality is to simulate the deformation and cutting of tri-dimensional anatomical models with the help of two virtual laparoscopic surgical instruments. Throughout the paper, we present the general features of the simulator including the implementation of different bio-mechanical models based on linear elasticity and finite element theory and the integration of two force-feedback devices in the simulation platform. More precisely, we describe two important developments that improve the overall realism of the simulator. First, we can create bio-mechanical models that include the notion of anisotropic deformation. Indeed, we have generalized the linear elastic behavior of anatomical models to ""transversally isotropic"" materials, i.e. materials having one privileged direction of deformation. The second improvement is related to the problem of haptic rendering. Currently, we are able to achieve a simulation frequency of 25 Hz (visual real-time) with anatomical models of complex geometry and behavior. But to achieve a good haptic feedback requires a frequency update of applied forces typically above 300 Hz (haptic real-time). Thus, we propose a force extrapolation algorithm in order to reach haptic real-time.","1050-4729","0-7803-5886-4","10.1109/ROBOT.2000.844118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=844118","","Anisotropic magnetoresistance;Elasticity;Extrapolation;Deformable models;Haptic interfaces;Minimally invasive surgery;Biological materials;Solid modeling;Frequency;Virtual prototyping","elasticity;surgery;force feedback;finite element analysis;integration;computer based training","anisotropic elasticity;force extrapolation;surgery simulation;minimally invasive hepatic surgery simulator prototype;training test-bed;laparoscopic procedures;tri-dimensional anatomical models;bio-mechanical models;linear elasticity;force-feedback devices;anisotropic deformation;anatomical models;transversally isotropic materials;haptic feedback;visual real-time;haptic real-time","","19","1","27","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Generalized approach for modeling minimally invasive surgery as a stochastic process using a discrete Markov model","J. Rosen; J. D. Brown; L. Chang; M. N. Sinanan; B. Hannaford","Dept. of Electr. Eng., Univ. of Washington, WA, USA; NA; NA; NA; NA","IEEE Transactions on Biomedical Engineering","21 Feb 2006","2006","53","3","399","413","Minimally invasive surgery (MIS) involves a multidimensional series of tasks requiring a synthesis between visual information and the kinematics and dynamics of the surgical tools. Analysis of these sources of information is a key step in defining objective criteria for characterizing surgical performance. The Blue DRAGON is a new system for acquiring the kinematics and the dynamics of two endoscopic tools synchronized with the endoscopic view of the surgical scene. Modeling the process of MIS using a finite state model [Markov model (MM)] reveals the internal structure of the surgical task and is utilized as one of the key steps in objectively assessing surgical performance. The experimental protocol includes tying an intracorporeal knot in a MIS setup performed on an animal model (pig) by 30 surgeons at different levels of training including expert surgeons. An objective learning curve was defined based on measuring quantitative statistical distance (similarity) between MM of experts and MM of residents at different levels of training. The objective learning curve was similar to that of the subjective performance analysis. The MM proved to be a powerful and compact mathematical model for decomposing a complex task such as laparoscopic suturing. Systems like surgical robots or virtual reality simulators in which the kinematics and the dynamics of the surgical tool are inherently measured may benefit from incorporation of the proposed methodology.","1558-2531","","10.1109/TBME.2005.869771","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1597490","Dynamics;haptics;human machine interface;kinematics;manipulation;Markov model;minimally invasive;robotics;simulation;soft tissue;surgery;surgical skill assessment;surgical tool;vector quantization","Minimally invasive surgery;Stochastic processes;Kinematics;Performance analysis;Multidimensional systems;Information analysis;Information resources;Layout;Animal structures;Protocols","surgery;Markov processes;endoscopes;medical robotics;virtual reality;robot kinematics","minimally invasive surgery;stochastic process;discrete Markov model;visual information;surgical tool kinematics;surgical tool dynamics;Blue DRAGON;endoscopic tools;finite state model;objective learning curve;subjective performance analysis;laparoscopic suturing;surgical robots;virtual reality simulators","Computer Simulation;Endoscopes;Endoscopy;Expert Systems;Humans;Man-Machine Systems;Markov Chains;Models, Biological;Models, Statistical;Robotics;Robotics;Stochastic Processes;Surgery, Computer-Assisted;Surgery, Computer-Assisted;Surgical Procedures, Minimally Invasive;Surgical Procedures, Minimally Invasive;Task Performance and Analysis;User-Computer Interface","160","3","47","","21 Feb 2006","","","IEEE","IEEE Journals"
"Improving Quality of Life from Birth to Old Age with Ubiquitous Computing and Virtual Reality","S. Duval; C. Hoareau; H. Hashizume","Nat. Inst. of Inf., Tokyo; Nat. Inst. of Inf., Tokyo; Nat. Inst. of Inf., Tokyo","2008 International Conference on Convergence and Hybrid Information Technology","9 Sep 2008","2008","","","371","377","Virtual reality and ubiquitous computing can significantly improve the general public's quality of life worldwide from birth to old age because they allow monitoring, awareness and support in real and digital worlds thanks to sensors, actuators, remote connections, and dedicated knowledge bases. However, age influences their usefulness and appropriateness due to growth and decline as well as changes in activities and uses of technology. Based on the cognitive, physical, physiological, and sensory characteristics of young people and older adults, we discuss dedicated systems that exploit intelligent environments, wearable computers and virtual reality. Our most significant contribution is the analysis of the potential and limits of ubiquitous computing and virtual reality to improve quality of life, taking into account all age ranges.","","978-0-7695-3328-5","10.1109/ICHIT.2008.202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4622854","Virtual Reality;Ubiquitous Computing;Age;Design;Sociology","Virtual reality;Biomedical monitoring;Monitoring;Temperature sensors;Temperature measurement;Pediatrics;Training","artificial intelligence;social aspects of automation;ubiquitous computing;virtual reality;wearable computers","ubiquitous computing;virtual reality;public quality of life;sensors;actuators;remote connections;dedicated knowledge bases;intelligent environments;wearable computers","","1","","26","","9 Sep 2008","","","IEEE","IEEE Conferences"
"The development and trial of SEGWorld: a virtual environment for software engineering student group work","S. Drummond; C. Boldyreff","Dept. of Comput. Sci., Durham Univ., UK; NA","Thirteenth Conference on Software Engineering Education and Training","6 Aug 2002","2000","","","87","97","Software engineering tasks, during both development and maintenance, typically involve teamwork using computers. Team members rarely work on isolated computers. An underlying assumption of our research is that software engineering teams will work more effectively if adequately supported by network-based groupware technology and project management tools. This research is investigating the provision of such network-based support for software engineering teams. The immediate objective is to provide network-based support, specifically for students working on software engineering group (SEG) projects in the Department of Computer Science at Durham. The long term objectives are to develop more flexible support for group working among computer science students and their staff supervisors for project work and tutorials in general. This paper reports on our recent results and assesses how far we have been successful in achieving our immediate objective.","1093-0175","0-7695-0421-3","10.1109/CSEE.2000.827026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=827026","","Virtual environment;Software engineering;Computer science;Electrical capacitance tomography;Collaborative work;Teamwork;Computer science education;Collaborative software;Isolation technology;Project management","software engineering;groupware;computer science education;project management;educational courses;computer aided instruction","SEGWorld;virtual environment;software engineering student;student group work;software development;software maintenance;teamwork;groupware;project management tools;network-based support;software engineering group projects;computer science education","","5","","14","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Organisation and functioning of the training centre serving lifelong seafarers' education","M. Nadrljanski; R. Božić; L. Dula","Faculty of Maritime Studies 21000 Split, Ctoatia; Split Ship Management 21000 Split, Croatia; CEO of Aldi, 21000 Split, Croatia","2011 Proceedings of the 34th International Convention MIPRO","28 Jul 2011","2011","","","1354","1358","Developed world societies are based on knowledge. They are based on the concept of lifelong education which differs completely from traditional education, not only in quality but also in quantity. Formal education in childhood and youth now becomes a synergy of initial and continuous education, as formal and informal competence education, in terms of various opportunities of society which is based on lifelong learning. In this context, the European Union also proclaimed lifelong learning based on Europe of knowledge as the key development guideline in the first decade of the 21st century. The goal of this paper is to present and analyse the phenomenon of lifelong education of maritime officials in `Split Ship Management', Split, to be precise, in its Nautical training centre, known as `Training Centre'. The mariner education project arose from cooperation with world education centres which use the most recent aspects of maritime theory and practice, both in the domestic and wider world expertise context adjusted to the latest European Union criteria. It is worth emphasising the growing popularity of additional maritime trainings in the world as a necessity of the development of new knowledges and skills in various areas in maritime economy, which are becoming a basis for further development both with individuals and companies. Trainings are conducted in computerised laboratories and on a simulator. This formal framework used for shaping and performing trainings at the Nautical training centre is based on the current knowledge and experience of trainers and their constant strive for modernisation and professional knowledge quality improvement, as well as for knowledge in general as a basic principle of development.","","978-953-233-059-5","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5967270","education of seafarers;concept of lifelong learning;e-learning;inspection and staff management","Training;Marine vehicles;Europe;Navigation;Engines;Educational institutions","computer based training;continuing professional development;marine engineering","nautical training centre organisation;nautical training centre functioning;lifelong seafarers education;European Union;maritime officials;split ship management;mariner education project;modernisation knowledge quality improvement;professional knowledge quality improvement","","","","3","","28 Jul 2011","","","IEEE","IEEE Conferences"
"A coupling library for the force dimension haptic devices and the 20-sim modelling and simulation environment","F. Sanfilippo; P. B. T. Weustink; K. Y. Pettersen","Department of Maritime Technology and Operations, Aalesund University College, Postboks 1517, 6025 Aalesund, Norway; Controllab Products B.V. Hengelosestraat, 500, 7521 AN Enschede, Netherlands; Department of Engineering, Cybernetics, Norwegian University of Science and Technology, 7491 Trondheim, Norway","IECON 2015 - 41st Annual Conference of the IEEE Industrial Electronics Society","28 Jan 2016","2015","","","000168","000173","A haptic feedback device is a device that establishes a kinaesthetic link between a human operator and a computer-generated environment. This paper addresses the bidirectional coupling between a commercial off-the-shelf (COTS) haptic feedback device and a general-purpose modelling and simulation environment. In particular, an open-source library is developed to couple the Force Dimension omega.7 haptic device with the 20-sim modelling and simulation environment. The presented coupling interface is also compatible with all the different haptic devices produced by Force Dimension. The proposed integrated haptic interface makes it possible to track the user's motion, detect collisions between the user-controlled probe and virtual objects, compute reaction forces in response to motion or contacts and exert an intuitive force feedback on the user. A real-time one-to-one correspondence between reality and virtual reality can be transparently created. This allows for a variety of possible applications. Stability issues, performance issues, design and virtual prototyping challenges can be addressed and investigated for research purposes. In addition, design and virtual prototyping are also of interest to industry. Realistic training environments can be developed for the user considering different possible operations and stressing the importance of usability and user experience. Experiments based on using haptics technology in the field of education can also be easily performed. To demonstrate the potential of the proposed coupling, a case study is presented. Related simulations and experimental results are carried out.","","978-1-4799-1762-4","10.1109/IECON.2015.7392094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7392094","Haptics;Human-computer interaction;Simulation","Haptic interfaces;Solid modeling;Libraries;Couplings;Force;Computational modeling;Programming","force feedback;haptic interfaces;human computer interaction;motion estimation;public domain software;virtual reality","haptics technology;realistic training environments;virtual prototyping;virtual reality;real-time one-to-one correspondence;virtual objects;user-controlled probe;collision detection;user motion detection;integrated haptic interface;force dimension;coupling interface;haptic feedback devices;simulation environment;20-sim modelling;force dimension haptic devices;coupling library","","4","","13","","28 Jan 2016","","","IEEE","IEEE Conferences"
"Virtual Video Synthesis for Personalized Training","F. Markolefas; K. Moirogiorgou; G. Giakos; M. Zervakis","School of Electrical & Computer Engineering, Technical University of Crete, University Campus, Chania, Crete, 73100, Greece; School of Electrical & Computer Engineering, Technical University of Crete, University Campus, Chania, Crete, 73100, Greece; Department of Electrical and Computer Engineering, Manhattan College, Riverdale, NY; School of Electrical & Computer Engineering, Technical University of Crete, University Campus, Chania, Crete, 73100, Greece","2018 IEEE International Conference on Imaging Systems and Techniques (IST)","16 Dec 2018","2018","","","1","6","Online personal training allows users to work out from the comfort of their own homes using workout videos designed by fitness instructors. Users of such applications can use their device (PC, laptop, smart TV, etc.) camera and work out with others in a group setting, enabling plethora of intertwined benefits. In order to enhance training efficiency, it could be helpful for the trainee to superimpose his/her human silhouette, giving the opportunity to easily detect the differences of his/her exercise over the trainer's movements. One way to proceed towards this direction is to have a camera recording the video of the trainee during the exercise, which should be presented in contrast to the instructor's video on the device screen. In this work, we explore this direction and present traditional background estimation approaches in combination with foreground extraction techniques using videos recorded with static cameras. It is shown that none of the presented methods is able to efficiently face all possible challenges, like slow moving object (foreground) or presence of the moving object at the phase of background initialization, problems that mainly appear in in yoga exercise. As an alternative, we propose a series of techniques including an initial background reconstruction method followed by a selective updating scheme. In this way, the background image adaptively converges to the ground truth data enabled by the merging of information from detected moving regions (temporal processing) and color-based regions (spatial processing) of the video segment. Finally, we also apply the proposed method in space surveillance applications, using surveillance cameras, in order to evaluate the generality and efficiency of the proposed approach.","1558-2809","978-1-5386-6628-9","10.1109/IST.2018.8577097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8577097","video processing;silhouette extraction;image background reconstruction;motion tracking;fusion of temporal and spatial information","Image segmentation;Image color analysis;Image reconstruction;Object recognition;Cameras;Training;Estimation","cameras;computer based training;image colour analysis;image motion analysis;image reconstruction;image segmentation;object detection;video recording;video signal processing;video surveillance","foreground extraction techniques;static cameras;yoga exercise;background image;surveillance cameras;virtual video synthesis;online personal training;fitness instructors;plethora;human silhouette;device screen;color-based regions;camera recording;background reconstruction method;video segments;background estimation","","","","19","","16 Dec 2018","","","IEEE","IEEE Conferences"
"A Local Approach to Forward Model Learning: Results on the Game of Life Game","S. M. Lucas; A. Dockhorn; V. Volz; C. Bamford; R. D. Gaina; I. Bravi; D. Perez-Liebana; S. Mostaghim; R. Kruse","The School of Electrical Engineering and Computer Engineering, Queen Mary University of London, London, UK; The Computational Intelligence Research Group, Otto von Guericke University, Magdeburg, Germany; The School of Electrical Engineering and Computer Engineering, Queen Mary University of London, London, UK; The School of Electrical Engineering and Computer Engineering, Queen Mary University of London, London, UK; The School of Electrical Engineering and Computer Engineering, Queen Mary University of London, London, UK; The School of Electrical Engineering and Computer Engineering, Queen Mary University of London, London, UK; The School of Electrical Engineering and Computer Engineering, Queen Mary University of London, London, UK; The School of Electrical Engineering and Computer Engineering, Queen Mary University of London, London, UK; The School of Electrical Engineering and Computer Engineering, Queen Mary University of London, London, UK","2019 IEEE Conference on Games (CoG)","26 Sep 2019","2019","","","1","8","This paper investigates the effect of learning a forward model on the performance of a statistical forward planning agent. We transform Conway's Game of Life simulation into a single-player game where the objective can be either to preserve as much life as possible or to extinguish all life as quickly as possible. In order to learn the forward model of the game, we formulate the problem in a novel way that learns the local cell transition function by creating a set of supervised training data and predicting the next state of each cell in the grid based on its current state and immediate neighbours. Using this method we are able to harvest sufficient data to learn perfect forward models by observing only a few complete state transitions, using either a look-up table, a decision tree, or a neural network. In contrast, learning the complete state transition function is a much harder task and our initial efforts to do this using deep convolutional auto-encoders were less successful.We also investigate the effects of imperfect learned models on prediction errors and game-playing performance, and show that even models with significant errors can provide good performance.","2325-4289","978-1-7281-1884-0","10.1109/CIG.2019.8848002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848002","Forward Model Learning;General Game Playing/Learning;Neural Networks;Decision Tree;Rolling Horizon Evolutionary Algorithm","Games;Predictive models;Two dimensional displays;Trajectory;Planning;Neural networks;Training","computer games;computer simulation;decision trees;learning (artificial intelligence);neural nets;table lookup","statistical forward planning agent;single-player game;local cell transition function;supervised training data;state transition function;forward model learning;Game of Life simulation;look-up table;decision tree;neural network","","6","","23","","26 Sep 2019","","","IEEE","IEEE Conferences"
"War Chess as Hierarchical Learning Environment","S. Jiang; W. Wei; Y. Wu; R. Tang; Q. Feng; D. Ji","College of Information and Communication National University of Defense Technology,Wuhan,China; College of Information and Communication National University of Defense Technology,Wuhan,China; College of Information and Communication National University of Defense Technology,Wuhan,China; College of Information and Communication National University of Defense Technology,Wuhan,China; College of Information and Communication National University of Defense Technology,Wuhan,China; College of Information and Communication National University of Defense Technology,Wuhan,China","2020 13th International Symposium on Computational Intelligence and Design (ISCID)","20 Jan 2021","2020","","","368","371","This paper introduces GWCLE (General War Chess Learning Environment), a general machine learning environment based on hexagonal wargaming. Hexagonal war chess, when utilized as machine learning challenge, is naturally a multi-agent problem with the intelligent interaction of human or machine. The GWCLE supports hybrid engine, allowing credible simulation for kinds of war chess, which provides hierarchical training framework for massive agents control problem. The agent can be trained with designated level of war chess data and transferred bottom-up or top-down. For training on the whole deduction, we build the database to store refined replay data. Our framework is able to support agents to be trained in tactical and strategic level simultaneously. GWCLE offers a hierarchical perspective of the war chess simulation, allowing researchers controlling the granularity of action and time step.","2473-3547","978-1-7281-8446-3","10.1109/ISCID51228.2020.00089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9325790","machine learning;hierarchical;multi-agent;war chess","Engines;Training;Machine learning;Games;Databases;Machine learning algorithms;Artificial intelligence","computer games;learning (artificial intelligence);multi-agent systems","GWCLE;general machine learning environment;hexagonal wargaming;hexagonal war chess;multiagent problem;human machine;hierarchical training framework;war chess simulation;general war chess learning environment;hierarchical learning environment;intelligent interaction;massive agents control problem","","","","5","","20 Jan 2021","","","IEEE","IEEE Conferences"
"A computer-assisted training/monitoring system for TURP structure and design","M. P. S. F. Gomes; A. R. W. Barrett; A. G. Timoney; B. L. Davies","Dept. of Mech. Eng., Imperial Coll. of Sci., Technol. & Med., London, UK; NA; NA; NA","IEEE Transactions on Information Technology in Biomedicine","6 Aug 2002","1999","3","4","242","251","A generic framework for a computer-assisted system for both soft tissue endoscopic surgery and surgical training is being researched and developed. The concept demonstrator is a specific system for transurethral prostatic resection (TURF). The main novelty of the research is that it is not confined to an in vitro trainer system. An in vivo monitoring version of the system, for use in the operating theater, is also being researched. This paper presents the framework's structure and design using the Unified Modeling Language. It also discusses and justifies the underlying information technologies chosen to implement this approach. Object-oriented concepts and well-proven mathematical tools have been adopted as the foundation of this research and development. The rationale for having chosen such tools is presented. The objectives are to arrive at a system which is modular, general, and reusable.","1558-0032","","10.1109/4233.809168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=809168","","Computerized monitoring;Surgery;Imaging phantoms;In vitro;In vivo;Virtual reality;Humans;Biological tissues;Haptic interfaces;Feedback","surgery;patient monitoring;computer based training;biomedical education;object-oriented programming;medical computing","computer-assisted training system;computer-assisted monitoring system;TURP structure;TURP design;soft tissue endoscopic surgery;surgical training;concept demonstrator;transurethral prostatic resection;in vivo monitoring system;operating theater;in vitro trainer system;Unified Modeling Language;object-oriented concepts;mathematical tools;research and development","Computer Simulation;Humans;Male;Therapy, Computer-Assisted;Transurethral Resection of Prostate","19","","10","","6 Aug 2002","","","IEEE","IEEE Journals"
"Transitioning to the next generation (nextgen) defense training environment (DTE)","W. Bizub; J. Brandt","Joint Advanced Concepts, Joint and Coalition Warfighting, 116 Lake View Parkway, Suffolk, VA 23435, USA; General Dynamics Information Technology, 112 Lake View Parkway, Suffolk, VA 23435, USA","Proceedings of the 2011 Winter Simulation Conference (WSC)","9 Feb 2012","2011","","","2559","2570","Department of Defense (DoD) closed architectures and proprietary solutions limit the ability to provide the warfighter gaming, semantic reasoning and social networking capabilities employed by industry and readily available in the open source community. Exorbitant sustainment costs of legacy solutions are unjustifiable and significantly inhibit transition to enhanced solutions. Additionally, legacy solutions leave a dependence on an aging workforce of static-centric modeling & simulation (M&S) subject matter expertise (SME) to promote reuse, while budget cuts increase attrition among junior-level technical staff. This paper describes challenges and recommendations for changing the DoD M&S training paradigm to facilitate interoperability, incorporate emerging semantic web technologies, and provide a knowledge base to promote reuse. Two ongoing R&D projects will be used to illustrate innovative strategies and their potential to alleviate many legacy system interoperability issues while transitioning to a Defense Training Environment (DTE) where US and Coalition Command and Control (C2) and M&S systems seamlessly interoperate to train as we fight.","1558-4305","978-1-4577-2109-0","10.1109/WSC.2011.6147964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6147964","","Ontologies;Semantic Web;Communities;US Department of Defense;Training;Semantics;Cancer","cloud computing;command and control systems;computer based training;inference mechanisms;knowledge based systems;ontologies (artificial intelligence);open systems;public domain software;semantic Web","next generation defense training environment;Department of Defense;warfighter gaming;semantic reasoning;social networking capability;open source community;legacy solution sustainment cost;subject matter expertise;interoperability;semantic Web technology;knowledge base;research and development;command and control system;modeling and simulation system","","1","","15","","9 Feb 2012","","","IEEE","IEEE Conferences"
"Skill assessment based on automatic classification of forceps manipulations","Y. Kurita; Y. Hayama; T. Ogasawara; T. Kawahara; M. Okajima; H. Egi; H. Ohdan","Faculty of Engineering, Hiroshima University, Higashi-Hiroshima, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan; Frontier Research Academy, Kyushu Institute of Technology, Kita-Kyushu, Fukuoka, Japan; Hiroshima City Asa Hospital, Asa-Kita, Japan; Graduate School of Biomedical Sciences, Hiroshima University, Kasumi, Japan; Graduate School of Biomedical Sciences, Hiroshima University, Kasumi, Japan","2012 ICME International Conference on Complex Medical Engineering (CME)","23 Aug 2012","2012","","","56","59","Haptic information is crucial in the execution of precise and dexterous manipulations. During minimally invasive surgery, medical doctors are required to indirectly sense force-related information from body organ tissue via forceps because they cannot directly touch the tissue. The evaluation of force-based skill is critical in the judgment of whether a person has adequate manipulation skills to conduct surgery procedures. Currently, simulation training in minimally invasive surgery is a required component of general surgery residency training. This paper addresses the challenge of skill evaluation during laparoscopic surgery by measuring the force applied to forceps.","","978-1-4673-1618-7","10.1109/ICCME.2012.6275610","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6275610","Laparoscopy;Skill assessment;Forceps;Manipulation log","Force;Training;Atmospheric measurements;Particle measurements;Force measurement","biomechanics;force feedback;haptic interfaces;medical computing;muscle;surgery;training","skill assessment;automatic classification;forcep manipulations;haptic information;minimally invasive surgery;force related information;body organ tissue;simulation training;general surgery residency;laparoscopic surgery","","3","","8","","23 Aug 2012","","","IEEE","IEEE Conferences"
"Architectural design of ARTeMIS: A multi-tasking robot for people with disabilities","K. Mykoniatis; A. Angelopoulou; J. P. Kincaid","Institute for Simulation and Training, University of Central Florida, Orlando, USA; Institute for Simulation and Training, University of Central Florida, Orlando, USA; Institute for Simulation and Training, University of Central Florida, Orlando, USA","2013 IEEE International Systems Conference (SysCon)","1 Jul 2013","2013","","","269","273","Human-Robot Interaction (HRI) is a research field dedicated to understanding, designing, evaluating and improving the communication between a human and a robot. Technological progress in fields, such as artificial intelligence, computer science, speech simulation, image processing, and remote controls, has led to advances in robotic technology [1]. Interaction between human and robot can be separated into two general categories: remote, where the human and the robot are separated in space or time, and proximate, where the human and the robot may be found in the same location [2]. These two general categories can be further distinguished between applications that require mobility, physical manipulation, or social interaction. Social interactions with robots are more proximate rather than remote. The purpose of this paper is to design the architecture of a robotic system and understand how it might assist people with disabilities and help them stay independent longer. Future work includes verification and validation of the architecture and robotic construction. An experimentation plan will take place in order to evaluate the behavior and performance of the robotic system. The results will be used for the robotic construction.","","978-1-4673-3108-1","10.1109/SysCon.2013.6549893","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549893","Kinect;face recognition;human robot interaction;object recognition;facial expression;obstacle avoidance;gestures;disabilities","Navigation;Robot sensing systems;Robot kinematics;Face recognition;Unified modeling language;Face","architecture;handicapped aids;human-robot interaction;medical robotics","ARTeMIS;multitasking robot;people with disabilities;human-robot interaction;HRI;artificial intelligence;computer science;speech simulation;image processing;remote controls;robotic technology;mobility;physical manipulation;social interactions;robotic system architectural design;robotic construction","","2","","17","","1 Jul 2013","","","IEEE","IEEE Conferences"
"Evolution-based virtual training in extracting fuzzy knowledge for deburring tasks","S. -. Su; T. -. Horng; K. -. Young","Dept. of Electr. Eng., Nat. Taiwan Univ. of Sci. & Technol., Taiwan; NA; NA","Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065)","6 Aug 2002","2000","4","","3855","3860 vol.4","In this research, the problems of how to teach a robot to execute skilled operations are studied. Human workers usually accumulate his experience after executing the same task repetitively. In the process of training, the worker must find ways of adjusting his/her execution. In our system, the parameters for the impedance control scheme are used as the targets for adjustment. After mass amount of training, the worker is supposed to be able to execute deburring tasks successfully. This is because the worker might have gotten some knowledge about tuning the parameters required in the impedance control scheme. Thus, the rules for adjusting the parameters in impedance control are the operational skills to be identified. In this research, a training scheme, called the evolution-based virtual training scheme, is proposed in extracting knowledge for robotic deburring tasks. In this approach, an evolution strategy is employed for searching for the best set of fuzzy rules. This learning scheme has been successfully applied in adjusting the parameters of impedance controllers required in deburring operations. In general, the results of deburring are much more satisfactory when compared with those in previous research. When executing a deburring task, the robot simulator can find its optimal adjusting rules for parameters after several generations of evolution.","1050-4729","0-7803-5886-4","10.1109/ROBOT.2000.845332","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=845332","","Deburring;Fuzzy control;Impedance;Data mining;Robot control;Decision making;Training data;Costs","industrial robots;robot programming;virtual reality;force control;knowledge acquisition;fuzzy logic;evolutionary computation","evolution-based virtual training;fuzzy knowledge extraction;deburring tasks;skilled operations;impedance control scheme;fuzzy rules;robot simulator","","","","22","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Attention Based Natural Language Grounding by Navigating Virtual Environment","A. Sinha; B. Akilesh; M. Sarkar; B. Krishnamurthy","Adobe Syst., Noida, India; Mila, Universite de Montreal; Adobe Syst., Noida, India; Adobe Syst., Noida, India","2019 IEEE Winter Conference on Applications of Computer Vision (WACV)","7 Mar 2019","2019","","","236","244","In this work, we focus on the problem of grounding language by training an agent to follow a set of natural language instructions and navigate to a target object in an environment. The agent receives visual information through raw pixels and a natural language instruction telling what task needs to be achieved and is trained in an end-to-end way. We develop an attention mechanism for multi-modal fusion of visual and textual modalities that allows the agent to learn to complete the task and achieve language grounding. Our experimental results show that our attention mechanism outperforms the existing multi-modal fusion mechanisms proposed for both 2D and 3D environments in order to solve the above-mentioned task in terms of both speed and accuracy. We show that the learnt textual representations are semantically meaningful as they follow vector arithmetic in the embedding space. The effectiveness of our attention approach over the contemporary fusion mechanisms is also highlighted from the textual embeddings learnt by the different approaches. We also show that our model generalizes effectively to unseen scenarios and exhibit zero-shot generalization capabilities both in 2D and 3D environments. The code for our 2D environment as well as the models that we developed for both 2D and 3D are available at https://github.com/rl-lang-grounding/rl-lang-ground.","1550-5790","978-1-7281-1975-5","10.1109/WACV.2019.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658389","","Two dimensional displays;Visualization;Three-dimensional displays;Task analysis;Natural languages;Navigation;Grounding","learning (artificial intelligence);natural language processing;virtual reality","natural language grounding;grounding language;natural language instruction;target object;visual information;attention mechanism;visual modalities;textual modalities;attention approach;contemporary fusion mechanisms;virtual environment;textual embeddings;textual representations;vector arithmetic;zero-shot generalization capabilities;3D environments;2D environments","","2","","21","","7 Mar 2019","","","IEEE","IEEE Conferences"
"Helping Robots Learn: A Human-Robot Master-Apprentice Model Using Demonstrations via Virtual Reality Teleoperation","J. DelPreto; J. I. Lipton; L. Sanneman; A. J. Fay; C. Fourie; C. Choi; D. Rus","MIT Distributed Robotics Lab,Cambridge,MA,02139; MIT Distributed Robotics Lab,Cambridge,MA,02139; MIT Interactive Robotics Group,Cambridge,MA,02139; MIT Distributed Robotics Lab,Cambridge,MA,02139; MIT Interactive Robotics Group,Cambridge,MA,02139; MIT Distributed Robotics Lab,Cambridge,MA,02139; MIT Distributed Robotics Lab,Cambridge,MA,02139","2020 IEEE International Conference on Robotics and Automation (ICRA)","15 Sep 2020","2020","","","10226","10233","As artificial intelligence becomes an increasingly prevalent method of enhancing robotic capabilities, it is important to consider effective ways to train these learning pipelines and to leverage human expertise. Working towards these goals, a master-apprentice model is presented and is evaluated during a grasping task for effectiveness and human perception. The apprenticeship model augments self-supervised learning with learning by demonstration, efficiently using the human's time and expertise while facilitating future scalability to supervision of multiple robots; the human provides demonstrations via virtual reality when the robot cannot complete the task autonomously. Experimental results indicate that the robot learns a grasping task with the apprenticeship model faster than with a solely self-supervised approach and with fewer human interventions than a solely demonstration-based approach; 100% grasping success is obtained after 150 grasps with 19 demonstrations. Preliminary user studies evaluating workload, usability, and effectiveness of the system yield promising results for system scalability and deployability. They also suggest a tendency for users to overestimate the robot's skill and to generalize its capabilities, especially as learning improves.","2577-087X","978-1-7281-7395-5","10.1109/ICRA40945.2020.9196754","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9196754","","Robots;Grasping;Task analysis;Three-dimensional displays;Solid modeling;Virtual reality;Pipelines","control engineering computing;human-robot interaction;learning (artificial intelligence);multi-robot systems;robot programming;telerobotics;virtual reality","grasping task;human perception;human-robot master-apprentice model;virtual reality teleoperation;artificial intelligence;self-supervised learning","","1","","50","","15 Sep 2020","","","IEEE","IEEE Conferences"
"Improving Generalisation in Learning Assistance by Demonstration for Smart Wheelchairs","V. Schettino; Y. Demiris","Imperial College London,Personal Robotics Laboratory,United Kingdom; Imperial College London,Personal Robotics Laboratory,United Kingdom","2020 IEEE International Conference on Robotics and Automation (ICRA)","15 Sep 2020","2020","","","5474","5480","Learning Assistance by Demonstration (LAD) is concerned with using demonstrations of a human agent to teach a robot how to assist another human. The concept has previously been used with smart wheelchairs to provide customised assistance to individuals with driving difficulties. A basic premise of this technique is that the learned assistive policy should be able to generalise to environments different than the ones used for training; but this has not been tested before. In this work we evaluate the assistive power and the generalisation capability of LAD using our custom teleoperation and learning system for smart wheelchairs, while seeking to improve it by experimenting with different combinations of dimensionality reduction techniques and machine learning models. Using Autoencoders to reduce the dimension of laserscan data and a Gaussian Process as the learning model, we achieved a 23% improvement in prediction performance against the combination used by the latest work on the field. Using this model to assist a driver exposed to a simulated disability, we observed a 9.8% reduction in track completion times when compared to driving without assistance.","2577-087X","978-1-7281-7395-5","10.1109/ICRA40945.2020.9197490","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197490","","Wheelchairs;Training;Robots;Vehicles;Haptic interfaces;Sensors;Navigation","Gaussian processes;generalisation (artificial intelligence);handicapped aids;human-robot interaction;learning (artificial intelligence);neural nets;wheelchairs","Gaussian process;learning assistance by demonstration;human agent;machine learning models;dimensionality reduction techniques;learning system;custom teleoperation;LAD;generalisation capability;assistive power;learned assistive policy;customised assistance;smart wheelchairs","","","","30","","15 Sep 2020","","","IEEE","IEEE Conferences"
"Virtual-reality-based multidimensional therapy for the treatment of body image disturbances in binge eating disorders: a preliminary controlled study","G. Riva; M. Bacchetta; M. Baruffi; E. Molinari","Appl. Technol. for Neuro-Psychol. Lab., Ist. Auxologico Italiano, Verbania, Italy; NA; NA; NA","IEEE Transactions on Information Technology in Biomedicine","7 Nov 2002","2002","6","3","224","234","The main goal of this paper is to preliminarily evaluate the efficacy of a virtual-reality (VR)-based multidimensional approach in the treatment of body image attitudes and related constructs. The female binge eating disorder (BED) patients (n=20), involved in a residential weight control treatment including low-calorie diet (1200 cal/day) and physical training, were randomly assigned either to the multidimensional VR treatment or to psychonutritional groups based on the cognitive-behavior approach. Patients were administered a battery of outcome measures assessing eating disorders symptomathology, attitudes toward food, body dissatisfaction, level of anxiety, motivation for change, level of assertiveness, and general psychiatric symptoms. In the short term, the VR treatment was more effective than the traditional cognitive-behavioral psychonutritional groups in improving the overall psychological state of the patients. In particular, the therapy was more effective in improving body satisfaction, self-efficacy, and motivation for change. No significant differences were found in the reduction of the binge eating behavior. The possibility of inducing a significant change in body image and its associated behaviors using a VR-based short-term therapy can be useful to improve the body satisfaction in traditional weight reduction programs. However, given the nature of this research that does not include a followup study, the obtained results are preliminary only.","1558-0032","","10.1109/TITB.2002.802372","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1033951","","Multidimensional systems;Medical treatment;Psychology;Virtual reality;Laboratories;Heart;Attitude control;Weight control;Battery charge measurement;Books","virtual reality;psychology;medical computing;patient treatment;user interfaces","virtual reality;multidimensional therapy;body image disturbances;binge eating disorders;obesity;patient therapy;residential weight control treatment;psychonutritional groups;cognitive-behavior approach;anxiety;psychiatric symptoms","Adolescent;Adult;Body Image;Bulimia;Bulimia;Chronic Disease;Cognitive Therapy;Computer Graphics;Computer Simulation;Female;Humans;Reproducibility of Results;Sensitivity and Specificity;Severity of Illness Index;Therapy, Computer-Assisted;Treatment Outcome;User-Computer Interface","44","","68","","7 Nov 2002","","","IEEE","IEEE Journals"
"A hybrid neural network and virtual reality system for spatial language processing","G. C. Martinez; A. Cangelosi; K. R. Coventry","Sch. of Comput., Plymouth Univ., UK; NA; NA","IJCNN'01. International Joint Conference on Neural Networks. Proceedings (Cat. No.01CH37222)","7 Aug 2002","2001","1","","16","21 vol.1","Describes a neural network model for the study of spatial language. It deals with both geometric and functional variables, which have been shown to play an important role in the comprehension of spatial prepositions. The network is integrated with a virtual reality interface for the direct manipulation of geometric and functional factors. The training uses experimental stimuli and data. Results show that the networks reach low training and generalization errors. Cluster analyses of hidden activation show that stimuli primarily group according to extra-geometrical variables.","1098-7576","0-7803-7044-9","10.1109/IJCNN.2001.938984","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=938984","","Neural networks;Virtual reality;Psychology;Cognition;Natural languages;Geometry;Computer networks;Error analysis;Testing;Virtual prototyping","virtual reality;psychology;learning (artificial intelligence);generalisation (artificial intelligence);multilayer perceptrons;natural language interfaces","hybrid neural network;virtual reality system;spatial language processing;functional variables;geometric variables;spatial prepositions;experimental stimuli;cluster analyses;hidden activation","","1","","14","","7 Aug 2002","","","IEEE","IEEE Conferences"
"Software Solution for Visualization and Evaluation of Flight Data in Terms of Competency-Based Training","T. Malich; V. Socha; R. Matyáš; L. Hanáková; S. Kušmírek; V. Kráčmar","Czech Technical University in Prague,Department of Air Transport,Prague,Czech Republic; Czech Technical University in Prague,Department of Air Transport,Prague,Czech Republic; Czech Technical University in Prague,Department of Air Transport,Prague,Czech Republic; Czech Technical University in Prague,Department of Air Transport,Prague,Czech Republic; Czech Technical University in Prague,Department of Air Transport,Prague,Czech Republic; Czech Technical University in Prague,Department of Air Transport,Prague,Czech Republic","2020 AIAA/IEEE 39th Digital Avionics Systems Conference (DASC)","18 Nov 2020","2020","","","1","7","In this paper, we present a complex solution for flight data gathering, analyzation, and visualization. This solution can be used for the Competency-Based Training of pilots in general aviation. For the data gathering, we are introducing a concept of an embedded device. For data analyzation, we are introducing the approach for algorithmic detection of flight maneuvers based on the recorded flight data. There is a multiplatform software application for data visualization. We are also describing the reasons for creating such solutions and potential future uses of our hardware and software products. This paper is mostly describing the important requirements and their implementation regarding the future usage for Competency-Based Training of pilots in general aviation. We are not describing a lot of technical details to keep this paper straightforward and we are mostly focusing on passing the whole idea and benefits of our products.","2155-7209","978-1-7281-9825-5","10.1109/DASC50938.2020.9256590","Czech Technical University in Prague; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9256590","CBT;Competency-Based Training;flight;data;visualization;gathering;analyzation","Training;Data visualization;Software;Receivers;Hardware;Global Positioning System;Data analysis","aerospace computing;aerospace simulation;aerospace testing;computer based training;data acquisition;data visualisation;embedded systems","general aviation;software solution;complex solution;flight data gathering;data analyzation;flight maneuvers;recorded flight data;multiplatform software application;data visualization;software products;competency-based training","","","","11","","18 Nov 2020","","","IEEE","IEEE Conferences"
"A Serious Game Engine for Interview Simulation: Application to the Development of Doctor-Patient Communication Skills","J. Guo; N. Singer; R. Bastide","IRIT, Univ. de Toulouse, Castres, France; IRIT, Univ. de Toulouse, Castres, France; IRIT, Univ. de Toulouse, Castres, France","2014 6th International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES)","19 Jan 2015","2014","","","1","6","In this paper we present the architecture of a conversation engine aimed to simulate an interview process between a human and a computer player. This component is a central element of many serious games where educational goal is to develop player communication skills. We demonstrate the use of our engine in AgileDoctor, a serious game project for training medical students and general practitioners to communicate with their patients, so as to improve their long-term relationship and provide a higher quality health care. Our proposed conversation engine uses a generic method to combine the game scenario and the educational objectives. The game scenario is described by an instance of a model that formalizes the general doctor-patient interview process and the skills to develop. The conversation engine is able to use this model to engage a challenging dialogue with a human player where missing skills are focused. The proposed design methodology is not bound to the health domain and is transferable to a large range of educational usages.","","978-1-4799-4056-1","10.1109/VS-Games.2014.7012026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7012026","","Games;Medical services;Engines;Interviews;Training;Vectors;Design methodology","biomedical education;computer based training;health care;professional communication;serious games (computing)","serious game engine;interview simulation;doctor-patient communication skills development;conversation engine architecture;central element;educational goal;player communication skills development;AgileDoctor engine;medical student training;general practitioner training;long-term relationship improvement;health care;generic method;game scenario;educational objectives;general doctor-patient interview process simulation;human player;computer player;design methodology;health domain;educational usages","","","","16","","19 Jan 2015","","","IEEE","IEEE Conferences"
"A Stable and Real-Time Nonlinear Elastic Approach to Simulating Guidewire and Catheter Insertions Based on Cosserat Rod","W. Tang; T. R. Wan; D. A. Gould; T. How; N. W. John","School of Computing, the University of Teesside, Middlesbrough, U.K.; Bradford University, Bradford, U.K.; Royal Liverpool University Hospital, Liverpool, U.K.; Liverpool University, Liverpool, U.K.; Bangor University , Bangor, U.K.","IEEE Transactions on Biomedical Engineering","12 Jul 2012","2012","59","8","2211","2218","Interventional Radiology procedures (e.g., angioplasty, embolization, stent graft placement) provide minimally invasive therapy to treat a wide range of conditions. These procedures involve the use of flexible tipped guidewires to advance diagnostic or therapeutic catheters into a patient's vascular or visceral anatomy. This paper presents a real-time physically based hybrid modeling approach to simulating guidewire insertions. The long, slender body of the guidewire shaft is simulated using nonlinear elastic Cosserat rods, and the shorter flexible tip composed of a straight, curved, or angled design is modeled using a more efficient generalized bending model. Therefore, the proposed approach efficiently computes intrinsic dynamic behaviors of guidewire interactions within vascular structures. The efficacy of the proposed method is demonstrated using detailed numerical simulations inside 3-D blood vessel structures derived from preprocedural volumetric data. A validation study compares positions of four physical guidewires deployed within a vascular phantom, with the co-ordinates of the corresponding simulated guidewires within a virtual model of the phantom. An optimization algorithm is also implemented to further improve the accuracy of the simulation. The presented simulation model is suitable for interactive virtual reality-based training and for treatment planning.","1558-2531","","10.1109/TBME.2012.2199319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6200309","Cosserat theory of elastic rod;guidewire insertion;minimally invasive interventions;physically based simulation","Computational modeling;Solid modeling;Materials;Friction;Shafts;Accuracy;Real time systems","catheters;phantoms;radiology;surgery;virtual reality","stable nonlinear elastic approach;real time nonlinear elastic approach;guidewire simulation;catheter insertion simulation;Cosserat rod;interventional radiology;angioplasty;embolization;stent graft placement;minimally invasive therapy;vascular anatomy;visceral anatomy;vascular phantom;interactive virtual reality based training;treatment planning","Algorithms;Aorta, Abdominal;Aortic Aneurysm, Abdominal;Catheterization;Catheterization;Computer Simulation;Humans;Image Processing, Computer-Assisted;Models, Cardiovascular;Nonlinear Dynamics;Phantoms, Imaging;Reproducibility of Results","51","","26","","15 May 2012","","","IEEE","IEEE Journals"
"Development of training games of physical posture for people with developmental disorders","S. Sato; O. Morikawa; K. Kanamori; M. Umeda; H. Ota; M. Nara; E. Nakazawa; T. Hakomori; Y. Ono","National Institute of Advanced Industrial Science and Technology, 1-1-1, Higashi, Tsukuba, Ibaraki, 305-8566 Japan; National Institute of Advanced Industrial Science and Technology, 1-1-1, Higashi, Tsukuba, Ibaraki, 305-8566 Japan; National Institute of Special Needs Education, 5-1-1, Nobi, Yokosuka, Kanagawa, 239-8585 Japan; National Institute of Special Needs Education, 5-1-1, Nobi, Yokosuka, Kanagawa, 239-8585 Japan; Shiga Prefectural Mikumo School for the Physically and Mentally Impaired, 1546, Kojibukuro, Konan, Shiga, 520-3233 Japan; psychotherapist, Japan; physical therapist, Japan; University of Tsukuba Education Bureau of Laboratory Schools, Otsuka, 3-29-1, Bunkyo-ku, Tokyo, 112-0012, Japan; NAMCO BANDAI Games Inc., 4-5-15, Higashi-Shinagawa, Shinagawa-ku, Tokyo, 140-8590, Japan","2011 IEEE/SICE International Symposium on System Integration (SII)","9 Feb 2012","2011","","","533","536","This paper describes two prototypes of training games of physical posture adaptive for people with developmental disorders. Two types of games are developed and their prototypes are produced. One is a game for exercise user's body posture control. The other is a simulator of holding some object horizontally. Though it is said that ASD people generally have resistance against new, inexperienced items, all of the ASD subjects are interested in the games without refusal. This fact is considered to be an effective utilization of attraction and diffusing potential that games have.","","978-1-4577-1524-2","10.1109/SII.2011.6147505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6147505","","Games;Variable speed drives;Prototypes;Educational institutions;Ice;Autism","biomechanics;computer games;medical computing;training","training games;physical posture;developmental disorders;body posture control","","1","","11","","9 Feb 2012","","","IEEE","IEEE Conferences"
"Approaches to Simulation of Mouse Behaviour in the Morris Water Maze","R. J. Cant; C. S. Langensiepen; S. Saev; D. Ward-Williams; A. Michaelides","Sch. of Sci. & Technol., Nottingham Trent Univ., Nottingham, UK; Sch. of Sci. & Technol., Nottingham Trent Univ., Nottingham, UK; Sch. of Sci. & Technol., Nottingham Trent Univ., Nottingham, UK; Sch. of Sci. & Technol., Nottingham Trent Univ., Nottingham, UK; Sch. of Sci. & Technol., Nottingham Trent Univ., Nottingham, UK","2013 8th EUROSIM Congress on Modelling and Simulation","12 Jan 2015","2013","","","73","77","As computer games have become more complex emphasis has shifted from graphics to the use of artificial intelligence to make the behaviour of non-player characters (NPCs) richer and more believable. In order to do this successfully it is necessary to understand what realistic behaviour actually is. In the world of neurological science, the Morris Water maze is frequently used as a way of testing whether mouse or rat behaviour is affected by brain lesions, drugs etc. It provides a very clean and simple environment for assessing the search patterns undertaken by a mouse swimming to find a hidden platform. Our aim is to find a simple approach to providing a realistic approximation to real mouse behaviour, in order to gain insight into general creature behaviour. A solution that combines basic behaviour with A searching showed similar behaviour to mice during training, but tended to be fragile. A genetic algorithm approach based on criteria used for assessing real mouse behaviour fails to converge to anything realistic. We have found that an ant colony model can be made to work reasonably well in replicating the real mouse training, but lacks the wider search behaviour employed by real mice when the platform is absent.","","978-0-7695-5073-2","10.1109/EUROSIM.2013.23","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004921","Computer Games;Ant Colony;Morris Water Maze;Animal Simulation","","ant colony optimisation;computer games;genetic algorithms;learning (artificial intelligence)","mouse behaviour simulation;Morris Water maze;computer games;nonplayer character behavior;NPC behavior;artificial intelligence;genetic algorithm;ant colony model","","","","19","","12 Jan 2015","","","IEEE","IEEE Conferences"
"Lock picking simulation using visual and bimanual haptic display","K. Arthur; A. J. Doxon; C. Parsons; W. R. Provancher","Haptics and Embedded Mechatronics Lab, University of Utah, USA; Haptics and Embedded Mechatronics Lab, University of Utah, USA; Haptics and Embedded Mechatronics Lab, University of Utah, USA; Haptics and Embedded Mechatronics Lab, University of Utah, USA","2012 IEEE Haptics Symposium (HAPTICS)","16 Apr 2012","2012","","","547","551","As locks become more and more complex and numerous, locksmiths have less opportunity to practice on and find design flaws with each type of lock. As in other fields, such as dentistry, haptic simulations can provide an alternative form of practice. Lock picking is inherently suited to haptic simulation, as feedback during lock picking is limited to the sense of touch, and the inner workings of locks are intentionally hidden to prevent easy inspection. The technique used to bypass a simple pin-tumbler lock relies on haptic feedback experienced through both hands, with one hand managing a tension wrench and the other hand manipulating a pick. A visual-haptic simulation of pin-tumbler locks that mimics the sensations of lock picking was developed and tested. Experimental results show that haptic training with our simulation enables participants to more quickly pick their first tumbler lock and provides better preparation to pick more difficult locks. Our visual-haptic simulation could be used to provide practice on increasingly difficult locks, and if generalized, could be used to model any number of complex locks on the market, enabling locksmiths and lock-designers to test the security of various locks, or to train apprentices.","2324-7355","978-1-4673-0809-0","10.1109/HAPTIC.2012.6183845","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6183845","Haptic;visual;virtual;bimanual;multi-display;simulation;lock;key;wrench;pick;feedback;locksmith;design;touch","Presses;Indexes;Training;Haptic interfaces","computer based training;design engineering;force feedback;haptic interfaces;inspection;keys (locking);touch (physiological)","lock picking simulation;visual display;bimanual haptic display;design flaws;locksmiths;touch sense;easy inspection prevention;pin-tumbler lock;haptic feedback;tension wrench;visual-haptic simulation;lock picking sensation;haptic training;tumbler lock;lock designer","","","","10","","16 Apr 2012","","","IEEE","IEEE Conferences"
"Decoding Subjective Emotional Arousal during a Naturalistic VR Experience from EEG Using LSTMs","S. M. Hofmann; F. Klotzsche; A. Mariola; V. V. Nikulin; A. Villringer; M. Gaebler","Amsterdam Brain & Cognition, Univ. of Amsterdam, Amsterdam, Netherlands; Berlin Sch. of Mind & Brain, Humboldt Univ. zu Berlin, Berlin, Germany; Sussex Neurosci., Univ. of Sussex, Brighton, UK; Neurology, MPI Hum. Cog. & Brain Sci., Leipzig, Germany; Neurology, MPI Hum. Cog. & Brain Sci., Leipzig, Germany; Neurology, MPI Hum. Cog. & Brain Sci., Leipzig, Germany","2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","17 Jan 2019","2018","","","128","131","Emotional arousal (EA) denotes a heightened state of activation that has both subjective and physiological aspects. The neurophysiology of subjective EA, among other mind-brain-body phenomena, can best be tested when subjects are stimulated in a natural fashion. Immersive virtual reality (VR) enables naturalistic experimental stimulation and thus promises to increase the ecological validity of research findings i.e., how well they generalize to real-life settings. In this study, 45 participants experienced virtual rollercoaster rides while their brain activity was recorded using electroencephalography (EEG). A Long Short-Term Memory (LSTM) recurrent neural network (RNN) was then trained on the alpha-frequency (8-12 Hz) component of the EEG signal (input) and the retrospectively acquired continuous reports of subjective EA (target). With the LSTM-based model, subjective EA could be predicted significantly above chance level. This demonstrates a novel EEG-based decoding approach for subjective states of experience in naturalistic research designs using VR.","","978-1-5386-9269-1","10.1109/AIVR.2018.00026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613645","subjective experience;neural decoding;emotional arousal;continuous time series;naturalistic research designs","Brain modeling;Electroencephalography;Feature extraction;Decoding;Biological system modeling;Predictive models;Time series analysis","electroencephalography;medical signal processing;neurophysiology;recurrent neural nets;virtual reality","naturalistic VR experience;subjective aspects;physiological aspects;LSTM;neurophysiology;electroencephalography;alpha-frequency component;EEG signal;EEG-based decoding approach;subjective emotional arousal;naturalistic research designs;Long Short-Term Memory recurrent neural network;brain activity;virtual rollercoaster rides;ecological validity;naturalistic experimental stimulation;immersive virtual reality;natural fashion;mind-brain-body phenomena;subjective EA;frequency 8.0 Hz to 12.0 Hz","","","","28","","17 Jan 2019","","","IEEE","IEEE Conferences"
"Education and Training for Troubleshooting in Automotive Chassis","J. S. Liang","Yung-Ta Institute of Technology and Commerce, Taiwan","Fourth International Conference on Information Technology (ITNG'07)","16 Apr 2007","2007","","","311","316","There are several subjects discussed in this research: (1) developing the learning contents for repairing automotive chassis; (2) building the virtual and interactive platform for browsing and practice of troubleshooting; (3) creating the online evaluation tools and effectiveness analysis. Meanwhile, the framework has been tested and implemented in the course, ""Automotive Practice: Chassis,"" in the spring semester of 2004. The platform developed is not dependent on specific automobile style and software configuration and it uses open software (e.g. Java, VRML, PHP, MySQL, etc.) in the virtual display and data storage. The system can achieve the advantages and goals of (1) constructing a Web-based troubleshooting architecture of automotive chassis that can enhance learners' knowledge and promote practical technologies; (2) providing references for drivers in self-detection of general chassis problems to raise driving safety; (3) creating a prototype environment for distance learning to eliminate the limitation of space and time on learning; (4) raising the learning effectiveness and motivation of on-site and distant learners","","0-7695-2776-0","10.1109/ITNG.2007.81","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4151702","","Automotive engineering;Space technology;Testing;Automobiles;Java;Displays;Memory;Computer architecture;Safety;Prototypes","automotive engineering;computer based training;distance learning;Internet;public domain software;virtual reality languages","automotive chassis troubleshooting;Virtual Reality Modelling Language;online evaluation tools;open software;Web-based troubleshooting architecture;distance learning","","","","14","","16 Apr 2007","","","IEEE","IEEE Conferences"
"A Steering Algorithm for Redirected Walking Using Reinforcement Learning","R. R. Strauss; R. Ramanujan; A. Becker; T. C. Peck",Davidson College; Davidson College; Davidson College; Davidson College,"IEEE Transactions on Visualization and Computer Graphics","31 Mar 2020","2020","26","5","1955","1963","Redirected Walking (RDW) steering algorithms have traditionally relied on human-engineered logic. However, recent advances in reinforcement learning (RL) have produced systems that surpass human performance on a variety of control tasks. This paper investigates the potential of using RL to develop a novel reactive steering algorithm for RDW. Our approach uses RL to train a deep neural network that directly prescribes the rotation, translation, and curvature gains to transform a virtual environment given a user's position and orientation in the tracked space. We compare our learned algorithm to steer-to-center using simulated and real paths. We found that our algorithm outperforms steer-to-center on simulated paths, and found no significant difference on distance traveled on real paths. We demonstrate that when modeled as a continuous control problem, RDW is a suitable domain for RL, and moving forward, our general framework provides a promising path towards an optimal RDW steering algorithm.","1941-0506","","10.1109/TVCG.2020.2973060","Davidson Research Initiative; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8998570","Virtual Reality;Locomotion;Redirected Walking;Steering Algorithms;Reinforcement Learning","Legged locomotion;Learning (artificial intelligence);Prediction algorithms;Meters;Tracking;Heuristic algorithms;Space exploration","learning (artificial intelligence);neural nets;virtual reality","RL;reactive steering algorithm;deep neural network;learned algorithm;steer-to-center;simulated paths;optimal RDW steering algorithm;reinforcement learning;human-engineered logic;human performance;control tasks;redirected walking steering algorithms","Algorithms;Computer Graphics;Deep Learning;Humans;Video Games;Virtual Reality;Walking","","","58","","13 Feb 2020","","","IEEE","IEEE Journals"
"Doctoral Colloquium—Enhancing Brain Plasticity and Cognition Utilizing Immersive Technology and Virtual Reality Contexts for Gameplay","C. M. Eng; D. M. Calkosz; S. Y. Yang; N. C. Williams; E. D. Thiessen; A. V. Fisher","Carnegie Mellon University,Psychology,Pittsburgh,USA; Carnegie Mellon University,Computer Science,Pittsburgh,USA; Carnegie Mellon University,Information Systems,Pittsburgh,USA; Carnegie Mellon University,Logic and Computation,Pittsburgh,USA; Carnegie Mellon University,Psychology,Pittsburgh,USA; Carnegie Mellon University,Psychology,Pittsburgh,USA","2020 6th International Conference of the Immersive Learning Research Network (iLRN)","4 Aug 2020","2020","","","395","398","This work-in-progress paper examines the effects of immersive virtual experiences on cognition and neuroplasticity. Study 1 examined the separate and combined effects of physically active and cognitively demanding immersive gameplay on executive function and associated neural substrates. Results indicated that cognition and neuroplasticity-the building of new brain connections-increase when learning novel skills via active gameplay. Study 2 devised an experimental design to reproduce Study 1 in virtual reality to examine whether the findings of enhanced cognition and neuroplasticity generalize across virtual contexts and development. Incorporating neuroimaging measures into virtual experiences may identify the underlying mechanisms for behavioral changes in learning.","","978-1-7348995-0-4","10.23919/iLRN47897.2020.9155120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9155120","executive function;neuroplasticity;exergames","Task analysis;Neuroplasticity;Games;Neuroimaging;Training;Fish;Cognition","brain;cognition;computer games;neurophysiology;virtual reality","immersive technology;brain plasticity;virtual contexts;neuroplasticity;active gameplay;brain connection;neural substrates;executive function;immersive gameplay;immersive virtual experiences;virtual reality contexts;cognition utilizing immersive technology;doctoral colloquium","","1","","16","","4 Aug 2020","","","IEEE","IEEE Conferences"
"Novel, Robust, and Efficient Guidewire Modeling for PCI Surgery Simulator Based on Heterogeneous and Integrated Chain-Mails","W. Wang; S. Li; H. Qin; A. Hao",NA; NA; NA; NA,"2015 14th International Conference on Computer-Aided Design and Computer Graphics (CAD/Graphics)","9 Apr 2016","2015","","","105","112","Despite the long R&D history of interactive minimally-invasive surgery and therapy simulations, the guide wire/catheter behavior modeling remains challenging in Percutaneous Coronary Intervention (PCI) surgery simulators. This is primarily due to the heterogeneous heart physiological structures and complex intravascular inter-dynamic procedures. To ameliorate, this paper advocates a novel, robust, and efficient guide wire/catheter modeling method based on heterogeneous and integrated chain-mails, that can afford medical practitioners and trainees the unique opportunity to experience the entire guide wire-dominant PCI procedures in virtual environments as our model aims to mimic what occurs in clinical settings. Our approach's originality is primarily founded upon this new method's unconditional stability, real time performance, flexibility, and high-fidelity realism for guide wire/catheter simulation. Considering the front end of the guide wire has different stiffness with its conjunctive slender body and the guide wire length is adaptive to the surrounding environment, we propose to model the spatially-varying six-degree of freedom behaviors by solely resorting to the generalized 3D chain-mails. Meanwhile, to effectively accommodate the motion constraints caused by the beating vessels and flowing blood, we integrate heterogeneous volumetric chain mails to streamline guide wire modeling and its interaction with surrounding substances. By dynamically coupling guide wire chain-mails with the surrounding media via virtual links, we are capable of efficiently simulating the collision-involved interdynamic behaviors of the guide wire. Finally, we showcase a PCI prototype simulator equipped with hap tic feedback for mimicing the guide wire intervention therapy, including pushing, pulling, and twisting operations, where the built-in high-fidelity, real-time efficiency, and stableness show great promise for its practical applications in clinical training and surgery rehearsal fields.","","978-1-4673-8020-1","10.1109/CADGRAPHICS.2015.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7450404","guidewire simulation;heterogeneous chain-mails;guidewire-vessel interaction;guidewire-blood interaction;PCI simulator;haptic feedback","Solid modeling;Adaptation models;Three-dimensional displays;Blood;Couplings;Computational modeling;Surgery","catheters;haptic interfaces;medical computing;surgery","guidewire modeling;integrated chain-mails;interactive minimally-invasive surgery;therapy simulations;guide wire/catheter behavior modeling method;percutaneous coronary intervention surgery simulators;PCI surgery simulators;heterogeneous heart physiological structures;complex intravascular inter-dynamic procedures;guide wire-dominant PCI procedures;virtual environments;unconditional stability;high-fidelity realism;guide wire/catheter simulation;conjunctive slender body;guide wire length;generalized 3D chain-mails;beating vessels;flowing blood;heterogeneous volumetric chain mails;streamline guide wire modeling;guide wire chain-mails;virtual links;collision-involved interdynamic behaviors;PCI prototype simulator;haptic feedback;guide wire intervention therapy;surgery rehearsal fields","","1","","23","","9 Apr 2016","","","IEEE","IEEE Conferences"
"Simulation and gaming as a support tool for lean manufacturing systems - a case example from industry","D. J. van der Zee; J. Slomp","Fac. of Manage. & Organ., Groningen Univ., Netherlands; Fac. of Manage. & Organ., Groningen Univ., Netherlands","Proceedings of the Winter Simulation Conference, 2005.","23 Jan 2006","2005","","","10 pp.","","In this article we illustrate how simulation and gaming can be used to support lean manufacturing systems. More in particular we study a case example from industry - a manual assembly line for mail-inserting systems - for which we have developed a simulation game. This paper focuses on the development steps of the simulation game. The objective of the game is to support the introduction of lean principles in an existing assembly line. The simulation game can be used to demonstrate applicability of a lean control concept at the assembly line and to train workers to make appropriate control decisions within this concept. In this paper, we indicate a definite need for the development of this game. The systematic way in which it is developed, the use of a general simulation language in the design phase, and its usefulness may stimulate the introduction of simulation games in more industrial settings","1558-4305","0-7803-9519-0","10.1109/WSC.2005.1574520","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1574520","","Lean production;Computer aided software engineering;Manufacturing industries;Assembly systems;Postal services;Toy industry;Toy manufacturing industry;Electrical equipment industry;Throughput;Management training","assembling;computer games;digital simulation;lean production;mailing systems;simulation languages","lean manufacturing systems;manual assembly line;mail-inserting systems;simulation game;lean control;control decisions;general simulation language","","5","","15","","23 Jan 2006","","","IEEE","IEEE Conferences"
"A multimodal training platform for minimally invasive robotic surgery","R. Konietschke; A. Tobergte; C. Preusche; P. Tripicchio; E. Ruffaldi; S. Webel; U. Bockholt","Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; PERCRO, Scuola Superiore S.Anna/CEIICP, Italy; PERCRO, Scuola Superiore S.Anna/CEIICP, Italy; Fraunhofer Institute for Computer Graphics Research (IGD), Germany; Fraunhofer Institute for Computer Graphics Research (IGD), Germany","19th International Symposium in Robot and Human Interactive Communication","11 Oct 2010","2010","","","422","427","This paper gives an overview of a multimodal training platform developed for minimally invasive robotic surgery, based on the DLR MiroSurge system. It describes the technological components and integration of the hardware and software platform and presents the first integrated training tasks that enable surgeons to get familiar with the robotic system. The training platform shares the same surgical operator workstation as MiroSurge and simulates the behaviour of the telemanipulator arms and the surgical instruments. Like the real system the training platform provides haptic feedback and 3D-vision. However instead of the real telemanipulator itself, a virtual environment with abstracted tasks is connected to the operator workstation. This allows reduction in costs, to provide various levels of difficulty, and to focus on the skills to be taught. Thus a training platform is presented that aims at training a surgeon's skills in handling the robotic system MiroSurge rather than training surgery in general.","1944-9437","978-1-4244-7990-0","10.1109/ROMAN.2010.5598608","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5598608","","Training;Surgery;Robots;Solid modeling;Instruments;Haptic interfaces;Computational modeling","biology computing;haptic interfaces;manipulators;medical robotics;robot vision;surgery;virtual reality","multimodal training platform;minimally invasive robotic surgery;DLR mirosurge system;surgical operator workstation;telemanipulator arms;surgical instruments;haptic feedback;3D-vision;virtual environment","","5","","19","","11 Oct 2010","","","IEEE","IEEE Conferences"
"Encountered-Type Haptic Interface for Representation of Shape and Rigidity of 3D Virtual Objects","N. Takizawa; H. Yano; H. Iwata; Y. Oshiro; N. Ohkohchi","Graduate School of System and Information Engineering, University of Tsukuba, Tsukuba, Japan; Faculty of Engineering, Information, and System, University of Tsukuba, Tsukuba, Japan; Faculty of Engineering, Information, and System, University of Tsukuba, Tsukuba, Japan; Faculty of Medicine, University of Tsukuba, Tsukuba, Japan; Faculty of Medicine, University of Tsukuba, Tsukuba, Japan","IEEE Transactions on Haptics","14 Dec 2017","2017","10","4","500","510","This paper describes the development of an encountered-type haptic interface that can generate the physical characteristics, such as shape and rigidity, of three-dimensional (3D) virtual objects using an array of newly developed non-expandable balloons. To alter the rigidity of each non-expandable balloon, the volume of air in it is controlled through a linear actuator and a pressure sensor based on Hooke's law. Furthermore, to change the volume of each balloon, its exposed surface area is controlled by using another linear actuator with a trumpet-shaped tube. A position control mechanism is constructed to display virtual objects using the balloons. The 3D position of each balloon is controlled using a flexible tube and a string. The performance of the system is tested and the results confirm the effectiveness of the proposed principle and interface.","2329-4051","","10.1109/TOH.2017.2740934","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8012404","Haptic interface;encountered-type;balloon;surgical training;virtual clay","Virtual reality;Three-dimensional displays;Actuators;Haptic interfaces;Surgery;Training","actuators;haptic interfaces;position control;pressure sensors","linear actuator;trumpet-shaped tube;encountered-type haptic interface;rigidity;physical characteristics;three-dimensional virtual objects;nonexpandable balloon;position control;shape representation;3D virtual object;air volume;pressure sensor;Hooke law","Air;Computer-Aided Design;Equipment Design;General Surgery;Humans;Liver;Pressure;Touch;User-Computer Interface;Virtual Reality","3","","18","Traditional","17 Aug 2017","","","IEEE","IEEE Journals"
"Extending haptic augmented reality: Modulating stiffness during two-point squeezing","S. Jeon; M. Harders","Computer Vision Laboratory, ETH Zurich, Switzerland; Computer Vision Laboratory, ETH Zurich, Switzerland","2012 IEEE Haptics Symposium (HAPTICS)","16 Apr 2012","2012","","","141","146","This paper is concerned with haptic augmented reality, which allows us to merge virtual haptic stimuli into the real haptic environment. Considering the modulation of real haptic properties as a key functionality, we previously focused on modulating stiffness of a real fixed object constrained at one contact point. In this paper we generalize the approach by enabling a user to grasp, lift, and manipulate an object via two interaction points. Modulated stiffness can be explored by squeezing an object. To this end, two haptic interfaces equipped with force sensors are employed to render the additional virtual forces of the augmentation at the two interaction points. We introduce the required extended algorithms and evaluate the performance in a pilot user study. A longer term goal of our work is the development of a training environment for tumor palpation.","2324-7355","978-1-4673-0809-0","10.1109/HAPTIC.2012.6183782","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6183782","","Haptic interfaces;Force;Modulation;Rendering (computer graphics);Vectors;Visualization;Hardware","augmented reality;elasticity;haptic interfaces;modulation","haptic augmented reality;stiffness modulation;two-point squeezing;virtual haptic stimuli;real haptic environment;real haptic properties;object manipulation;modulated stiffness;haptic interfaces;force sensors;virtual forces;training environment;tumor palpation","","7","","18","","16 Apr 2012","","","IEEE","IEEE Conferences"
"A 4-dof haptic device for hysteroscopy simulation","U. Spaelter; T. Moix; D. Ilic; H. Bleuler; M. Bajka","Laboratoire de Syst. Robotiques, Fed. Inst. of Technol., Lausanne, Switzerland; Laboratoire de Syst. Robotiques, Fed. Inst. of Technol., Lausanne, Switzerland; Laboratoire de Syst. Robotiques, Fed. Inst. of Technol., Lausanne, Switzerland; Laboratoire de Syst. Robotiques, Fed. Inst. of Technol., Lausanne, Switzerland; NA","2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)","14 Feb 2005","2004","4","","3257","3263 vol.4","In minimal-invasive surgery surgeons are generally confronted with complex scenario and sometimes they have to overcome unexpected pathologies or life-threatening injuries. Therefore there is a demand for realistic training without risk to the patient. Since a decade ago there have been research activities on virtual reality surgery simulators with haptic feedback with the goal to provide an alternative to traditional training methods on animals or cadavers. Haptic feedback is a key feature for every surgery simulator for the training of hand-eye coordination. In this paper a 4-dof haptic device is presented for hysteroscopy, the examination and treatment of the uterine cavity through the vagina. Specifications are presented, and kinematics as well as force transmission are analyzed. The realized prototype, result of a systematic design process, is based on a 2-dof spherical manipulator with low inertia and a 2-dof serial extension, which allows the use of slightly adapted original instruments. With difference to common surgery simulators tool insertion and complete removal can be performed. The performance of the prototype is shortly discussed.","","0-7803-8463-6","10.1109/IROS.2004.1389919","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1389919","","Haptic interfaces;Surgery;Feedback;Prototypes;Pathology;Injuries;Virtual reality;Animals;Cadaver;Kinematics","haptic interfaces;surgery;virtual reality;medical robotics;manipulators;medical computing","4dof haptic device;hysteroscopy simulation;minimal invasive surgery surgeon;virtual reality surgery simulator;haptic feedback;spherical manipulator","","4","","18","","14 Feb 2005","","","IEEE","IEEE Conferences"
"A Large-scale Simulation Dataset: Boost the Detection Accuracy for Special Weather Conditions","D. Liu; Y. Cui; Z. Cao; Y. Chen","Purdue University,Department of Computer Graphics Technology,West Lafayette,USA,47907; University of Florida,Department of Electrical & Computer Engineering,Gainesville,FL,USA,32611; Purdue University,Department of Computer Graphics Technology,West Lafayette,USA,47907; Purdue University,Department of Computer Graphics Technology,West Lafayette,USA,47907","2020 International Joint Conference on Neural Networks (IJCNN)","28 Sep 2020","2020","","","1","8","Object detection is a fundamental task for autonomous driving systems. One bottleneck hindering detection accuracy is a shortage of well-annotated image data. Virtual reality has provided a feasible low-cost way to facilitate computer vision related developments. In autonomous driving area, existing public datasets from real world generally have data biases and cannot represent a wide range of weather conditions, such as rainy or snowy roads. To address this challenge, we introduce a new large-scale simulation dataset which is generated by an automated pipeline from a high realism video game. Our dataset focuses on weather conditions, which can be adopted to train networks to effectively detect objects under such conditions. We use extensive experiments to evaluate our dataset by comparing it with public datasets. The experiment results show that networks trained with our dataset outperform the networks trained by other public datasets. Our work demonstrates the effectiveness of using simulation data to address real-world challenges in the practice of object detection.","2161-4407","978-1-7281-6926-2","10.1109/IJCNN48605.2020.9206716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9206716","Large-scale dataset for autonomous driving;simulation data;automated data generation;special weather autonomous driving;object detection accuracy","Solid modeling;Meteorology;Object detection;Data models;Autonomous vehicles;Games;Computational modeling","computer games;computer vision;feature extraction;intelligent transportation systems;learning (artificial intelligence);neural nets;object detection;traffic engineering computing;virtual reality","special weather conditions;object detection;autonomous driving systems;detection accuracy;image data;virtual reality;computer vision;high realism video game;network training;deep learning networks","","","","38","","28 Sep 2020","","","IEEE","IEEE Conferences"
"A framework for multiuser distributed virtual environments","M. Matijasevic; D. Gracanin; K. P. Valavanis; I. Lovrek","Fac. of Electr. Eng. & Comput., Zagreb Univ., Croatia; NA; NA; NA","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","7 Aug 2002","2002","32","4","416","429","A framework for multi-user distributed virtual environments (DVEs) has been proposed. The proposed framework, incorporating two models (the functional model and the interconnection model), attempts to represent the common functionality, communication issues and requirements found in multi-user DVEs. The functional model concentrates on the DVE's functionality, while the interconnection model concentrates on how the components are interconnected to realize the required functionality. The models have been specified using the Unified Modeling Language (UML). An experimental case study demonstrates the applicability and generality of the proposed approach.","1941-0492","","10.1109/TSMCB.2002.1018762","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1018762","","Virtual environment;LAN interconnection;Unified modeling language;Virtual reality;Industrial training;Telecommunication traffic;Defense industry;Toy industry;Service robots;Medical robotics","virtual reality;groupware;multi-access systems;distributed processing;digital simulation;modelling;formal specification","multi-user distributed virtual environments;functional model;interconnection model;common functionality;communication issues;system requirements;interconnected components;Unified Modeling Language;UML;case study;distributed simulation;networked virtual environment;virtual reality","","16","","37","","7 Aug 2002","","","IEEE","IEEE Journals"
"Teaching a Global Software Development Course: Student Experiences Using Onsite Exercise Simulation","J. Lappalainen; N. Tripathi; J. Similä","Dept. of Inf. Process. Sci., Univ. of Oulu, Oulu, Finland; Dept. of Inf. Process. Sci., Univ. of Oulu, Oulu, Finland; Dept. of Inf. Process. Sci., Univ. of Oulu, Oulu, Finland","2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C)","23 Mar 2017","2016","","","440","450","Over the past decade, major advancements in software development have occurred in the global context. Global software development (GSD) is an effective strategy, and many higher educational institutions have been offering GSD courses. These courses are usually organized together with another institution situated in a different location. However, conducting such a course with more than one institution is not so economical since it involves greater collaboration among various institutions than in the case of a general onsite course. In this paper, we present an onsite simulation that deals with the specifics in the field of GSD training and teaching. We analyzed the students' learning reflections with a phenomenographic approach to validate the relevance of the design science construct of the course model containing an onsite simulation. Based on the analyzed data, it is possible to organize a GSD course on a single location with the aid of role-play simulation. The presented course model can help an institution prepare its students to solve most of the common problems faced in industrial GSD settings.","","978-1-4503-4205-6","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883331","Course structure;Global software development;Phenomenography","Software;Collaboration;Reflection;Industries;Context;Training","computer science education;educational courses;educational institutions;further education;software engineering;teaching;training","global software development course;higher educational institutions;onsite simulation;GSD course training;GSD course teaching;student learning reflections;phenomenographic approach;design science;GSD course model;data analysis;role-play simulation;industrial GSD settings","","","","31","","23 Mar 2017","","","IEEE","IEEE Conferences"
"The effect of sound on haptic fidelity perception","M. Melaisi; M. Nguyen; A. Uribe; B. Kapralos","University of Ontario Institute of Technology, Oshawa, Canada; Universidad Militar Nueva Granada, Bogota, Colombia; Universidad Militar Nueva Granada, Bogota, Colombia; University of Ontario Institute of Technology, Oshawa, Canada","2017 IEEE Global Engineering Education Conference (EDUCON)","8 Jun 2017","2017","","","714","717","Recent hardware and computational advancements are providing the opportunity to develop virtual simulations and serious games with high levels of (visual) fidelity using off-the-shelf consumer-level hardware. However, so far, these applications have generally been restricted to cognitive skills training given the complexities and costs associated with high-end haptic-based rendering inherent in a variety of applications including those related to medical-based technical skills development. In the visual domain, sound has been shown to influence the perception of visual fidelity perception yet little, if any work has investigated the effect of sound on haptic fidelity perception. In this paper, we examine the influence of sound on haptic fidelity perception in a virtual drilling scenario to determine whether the low fidelity haptic feedback associated with lower-end, consumer level haptic devices can be compensated for through the use of sound. Although our results are preliminary, they do indicate that sound can o influence (increase) haptic fidelity perception.","2165-9567","978-1-5090-5467-1","10.1109/EDUCON.2017.7942926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7942926","haptics;simulation;virtual reality;serious gaming;virtual drilling","Haptic interfaces;Visualization;Three-dimensional displays;Games;Surgery;Graphical user interfaces;Libraries","haptic interfaces;virtual reality","haptic fidelity perception;virtual drilling scenario;low fidelity haptic feedback;consumer level haptic devices","","1","","19","","8 Jun 2017","","","IEEE","IEEE Conferences"
"Organization and functioning of the training centre serving lifelong seafarers' education","Đ. Nadrljanski; M. Nadrljanski; R. Boz̆ić","Fakultet of Management Novi Sad, Vase Stajića 6, 21000, R.Srbija; University of Split, Faculty of Maritime Studies, Zrinjsko-Frankopanska, Croatia; Split Ship Management, Boktuljin put, bb, Croatia","The 33rd International Convention MIPRO","29 Jul 2010","2010","","","949","953","Developed world societies are based on knowledge. They are based on the concept of lifelong education which differs completely from traditional education, not only in quality but also in quantity. Formal education in childhood and youth now becomes a synergy of initial and continuous education, as formal and informal competence education, in terms of various opportunities of society which is based on lifelong learning. In this context, the European Union also proclaimed lifelong learning based on Europe of knowledge as the key development guideline in the first decade of the 21st century. The goal of this paper is to present and analyze the phenomenon of lifelong education of maritime officials in `Split Ship Management', Split, to be precise, in its Nautical training centre, known as `Training Centre'. The mariner education project arose from cooperation with world education centers which use the most recent aspects of maritime theory and practice, both in the domestic and wider world expertise context adjusted to the latest European Union criteria. It is worth emphasizing the growing popularity of additional maritime trainings in the world as a necessity of the development of new knowledges and skills in various areas in maritime economy, which are becoming a basis for further development both with individuals and companies. Trainings are conducted in computerized laboratories and on a simulator. This formal framework used for shaping and performing trainings at the Nautical training centre is based on the current knowledge and experience of trainers and their constant strive for modernization and professional knowledge quality improvement, as well as for knowledge in general as a basic principle of development.","","978-9-5323-3050-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5533570","","Management training;Marine vehicles;Engines;Computational modeling;Navigation;Computer simulation;Continuing education;Technology management;Educational technology;Bridges","computer based training;continuing professional development;marine engineering","lifelong seafarer education;formal education;split ship management;nautical training centre;mariner education project;European Union criteria","","","","3","","29 Jul 2010","","","IEEE","IEEE Conferences"
"Effects of haptic guidance and disturbance on motor learning: Potential advantage of haptic disturbance","J. Lee; Seungmoon Choi","Haptics and Virtual Reality Laboratory, Department of Computer Science and Technology, Pohang University of Science and Technology (POSTECH), Republic of Korea; Haptics and Virtual Reality Laboratory, Department of Computer Science and Technology, Pohang University of Science and Technology (POSTECH), Republic of Korea","2010 IEEE Haptics Symposium","8 Apr 2010","2010","","","335","342","One of the primary goals of haptic guidance is to facilitate the learning of complex human motor skills by providing haptic cues that are helpful to induce desired movements. Nevertheless, a majority of previous studies have found that haptic guidance is ineffective, or sometimes even detrimental, to motor skill learning. In this paper, we propose the opposite concept, haptic disturbance, and evaluate its efficacy. In haptic disturbance, haptic cues that interfere with the movements of a learner are presented during training. We designed two methods of haptic disturbance using repulsive and noise-like forces, respectively. The effects of these methods were experimentally assessed, comparatively with the conventional methods of visual learning only and progressive haptic guidance. The motor task was to track a dot moving on a 2D plane with a haptic interface operated with one arm. We found that during training, the progressive haptic guidance showed the best tracking accuracy, but in immediate and delayed retention tests, the noise-like haptic disturbance led to the best performance. The results suggest high potentials for haptic disturbance to be a general strategy for expediting the motor learning process.","2324-7355","978-1-4244-6822-5","10.1109/HAPTIC.2010.5444635","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444635","","Haptic interfaces;Feedback;Testing;Virtual reality;Humans;Computer graphics;Computational modeling;Computer simulation;Laboratories;Computer science","computer based training;graphical user interfaces;haptic interfaces;human factors","haptic guidance;haptic disturbance;human motor skill learning;haptic cues;repulsive force;noise like force","","65","","36","","8 Apr 2010","","","IEEE","IEEE Conferences"
"Heart Rate Variability During Fighter Pilot Training Preliminary Study","P. Kutilek; P. Volf; K. Sedova; J. Hejda; V. Krivanek; M. Stehlík; K. Rusnakova; S. Kozlova; M. Braunova","Faculty of Military Technology, University of Defence, Czech Republic; Faculty of Biomedical Engineering, Czech Technical University in Prague, Sitna sq., Kladno, 3105, Czech Republic; Faculty of Biomedical Engineering, Czech Technical University in Prague, Sitna sq., Kladno, 3105, Czech Republic; Faculty of Biomedical Engineering, Czech Technical University in Prague, Sitna sq., Kladno, 3105, Czech Republic; Faculty of Military Technology, University of Defence, Czech Republic; Podbabská 1590/3 Prague, Sports Research Institute of Czech Armed Forces, Czech Republic; Podbabská 1590/3 Prague, Sports Research Institute of Czech Armed Forces, Czech Republic; Podbabská 1590/3 Prague, Sports Research Institute of Czech Armed Forces, Czech Republic; Podbabská 1590/3 Prague, Sports Research Institute of Czech Armed Forces, Czech Republic","2019 International Conference on Military Technologies (ICMT)","17 Oct 2019","2019","","","1","5","The aim of this study is to describe an evaluation method and measurement methodology for the study of heart rate variability in fighter pilots during their training. The reason for this research is the demand to monitor the physical and mental state of fighter pilots. Knowledge of these states allows experts to determine the pilot's readiness to perform real missions. It is generally known that a person's physical and mental state affects physiological functions like heart rate variability. To assess the heart rate variability, it is standard to use beats per minute (BPM). In this study, the BPM signal was obtained from two fighter pilots and the data was recorded during training missions in a flight simulator. The training mission was composed of three submissions (composed of stressful events and mid events) and four rest intervals. The nonlinear Poincaré plot analysis was used for evaluating BPM variability during training. The results showed statistically significant differences in heart rate variability, when comparing submission stressful events or mid event periods with the rest intervals. The findings demonstrate the ability of the proposed method to quantify the fighter pilot's physical and mental load, i.e. stress during flight simulator training. The results can be used to help evaluate the level of stress and readiness for missions.","","978-1-7281-4593-8","10.1109/MILTECHS.2019.8870071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8870071","fighter pilots;training;heart rate;variability non-linear method;Poincaré plot","Training;Stress;Monitoring;Heart rate variability;Biomedical monitoring","aerospace computing;aerospace simulation;biomechanics;computer based training;electrocardiography;medical signal processing","fighter pilots;heart rate variability;fighter pilot training preliminary study;physical state;mental state;BPM variability;beats per minute;nonlinear Poincare plot analysis","","","","28","","17 Oct 2019","","","IEEE","IEEE Conferences"
"Electrophysiology course with quantitative method","Q. Qiao","Department of Biomedical Engineering, Tianjin Medical University, 300070, China","2009 IEEE International Symposium on IT in Medicine & Education","15 Sep 2009","2009","1","","706","710","An interdisciplinary course ""Quantitative Electrophysiology"" at the graduate level has been developed and implemented for biomedical engineering students with electrophysiological training and medical students with mathematical and computer programming training. The contemporary electrophysiology curricula generally consist of a significant amount of facts and limited experiments. In this course, the intricacies of physiological systems were integrated with the traditional engineering and computer training. The topic are covered in our course in cell level, ranging from such elementary topics as diffusion and charge separation to the more dynamic actions of the second-messenger cascade in synaptic transmission. In every part of the topics, the lecture began with experiment facts in ordinary electrophysiology textbook, physical modeling, mathematical description, and ended with computer simulation. This course has proven to be an effective way to incorporate electrical circuits, computer training, mathematical modeling, with neuroscience. The students were more involved in participating in the activity of teaching and learning.","","978-1-4244-3928-7","10.1109/ITIME.2009.5236332","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5236332","","Biomedical engineering;Mathematical model;Bioelectric phenomena;Computational modeling;Electric potential;Education;Biomembranes;Equations;Computer simulation;Medical simulation","bioelectric phenomena;biomedical education;educational courses;neurophysiology;training","quantitative electrophysiology;biomedical engineering student;electrophysiological training;mathematical training;computer programming training;contemporary electrophysiology curricula;synaptic transmission;cell level;electrical circuit;neuroscience","","","","9","","15 Sep 2009","","","IEEE","IEEE Conferences"
"Fetal birth simulation teaching system","Z. Zhang; W. Lu; Y. Shi; T. Yang; S. Liang","College of Electronic Information and Control Engineering, Beijing University of Technology, Beijing, China; College of Electronic Information and Control Engineering, Beijing University of Technology, Beijing, China; College of Electronic Information and Control Engineering, Beijing University of Technology, Beijing, China; College of Electronic Information and Control Engineering, Beijing University of Technology, Beijing, China; College of Electronic Information and Control Engineering, Beijing University of Technology, Beijing, China","2011 IEEE International Conference on Mechatronics and Automation","18 Aug 2011","2011","","","2227","2231","The maternal confinement is a compulsory course for the obstetricians. It is a highly professional, technical and practical course. Generally, the multimedia is used to group teach obstetrics techniques via classroom demonstration. However, due to the lack of authenticity and interactivity features, this approach is not fundamentally to meet the modern teaching of medical simulation teaching situations and individual teaching needs. The advancement of electronic and digital signal processing technologies facilitates simulating this learning environment. This study aims to develop a fetal birth simulation teaching system for assisting teachers and obstetrics and gynecology students in obstetrics teaching and learning. Fetal birth simulation teaching system includes a simulation pregnant woman and baby, fetal tone controller, fetal birth controller, contraction controller and the software package on PC. There is a dual-display design in the software. One display shows the main interface of the program, in which set the parameters of the simulation fetal birth, such as the style of the fetal birth and fetal birth rate, etc. The other display shows the vital signs of the pregnant woman and the fetal likes the vital signs monitor. In addition, the system integrated the CPR (Cardiopulmonary resuscitation) to train the student to rescue the pregnant woman whom in the dangerous situation.","2152-744X","978-1-4244-8115-6","10.1109/ICMA.2011.5986285","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5986285","medical simulation education;simulation fetal birth;electronic control","Biomedical monitoring;Monitoring;Solid modeling;Fetal heart rate;Computational modeling;Training","biomedical education;computer aided instruction;educational courses;gynaecology;interactive systems;medical computing;medical control systems;multimedia computing;obstetrics;teaching","fetal birth simulation teaching system;maternal confinement;compulsory course;obstetrician;multimedia;obstetrics technique;classroom demonstration;authenticity feature;interactivity feature;medical simulation teaching;teaching needs;electronic signal processing;digital signal processing;learning environment;gynecology student;obstetrics teaching;obstetrics learning;pregnant woman;fetal tone controller;fetal birth controller;contraction controller;software package;dual-display design;cardiopulmonary resuscitation","","","","7","","18 Aug 2011","","","IEEE","IEEE Conferences"
"Haptic Guidance Benefits Musical Motor Learning","G. Grindlay","Media Laboratory, Massachusetts Institute of Technology, e-mail: grindlay@mit.edu","2008 Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems","31 Mar 2008","2008","","","397","404","This paper presents the results of a pilot experiment looking at the effect of haptic guidance on musical training. A percussion performance task was used where subjects learned to play short rhythmic sequences on a device capable of recording drumstick movements with a high degree of spatiotemporal accuracy. Subjects learned to perform the sequences under three primary training paradigms: listening to the rhythm (audio), being guided through the motions involved in the rhythm's performance (haptic), and being guided through the required motions while listening to the resulting sound (audio+haptic). Performance was assessed in terms of both timing and loudness (velocity) accuracy using several different metrics. 	Results indicate that haptic guidance can significantly benefit recall of both note timing and velocity. When subject performance was compared in terms of note velocity recall, the addition of haptic guidance to audio-based training produced a 17% reduction in final error when compared to audio training alone. When performance was evaluated in terms of liming recall, the combination of audio and haptic guidance led to an 18% reduction in early-stage error.","2324-7355","978-1-4244-2005-6","10.1109/HAPTICS.2008.4479984","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4479984","H.5.2 [Information Interfaces and Presentation]: User Interfaces¿Haptic I/O;K.3.0 [Computers and Education]: General¿","Haptic interfaces;Timing;Rhythm;Computer errors;Feedback;System testing;Optimal control;Laboratories;Audio recording;Spatiotemporal phenomena","audio user interfaces;computer based training;haptic interfaces;music","haptic guidance;musical motor learning;drumstick movement recording;audio-based training","","25","1","21","","31 Mar 2008","","","IEEE","IEEE Conferences"
"Bayesian neural network approach to hand gesture recognition system","L. Li; S. Dai","Science and Technology on Aircraft Control Laboratory, Beihang University, Beijing, 100191 China; Science and Technology on Aircraft Control Laboratory, Beihang University, Beijing, 100191 China","Proceedings of 2014 IEEE Chinese Guidance, Navigation and Control Conference","15 Jan 2015","2014","","","2019","2023","This paper presents a hand gesture recognition system as a part of our virtual reality system called non-contact flight auxiliary (NCFAC) system. The system is developed using Bayesian neural network to translate hand gestures to corresponding commands and utilizes one hand gesture to prepare for collision detection. Cyberglove sensory glove and Flock of Birds motion tracker are applied to this system to extract hand features. The Bayesian neural network model is trained and tested with different sample groups. Experiment shows that our system is able to recognize 16 kinds of hand gestures with the accuracy of 95.6% and greater generalization capability. The system can also be extended and use other algorithms for future works.","","978-1-4799-4699-0","10.1109/CGNCC.2014.7007487","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7007487","Gesture recognition;Bayesian neural network;Glove;Virtual reality","Gesture recognition;Biological neural networks;Bayes methods;Computers;Neurons;Backpropagation","Bayes methods;data gloves;generalisation (artificial intelligence);gesture recognition;neural nets;virtual reality","Bayesian neural network approach;hand gesture recognition system;virtual reality system;noncontact flight auxiliary system;NCFAC system;collision detection;cyberglove sensory glove;flock of birds motion tracker;hand feature extraction;Bayesian neural network model;generalization capability","","","","17","","15 Jan 2015","","","IEEE","IEEE Conferences"
"Intelligent control of a planning system for astronaut training","J. Ortiz; Guanrong Chen","NASA Johnson Space Center, Houston, TX, USA; NA","IEEE Transactions on Aerospace and Electronic Systems","6 Aug 2002","1999","35","3","1055","1070","This work intends to design, analyze and solve, from the systems control perspective, a complex, dynamic, and multiconstrained planning system for generating training plans for crew members of the NASA-led International Space Station. Various intelligent planning systems have been developed within the framework of artificial intelligence. These planning systems generally lack a rigorous mathematical formalism to allow a reliable and flexible methodology for their design, modeling, and performance analysis in a dynamical, time-critical, and multiconstrained environment. Formulating the planning problem in the domain of discrete-event systems under a unified framework such that it can be modeled, designed, and analyzed as a control system will provide a self-contained theory for such planning systems. This will also provide a means to certify various planning systems for operations in the dynamical and complex environments in space. The work presented here completes the design, development, and analysis of an intricate, large-scale, and representative mathematical formulation for intelligent control of a real planning system for Space Station crew training. This planning system has been tested and used at NASA-Johnson Space Center.","1557-9603","","10.1109/7.784074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=784074","","Intelligent control;Artificial intelligence;Control systems;International Space Station;Intelligent systems;Design methodology;Mathematical model;Performance analysis;Time factors;Discrete event systems","computer based training;aerospace simulation;intelligent control;planning (artificial intelligence);aerospace expert systems;discrete event systems;Petri nets","astronaut training;planning system;intelligent control;complex dynamic multiconstrained system;training plans;crew members;International Space Station;discrete-event systems;self-contained theory;AI planning;supervisory controller;Petri net;computer implementation","Algorithms;Artificial Intelligence;Astronauts;Humans;Inservice Training;Space Flight;Spacecraft;Systems Analysis;Time Management;United States;United States National Aeronautics and Space Administration","2","1","21","","6 Aug 2002","","","IEEE","IEEE Journals"
"Repeatable Folding Task by Humanoid Robot Worker Using Deep Learning","P. Yang; K. Sasaki; K. Suzuki; K. Kase; S. Sugano; T. Ogata","Department of Modern Mechanical Engineering, Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Department of Modern Mechanical Engineering, Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan","IEEE Robotics and Automation Letters","20 May 2017","2017","2","2","397","403","We propose a practical state-of-the-art method to develop a machine-learning-based humanoid robot that can work as a production line worker. The proposed approach provides an intuitive way to collect data and exhibits the following characteristics: task performing capability, task reiteration ability, generalizability, and easy applicability. The proposed approach utilizes a real-time user interface with a monitor and provides a first-person perspective using a head-mounted display. Through this interface, teleoperation is used for collecting task operating data, especially for tasks that are difficult to be applied with a conventional method. A two-phase deep learning model is also utilized in the proposed approach. A deep convolutional autoencoder extracts images features and reconstructs images, and a fully connected deep time delay neural network learns the dynamics of a robot task process from the extracted image features and motion angle signals. The “Nextage Open” humanoid robot is used as an experimental platform to evaluate the proposed model. The object folding task utilizing with 35 trained and 5 untrained sensory motor sequences for test. Testing the trained model with online generation demonstrates a 77.8% success rate for the object folding task.","2377-3766","","10.1109/LRA.2016.2633383","AIST; Research Institute for Science and Engineering, Waseda University; MEXT Grant-in-Aid for Scientific Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7762066","Humanoid robots;learning and adaptive systems;motion control of manipulators;neurorobotics","Robot sensing systems;Machine learning;Feature extraction;Humanoid robots;Training;Data models","data handling;delays;feature extraction;generalisation (artificial intelligence);humanoid robots;human-robot interaction;image reconstruction;industrial robots;learning (artificial intelligence);neurocontrollers;robot dynamics;robot vision;telerobotics;user interfaces","repeatable folding task;humanoid robot worker;machine-learning-based humanoid robot;production line worker;task performing capability;task reiteration ability;generalizability;user interface;first-person perspective;head-mounted display;teleoperation;task operating data collection;two-phase deep learning;deep convolutional autoencoder;image feature extraction;image reconstruction;deep time delay neural network learning;robot task process dynamics;Nextage Open humanoid robot;sensory motor sequences","","76","","21","","29 Nov 2016","","","IEEE","IEEE Journals"
"Force reflection distribution of haptic devices","M. Hossny; A. Bhatti; S. Nahavandi; R. Tilove","Centre for Intelligent Systems Research (CISR), Deakin University, Australia; Centre for Intelligent Systems Research (CISR), Deakin University, Australia; Centre for Intelligent Systems Research (CISR), Deakin University, Australia; GM Global Research and Development, General Motors, USA","2014 8th International Conference on Signal Processing and Communication Systems (ICSPCS)","26 Jan 2015","2014","","","1","9","Haptically enabled virtual reality systems facilitate rapid and low cost testing for process design, training practices and ergonomic analysis in many manufacturing industries, particularly automotive and aerospace. In this work we design a validation framework to validate the dynamic forces displayed by haptic display devices using a robot arm equipped with a force sensor. The validation framework is completely autonomous to ensure unbiased characterization. Measured force magnitude and the direction of the sensed force vector are the main criteria used in this work.","","978-1-4799-5255-7","10.1109/ICSPCS.2014.7021102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7021102","Haptics Interface;Force Validation","Force;Haptic interfaces;Vectors;Force sensors;Robot kinematics;Robot sensing systems","force sensors;haptic interfaces;manipulators;virtual reality","force reflection distribution;virtual reality systems;dynamic forces;haptic display devices;force sensor;robot arm","","","","15","","26 Jan 2015","","","IEEE","IEEE Conferences"
"Delay Compensation for a Telepresence System With 3D 360 Degree Vision Based on Deep Head Motion Prediction and Dynamic FoV Adaptation","T. Aykut; M. Karimi; C. Burgmair; A. Finkenzeller; C. Bachhuber; E. Steinbach","Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany","IEEE Robotics and Automation Letters","31 Aug 2018","2018","3","4","4343","4350","The usability of telepresence applications is strongly affected by the communication delay between the user and the remote system. Special attention needs to be paid in case the distant scene is experienced by means of a Head Mounted Display. A high motion-to-photon latency, which describes the time needed to fully reflect the user's motion on the display, results in a poor feeling of presence. Further consequences involve unbearable motion sickness, indisposition, and termination of the telepresence session in the worst case. In this letter, we present our low-cost MAVI telepresence system, which is equipped with a stereoscopic 360° vision system and high-payload manipulation capabilities. Special emphasis is placed on the stereoscopic vision system and its delay compensation. More specifically, we propose velocity-based dynamic field-of-view adaptation techniques to decrease the emergence of simulator sickness and to improve the achievable level of delay compensation. The proposed delay compensation approach relies on deep learning to predict the prospective head motion. We use our previously described head motion dataset for training, validation, and testing. To prove the general validity of our approach, we perform cross validation with another independent dataset. We use both qualitative measures and subjective experiments for evaluation. Our results show that the proposed approach is able to achieve mean compensation rates of around 99.9% for latencies between 0.1 and 0.5 s.","2377-3766","","10.1109/LRA.2018.2864359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8429079","3D vision;telepresence;virtual reality;remote reality;omnidirectional vision","Deep learning;Visualization;Delays;Telepresence;Virtual reality;Stereo image processing","compensation;delays;haptic interfaces;helmet mounted displays;learning (artificial intelligence);optical tracking;stereo image processing;three-dimensional displays;virtual reality;visual perception","field-of-view adaptation techniques;delay compensation approach;prospective head motion;mean compensation rates;dynamic FoV adaptation;telepresence applications;communication delay;remote system;Head Mounted Display;unbearable motion sickness;telepresence session;low-cost MAVI telepresence system;stereoscopic 360° vision system;high-payload manipulation capabilities;head motion dataset;3D 360 degree vision;velocity-based dynamic field-of-view adaptation techniques;high motion-to-photon latency;deep head motion prediction;simulator sickness;deep learning","","2","","29","","8 Aug 2018","","","IEEE","IEEE Journals"
"Implementation of general DCS configuration platform and project conversion system","L. Lv; Y. Dong; C. Han","School of Control and Computer Engineering, North China Electric Power University, Baoding 071003, China; School of Control and Computer Engineering, North China Electric Power University, Baoding 071003, China; School of Control and Computer Engineering, North China Electric Power University, Baoding 071003, China","2011 Seventh International Conference on Natural Computation","19 Sep 2011","2011","4","","2116","2119","To meet different distributed control system (DCS) training requirements of thermal staff from different power stations, this paper presents a general DCS configuration platform and project conversion system which is based on Ovation and researched through configuration environments of ABB Symphony. The platform is built by using the analyzing technology which based on binary files and the redeveloped technology of C++ Builder. According to the test results, this platform can simulate Symphony and other several DCS configuration environments, and provides a new idea for thermal training.","2157-9563","978-1-4244-9953-3","10.1109/ICNC.2011.6022433","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6022433","DCS;Configuration platform;Ovation;Project conversion system","Real time systems;Algorithm design and analysis;Databases;Training;Power systems;Software algorithms;Power generation","C++ language;computer based training;distributed control;operating systems (computers);power engineering computing;thermal power stations","DCS configuration platform;project conversion system;thermal staff training requirements;power stations;Ovation;ABB Symphony;binary files;C++ builder","","","","5","","19 Sep 2011","","","IEEE","IEEE Conferences"
"Photorealistic Large-Scale Urban City Model Reconstruction","C. Poullis; S. You","University of Southern California, Los Angeles; University of Southern California, Los Angeles","IEEE Transactions on Visualization and Computer Graphics","12 May 2009","2009","15","4","654","669","The rapid and efficient creation of virtual environments has become a crucial part of virtual reality applications. In particular, civil and defense applications often require and employ detailed models of operations areas for training, simulations of different scenarios, planning for natural or man-made events, monitoring, surveillance, games, and films. A realistic representation of the large-scale environments is therefore imperative for the success of such applications since it increases the immersive experience of its users and helps reduce the difference between physical and virtual reality. However, the task of creating such large-scale virtual environments still remains a time-consuming and manual work. In this work, we propose a novel method for the rapid reconstruction of photorealistic large-scale virtual environments. First, a novel, extendible, parameterized geometric primitive is presented for the automatic building identification and reconstruction of building structures. In addition, buildings with complex roofs containing complex linear and nonlinear surfaces are reconstructed interactively using a linear polygonal and a nonlinear primitive, respectively. Second, we present a rendering pipeline for the composition of photorealistic textures, which unlike existing techniques, can recover missing or occluded texture information by integrating multiple information captured from different optical sensors (ground, aerial, and satellite).","1941-0506","","10.1109/TVCG.2008.189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4653489","Large-scale modeling;rapid reconstruction;photorealistic model.;Three-Dimensional Graphics and Realism;Modeling packages;Computer Graphics;General;Virtual reality;Applications","Large-scale systems;Cities and towns;Virtual environment;Buildings;Virtual reality;Discrete event simulation;Surveillance;Surface reconstruction;Pipelines;Optical sensors","structural engineering;virtual reality","photorealistic model;urban city model reconstruction;virtual reality;rapid reconstruction;automatic building identification","","29","","21","","17 Oct 2008","","","IEEE","IEEE Journals"
"Modeling of System Software for Computer Based Training","J. R. G. Braga; J. B. Mendes; L. A. B. Júnior; A. C. B. Ramos","Univ. Fed. de Itajuba, Itajuba, Brazil; Univ. Fed. de Itajuba, Itajuba, Brazil; Univ. Fed. de Itajuba, Itajuba, Brazil; Univ. Fed. de Itajuba, Itajuba, Brazil","2010 Seventh International Conference on Information Technology: New Generations","1 Jul 2010","2010","","","1051","1056","With major technological advances and to reduce the cost of training apprentices for real-time critical systems, it was necessary to the development of Intelligent Tutoring Systems for training apprentices in these systems. These systems, in general, have interactive features so that the learning is actually more efficient, making the learner is more familiar with the mechanism in question. In the home stage of learning, tests are performed to obtain the student's income, a measure on their use. The aim of this paper is to present the modeling of Tutorial of Intelligent Systems using the UML language. The various steps of the analysis are considered the diagrams required to build a general model, whose purpose is to present the different perspectives of its development.","","978-1-4244-6271-1","10.1109/ITNG.2010.10","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5501492","E-learning;Hypermedia;Simulator;UML","System software;Intelligent systems;Education;Unified modeling language;Costs;Computer aided instruction;Artificial intelligence;Information technology;Computer displays;Employee welfare","computer based training;intelligent tutoring systems;software engineering;Unified Modeling Language","system software modeling;computer based training;intelligent tutoring systems;UML language","","2","","8","","1 Jul 2010","","","IEEE","IEEE Conferences"
"Simulation and modelling of virtual operators for workspace design","V. Hue; J. -. Fourquet; P. Chiron","Lab. Genie de Production, LGP-ENIT, Tarbes, France; Lab. Genie de Production, LGP-ENIT, Tarbes, France; Lab. Genie de Production, LGP-ENIT, Tarbes, France","2005 ICSC Congress on Computational Intelligence Methods and Applications","7 Aug 2006","2005","","","6 pp.","","This paper deals with modelling of human movement in order to provide an analysis and simulation tool which could be used for workspace design. We are interested in systematic generation of human motion and postures that correspond to working tasks defined by grasps or, more generally, by locations of particular frames linked to hands, head or another body of interest. These tasks are reaching - point to point - tasks or tasks with imposed Cartesian path. So the problem is: how to control global posture when frames attached to some bodies are imposed? In the general case, the constraints imposed by the task are equality constraints imposed by kinematics on one side, and obstacles or articular bounds defining inequality constraints on another side. When there is less equality constraints than independent control variables, then the problem is redundant and many solutions realize the constraints. Since the goal is to provide a realistic simulation in order to predict real human motion, redundancy has to be used to obtain realistic movements, to avoid collisions with 3D environment and to take into account articular limitations","","1-4244-0020-1","10.1109/CIMA.2005.1662301","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1662301","","Humans;Medical simulation;Analytical models;Kinematics;Motion measurement;Computational modeling;Management training;Production;Software tools;Software systems","digital simulation;ergonomics;office environment;virtual reality","virtual operator simulation;virutal operator modelling;workspace design;human movement modelling;human motion generation;human postures generation;Cartesian path;global posture control;collision avoidance","","","","24","","7 Aug 2006","","","IEEE","IEEE Conferences"
"Differences in general and commercial aviation automation","J. M. Hitt; F. Jentsch","Lab. of Team Performance, Central Florida Univ., Orlando, FL, USA; NA","Gateway to the New Millennium. 18th Digital Avionics Systems Conference. Proceedings (Cat. No.99CH37033)","6 Aug 2002","1999","1","","4.A.1","4.A.1","The purpose of this paper is to examine barriers to the application of research findings from the commercial aviation to the GA environment. Specific attention is given to the areas of automation needs and capabilities, training, teamwork, redundancy of system information, and environmental flight characteristics.","","0-7803-5749-3","10.1109/DASC.1999.863719","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=863719","","Automation;Laboratories;Military aircraft;Global Positioning System;Aerospace electronics;Business;Aircraft navigation;Safety devices;Automatic testing;System testing","aerospace control;man-machine systems;redundancy;training;human factors;aerospace simulation","commercial aviation automation;training;teamwork;redundancy;environmental flight characteristics;general aviation;simulation","","","","28","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Overcoming Glossophobia Based on Virtual Reality and Heart Rate Sensors","D. Herumurti; A. Yuniarti; P. Rimawan; A. A. Yunanto","Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia; Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia","2019 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)","5 Aug 2019","2019","","","139","144","Glossophobia or commonly called speech anxiety is the fear of public speaking. It is a psychological disorder which a person is afraid to speak in public or can be interpreted as nervous. This problem is caused by the lack of preparation or training carried out to public speaking. In Addition, the training is generally lack the atmosphere or impression like speaking in public. Therefore, this system was created for helping someone in preparation before public speaking. This system simulation for practicing public speaking based on technology such as virtual reality, video 360, and arduino heart rate sensors. The results of the functionality and non-functionality of the system have been fully implemented and are running well. In addition, based on the results of the questionnaire and test of objectivity, this system has good feedback for helping someone to prepare and practice in public speaking based on virtual reality technology.","","978-1-7281-3745-2","10.1109/ICIAICT.2019.8784846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8784846","Public Speaking;Glossophobia;Virtual Reality;Heart Rate Sensors","Heart rate;Public speaking;Virtual reality;Sensors;Testing;Solid modeling;Tools","biosensors;medical computing;medical disorders;patient treatment;psychology;virtual reality","glossophobia;virtual reality;public speaking;Arduino heart rate sensors;speech anxiety;psychological disorder;video 360","","6","","14","","5 Aug 2019","","","IEEE","IEEE Conferences"
"The Effects of Two Game Interaction Modes on Cortical Activation in Subjects of Different Ages: A Functional Near-Infrared Spectroscopy Study","R. Ge; Z. Wang; X. Yuan; Q. Li; Y. Gao; H. Liu; Z. Fan; L. Bu","School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical Engineering, Shandong University, Jinan, China; School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore","IEEE Access","20 Jan 2021","2021","9","","11405","11415","Increasing age and various pathological factors lead to cognitive function decline among the elderly. The most serious cognitive dysfunctions among the elderly include mild cognitive impairment (MCI), Alzheimer's disease (AD), and vascular dementia (VAD). Cognitive training is an effective approach to mitigate the decline in cognitive function. Recent studies have confirmed that emerging training methods using new technologies, such as virtual reality (VR) and mobile phones, can be used effectively for cognitive training. This study used functional near-infrared spectroscopy (fNIRS) to compare the brain activation of young and elderly people during VR and mobile phone training when performing a cognitive training game. fNIRS has been shown to be an effective tool for monitoring cognitive decline. In the current study, the MMSE scale was used to measure cognitive performance and fNIRS was used to measure brain activation among 20 youth (mean age 25.33± 1.59 years) and 17 elderly people (mean age 63± 4.35 years). The results showed that the mobile phone game produced significant activation of the prefrontal lobe (PFC) and the VR game produced significant activation of the parietal lobe (MC). The average MMSE scale score of the elderly group was lower than that of the young group and was strongly correlated with PFC activation. This study confirms that elderly people have reduced cognitive function compared to young people. The results indicate that mobile phone games have a positive training effect on reducing cognitive decline, and that VR is a suitable means for cognitive function training among the elderly.","2169-3536","","10.1109/ACCESS.2021.3050210","Ministry of Education in China (MOE) Project of Humanities and Social Sciences; Shandong Social Science Planning Fund Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9317849","Virtual reality;functional near-infrared spectroscopy;cortical activation;game experience;cognitive decline","Games;Training;Senior citizens;Mobile handsets;Spectroscopy;Land mobile radio;Task analysis","biomedical optical imaging;brain;cognition;computer games;diseases;geriatrics;infrared spectroscopy;neurophysiology;virtual reality","game interaction modes;cortical activation;cognitive function decline;mild cognitive impairment;mobile phones;near-infrared spectroscopy;fNIRS;brain activation;mobile phone training;cognitive training game;cognitive decline;cognitive performance;mobile phone game;VR game;PFC activation;cognitive function training","","","","50","CCBY","8 Jan 2021","","","IEEE","IEEE Journals"
"Automatic meal planning using artificial intelligence algorithms in computer aided diabetes therapy","J. Bulka; A. Izworski; J. Koleszynska; J. Lis; I. Wochlik","AGH University of Science and Technology, al. Mickiewicza 30, 30-059 Kraków, Poland; AGH University of Science and Technology, al. Mickiewicza 30, 30-059 Kraków, Poland; AGH University of Science and Technology, al. Mickiewicza 30, 30-059 Kraków, Poland; AGH University of Science and Technology, al. Mickiewicza 30, 30-059 Kraków, Poland; AGH University of Science and Technology, al. Mickiewicza 30, 30-059 Kraków, Poland","2009 4th International Conference on Autonomous Robots and Agents","21 Mar 2009","2009","","","393","397","This paper presents the review of the computer aided diabetes therapy introducing GIGISim (Glucose-Insulin and Glycemic Index Web Simulator) e-learning tool based on the glucose and insulin plasma levels simulation models and genetic algorithms optimization. Together with the system, reported solutions assisting diabetes therapy were summarized and their functionality presented. Artificial intelligence is applied in GIGISim tools to improve patients' management and health awareness. Interactive, diabetes-dedicated simulators, supported with genetic algorithms (GA) have a great deal of educational potential for patients and their families, and may also offer a means of training for health-care professionals. It is generally believed that evolutionary algorithms (EA), which GA are a particular class of, perform consistently well across all types of optimization problems, in this case the optimization of the diabetes meal plan.","","978-1-4244-2712-3","10.1109/ICARA.2000.4803989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4803989","Tele-health system;Tele-education;web tools;glucoseinsulin models;interactive simulation;diabetes therapy;evolutionary computing","Artificial intelligence;Diabetes;Medical treatment;Plasma simulation;Computational modeling;Computer simulation;Genetic algorithms;Electronic learning;Sugar;Insulin","artificial intelligence;biomedical education;computer based training;diseases;genetic algorithms;health care;medical computing;patient treatment;planning;sugar","automatic meal planning;artificial intelligence algorithms;computer aided diabetes therapy;Glucose-Insulin and Glycemic Index Web Simulator e-learning tool;glucose plasma levels simulation model;insulin plasma levels simulation model;genetic algorithms optimization;patients management;health awareness;health-care professional training;evolutionary algorithms","","2","","19","","21 Mar 2009","","","IEEE","IEEE Conferences"
"Analysis of virtual environment haptic robotic systems for a rehabilitation of post-stroke patients","T. T. Jiang; Z. Q. Qian; Y. Lin; Z. M. Bi; Y. F. Liu; W. J. Zhang","Complex and Intelligent System Research Center, East China University of Science and Technology, Shanghai, China; Complex and Intelligent System Research Center, East China University of Science and Technology, Shanghai, China; Department of Mechanical and Industrial Engineering, Northeastern University, USA; Department of Engineering, Purdue University of Fort Wayne, Fort Wayne, USA; Robot Hub, NO.257 Jinzang Rd., Pudong New District, Shanghai, China; Complex and Intelligent System Research Center, East China University of Science and Technology, Shanghai, China","2017 IEEE International Conference on Industrial Technology (ICIT)","4 May 2017","2017","","","738","742","Haptic refers to feedback of a physical signal to a human user through touch. A haptic system realizes this feedback. In most of the applications today, the physical signal refers to force but not necessary. Virtual environment haptic systems refers to the situation where the force to be feedback from the objects in a virtual environment or computer. Virtual environment haptic robotic systems are widely used for rehabilitation and training of surgeon. However, currently, these systems seem to be qualitative; as such the training goal can never be precise. The root cause for this shortcoming is absence of theoretical analysis of virtual environment haptic robotic systems. This paper reports our work on a theoretical analysis of the virtual environment haptic robotic system. A commercial system Phantom Omni was taken as a case system to facilitate this research. This research has a generalized implication to any kind of virtual environment haptic robotic system as well as to general Human-Machine Cooperative Robot, a kind of which is the haptic system.","","978-1-5090-5320-9","10.1109/ICIT.2017.7915451","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7915451","Human-machine cooperative robot;haptic interface;stroke treatment;kinematics","Haptic interfaces;Robot kinematics;Virtual environments;Kinematics;Force;Computers","haptic interfaces;man-machine systems;medical robotics;patient rehabilitation","virtual environment haptic robotic systems;post-stroke patient rehabilitation;physical signal feedback;surgeon training;Phantom Omni;human-machine cooperative robot","","4","","17","","4 May 2017","","","IEEE","IEEE Conferences"
"Virtual Eye: A sensor based mobile viewer to aid collaborative decision making in virtual environments","W. Ranaweera; R. Wickramarachchi; S. Jabbar; M. Weerasinghe; N. Gunathilake; C. Keppitiyagama; D. Sandaruwan; P. Samarasinghe","School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka; School of Computing, University of Colombo 35, Reid Avenue, 7, Sri Lanka","International Conference on Advances in ICT for Emerging Regions (ICTer2012)","31 Jan 2013","2012","","","56","61","Current virtual simulation techniques often include multi-user interactivity in virtual environments that can be controlled in real time. Such simulation techniques are mostly employed in virtual military training sessions and in real time gaming experiences, where users have to make more strategic decisions by analyzing the information they receive, in response to the actions of the other users in the same virtual environment. Generally, in the real world, collaborative decision making takes place when a team of people work together to control the behaviour of a single object which cannot be handled alone by an individual. A ship with its crew can be held as an example. When applying this scenario into virtually simulated environments, multiple users have to involve in representing a single object in the virtual world. These users need to obtain sufficient information about the activities in the environment that will contribute to the collaborative decision making process. Out of many sources, visual information is the most reliable source the users tend to depend on. The use of traditional static displays to obtain visual information limits the capability of providing a rich set of information about the 3D environment. Head Mounted Displays address these limitations while introducing several new problems. On the otherhand, our work is focused on exploring how smart devices can be employed by a collaboratively working team of users to obtain visual information to the level beyond which a static display provides, thus aiding the process of decision making. To serve the above purpose, we propose a solution, “Virtual Eye”, which uses a smart mobile device with the ability to view the visual output of the virtual world and the ability to control that view according to user's orientation changes and movements with the use of its inbuilt sensors.","","978-1-4673-5530-8","10.1109/ICTer.2012.6422831","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6422831","Virtual reality;collaborative decision making;mobile;sensors;streaming","Educational institutions;Mobile communication;Visualization;Servers;Communication channels;Optical reflection;Optical sensors","computer games;decision making;digital simulation;mobile computing;sensors;virtual reality","virtual eye;sensor based mobile viewer;aid collaborative decision making;virtual environments;virtual simulation techniques;multiuser interactivity;virtual military training sessions;virtual world;collaborative decision making process;visual information;head mounted displays;static display","","1","","13","","31 Jan 2013","","","IEEE","IEEE Conferences"
"Elastodynamic shape modeling in virtual medicine","A. Radetzky; A. Nurnberger; M. Teistler; D. P. Pretschner","Inst. for Med. Inf., Tech. Univ. Braunschweig, Germany; NA; NA; NA","Proceedings Shape Modeling International '99. International Conference on Shape Modeling and Applications","6 Aug 2002","1999","","","172","178","Surgical simulation is the coming training method for medical education. The main reasons for this are the reduced risk for the patients and the easy repeatability of complicated surgical procedures. Therefore, an improved impression of reality during the simulated training must be obtained. For this, a complex model of the human's anatomy and physiology is needed. With regards to pathological conditions, which should be considered, it is necessary to build more general anatomical models. Simple static models are unsuitable for surgical simulation because convincing interactivity is only possible with deformable organs and elastic tissues. Traditional models of tissue deformation have difficulties to simulate the appearance of deformation because of the unknown physical parameters of the tissue's elasticity. Hence the paper describes a method for elastodynamic shape modeling with neuro fuzzy systems, which are able to adapt the necessary parameters from real tissues.","","0-7695-0065-X","10.1109/SMA.1999.749337","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=749337","","Elastodynamics;Shape;Deformable models;Surgery;Medical simulation;Human anatomy;Physiology;Pathology;Elasticity;Fuzzy systems","biomedical education;medical computing;virtual reality;digital simulation;computer based training;fuzzy neural nets;computer graphics","elastodynamic shape modeling;virtual medicine;surgical simulation;training method;medical education;complicated surgical procedures;human anatomy;physiology;pathological conditions;anatomical models;interactivity;deformable organs;elastic tissues;tissue deformation;neuro fuzzy systems;real tissues","","8","","26","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Simulation for enhancing e-Learning environments: A software for teaching heart-lung interaction to medicine students","C. De Lazzari; I. Genuini; D. Pisanelli; A. D'Ambrosi; E. Silvetti; M. C. Gatto; E. Del Prete; F. Fedele","CNR, Institute of Clinical Physiology, UOS of Rome, Italy; Dept. of Cardiovascular, Respiratory, Nephrological, Anaesthesiological and Geriatric Sciences, “Sapienza” University of Rome Italy; CNR, Institute of Cognitive Sciences and Technology (ISTC), Rome, Italy; Dept. of Cardiovascular, Respiratory, Nephrological, Anaesthesiological and Geriatric Sciences, “Sapienza” University of Rome Italy; Dept. of Cardiovascular, Respiratory, Nephrological, Anaesthesiological and Geriatric Sciences, “Sapienza” University of Rome Italy; Dept. of Cardiovascular, Respiratory, Nephrological, Anaesthesiological and Geriatric Sciences, “Sapienza” University of Rome Italy; Italian Workers' Compensation Authority (Istituto Nazionale per l'Assicurazione contro gli Infortuni sul Lavoro); Dept. of Cardiovascular, Respiratory, Nephrological, Anaesthesiological and Geriatric Sciences, “Sapienza” University of Rome Italy","2013 IEEE 12th International Conference on Intelligent Software Methodologies, Tools and Techniques (SoMeT)","24 Oct 2013","2013","","","197","202","Heart-lung interaction must be analyzed while assisting patients with severe respiratory problems or with heart failure in intensive care unit. Such patients can be assisted by mechanical ventilatory assistance or by thoracic artificial lung. This paper presents an e-Learning environment aiming at teaching the interaction of cardiovascular and lung systems to medical students. Such an environment was experimented during a training course given to students of the School of Specialization in Cardiology at the Department of Cardiovascular, Respiratory, Nephrological, Anesthesiological and Geriatric Sciences held at `Sapienza' University in Rome. The training course employed CARDIOSIM©, the numerical simulator of the cardiovascular system. Such simulator is able to reproduce pathophysiological conditions of patients affected by cardiovascular and/or lung disease. The simulator implements several different cardiovascular pumps in order to assist one or both ventricles in parallel or in series. Thoracic artificial lung assistance was applied in parallel and hybrid mode to show the different effects produced on left (right) ventricular end diastolic (systolic) volume, cardiac output, mean pulmonary arterial pressure, mean left atrial pressure, mean systemic venous pressure and the value of the area of coronary blood flow-aortic pressure loop (CBP-AoP). The results presented here are consistent with those presented in the literature. Finally, the paper discusses the benefit of employing a software simulator to enhance the performances of an eLearning environment. We also believe that not only a simulation software, but also an ontology-based modelling of the relevant concepts involved in the e-Learning domain is a valid approach in order to reuse an environment in other domains or for other students' profiles (e.g. general practitioners, anesthesiologists, nurses).","","978-1-4799-0421-1","10.1109/SoMeT.2013.6645662","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6645662","","Lungs;Software;Blood flow;Resistance;Educational institutions;Training;Electronic learning","artificial organs;biomedical education;blood vessels;cardiovascular system;computer based training;diseases;educational courses;haemodynamics;haemorheology;lung;medical computing;numerical analysis;ontologies (artificial intelligence);teaching","heart-lung interaction teaching software;medicine students;severe respiratory problem patient assistance;heart failure patient assistance;intensive care unit;mechanical ventilatory assistance;cardiovascular-lung system interaction teaching;training course;School of Specialization in Cardiology;Department of Cardiovascular;Sapienza University;Rome;CARDIOSIM numerical simulator;pathophysiological condition reproduction;cardiovascular disease;lung disease;cardiovascular pumps;ventricle assistance;thoracic artificial lung assistance;parallel mode;hybrid mode;series mode;left-ventricular end diastolic volume;left-ventricular end systolic volume;right-ventricular end diastolic volume;right-ventricular end systolic volume;cardiac output;mean pulmonary arterial pressure;mean left atrial pressure;mean systemic venous pressure;coronary blood flow-aortic pressure loop area value;CBP-AoP area value;software simulator;e-learning environment performance enhancement;ontology-based modelling;student profiles;general practitioners;anesthesiologists;nurses;Department of Cardiovascular Sciences;Department of Respiratory Sciences;Department of Nephrological Sciences;Department of Anesthesiological Sciences;Department of Geriatric Sciences","","","","27","","24 Oct 2013","","","IEEE","IEEE Conferences"
"Customization of a low-end haptic device to add rotational DOF for virtual cardiac auscultation training","A. Uribe-Quevedo; D. Rojas; B. Kapralos","The Games Institute, University of Waterloo, Waterloo, Ontario, Canada; The Wilson Centre, Toronto, Ontario, Canada; University of Ontario Institute of Technology, Oshawa, Ontario, Canada","2016 7th International Conference on Information, Intelligence, Systems & Applications (IISA)","19 Dec 2016","2016","","","1","6","Cardiac auscultation is a cost-effective medical procedure used to examine the heart and obtain information regarding the hearts rate, rhythm, location timing, intensity, quality, and shape. Relying on visual, audio and haptic cues, it is a difficult skill to master and with the availability of various new diagnostic techniques, the emphasis on cardiac auscultation is decreasing in both education and practice settings. Traditional cardiac auscultation training is focused on memorizing various heart sounds and their corresponding diagnosis. Recent hardware and computational advancements are providing the opportunity to develop virtual-based medical simulations that employ a high level of fidelity and novel user-simulation interaction techniques using off-the-shelf consumer-level hardware and devices. However, these virtual applications are generally restricted to cognitive skills training given that the simulation of accurate haptic cues required to replicate the sense of touch (an important component of many medical procedures including cardiac auscultation), is still difficult and cost-prohibitive. Although several low fidelity and low-cost gaming-based haptic devices are currently available, they are generally restrictive and cannot provide the range of motions (degrees of freedom) required to simulate many medical procedures. Here we describe an approach to add rotational degrees of freedom to the Novint Falcon, a consumer level (gaming) haptics device, by coupling a smartphone and incorporating the smartphone's accelerometer data to the haptics virtual controller. Our goal is to overcome the limitations associated with the limited degrees of freedom available on consumer level haptic devices and permit their use in medical technical skills-based simulation training with an affordable approach.","","978-1-5090-3429-1","10.1109/IISA.2016.7785431","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7785431","","Haptic interfaces;Training;Solid modeling;Medical diagnostic imaging;Visualization;Games;Surgery","accelerometers;cardiology;computer based training;haptic interfaces;medical computing;patient diagnosis;smart phones","low-end haptic device;rotational DOF;virtual cardiac auscultation training;heart sounds;virtual-based medical simulations;user-simulation interaction techniques;low-cost gaming-based haptic devices;medical procedures;smartphone accelerometer data;haptics virtual controller;consumer level haptic devices","","1","","28","","19 Dec 2016","","","IEEE","IEEE Conferences"
"Generalized circle agent for geometry friends using deep reinforcement learning","A. C. Özgen; M. Fasounaki; H. K. Ekenel","Istanbul Technical University, SiMiT Lab, Department of Computer Engineering, Istanbul, Turkey; Istanbul Technical University, SiMiT Lab, Department of Computer Engineering, Istanbul, Turkey; Istanbul Technical University, SiMiT Lab, Department of Computer Engineering, Istanbul, Turkey","2018 26th Signal Processing and Communications Applications Conference (SIU)","9 Jul 2018","2018","","","1","4","Reinforcement learning began to perform at human-level success in game intelligence after deep learning revolution. Geometry Friends is a puzzle game, where we can benefit from deep learning and expect to have successful game playing agents. In the game, agents are collecting targets in two dimensional environment and they try to overcome obstacles in the way. In this paper, Q-learning approach is applied to this game and a generalized circle agent for different types of environment is implemented. Agent is trained by giving only screen pixels as input via a Convolutional Neural Network. Experimental results show that with the proposed method game completion rate and completion times are improved compared to random agent.","","978-1-5386-1501-0","10.1109/SIU.2018.8404596","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8404596","Game-playing AI;Reinforcement Learning;Q-learning;Convolutional Neural Networks","Games;Diamond;Training;Geometry;Machine learning;Acceleration;Testing","computer games;convolution;feedforward neural nets;geometry;learning (artificial intelligence);multi-agent systems","game intelligence;deep learning revolution;generalized circle agent;deep reinforcement learning;game playing agents;Q-learning;game completion rate;Geometry Friends puzzle game;convolutional neural network;game-playing AI","","","","","","9 Jul 2018","","","IEEE","IEEE Conferences"
"Constructing virtual parallel system for offshore oil subsea production","K. Chen; H. Guo; B. Li; Q. Miao","Research Institute, China National Offshore Oil Corporation, Beijing, China; Research Institute, China National Offshore Oil Corporation, Beijing, China; Research Institute, China National Offshore Oil Corporation, Beijing, China; Engineering Computing Center, Graduate University, Chinese Academy of Sciences, Beijing, China","Proceedings of 2012 IEEE International Conference on Service Operations and Logistics, and Informatics","20 Aug 2012","2012","","","389","393","A framework of parallel system for training, evaluation and decision supporting of offshore subsea production was proposed. A general virtual system based delta3d game/simulation engine was built. OpenGL shade language was adopted to enhance the realistic feeling. The framework has been used constructing a parallel system for the first deep water gas field in South China Sea. The parallel system helps to improve the learning efficiency in a much intuitive and interactive mode.","","978-1-4673-2401-4","10.1109/SOLI.2012.6273568","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6273568","parallel system;virtual reality;subsea production;system integration","Sea surface;Games;Training;Computational modeling;Transforms;Attenuation","offshore installations;oil drilling;parallel processing;virtual reality","virtual parallel system;offshore oil subsea production;training;evaluation;decision support;general virtual system;delta3d game/simulation engine;OpenGL shade language;deep water gas field","","1","","12","","20 Aug 2012","","","IEEE","IEEE Conferences"
"Virtual and remote robotic laboratory: comparative experimental evaluation","C. S. Tzafestas; N. Palaiologou; M. Alifragis","Sch. of Electr. & Comput. Eng., Athens Univ., Zographou, Greece; NA; NA","IEEE Transactions on Education","7 Aug 2006","2006","49","3","360","369","This paper describes the development and experimental evaluation of an e-laboratory platform in the field of robotics. The system in its current configuration is designed to enable distance training of students in real scenarios of robot manipulator programming. From a technological perspective, the research work presented in this paper is directed towards the adaptation of concepts and techniques developed in the field of telerobotics and virtual reality, and their integration in such e-laboratory settings. This paper focuses particularly on the educational impact of such systems. The goal is to assess the performance of e-laboratory scenarios in terms of the efficacy of training provided to students. The results of a pilot experimental study are presented, providing a comparative evaluation for three training modalities: real, remote, and virtual training on robot manipulator programming. The experiments were conducted according to an evaluation protocol specially designed for the considered target training task, using scoring charts to obtain quantitative performance measures and assess the performance of the student groups participating in the course. Training, as a dynamic process, is approached according to a classical three dimensional model, and performance scores are accordingly assessed in these dimensions (namely: low-level versus mid and high-level skills and understanding). The obtained results reveal certain differences between the three groups, particularly as related to the low-level skill training score, giving some insight about the training `dimensions' that are expected to be mostly affected by the absence of physical (or realistic virtual) presence in a real hands-on experimentation. Statistical analysis indicates, however, that, despite these apparent differences, such e-laboratory modules can be integrated quite effectively in practical scenarios, creating virtual training environments that can provide adequate learning elements, as related particularly to mid and high-level skill acquisition. Further work and large-scale studies are still needed, though, in order to explore the extent to which such a general conclusion is valid in different training settings, and to form the basis of a more theoretical evaluation for a comprehensive understanding of the pedagogical differences between real, virtual, and remote learning/training methodologies and experiences","1557-9638","","10.1109/TE.2006.879255","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1668280","Distance training;evaluation methodology;remote laboratory;telerobotics;virtual robotic laboratory","Manipulators;Telerobotics;Virtual reality;Control engineering education;Statistics;Student experiments","computer based training;control engineering education;distance learning;educational courses;manipulators;statistical analysis;student experiments;telerobotics;virtual reality","virtual robotic laboratory;remote robotic laboratory;e-laboratory;distance training;robot manipulator programming;telerobotics;virtual reality;scoring charts;statistical analysis;virtual training environments;high-level skill acquisition","","103","","24","","7 Aug 2006","","","IEEE","IEEE Journals"
