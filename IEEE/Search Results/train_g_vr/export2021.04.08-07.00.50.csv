"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Automobility: the coming use of fully-automated on-road vehicles","P. A. Hancock","Department of Psychology, Institute for Simulation & Training, University of Central Florida, Orlando, USA","2015 IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision","18 May 2015","2015","","","137","139","In a world that appears primarily to be motivated by a worship of the false idol of profit, there can be little doubt that the era of automated road vehicles is upon us. Indeed, such technologies have already begun to percolate into the bespoke vehicle domain and what becomes feasible in the special case is a prime candidate to penetrate into the more general circumstance. Within a period of mere decades, will it be the case that we will look back upon the manually controlled vehicle in the same manner that we now look upon the manually operated elevator, as a piquant anachronism or the particular domain of a specialized segment of the antiques trade? But, before we achieve even the first degree of true “automobility” we shall have to pass through a hybrid stage of development in which the role of the individual human driver will have to evolve substantively. During this phase of evolution, the population of vehicles on the road will be best described as `mixed equipage' (i.e., dynamically changing combinations of automated and manually controlled vehicles). Whether such differing capacity vehicles will be separated in either space (e.g., lanes devoted to automatic vehicles) or time (e.g., blocks of time when only manual vehicles are permitted on a specific roadway), is a question which must concern all who attend this important inception. If differing capacity vehicles are allowed to `mix,' a critical element of acceptance for example, will be how automated vehicles deal with drowsy, fatigued, or otherwise impaired drivers exercising traditional manual control. After exploring this specific strand of hybrid development and innovative forms of vehicle control from a human factors perspective, and briefly considering the parallel development of diverse robotic systems, I conclude my present discourse by asking the provocative question which may be expressed as follows. While we can develop such automated systems, should we in fact pursue this line of development? The latter questions are intimately bound up in the notions of safety, efficiency, choice, freedom, and our prospective overall social and individual quality of life. Whether these latter questions ever enter into the primary scientific and engineering discourse about the coming technological wave of automation I considered rather doubtful.","2379-1675","978-1-4799-8015-4","10.1109/COGSIMA.2015.7108188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7108188","automated road vehicles;automobility;trust","Robot sensing systems;Visualization;Resource management;Social network services;Read only memory;Cognitive science","human factors;road vehicles","fully-automated on-road vehicles;bespoke vehicle domain;manually controlled vehicle;automobility degree;vehicle control;human factors perspective;diverse robotic systems","","8","","9","","18 May 2015","","","IEEE","IEEE Conferences"
"pProgramming for artists: a visual language for expressive lighting design","J. B. Gross","Sch. of Inf. Sci. & Technol., Pennsylvania State Univ., University Park, PA, USA","2005 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC'05)","17 Oct 2005","2005","","","331","332","Programming is a process of formalizing and codifying knowledge, and, as a result, programming languages are designed for generalists trained in this process of formalization. Artists, whose training focuses on skill and tacit knowledge, are marginalized by existing tools. By designing visual languages that take advantage of an artist's skills in visual perception and expression, we can allow that artist to take advantage of the expressive potential that modern computing offers. In particular, this paper will look at lighting design for interactive, virtual environments, and augmenting an existing programming language to allow artists to leverage their skills in the pragmatics of that medium.","1943-6106","0-7695-2443-5","10.1109/VLHCC.2005.54","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1509533","Semiotics;pragmatics;domain specific language;virtual environments","Programming profession;Computer languages;Lighting control;Virtual environment;Domain specific languages;Engines;Visual perception;Art;Design engineering;Cognitive science","art;lighting;visual languages;virtual reality;computational linguistics","artists;visual language;expressive lighting design;programming languages;visual perception;visual expression;interactive virtual environments;semiotics;pragmatics;domain specific language","","","","7","","17 Oct 2005","","","IEEE","IEEE Conferences"
"Adaptive model fitting with time-varying input variables","J. C. Spall","Appl. Phys. Lab., Johns Hopkins Univ., Laurel, MD, USA","Proceedings of the 1999 American Control Conference (Cat. No. 99CH36251)","6 Aug 2002","1999","2","","1435","1440 vol.2","Consider the long-standing problem of fitting a model to multivariate data. In many control systems, we are interested in models that are associated with tracking a nonstationary process with time-varying input variables. It is often hopeless to produce a globally valid model over the whole domain in such a setting. Further, a globally valid model is not likely to be even needed in practice since some combinations of input variables are highly unlikely to occur. For this reason, we consider an adaptive model estimation method that emphasizes local fitting. This can be implemented in an elegant way using recursive methods such as stochastic approximation. The application motivating the general approach is the construction of real-time (or faster) training simulators for use by Navy personnel; the approach would apply in many other control and tracking applications.","0743-1619","0-7803-4990-3","10.1109/ACC.1999.783606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=783606","","Input variables;Neural networks;Time varying systems;Stochastic processes;Personnel;Spline;Parameter estimation;Physics;Laboratories;Electronic mail","simulation;adaptive estimation;approximation theory;recursive estimation;computer based training","adaptive model fitting;time-varying input variables;multivariate data;nonstationary process;adaptive model estimation method;local fitting;recursive methods;stochastic approximation;real-time training simulators;Navy personnel","","3","","22","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Real Time Pathfinding with Genetic Algorithm","A. F. d. V. Machado; U. O. Santos; H. Vale; R. Gonçalvez; T. Neves; L. S. Ochi; E. W. G. Clua","Depto. Academico de Cienc. da Comput., Inst. Fed. de Educ. Tec. do Sudeste de Minas, Rio Pomba, Brazil; Depto. Academico de Cienc. da Comput., Inst. Fed. de Educ. Tec. do Sudeste de Minas, Rio Pomba, Brazil; Depto. Academico de Cienc. da Comput., Inst. Fed. de Educ. Tec. do Sudeste de Minas, Rio Pomba, Brazil; Depto. Academico de Cienc. da Comput., Inst. Fed. de Educ. Tec. do Sudeste de Minas, Rio Pomba, Brazil; Dept. de Comput., Univ. Fed. Fluminense, Niteroi, Brazil; Dept. de Comput., Univ. Fed. Fluminense, Niteroi, Brazil; Dept. de Comput., Univ. Fed. Fluminense, Niteroi, Brazil","2011 Brazilian Symposium on Games and Digital Entertainment","29 Nov 2012","2011","","","215","221","This paper presents a method to optimize the process of finding paths using a model based on genetic algorithms and A* for real time systems, such as video games, virtual reality environments. The proposed solution uses obstacle pattern detection based on online training system that is generally used in systems with real time requirements and in dynamic environments. The architecture, named Real Time Path finding with Genetic Algorithm (RTP-GA), uses a Genetic Algorithm in order to create an agent adapted to the environment that is able to optimize the search for paths even in the presence of obstacles. In specific cases, the RTP-GA architecture presents a complexity that is better than A* algorithm.","2159-6662","978-0-7695-4648-3","10.1109/SBGAMES.2011.23","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6363236","pathfinding;genetic algorithm;dynamic environment","Biological cells;Genetic algorithms;Linear programming;Heuristic algorithms;Real-time systems;Games;Vectors","computer games;genetic algorithms;real-time systems;virtual reality","video games;virtual reality environments;obstacle pattern detection;dynamic environments;real time path finding with genetic algorithm;RTP-GA","","2","","9","","29 Nov 2012","","","IEEE","IEEE Conferences"
"Overcoming the limitations of traditional media for teaching modern processor design","P. Marwedel; B. Sirocic","Dept. of Comput. Sci., Univ. of Dortmund, Dortmund, Germany; Dept. of Comput. Sci., Univ. of Dortmund, Dortmund, Germany","Proceedings 2003 IEEE International Conference on Microelectronic Systems Education. MSE'03","20 Jun 2003","2003","","","102","103","Understanding modern processors requires a good knowledge of the dynamic behavior of processors. Traditional media like books can be used for describing the dynamic be behaviour of processors. Visualization of this behavior, however, is impossible, due to the static nature of books. In this paper, we describe a Java-based tool for visualizing the dynamic behavior of hardware structures, called RaVi (abbreviation for the German equivalent of ""computer architecture visualization""). Available RaVi components include models of a microcoded MIPS architecture, of a MIPS pipeline, of scoreboarding, Tomasulo's algorithm and the MESI multiprocessor cache protocol. These models were found to be more useful than general simulators in classroom use. The Java-based design also enables Internet-based distance learning.","","0-7695-1973-3","10.1109/MSE.2003.1205274","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1205274","","Education;Process design;Visualization;Books;Java;Computer architecture;Hardware;Pipelines;Protocols;Computational modeling","Java;computer architecture;distance learning;program visualisation;computer based training;firmware;information resources","traditional media limitations;teaching;modern processor design;hardware structures;Java-based tool;computer architecture visualization;microcoded MIPS architecture;MIPS pipeline;Tomasulos algorithm;MESI multiprocessor;Internet-based distance learning;million instructions per second","","","","4","","20 Jun 2003","","","IEEE","IEEE Conferences"
"Creature Academy: A system for virtual creature evolution","M. L. Pilat; C. Jacob","Department of Computer Science, University of Calgary, AB, Canada; Department of Computer Science, University of Calgary, AB, Canada","2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)","23 Sep 2008","2008","","","3289","3297","In this paper, we present creature academy, a virtual laboratory that allows for the evolution of form and function within simulated physical 3D environments. Creature academy can be used to explore evolutionary mechanisms, design, learning and other processes studied in artificial life simulations. Our system allows to perform hierarchical evolutionary experiments and ecosystem-inspired setups to investigate bodied creatures that interact, compete, adapt, and evolve. As a first proof of concept, we use creature academy to evolve morphologies and motion strategies of virtual creatures that walk and jump. We then present results that compare hierarchical evolution scenarios to generate creatures that excel in both walking and jumping, demonstrating how to evolve from creature specialists to generalists.","1941-0026","978-1-4244-1822-0","10.1109/CEC.2008.4631243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4631243","","Training;Neurons;Biological system modeling;Evolution (biology);Artificial neural networks;Evolutionary computation;Joints","artificial life;evolutionary computation;virtual reality","virtual creature evolution;virtual laboratory;3D environments;evolutionary mechanisms;hierarchical evolutionary;ecosystem-inspired setups;hierarchical evolution scenarios","","6","","15","","23 Sep 2008","","","IEEE","IEEE Conferences"
"Counterfactual Vision and Language Learning","E. Abbasnejad; D. Teney; A. Parvaneh; J. Shi; A. van den Hengel","Australian Institute for Machine Learning & The University of Adelaide, Australia; Australian Institute for Machine Learning & The University of Adelaide, Australia; Australian Institute for Machine Learning & The University of Adelaide, Australia; Australian Institute for Machine Learning & The University of Adelaide, Australia; Australian Institute for Machine Learning & The University of Adelaide, Australia","2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","10041","10051","The ongoing success of visual question answering methods has been somwehat surprising given that, at its most general, the problem requires understanding the entire variety of both visual and language stimuli. It is particularly remarkable that this success has been achieved on the basis of comparatively small datasets, given the scale of the problem. One explanation is that this has been accomplished partly by exploiting bias in the datasets rather than developing deeper multi-modal reasoning. This fundamentally limits the generalization of the method, and thus its practical applicability. We propose a method that addresses this problem by introducing counterfactuals in the training. In doing so we leverage structural causal models for counterfactual evaluation to formulate alternatives, for instance, questions that could be asked of the same image set. We show that simulating plausible alternative training data through this process results in better generalization.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.01006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156448","","Training;Visualization;Training data;Task analysis;Machine learning;Knowledge discovery;Data models","case-based reasoning;data visualisation;human computer interaction;inference mechanisms;learning (artificial intelligence);question answering (information retrieval)","language learning;ongoing success;visual question answering methods;visual language;multimodal reasoning;counterfactuals;structural causal models;counterfactual evaluation;plausible alternative training data;counterfactual vision","","1","","42","","5 Aug 2020","","","IEEE","IEEE Conferences"
"Using hardware and software studies to teach power-system modeling and analysis","A. Shrestha; R. W. Cox; Z. Salami; J. Anderson; P. Parikh","University of North Carolina-Charlotte, Charlotte, NC, 28223; University of North Carolina-Charlotte, Charlotte, NC, 28223; AREVA NP, Charlotte, NC; University of North Carolina-Charlotte, Charlotte, NC, 28223; University of North Carolina-Charlotte, Charlotte, NC, 28223","2009 IEEE Power & Energy Society General Meeting","2 Oct 2009","2009","","","1","6","The power industry desperately needs talented young engineers. Researchers in the ECE Department at UNC Charlotte (UNCC) have partnered with AREVA to address this issue. Together, we have developed new curricula that tightly integrate theory with practice. This paper describes a three-level approach used in the senior-level electric machines course at UNCC. In this course, students move directly from theory to hands-on exploration to real-world application. Following the first two stages of that process, students are able to model individual components. Using that ability, they then analyze a complete system. The course culminates in a design project focused on the design of a small power system similar to that encountered in a generating station. Specific curriculum examples are discussed, and some feedback on the initial offerings is presented.","1932-5517","978-1-4244-4241-6","10.1109/PES.2009.5275243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5275243","education;power engineering education","Hardware;Power engineering and energy;Power system modeling;Electric machines;Industrial training;Power industry;Educational institutions;Laboratories;Power system analysis computing;Nuclear power generation","design engineering;educational courses;electric machines;power engineering education;power system simulation;student experiments","power-system modeling;power industry;ECE Department;UNC Charlotte;AREVA;teaching;senior-level electric machine course;design project;generating station","","","","9","","2 Oct 2009","","","IEEE","IEEE Conferences"
"Cost-effective virtual world development for serious games","H. Liu; Y. Arafa; C. Boldyreff; M. Dastbaz","University of East London, UK; University of East London, UK; University of East London, UK; University of East London, UK","2011 IEEE International Games Innovation Conference (IGIC)","29 Dec 2011","2011","","","48","51","Developing a virtual world environment from scratch normally involves a large number of model creations, animations and event simulations. Such undertakings generally require a large amount of man-hours and expensive software. This paper introduces an open-source approach that will enable developers to easily and quickly create scenario-driven collaborative environments for serious games. A case study based on the development of a virtual crisis room in the Pandora project1 is provided to demonstrate the effectiveness of the approach.","2166-675X","978-1-4577-0259-4","10.1109/IGIC.2011.6115129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6115129","","Training;Games;Avatars;Three dimensional displays;Second Life;Engines;Open source software","computer games;virtual reality","cost effective virtual world development;serious games;open source approach;collaborative environments;virtual crisis room;Pandora project1","","1","","16","","29 Dec 2011","","","IEEE","IEEE Conferences"
"Haptic Perception of Material Properties and Implications for Applications","R. L. Klatzky; D. Pawluk; A. Peer","Department of Psychology and the Human-Computer Interaction Institute , Carnegie Melon University, Pittsburgh, PA , USA; Department of Biomedical Engineering, Virginia Commonwealth University, Richmond, VA, USA; Institute of Automatic Control Engineering, Technische Universitäat München, Munich, Germany","Proceedings of the IEEE","16 Aug 2013","2013","101","9","2081","2092","Perceiving the material properties of objects through touch is generally superior to the perception of shape. We review major material properties accessible through haptic interaction, along with theoretical accounts of the underlying perceptual processes. These include roughness, friction, compliance, and thermal properties. Subsequently, we describe algorithms that have been used to render these same material properties on haptic devices. We then point to applications that have capitalized on the accessibility of material through touch, including tactile displays, simulation of mechanical mechanisms in the automobile, and medical training simulators.","1558-2256","","10.1109/JPROC.2013.2248691","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6510431","Applications;haptic perception;haptic rendering","Haptic interfaces;Rendering (computer graphics);Shape analysis;Algorithm design and analysis","digital simulation;haptic interfaces","haptic perception;material properties;shape perception;friction;thermal properties;haptic devices;tactile displays;mechanical mechanisms;automobile simulators;medical training simulators","","9","","128","","30 Apr 2013","","","IEEE","IEEE Journals"
"e-Kampus-IS: information system for a virtual university consortium","P. Onay; N. Yalabik; G. Koksal","Informatics Inst., Middle East Tech. Univ., Bulvari, Turkey; Informatics Inst., Middle East Tech. Univ., Bulvari, Turkey; Informatics Inst., Middle East Tech. Univ., Bulvari, Turkey","2005 6th International Conference on Information Technology Based Higher Education and Training","19 Dec 2005","2005","","","S3A/1","S3A/6","In this study, an information system for a virtual university consortium is designed. This consortium is assumed to be formed by a large number of educational institutions from diverse geographical regions as well as some private companies specialized on e-learning. A hybrid learning approach according to which students spend part of their time in the nearest campus is planned. The organizational, technical and educational models of the system are proposed. A centralized structure with tight connections to local universities is designed. Traditional organizational functions are to be handled by current units and new units are proposed to perform functions specific to a virtual university. The technical model that interconnects the central and local institutions is developed. Network infrastructure, how data flow is handled among institutions and the software infrastructure are determined. The software unifies the general services provided by traditional universities, and services specific to a virtual university.","","0-7803-9141-1","10.1109/ITHET.2005.1560324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1560324","Virtual University;university consortium;organizational;technical and educational models","Information systems;Educational institutions;Educational programs;Electronic learning;Internet;Government;Informatics;Computer aided instruction;Virtual environment;Education","computer aided instruction;distance learning;information systems;educational institutions;Internet","e-Kampus-IS;information system;virtual university consortium;educational institution;e-learning;hybrid learning;educational model;organizational model;network infrastructure;software infrastructure;technical model","","","","7","","19 Dec 2005","","","IEEE","IEEE Conferences"
"Learning Algorithms for Human–Machine Interfaces","Z. Danziger*; A. Fishbach; F. A. Mussa-Ivaldi","Northwestern Univ., Evanston, IL; Sensory Motor Performance Program, Rehabilitation Inst. of Chicago, Chicago, IL; Northwestern Univ., Evanston, IL","IEEE Transactions on Biomedical Engineering","26 May 2009","2009","56","5","1502","1511","The goal of this study is to create and examine machine learning algorithms that adapt in a controlled and cadenced way to foster a harmonious learning environment between the user and the controlled device. To evaluate these algorithms, we have developed a simple experimental framework. Subjects wear an instrumented data glove that records finger motions. The high-dimensional glove signals remotely control the joint angles of a simulated planar two-link arm on a computer screen, which is used to acquire targets. A machine learning algorithm was applied to adaptively change the transformation between finger motion and the simulated robot arm. This algorithm was either LMS gradient descent or the Moore-Penrose (MP) pseudoinverse transformation. Both algorithms modified the glove-to-joint angle map so as to reduce the endpoint errors measured in past performance. The MP group performed worse than the control group (subjects not exposed to any machine learning), while the LMS group outperformed the control subjects. However, the LMS subjects failed to achieve better generalization than the control subjects, and after extensive training converged to the same level of performance as the control subjects. These results highlight the limitations of coadaptive learning using only endpoint error reduction.","1558-2531","","10.1109/TBME.2009.2013822","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4776455","Adaptive learning;hand posture;human–machine interface;machine learning","Machine learning algorithms;Machine learning;Fingers;Computational modeling;Least squares approximation;Control systems;Electronic mail;Instruments;Data gloves;Computer simulation","biocybernetics;data gloves;gradient methods;human-robot interaction;learning (artificial intelligence);least mean squares methods;telecontrol","human-machine interfaces;machine learning algorithms;data glove;finger motions;high dimensional glove signals;remote control;simulated planar two link arm;simulated robot arm;least mean square gradient descent;Moore-Penrose pseudoinverse transformation","Algorithms;Artificial Intelligence;Communication Aids for Disabled;Hand;Humans;Man-Machine Systems;Multivariate Analysis;Posture;Psychomotor Performance;Robotics;Signal Processing, Computer-Assisted;User-Computer Interface","32","","31","","6 Feb 2009","","","IEEE","IEEE Journals"
"Construction of an Execution Environment using Container Type Virtualization for a Support System of Programming Exercises with Game Strategies and Contests","T. Shimizu; H. Tominaga","Graduate School of Engineering, Kagawa University,Takamatsu,Japan; Faculty of Engineering and Design, Kagawa University,Takamatsu,Japan","2019 18th International Conference on Information Technology Based Higher Education and Training (ITHET)","23 Dec 2019","2019","","","1","8","We have proposed applied programming exercises with game strategies. This exercise is a contest style using poker game and board game strategy. In these exercises, each support system provides its own execution environment. To experience continuous integration, we have set a preliminary contest period to accept submissions many times. During this period, a large amount of code execution is performed on the server-side. Due to this, the presentation of the execution results is delayed. In this research, we have developed an independent and safe program execution platform Cachalot suitable for programming exercises using game strategies. The purpose is to improve the response quality to the learners and to consolidate and generalize the execution environment that each support system has been uniquely implemented. We implemented distributed execution with multiple computers using a container type virtual environment. To evaluate this method, we applied Cachalot to the exercise support system WinT for a poker exercise. We experimented on response quality and collected indicators such as processing time. This confirmed the effectiveness of the proposed method for response quality.","2380-1603","978-1-7281-2464-3","10.1109/ITHET46829.2019.8937341","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937341","Game strategy;Applied programming exercise;Load balancing;Container type virtualization","Games;Programming profession;Education;Virtual environments;Servers;Containers","computer aided instruction;computer science education;programming;serious games (computing);virtual reality;virtualisation","poker exercise;response quality;container type virtualization;programming exercises;game strategies;poker game;board game strategy;code execution;program execution platform;container type virtual environment;WinT support system;Cachalot;game contests","","","","11","","23 Dec 2019","","","IEEE","IEEE Conferences"
"New applications of multimodal human-computer interfaces","A. Czyżewski","Gdansk University of Technology, Multimedia Systems Department 80-233 Gdansk, Poland, ul. Narutowicza 11/12","2012 Joint Conference New Trends In Audio & Video And Signal Processing: Algorithms, Architectures, Arrangements And Applications (NTAV/SPA)","16 Apr 2015","2012","","","19","24","Multimodal computer interfaces and examples of their applications to education software and for the disabled people are presented. The proposed interfaces include the interactive electronic whiteboard based on video image analysis, application for controlling computers with gestures and the audio interface for speech stretching for hearing impaired and stuttering people. Application of the eye-gaze tracking system to awareness evaluation is demonstrated. The proposed method assumes analysis of visual activity of patients remaining in vegetative state. The scent emitting multimo-dal computer interface is an important supplement of the polysen-soric stimulation process, playing an essential role in education and therapy of children with developmental disorders. A new approach to diagnosing Parkinson's disease is shown. The progression of the disease can be measured by the UPDRS (Unified Parkinson Disease Rating Scale) scale which is used for evaluating motor and behavioral symptoms of Parkinson's disease, employing the multimo-dal interface called Virtual-Touchpad (VTP) to support medical diagnosis. The paper is concluded with some general remarks concerning the role of multimodal computer interfaces applied to learning, therapy and everyday usage of computerized devices.","2326-0319","978-8-3620-6514-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7085506","multimodal interfaces;video processing;speech processing","Speech;Streaming media;Auditory system;Cameras;Signal processing algorithms;Algorithm design and analysis;Training","computer aided instruction;diseases;gaze tracking;gesture recognition;handicapped aids;human computer interaction;interactive systems;medical diagnostic computing;medical disorders;patient diagnosis;speech-based user interfaces;touch sensitive screens;video signal processing","scent emitting multimodal human-computer interfaces;education software;disabled people;interactive electronic whiteboard;video image analysis;audio interface;gestures;speech stretching;hearing impaired people;stuttering people;eye-gaze tracking system;awareness evaluation;visual activity analysis;vegetative state;polysensoric stimulation process;developmental disorders;Parkinson's disease diagnosis;UPDRS scale;unified Parkinson disease rating scale;motor symptoms;behavioral symptoms;virtual-touchpad;VTP;medical diagnosis;computerized devices","","","","9","","16 Apr 2015","","","IEEE","IEEE Conferences"
"Field evaluation of data link services for general aviation","D. C. Chandra; D. J. Bernays; S. R. Bussolari","Lincoln Lab., MIT, Lexington, MA, USA; Lincoln Lab., MIT, Lexington, MA, USA; Lincoln Lab., MIT, Lexington, MA, USA","Proceedings of 14th Digital Avionics Systems Conference","6 Aug 2002","1995","","","258","263","Data link traffic and weather services have been developed for general aviation: The Traffic Information Service (TIS) displays ground-based traffic information, Graphical Weather Service (GWS) disseminates graphical precipitation maps, and Text Weather Service (TWS) provides surface observations and terminal forecasts. Development of the data link applications has now reached the field evaluation stage. Plans are to equip a limited number of light aircraft with the data link avionics for a six-month period. The services are provided via the Dulles Mode S sensor and a ground transmit/receive station installed in Frederick, MD. Pilot evaluators have access to the services on structured evaluation flights and routine business flights. Evaluators will assess each of the services, the training procedures, and the cockpit interface.","","0-7803-3050-1","10.1109/DASC.1995.482837","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=482837","","Weather forecasting;Laboratories;FAA;Aircraft;Aerospace electronics;Air traffic control;Displays;Testing;Road accidents;Force sensors","aircraft displays;human factors;traffic information systems;traffic engineering computing;air traffic control;ground support systems;weather forecasting;meteorological radar;aircraft computers;data communication;aerospace simulation;aircraft communication","general aviation;data link services;field evaluation;graphical weather services;ground-based traffic information;traffic information service;graphical precipitation maps;text weather service;surface observations;terminal forecasts;light aircraft;data link avionics;Dulles Mode S sensor;ground transmit/receive station;structured evaluation flights;routine business flights;pilot training procedure;cockpit interface;system implementation","","4","","6","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Improvement of human hand motion observation by exploiting contact force measurements","P. Falco; R. Jäkel; C. Natale; R. Dillmann","Dipartimento di Ingegneria dell'Informazione, Seconda Università di Napoli, 81031 Aversa (CE), Italy; Institute for Anthropomatics, Karlsruhe Institute of Technology, 76131, Germany; Dipartimento di Ingegneria dell'Informazione, Seconda Università di Napoli, 81031 Aversa (CE), Italy; Institute for Anthropomatics, Karlsruhe Institute of Technology, 76131, Germany","2011 11th IEEE-RAS International Conference on Humanoid Robots","12 Dec 2011","2011","","","141","146","The aim of this paper is to present a novel method to improve the observation of the human hand motion, exploiting the measurements of fingertip contact forces. The core idea of the proposed algorithm is to compare the fingertip contact information, obtained by commercial tactile sensors, with the contact information computed in a virtual environment, that reproduces the real environment in which the observation is carried out. In case the estimation of the joint angles and the relative pose between the hand and the object are accurate, the contact information in the virtual and in the real environment are consistent. On the other hand, when the two sources of information are not consistent, a correction of the hand posture is applied. The algorithm has been designed to work on-line. In general, this feature is particulary important for Programming by Demonstration (PbD) applications, since it allows the trainer to actively adapt the demonstration to measurement noise and model errors. The effectiveness of the proposed method has been tested in three different tasks: grasping a cup, unscrewing a bottle, grasping a plate.","2164-0580","978-1-61284-868-6","10.1109/Humanoids.2011.6100858","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6100858","","Computational modeling;Humans;Joints;Sensors;Solid modeling;Kinematics;Force measurement","force measurement;tactile sensors;virtual reality","human hand motion observation;exploiting contact force measurements;fingertip contact forces;fingertip contact information;tactile sensors;contact information;virtual environment;hand posture;programming by demonstration;PbD","","3","","19","","12 Dec 2011","","","IEEE","IEEE Conferences"
"Stereo matching with VG-RAM Weightless Neural Networks","L. de Paula Veronese; L. J. Lyrio Junior; F. W. Mutz; J. de Oliveira Neto; V. Barbirato Azevedo; M. Berger; A. Ferreira De Souza; C. Badue","Dept. de Inf., Univ. Fed. do Espirito Santo, Vitoria, Brazil; Dept. de Inf., Univ. Fed. do Espirito Santo, Vitoria, Brazil; Dept. de Inf., Univ. Fed. do Espirito Santo, Vitoria, Brazil; Dept. de Inf., Univ. Fed. do Espirito Santo, Vitoria, Brazil; Dept. de Inf., Univ. Fed. do Espirito Santo, Vitoria, Brazil; Dept. de Inf., Univ. Fed. do Espirito Santo, Vitoria, Brazil; Dept. de Inf., Univ. Fed. do Espirito Santo, Vitoria, Brazil; Dept. de Inf., Univ. Fed. do Espirito Santo, Vitoria, Brazil","2012 12th International Conference on Intelligent Systems Design and Applications (ISDA)","24 Jan 2013","2012","","","309","314","Virtual Generalizing Random Access Memory Weightless Neural Networks (VG-RAM WNN) is an effective machine learning technique that offers simple implementation and fast training and test. We examined the performance of VG-RAM WNN on binocular dense stereo matching using the Middlebury Stereo Datasets. Our experimental results showed that, even without tackling occlusions and discontinuities in the stereo image pairs examined, our VG-RAM WNN architecture for stereo matching was able to rank at 114th position in the Middlebury Stereo Evaluation system. This result is promising, because the difference in performance among approaches ranked in distinct positions is very small.","2164-7151","978-1-4673-5119-5","10.1109/ISDA.2012.6416556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6416556","Binocular Dense Stereo Matching;VG-RAM Weightless Neural Networks;Middlebury Stereo Vision Page","Neurons;Random access memory;Biological neural networks;Cameras;Training;Venus;Computer architecture","image matching;learning (artificial intelligence);neural nets;random-access storage;stereo image processing;virtual reality","stereo matching;virtual generalizing random access memory weightless neural networks;VG-RAM WNN;machine learning technique;middlebury stereo datasets","","","","21","","24 Jan 2013","","","IEEE","IEEE Conferences"
"The need for a Real Time Strategy game language","R. Hayes; P. Beling; W. Scherer","University of Virginia, System and Information Engineering, 151 Engineer's Way, Charlottesville, 22904, USA; University of Virginia, System and Information Engineering, 151 Engineer's Way, Charlottesville, 22904, USA; University of Virginia, System and Information Engineering, 151 Engineer's Way, Charlottesville, 22904, USA","Proceedings of the Winter Simulation Conference 2014","26 Jan 2015","2014","","","3495","3504","Real Time Strategy (RTS) games provide complex domain to test the latest artificial intelligence (AI) research. In much of the literature, AI systems have been limited to playing one game. Although, this specialization has resulted in stronger AI gaming systems it does not address the key concerns of AI research, which focuses on the development of AI agents that can autonomously interpret, learn, and apply new knowledge. To achieve human level performance, current AI systems rely on game specific knowledge of an expert. This paper proposes a RTS language in hopes of shifting the current research focus to the development of general RTS agents. General RTS agents are AI gaming systems that can play any RTS game, defined in the proposed RTS language. The structure of the RTS language prevents game specific knowledge from being hard coded into the system, thereby facilitating research that addresses the fundamental concerns of artificial intelligence.","1558-4305","978-1-4799-7486-3","10.1109/WSC.2014.7020181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7020181","","Games;Artificial intelligence;Real-time systems;Buildings;Autonomous agents;Resource management;Training","artificial intelligence;computer games;real-time systems;XML","real-time strategy game language;RTS game language;complex domain;artificial intelligence research test;AI research test;AI gaming systems;AI agent development;human level performance;game specific expert knowledge;general agents;game specific knowledge prevention","","","","18","","26 Jan 2015","","","IEEE","IEEE Conferences"
"DeepDriving: Learning Affordance for Direct Perception in Autonomous Driving","C. Chen; A. Seff; A. Kornhauser; J. Xiao",NA; NA; NA; NA,"2015 IEEE International Conference on Computer Vision (ICCV)","18 Feb 2016","2015","","","2722","2730","Today, there are two major paradigms for vision-based autonomous driving systems: mediated perception approaches that parse an entire scene to make a driving decision, and behavior reflex approaches that directly map an input image to a driving action by a regressor. In this paper, we propose a third paradigm: a direct perception approach to estimate the affordance for driving. We propose to map an input image to a small number of key perception indicators that directly relate to the affordance of a road/traffic state for driving. Our representation provides a set of compact yet complete descriptions of the scene to enable a simple controller to drive autonomously. Falling in between the two extremes of mediated perception and behavior reflex, we argue that our direct perception representation provides the right level of abstraction. To demonstrate this, we train a deep Convolutional Neural Network using recording from 12 hours of human driving in a video game and show that our model can work well to drive a car in a very diverse set of virtual environments. We also train a model for car distance estimation on the KITTI dataset. Results show that our direct perception approach can generalize well to real driving images. Source code and data are available on our project website.","2380-7504","978-1-4673-8391-2","10.1109/ICCV.2015.312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7410669","","Roads;Games;Automobiles;Training;Neural networks;Robots;Testing","computer games;computer vision;neural nets;road traffic;traffic engineering computing;virtual reality","KITTI dataset;car distance estimation;virtual environments;video game;convolutional neural network;direct perception representation;behavior reflex;traffic state;road state;mediated perception approaches;vision-based autonomous driving systems","","497","7","22","","18 Feb 2016","","","IEEE","IEEE Conferences"
"Can Two-Player Games Increase Motivation in Rehabilitation Robotics?","D. Novak; A. Nagle; R. Riener","ETH Zurich, Tannenstrasse 1, TAN E3, Zurich, CH-8092, Switzerland; ETH Zurich, Sonneggstrasse 3, ML G53.2, Zurich, CH-8092, Switzerland; ETH Zurich, Tannenstrasse 1, TAN E4, Zurich, CH-8092, Switzerland","2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","22 Nov 2018","2014","","","447","454","Rehabilitation robots have the potential to greatly improve motor rehabilitation. However, the patient must be properly motivated to actively participate in therapy. Several strategies have been suggested to improve patient motivation, but one element has not yet been explored: playing with other people. We designed a two-player rehabilitation game played by two people using two ARMin III robots. We tested three game modes: single-player (competing against a computer), competitive (competing against a human), and cooperative (cooperating with a human against a computer). All modes were played by 24 healthy subjects who filled out questionnaires about their personality and in-game motivation. Almost all subjects preferred playing the two-player game modes to the single-player one, as they enjoyed being able to talk and interact with another person. However, there were two distinct player groups. One group liked the competitive mode but not the cooperative mode while the other liked the cooperative but not the competitive mode. Subjects who liked the competitive mode also put more effort into it. Finally, subjects' personalities partially predicted what mode they would like. This emphasizes that two-player rehabilitation games have advantages over single-player ones, but that the right game needs to be chosen for each subject. An extended patient study is planned for the near future. Categories and Subject Descriptors H.1.2 [User/Machine Systems]: Human factors. H.5.1 [Multimedia Information Systems]: Artificial, augmented and virtual realities. J.3 [Life and Medical Sciences]: Health. General Terms Design, Experimentation, Human Factors.","2167-2121","978-1-4503-2658-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8542474","Rehabilitation robotics;virtual reality;multiplayer games;motivation.","Games;Rehabilitation robotics;Virtual reality;Medical treatment;Training;Manipulators","computer games;human factors;medical robotics;patient rehabilitation","two-player rehabilitation game;rehabilitation robotics;rehabilitation robots;motor rehabilitation;patient motivation;ARMin III robots;in-game motivation;robotic interfaces","","","","29","","22 Nov 2018","","","IEEE","IEEE Conferences"
"Rapid recovery: a kayaking-based exergame for shoulder rehabilitation and physical fitness","B. Shroeder; M. Kunanec; B. Kroese; O. Pollard; O. Sadoon; B. Kapralos; J. Brennan; E. Leach; J. Jenson","Business and Information Technology, University of Ontario Institute of Technology, Oshawa, Canada. L1H 7K4; Business and Information Technology, University of Ontario Institute of Technology, Oshawa, Canada. L1H 7K4; Business and Information Technology, University of Ontario Institute of Technology, Oshawa, Canada. L1H 7K4; Business and Information Technology, University of Ontario Institute of Technology, Oshawa, Canada. L1H 7K4; Department of Kinesiology, York University, Toronto, Canada. M3J 1P3; Business and Information Technology, University of Ontario Institute of Technology, Oshawa, Canada. L1H 7K4; Northern Ontario School of Medicine, Sudbury, Canada. P3E 2C6; Georgian College, Toronto, Canada. M3J 1P3; Department of Education, York University, Toronto, Canada. M3J 1P3","2014 IEEE Games Media Entertainment","27 Aug 2015","2014","","","1","4","We present Rapid Recovery, a novel engaging exergame intended to facilitate shoulder rehabilitation, and physical fitness through a kayak simulation across several courses/scenarios. Central to Rapid Recovery is the Spincore Inc. Helium 6 baton, a unique stand-alone fitness and rehabilitation device. Using a Microsoft Kinect stereo vision sensor, the player's kayak paddling motions of the Helium 6 baton are captured at interactive rates, and mapped to movements in the game world. Rapid Recovery supports multiple players, allowing the opportunity for players to race each other. Rapid Recovery provides users with an engaging, interactive, motivating and fun environment while promoting physical rehabilitation, and general physical fitness.","","978-1-4799-7546-4","10.1109/GEM.2014.7224735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7224735","Serious games;exergaming;physical fitness;shoulder rehabilitation","Games;Helium;Tutorials;Shoulder;Injuries;Training","serious games (computing);sport;stereo image processing","Helium 6 baton;Microsoft Kinect stereo vision sensor;kayak simulation;physical fitness;shoulder rehabilitation;kayaking-based exergame;novel engaging exergame;rapid recovery","","5","","13","","27 Aug 2015","","","IEEE","IEEE Conferences"
"Study on force display system using couple of ER brakes","K. Koyanagi; J. Furusho; Li-Cheng Dong","Dept. of Eng., Osaka Univ., Japan; Dept. of Eng., Osaka Univ., Japan; Dept. of Eng., Osaka Univ., Japan","2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)","14 Feb 2005","2004","4","","3251","3256 vol.4","Force information in virtual space is important and often required for tele-operation, training, amusement, design supporting and other virtual reality systems. While conventional force displays are active systems with actuators and therefore may become inherently dangerous, passive force displays, which use only passive elements, are an effective methods for assuring safety. However, passive type systems have some directions and link postures, which are hard to present force. To this problem, a method for improvement of controllability using redundant couple of brakes had been suggested. It was able to be considered this method made it possible to display various force directions and various postures of virtual objects. The purpose of this study was, for further improvement of controllability of systems with redundant couples of brakes, design and development of more generalized redundant mechanism by adding another element of design freedom. Moreover, improvement of force display-ability by reducing equivalent inertia was also aimed. In this paper, the developed system was outlined and basic experiments with it discussed.","","0-7803-8463-6","10.1109/IROS.2004.1389918","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1389918","","Displays;Erbium;Force sensors;Safety;Control systems;Force measurement;Controllability;Virtual reality;Haptic interfaces;TV","controllability;electrorheology;force feedback;virtual reality","force display system;controllability;electrorheological fluid brake;passive force display;virtual object","","8","","10","","14 Feb 2005","","","IEEE","IEEE Conferences"
"Software design for the evaluation of competency based learning in engineering careers Ontological approach for modeling","L. Romero; M. Gutiérrez","Universidad Nacional del Litoral,GIDIS Research Group Facultad de Ingeniería y Ciencias Hídricas,Santa Fe,Argentina; CIDISI Research Center UTN - Facultad Regional Santa Fe,Santa Fe,Argentina","2020 15th Iberian Conference on Information Systems and Technologies (CISTI)","15 Jul 2020","2020","","","1","6","Nowadays, in engineering careers, it is necessary to carry out activities that allow evaluation of the training process based on professional skills. This implies generating mechanisms that enable the assessment of learning based on quantitative and qualitative criteria from which competence levels of learning are defined. In this sense, it is necessary to arbitrate the means to determine performance of students before real or simulated activities of the future professional context. In this work, authors propose an ontological model as part of the design of a software. It involves the definition of the evaluation activities for the learning process based on competencies in engineering careers, such as definition of level of domain indicators, criteria and evidence determination, weights and scores specification, which accredit professional performance and stimulate the necessary feedback to complete this process. In this way, authors seek to collaborate with professors, academic management staff and other university actors who want to improve the quality of learning through new educational paradigms such as learning by competencies, since carrying out an appropriate evaluation is a task pending in education in general, and in the training of engineers in particular, mainly because of its complexity.","2166-0727","978-989-54659-0-3","10.23919/CISTI49556.2020.9140954","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9140954","ontology;e-learning;ontology network;professional competencies;curriculum","Engineering profession;Information systems;Training;Adaptation models;Software design;Electronic mail","computer aided instruction;continuing professional development;educational institutions;engineering education;learning (artificial intelligence);ontologies (artificial intelligence);software engineering","software design;engineering careers;training process;professional skills;ontological model;learning process;evidence determination;professional performance;competency based learning evaluation","","","","0","","15 Jul 2020","","","IEEE","IEEE Conferences"
"Supplemental Cultivation Plan of Innovation Quality for the Undergraduates of Building Environment and Energy Engineering in the Applied Technology Universities","Q. Qiu; Y. Hu; J. Liu; Q. Liu; Z. Dong","Wuhan Business University,School of Mechanical and Electrical Engineering,Dept. of Building Environment and Energy Engineering,Wuhan,China; Wuhan Business University,School of Mechanical and Electrical Engineering,Dept. of Building Environment and Energy Engineering,Wuhan,China; Wuhan Business University,School of Mechanical and Electrical Engineering,Dept. of Building Environment and Energy Engineering,Wuhan,China; Wuhan Business University,School of Mechanical and Electrical Engineering,Dept. of Building Environment and Energy Engineering,Wuhan,China; Wuhan Business University,School of Mechanical and Electrical Engineering,Dept. of Building Environment and Energy Engineering,Wuhan,China","2020 International Conference on Artificial Intelligence and Education (ICAIE)","23 Nov 2020","2020","","","459","462","One of the most fundamental qualities for science research and technology development is the innovation quality, which covers many aspects such as consciousness, method and spirit. The innovation quality developed in the undergraduate period would be the most basic foundation in their over forty-years working life. A supplemental cultivation plan with a routine consisting of hardware, programming, simulation and optimization was presented in this paper for the undergraduates of Building Environment and Energy Engineering (BEEE). The hardware manufacture of digital devices was trained to promote the freshmen manipulative capability, while software programming with general-purpose languages was introduced to enhance the comprehension of data analysis in the 2nd academic year. During the period when some professional courses were taught, the building simulation modular could be introduced to enhance the understanding for the building thermal process and its corresponding Heating, Ventilating, Air-conditioning and Refrigeration (HVAC & R) system. A building management system (BMS) would be developed step by step and interactive with virtual building platform. That BMS and its virtual cases could be employed as the testbed for optimization of HVAC & R system, such as energy consumption prediction, fault detection and diagnosis. Python and EnergyPlus were used in the custom training program oriented to the employment direction for the system operation and maintenance. Group achievements and individual cases show that the presented supplemental cultivation plan played a very important role in the cultivation of BEEE graduates' innovative quality. The effect for the graduated students need pay more attention to investigate the long-term effects, and more volunteers will participate in this plan to find out their better future.","","978-1-7281-6659-9","10.1109/ICAIE50891.2020.00111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262525","cultivation plan;innovation quality;applied technology university;building environment and energy engineering;operation and maintenance","Buildings;Training;Technological innovation;Software;Python;Programming;Maintenance engineering","building management systems;computer aided instruction;data analysis;educational courses;educational institutions;electrical engineering education;energy consumption;further education;HVAC;virtual reality","building simulation modular;building thermal process;building management system;virtual building platform;HVAC & R system;custom training program;supplemental cultivation plan;air conditioning and refrigeration system;building environment and energy engineering;BEEE undergraduates;professional courses;Python;EnergyPlus;system operation;system maintenance;software programming;hardware manufacture;applied technology universities;innovation quality","","","","6","","23 Nov 2020","","","IEEE","IEEE Conferences"
"Resting state functional connectivity and task-related effective connectivity changes after upper extremity rehabilitation: a pilot study","S. Saleh; S. V. Adamovich; E. Tunik","New Jersey Institute of Technology, Newark, 07102 USA; New Jersey Institute of Technology, Newark, 07102 USA; School of Health Related Professions and the school of Biomedical Sciences at the University of Medicine and Dentistry, Newark, 07107, USA","2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society","10 Nov 2012","2012","","","4559","4562","In this study we investigated the effect of 2 weeks of robot-aided virtual reality therapy for the paretic upper limb in stroke patients on changes in brain activation. Brain activation was acquired during the resting state and during visually-guided hand movement. fMRI analysis focused on characterizing functional connectivity with ipsilesional primary motor cortex (iM1) at rest and during execution of paretic hand movement. Two subjects who sustained a stroke more than 6 months ago participated. Before and after the training period, motor function was evaluated (Wolf Motor Function Test [WMFT], Jebsen Test of Hand Function [JTHF]). After the training period, clinical outcomes (WMFT and JTHF) improved in both subjects. The resting state functional connectivity (rsFC) maps and task-related functional connectivity with iM1 showed different magnitudes of activation, however, the general directionality of the pattern (increases versus decreases) was similar. Specifically, both the rsFC and the task-related functional connectivity between iM1 and contralesional primary motor cortex (cM1) decreased after the therapy for the first subject and increased for the second subject. Our preliminary data suggest that resting state functional connectivity may be a useful measure of brain reorganization, particularly for subjects with limited volitional control of the paretic limb.","1558-4615","978-1-4577-1787-1","10.1109/EMBC.2012.6346981","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6346981","stroke;fMRI connectivity;brain reorganization;hand rehabilitation","Training;Kinematics;Medical treatment;Lesions;Robots;Magnetic resonance imaging;Correlation","biomedical MRI;medical disorders;medical robotics;neurophysiology;patient rehabilitation;virtual reality","resting state functional connectivity;task related effective connectivity change;upper extremity rehabilitation;robot aided virtual reality therapy;paretic upper limb;stroke patients;brain activation;visually guided hand movement;fMRI analysis;ipsilesional primary motor cortex;paretic hand movement;Wolf Motor Function Test;Jebsen Test of Hand Function;task related functional connectivity","Aged;Brain Mapping;Connectome;Humans;Magnetic Resonance Imaging;Male;Middle Aged;Motor Cortex;Movement;Neuronal Plasticity;Paresis;Paresis;Paresis;Pilot Projects;Psychomotor Performance;Recovery of Function;Rest;Treatment Outcome;Upper Extremity","3","","20","","10 Nov 2012","","","IEEE","IEEE Conferences"
"Classification of college students' mobile learning strategies based on principal component analysis and probabilistic neural network","Shuai Hu; Yingxin Cheng","Teaching and Research Institute of Foreign Languages, Bohai University, Jinzhou, China; Teaching and Research Institute of Foreign Languages, Bohai University, Jinzhou, China","2015 4th International Conference on Computer Science and Network Technology (ICCSNT)","16 Jun 2016","2015","01","","58","61","To increase classification accuracy of college students' mobile learning (m-learning) strategies in foreign language learning, a classification model based on principal component analysis (PCA) and probabilistic neural network (PNN) is proposed. First, an index system of college student m-learning strategy evaluation was established. Second, PCA was employed to reduce the dimensions of the original data of students' m-learning strategies obtained through questionnaire. Five principal components were extracted to be the input variables of PNN to create a PCA-PNN classification model. Third, a simulation experiment was done to compare the classification effectiveness of the established PCA-PNN model with a PNN model and a BPNN model. The experiment result shows that the PCA-PNN model has simpler network architecture, faster convergence speed, higher accuracy and better generalization ability, which proves the effectiveness of the proposed model.","","978-1-4673-8173-4","10.1109/ICCSNT.2015.7490708","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7490708","principal component analysis;probabilistic neural network;classification;mobile learning strategy","Principal component analysis;Neurons;Training;Neural networks;Mobile computing;Mobile communication;Probabilistic logic","convergence;further education;generalisation (artificial intelligence);mobile learning;neural nets;pattern classification;principal component analysis","college student mobile learning strategy classification;principal component analysis;probabilistic neural network;m-learning;foreign language learning;principal component extraction;PCA-PNN classification model;convergence speed;generalization ability","","","","9","","16 Jun 2016","","","IEEE","IEEE Conferences"
"Exploiting Transfer Learning for Emotion Recognition Under Cloud-Edge-Client Collaborations","D. Wu; X. Han; Z. Yang; R. Wang","Chongqing Key Laboratory of Optical Communication and Networks, Chongqing Key Laboratory of Ubiquitous Sensing and Networking, School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Optical Communication and Networks, Chongqing Key Laboratory of Ubiquitous Sensing and Networking, School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Optical Communication and Networks, Chongqing Key Laboratory of Ubiquitous Sensing and Networking, School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China","IEEE Journal on Selected Areas in Communications","14 Jan 2021","2021","39","2","479","490","Emerging virtual reality/augmented reality games and self-driving cars necessitate accurate/responsive/private emotion recognition. Usually, traditional emotion recognition models are deployed at central servers, which results in the lack of abilities in generalization and covering the individual variation of clients. This paper proposes a responsive, localized, and private transfer learning based emotion recognition framework under the cloud-edge-client collaborations. Additionally, a 3-dimensional channel mapping method is designed to aggregate features extracted from electroencephalogram (EEG) signals for the generic emotion recognition model, which is further localized and personalized using transfer learning. Simulation results validate the performance of the proposed TLER framework in reducing model training time and improving emotion recognition accuracy.","1558-0008","","10.1109/JSAC.2020.3020677","National Natural Science Foundation of China; Science and Technology Research Program of Chongqing Municipal Education Commission; Natural Science Foundation of Chongqing of China; Science and Technology Research Program of Chongqing Municipal Education Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187207","Electroencephalogram;emotion recognition;transfer learning;cloud-edge-client collaboration","Brain modeling;Emotion recognition;Electroencephalography;Feature extraction;Machine learning;Collaboration;Scalp","augmented reality;cloud computing;computer games;electroencephalography;emotion recognition;feature extraction;learning (artificial intelligence);medical signal processing","cloud-edge-client collaborations;self-driving cars;3-dimensional channel mapping;responsive transfer learning based emotion recognition;localized transfer learning based emotion recognition;private transfer learning based emotion recognition;electroencephalogram signals;feature extraction;TLER framework;virtual reality-augmented reality games","","1","","43","IEEE","7 Sep 2020","","","IEEE","IEEE Journals"
"Providing a Baseline in Software Process Improvement Education with Lego Scrum Simulations","J. Steghöfer","Dept. of Comput. Sci. & Eng., Chalmers | Univ. of Gothenburg, Gothenburg, Sweden","2018 IEEE/ACM 40th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)","26 Aug 2018","2018","","","126","135","A critical aspect of software process education in general and software process improvement (SPI) education in particular is to give students the chance to experience processes and issues associated with process at first hand. This is, however, often difficult in an educational setting since providing a meaningful project in which to apply a process can take away time and focus from the intended learning objectives. Instead, miniatures and simulations can be used to create an environment in which students can interact with processes directly without taking up large parts of the curriculum. In this paper, we report on our experience of using Lego Scrum simulations in an SPI course at the Bachelor level. The simulations are used both to introduce a baseline for the students to let them experience process issues directly, create an improvement plan that addresses observed issues, and to apply and evaluate the plan in a second simulation. This allows students to engage with SPI methods practically, instead of purely theoretically, and allows the teacher to refer to the shared experience throughout the course. The collected data shows that the approach is suitable, but that students struggle with the demand of putting an improvement plan into practice. We show which issues commonly occur in the simulations and thus allow teachers who adopt the practice to scaffold it and react accordingly, in particular to empower the students to take on responsibility for the improvement of the process.","","978-1-4503-5660-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8445190","Software Process Improvement;SPI;Software Engineering Education;Scrum","Education;Software;Software engineering;Scrum (Software development);Interviews;Industries;Reflection","computer science education;educational courses;software process improvement;software prototyping","software process improvement education;Lego Scrum simulations;educational setting;SPI course;improvement plan;SPI methods;shared experience;learning objectives;baseline provision","","","","30","","26 Aug 2018","","","IEEE","IEEE Conferences"
"An Ontology based approach to teach Computational Thinking","C. Araújo; L. V. O. Lima; P. R. Henriques","Universidade do Minho,Centro Algoritmi / Dep. de Informática,Braga,Portugal; Universidade do Minho,Centro Algoritmi / Dep. de Informática,Braga,Portugal; Universidade do Minho,Centro Algoritmi / Dep. de Informática,Braga,Portugal","2019 International Symposium on Computers in Education (SIIE)","28 Jan 2020","2019","","","1","6","This paper is focused on the teaching/learning process of Computational Thinking at primary and secondary schools. It is generally accepted that Programming is a complex task that requires a long learning process. Theoretical knowledge about fundamentals on algorithms and data structures, as well as, on programming languages are required but are not enough; practicing a lot is also necessary. However, teaching Computer Programming is a hard job, most of the times unsuccessful. To overcome all the difficulties, felt by teachers and students, an increasingly bigger community of researchers in Computer Science is defending the importance of teaching Computational Thinking to young students to train them, since very earlier, in logic and abstract reasoning for problem solving. Our starting point to approach this topic relies on the use of an Ontology (OntoCnE) that describes in detail the concepts “Computational Thinking” and “Programming”, and maps those concepts to different education levels, starting with the first year. We believe that a person just acquires a new way of thinking, or a new way of behaving, if he is trained with the appropriate learning resources. So a main investment to educate people in Computational Thinking is on the choice/creation of those convenient resources. In particular we intended to investigate the impact of Augmented Reality in the usefulness of the referred resources. In that direction we will also discuss the development of a Web Platform to help on collecting and classifying (according to the referred ontology) learning resources to be used by teachers in computing classes. On the other hand, the platform will help on the retrieval, from that repository, of the most adequate resources to teach a specific subject to a specific level.","","978-1-7281-3182-5","10.1109/SIIE48397.2019.8970131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8970131","computational thinking;programming;learning resource;teacher support tools;ontology","","augmented reality;computer aided instruction;educational courses;educational institutions;ontologies (artificial intelligence);teaching","ontology based approach;computational thinking;long learning process;programming languages;computer programming;computer science;computing classes;learning resources","","1","","15","","28 Jan 2020","","","IEEE","IEEE Conferences"
"Markov Model Assessment of Subjects' Clinical Skill Using the E-Pelvis Physical Simulator","T. R. Mackel; J. Rosen; C. M. Pugh","Rockwell Collins Inc., Cedar Rapids; NA; NA","IEEE Transactions on Biomedical Engineering","19 Nov 2007","2007","54","12","2133","2141","Inherent difficulties evaluating clinical competence of physicians has led to the widespread use of subjective skill assessment techniques. Inspired by an analogy between spoken language and surgical procedure, a generalized methodology using Markov models (MMs), independent of the modality under study, was developed. The methodology applied to an endoscopic experiment in ""Generalized approach for modeling minimally invasive surgery as a stochastic process using a discrete Markov model"" by J. Rosen et al. (IEEE Trans. Biomed. Eng., Vol. 53, No. 3, pp. 399-413, Mar. 2006) is modified and applied to data collected with the E-Pelvis physical simulator. The simulator incorporates five contact pressure sensors located in key anatomical landmarks. Two 32-state fully connected MMs are used, one for each skill level. Each state corresponds to a unique five-dimensional signature of contact pressures. Statistical distances measured between models representing subjects with different skill levels are sensitive enough to provide an objective measure of medical skill level. The method was tested with 41 expert subjects and 41 novice subjects in addition to the 30 subjects used for training the MM. Of the 82 subjects, 76 (92%) were classified correctly. Unique state transitions as well as pressure magnitudes for corresponding states were found to be skill dependent. The ""white box"" nature of the model provides insight into the examination process performed.","1558-2531","","10.1109/TBME.2007.908338","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376256","Classification;E-Pelvis;Markov model (MM);pressure sensing;skill assessment","Hidden Markov models;Medical simulation;Natural languages;Minimally invasive surgery;Biomedical measurements;Medical treatment;Medical robotics;Automatic speech recognition;Jacobian matrices;Stochastic processes","biomedical education;Markov processes;training","white box model;medical skill level;contact pressure sensors;endoscopic experiment;subjective skill assessment techniques;physician clinical competence;E-pelvis physical simulator;clinical skill assessment;Markov model","Computer-Assisted Instruction;Expert Systems;Female;Gynecology;Gynecology;Humans;Markov Chains;Obstetrics;Obstetrics;Palpation;Palpation;Pelvis;Physical Examination;Physical Examination;Professional Competence;Students, Medical;Task Performance and Analysis;United States;User-Computer Interface","4","","25","","19 Nov 2007","","","IEEE","IEEE Journals"
"Power-optimized stiffness and nonlinear position control of an actuator with Variable Torsion Stiffness","P. Beckerle; J. Wojtusch; J. Schuy; B. Strah; S. Rinderknecht; O. v. Stryk","Institute for Mechatronic Systems, Department of Mechanical Engineering, Technische Universität Darmstadt, Germany; Simulation, Systems Optimization, and Robotics Group, Department of Computer Science, Technische Universität Darmstadt, Germany; Institute for Mechatronic Systems, Department of Mechanical Engineering, Technische Universität Darmstadt, Germany; Institute for Mechatronic Systems, Department of Mechanical Engineering, Technische Universität Darmstadt, Germany; Institute for Mechatronic Systems, Department of Mechanical Engineering, Technische Universität Darmstadt, Germany; Simulation, Systems Optimization, and Robotics Group, Department of Computer Science, Technische Universität Darmstadt, Germany","2013 IEEE/ASME International Conference on Advanced Intelligent Mechatronics","22 Aug 2013","2013","","","387","392","Introducing compliant actuation to robotic joints is an approach to ensure safety in closer human-machine interaction. Further, the possibility to adjust stiffness can be beneficial considering energy storage and the power consumption required to track certain trajectories. The subject of this paper is the stiffness and position control of the Variable Torsion Stiffness (VTS) actuator for application in compliant robotic joints. For the realization of a variable rotational stiffness, the active length of a torsional elastic element in serial configuration between drive and link is adjusted in VTS. After the deduction of an extended drive train model, this paper gives an advanced power analysis clarifying power-optimal settings from previous basic models and identifying additional settings that allow for a more versatile operation. Based on these results that can be generalized to other variable elastic actuator concepts, an optimized strategy for setting stiffness is determined considering the whole system dynamics including natural frequencies as well as antiresonance effects. For position control of VTS in a prototypical implementation, a nonlinear position controller is designed by means of feedback linearization. Although the system is modified significantly by changing drive train stiffness, the stiffness adaptation of the controller ensures the required tracking performance.","2159-6255","978-1-4673-5320-5","10.1109/AIM.2013.6584122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6584122","","Robots","actuators;compliant mechanisms;control system synthesis;couplings;drives;elasticity;energy storage;feedback;human-robot interaction;linearisation techniques;nonlinear control systems;position control;power consumption;torsion;trajectory control","power-optimized stiffness;nonlinear position control;variable torsion stiffness actuator;compliant actuation;robotic joints;human-machine interaction;energy storage;power consumption;trajectory tracking;stiffness control;VTS actuator;compliant robotic joints;variable rotational stiffness;torsional elastic element;serial configuration;extended drive train model;advanced power analysis;power-optimal settings;natural frequencies;antiresonance effects;VTS position control;nonlinear position controller;feedback linearization;stiffness adaptation","","14","","16","","22 Aug 2013","","","IEEE","IEEE Conferences"
"Evaluating Competition in Training of Deep Reinforcement Learning Agents in First-Person Shooter Games","P. B. S. Serafim; Y. L. B. Nogueira; C. A. Vidal; J. B. C. Neto","Dept. of Comput., Fed. Univ. of Ceara, Fortaleza, Brazil; Dept. of Comput., Fed. Univ. of Ceara, Fortaleza, Brazil; Dept. of Comput., Fed. Univ. of Ceara, Fortaleza, Brazil; Dept. of Comput., Fed. Univ. of Ceara, Fortaleza, Brazil","2018 17th Brazilian Symposium on Computer Games and Digital Entertainment (SBGames)","7 Feb 2019","2018","","","117","11709","This work evaluates competition in training of autonomous agents immersed in First-Person Shooter games using Deep Reinforcement Learning. The agents are composed of a Deep Neural Network, which is trained using Deep QLearning. The inputs of the networks are only the pixels of the screen, allowing the creation of general players, capable of handling several environments without the need for further modifications. ViZDoom, an Application Programming Interface based on the game Doom, is used as the testbed because of its appropriate features. Fifteen agents were divided into three groups, two of which were trained by competing with each other, and the third was trained by competing against opponents that act randomly. The developed agents were able to learn adequate behaviors to survive in a custom one-onone scenario. The tests showed that the competitive training of autonomous agents leads to a greater number of wins compared to training against non-intelligent agents.","2159-6662","978-1-5386-9605-7","10.1109/SBGAMES.2018.00023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8636940","autonomous agents;deep reinforcement learning;digital games;competitive learning;first-person shooter games","Games;Training;Reinforcement learning;Autonomous agents;Neurons;Biological neural networks;Kernel","application program interfaces;computer games;learning (artificial intelligence);multi-agent systems;neural nets","autonomous agents;nonintelligent agents;First-Person Shooter games;Deep Neural Network;Application Programming Interface;competitive training;deep reinforcement learning agents;deep Q learning;competition evaluation;Doom game;ViZDoom","","2","","39","","7 Feb 2019","","","IEEE","IEEE Conferences"
"Audio–Visual Emotion-Aware Cloud Gaming Framework","M. S. Hossain; G. Muhammad; B. Song; M. M. Hassan; A. Alelaiwi; A. Alamri","Department of Software EngineeringCollege of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Department of Computer EngineeringCollege of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Department of Information SystemsCollege of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Department of Information SystemsCollege of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Department of Software EngineeringCollege of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Department of Information SystemsCollege of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia","IEEE Transactions on Circuits and Systems for Video Technology","2 Dec 2015","2015","25","12","2105","2118","The promising potential and emerging applications of cloud gaming have drawn increasing interest from academia, industry, and the general public. However, providing a high-quality gaming experience in the cloud gaming framework is a challenging task because of the tradeoff between resource consumption and player emotion, which is affected by the game screen. We tackle this problem by leveraging emotion-aware screen effects in the cloud gaming framework and combining them with remote display technology. The first stage in the framework is the learning or training stage, which establishes a relationship between screen features and emotions using Gaussian mixture model-based classifiers. In the operating stage, a linear programming model provides appropriate screen changes based on the real-time user emotion obtained in the first stage. Our experiments demonstrate the effectiveness of the proposed framework. The results show that our proposed framework can provide a high quality gaming experience while generating an acceptable amount of workload for the cloud server in terms of resource consumption.","1558-2205","","10.1109/TCSVT.2015.2444731","Deanship of Scientific Research through King Saud University, Riyadh, Saudi Arabia, within the Research Group Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7122897","Emotion recognition;cloud gaming;gaming experience;remote display;Cloud gaming;emotion recognition;gaming experience;remote display","Games;Emotion recognition;Servers;Cloud computing;Real-time systems;Harmonic analysis","audio-visual systems;cloud computing;computer games;emotion recognition;Gaussian processes;linear programming;mixture models;pattern classification;screens (display)","audiovisual emotion aware cloud gaming;resource consumption;player emotion;game screen;remote display technology;Gaussian mixture model-based classifier;linear programming model;cloud server;training stage;learning stage","","46","","47","","12 Jun 2015","","","IEEE","IEEE Journals"
"Improving laboratory training for automation and process control courses with a specifically designed testing software application","F. Mateos; A. M. Lopez; V. M. Gonazalez; J. M. Enguita","Viesques, Asturias, Spain; NA; NA; NA","IEEE Transactions on Education","7 Aug 2002","2001","44","2","14 pp.","","A common problem in automation and process control courses, often arises at the practical stage. Students have to implement and test their control programs using specialized control devices (such as microcontrollers or PLCs) and, in many cases, the use of scale models or real process components is not possible, having to deal with a large number of switches, LEDs, etc., which not only may be confusing, but also drastically reduces their motivation. To mitigate this problem, other tools that could somewhat help by simulating the general behavior of the process (such as SCADA applications), are used. However, they are not intended for that purpose, so in most cases they are found inadequate. PROSIMAX, an easy-to-use Windows based tool for testing control programs implemented on different control devices, is presented. Using PROSIMAX, a virtually infinite number of real processes are easily cloned into virtual processes which, once attached to the control device, will behave as the real ones. It is intended to minimize the main drawbacks of classical tools used for test in educational environments. However, PROSIMAX is intended to be used as an auxiliary tool, being known the fact that the use of real components or scale models is the best way to achieve a satisfactory educational result.","1557-9638","","10.1109/13.925869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=925869","","Control engineering education","control engineering education;student experiments;courseware;educational courses;laboratories","laboratory training;process control courses;automation courses;testing software application;microcontrollers;PLCs;SCADA applications;PROSIMAX","","2","","","","7 Aug 2002","","","IEEE","IEEE Journals"
"Haptic interfaces: a new interaction paradigm","C. A. Avizzano; M. Bergamasco","Simultaneous Presence, Telepresence & Virtual Presence, PERCRO, Pisa, Italy; NA","Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289)","6 Aug 2002","1999","3","","1531","1536 vol.3","Haptic interfaces have ordinarily been used as tools in the exploration of virtual environments as well as masters in teleoperation systems. In these systems the haptic interfaces have been commonly employed only to reproduce and simulate contact experience with a simulated or remote environment. This use is good enough for the realization of high quality simulators such as VETIR. All actions in simulators are generated by a precise set of rules which determine the correct feedback stimuli to be presented to the operator. In the article, haptic interfaces are presented as stand alone systems having their own and independent control. Consequently we explore the control capabilities and we identify a new extended interaction paradigm which provides to the machine the capability of interpreting the human actions and organizing a new high level feedback. The paper introduces a general structure for such a type of systems called reactive systems. A large set of interactive systems, such as tutors, trainers as well as technological aids for rehabilitation can be easily realized with the presented architecture.","","0-7803-5184-3","10.1109/IROS.1999.811696","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=811696","","Haptic interfaces;Humans;Virtual reality;Control systems;Service robots;Rehabilitation robotics;Force feedback;Virtual environment;Organizing;Interactive systems","haptic interfaces;closed loop systems;telerobotics;virtual reality","interaction paradigm;stand alone systems;control capabilities;human actions;high level feedback;reactive systems;tutors;trainers;technological aids;rehabilitation","","3","","14","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Design of a haptic display for catheterization","T. A. Kern; R. Werthschutzky","Inst. EMK, Darmstadt Univ. of Technol., Germany; Inst. EMK, Darmstadt Univ. of Technol., Germany","First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems. World Haptics Conference","4 Apr 2005","2005","","","477","478","Navigating a catheter inside the patient and orientation during this procedure is mainly dependent on a live x-ray image. Although methods for 3D visualization and remote navigation of the catheter are emerging and subject to tests, still precise positioning is merely the result of intense training and high skills of the performing surgeon. A novel assistance-system intends to provide measured force data from the tip of a guide wire and display them as feedback to the performing surgeon. It is intended to build a simulator giving a first impression of the feel and touch of such an assistance. For this simulator a haptic display is needed. This article refers to design methods and the actual structure of this display. It has to be capable applying torque and force on the catheter. General technical requirements are presented. The realized prototype itself is shown and the experience made is presented.","","0-7695-2310-2","10.1109/WHC.2005.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1406975","","Haptic interfaces;Displays;Catheterization;Catheters;Navigation;Performance evaluation;Surges;Force measurement;Force feedback;X-ray imaging","catheters;force feedback;haptic interfaces;torque;medical computing;diagnostic radiography","catheter;3D visualization;remote navigation;haptic display;force feedback;haptic interfaces;torque;medical computing;diagnostic radiography","","4","","3","","4 Apr 2005","","","IEEE","IEEE Conferences"
"Learning the sense of touch in simulation: a sim-to-real strategy for vision-based tactile sensing","C. Sferrazza; T. Bi; R. D’Andrea","ETH Zurich,Institute for Dynamic Systems and Control,Switerland; ETH Zurich,Institute for Dynamic Systems and Control,Switerland; ETH Zurich,Institute for Dynamic Systems and Control,Switerland","2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","10 Feb 2021","2020","","","4389","4396","Data-driven approaches to tactile sensing aim to overcome the complexity of accurately modeling contact with soft materials. However, their widespread adoption is impaired by concerns about data efficiency and the capability to generalize when applied to various tasks. This paper focuses on both these aspects with regard to a vision-based tactile sensor, which aims to reconstruct the distribution of the three- dimensional contact forces applied on its soft surface. Accurate models for the soft materials and the camera projection, derived via state-of-the-art techniques in the respective domains, are employed to generate a dataset in simulation. A strategy is proposed to train a tailored deep neural network entirely from the simulation data. The resulting learning architecture is directly transferable across multiple tactile sensors without further training and yields accurate predictions on real data, while showing promising generalization capabilities to unseen contact conditions.","2153-0866","978-1-7281-6212-6","10.1109/IROS45743.2020.9341285","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9341285","","Training;Surface reconstruction;Tactile sensors;Data models;Sensors;Task analysis;Optical flow","deep learning (artificial intelligence);human-robot interaction;neural net architecture;robot vision;stereo image processing;tactile sensors;touch (physiological)","vision-based tactile sensing;data-driven approaches;contact modeling;soft materials;camera projection;deep neural network;learning architecture;multiple tactile sensors;three-dimensional contact forces;sim-to-real strategy;sense of touch learning;robot interaction","","","","26","","10 Feb 2021","","","IEEE","IEEE Conferences"
"Virtual Pet Game Application to Train and Manage How to Raise a Cat Well and Properly","Emilisa; R. Darmakusuma","Bandung Institute of Technology,School of Electrical Engineering and Informatics,Bandung; Bandung Institute of Technology,School of Electrical Engineering and Informatics,Bandung","2020 6th International Conference on Interactive Digital Media (ICIDM)","4 Feb 2021","2020","","","1","7","Many people like cats, but not many know how to care for cats properly. Therefore it is not uncommon to find cats that get sick quickly and die due to the cat owner's mistake in treating his cat. AICat 3D is an application that is given artificial intelligence in accordance with the behavior of cats in general. Based on that it can be used for learning how to care for cats properly. In this paper, author will provide an explanation of how to create an Android-based virtual pet application and artificial intelligence used in the application, such as state machine, the features used, the design, and the scripts used. This system can be used to train children who want to know how to raise a cat properly and correctly without having to worry about the cat dying and cost incurred for maintenance. The use of android for the AICat 3D game is very suitable for implementation because it does not require additional costs because of the use of existing smartphones everywhere. AICat 3D use memory of 174.1 mega-byte only. It does not use too much memory for a kind of three-dimensional game like this AICat 3D. based on that, this game suitable installed in low spec smartphone though. Therefore, this game has no lag when we play it. Aside from that this game also has no error.","","978-1-7281-4928-8","10.1109/ICIDM51048.2020.9339682","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9339682","virtual pet;simulation game;android game;learning game for kid;game for learning","Cats;Three-dimensional displays;Games;Media;Maintenance engineering;Artificial intelligence;Smart phones","artificial intelligence;biology computing;computer games;smart phones;zoology","virtual pet game application;cat owner;AICat 3D;Android-based virtual pet application;smartphone;three-dimensional game;artificial intelligence","","","","12","","4 Feb 2021","","","IEEE","IEEE Conferences"
"Supporting Mathematics Teachers' Online Discussion with the Use of Animated Classroom Stories as Reference Point","V. Chieu; P. G. Herbst","Sch. of Educ., Univ. of Michigan, Ann Arbor, MI, USA; Sch. of Educ., Univ. of Michigan, Ann Arbor, MI, USA","2011 IEEE 11th International Conference on Advanced Learning Technologies","18 Aug 2011","2011","","","479","481","Sustaining online discussion in general has been a critical problem because of the nature of text-based exchange among participants. Supporting online teacher learning through the use of forums, in particular, has been more difficult because of the extreme complexity of the instructional practice that participants are expected to learn. We have used animated classroom episodes as embedded reference points in forum and a design-based research approach to develop and evaluate virtual settings for mathematics teachers to improve their practical skills. This paper reports on a part of results of the second study of the approach. We show evidence that teacher users produced meaningful and in-depth discussion over a period of eight weeks. This evidence supports the principle of embedding animations directly to the discussion space, which we found in a previous study, as well as supports a new principle of organizing forum in a tree-based structure format.","2161-377X","978-1-61284-209-7","10.1109/ICALT.2011.149","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5992401","classroom animations;online forums;teacher learning;mathematics education;teaching practice","Animation;Mathematics;Context;Communities;Presses;Educational institutions","computer aided instruction;computer animation;embedded systems;mathematics computing;teacher training;trees (mathematics);virtual reality","mathematics teacher;online discussion;animated classroom story;text-based exchange;online teacher learning;animated classroom episode;design-based research approach;embedding animation;tree-based structure","","1","","20","","18 Aug 2011","","","IEEE","IEEE Conferences"
"Learning ergonomics by doing job analysis","V. A. Petrushin; C. Thompson; L. DeSetto","Georgia Inst. of Technol., Atlanta, GA, USA; NA; NA","Technology-Based Re-Engineering Engineering Education Proceedings of Frontiers in Education FIE'96 26th Annual Conference","6 Aug 2002","1996","1","","158","162 vol.1","This paper describes the pedagogical principles, structure and functionality of a class of multimedia learning environments designed for learning manufacturing in general and ergonomics in particular. It also presents the Ergonaut environment, which is intended for acquiring the knowledge and skills necessary to conduct ergonomic job analysis. The environment is an open one allowing the learner to explore and experiment with the resources and problems included. A rich set of tools and reference sources are provided in a manner similar to what the real world practicing ergonomist encounters. The learner is assigned a role on a simulated ergonomics team and must interact with and solicit help from other members of the ream in order to solve the problem completely. Explicit support is provided for the learning activities through scaffolding of the complete analysis/solution procedure, identification of learning needs, and reflective articulation. Throughout the learning process the learner constructs his or her own case library of problems and solutions which serve as the basis for reflecting on what has been learned and for future reference. Progress and actions are monitored to infer the student knowledge state and provide intelligent assistance when requested.","0190-5848","0-7803-3348-9","10.1109/FIE.1996.569934","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=569934","","Ergonomics;Production;Computer aided manufacturing;Management training;Electronic mail;Pulp manufacturing;Libraries;Monitoring;Intelligent robots;Knowledge engineering","ergonomics;computer aided instruction;computer science education","ergonomics learning;job analysis;pedagogical principles;functionality;multimedia learning environments;Ergonaut environment;simulated ergonomics;student knowledge state;intelligent assistance","","1","","3","","6 Aug 2002","","","IEEE","IEEE Conferences"
"A Fuzzy Rule-Based Model of Vibrotactile Perception via an Automobile Haptic Screen","L. Duţu; G. Mauris; P. Bolon; S. Dabic; J. Tissot","Laboratoire d’Informatique, Systèmes, Traitement de l’Information et de la Connaissance, Polytech Annecy-Chambéry, University of Savoie, Chambéry, France; Laboratoire d’Informatique, Systèmes, Traitement de l’Information et de la Connaissance, Polytech Annecy-Chambéry, University of Savoie, Chambéry, France; Laboratoire d’Informatique, Systèmes, Traitement de l’Information et de la Connaissance, Polytech Annecy-Chambéry, University of Savoie, Chambéry, France; Department of Interior Controls, Valeo, Annemasse, France; Department of Interior Controls, Valeo, Annemasse, France","IEEE Transactions on Instrumentation and Measurement","10 Jul 2015","2015","64","8","2323","2333","With the increased popularity of touch-sensitive surfaces, much attention has been drawn to their security-related issues, as they currently rely only on the visual sense for feedback. To improve operability, vibrotactile signals may be delivered to the finger on screen interaction. The way vibrotactile signals affect human perception is examined via three measured variables, related to their energy, velocity, and spectral complexity, and which are analytically defined in this paper. It is shown that these variables accurately account for the psychophysical properties of the tactile sense. Based on this, a psychophysical fuzzy rule-based model of vibrotactile perception is introduced to forecast the comfort values of the vibrational signals provided by an automobile haptic screen. Using an efficient rule-based generation method, a Mamdani fuzzy inference system is proposed; it achieves a mean error rate of 14% for the train set and 17% for the test set, while correctly classifying most of the signals within a reasonable tolerance, related to human evaluation imprecision. The system also produces a comprehensible linguistic rule structure, which allows behavioral patterns to be detected.","1557-9662","","10.1109/TIM.2015.2398952","FUI-MISAC Project through the French Government; Conseil Général 74; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7047868","Continuous wavelet transforms (CWTs);fuzzy systems;haptic interfaces;sensory evaluation;signal processing.;Continuous wavelet transforms (CWTs);fuzzy systems;haptic interfaces;sensory evaluation;signal processing","Acceleration;Haptic interfaces;Time-frequency analysis;Complexity theory;Automobiles;Visualization;Indexes","computerised instrumentation;fuzzy reasoning;haptic interfaces;knowledge acquisition;learning (artificial intelligence);signal classification;tactile sensors;touch (physiological);vibration measurement","psychophysical fuzzy rule-based model;rule-based generation method;Mamdani fuzzy inference system;signal classification;human evaluation imprecision;comprehensible linguistic rule structure;tactile sensor;psychophysical property;velocity complexity;energy complexity;spectral complexity;human perception;vibrotactile signal;visual sensor;security related issue;touch-sensitive surface;automobile haptic screen;vibrotactile perception","","5","","52","","24 Feb 2015","","","IEEE","IEEE Journals"
"Close Encounters of the Agent Kind: Designing Agents for Effective Training","F. Dignum; V. Dignum; C. M. Jonker","Utrecht Univ., Utrecht, Netherlands; Delft Univ. of Technol., Delft, Netherlands; Delft Univ. of Technol., Delft, Netherlands","2012 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology","2 May 2013","2012","2","","251","257","In this paper we describe how culture and personality form important influences on the decision making processes of persons. When designing agents for serious games and simulations we need to take these aspects into consideration in order to create realistic behavior for the agents. We propose to model culture and personality as separate modules in the agent architecture in order to separate the domain dependent decision rules for action from the general sociological rules governing these aspects. We illustrate with an example how the architecture works.","","978-1-4673-6057-9","10.1109/WI-IAT.2012.74","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6511578","Serious games;culture;personality;agent architecture","","behavioural sciences computing;serious games (computing);software agents","agent kind;designing agents;effective training;culture;personality;decision making processes;serious games;realistic behavior;agent architecture;domain dependent decision rules;general sociological rules","","","","21","","2 May 2013","","","IEEE","IEEE Conferences"
"MPEG Media Transport (MMT) for 3D Tele-Immersion Systems","K. Venkatraman; S. Vellingiri; B. Prabhakaran; N. Nguyen","Univ. of Texas at Dallas, Richardson, TX, USA; Univ. of Texas at Dallas, Richardson, TX, USA; Univ. of Texas at Dallas, Richardson, TX, USA; TIN Consulting, Richardson, TX, USA","2014 IEEE International Symposium on Multimedia","9 Feb 2015","2014","","","279","282","3D Tele-Immersion (3DTI) environments are a new medium for highly interactive and immersive means of collaborations through a shared virtual 3D environment. They have many applications in the areas of education, entertainment, sports training, tele-medicine etc. The data in these systems are multi-modal, some high volume, some high frequency and all highly correlated. We identify three major challenges in a general 3DTI system, session management, synchronization and data format conversion. We discuss the shortcomings of some of the existing protocols/solutions to them. We describe some features relevant to 3DTI of the MPEG Media Transport (MMT) standard. In this paper we evaluate the use of MMT in a 3DTI application. We provide a feature comparison with the most popular protocols currently being used in such applications, RTP, RTSP, TCP and UDP etc. MPEG DASH was another protocol that was being considered, but that also fails to fully address some of the challenges that 3DTI applications face. Through this comparison study we advocate the use of MMT in 3DTI applications.","","978-1-4799-4311-1","10.1109/ISM.2014.65","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7033039","Tele-Immersion;MPEG Media Transport;Haptic;Body Sensor Networks","Media;Synchronization;Transform coding;Encapsulation;Three-dimensional displays;Transport protocols","multimedia computing;synchronisation;virtual reality","MPEG media transport;MMT;3D tele-immersion systems;3DTI;shared virtual 3D environment;session management;data format conversion;synchronization;feature comparison;RTP;RTSP;TCP;UDP;MPEG DASH","","3","","9","","9 Feb 2015","","","IEEE","IEEE Conferences"
"From Video Game to Real Robot: The Transfer Between Action Spaces","J. Karttunen; A. Kanervisto; V. Kyrki; V. Hautamäki","Karelics Oy,Joensuu,Finland; University of Eastern Finland,School of Computing,Joensuu,Finland; Aalto University,School of Electrical Engineering,Espoo,Finland; University of Eastern Finland,School of Computing,Joensuu,Finland","ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","9 Apr 2020","2020","","","3567","3571","Deep reinforcement learning has proven to be successful for learning tasks in simulated environments, but applying same techniques for robots in real-world domain is more challenging, as they require hours of training. To address this, transfer learning can be used to train the policy first in a simulated environment and then transfer it to physical agent. As the simulation never matches reality perfectly, the physics, visuals and action spaces by necessity differ between these environments to some degree. In this work, we study how general video games can be directly used instead of fine-tuned simulations for the sim-to-real transfer. Especially, we study how the agent can learn the new action space autonomously, when the game actions do not match the robot actions. Our results show that the different action space can be learned by re-training only part of neural network and we obtain above 90% mean success rate in simulation and robot experiments.","2379-190X","978-1-5090-6631-5","10.1109/ICASSP40776.2020.9053221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9053221","deep reinforcement learning;transfer learning;sim-to-real;reality gap;action space transfer","Training;Visualization;Neural networks;Transfer learning;Games;Task analysis;Robots","computer games;learning (artificial intelligence);neural nets;robots","video game;deep reinforcement learning;simulated environment;real-world domain;transfer learning;physical agent;general video games;fine-tuned simulations;game actions;robot actions;action space;mean success rate;robot experiments;learning tasks;visuals spaces;physics spaces;neural network","","","","19","","9 Apr 2020","","","IEEE","IEEE Conferences"
"Volumetric Capture of Humans With a Single RGBD Camera via Semi-Parametric Learning","R. Pandey; A. Tkach; S. Yang; P. Pidlypenskyi; J. Taylor; R. Martin-Brualla; A. Tagliasacchi; G. Papandreou; P. Davidson; C. Keskin; S. Izadi; S. Fanello",Google; Google; Google; Google; Google Inc.; Google; Google Inc.; Ariel AI; Google Inc.; Google; Google; Google,"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","9 Jan 2020","2019","","","9701","9710","Volumetric (4D) performance capture is fundamental for AR/VR content generation. Whereas previous work in 4D performance capture has shown impressive results in studio settings, the technology is still far from being accessible to a typical consumer who, at best, might own a single RGBD sensor. Thus, in this work, we propose a method to synthesize free viewpoint renderings using a single RGBD camera. The key insight is to leverage previously seen “calibration” images of a given user to extrapolate what should be rendered in a novel viewpoint from the data available in the sensor. Given these past observations from multiple viewpoints, and the current RGBD image from a fixed view, we propose an end-to-end framework that fuses both these data sources to generate novel renderings of the performer. We demonstrate that the method can produce high fidelity images, and handle extreme changes in subject pose and camera viewpoints. We also show that the system generalizes to performers not seen in the training data. We run exhaustive experiments demonstrating the effectiveness of the proposed semi-parametric model (i.e. calibration images available to the neural network) compared to other state of the art machine learned solutions. Further, we compare the method with more traditional pipelines that employ multi-view capture. We show that our framework is able to achieve compelling results, with substantially less infrastructure than previously required.","2575-7075","978-1-7281-3293-8","10.1109/CVPR.2019.00994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8954320","3D from Single Image;Deep Learning ; Image and Video Synthesis","","calibration;cameras;image colour analysis;image sensors;image texture;interactive systems;learning (artificial intelligence);rendering (computer graphics);virtual reality","single RGBD camera;semiparametric learning;volumetric performance capture;4D performance capture;studio settings;typical consumer;single RGBD sensor;free viewpoint renderings;calibration images;multiple viewpoints;current RGBD image;end-to-end framework;data sources;novel renderings;high fidelity images;camera viewpoints;training data;semiparametric model;employ multiview capture;machine learned solutions","","","","51","","9 Jan 2020","","","IEEE","IEEE Conferences"
"Study of classification model for college students' M-learning strategies based on PCA-LVQ neural network","S. Hu; Y. Gu; H. Jiang","Teaching and Research Institute of Foreign Languages, Bohai University, Jinzhou, Liaoning, China; Teaching and Research Institute of Foreign Languages, Bohai University, Jinzhou, Liaoning, China; Teaching and Research Institute of Foreign Languages, Bohai University, Jinzhou, Liaoning, China","2015 8th International Conference on Biomedical Engineering and Informatics (BMEI)","11 Feb 2016","2015","","","742","746","Study of learner-oriented mobile learning (m-learning) instructions based on classification of student m-learning strategies has aroused much attention over the last decade. Due to the multivariate nature of students' learning strategies, traditional classification methods often fail to produce reliable classification results. In this paper, a new classification method based on Principal Component Analysis (PCA) and Learning Vector Quantization (LVQ) neural network is proposed. PCA was first used to reduce the dimensionality of original data about students' learning strategies. 5 principal components were extracted to create a PCA-LVQ classification model. The classification result of the proposed model was compared with those produced by a simple LVQ network model and a standard BP network model. The simulation results show that compared with the other two networks, the PCA-LVQ model has a better performance in training speed, classification accuracy and generalization ability.","","978-1-5090-0022-7","10.1109/BMEI.2015.7401601","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7401601","LVQ neural network;PCA;classification;m-learning strategy","Neurons;Principal component analysis;Training;Correlation;Indexes;Neural networks;Data mining","data reduction;further education;mobile learning;neural nets;pattern classification;principal component analysis;vector quantisation","generalization ability;training speed;dimensionality reduction;learner-oriented mobile learning instructions;learning vector quantization neural network;principal component analysis;PCA-LVQ neural network;college students m-learning strategies;classification model","","","","10","","11 Feb 2016","","","IEEE","IEEE Conferences"
"Identifying and ranking factors in evaluating the Web 2.0-based educational simulation games","K. M. Davood; S. Afsaneh","Department of IT Management, Central Office, Payame Noor University, Tehran, Iran; Department of IT Management, Payame Noor University, Tehran, Iran","4th International Conference on e-Learning and e-Teaching (ICELET 2013)","12 Dec 2013","2013","","","14","19","Today, modern methods of training are developed with the aid of information technology to help learners better understand the circumstances of real organizations and increase the power of relating between classroom theoretical concepts and practical concepts in the real world. Training by simulation games is one of the training tools that due to the rapid development of network technology is significantly developed and if used correctly highly influences teaching and learning. The general aim of this research is to identify and rank the evaluation factors of training simulation games for optimum designing or selecting the best simulation game in training. For this purpose after reviewing the literature and studying the models and frameworks presented about the development and design of serious and simulation games, their main elements and components were identified. Then by using The Delphi method and opinions of 15 Training and simulation games experts, Factors that had the greatest deal of emphasis were presented in the form of 3 Psychological, Educational, and Technical dimensions and 30 evaluation factors and after comparing and rating the factors by the experts the answers were analyzed and ranked. Ranking the evaluation factors in this research shows that technical and educational factors had higher importance in the experts' view than the psychological factors. Also the high rank of web2.0 factors among the technical factors shows the high importance of educational simulation games in web context 2.0 in experts' view.","2163-6982","978-1-4673-5268-0","10.1109/ICELET.2013.6681638","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6681638","Simulation Game;Serious Game;Web 2.0;e-Learning","Psychology;Computational modeling;Visualization;Reliability;Safety;Games","computer aided instruction;computer games;forecasting theory;Internet","Web 2.0-based educational simulation games;information technology;real organizations;training tools;Delphi method;psychological factors;educational factors;technical factors","","","","30","","12 Dec 2013","","","IEEE","IEEE Conferences"
"Invigorating of the Quality Engineering and Management education by virtual educational laboratories","K. Zgodavova; P. Palfy; L. Lengyel","Technical University of Kosice / Faculty of Metallurgy/Department of Integrated Management Systems, Slovakia; Technical University of Kosice / Faculty of Metallurgy/Department of Integrated Management Systems, Slovakia; Faurecia Slovakia, s.r.o., Bratislava, Slovakia","2016 International Conference on Emerging eLearning Technologies and Applications (ICETA)","2 Jan 2017","2016","","","381","386","The purpose of the paper is to provide generalized knowledge about the education and training within the Quality Engineering and Management study programs with the application of information and communication technologies (ICT) in the environment of CRELABTE virtual laboratories, which enable simulation of specific situations from industrial practice. The infrastructure of CRELABTE consists of hardware (remote server) and software supporting laboratory tasks in the subjects of related study programs. The paper also describes a new floor shop manual data entry system KONIS® for the invigoration of the laboratory education. KONIS® software supports training in decision making regarding product quality through remote access to the information.","","978-1-5090-4701-7","10.1109/ICETA.2016.7802078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7802078","","Laboratories;Training;Servers;Companies;Information and communication technology","computer based training;engineering education;management education;product quality;quality management;virtual instrumentation","training;quality engineering and management education;quality engineering and management study programs;information and communication technologies;CRELABTE virtual laboratories;remote server;floor shop manual data entry system;KONIS software;decision making;product quality;remote information access","","1","","17","","2 Jan 2017","","","IEEE","IEEE Conferences"
"Safety Model Scenarios in the Synthetic Air Traffic Management Environment on Bases of LETVIS Real Information System","M. Žentek; P. Bučka","Armed Forces Academy of general M. R., Štefánik in Liptovský Mikuláš, Liptovský Mikuláš, Slovakia; Armed Forces Academy of general M. R., Štefánik in Liptovský Mikuláš, Liptovský Mikuláš, Slovakia","2019 New Trends in Aviation Development (NTAD)","21 Oct 2019","2019","","","218","222","The implementation of the deployment of new information and communication technologies as well as the possibility of their safe use are an important part for the functionality of the system to achieve the required level of safety of air traffic control services in the Slovak airspace. The condition to use the “LETVIS” flight information system in the Slovak Republic's Armed Forces for air traffic services is currently a potential option for the occurrence of undesirable security incidents in such an environment, and this could result in a human factor failure while the commands in the airspace are being issued or executed. Appropriate application of scientific research in a synthetic environment makes it possible to optimize and verify the correctness of training principles by the form of modular exercises which are aimed for solving the crisis situations. This would make the air traffic controllers prepared for a safety incident in practice and they could eliminate some fatal consequences. Some of the possible scenarios of occurrence and safety incidents on the radar screen output of this information system are analyzed in this paper.","","978-1-7281-4079-7","10.1109/NTAD.2019.8875569","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8875569","","Security;Aircraft;Radar;Air traffic control;Safety;Military aircraft;Information and communication technology","air traffic;air traffic control;human factors;military computing;safety;security","safety model scenarios;synthetic air traffic management environment;information and communication technologies;air traffic control services;Slovak airspace;LETVIS flight information system;air traffic services;human factor failure;air traffic controllers;safety incident;LETVIS real information system;Slovak Republic armed forces;security incidents","","","","15","","21 Oct 2019","","","IEEE","IEEE Conferences"
"Learning an Action-Conditional Model for Haptic Texture Generation","N. Heravi; W. Yuan; A. M. Okamura; J. Bohg","Stanford University,Department of Mechanical Engineering; Carnegie Mellon University,Robotics Institute; Stanford University,Department of Mechanical Engineering; Stanford University,Department of Computer Science","2020 IEEE International Conference on Robotics and Automation (ICRA)","15 Sep 2020","2020","","","11088","11095","Rich haptic sensory feedback in response to user interactions is desirable for an effective, immersive virtual reality or teleoperation system. However, this feedback depends on material properties and user interactions in a complex, non-linear manner. Therefore, it is challenging to model the mapping from material and user interactions to haptic feedback in a way that generalizes over many variations of the user's input. Current methodologies are typically conditioned on user interactions, but require a separate model for each material. In this paper, we present a learned action-conditional model that uses data from a vision-based tactile sensor (GelSight) and user's action as input. This model predicts an induced acceleration that could be used to provide haptic vibration feedback to a user. We trained our proposed model on a publicly available dataset (Penn Haptic Texture Toolkit) that we augmented with GelSight measurements of the different materials. We show that a unified model over all materials outperforms previous methods and generalizes to new actions and new instances of the material categories in the dataset.","2577-087X","978-1-7281-7395-5","10.1109/ICRA40945.2020.9197447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197447","","Haptic interfaces;Autoregressive processes;Force;Acceleration;Predictive models;Solid modeling;Discrete Fourier transforms","feedback;haptic interfaces;human-robot interaction;image texture;learning (artificial intelligence);mobile robots;robot vision;tactile sensors;telerobotics;virtual reality","Haptic Texture generation;haptic sensory feedback;user interactions;immersive virtual reality;material properties;haptic vibration feedback;Penn Haptic Texture Toolkit;action-conditional model learning;GelSight measurements;teleoperation system;autonomous robot;GelSight image texture","","","","33","","15 Sep 2020","","","IEEE","IEEE Conferences"
"OxyBlood","A. F. S. Barbosa; F. G. M. Silva","Instituto de Telecomunicações, Dep. Informática, Universidade da Beira Interior, 6201-001 Covilhã, Portugal; Instituto de Telecomunicações, Dep. Informática, Universidade da Beira Interior, 6201-001 Covilhã, Portugal","6th Iberian Conference on Information Systems and Technologies (CISTI 2011)","4 Aug 2011","2011","","","1","4","With the growth of the video game industry, interest in video game research has increased, leading to the study of Serious Games. Serious Games are generally perceived as games with purposes other than mere entertainment. These purposes range from education to training, marketing to design, among others. By exploiting the potential of these virtual worlds, we can provide the possibility to experience situations that would otherwise be impossible to experience in the real world, mainly due to reasons of cost, safety and time. Web browsers can now provide easy access to realistic virtual worlds with WebGL, which grants video game developers the tools to create compelling and rich environments that can be used in the future by virtually anyone. This paper presents a prototype of a Serious Game developed with WebGL.","2166-0735","978-989-96247-5-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5974333","Serious Games;3D Games;WebGL;Browser","Lead;Games","computer games;online front-ends;virtual reality","OxyBlood;WebGL;video game industry;video game research;serious games;entertainment;virtual worlds;Web browsers","","","","26","","4 Aug 2011","","","IEEE","IEEE Conferences"
"Network-Assisted Neural Adaptive Naked-Eye 3D Video Streaming Over Wireless Networks","Y. Liu; W. He; Y. Wang; H. Yang","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Access","7 Oct 2019","2019","7","","141363","141373","High quality transmission of Virtual Reality (VR) video depends strictly on bandwidth and delay requirements. It becomes possible with the maturity and commercialization of 5G technology. However, to transmit VR video streaming over wireless communication system, we must cope with the challenge that fluctuation exists in the wireless channel conditions. For example, available channel bandwidth, packet loss rate, and interference level may vary with time due to channel fading and user's mobility. The problem is more prominent when transmitting naked-eye 3D video which generally consists of multiple viewpoints with different resolutions. In order to optimize the quality of experience (QoE) of watching naked-eye VR video over wireless networks, this paper proposes a network-assisted neural adaptive video streaming algorithm (NAVSA). Specifically, we present a modified QoE function to describe the quality of naked-eye 3D streaming quantitatively, which not only considers the quality of naked-eye 3D video itself, but also considers the phenomenon of rebuffering and video fluctuation that occurs during video transmission. Next, with the network-assisted feedback, the physical layer information, the buffer occupancy of the video client, and the size of the next video chunk are collected to train a reinforcement learning model. Based on dynamic adaptive streaming over HTTP (DASH), the model can automatically choose appropriate viewpoints and resolutions corresponding to the current condition of the wireless networks such that the network capacity can be fully explored. To verify the performance of our proposed NAVSA, we simulate 3 naked-eye 3D video application scenarios on the NS3 platform. The results show that the performance of NAVSA is about 5~8% better than some state-of-the-art algorithms in wireless networks.","2169-3536","","10.1109/ACCESS.2019.2944437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852692","Reinforcement learning;adaptive transmission;naked-eye 3D;network assistance;wireless networks","Streaming media;Three-dimensional displays;Quality of experience;Wireless networks;Bandwidth;Adaptive systems;Reinforcement learning","5G mobile communication;bandwidth allocation;channel allocation;fading channels;learning (artificial intelligence);mobility management (mobile radio);neural nets;quality of experience;radiofrequency interference;transport protocols;video streaming;virtual reality","naked-eye 3D video;naked-eye 3D video application;5G technology;quality of experience;NAVSA;reinforcement learning model;dynamic adaptive streaming over HTTP;DASH;network-assisted neural adaptive video streaming algorithm;naked-eye VR video;channel bandwidth;wireless channel conditions;wireless communication system;Virtual Reality video;network-assisted neural adaptive naked-eye 3D video streaming;NS3 platform;wireless networks;network-assisted feedback;video transmission","","","","45","CCBY","30 Sep 2019","","","IEEE","IEEE Journals"
"Adaptive Neural Network-based Perception and Awareness of Teleoperation Systems in Human-Machine Interactions","P. M. Kebria; D. Nahavandi; A. Khosravi; S. Nahavandi; F. Bello","Deakin University,Institute for Intelligent Systems Research and Innovation (IISRI),Waurn Ponds,VIC,Australia,3216; Deakin University,Institute for Intelligent Systems Research and Innovation (IISRI),Waurn Ponds,VIC,Australia,3216; Deakin University,Institute for Intelligent Systems Research and Innovation (IISRI),Waurn Ponds,VIC,Australia,3216; Deakin University,Institute for Intelligent Systems Research and Innovation (IISRI),Waurn Ponds,VIC,Australia,3216; Centre for Engagement and Simulation Science, Imperial College, Chelsea and Westminster Hospital,London,UK","2020 IEEE International Conference on Human-Machine Systems (ICHMS)","30 Sep 2020","2020","","","1","6","This paper addresses the problem of perception and awareness of teleoperation systems in the presence of human collaboratives/objects in the workspace. Although the term teleoperation generally refers to operations being executed remotely, in many applications, like telemedicine, there exist human beings in the remote workspace. Hence, it is critically important that the teleoperator system to operate safely enough in the presence of human kinds in the workspace. In this paper, we propose a perception and awareness scheme for a teleoperation system that prevents the teleoperator from imposing extreme and unwanted forces/movements. To achieve this goal, we train a neural network to estimate and predict the motion and force commands from the human operator. Furthermore, we develop an adaptive algorithm for fine-tuning network parameters for robustness purposes. Theoretically proven, stability and performance of the proposed scheme is comparatively evaluated in comprehensive simulations.","","978-1-7281-5871-6","10.1109/ICHMS49158.2020.9209437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9209437","","Force;Neural networks;Teleoperators;Adaptive algorithms;Reliability;Training","human computer interaction;learning (artificial intelligence);man-machine systems;neural nets;telemedicine","fine-tuning network parameters;human operator;neural network;awareness scheme;human kinds;teleoperator system;remote workspace;term teleoperation;human-machine interactions;teleoperation system","","","","27","","30 Sep 2020","","","IEEE","IEEE Conferences"
"Self-Supervised Pose Adaptation for Cross-Domain Image Animation","C. Wang; C. Xu; D. Tao","School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW, Australia; School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW, Australia; School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW, Australia","IEEE Transactions on Artificial Intelligence","25 Nov 2020","2020","1","1","34","46","Image animation is to animate a still image of the object of interest using poses extracted from another video sequence. Through training on a large-scale video dataset, most existing approaches aim to explore disentangled appearance and pose representations of training frames. Then, the desired output with a specific appearance and pose can be synthesized via recombining learned representations. However, in some real-world applications, test images may lack the corresponding video ground-truth or follow a different distribution than the distribution of the training video frames (i.e., different domains), which largely limit the performance of existing methods. In this paper, we propose domain-independent pose representations that are compatible with and accessible by still images from a different domain. Specifically, we devise a two-stage self-supervised pose adaptation framework for general image animation tasks. A domain-independent pose adaptation generative adversarial network (DIPA-GAN) and a shuffle-patch generative adversarial network (Shuffle-patch GAN) are proposed to penalize the rationality of the synthesized frame's pose and appearance, respectively. Finally, experiments evaluated on various image animation tasks, which include same/cross-domain moving objects, facial expression transfer and human pose retargeting, demonstrate the superiority of the proposed framework over prior literature. Impact Statement-Image animation is a popular technology in video production. Benefiting from the rapid development of artificial intelligence (AI), recent image animation algorithms have been widely used in real-world applications, such as virtual AI news anchor, virtual try-on, and face swapping. However, most existing methods are designed for specific cases. To animate a new portrait, users are asked to collect hundreds of images of the same person and train a new model. The technology proposed in this paper overcomes these training limitations and generalizes image animations. In the challenging cross-domain facial expression transfer task, the user study demonstrated that our technology achieved more than 20% increase in animation success rate. The proposed technology could benefit users in a wide variety of industries including movie production, virtual reality, social media and online retail.","2691-4581","","10.1109/TAI.2020.3031581","Australian Research Council Projects; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229197","Adversarial learning;deep learning;representation learning","Animation;Task analysis;Training;Generative adversarial networks;Artificial intelligence;Solid modeling;Adaptation models","computer animation;face recognition;feature extraction;image classification;image motion analysis;image sequences;learning (artificial intelligence);neural nets;pose estimation;video signal processing;virtual reality","cross-domain image animation;video sequence;large-scale video dataset;learned representations;adaptation framework;general image animation tasks;adaptation generative adversarial network;shuffle-patch generative adversarial network;synthesized frame;video production;animation success rate;cross-domain facial expression transfer task;image animation algorithm;video ground-truth","","","","59","IEEE","19 Oct 2020","","","IEEE","IEEE Journals"
"Mechanical properties of the haptic signals indicative of a breast cancer tumor","M. Petrie; G. Thomas","Department of Mechanical and Industrial Engineering at The University of Iowa, 52242 USA; Department of Mechanical and Industrial Engineering at The University of Iowa, 52242 USA","2007 IEEE International Conference on Systems, Man and Cybernetics","2 Jan 2008","2007","","","2233","2238","A clinical breast exam (CBE), in which a nurse or doctor palpates a patient's breast tissue searching for hard lumps, is a recommended annual breast cancer diagnostic for women over 40. Recent advances in training technology have suggested that the sensitivity of this exam can be improved and that clinicians are interested in improving training approaches. Currently researchers have an incomplete understanding of which features of the force pattern an observer must perceive in order to recognize the presence of a tumor. This limitation in our knowledge limits our ability to build more effective simulators that emphasize the specific characteristics of the signal that clinicians must perceive. Three experiments were performed using tissue analogs made from silicone rubber embedded with hard spheres. The size of the balls, their depth and the stiffness of the silicone were varied. The force exerted on a probe indented at regular intervals along the samples revealed the general force profile that a clinician may experience on his or her finger pad when searching for a tumor. Several measures of the force profiles were compared to the salience of the ball within the silicone: the ratio of the response force directly above the sphere to the force response far from the sphere, the rate of change of the force response near the sphere, and difference between the force above and to the side divided by the force to the side. These measures correlated with salience when the ball size and ball depth was varied, but not when the silicone stiffness varied. The results suggest that the relationship between the force profile and the salience of the stimulus is more complex that expected. Once this relationship is more fully understood, new training tools and procedures can be developed to trains clinicians and improve the sensitivity of clinical breast exams.","1062-922X","978-1-4244-0990-7","10.1109/ICSMC.2007.4414166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4414166","","Mechanical factors;Haptic interfaces;Breast cancer;Breast neoplasms;Force measurement;Breast tissue;Pattern recognition;Rubber;Probes;Fingers","computer based training;force feedback;haptic interfaces;medical computing;touch (physiological)","haptic signals;breast cancer tumor;clinical breast exam;patient breast tissue;lump searching;breast cancer diagnostic;medical training;force pattern;tumor recognition;medical simulation;tissue analogs;silicone rubber;finger pad;force response;silicone stiffness;force profile;clinical training","","2","","25","","2 Jan 2008","","","IEEE","IEEE Conferences"
"A brain-computer interface to examine the effects of sound on a haptic-based virtual drilling task","D. Moreno; M. Melaisi; S. MacDonald; A. Uribe-Quevedo; B. Kapralos; M. V. Martin","Universidad Militar Nueva Granada Bogota, Colombia; University of Ontario Institute Technology, Oshawa, ON, Canada; University of Ontario Institute Technology, Oshawa, ON, Canada; Universidad Militar Nueva Granada Bogota, Colombia; University of Ontario Institute Technology, Oshawa, ON, Canada; University of Ontario Institute Technology, Oshawa, ON, Canada","2017 8th International Conference on Information, Intelligence, Systems & Applications (IISA)","15 Mar 2018","2017","","","1","4","Despite the recent hardware and computational advancements, virtual simulations and serious games have generally been restricted to cognitive skills training given the complexities and costs associated with high-end haptic-based rendering inherent in a variety of applications including those related to medical-based technical skills development. In this paper, we explore the effect of sound on haptic fidelity perception (with respect to a virtual drilling task), to determine whether sound can be used to increase our perception of haptic fidelity perception. To validate the effects we use data obtained from a brain-computer interface (BCI) and user ratings on the haptics and sound experience. Although our results are very preliminary, they do indicate that sound can influence (increase) haptic fidelity perception. Furthermore, our results also demonstrate the difficulty associated in employing a consumer-level BCI device in such a situation.","","978-1-5386-3731-9","10.1109/IISA.2017.8316403","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8316403","","Haptic interfaces;Electroencephalography;Task analysis;Visualization;Solid modeling;Training;Brain-computer interfaces","brain-computer interfaces;cognition;haptic interfaces;serious games (computing);virtual reality","brain-computer interface;haptic-based virtual drilling task;computational advancements;virtual simulations;serious games;cognitive skills;haptic fidelity perception;user ratings;sound experience;consumer-level BCI device;medical-based technical skills development","","","","15","","15 Mar 2018","","","IEEE","IEEE Conferences"
"Co-presentation of force cues for skill transfer via shared-control systems","D. Powell; M. K. O'Malley","Rice University, USA; Rice University, USA","2010 IEEE Haptics Symposium","8 Apr 2010","2010","","","453","456","During training and rehabilitation with haptic devices, it is often necessary to simultaneously present force cues arising from different haptic models (such as guidance cues and environmental forces). Multiple force cues are typically summed to produce a single output force, which conveys only relative information about the original force cues and may not be useful to trainees. Two force co-presentation paradigms are proposed as potential solutions to this problem: temporal separation of force cues, where one type of force is overlaid with the other in staggered pulses, and spatial separation, where the forces are presented via multiple haptic devices. A generalized model for separating task and guidance forces in a virtual environment is also proposed. In a pilot study where sixteen participants were trained in a dynamic target-hitting task using these co-presentation paradigms, simple summation was in fact most effective at eliciting skill transfer in most respects. Spatial separation imposed the lowest overall workload on participants, however, and might thus be more appropriate than summation in tasks with other significant physical or mental demands. Temporal separation was relatively inferior at eliciting skill transfer, but it is hypothesized that this paradigm would have performed considerably better in a non-rhythmic task, and the need for further research is indicated.","2324-7355","978-1-4244-6822-5","10.1109/HAPTIC.2010.5444619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444619","","Haptic interfaces;Virtual environment;Fixtures;Education;Performance evaluation;Manipulator dynamics;Displays;USA Councils;Force control;Feedback","haptic interfaces;virtual reality","force cues;skill transfer;shared-control systems;haptic devices;guidance cues;environmental forces;virtual environment;copresentation paradigms","","1","","7","","8 Apr 2010","","","IEEE","IEEE Conferences"
"A haptic display for tactile and kinesthetic feedback in a CHAI 3D palpation training scenario","J. Hergenhan; J. Rutschke; M. Uhl; S. E. Navarro; B. Hein; H. Worn","Institute of Anthropomatics and Robotics (IAR) - Intelligent Process Control and Robotics (IPR), Karlsruhe Institute of Technology (KIT), Engler-Bunte-Ring 8, 76137 Karlsruhe, Germany; Institute of Anthropomatics and Robotics (IAR) - Intelligent Process Control and Robotics (IPR), Karlsruhe Institute of Technology (KIT), Engler-Bunte-Ring 8, 76137 Karlsruhe, Germany; Faculty of Mechanical Engineering and Mechatronics (MMT), University of Applied Sciences, Karlsruhe, Germany; Institute of Anthropomatics and Robotics (IAR) - Intelligent Process Control and Robotics (IPR), Karlsruhe Institute of Technology (KIT), Engler-Bunte-Ring 8, 76137 Karlsruhe, Germany; Institute of Anthropomatics and Robotics (IAR) - Intelligent Process Control and Robotics (IPR), Karlsruhe Institute of Technology (KIT), Engler-Bunte-Ring 8, 76137 Karlsruhe, Germany; Institute of Anthropomatics and Robotics (IAR) - Intelligent Process Control and Robotics (IPR), Karlsruhe Institute of Technology (KIT), Engler-Bunte-Ring 8, 76137 Karlsruhe, Germany","2015 IEEE International Conference on Robotics and Biomimetics (ROBIO)","25 Feb 2016","2015","","","291","296","Robot-assisted minimally invasive surgery generally prevents the use of an important diagnostic tool in medicine: palpation. There are various approaches to reestablish the haptic feedback for the surgeon, including tactile displays and haptic input devices. We present a novel haptic display that features seven pins mounted on compression springs that can be pre-loaded with servo motors. Each pin has a stroke of 10 mm and a maximum counterforce of 1.1 N. An additional force of 0.7 N per pin can be applied with the motors. This technique allows for simultaneous stimulation of kinesthetic as well as tactile perception. The control of the haptic display has been implemented in the open-source haptics library CHAI 3D. We extended the framework with a multi interaction point tool to represent the hardware. This eventually lead to a palpation training program where bodies with multiple adjustable parameters encapsulated in a virtual soft tissue can be simulated. We evaluated this software in a user study with 15 participants in order to demonstrate the usability of the haptic display. With 90 % of successful hits, we are confident that sensible haptic feedback can be generated with the presented device. Furthermore, we are currently extending the scope of the haptic display to make use of a novel capacitive tactile proximity sensor in exploration scenarios.","","978-1-4673-9675-2","10.1109/ROBIO.2015.7418782","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7418782","","Haptic interfaces;Force;Servomotors;Robot sensing systems;Pins;Springs;Three-dimensional displays","C++ language;display instrumentation;feedback;haptic interfaces;medical robotics;public domain software;software libraries;surgery","kinesthetic feedback;tactile feedback;CHAI 3D palpation training scenario;haptic display;compression springs;servo motors;pins;open-source haptics library;multiinteraction point tool;virtual soft tissue;robot-assisted minimally invasive surgery;C++library","","4","","22","","25 Feb 2016","","","IEEE","IEEE Conferences"
"Sepsis Fast Track: A simulation game for Clinical education based on the Sepsis Fast Track protocol","C. Ribeiro; M. Monteiro; J. B. Hauge; J. Pereira; T. Antunes","INESC-ID, Instituto Superior Técnico, Universidade Técnica de Lisboa, Portugal; Serviço de Urgência Geral Centro Hospitalar Lisboa Ocidental, Lisbon, Portugal; Bremer Institut für Produktion und Logistik, Hochschulring 20, 28359 Bremen Germany; INESC-ID, Instituto Superior Técnico, Universidade Técnica de Lisboa, Portugal; INESC-ID, Instituto Superior Técnico, Universidade Técnica de Lisboa, Portugal","2016 IEEE International Conference on Serious Games and Applications for Health (SeGAH)","10 Oct 2016","2016","","","1","8","Sepsis is a serious medical condition responsible for high levels of in-hospital mortality. It requires fast diagnosis and treatment, since the survival rate decreases 7.6% for every hour without treatment. In order to facilitate this process of diagnosis and medical therapy, the Portuguese Directorate-General of Health issued a document regulating the implementation of a Sepsis Fast Track protocol based on the Surviving Sepsis Campaign guidelines. Training of emergency department healthcare professionals is essential, and should be attended regularly in order to refresh knowledge and to be made aware of updates to any changes of the protocol. Currently, this training is conducted through traditional learning methods often considered as outdated for the younger generation, the so-called ""digital natives"". The usage of serious games is a trend that has been considered when discussing new tools for teaching and training in various fields, including healthcare. Several research works on the impact of applying such technologies in healthcare, stating that serious games could provide new approaches and opportunities have been published. This paper presents the Sepsis Fast Track serious game. It is a serious game developed to teach and train nurses and physicians working in hospital Emergency Departments on the Sepsis Fast Track protocol. An evaluation study carried out with the healthcare professionals is also presented. The main goal of which was to evaluate the impact of serious games on professional working practices.","","978-1-5090-2210-6","10.1109/SeGAH.2016.7586226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586226","","Games;Training;Protocols;Hospitals","computer aided instruction;health care;medical diagnostic computing;serious games (computing)","simulation game;clinical education;sepsis fast track protocol;in-hospital mortality;medical therapy;medical diagnosis;Portuguese Directorate-General of Health;surviving Sepsis campaign guidelines;emergency department healthcare professionals;digital natives;serious games;healthcare professionals;emergency departments;professional working practices","","1","","19","","10 Oct 2016","","","IEEE","IEEE Conferences"
"Lung capacity estimation through acoustic signal of breath","A. Abushakra; M. Faezipour","Department of Computer Science & Engineering University of Bridgeport, Bridgeport, CT 06604; Department of Computer Science & Engineering University of Bridgeport, Bridgeport, CT 06604","2012 IEEE 12th International Conference on Bioinformatics & Bioengineering (BIBE)","3 Jan 2013","2012","","","386","391","Breathing disorders are generally associated with the lung cancer disease. Through daily treatment, lung cancer patients often use a traditional spirometer to measure their lung capacity. However, the use of a spirometer device for accurate measurement requires some sort of training and adjustment, which may be inconvenient for certain groups of patients, especially the elderly. In addition, the spirometer readings can become unreliable if the measurements are not taken as instructed. On the other hand, a microphone, say the microphone on a hand-held device such as a smart-phone, can easily capture the acoustic signal of breath without certain instructions. This signal can then be processed to estimate the lung capacity. In this paper, we propose a methodology through the simply recorded acoustic signal of breath, splitting the breathing cycle to inhale, pause, exhale and pause phases to measure the depth of the breath along with the time duration and signal energy of the breathing phases. We show how these computed parameters are used to estimate the lung size with a high degree of accuracy. This work is part of a virtual reality platform embedded within a smart-phone to assist lung cancer patients regulate their breath. Furthermore, the lung capacity estimation methodology proposed in this paper can also be used to aid patients with other breathing disorders.","","978-1-4673-4358-9","10.1109/BIBE.2012.6399655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6399655","Acoustic signal of breath;lung capacity;microphone","Lungs;Cancer;Speech;Microphones;Acoustics;Equations;Mathematical model","acoustic signal processing;bioacoustics;biomedical measurement;cancer;lung;medical computing;medical disorders;microphones;pneumodynamics;smart phones;virtual reality","lung capacity estimation;breath acoustic signal;breathing disorders;lung cancer disease;spirometer device;elderly patients;microphone;handheld device;smartphone;simply recorded acoustic signal;breathing cycle;computed parameters;lung size;virtual reality platform","","9","","22","","3 Jan 2013","","","IEEE","IEEE Conferences"
"BCI decoder performance comparison of an LSTM recurrent neural network and a Kalman filter in retrospective simulation","T. Hosman; M. Vilela; D. Milstein; J. N. Kelemen; D. M. Brandman; L. R. Hochberg; J. D. Simeral","School of Engineering and Carney Institute for Brain Science, Brown University, Providence, RI, 02912; School of Engineering and Carney Institute for Brain Science, Brown University, Providence, RI, 02912; Department of Computer Science and Carney Institute for Brain Science, Brown University; Department of Neurology, Massachusetts General Hospital (MGH), Boston, MA; School of Engineering, Brown University; Dept. of VA Med. Ctr., VA Rehabilitation R&D Center for Neurorestoration and Neurotechnology, Providence, RI; Dept. of VA Med. Ctr., VA Rehabilitation R&D Center for Neurorestoration and Neurotechnology, Providence, RI","2019 9th International IEEE/EMBS Conference on Neural Engineering (NER)","20 May 2019","2019","","","1066","1071","Intracortical brain computer interfaces (iBCIs) using linear Kalman decoders have enabled individuals with paralysis to control a computer cursor for continuous point-and-click typing on a virtual keyboard, browsing the internet, and using familiar tablet apps. However, further advances are needed to deliver iBCI-enabled cursor control approaching able-bodied performance. Motivated by recent evidence that nonlinear recurrent neural networks (RNNs) can provide higher performance iBCI cursor control in nonhuman primates (NHPs), we evaluated decoding of intended cursor velocity from human motor cortical signals using a long-short term memory (LSTM) RNN trained across multiple days of multi-electrode recordings. Running simulations with previously recorded intracortical signals from three BrainGate iBCI trial participants, we demonstrate an RNN that can substantially increase bits-per-second metric in a high-speed cursor-based target selection task as well as a challenging small-target high-accuracy task when compared to a Kalman decoder. These results indicate that RNN decoding applied to human intracortical signals could achieve substantial performance advances in continuous 2-D cursor control and motivate a real-time RNN implementation for online evaluation by individuals with tetraplegia.","1948-3554","978-1-5386-7921-0","10.1109/NER.2019.8717140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8717140","","Decoding;Task analysis;Kalman filters;Recurrent neural networks;Bit rate;Data models;Brain modeling","biomedical electrodes;brain;brain-computer interfaces;decoding;handicapped aids;human computer interaction;Kalman filters;medical signal processing;neural nets;neurocontrollers;neurophysiology;recurrent neural nets","retrospective simulation;intracortical brain computer interfaces;linear Kalman decoders;computer cursor;continuous point;virtual keyboard;familiar tablet apps;cursor control;able-bodied performance;nonlinear recurrent neural networks;higher performance;intended cursor velocity;human motor cortical signals;long-short term memory RNN;multielectrode recordings;recorded intracortical signals;BrainGate iBCI trial participants;high-speed cursor-based target selection task;challenging small-target high-accuracy task;Kalman decoder;human intracortical signals;substantial performance advances;BCI decoder performance comparison;LSTM recurrent neural network;Kalman filter","","3","","31","","20 May 2019","","","IEEE","IEEE Conferences"
"Physical rehabilitation based on kinect serious games","D. Ferreira; R. Oliveira; O. Postolache","Instituto Universitário de Lisboa, ISCTE-IUL, Instituto de Telecomunicações, IT-IUL, Lisbon, Portugal; Faculdade de Motricidade Humana, Universidade de Lisboa, Lisbon, Portugal; Instituto Universitário de Lisboa, ISCTE-IUL, Instituto de Telecomunicações, IT-IUL, Lisbon, Portugal","2017 Eleventh International Conference on Sensing Technology (ICST)","1 Mar 2018","2017","","","1","6","This article presents a serious game framework developed using Unity 3D game engine and Kinect V2 sensor as a natural user interface. The developed serious games are used for objective evaluation of physical rehabilitation considering the Kinect V2 sensors for 3D motion detection of different body joints training and provide different types of data, such as angles velocities, for physiotherapists and patients during the rehabilitation process. The framework provide data storage capability in a remote database thus patient's biometric data, patients' medical record, obtained scores during serious game based training and values of metrics such as the distance between feet during game, left right feet usage frequency and execution time for imposed movement associated with game mechanics. A general description of the applied technologies on serious game for lower limb rehabilitation developments as so as the experimental results obtained for a set of volunteers are included in the paper.","2156-8073","978-1-5090-6526-4","10.1109/ICSensT.2017.8304512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8304512","objective physiotherapy;lower limb rehabilitation;Kinect sensor;serious game;virtual reality","Games;Training;Three-dimensional displays;Databases;Sensors;Software;Mobile applications","medical computing;patient rehabilitation;serious games (computing)","physical rehabilitation;serious game framework;Kinect V2 sensor;natural user interface;3D motion detection;rehabilitation process;data storage capability;feet usage frequency;execution time;game mechanics;lower limb rehabilitation developments;Kinect serious games;Unity 3D game engine;body joints training","","8","","15","","1 Mar 2018","","","IEEE","IEEE Conferences"
"Ability of the Information Science teachers to teach programing in the lower grades of primary school","J. Žufić; A. Žufić","Juraj Dobrila University of Pula,Faculty of Educational Sciences,Pula,Croatia; Elementary school Veli Vrh Pula,Pula,Croatia","2020 43rd International Convention on Information, Communication and Electronic Technology (MIPRO)","6 Nov 2020","2020","","","899","904","In anticipation of the introduction of the elective subject of Information Sciences for the lower grades of primary school, a question of the professional teaching competences of students - future teachers and current teachers of Information Sciences (with an emphasis on programing), comes into the focus. This article discusses their ability from professional (knowledge of programing) and pedagogical aspects. We present the results of a research conducted among students of the Faculty of Education Sciences with a module in Information Sciences and Informatics Teachers in the Class Teaching study group. Respondents, through self-evaluation of their knowledge and competencies in the field of programing, gave answers from which it can be concluded whether they are ready to teach programing. The article also presents a case study in which students of the final year of the Faculty of Education Sciences with a module of Information Sciences, made a video clip of processing new contents for a programing class, as a methodical exercise. The programing languages used were Scratch, Python and the micro:bit simulator. Project assignments were correlated with the subjects of Croatian language, Physical and Health Culture, Music Culture, Mathematics and Information Sciences. The results of the research indicate that the respondents are generally ready, but they would need additional education in programing domain.","2623-8764","978-953-233-099-1","10.23919/MIPRO48935.2020.9245284","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9245284","programming;Scratch;classroom teaching;computer thinking and programming","Training;Information science;Education;Mathematics;Informatics;Programming profession;Python","computer science education;educational institutions;teacher training;teaching","lower grades;primary school;professional teaching competences;education sciences;programing class;programing languages;information science teachers;programing teaching;class teaching study group","","","","16","","6 Nov 2020","","","IEEE","IEEE Conferences"
"Blaze: A serious game for improving household fire safety awareness","A. DeChamplain; E. Rosendale; I. McCabe; M. Stephan; V. Cole; B. Kapralos","Squabble Studios, Oshawa, Ontario, Canada; Squabble Studios, Oshawa, Ontario, Canada; Squabble Studios, Oshawa, Ontario, Canada; Squabble Studios, Oshawa, Ontario, Canada; Squabble Studios, Oshawa, Ontario, Canada; Faculty of Business and Information Technology, University of Ontario Institute of Technology, Oshawa, Ontario, Canada","2012 IEEE International Games Innovation Conference","15 Oct 2012","2012","","","1","4","A longstanding issue among the general public in North America is the lack of awareness about common household fire safety practices and procedures. With the knowledge that virtual simulations and more recently, serious games, can provide environments for individuals to experience and learn from situations that would typically be dangerous and life-threatening, we have developed Blaze, a highly interactive serious game aimed at improving household fire safety awareness. Through exposing the audience to these usually harmful and rare events, initial reaction to common situations, as well as problem-solving under pressure can be experienced safely in a realistic environment.","2166-675X","978-1-4673-1358-2","10.1109/IGIC.2012.6329839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6329839","serious games;fire safety;virtual simulation;virtual environment;personal fire safety awareness","Fires;Games;Training;Conferences;Computational modeling","computer games;digital simulation;fires;interactive systems;safety","Blaze;household fire safety awareness improvement;North America;virtual simulations;interactive serious game;problem-solving","","3","","12","","15 Oct 2012","","","IEEE","IEEE Conferences"
"Proposal for a computer-based learning environment (CBLE) to improve the decision-making skills of general aviation pilots","N. Barrette-Sabourin; D. Dodds-Nagy; K. Staudinger","Concordia Univ., Montreal, Que., Canada; NA; NA","19th DASC. 19th Digital Avionics Systems Conference. Proceedings (Cat. No.00CH37126)","6 Aug 2002","2000","2","","5C3/1","5C311 vol.2","A discussion and description of a computer-based learning environment (CBLE) to improve the decision-making skills of GA pilots are presented. Critical needs, the decision-making model applicable to piloting, a cognitive task analysis, and the learning objectives are examined. The theoretical considerations that served to guide the design are discussed. Finally the design itself is described in a flowchart and a storyboard. The CBLE presents the learner with a number of dynamic adverse weather situations using multimedia technology. The learner interacts with the CBLE as a pilot of a generic small aircraft encountering difficult weather and engages in the decision-making processes warranted by a given situation.","","0-7803-6395-7","10.1109/DASC.2000.884881","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=884881","","Proposals;Decision making;Accidents;Aerodynamics;Aircraft;FAA;Flowcharts;Instruments;Meteorology;Feedback loop","computer based training;aerospace simulation;decision support systems;multimedia computing;task analysis;aerospace computing","CBL environment;decision-making skills;general aviation pilots;critical needs;decision-making model;cognitive task analysis;learning objectives;software flowchart;storyboard;dynamic adverse weather situations;multimedia technology;generic small aircraft pilot;naturalistic models;recognition-primed decision-making model;constructivism","","","","7","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Towards Playing a 3D First-Person Shooter Game Using a Classification Deep Neural Network Architecture","P. B. S. Serafim; Y. L. B. Nogueira; C. A. Vidal; J. B. C. Neto","Department of Computing Federal University of Cear´a , Fortaleza, Brazil; Dept. of Comput., Fed. Univ. of Ceara, Fortaleza, Brazil; Department of Computing Federal University of Cear´a , Fortaleza, Brazil; Dept. of Comput., Fed. Univ. of Ceara, Fortaleza, Brazil","2017 19th Symposium on Virtual and Augmented Reality (SVR)","20 Nov 2017","2017","","","120","126","In this work, we present a network architecture to solve a supervised learning problem, the classification of a handwritten dataset, and a reinforcement learning problem, a complex First-Person Shooter 3D game environment. We used a Deep Neural Network model to solve both problems. For classification, we used a Softmax regression and cross entropy loss to train the network. To play the game, we used a Q-Learning adaptation for Deep Learning to train the autonomous agent. In both cases, the input was only the pixels of an image. We show that this single network architecture is suitable for the classification task and is capable of playing the 3D game. This result gives us an insight into the possibility of a general network architecture, capable of solving any kind of problems, regardless of the learning paradigm.","","978-1-5386-3588-9","10.1109/SVR.2017.24","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114428","first-person 3D environment;visual-based autonomous agent;supervised learning;reinforcement learning;deep neural networks","Games;Learning (artificial intelligence);Training;Three-dimensional displays;Neural networks;Supervised learning","computer games;handwritten character recognition;image classification;learning (artificial intelligence);neural nets","classification Deep Neural Network architecture;supervised learning problem;reinforcement learning problem;handwritten dataset classification;3D First-Person Shooter game;Softmax regression;cross entropy loss;network training;Q-Learning adaptation;image pixels;digital games;handwritten digit classification","","4","","25","","20 Nov 2017","","","IEEE","IEEE Conferences"
"Understanding the Interplay of Model Complexity and Fidelity in Multiagent Systems via an Evolutionary Framework","E. Lakshika; M. Barlow; A. Easton","School of Engineering and IT, University of New South Wales, Canberra, Australia; School of Engineering and IT, University of New South Wales, Canberra, Australia; Simcentric Technologies, Oxford, U.K.","IEEE Transactions on Computational Intelligence and AI in Games","13 Sep 2017","2017","9","3","277","289","Modern video games come with highly realistic graphics enabling the players to interact with visually rich virtual worlds. Realistic (life-like) animation of nonplayer characters (NPCs) in such virtual worlds is particularly important to enhance the gaming experience. Multiagent systems are one effective approach to synthesize life-like behaviors and interactions by codifying simple rules into NPCs (each NPC as an autonomous agent). However, such behaviors generally come at the cost of increasing computational expense and complexity in terms of aspects such as number of rules and parameters. Therefore, the desire for high fidelity (highly realistic) behaviors is often in conflict with the drive for low complexity. Multiobjective evolutionary algorithms provide a sophisticated mechanism to optimize two or more conflicting objectives simultaneously. However, evolutionary computing techniques need an appropriate objective function to drive the exploration in the correct direction. Pairing of evolutionary techniques and multiagent systems is challenging in the classes of problems in which the fitness is evaluated based on human aesthetic judgment rather than on objective forms of measurements. In this study, we present a multiobjective evolutionary framework to evolve low complexity and high fidelity multiagent systems by utilizing a machine learning system trained by bootstrapping human aesthetic judgment. We have gathered empirical data in three problem areas-simulation of conversational group dynamics, sheepdog herding behaviors, and traffic dynamics, and show the effectiveness of our approach in deriving low complexity and high fidelity multiagent systems. Further, we have identified common properties of the Pareto-optimal frontiers in the three problem areas that can ultimately lead to an understanding of a relationship between simulation model complexity and behavior fidelity. This understanding will be useful in deciding which level of behavioral fidelity is required for the characters in video games based on the distance to the camera, importance to the scene, and available computational resources.","1943-0698","","10.1109/TCIAIG.2016.2560882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7463035","Complexity;fidelity;level of detail artificial intelligence (LOD AI);multiagent systems;multiobjective optimization","Complexity theory;Multi-agent systems;Optimization;Evolutionary computation;Computational modeling;Learning systems;Games","computational complexity;computer animation;computer games;evolutionary computation;multi-agent systems;Pareto optimisation;statistical analysis;virtual reality","multiobjective evolutionary algorithms;evolutionary computing techniques;multiobjective evolutionary framework;simulation model complexity;behavioral fidelity;virtual worlds;objective function;multiagent systems;video games;nonplayer characters;NPC animation;realistic graphics;human aesthetic judgment bootstrapping;Pareto-optimal frontiers","","1","","36","Traditional","29 Apr 2016","","","IEEE","IEEE Journals"
"A Real-Time ECG Feature Extraction Algorithm for Detecting Meditation Levels within a General Measurement Setup","H. Alawieh; Z. Dawy; E. Yaacoub; N. Abbas; J. El-Imad","Department of Electrical and Computer Engineering, American University of Beirut, Beirut, Lebanon; Department of Electrical and Computer Engineering, American University of Beirut, Beirut, Lebanon; Department of Electrical and Computer Engineering, American University of Beirut, Beirut, Lebanon; NeuroPro AG, Zurich, Switzerland; Department of Electrical & Electronic Engineering, Imperial College, London, UK","2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","7 Oct 2019","2019","","","99","103","This paper presents a setup for the real-time extraction of Electroencephalography (EEG) and Electrocardiogram (ECG) features indicating the level of focus, relaxation, or meditation of a given subject. An algorithm for detecting meditation in real-time using the extracted ECG features is designed and shown to lead to accurate results using an online ECG measurement dataset. Similar methods can be used for EEG data, such that the proposed measurement setup can be used, for example, for investigating the effect of virtual reality based EEG training, with and without neurofeedback, on the capability of subjects to focus, relax, or meditate.","1558-4615","978-1-5386-1311-5","10.1109/EMBC.2019.8857832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8857832","","Feature extraction;Electrocardiography;Electroencephalography;Biomedical monitoring;Heart rate variability;Real-time systems","electrocardiography;electroencephalography;feature extraction;medical signal detection;medical signal processing;virtual reality","electrocardiogram features;extracted ECG features;online ECG measurement dataset;real-time ECG feature extraction algorithm;meditation levels;electroencephalography;EEG data;virtual reality;neurofeedback","Algorithms;Electrocardiography;Electroencephalography;Meditation;Neurofeedback","1","","8","","7 Oct 2019","","","IEEE","IEEE Conferences"
"Bangla Sign Language recognition using convolutional neural network","F. Yasir; P. W. C. Prasad; A. Alsadoon; A. Elchouemi; S. Sreedharan","Charles Sturt University Study Centre, Sydney, Australia; Charles Sturt University Study Centre, Sydney, Australia; Charles Sturt University Study Centre, Sydney, Australia; Walden University, USA; Department of Computer Engineering, College of Computer Science, King Khalid University, KSA","2017 International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT)","23 Apr 2018","2017","","","49","53","This paper presents a learning based approach to Bangla Sign Language(BdSL) recognition using the convolutional neural network. In our proposed method, a virtual reality-based hand tracking controller known as Leap motion controller (LMC) has introduced to track the continuous motion of the hands. LMC provides a skeletal model of the hand with appropriate data of hand position, orientation, rotation, fingertips, grabbing and more non-linear features. This controller preprocessed all the motion features and provides error free data. This machine calibrates with the environment and builds a virtual hand in a space. LMC also calculates the rotation, orientation, and textures from hands to determine and to extract hand gesture. In the next process, an efficient method is established to proceed a sequence of frames for positional hand gestures and summarize them to a shorter and more generalized sequence of lines and curves which are added to a Hidden Markov Model. For each sign of expression, we considered a start and an end point of state and segmented the state transitions into segmented HMM. In the segmentation, we assumed the state scope of the hidden variables is discrete. The transition probabilities controlled the way of hidden state at a distinct time. If there is a histogram difference in any state, the transition state moved to new frame to achieve a new sign expression. If there is no hand gesture in the frame, the state has ended by moving to the end point of the model. In the end point, we evaluated the desired hand gesture for recognition. After evaluation, hand gesture data set are proceeded over the convolutional neural network (CNN) and built a decision network. Each neuron is built up by calculating the dot product of extracted features in the dataset. In CNN, a single vector of hand gesture data is received and connected through a series of hidden layers and in the end point computed as a single vector loss function. Each feature is considered as a hidden layer. Determining the least loss function, the network recognizes the expected sign expression. In our experiment, we considered training data first to create the neurons in our network as a supervised way. We achieved significant results from our basic sign expressions in a 3% rate of error where without distortion the rate reduced to 2%. This is an enormous achievement in the Bangla sign language recognition method.","","978-1-5090-6106-8","10.1109/ICICICT1.2017.8342533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8342533","Bangla Sign Language Recognition;Hidden Markov model;Convolution neural network;leap motion controller","Thumb;Hidden Markov models;Assistive technology;Gesture recognition;Bones;Feature extraction","computer vision;convolution;feature extraction;feedforward neural nets;gesture recognition;hidden Markov models;learning (artificial intelligence);motion control;object detection;sign language recognition;virtual reality","LMC;skeletal model;hand position;motion features;error free data;positional hand gestures;shorter sequence;Hidden Markov Model;end point;state transitions;state scope;hidden state;transition state;desired hand gesture;hand gesture data;convolutional neural network;decision network;hidden layer;basic sign expressions;Bangla sign language recognition method;virtual reality;Leap motion controller;continuous motion;virtual hands;generalized sequence;sign expression;BdSL recognition;CNN","","","","19","","23 Apr 2018","","","IEEE","IEEE Conferences"
"Flexible Indoor Scene Synthesis via a Multi-object Particle Swarm Intelligence Optimization Algorithm and User Intentions","Y. Li; X. Wang; Z. Wu; S. Liu; M. Zhou",Beijing Normal University; Beijing Normal University; Beijing Normal University; Beijing Normal University; Beijing Normal University,"2019 International Conference on Cyberworlds (CW)","5 Dec 2019","2019","","","29","36","Flexible indoor scene synthesis is a popular topic in computer graphics and virtual reality research due to its wide-ranging applications in home design, games and automated robotics training. We propose a novel approach to automatic and flexible indoor scene synthesis using an energy-based method. We regard indoor scene synthesis as a multiple-object optimization problem with furniture location and orientation according to the user's intention, as a constraint on the energy of the optimization problem. Based on the relationship of objects, the embedded aesthetic criterion, the design criterion for proper placement and human movement in a scene, we design five energy functions, the overlap constraint, pairwise constraint, wall constraint, aisle constraint, angle constraint and penalty item, are proposed. We use a multi-object particle swarm intelligence optimization method with a Markov chain Monte Carlo algorithm to solve this optimization problem and obtain a Pareto-optimal solution. 3D gestures are used as the medium of interaction between the user and the system. Our method significantly enhances the existing weighted energy optimization method by allowing a joint optimization of various energy functions. The experiments confirm that all the energy functions can converge at the same time and that the proposed method obtains results superior to those of the weighted methods. The proposed method is general which can be used to obtain layouts for various kind of rooms with different furniture.","2642-3596","978-1-7281-2297-7","10.1109/CW.2019.00014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918966","Indoor scene synthesis, Automatic layout, Multiobject particle swarm intelligence, Pareto optimal, 3D gesture","Layout;Three-dimensional displays;Optimization;Particle swarm optimization;Solid modeling;Task analysis;Databases","furniture;Markov processes;Monte Carlo methods;Pareto optimisation;particle swarm optimisation;virtual reality","flexible indoor scene synthesis;multiobject particle swarm intelligence optimization algorithm;energy-based method;multiple-object optimization problem;energy functions;multiobject particle swarm intelligence optimization method;Pareto-optimal solution;weighted energy optimization method;user intentions;computer graphics;virtual reality;overlap constraint;pairwise constraint;wall constraint;aisle constraint;angle constraint;penalty item;Markov chain Monte Carlo algorithm;3D gestures;furniture location","","","","29","","5 Dec 2019","","","IEEE","IEEE Conferences"
"Production of body model for education of dance by measurement active quantity","M. Takai","Graduate School of Science and Engineering, Tokyo Institute of Technology, Yokohama, Japan","The 1st IEEE Global Conference on Consumer Electronics 2012","13 Dec 2012","2012","","","212","216","This study makes a body model for education of dance how lively a dance trainer moves his/her body so that the dance student can learn dance from the dance trainer who is in the distant place through communication line in virtual dance studio. In late years, network game gives the virtual space enjoying sports, music, and dance to plural people who are in the remote place at the same time. However, the general network game has to attach sensors or devices to the body of the players to input livingness by the movement of them. Therefore, not only they feel botheration in the player attaching sensors or devices, but also it is necessary to spend labor and time to attach sensors or devices to the body. This study proposes Active Quantity to measure with quantity from 0.0 to 1.0 from a dynamic image which photographed the movement of the dance trainer in digital video camera. Furthermore, the proposal method makes the body model that put the silhouette of the dance trainer and Active Quantity together so that the dance students are easy to understand the movement of the dance trainer from sight.","2378-8143","978-1-4673-1501-2","10.1109/GCCE.2012.6379584","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6379584","human action;body model;camera;virtual;dance","Proposals;Foot;Brightness;Legged locomotion;Sensors;Hidden Markov models;Games","computer aided instruction;computer games;human computer interaction;humanities;image sensors;music;sport;user interfaces;virtual reality","body model production;dance education;measurement active quantity;communication line;virtual dance studio;network game;virtual space;digital video camera;sports;music","","1","","6","","13 Dec 2012","","","IEEE","IEEE Conferences"
"EMG Feature Extractions for Upper-Limb Functional Movement During Rehabilitation","M. S. Hazam Majid; W. Khairunizam; A. B. Shahriman; I. Zunaidi; B. N. Sahyudi; M. R. Zuradzman","AiCOS Research Lab, School of Mechatronic, Universiti Malaysia Perlis, Perlis, Malaysia; AiCOS Research Lab, School of Mechatronic, Universiti Malaysia Perlis, Perlis, Malaysia; AiCOS Research Lab, School of Mechatronic, Universiti Malaysia Perlis, Perlis, Malaysia; Technopreneur at UniMAP Sdn. Bhd., Perlis, 01000, Malaysia; AiCOS Research Lab, School of Mechatronic, Universiti Malaysia Perlis, Perlis, Malaysia; AiCOS Research Lab, School of Mechatronic, Universiti Malaysia Perlis, Perlis, Malaysia","2018 International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS)","29 Nov 2018","2018","3","","314","320","Rehabilitation is important treatment for post stroke patient to regain their muscle strength and motor coordination as well as to retrain their nervous system. Electromyography (EMG) has been used by researcher to enhance conventional rehabilitation method as a tool to monitor muscle electrical activity however EMG signal is very stochastic in nature and contains some noise. Special technique is yet to be researched in processing EMG signal to make it useful and effective both to researcher and to patient in general. Feature extraction is among the signal processing technique involved and the best method for specific EMG study needs to be applied. In this works, nine feature extractions techniques are applied to EMG signals recorder from subjects performing upper limb rehabilitation activity based on suggested movement sequence pattern. Three healthy subjects perform the experiment with three trials each and EMG data were recorded from their bicep and deltoid muscle. The applied features for every trials of each subject were analyzed statistically using student T-Test their significant of p-value. The results were then totaled up and compared between the nine features applied and Auto Regressive coefficient (AR) present the best result and consistent with each subjects' data. This feature will be used later in our future research work of Upper-limb Virtual Reality Rehabilitation.","2189-8723","978-1-5386-7516-8","10.1109/ICIIBMS.2018.8549932","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8549932","Electromyography;Arm Rehabilitation;Feature extraction","Electromyography;Muscles;Feature extraction;Task analysis;Training;Electrodes","biomechanics;electromyography;feature extraction;medical computing;medical robotics;medical signal processing;neurophysiology;patient rehabilitation;virtual reality","EMG feature extractions;important treatment;post stroke patient;muscle strength;motor coordination;nervous system;conventional rehabilitation method;muscle electrical activity;special technique;processing EMG signal;feature extraction;signal processing technique;specific EMG study;feature extractions techniques;EMG signals recorder;upper limb rehabilitation activity;suggested movement sequence pattern;healthy subjects;EMG data;bicep;deltoid muscle;future research work;upper-limb virtual reality rehabilitation;upper-limb functional movement","","1","","22","","29 Nov 2018","","","IEEE","IEEE Conferences"
"Residual MLP Network for Mental Fatigue Classification in Mining Workers from Brain Data","A. C. Q. Siravenha; M. N. F. Reis; I. Cordeiro; R. A. Tourinho; B. D. Gomes; S. R. Carvalho",Vale Institute of Technology; Federal University of Para; Vale Institute of Technology; Vale S/A; Federal University of Para; Vale Institute of Technology,"2019 8th Brazilian Conference on Intelligent Systems (BRACIS)","5 Dec 2019","2019","","","407","412","At the mining industry, human safety and productivity are both desirable in the logistics pipeline. Since the operation of heavy machines requires continued vigilance and mental activity, fatigue caused by long hours of work and constant effort generally occurs in this environment. In general, mental fatigue is related to a loss of efficiency, leading to a decrease in productivity and inducing critical errors, which can provoke equipment breakups or accidents with human victims. At this high cognitive workload environment, there is a need for the development of robust monitoring techniques aiming to predict mental fatigue before workers' movement responses become slower, more variable, and more error-prone. In this work, we introduce a residual multilayer perceptron (MLP) network (ResMLPNet) and assess its performance in the challenging problem of mental fatigue classification from cognitive electrophysiology data, acquired during Virtual Reality (VR) training sessions mimicking a real operation faced by excavator workers at the mining industry. In a three-step training strategy, the ResMLPNet achieved slightly better classification accuracies compared to its plain MLP architecture.","2643-6264","978-1-7281-4253-1","10.1109/BRACIS.2019.00078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8923986","Residual multilayer perceptron network;Classification;mental fatigue;EEG time series","Fatigue;Electroencephalography;Electrodes;Training;Task analysis;Databases;Benchmark testing","brain;cognition;electroencephalography;ergonomics;fatigue;medical signal processing;mining industry;multilayer perceptrons;neurophysiology;occupational stress;pattern classification;virtual reality","mining workers;brain data;mining industry;human safety;logistics pipeline;mental activity;human victims;residual multilayer perceptron network;mental fatigue classification;cognitive electrophysiology data;residual MLP network","","","","15","","5 Dec 2019","","","IEEE","IEEE Conferences"
"Realtime Coarse Pose Recognition Using a Multi-scaled Local Integral Histograms","D. Jang; Y. Chai; X. Jin; T. Kim","Chung-Ang Univ., Seoul; Chung-Ang Univ., Seoul; Chung-Ang Univ., Seoul; Chung-Ang Univ., Seoul","2007 International Conference on Convergence Information Technology (ICCIT 2007)","7 Jan 2008","2007","","","1982","1987","We present a fast and robust algorithm for segmenting foreground object from background image by comparing local histograms. Background subtraction is a important preprocessing step for extracting the features that can be used for object tracking in surveillance system or HCI system in virtual environment. In this paper, the local histograms of the same area are used to compute a foreground probability. The histogram-based method is partially robust against illumination change and small moving objects in background. However without data quantization to reduce bin size, histograms are generally not suitable for realtime applications. Moreover quantization errors are a major drawback of using histograms. We propose a new method to keep the advantages of histograms without suffering computational load and quantization error using local kernel histogram with the multi-scaled integral histograms. We implement the video game interface with a trained neural network to prove the proposed method is highly applicable to coarse pose recognition.","","0-7695-3038-9","10.1109/ICCIT.2007.273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4420542","","Histograms;Quantization;Robustness;Image segmentation;Feature extraction;Surveillance;Human computer interaction;Virtual environment;Lighting;Kernel","computer games;feature extraction;human computer interaction;image motion analysis;image segmentation;learning (artificial intelligence);object detection;pose estimation;tracking;video surveillance","realtime coarse pose recognition;multiscaled local integral histograms;foreground object segmentation;background subtraction;features extraction;object tracking;surveillance system;HCI system;foreground probability;local kernel histogram;video game interface;trained neural network","","","","16","","7 Jan 2008","","","IEEE","IEEE Conferences"
"Enter the Serious E-scape Room: A Cost-Effective Serious Game Model for Deep and Meaningful E-learning","S. Mystakidis; E. Cachafeiro; I. Hatzilygeroudis","University of Jyväskylä & Patras,Faculty of Information Technology,Jyväskylä,Finland & Patras,Greece; OESO Duke Health,Durham,USA; University of Patras,Department of Computer Engineering & Informatics,Patras,Greece","2019 10th International Conference on Information, Intelligence, Systems and Applications (IISA)","14 Nov 2019","2019","","","1","6","Escape rooms are a phenomenon that has taken the world by storm in the last decade. Simultaneously Virtual Reality is a promising technology for innovation in education, training and e-learning. Combining these two concepts, this paper outlines a new model for designing serious games in virtual reality environments for high quality, deep and meaningful learning, the Serious E-scape Room. It describes the theoretical grounding, general guidelines and principles of the model. It also presents the case study “Room of Keys”, a serious virtual escape room for biology concepts. To test the assumptions of the model, researchers conducted a mixed research study with 148 students in a US high school. Pre-post test results recorded a 13.8% performance increase and high overall satisfaction. The game has been received enthusiastically by students, it increased their motivation and helped them build a deeper understanding of the learned concepts.","","978-1-7281-4959-2","10.1109/IISA.2019.8900673","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900673","escape room;virtual reality;serious games;deep and meaningful learning;biology","","computer aided instruction;educational institutions;serious games (computing);virtual reality","serious e-scape room;serious virtual escape room;serious game model;e-learning;virtual reality environments;US high school","","4","","32","","14 Nov 2019","","","IEEE","IEEE Conferences"
"ObjectStab-an educational tool for power system stability studies","M. Larsson","Lund Univ., Sweden","IEEE Transactions on Power Systems","19 Feb 2004","2004","19","1","56","63","Traditionally, the simulation of transient and voltage stability in power systems has been constrained to domain-specific tools such as Simpow, PSS/E, ETMSP, and EuroStag. While being efficient and thereby able to simulate large systems, their component models are often encapsulated and difficult or impossible to examine and modify. Also, these simulators often require substantial training and are therefore not ideal for normal classroom use. For academic and educational use, it is more important that the component modeling be transparent and flexible, and that students quickly get started with their simulations. This paper describes a freely available power system library called ObjectStab intended for power system stability simulations written in Modelica, a general-purpose object-oriented modeling language. All component models are transparent and can easily be modified or extended. Power system topology and parameter data are entered in one-line diagram form using a graphical editor. The component library has been validated using comparative simulations with EuroStag.","1558-0679","","10.1109/TPWRS.2003.821001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1266551","","Power system stability;Power system modeling;Object oriented modeling;Power system simulation;Mathematical model;Power system dynamics;Power system transients;Power system analysis computing;Libraries;Topology","power system stability;educational aids;power system simulation;computer aided instruction;object-oriented methods;educational courses","ObjectStab;educational tool;power system stability;power system library;Modelica;object-oriented modeling language;power system topology;graphical editor;EuroStag;power system simulation","","42","","14","","19 Feb 2004","","","IEEE","IEEE Journals"
"Immersive integration for virtual and human-centered environments","H. Fuchs","North Carolina Univ., Chapel Hill, NC, USA","2005 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC'05)","17 Oct 2005","2005","","","13","","Summary form only given. We envision future work and play environments that are more effectively human-centered with the user's computing interface being more closely integrated with the physical surroundings than today's conventional computer display screens and keyboards. We are working toward realizable versions of such environments, in which multiple video projectors and digital cameras enable every visible surface to be both measured in 3D and used for display. If the 3D surface positions are transmitted to a distant location, they may also enable distant collaborations to become more like working in adjacent offices connected by large windows. In one prototype, depth maps are calculated from streams of video images and the resulting 3D surface points are displayed to the user in head-tracked stereo. Another prototype allows direct ""painting"" onto movable objects - a dollhouse, for example. One long-term goal is advanced training for trauma surgeons by immersive replay of recorded procedures. More generally, we hope to demonstrate that the principal interface of a future computing environment need not be limited to a screen the size of one or two sheets of paper. Just as a useful physical environment is all around us, so too can the increasingly ubiquitous computing environment be all around us - becoming more effectively human-centered and integrated into our physical surroundings.","1943-6106","0-7695-2443-5","10.1109/VLHCC.2005.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1509481","","Computer displays;Computer interfaces;Prototypes;Physics computing;Keyboards;Digital cameras;Three dimensional displays;Large screen displays;Collaborative work;Streaming media","visual programming;solid modelling;virtual reality;human computer interaction;user centred design;user interfaces","immersive integration;virtual environments;human-centered environments;user interface;multiple video projectors;digital cameras;3D surface position;windows;video images;3D surface points;movable objects;ubiquitous computing","","","","","","17 Oct 2005","","","IEEE","IEEE Conferences"
"Game Prototype for Understanding Safety Issues of Life Boat Launching Process","M. Jiang; J. Chang; M. Dodwell; J. Jekins; H. J. Yang; J. J. Zhang","Nat. Centre for Comput. Animation, Bournemouth Univ., Bournemouth, UK; Nat. Centre for Comput. Animation, Bournemouth Univ., Bournemouth, UK; Nat. Centre for Comput. Animation, Bournemouth Univ., Bournemouth, UK; R. Nat. Lifeboat Instn., Poole, UK; Northwest A&F Univ., Xianyang, China; Nat. Centre for Comput. Animation, Bournemouth Univ., Bournemouth, UK","2016 8th International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES)","18 Oct 2016","2016","","","1","8","Novel advanced game techniques provide us with new possibilities to mimic a complicated training process, with the benefit of safety enhancement. In this paper, we design and implement a 3D game which imitates the lifeboat launching process. Lifeboat launching is such a complex but vital process which can on one side saving people's life on sea and on the other side associating many potential hazards. It involves both the tractor manoeuvres and boat operations. The primary objective of the game is to allow novices to better understand the sequence of the operations in launching process and manager the potential hazards happening during the launching. There is also great educational significance with the promotion of the game to the general public for enhanced awareness of safety issues. The key modules of the game are designed based on physical simulation which gives the players enhanced plausible cognition and enjoyable interaction.","","978-1-5090-2722-4","10.1109/VS-GAMES.2016.7590351","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7590351","","Games;Training;Agricultural machinery;Hazards;Boats;Solid modeling","boats;computer based training;computer games;digital simulation;hazards;marine safety","complicated training process;enhanced plausible cognition;physical simulation;boat operations;tractor manoeuvres;lifeboat launching hazards;3D game;life boat launching process safety issues","","","","29","","18 Oct 2016","","","IEEE","IEEE Conferences"
"A New Hands-On Course in Characterization of Wide-Bandgap Devices","Z. Zhang; L. M. Tolbert; D. Costinett; F. Wang; B. J. Blalock","Global Research, General Electric, Niskayuna, NY, USA; Department of Electrical Engineering and Computer Science, The University of Tennessee, Knoxville, TN, USA; Department of Electrical Engineering and Computer Science, The University of Tennessee, Knoxville, TN, USA; Department of Electrical Engineering and Computer Science, The University of Tennessee, Knoxville, TN, USA; Department of Electrical Engineering and Computer Science, The University of Tennessee, Knoxville, TN, USA","IEEE Transactions on Power Electronics","1 Jul 2019","2019","34","10","9392","9403","As wide-bandgap (WBG) devices and applications move from niche to mainstream, a new generation of engineers trained in this area is critical to continue the development of the field. This paper introduces a new hands-on course in characterization of WBG devices, which is an emerging and fundamental topic in WBG-based techniques. First, the lecture-simulation-experiment format based course structure and design considerations, such as safety, are presented. Then, the necessary facilities to support this hands-on course are summarized, including classroom preparation, software tools, and laboratory equipment. Afterward, the detailed course implementation flow is presented to illustrate the approach of close interaction among lecture, simulation, and experiment to maximize students' learning outcomes. Finally, grading for students and course evaluation by students are discussed, highlighting the findings and potential improvements. Detailed course materials are provided via potenntial.eecs.utk.edu/WBGLab for educational use.","1941-0107","","10.1109/TPEL.2018.2890615","U.S. Department of Energy's Wide Bandgap Traineeship Program; Engineering Research Center Program of the National Science Foundation and DOE; CURENT Industry Partnership Program via Engineering Research Center Shared Facilities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598833","Electrical engineering education;hands-on training;power electronics;wide-bandgap (WBG) devices","Silicon;Gallium nitride;Silicon carbide;Power electronics;Switches;Photonic band gap;HEMTs","computer simulation;courseware;educational courses;electronic engineering computing;electronic engineering education;power semiconductor devices;wide band gap semiconductors","wide-bandgap devices;WBG devices;WBG-based techniques;design considerations;course evaluation;hands-on course;course materials;lecture-simulation-experiment format based course structure;classroom preparation;software tools;laboratory equipment;course implementation flow;students learning outcomes","","4","","31","","1 Jan 2019","","","IEEE","IEEE Journals"
"Wii-based compared to standard of care balance and mobility rehabilitation for two individuals post-stroke","J. E. Deutsch; D. Robbins; J. Morrison; P. Guarrera Bowlby","Dept. of Rehab and Movt. Sciences - UMDNJ-SHRP, Newark NJ, USA; Dept. of Rehab and Movt. Sciences - UMDNJ-SHRP, Newark NJ, USA; Dept. of Rehab and Movt. Sciences - UMDNJ-SHRP, Newark NJ, USA; Dept. of Rehab and Movt. Sciences - UMDNJ-SHRP, Newark NJ, USA","2009 Virtual Rehabilitation International Conference","24 Jul 2009","2009","","","117","120","Great interest and some hype have accompanied the introduction of Nintendo Wii-based rehabilitation. The purpose of these cases is to describe a Wii-based balance and mobility program and compare it to a standard of care balance and mobility program for two individuals in the chronic phase post-stroke. Both individuals with left cerebrovascular accidents received four weeks (12 one hour sessions) of either a Nintendo Wii and Wii Fit program or standard of care balance and mobility program. Gait speed, walking endurance (six minute walk test), balance (Dynamic Gait Index) balance confidence (Activity Balance Confidence Questionnaire) and dual tasks mobility tests (Timed-Up and Go) were measured prior to training, upon training completion and at three months post-training. Both individuals demonstrated improvements in most outcomes measured. The percent increases were generally greater for the person in the Wii-based program. Retention of improvements, however, was greater for the individual who received the standard of care. Enthusiasm for new therapies needs to be tempered with evidence of efficacy with particular attention to retention of gains.","2331-9569","978-1-4244-4188-4","10.1109/ICVR.2009.5174216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5174216","Interactive Computer Gaming;Nintendo Wii;Wii-Sports;Wii-fit;balance;gait;gaming;virtual reality;stroke;Interactive computer gaming","Accidents;Testing;Medical treatment;Virtual reality;Birth disorders;Extremities;Legged locomotion;Velocity measurement;Home computing;Application software","computer games;medical computing;patient rehabilitation","Wii-based rehabilitation;mobility rehabilitation;balance rehabilitation;post- stroke patients;interactive computer gaming;virtual reality;left cerebrovascular accidents;Wii Fit program;walking endurance","","40","","14","","24 Jul 2009","","","IEEE","IEEE Conferences"
"Medical interview training using depressed patient robot in psychiatric education","T. Hashimoto; H. Nakane; R. Kurimoto; H. Kobayashi","Dept. of Mechanical Engineering and Intelligent Systems The University of Electro-Communications Tokyo, Japan; Dept. of Neuropsychiatry Nagasaki University Nagasaki, Japan; Dept. of Mechanical Engineering Tokyo University of Science Tokyo, Japan; Dept. of Mechanical Engineering Tokyo University of Science Tokyo, Japan","2014 IEEE Symposium on Robotic Intelligence in Informationally Structured Space (RiiSS)","15 Jan 2015","2014","","","1","6","This paper introduces a psychiatric patient robot that can be used for medical interview training in psychiatric education. The patient robot is developed based on an android robot technology. Medical interview training in psychiatric field is generally conducted by employing human simulated or standardized patient (SP) who is trained to reproduce a set of symptoms of intended mental disorder by veteran psychiatrists. But in the use of a healthy person as a SP there are some problems such as mental burden, time-consuming, the lack of human resources, and so forth. In contrast, the merit of the use of a patient robot is to offer standardized and reproducible interview training to psychiatric trainees. Furthermore, it is expected that psychiatric trainees are able to experience realistic medical interview as if they face to a real human SP by taking advantage of characteristics of android robots. As the first step, the patient robot was particularly designed to simulate a set of symptoms of unipolar depression, because it is a common mental disorder worldwide. The interview scenario, that is question and answer process between an interviewer and the patient robot, was prepared based on the “Structured Interview Guide for the Hamilton Depression Rating Scale (SIGH-D)” which is widely used for interview training and clinical studies. The medical interview training with patient robot was introduced in actual psychiatric education, and eight students participated and evaluated its educational effect.","","978-1-4799-4464-4","10.1109/RIISS.2014.7009172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7009172","patient patient robot;android robot;psychiatric education;unipolar depression","Interviews;Training;Medical diagnostic imaging;Androids;Humanoid robots","biomedical education;computer aided instruction;medical disorders;medical robotics;patient care;psychology","medical interview training;depressed patient robot;psychiatric education;Android robot technology;mental disorder;unipolar depression;structured interview guide for the Hamilton depression rating scale;SIGH-D","","","","11","","15 Jan 2015","","","IEEE","IEEE Conferences"
"Understanding Limb Position and External Load Effects on Real-Time Pattern Recognition Control in Amputees","Y. Teh; L. J. Hargrove","Regenstein Center for Bionic Medicine, Shirley Ryan AbilityLab, Chicago, IL, USA; Regenstein Center for Bionic Medicine, Shirley Ryan AbilityLab, Chicago, IL, USA","IEEE Transactions on Neural Systems and Rehabilitation Engineering","7 Jul 2020","2020","28","7","1605","1613","Limb position is a factor that negatively affects myoelectric pattern recognition classification accuracy. However, prior studies evaluating impact on real-time control for upper-limb amputees have done so without a physical prosthesis on the residual limb. It remains unclear how limb position affects real-time pattern recognition control in amputees when their residual limb is supporting various weights. We used a virtual reality target achievement control test to evaluate the effects of limb position and external load on real-time pattern recognition control in fourteen intact limb subjects and six major upper limb amputee subjects. We also investigated how these effects changed based on different control system training methods. In a static training method, subjects kept their unloaded arm by their side with the elbow bent whereas in the dynamic training method, subjects moved their arm throughout a workspace while supporting a load. When static training was used, limb position significantly affected real-time control in all subjects. However, amputee subjects were still able to adequately complete tasks in all conditions, even in untrained limb positions. Moreover, increasing external loads decreased controller performance, albeit to a lesser extent in amputee subjects. The effects of limb position did not change as load increased, and vice versa. In intact limb subjects, dynamic training significantly reduced the limb position effect but did not completely remove them. In contrast, in amputee subjects, dynamic training eliminated the limb position effect in three out of four outcome measures. However, it did not reduce the effects of load for either subject population. These findings suggest that results obtained from intact limb subjects may not generalize to amputee subjects and that advanced training methods can substantially improve controller robustness to different limb positions regardless of limb loading.","1558-0210","","10.1109/TNSRE.2020.2991643","National Institutes of Health NIH; Congressionally Directed Medical Research Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9090887","Prosthetics;myoelectric control;pattern recognition (PR);limb position","Training;Wrist;Real-time systems;Prosthetics;Elbow;Muscles;Electrodes","biomechanics;electromyography;medical control systems;medical signal processing;pattern recognition;prosthetics;signal classification;virtual reality","untrained limb positions;limb position effect;limb loading;real-time pattern recognition control;myoelectric pattern recognition classification accuracy;upper-limb amputees;residual limb;virtual reality target achievement control test;control system training methods","","","","43","CCBY","11 May 2020","","","IEEE","IEEE Journals"
"Habitat: A Platform for Embodied AI Research","M. Savva; A. Kadian; O. Maksymets; Y. Zhao; E. Wijmans; B. Jain; J. Straub; J. Liu; V. Koltun; J. Malik; D. Parikh; D. Batra",Simon Fraser University; Facebook AI Research; Facebook AI Research; Facebook AI Research; Georgia Tech; Facebook AI Research; Facebook Reality Labs; Facebook AI Research; Intel Labs; University of California at Berkley; Georgia Tech & Facebook AI Research; Georgia Tech & Facebook AI Research,"2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","9338","9346","We present Habitat, a platform for research in embodied artificial intelligence (AI). Habitat enables training embodied agents (virtual robots) in highly efficient photorealistic 3D simulation. Specifically, Habitat consists of: (i) Habitat-Sim: a flexible, high-performance 3D simulator with configurable agents, sensors, and generic 3D dataset handling. Habitat-Sim is fast - when rendering a scene from Matterport3D, it achieves several thousand frames per second (fps) running single-threaded, and can reach over 10,000 fps multi-process on a single GPU. (ii) Habitat-API: a modular high-level library for end-toend development of embodied AI algorithms - defining tasks (e.g. navigation, instruction following, question answering), configuring, training, and benchmarking embodied agents. These large-scale engineering contributions enable us to answer scientific questions requiring experiments that were till now impracticable or `merely' impractical. Specifically, in the context of point-goal navigation: (1) we revisit the comparison between learning and SLAM approaches from two recent works [19, 16] and find evidence for the opposite conclusion - that learning outperforms SLAM if scaled to an order of magnitude more experience than previous investigations, and (2) we conduct the first cross-dataset generalization experiments {train, test} × {Matterport3D, Gibson} for multiple sensors {blind, RGB, RGBD, D} and find that only agents with depth (D) sensors generalize across datasets. We hope that our open-source platform and these findings will advance research in embodied AI.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.00943","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010745","","Sensors;Three-dimensional displays;Artificial intelligence;Task analysis;Navigation;Training;Robots","application program interfaces;graphics processing units;learning (artificial intelligence);mobile robots;rendering (computer graphics);virtual reality","Matterport3D;multiprocess;Habitat-API;modular high-level library;embodied AI algorithms;embodied AI research;embodied artificial intelligence;training embodied agents;highly efficient photorealistic 3D simulation;Habitat-Sim;configurable agents;generic 3D dataset handling;flexible high-performance 3D simulator","","33","","28","","27 Feb 2020","","","IEEE","IEEE Conferences"
"A Serious Game for Exploring and Training in Participatory Management of National Parks for Biodiversity Conservation: Design and Experience","E. Vasconcelos; C. Lucena; G. Melo; M. Irving; J. Briot; V. Sebba; A. Sordoni","Comput. Sci. Dept., Pontificia Univ. Catolica, Rio de Janeiro, Brazil; Comput. Sci. Dept., Pontificia Univ. Catolica, Rio de Janeiro, Brazil; EICOS Program, Univ. Fed. do Rio de Janeiro, Rio de Janeiro, Brazil; EICOS Program, Univ. Fed. do Rio de Janeiro, Rio de Janeiro, Brazil; Lab. d'Inf. de Paris 6, Univ. Pierre et Marie Curie, Paris, France; Lab. d'Inf. de Paris 6, Univ. Pierre et Marie Curie, Paris, France; Lab. d'Inf. de Paris 6, Univ. Pierre et Marie Curie, Paris, France","2009 VIII Brazilian Symposium on Games and Digital Entertainment","7 Jun 2010","2009","","","93","100","In this paper, we discuss the experience in the design, use and evaluation of a serious game about participatory management of national parks for biodiversity conservation and social inclusion. Our objective is to help various stakeholders (e.g., environmentalist NGOs, communities, tourism operators, public agencies, and so on) to collectively understand conflict dynamics for natural resources management and to exercise negotiation management strategies for protected areas, one of the key issues linked to biodiversity conservation in national parks. Our serious game prototype combines, techniques such as: distributed role-playing games, support for negotiation between players, and insertion of various types of artificial agents (decision making agents, virtual players, assistant agents). After a general introduction to the project, we will present project's current prototype architecture and results from game sessions, as well as some prospects for the future, namely: the design of assistant artificial agents and of virtual players and the integration of a viability-based simulation engine.","2159-6662","978-1-4244-6011-3","10.1109/SBGAMES.2009.19","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5479103","Serious games;Simulation;Participatory management of Parks","Management training;Biodiversity;Game theory;Resource management;Protection;Research and development management;Project management;Environmental management;Virtual prototyping;Decision making","computer games;decision making;environmental factors;public administration;software agents","serious game;participatory management;national parks;biodiversity conservation;natural resources management;negotiation management strategy;distributed role-playing games;decision making agents;virtual players;assistant agents;game sessions;assistant artificial agents;viability-based simulation engine","","7","","11","","7 Jun 2010","","","IEEE","IEEE Conferences"
"Image Recognition and Safety Risk Assessment of Traffic Sign Based on Deep Convolution Neural Network","R. Chen; L. Hei; Y. Lai","School of Communications and Information Engineering, Xi’an University of Posts and Telecommunications, Xi’an, China; Institute of Xi’an Aerospace Solid Propulsion Technology, Xi’an, China; School of Communications and Information Engineering, Xi’an University of Posts and Telecommunications, Xi’an, China","IEEE Access","18 Nov 2020","2020","8","","201799","201805","A neural network model based on deep learning is utilized to explore the traffic sign recognition (TSR) and expand the application of deep intelligent learning technology in the field of virtual reality (VR) image recognition, thereby assessing the road traffic safety risks and promoting the construction of intelligent transportation networks. First, a dual-path deep CNN (TDCNN) TSR model is built based on the convolutional neural network (CNN), and the cost function and recognition accuracy are selected as indicators to analyze the training results of the model. Second, the recurrent neural network (RNN) and long-short-term memory (LSTM) RNN are utilized to assess the road traffic safety risks, and the prediction and evaluation effects of them are compared. Finally, the changes in safety risks of road traffic accidents are analyzed based on the two key influencing factors of the number of road intersections and the speed of vehicles traveling. The results show that the learning rate of the network model and the number of hidden neurons in the fully-connected layer directly affect the training results, and there are differences in the choices between the early and late training periods. Compared with RNN, the LSTM network model has higher evaluation accuracy, and its corresponding root square error (RSE) is 0.36. The rational control of the number of intersections and the speed of roads traveled has a significant impact on improving the safety level and promoting road traffic efficiency. The VR image recognition algorithm and safety risk prediction method based on a neural network model positively affect the construction of an intelligent transport network.","2169-3536","","10.1109/ACCESS.2020.3032581","Education Department of Shaanxi Province; Shaanxi Provincial Natural Science Basic Research Project; Education Department of Shaanxi Provincen; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9233325","TDCNN;image recognition;RNN;LSTM;security risk;assessment","Training;Roads;Safety;Deep learning;Image recognition;Convolution;Predictive models","convolutional neural nets;image recognition;learning (artificial intelligence);recurrent neural nets;road accidents;road safety;road traffic;traffic engineering computing;virtual reality","VR image recognition algorithm;road traffic efficiency;safety level;LSTM network model;learning rate;road intersections;road traffic accidents;RNN;recognition accuracy;cost function;convolutional neural network;dual-path deep CNN TSR model;intelligent transportation networks;road traffic safety risks;virtual reality image recognition;deep intelligent learning technology;traffic sign recognition;deep convolution neural network;safety risk assessment;intelligent transport network;neural network model;safety risk prediction method","","","","23","CCBY","20 Oct 2020","","","IEEE","IEEE Journals"
"DCA: An Approach for Face Recognition through Component Analysis","P. Shamna; C. Tripti; P. Augustine","Dept. of Comput. Sci., Rajagiri Sch. of Eng. & Technol., Kochi, India; Dept. of Comput. Sci., Rajagiri Sch. of Eng. & Technol., Kochi, India; Dept. of Comput. Sci., Rajagiri Sch. of Eng. & Technol., Kochi, India","2013 Third International Conference on Advances in Computing and Communications","19 Dec 2013","2013","","","34","38","The developments in digital technologies is enhancing the communication between computers and Human. Face recognition is a vital technique that helps to develops user-friendly methods for Human Computer Interaction (HCI). In this paper we suggest a pattern recognition method using Difference Component Analysis (DCA) and present its application in face recognition. The DCA removes all the general features of images and compute the difference components of the images. The DCA is based on the principle that two similar images will have least difference components. Simulation of DCA is done by using Yale face database and AT&T face database. The experimental results indicate that, the presented approach is remarkably effective in recognizing faces under different conditions.","","978-0-7695-5033-6","10.1109/ICACC.2013.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6686332","Face Recognition;PCA;Difference Component Analysis(DCA);Image Processing;Pattern Recognition","Face;Face recognition;Databases;Training;Image recognition;Principal component analysis","face recognition;feature extraction;human computer interaction;principal component analysis","digital technologies;face recognition;user-friendly methods;human computer interaction;HCI;pattern recognition method;difference component analysis;DCA;image general features;Yale face database;AT&T face database","","","","12","","19 Dec 2013","","","IEEE","IEEE Conferences"
"Local Forward Model Learning for GVGAI Games","A. Dockhorn; S. Lucas","Queen Mary University of London,School of Electrical Engineering and Computer Engineering,London,UK; Queen Mary University of London,School of Electrical Engineering and Computer Engineering,London,UK","2020 IEEE Conference on Games (CoG)","20 Oct 2020","2020","","","716","723","In this paper, we are going to explain the design process for our GVGAI game-learning agent, which is going to be submitted to the GVGAI competition's learning track 2020. The agent relies on a local forward modeling approach, which uses predictions of future game-states to allow the application of simulation-based search algorithms. We first explain our process in identifying repeating tiles throughout a pixel-based state observation. Using the tile information, a local forward model is trained to predict the future state of each tile based on its current state and its surrounding tiles. We accompany this approach with a simple reward model, which determines the expected reward of a predicted state transition. The proposed approach has been tested using multiple games of the GVGAI framework. Results show that the approach seems to be especially feasible for learning how to play deterministic games. Except for one non-deterministic game, the agent performance is very similar to agents using the true forward model. Nevertheless, the prediction accuracy needs to be further improved to facilitate a better game-playing performance.","2325-4289","978-1-7281-4533-4","10.1109/CoG47356.2020.9231793","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9231793","Local Forward Model;Rolling Horizon Evolutionary Algorithm;General Game Learning;GVGAI framework","Games;Training;Predictive models;Prediction algorithms;Reliability;Reinforcement learning;Diamond","computer games;learning (artificial intelligence);search problems","local forward model learning;GVGAI games;game-playing performance;agent performance;nondeterministic game;deterministic games;GVGAI framework;reward model;local forward model;tile information;pixel-based state observation;simulation-based search algorithms;local forward modeling approach;GVGAI game-learning agent","","","","24","","20 Oct 2020","","","IEEE","IEEE Conferences"
"Gamers and learning","T. Vold; S. McCallum","Hedmark University College, Norway; Gjøvik University College, Norway","2011 International Conference on Information Technology Based Higher Education and Training","15 Sep 2011","2011","","","1","4","Games and simulations have been a part of military education for a long time. With the emergence of the computer gaming industry, with its continuous improvement in technology and fidelity, there is a potential for synergy. Simulations and games developed specifically for the military are generally costly as the full development cost must be covered. These are also expensive to update to match current technology. In this project at the Norwegian Army Military Academy we have used a commercial game specifically designed to have the potential to be used by the military. The learning objective for the course was to understand squad level tactics. Our results show that even if the cadets, particularly the gamers, enjoy playing the game and believe that it supports their learning process, it does not have any significant positive or negative effect on learning. In this paper we present research that explains similar results and discusses potential reasons for a lack of clear change in the overall performance. We conclude by proposing a new study to assess the longer term effects of game based education at NAMA.","","978-1-4577-1672-0","10.1109/ITHET.2011.6018685","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6018685","Commercial games;gamers;learning;reflection processes","Games;Reflection;Training;Computational modeling;Military computing;Educational institutions","computer aided instruction;computer games;military computing","military education;computer gaming industry;development cost;war games;Norwegian Army Military Academy;squad level tactics;game based education;NAMA","","2","","13","","15 Sep 2011","","","IEEE","IEEE Conferences"
"Design and realization of virtual scene explore system for artillery reconnaissance radar","Shan Xian-ming; Yang He-yong; Xiao Jun-ling","Department of Electronic Reconnaissance, Shenyang Artillery Academy, Liaoning, China; Department of Electronic Reconnaissance, Shenyang Artillery Academy, Liaoning, China; Department of Electronic Reconnaissance, Shenyang Artillery Academy, Liaoning, China","2010 3rd International Conference on Computer Science and Information Technology","7 Sep 2010","2010","4","","284","287","Virtual Scene Technology is one of the important parts of VR systems. It takes charge of Vision issue in VR systems, and is the most important fact to affect the immersive of the system. There are many problems in training simulation of artillery reconnaissance radar, such as the battlefield environment isn't living, the load of assemble and disassemble is large, the training cost is high. The virtual scene explore system was developed. The general structure of VS Explore System is analyzed and demonstrated, and connection between different parts of VS explore system in system construction process is explained. Several key techniques such as the building of virtual topography based on Delaunay triangle through Delaunay arithmetic, the building of radar, virtual scene explore, etc, are also given in detail.","","978-1-4244-5540-9","10.1109/ICCSIT.2010.5564786","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5564786","virtual scene;navigation;virtual topograph;DEM;model","Three dimensional displays;Clocks;Computers;Solid modeling;Visualization","mesh generation;radar;terrain mapping;virtual reality","virtual scene explore system;VR systems;artillery reconnaissance radar;virtual topography;Delaunay triangle","","","","6","","7 Sep 2010","","","IEEE","IEEE Conferences"
"Postural balance analysis using force platform for K-theragame users","O. Postolache; P. S. Girão; A. López; F. J. Ferrero; J. M. Dias Pereira; G. Postolache","Instituto de Telecomunicações, ISCTE-IUL, Lisbon Portugal; Instituto de Telecomunicações, DEEC/IST, Lisbon Portugal; DEEE/Universidad de Oviedo, Spain; DEEE/Universidad de Oviedo, Spain; Instituto de Telecomunicações, EST, Lisbon, Portugal; Instituto de Telecomunicações, Instituto Medicina Molecular, Lisbon, Portugal","2016 IEEE International Symposium on Medical Measurements and Applications (MeMeA)","8 Aug 2016","2016","","","1","6","Serious games based physical therapy is currently gaining a lot of interest by the physiotherapists and game developers that are using new natural user interfaces devices to assure an easy interaction between the user under rehabilitation and his avatar immersed in a virtual reality scenario. Arm motion training, as part of stroke rehabilitation program, can be one of the main objectives of the serious games, and was the object of several serious games developed by our group, the previous works being followed by postural stability monitoring during rehabilitation developments. Thus, the balance analysis on static conditions and during the arm rehabilitation based on implemented serious games represents the objective of the work. The system presented in the paper combine Kinect Serious Game Framework and a developed force platform architecture characterized by Bluetooth communication capabilities that provide the data related to postural balance to be processed together with the upper limb training data for general evaluation of stroke rehabilitation outcome. Experimental results, including time and frequency analysis of the data obtained by the Kinect and force platform, are included in the paper.","","978-1-4673-9172-6","10.1109/MeMeA.2016.7533705","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7533705","physical rehabilitation;serious games;force platform;electronic health record","Games;Force;Training;Sensors;Active filters;Digital filters;Trajectory","avatars;biomedical equipment;Bluetooth;graphical user interfaces;medical computing;medical disorders;patient monitoring;patient rehabilitation;serious games (computing)","avatar;Kinect platform;force platform;time frequency analysis;stroke rehabilitation outcome;upper limb training data;postural balance;Bluetooth communication capabilities;developed force platform architecture;Kinect Serious Game Framework;arm rehabilitation;balance analysis;postural stability monitoring;stroke rehabilitation program;arm motion training;virtual reality scenario;natural user interface devices;game developers;serious game based physical therapy;K-Theragame users;force platform;postural balance analysis","","7","","11","","8 Aug 2016","","","IEEE","IEEE Conferences"
"EEG-based motion sickness classification system with genetic feature selection","L. Ko; H. Lee; S. Tsai; T. Shih; Y. Chuang; H. Huang; S. Ho; C. Lin","Department of Biological Science and Technology, National Chiao Tung University (NCTU), Taiwan; Department of Biological Science and Technology, National Chiao Tung University (NCTU), Taiwan; Department of Computer Science, NCTU, Taiwan; Department of Biological Science and Technology, National Chiao Tung University (NCTU), Taiwan; Department of Biological Science and Technology, National Chiao Tung University (NCTU), Taiwan; Department of Biological Science and Technology, National Chiao Tung University (NCTU), Taiwan; Department of Biological Science and Technology, National Chiao Tung University (NCTU), Taiwan; Department of Biological Science and Technology, National Chiao Tung University (NCTU), Taiwan","2013 IEEE Symposium on Computational Intelligence, Cognitive Algorithms, Mind, and Brain (CCMB)","26 Sep 2013","2013","","","158","164","People tend to get motion sickness on a moving boat, train, airplane, car, or amusement park rides. Many previous studies indicated that motion sickness sometimes led to traffic accidents, so it becomes an important issue in our daily life. In this study, we designed a VR-based motion-sickness platform with a 32-channel EEG system and a joystick which is used to report the motion sickness level (MSL) in real time during experiments. The results show it is feasible to estimate subject's MSL based on re-sampling frequency band proved by the high test accuracy. A comparison between general prediction models (such as LDA, QDA, KNN) and IBCGA shows that the IBCGA can be effectively increase the accuracy. In this paper, an extended-IBCGA (e-IBCGA) is proposed and it provides more accuracy than the prior-art research. The test results show that e-IBCGA increases at least 10% to 20% test accuracy in 6 subjects.","","978-1-4673-5871-2","10.1109/CCMB.2013.6609180","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6609180","","Electroencephalography;Accuracy;Support vector machines;Brain;Visualization;Estimation;Roads","electroencephalography;medical signal processing;virtual reality","motion sickness classification system;genetic feature selection;VR-based motion sickness platform;EEG system;e-IBCGA","","5","","18","","26 Sep 2013","","","IEEE","IEEE Conferences"
"Virtual environments in neuroscience","G. Riva","Lab. of Appl. Technol. for Neuro-Psychol., IRCCS, Verbania, Italy","IEEE Transactions on Information Technology in Biomedicine","6 Aug 2002","1998","2","4","275","281","Virtual environments (VEs) let users navigate and interact with computer generated three dimensional (3D) environments in real time, allowing for the control of complex stimuli presentation. These VEs have attracted much attention in medicine, especially in remote or augmented surgery, and surgical training, which are critically dependent on hand-eye coordination. Recently, however, some research projects have begun to test the possibility of using VEs for the study and rehabilitation of human cognitive and functional activities. The paper highlights recent and ongoing research related to the applications of VEs in the neuroscience arena. In particular, it focuses on the American and European initiatives in this field, including a description of the European Commission (EC) funded VREPAR projects. Finally, the paper provides a general introduction to virtual reality (VR), as it relates to its impact on cognitive and functional abilities.","1558-0032","","10.1109/4233.737583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=737583","","Neuroscience;Virtual reality;Biomedical imaging;Surgery;Medical services;Computer displays;Testing;Humans;Telemedicine;Computer graphics","virtual reality;real-time systems;biomedical education;computer aided instruction;medical computing;neurophysiology","virtual environments;neuroscience;computer generated three dimensional environments;complex stimuli presentation;VEs;augmented surgery;surgical training;hand-eye coordination;human cognitive activities;European initiatives;European Commission funded VREPAR projects;virtual reality;functional abilities","Computer Systems;Neurosciences","28","","47","","6 Aug 2002","","","IEEE","IEEE Journals"
"Personalized Image Aesthetic Quality Assessment by Joint Regression and Ranking","K. Park; S. Hong; M. Baek; B. Han","Dept. of Comput. Sci. & Eng., POSTECH, Pohang, South Korea; Dept. of Comput. Sci. & Eng., POSTECH, Pohang, South Korea; Dept. of Comput. Sci. & Eng., POSTECH, Pohang, South Korea; Dept. of Comput. Sci. & Eng., POSTECH, Pohang, South Korea","2017 IEEE Winter Conference on Applications of Computer Vision (WACV)","15 May 2017","2017","","","1206","1214","We propose an image aesthetic quality assessment algorithm, which considers personal taste in addition to generally perceived preference. This problem is formulated by a combination of two different learning frameworks based on support vector machines-Support Vector Regression (SVR) and Ranking SVM (R-SVM), where SVR learns a general model based on public datasets and R-SVM adjusts the model to accommodate personal preference obtained from user interactions. The combined framework, called R-SVR, is represented by a single objective function, which is optimized jointly to learn a model for personalized image aesthetic quality assessment. For the optimization, we use only a small subset of public dataset identified by k-nearest neighbor search instead of using all available training data. This strategy is useful in practice because it reduces training time significantly and alleviates data imbalance problem between regression and ranking. The proposed algorithm is tested through simulation and user study, and we present that our interactive learning algorithm by R-SVR is effective to increase user's satisfaction and improve prediction performance.","","978-1-5090-4822-9","10.1109/WACV.2017.139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7926722","","Training;Testing;Quality assessment;Support vector machines;Image quality;Training data;Databases","human factors;image processing;learning (artificial intelligence);optimisation;regression analysis;search problems;support vector machines;visual databases","personalized image aesthetic quality assessment;joint regression-and-ranking;support vector machines;support vector regression;ranking SVM;SVR;public datasets;R-SVM;personal preference;user interactions;objective function;k-nearest neighbor search;train-ing time reduction;data imbalance problem;interactive learning algorithm;user satisfaction;prediction performance improvement","","6","","30","","15 May 2017","","","IEEE","IEEE Conferences"
"Imagineering: Fostering constructivism among pre-service teachers","D. M. Balajadia","College of Education University of the Assumption City of San Fernando, Pampanga, Philippines","2017 3rd International Conference on Science in Information Technology (ICSITech)","15 Jan 2018","2017","","","447","452","Constructivism has been evolving as to how educators all over the world have been perceiving it to be a responsive frame of mind in the 21st century schools. “Imagineering”, conceived as a blend of imagination and engineering, now becomes a significant concept rooted from how teachers innovate the curriculum toward making their learners create new knowledge. This descriptive-survey study generally assessed how constructivist are the 270 pre-service teachers who are the future of the modern schools. The results revealed that the would-be teachers are much more imaginative and creative in designing teaching strategies, techniques, and assessment tools than in acquiring concepts for learning. Data further imply that while they are too aggressive in creating outputs, pre-service teachers tend to overlook the significance of knowledge acquisition prior to exploration and creation. It is important to note that pre-service teacher training be founded on capacity building and stimulation of imagination before making decisions on creative teaching. Recreating this study is highly recommended to further understand the procedure in preparing prospective teachers in the new millennium.","","978-1-5090-5866-2","10.1109/ICSITech.2017.8257154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8257154","constructivism;imagineering;innovative teaching;21st century education;educational technology","Tools;Information technology;Training;Visualization;Cognition","decision making;educational institutions;knowledge management;teacher training;teaching","prospective teachers;Imagineering;pre-service teacher training;capacity building;constructivism;teaching strategies;assessment tools;knowledge acquisition;knowledge exploration;knowledge creation;imagination simulation;decision making;creative teaching","","","","20","","15 Jan 2018","","","IEEE","IEEE Conferences"
"Toward Increasing Awareness of Suspicious Content through Game Play","M. Hale; R. Gamble","Tandy Sch. of Comput. Sci., Univ. of Tulsa, Tulsa, OK, USA; Tandy Sch. of Comput. Sci., Univ. of Tulsa, Tulsa, OK, USA","2014 IEEE World Congress on Services","22 Sep 2014","2014","","","113","120","Phishing, elicitation, and impersonation techniques are performed using multiple forms, targeting content specific to the delivery modality, such as email, social media, and general browser communications. Education to increase awareness is one mechanism to combat phishing. Average email and internet users are less attentive to media warnings and training materials provided by employers than they are in interactive environments. In this paper, we overview a game concept that immerses users in a role play challenge where they must send email, use social media, and browse the web and determine whether content received within these modalities is trustworthy or not. The game, built as a Javascript framework, simulates phishing scams, measures trust and suspicion levels, and individualizes training for users. The game architecture employs components that facilitate dynamic content generation in each of the modalities, customize experiment design for specific assessment and training, and perform sophisticated tracking for automated analysis of user trust content assessments. We discuss the game content, the specific requirements the game must comply with, and the experiments to be conducted using the game.","2378-3818","978-1-4799-5069-0","10.1109/SERVICES.2014.30","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6903253","security;phishing;game;assessment;awareness","Games;Electronic mail;Training;Media;Companies;Browsers;Degradation","computer based training;message authentication;serious games (computing);social networking (online);unsolicited e-mail","suspicious content;game play;elicitation technique;impersonation technique;email;Internet;role play challenge;social media;Javascript framework;phishing scams;dynamic content generation;user trust content assessment","","4","","14","","22 Sep 2014","","","IEEE","IEEE Conferences"
"Generating multi-fingered robotic grasps via deep learning","J. Varley; J. Weisz; J. Weiss; P. Allen",NA; NA; NA; NA,"2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","17 Dec 2015","2015","","","4415","4420","This paper presents a deep learning architecture for detecting the palm and fingertip positions of stable grasps directly from partial object views. The architecture is trained using RGBD image patches of fingertip and palm positions from grasps computed on complete object models using a grasping simulator. At runtime, the architecture is able to estimate grasp quality metrics without the need to explicitly calculate the given metric. This ability is useful as the exact calculation of these quality functions is impossible from an incomplete view of a novel object without any tactile feedback. This architecture for grasp quality prediction provides a framework for generalizing grasp experience from known to novel objects.","","978-1-4799-9994-1","10.1109/IROS.2015.7354004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7354004","","Training;Machine learning;Heating;Grasping;Image segmentation;Training data;Computer architecture","grippers;haptic interfaces;image colour analysis","multifingered robotic grasps;deep learning architecture;fingertip positions;RGBD image patches;palm positions;object models;grasping simulator;grasp quality metrics;quality functions;tactile feedback;grasp quality prediction","","40","","19","","17 Dec 2015","","","IEEE","IEEE Conferences"
"Collaborative learning system based on wireless mobile equipments","Zhaopeng Meng; Jianjun Chu; Lianfang Zhang","Dept. of Comput. Sci., Tianjin Univ., China; Dept. of Comput. Sci., Tianjin Univ., China; Dept. of Comput. Sci., Tianjin Univ., China","Canadian Conference on Electrical and Computer Engineering 2004 (IEEE Cat. No.04CH37513)","1 Nov 2004","2004","1","","481","484 Vol.1","With the popularization of wireless mobile equipment, long distance education based on such equipment, e.g., PDAs, attracts increasing attention. However, two problems are: how to transform current Web pages to display correctly on PDA; how to deal with long distance discussions between PDA users and PC users. We have developed a mobile learning system, composed of a collaborative learning model and a network agent service model. The system can be deployed over a heterogeneous network of mobile wireless devices and wired devices, ranging from PDAs to desktop PCs. The collaborative learning system, based on traditional C/S (client-server) architecture, includes some basic discussion tools. The client side is implemented in the form of an applet, which can communicate with the server side located on the Web server. Teachers and students can communicate through the Web page browsers of PDAs or PCs. The network agent service model, which acts as an HTTP agency, can transform the text and images in HTML pages into an appropriate size and format that can be displayed by the PDA browser, according to the size of its screen. The architecture and framework of the mobile learning system, which includes some key technologies, such as the realization of image conversion, is introduced. We demonstrate the use and effect of the system in the context of long distance education.","0840-7789","0-7803-8253-6","10.1109/CCECE.2004.1345062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1345062","","Collaborative work;Personal digital assistants;Distance learning;Web pages;Learning systems;Personal communication networks;Web server;Displays;Network servers;HTML","distance learning;mobile computing;mobile radio;online front-ends;computer based training;client-server systems;Internet;distributed programming","collaborative learning system;wireless mobile equipment;long distance education;Web pages;mobile learning system;network agent service model;heterogeneous network;discussion tools;client-server architecture;applet;Web server;HTTP agency;HTML pages;image conversion","","","","7","","1 Nov 2004","","","IEEE","IEEE Conferences"
"Synchronous and Asynchronous Learning Methods under the light of General Data Protection Regulation","E. Mougiakou; S. Papadimitriou; M. Virvou","University of Piraeus,Department of Informatics,Piraeus,Greece,18534; University of Piraeus,Department of Informatics,Piraeus,Greece,18534; University of Piraeus,Department of Informatics,Piraeus,Greece,18534","2020 11th International Conference on Information, Intelligence, Systems and Applications (IISA","11 Dec 2020","2020","","","1","7","The continuous evolution of technology affects various areas of people's daily lives. One of them is the field of education, where the use of technological means allows alternative ways of teaching. The spread of the SARS-CoV-2 coronavirus, which has led to the closure of educational institutions in many countries, has increased the significance of educational platforms. Some platforms allow synchronous communication between the tutor and the student, i.e., the tutoring process takes place at a predetermined time, simulating conventional training. Asynchronous educational platforms enable the student to study and solve exercises in the time and at the pace of their own choice. However, there are questions about users' data, especially considering the General Data Protection Regulation 1 (GDPR) in force since 25 May 2018. In this article, we describe the features that distinguish synchronous from asynchronous learning systems and identify their points of impact with specific GDPR elements, respectively. Particularly for the asynchronous method, we focus on platforms that process user data and appropriately adapt the educational material. Having identified the impact points, we address the issue by providing guidelines for similar system designers. We also compare the two methods in terms of their benefits, taking into account the design needed for GDPR compliance.","","978-0-7381-2346-2","10.1109/IISA50023.2020.9284341","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284341","GDPR;Personal Data Protection;Personal Data Processing;Transparency;Consent;Privacy;Right to be Informed;Right of Access;Right to be Forgotten;Right to Object;Artificial Intelligence;Intelligent Tutoring Systems;ITS;Educational Systems;Children;Students;Education;Minors;Synchronous Learning Systems;Asynchronous Learning Systems;Online Teaching Platforms","COVID-19;Learning systems;Training;Data processing;General Data Protection Regulation;Statistics;Guidelines","computer aided instruction;educational institutions;law;teaching","SARS-CoV-2 coronavirus;technological means;asynchronous learning methods;synchronous learning methods;educational material;asynchronous learning systems;General Data Protection Regulation;asynchronous educational platforms;tutoring process;synchronous communication;educational institutions","","","","25","","11 Dec 2020","","","IEEE","IEEE Conferences"
"Gesture3DFramework: A Generic Gesture-Based Interaction Middleware Applied to 3D Environments","D. Passos Costa; P. N. M. Sampaio; V. F. Martins","Computing and Systems Graduate Program Salvador University (UNIFACS) Salvador, Bahia, Brazil; Computing and Systems Graduate Program Salvador University (UNIFACS) Salvador, Bahia, Brazil; School of Computing and Informatics Marckenzie Presbiterian University São Paulo, São Paulo, Brazil","2018 XLIV Latin American Computer Conference (CLEI)","5 Aug 2019","2018","","","590","598","The technological advances provide the development and wide adoption of different kinds of humanmachine interfaces, which leads to the creation of new applications such as those based on multimedia and virtual reality (3D). In particular, the proposal of interaction metaphors applied to 3D environments which aim at replicating real world concepts into the virtual environment, facilitates user's interaction. The utilization of gestural interaction metaphors within a 3D environment can turn the user experience more familiar and concrete, making the training curb smaller. However, in order to apply interaction metaphors it is necessary their classification and generalization, so that they can be widely deployed in different applications. This paper introduces the development of a generic and customizable solution for the mediation of user gestural interaction (selection, manipulation and navigation) with heterogeneous rendering engines for virtual reality environments. This solution, called Gesture3DFramework, allows the users context and gesture-metaphors configuration to be easily customized so that it can be adaptable to multiple 3D virtual environments. With Gesture3DFramework, the final user (and developer) will be provided with a higher level of abstraction when it comes to the development of interactive virtual reality applications, since once the configuration directives have been described, the system will adapt itself to the specific interaction routines of the applied rendering engine.","","978-1-7281-0437-9","10.1109/CLEI.2018.00076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8786315","Virtual Reality;Gesture Interaction;Selection;Manipulation;Navigation;Immersion;3D environment","Three-dimensional displays;Casting;Navigation;Middleware;Virtual environments;Rendering (computer graphics)","gesture recognition;graphical user interfaces;human computer interaction;middleware;rendering (computer graphics);virtual reality","generic gesture-based interaction middleware;user experience;user gestural interaction;multiple 3D virtual environments;interactive virtual reality applications;Gesture3DFramework;rendering engine;interaction routines","","","","","","5 Aug 2019","","","IEEE","IEEE Conferences"
"Model Decomposition for Forward Model Approximation","A. Dockhorn; T. Tippelt; R. Kruse","Intelligent Cooperative Systems, Otto von Guericke University, Magdeburg, Germany; Intelligent Cooperative Systems, Otto von Guericke University, Magdeburg, Germany; Intelligent Cooperative Systems, Otto von Guericke University, Magdeburg, Germany","2018 IEEE Symposium Series on Computational Intelligence (SSCI)","31 Jan 2019","2018","","","1751","1757","In this paper we propose a model decomposition architecture, which advances on our previous attempts of learning an approximated forward model for unknown games [1]. The developed model architecture is based on design constraints of the General Video Game Artificial Intelligence Competition and the Video Game Definition Language. Our agent first builds up a database of interactions with the game environment for each distinct component of a game. We further train a decision tree model for each of those independent components. For predicting a future state we query each model individually and aggregate the result. The developed model ensemble does not just predict known states with a high accuracy, but also adapts very well to previously unseen levels or situations. Future work will show how well the increased accuracy helps in playing an unknown game using simulation-based search algorithms such as Monte Carlo Tree Search.","","978-1-5386-9276-9","10.1109/SSCI.2018.8628624","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8628624","Forward Model Approximation;Decision Trees;Ensemble Learning;General Video Games","Games;Predictive models;Reinforcement learning;Adaptation models;Context modeling;Monte Carlo methods;Training","approximation theory;computer games;decision trees;learning (artificial intelligence)","forward model approximation;model decomposition architecture;General Video Game Artificial Intelligence Competition;Video Game Definition Language;decision tree model;simulation-based search algorithms","","2","","20","","31 Jan 2019","","","IEEE","IEEE Conferences"
