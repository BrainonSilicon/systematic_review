"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Training Transfer of Bimanual Assembly Tasks in Cost-Differentiated Virtual Reality Systems","S. Shen; H. -T. Chen; T. W. Leong","School of Software, University of Technology, Sydney; School of Software, University of Technology, Sydney; School of Software, University of Technology, Sydney","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1152","1153","Recent advances of the affordable virtual reality headsets make virtual reality training an economical choice when compared to traditional training. However, these virtual reality devices present a range of different levels of virtual reality fidelity and interactions. Few works have evaluated their validity against the traditional training formats. This paper presents a study that compares the learning efficiency of a bimanual gearbox assembly task among traditional training, virtual reality training with direct 3D inputs (HTC VIVE), and virtual reality training without 3D inputs (Google Cardboard). A pilot study was conducted and the result shows that HTC VIVE brings the best learning outcomes.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797917","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797917","Assistive systems;Head-mounted Display;Virtual Reality;Learning Transfer","Training;Task analysis;Virtual reality;Three-dimensional displays;Headphones;Google;Software","assembling;gears;helmet mounted displays;industrial training;production engineering computing;virtual reality","virtual reality training;bimanual gearbox assembly task;cost-differentiated virtual reality systems;virtual reality headsets;traditional training;head-mounted display","","","","3","","15 Aug 2019","","","IEEE","IEEE Conferences"
"Experience with head-mounted virtual reality (HMD-VR) predicts transfer of HMD-VR motor skills","J. M. Juliano; D. Saldana; A. Schmiesing; S. Liew","University of Southern California (USC),Neuroscience Graduate Program,Los Angeles,CA,USA; University of Southern California,Chan Division of Occupational,Los Angeles,CA,USA; University of Southern California,Chan Division of Occupational,Los Angeles,CA,USA; University of Southern California,Chan Division of Occupational,Los Angeles,CA,USA","2019 International Conference on Virtual Rehabilitation (ICVR)","13 Feb 2020","2019","","","1","2","Immersive, head-mounted virtual reality (HMD-VR) has the potential to be a useful tool for motor rehabilitation. However, when developing tools for rehabilitation, it is essential to design interventions that will be most effective for generalizing to the real world. Therefore, it is important to understand what factors facilitate transfer from HMD-VR to non-HMD-VR environments. Here we used a well-established test of skilled motor learning, the Sequential Visual Isometric Pinch Task (SVIPT), to train healthy individuals in an HMD-VR environment. We examined whether learned motor skills transferred to a more conventional (non-HMD-VR) environment and what factors facilitated transfer. Our results suggest that on average, learned motor skills from this task transfer from an immersive virtual environment to a conventional environment; however, some individuals did not transfer the learned motor skills. We then examined individual differences between those that did show transfer and those that did not. We found that individuals who had previous exposure to HMD-VR were more likely to transfer their learned motor skills than those who did not. Individual differences in previous exposure to HMD-VR environments prior to training may serve as a predictor to whether learned motor skills will transfer out of HMD-VR.","2331-9569","978-1-7281-1285-5","10.1109/ICVR46560.2019.8994345","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994345","head-mounted virtual reality;skilled motor learning;transfer","","biomechanics;helmet mounted displays;learning (artificial intelligence);patient rehabilitation;virtual reality","HMD-VR environment;learned motor skills;head-mounted virtual reality;HMD-VR motor skills;motor rehabilitation;nonHMD-VR environments;skilled motor learning;immersive virtual environment","","","","9","","13 Feb 2020","","","IEEE","IEEE Conferences"
"The effects of olfaction on training transfer for an assembly task","A. G. Moore; N. S. Herrera; T. C. Hurst; R. P. McMahan; S. Poeschl",The FIVE Lab at the University of Texas at Dallas; The FIVE Lab at the University of Texas at Dallas; The FIVE Lab at the University of Texas at Dallas; The FIVE Lab at the University of Texas at Dallas; Ilmenau University of Technology,"2015 IEEE Virtual Reality (VR)","27 Aug 2015","2015","","","237","238","Context-dependent memory studies have indicated that olfaction, the sense of smell, has a special odor memory that can significantly improve recall in some cases. Virtual reality (VR), which has been investigated as a training tool, could feasibly benefit from odor memory by incorporating olfactory stimuli. There have been a few studies on this concept for semantic learning, but not for procedural training. To address this gap in knowledge, we investigated the effects of olfaction on the transfer of knowledge from training to next-day execution for building a complex LEGO jet-plane model. Our results indicate that the pleasantness of an odor significantly affects training transfer more than whether the encoding and recall contexts match.","2375-5334","978-1-4799-1727-3","10.1109/VR.2015.7223383","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223383","Olfactory fidelity;training transfer","Training;Olfactory;Encoding;Virtual environments;Semantics;Testing","chemioception;computer based training;virtual reality","assembly task;context-dependent memory;smell-sense;odor memory;recall improvement;virtual reality;VR;training tool;olfactory stimuli;semantic learning;knowledge transfer;complex LEGO jet-plane model;odor pleasantness;training transfer","","2","","13","","27 Aug 2015","","","IEEE","IEEE Conferences"
"Transfer of a skilled motor learning task between virtual and conventional environments","J. Anglin; D. Saldana; A. Schmiesing; S. Liew","University of Southern California, Los Angeles, California, United States of America; University of Southern California, Los Angeles, California, United States of America; University of Southern California, Los Angeles, California, United States of America; University of Southern California, Los Angeles, California, United States of America","2017 IEEE Virtual Reality (VR)","6 Apr 2017","2017","","","401","402","Immersive, head-mounted virtual reality (HMD-VR) can be a potentially useful tool for motor rehabilitation. However, it is unclear whether the motor skills learned in HMD-VR transfer to the non-virtual world and vice-versa. Here we used a well-established test of skilled motor learning, the Sequential Visual Isometric Pinch Task (SVIPT), to train individuals in either an HMD-VR or conventional training (CT) environment. Participants were then tested in both environments. Our results show that participants who train in the CT environment have an improvement in motor performance when they transfer to the HMD-VR environment. In contrast, participants who train in the HMD-VR environment show a decrease in skill level when transferring to the CT environment. This has implications for how training in HMD-VR and CT may affect performance in different environments.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892346","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892346","Virtual reality;skilled motor learning;transfer","Training;Logic gates;Virtual reality;Computed tomography;Electroencephalography;Visualization;Indexes","medical computing;patient rehabilitation;virtual reality","skilled motor learning task;virtual environments;head-mounted virtual reality;HMD-VR;motor rehabilitation;sequential visual isometric pinch task;SVIPT;conventional training environment;CT environment","","8","","4","","6 Apr 2017","","","IEEE","IEEE Conferences"
"A collaborative virtual environment for industrial training","J. C. de Oliveira; S. Shirmohammadi; N. D. Georganas","Sch. of Inf. Tech. & Eng., Ottawa Univ., Ont., Canada; NA; NA","Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048)","6 Aug 2002","2000","","","288","","The concept of collaborative virtual environments has been deployed in many systems in the past few years. Applications of such technology have been used anywhere from military combat simulations to various civilian commercial applications. We present a specific system developed for industrial teletraining. The system, which aims to reduce the cost of training, consists of an interactive 3D environment with collaboration and management capabilities that allows a trainer to lead and control a session attended by many trainees.","1087-8270","0-7695-0478-7","10.1109/VR.2000.840516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=840516","","Collaboration;Virtual environment;Industrial training;Prototypes;Switches;Speech recognition;Asynchronous transfer mode;Avatars;Communication switching;User interfaces","virtual reality;computer based training;distance learning;groupware;multimedia computing","collaborative virtual environment;industrial training;industrial teletraining;interactive 3D environment;collaboration;management;ATM switching equipment","","7","","","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Does virtual-reality training on orthopaedic simulators improve performance in the operating room?","N. Vaughan; V. N. Dubey; T. W. Wainwright; R. G. Middleton","Faculty of Science and Technology, Bournemouth University (BU) Bournemouth, UK; Faculty of Science and Technology, Bournemouth University (BU) Bournemouth, UK; Department of Orthopaedics, Royal Bournemouth Hospital NHS Foundation Trust, Bournemouth, UK; Department of Orthopaedics, Royal Bournemouth Hospital NHS Foundation Trust, Bournemouth, UK","2015 Science and Information Conference (SAI)","3 Sep 2015","2015","","","51","54","This paper summarises recent validation studies and evidence demonstrating whether training on virtual reality (VR) simulators directly relates to improved performance in-vivo for orthopaedic surgical procedures. This research provides a summary of transfer validity on virtual reality orthopaedic simulators. This covers studies which have shown validation of simulators and have shown the transfer of simulator-acquired skill to the operating room. The findings of this study are that there are 6 studies showing transfer of skill for VR to in-vivo However more studies assessing efficacy and transfer validity are required to conclusively quantify the transfer validity of VR orthopaedic simulators. However there is a popular positive opinion for the ability of VR training to convert into better in-vivo performance.","","978-1-4799-8547-0","10.1109/SAI.2015.7237125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7237125","Orthopeadic;Simulator;Transfer validity;Efficacy;Testing;Surgery;Performance","Training;Surgery;Virtual reality;Hip;Solid modeling;Injuries","computer based training;medical computing;orthopaedics;surgery;virtual reality","virtual-reality training;operating room performance;orthopaedic surgical procedures;virtual reality orthopaedic simulators;simulator-acquired skill transfer;VR orthopaedic simulators","","3","","18","","3 Sep 2015","","","IEEE","IEEE Conferences"
"Comparison of a Gamified and Non-Gamified Virtual Reality Training Assembly Task","F. Palmas; D. Labode; D. A. Plecher; G. Klinker","Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Research Group Augmented Reality, Technical University of Munich, Munich, Germany","2019 11th International Conference on Virtual Worlds and Games for Serious Applications (VS-Games)","14 Oct 2019","2019","","","1","8","By using simulations in virtual reality (VR), people have the chance to train without supervision in a safe and controlled environment. VR simulation training allows users to gain new skills and apply them to real-life situations. However, the learning curve of this technology from a novice level could influence the expected learning results of a training session. A training approach based on the combination of VR and gamification could speed up this overall learning process and not just for a novice. In this paper we evaluate how gamification in a VR training session can improve the efficiency of the training and the accuracy of the task execution in a real-world practical test. In the training scenario of this study, 50 randomly assigned participants were divided into two groups. The groups were assigned to a gamified and a non-gamified version of the same VR training and were then guided through a step-by-step tutorial outlining how to solve an assembly task. Performance differences were evaluated based on time taken and specific errors made during the training session. The results of this study show, in general, that beneficial effects can be attributed to the use of gamification in the conducted VR training simulation, particularly for the VR novice participants.","2474-0489","978-1-7281-4540-2","10.1109/VS-Games.2019.8864583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8864583","virtual training;virtual reality;gamification;training;learning transfer;assembly task","Training;Task analysis;Games;Tutorials;Solid modeling;Augmented reality","computer based training;computer simulation;serious games (computing);virtual reality","VR simulation training;learning curve;novice level;gamification;learning process;VR training session;task execution;virtual reality training assembly task","","3","","44","","14 Oct 2019","","","IEEE","IEEE Conferences"
"Virtual Reality-Based Casting Skill Transfer and Human Resource Development","K. Watanuki","Saitama Univ., Saitama","17th International Conference on Artificial Reality and Telexistence (ICAT 2007)","2 Jan 2008","2007","","","316","317","This paper proposes a new virtual reality-based skill transfer and human resource development system for casting design, which is composed of the explicit and tacit knowledge transfer systems using synchronized multimedia and the knowledge internalization system using portable virtual environment. In our proposed system, the education content is displayed in the immersive virtual environment, whereby a trainee may experience work in the virtual site operation. Provided that the trainee has gained explicit and tacit knowledge of casting through the multimedia-based knowledge transfer system, the immersive virtual environment catalyzes the internalization of knowledge and also enables the trainee to gain tacit knowledge before undergoing on- the-job training at a real-time operation site.","","0-7695-3056-7","10.1109/ICAT.2007.60","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4414664","","Casting;Humans;Virtual environment;Industrial training;Manufacturing industries;Knowledge transfer;On the job training;Force feedback;Multimedia systems;Libraries","casting;computer based training;design;engineering education;human resource management;industrial training;knowledge management;multimedia systems;multiskilling;on-the-job training;production engineering computing;virtual reality","virtual reality-based casting skill transfer;human resource development system;casting design;multimedia-based knowledge transfer system;education content;immersive virtual environment;training;virtual site operation;on-the-job training","","","","1","","2 Jan 2008","","","IEEE","IEEE Conferences"
"Cognitive psychology and human factors engineering of virtual reality","A. K. T. Ng","The University of Hong Kong, Hong Kong, China","2017 IEEE Virtual Reality (VR)","6 Apr 2017","2017","","","407","408","This position paper summarizes the author's research interest in Cognitive Psychology and Human-Computer Interaction in the imseCAVE, a CAVE-like system in the University of Hong Kong. Several areas of interest were explored while finding the thesis topic for the Ph.D. research. They include a perception research on distance estimation with proposed error correction mechanism, neurofeedback meditation with EEG in VR and the effect with audio and video, the study of training transfer in VR training, the comparison and research of cybersickness between HMD and the imseCAVE, and comparing VR gaming in TV, HMD, and the imseCAVE by performance, activity level and time perception. With a broad interest, the exact direction is still in the search and requires future exploration.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892349","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892349","Virtual environment;cognitive psychology;HCI","Training;Psychology;Resists;Virtual reality;Human factors;Ergonomics;Human computer interaction","cognition;human factors;virtual reality","cognitive psychology;human factors engineering;virtual reality;CAVE-like system;error correction mechanism;neurofeedback meditation;EEG;VR;imseCAVE;distance estimation","","","","13","","6 Apr 2017","","","IEEE","IEEE Conferences"
"Transferability of Spatial Maps: Augmented Versus Virtual Reality Training","N. R. Caluya; A. Plopski; J. F. Ty; C. Sandor; T. Taketomi; H. Kato","Nara Institute of Science and Technology, Interactive Media Design Laboratory; Nara Institute of Science and Technology, Interactive Media Design Laboratory; Nara Institute of Science and Technology, Interactive Media Design Laboratory; Nara Institute of Science and Technology, Interactive Media Design Laboratory; Nara Institute of Science and Technology, Interactive Media Design Laboratory; Nara Institute of Science and Technology, Interactive Media Design Laboratory","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","387","393","Work space simulations help trainees acquire skills necessary to perform their tasks efficiently without disrupting the workflow, forgetting important steps during a procedure, or the location of important information. This training can be conducted in Augmented and Virtual Reality (AR, VR) to enhance its effectiveness and speed. When the skills are transferred to the actual application, it is referred to as positive training transfer. However, thus far, it is unclear which training, AR or VR, achieves better results in terms of positive training transfer. We compare the effectiveness of AR and VR for spatial memory training in a control-room scenario, where users have to memorize the location of buttons and information displays in their surroundings. We conducted a within-subject study with 16 participants and evaluated the impact the training had on short-term and long-term memory. Results of our study show that VR outperformed AR when tested in the same medium after the training. In a memory transfer test conducted two days later AR outperformed VR. Our findings have implications on the design of future training scenarios and applications.","","978-1-5386-3365-6","10.1109/VR.2018.8447561","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8447561","H.5.1-Information Interfaces and Presentation: Multimedia Information Systems-Artificial;augmented;and virtual realities;H.5.2-Information Interfaces and Presentation: Multimedia Information Systems-Ergonomics;Evaluation/methodology;Theory and methods","Training;Task analysis;Virtual reality;Resists;Layout;Legged locomotion;Media","augmented reality;computer based training","work space simulations;VR;spatial memory training;information displays;long-term memory;memory transfer test;spatial maps;virtual reality training;augmented reality training;training transfer;AR","","","","24","","30 Aug 2018","","","IEEE","IEEE Conferences"
"Distributed virtual environment for intravascular tele-surgery using multimedia telecommunication","F. Arai; M. Tanimoto; T. Fukuda; K. Shimojima; H. Matsuura; M. Negoro","Dept. of Micro Syst. Eng., Nagoya Univ., Japan; Dept. of Micro Syst. Eng., Nagoya Univ., Japan; Dept. of Micro Syst. Eng., Nagoya Univ., Japan; Dept. of Micro Syst. Eng., Nagoya Univ., Japan; Dept. of Micro Syst. Eng., Nagoya Univ., Japan; NA","Proceedings of the IEEE 1996 Virtual Reality Annual International Symposium","6 Aug 2002","1996","","","79","85","The number of specialized medical doctors is decreasing. It is important to assist doctors in their operation of surgical tools. To solve this problem, we propose a distributed VR system using multimedia telecommunication for training, diagnosis, and assistance in surgery. To realize this system, it is important to exchange high quality moving pictures. We use high speed optical fiber network with ATM (Asynchronous Transfer Mode). ATM has excellent features such as bandwidth allocation which is suitable for multimedia communication on computer networks. Based on this new information infrastructure we built a prototype telesurgery system for intravascular neurosurgery. We made a virtual simulator for the operation of a catheter, that is designed for minimum invasive surgery inside complex and narrow brain blood vessels. A force display and visual assistance method are proposed to assist the doctor. We undertook teleoperation experiments between Nagoya and Tokyo, about 350 km away each other, using high speed optical fiber network, and evaluated the effectiveness of the proposed system.","","0-8186-7296-X","10.1109/VRAIS.1996.490514","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=490514","","Virtual environment;Asynchronous transfer mode;Surgery;Optical fiber networks;Medical diagnostic imaging;Virtual reality;Multimedia systems;Channel allocation;Multimedia communication;Computer networks","surgery;medical computing;multimedia communication;multimedia computing;optical fibre networks;asynchronous transfer mode;virtual reality","distributed virtual environment;intravascular telesurgery;multimedia telecommunication;medical doctors;surgical tools;distributed VR system;training;high quality moving pictures;high speed optical fiber network;ATM;Asynchronous Transfer Mode;bandwidth allocation;multimedia communication;computer networks;telesurgery system;intravascular neurosurgery;virtual simulator;catheter;minimum invasive surgery;visual assistance method;teleoperation experiments","","20","","12","","6 Aug 2002","","","IEEE","IEEE Conferences"
"A Cross-Platform Classroom Training Simulator: Interaction Design and EvaluationA Cross-Platform Classroom Training Simulator: Interaction Design and Evaluation","A. Delamarre; C. Lisetti; C. Buche","Florida International University,VISAGE Lab, SCIS,Miami,USA; Florida International University,VISAGE Lab, SCIS,Miami,USA; LAB-STICC CNRS, ENIB,Brest,France","2020 International Conference on Cyberworlds (CW)","30 Oct 2020","2020","","","86","93","Virtual training environments experienced with different immersive technologies can accommodate users' preferences, proficiency, and platform availability. Whereas research comparing the effects of immersive technologies can provide important insights about their impact on users' experience (e.g. engagement, transfer of learning), current studies do not address how to design the user interface (UI) to ensure sound comparisons across platforms. For effective comparisons, however, the UI designs must be adapted for the platform used to provide comparable usability. In this article we describe our UI design methodology for the development of an effective and usable virtual classroom training simulator built for three technologies: (1) desktop; (2) Head-Mounted Display (HMD); and (3) Cave Automatic Virtual Environment (CAVE). Usability and other user experience factors were evaluated for each platform with concurrent think-aloud protocol and semi-structured interviews indicating that all three UIs were easy to use and to learn. We discuss insights for future development of cross-platform VTEs.","2642-3596","978-1-7281-6497-7","10.1109/CW49994.2020.00020","Florida International University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240533","Immersive Virtual Environment;Virtual Reality;Human Computer Interaction;User Study;Design","Training;Virtual environments;Resists;User interfaces;User experience;Usability;Interviews","computer based training;computer simulation;helmet mounted displays;user interfaces;virtual reality","interaction design;virtual training environments;platform availability;user interface;UI designs;comparable usability;UI design;usable virtual classroom training simulator;user experience factors;cross-platform VTEs;classroom training simulator;immersive technologies;cross-platform classroom training simulator;desktop;head-mounted display;cave automatic virtual environment","","","","24","","30 Oct 2020","","","IEEE","IEEE Conferences"
"Validation of virtual humanoid intelligent agents in virtual reality systems","A. Sadagic","Naval Postgraduate School - NPS, MOVES Institute","2012 IEEE Virtual Reality Workshops (VRW)","12 Apr 2012","2012","","","91","92","One of the great benefits VR systems offer is their ability to simulate a number of virtual humans when their presence is needed in the context of some learning or training experience. Being that the real humans may not be available to play different roles and support virtual sessions, the ability of a system to generate highly believable representations of autonomous virtual humans - virtual intelligent agents - is vital in achieving specific learning and training objectives. Eliminating the elements of the system that can cause a negative learning and training transfer is a paramount in those systems. We illustrate the results of two user studies focused on validation of non-deterministic domain-specific behaviors generated by our system (example: behaviors typical for a well coordinated group of paramedics or military unit). The results and observations confirmed that when it comes to VR systems with stringent requirements and high expectations for positive learning/training transfer, we still need humans to evaluate and validate synthesized human-like agent behaviors.","2375-5334","978-1-4673-1246-2","10.1109/VR.2012.6180897","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180897","virtual/digital characters;validation;simulation and behavior;intelligent agents;military applications","Training;Humans;Analytical models;Virtual reality;Intelligent agents;Solid modeling;Context","learning (artificial intelligence);software agents;virtual reality","virtual humanoid intelligent agent validation;virtual reality systems;VR systems;negative learning;training transfer;nondeterministic domain-specific behavior validation;positive learning;human-like agent behavior synthesis","","","","1","","12 Apr 2012","","","IEEE","IEEE Conferences"
"Implement Multi-Character Display in Virtual Reality Environment Based on Unet and Tracker","Y. Zou; P. Wang; Q. Tang; Y. Sun","Zunyi Power Supply Bureau,Safety Supervision Department,Zunyi,Guizhou,China; Zunyi Power Supply Bureau,Safety Supervision Department,Zunyi,Guizhou,China; Zunyi Power Supply Bureau,Safety Supervision Department,Zunyi,Guizhou,China; Zunyi Power Supply Bureau,Safety Supervision Department,Zunyi,Guizhou,China","2019 2nd International Conference on Safety Produce Informatization (IICSPI)","19 May 2020","2019","","","530","532","Power grid operation is a very safe operation site, it is very important to be able to carry out related operations in accordance with the safe operation process, the existing traditional safe operation process, mainly in the traditional teaching mode or simulated real scene operation mode. In the links of management and training, operators lack intuitive experience and interaction, and they are not enough to show the serious consequences of illegal operation; As the head-mounted display becomes the most important interactive virtual reality display device, the 3d interactive display and the expressive force of the game engine are gradually improved, significantly improving participants' sense of immersion. Virtual reality technology can be used to build a simulation teaching platform for authentic visual experience, authentic representation of work flow and convincing interactive feedback. Virtual reality technology is used to establish a practical environment for grid operation in the virtual three-dimensional space of the computer that integrates class a illegal operation events. Users participating in the learning practice can operate in the virtual space according to the process. In this paper, based on unity built-in HAPI unet and third-party plug-in VRTK, the complex interaction of large-scale training business process is realized. Through VRTK, steam VR interface, the handle button state is obtained and information is transmitted on multiple instances, so as to determine the transfer and pickup state of interactive objects.","","978-1-7281-4566-2","10.1109/IICSPI48186.2019.9096025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9096025","Multiplayer networking technology;Virtual reality technology;Multiplayer online interaction;Inverse dynamics","Games;Training;Servers;Virtual reality;Synchronization;Production;Safety","helmet mounted displays;interactive systems;power engineering computing;power grids;user interfaces;virtual reality","virtual reality environment;power grid operation;head-mounted display;virtual reality technology;simulation teaching platform;interactive feedback;large-scale training business process;interactive virtual reality display device;3D interactive display;multicharacter display;Unet;Tracker;VR interface;VRTK","","","","8","","19 May 2020","","","IEEE","IEEE Conferences"
"An Evaluation of Inanimate and Virtual Reality Training for Psychomotor Skill Development in Robot-Assisted Minimally Invasive Surgery","G. Caccianiga; A. Mariani; E. De Momi; G. Cantarero; J. D. Brown","Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Biorobotics Institute, Scuola Superiore Sant’Anna, Pisa, Italy; Department of Electronics, Information, and Bioengineering, Politecnico di Milano, Milan, Italy; Department of Physical Medicine and Rehabilitation, Johns Hopkins Medical Institute, Baltimore, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA","IEEE Transactions on Medical Robotics and Bionics","20 May 2020","2020","2","2","118","129","Robot-assisted minimally invasive surgery (RAMIS) is gaining widespread adoption in many surgical specialties, despite the lack of a standardized training curriculum. Current training approaches rely heavily on virtual reality simulators, in particular for basic psychomotor and visuomotor skill development. It is not clear, however, whether training in virtual reality is equivalent to inanimate model training. In this manuscript, we seek to compare virtual reality training to inanimate model training, with regard to skill learning and skill transfer. Using a custom-developed needle-driving training task with inanimate and virtual analogs, we investigated the extent to which N=18 participants improved their skill on a given platform post-training, and transferred that skill to the opposite platform. Results indicate that the two approaches are not equivalent, with more salient skill transfer after inanimate training than virtual training. These findings support the claim that training with real physical models is the gold standard, and suggest more inanimate model training be incorporated into training curricula for early psychomotor skill development.","2576-3202","","10.1109/TMRB.2020.2990692","JHU internal fundings; Tesi All’estero Scholarship of Politecnico di Milano; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9080087","Automated;inanimate;minimally invasive;objective;robot-assisted;sensors;simulation;skill transfer;surgery;training;virtual reality","Training;Task analysis;Solid modeling;Robot sensing systems;Needles","computer based training;control engineering computing;medical computing;medical robotics;surgery;training;virtual reality","current training approaches;virtual reality simulators;basic psychomotor;visuomotor skill development;inanimate model training;virtual reality training;skill learning;custom-developed needle-driving training task;inanimate analogs;virtual analogs;given platform post-training;salient skill transfer;inanimate training;virtual training;training curricula;early psychomotor skill development;robot-assisted minimally invasive surgery;standardized training curriculum","","","","53","IEEE","28 Apr 2020","","","IEEE","IEEE Journals"
"Comparing HMD-Based and Paper-Based Training","S. Werrlich; A. Daniel; A. Ginger; P. Nguyen; G. Notni","BMW Group, Munich, Germany; BMW Group, Munich, Germany; BMW Group, Munich, Germany; BMW Group, Munich, Germany; Tech. Univ. Ilmenau, Ilmenau, Germany","2018 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","17 Jan 2019","2018","","","134","142","Collaborative Systems are in daily use by millions of people promising to improve everyone's life. Smartphones, smartwatches and tablets are everyday objects and life without these unimaginable. New assistive systems such as head-mounted displays (HMDs) are becoming increasingly important for various domains, especially for the industrial domain, because they claim to improve the efficiency and quality of procedural tasks. A range of scientific laboratory studies already demonstrated the potential of augmented reality (AR) technologies especially for training tasks. However, most researches are limited in terms of inadequate task complexity, measured variables and lacking comparisons. In this paper, we want to close this gap by introducing a novel multimodal HMD-based training application and compare it to paper-based learning for manual assembly tasks. We perform a user study with 30 participants measuring the training transfer of an engine assembly training task, the user satisfaction and perceived workload during the experiment. Established questionnaires such as the system usability scale (SUS), the user experience questionnaire (UEQ) and the Nasa Task Load Index (NASA-TLX) are used for the assessment. Results indicate significant differences between both learning approaches. Participants perform significantly faster and significantly worse using paper-based instructions. Furthermore, all trainees preferred HMD-based learning for future assembly trainings which was scientifically proven by the UEQ.","1554-7868","978-1-5386-7459-8","10.1109/ISMAR.2018.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613759","Augmented Reality;Evaluation;Head Mounted Displays;Training","Task analysis;Training;Engines;Software;Resists;Atmospheric measurements;Particle measurements","augmented reality;computer based training;groupware;helmet mounted displays;human computer interaction;human factors;user interfaces;virtual reality","paper-based training;Collaborative Systems;smartwatches;head-mounted displays;industrial domain;scientific laboratory studies;augmented reality;training tasks;inadequate task complexity;training transfer;engine assembly training task;user satisfaction;system usability scale;user experience questionnaire;Nasa Task Load Index;paper-based instructions;assistive systems;multimodal HMD-based learning","","5","","28","","17 Jan 2019","","","IEEE","IEEE Conferences"
"A Comparison of Virtual and Physical Training Transfer of Bimanual Assembly Tasks","M. Murcia-López; A. Steed",University College London; University College London,"IEEE Transactions on Visualization and Computer Graphics","13 Mar 2018","2018","24","4","1574","1583","As we explore the use of consumer virtual reality technology for training applications, there is a need to evaluate its validity compared to more traditional training formats. In this paper, we present a study that compares the effectiveness of virtual training and physical training for teaching a bimanual assembly task. In a between-subjects experiment, 60 participants were trained to solve three 3D burr puzzles in one of six conditions comprised of virtual and physical training elements. In the four physical conditions, training was delivered via paper- and video-based instructions, with or without the physical puzzles to practice with. In the two virtual conditions, participants learnt to assemble the puzzles in an interactive virtual environment, with or without 3D animations showing the assembly process. After training, we conducted immediate tests in which participants were asked to solve a physical version of the puzzles. We measured performance through success rates and assembly completion testing times. We also measured training times as well as subjective ratings on several aspects of the experience. Our results show that the performance of virtually trained participants was promising. A statistically significant difference was not found between virtual training with animated instructions and the best performing physical condition (in which physical blocks were available during training) for the last and most complex puzzle in terms of success rates and testing times. Performance in retention tests two weeks after training was generally not as good as expected for all experimental conditions. We discuss the implications of the results and highlight the validity of virtual reality systems in training.","1941-0506","","10.1109/TVCG.2018.2793638","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260860","Learning transfer;virtual reality;assembly;training","Training;Testing;Three-dimensional displays;Virtual environments;Haptic interfaces","assembling;computer animation;computer based training;interactive systems;virtual reality","physical training transfer;bimanual assembly task;consumer virtual reality technology;traditional training formats;virtual training;3D burr puzzles;physical puzzles;interactive virtual environment;physical blocks;virtual reality systems;assembly completion testing","Adult;Female;Humans;Male;Task Performance and Analysis;Transfer, Psychology;User-Computer Interface;Virtual Reality;Young Adult","9","","23","CCBY","17 Jan 2018","","","IEEE","IEEE Journals"
"EMG and Kinematic Responses to Unexpected Slips After Slip Training in Virtual Reality","P. Parijat; T. E. Lockhart; J. Liu","School of Biomedical Engineering and Science, Virginia Tech, Blacksburg, VA, USA; School of Biological and Health Systems Engineering, Arizona State University, Tempe, AZ, USA; Division of Applied Science and Technology, Marshall University, Huntington, WV, USA","IEEE Transactions on Biomedical Engineering","16 Jan 2015","2015","62","2","593","599","The objective of the study was to design a virtual reality (VR) training to induce perturbation in older adults similar to a slip and examine the effect of the training on kinematic and muscular responses in older adults. Twenty-four older adults were involved in a laboratory study and randomly assigned to two groups (VR training and control). Both groups went through three sessions including baseline slip, training, and transfer of training on slippery surface. The training group experienced 12 simulated slips using a visual perturbation induced by tilting a VR scene while walking on the treadmill and the control group completed normal walking during the training session. Kinematic, kinetic, and electromyography data were collected during all the sessions. Results demonstrated the proactive adjustments such as increased trunk flexion at heel contact after training. Reactive adjustments included reduced time to peak activations of knee flexors, reduced knee coactivation, reduced time to trunk flexion, and reduced trunk angular velocity after training. In conclusion, the study findings indicate that the VR training was able to generate a perturbation in older adults that evoked recovery reactions and such motor skill can be transferred to the actual slip trials.","1558-2531","","10.1109/TBME.2014.2361324","NSF; NIOSH; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6915881","Elderly;electromyography (EMG);fall prevention training;falls;virtual reality (VR)","Training;Legged locomotion;Muscles;Electromyography;Knee;Virtual reality;Kinematics","electromyography;gait analysis;kinematics;medical signal processing;perturbation theory;virtual reality","EMG;kinematic responses;unexpected slips;slip training;virtual reality training;older adults;muscular responses;VR training;VR control;baseline slip;slippery surface;visual perturbation;VR scene;treadmill;normal walking;training session;electromyography data collection;proactive adjustments;trunk flexion;heel contact;knee flexors;peak activations;reduced knee coactivation;reduced trunk angular velocity;evoked recovery reactions;motor skill;actual slip trials","Accidental Falls;Aged;Biofeedback, Psychology;Electromyography;Female;Gait;Humans;Male;Muscle Contraction;Photic Stimulation;Physical Stimulation;Postural Balance;Psychomotor Performance;Treatment Outcome;User-Computer Interface;Virtual Reality Exposure Therapy","13","","33","","3 Oct 2014","","","IEEE","IEEE Journals"
"Amplified Head Rotation in Virtual Reality and the Effects on 3D Search, Training Transfer, and Spatial Orientation","E. D. Ragan; S. Scerbo; F. Bacim; D. A. Bowman","Texas A&M University, College Station, TX; Virginia Tech, Blacksburg, VA; Virginia Tech, Blacksburg, VA; Virginia Tech, Blacksburg, VA","IEEE Transactions on Visualization and Computer Graphics","28 Jun 2017","2017","23","8","1880","1895","Many types of virtual reality (VR) systems allow users to use natural, physical head movements to view a 3D environment. In some situations, such as when using systems that lack a fully surrounding display or when opting for convenient low-effort interaction, view control can be enabled through a combination of physical and virtual turns to view the environment, but the reduced realism could potentially interfere with the ability to maintain spatial orientation. One solution to this problem is to amplify head rotations such that smaller physical turns are mapped to larger virtual turns, allowing trainees to view the entire surrounding environment with small head movements. This solution is attractive because it allows semi-natural physical view control rather than requiring complete physical rotations or a fully-surrounding display. However, the effects of amplified head rotations on spatial orientation and many practical tasks are not well understood. In this paper, we present an experiment that evaluates the influence of amplified head rotation on 3D search, spatial orientation, and cybersickness. In the study, we varied the amount of amplification and also varied the type of display used (head-mounted display or surround-screen CAVE) for the VR search task. By evaluating participants first with amplification and then without, we were also able to study training transfer effects. The findings demonstrate the feasibility of using amplified head rotation to view 360 degrees of virtual space, but noticeable problems were identified when using high amplification with a head-mounted display. In addition, participants were able to more easily maintain a sense of spatial orientation when using the CAVE version of the application, which suggests that visibility of the user's body and awareness of the CAVE's physical environment may have contributed to the ability to use the amplification technique while keeping track of orientation.","1941-0506","","10.1109/TVCG.2016.2601607","Office of Naval Research; Virginia Tech Research Computing's Visionarium Lab; VisCube; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7547900","Virtual reality;spatial orientation;rotation amplification;3D interaction;search;cybersickness","Training;Legged locomotion;Three-dimensional displays;Games;Navigation;Visualization;Virtual reality","helmet mounted displays;virtual reality","amplified head rotation;virtual reality;3D search;training transfer;spatial orientation;VR systems;head movements;3D environment;virtual turns;seminatural physical view control;physical rotations;cybersickness;head-mounted display;surround-screen CAVE;VR search task","","13","","53","","19 Aug 2016","","","IEEE","IEEE Journals"
"Transfer Learning algorithm in image analysis with Augmented Reality headset for Industry 4.0 technology","M. Kozek","AGH University of Science and Technology,Faculty of Mechanical Engineering and Robotics,Krakow,Poland","2020 International Conference Mechatronic Systems and Materials (MSM)","22 Sep 2020","2020","","","1","5","Modern technology lines in Industry 4.0 standard use many complex smart systems to improve the speed of production. Manufacturing becomes more flexible and, on the other hand, more demanding for a process operator. This article presents mixed reality glasses that supports the work of the operator integrated via a cloud with a technology line. Transfer learning algorithm is shown in a set of artificial neural network algorithms belonging to the Deep Learning class to analyze the image from ML headset. This algorithm is designed to recognize the current occupation of the storage tray with direct transmission of information to the control and measurement system.","","978-1-7281-6956-9","10.1109/MSM49833.2020.9201739","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201739","machine learning;Industry 4.0;Augmented Reality;Mixed Reality","Robots;Industries;Training;Augmented reality;Headphones;Neural networks","augmented reality;flexible manufacturing systems;image processing;learning (artificial intelligence);neural nets;production engineering computing","cloud computing;flexible manufacturing;smart systems;Industry 4.0 standard;augmented reality headset;image analysis;ML headset;deep learning;artificial neural network;transfer learning;mixed reality glasses","","","","13","","22 Sep 2020","","","IEEE","IEEE Conferences"
"Simulation-Based Training Improves Catering Apprentices' Mise-en-Place Knowledge and Procedure Skills","Y. R. Yen","Dept. of MIS, Far East Univ., Tainan, Taiwan","2014 IEEE 14th International Conference on Advanced Learning Technologies","22 Sep 2014","2014","","","240","241","The research purpose of this paper is to discuss skill education's computer simulation training method and, with traditional film teaching method as the control group, know about the learning effectiveness of freshmen majoring in catering with respect to mise-en-place course of Western-style food. Moreover, the paper will probe further into the personal characteristics that affect the willingness to participate in simulation learning, and the user experience of instructional media.","2161-377X","978-1-4799-4038-7","10.1109/ICALT.2014.76","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6901448","Simulation-based training;computer self-efficacy;transfer of training;Mise en place component;Catering training","Training;Computational modeling;Computers;Marine animals;Films;Iron;Computer simulation","catering industry;computer based training;digital simulation;teaching","catering apprentices Mise-en-Place knowledge;procedure skills;skill education computer simulation training method;film teaching method;control group;freshmen learning effectiveness;Western-style food;personal characteristics;simulation learning;instructional media","","","","4","","22 Sep 2014","","","IEEE","IEEE Conferences"
"Virtual reality simulation training and assisted surgery: AYRA: Virtual and physical biomodels in surgery","C. Suárez-Mejías; G. G. Ciriza; C. P. Calderón; T. G. Cía; P. Gacto-Sánchez","Innovation Technologies Group, Virgen del Rocío, University Hospital, Seville, Spain; Innovation Technologies Group, Virgen del Rocío, University Hospital, Seville, Spain; Innovation Technologies Group, Virgen del Rocío, University Hospital, Seville, Spain; Plastic and Reconstructive Surgery Department, Virgen del Rocío, University Hospital, Seville, Spain; Plastic and Reconstructive Surgery Department, Virgen del Rocío, University Hospital, Seville, Spain","2012 18th International Conference on Virtual Systems and Multimedia","3 Dec 2012","2012","","","437","444","In this paper we present a surgical application based on virtual reality called AYRA. AYRA allows surgeons training, planning and optimization of surgical procedures. AYRA was developed under a research, development and innovation project financed by the Andalusia Department of Health called VirSSPA. AYRA is very important for the health organization since the surgeons can be trained and helped by AYRA in decision making issues. Nowadays AYRA has been successfully used in more than 489 real cases and surgeons have declared their satisfaction with the results. After proving its efficiency it has been introduced in the clinical practice during the surgical planning sessions at the Virgen del Rocío University Hospital. For example, the use of AYRA reduces by 45 % the complication rate and in two hours the operating room time in breast microvascular reconstruction by DIEAP free flap. The success rate is increased because physicians can see the exact anatomy of the case and the extent of the injury that the patient suffers before proceeding with the surgery. In addition, surgeons can see and interact in 3D with other similar cases made in AYRA by other surgeon colleagues, thus promoting the training of surgeons and the knowledge transfer in this field.","","978-1-4673-2563-9","10.1109/VSMM.2012.6365956","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365956","surgeons training;surgical planning;virtual reality;Computer assisted surgery;Simulation based training;biomodel printing","Surgery;Training;Solid modeling;Planning;Servers;DICOM;Virtual reality","biomedical education;computer based training;digital simulation;injuries;knowledge management;medical computing;surgery;virtual reality","virtual reality simulation training;AYRA;virtual biomodels;physical biomodels;surgical application;innovation project;Andalusia Department of Health;VirSSPA health organization;decision making issues;clinical practice;surgical planning sessions;Virgen del Rocio University Hospital;breast microvascular reconstruction;DIEAP free flap;injury;3D interaction;surgeon training;knowledge transfer;computer assisted surgery","","","","36","","3 Dec 2012","","","IEEE","IEEE Conferences"
"Applied RFID and Virtual Reality Technology in professional training system for manufacturing","S. F. Wong; Z. X. Yang; N. Cao; W. I. Ho","Department of Electromechanical Engineering, University of Macau, China; Department of Electromechanical Engineering, University of Macau, China; Department of Electromechanical Engineering, University of Macau, China; Department of Electromechanical Engineering, University of Macau, China","2010 IEEE International Conference on Industrial Engineering and Engineering Management","23 Dec 2010","2010","","","676","680","Enhancing the professional knowledge in different levels of operator is a critical success factor to advance the performance of manufacturing industry. However, the traditional training system is lack of scientific method to transfer the professional knowledge (tacit knowledge) to the operator. Applied RFID and Virtual Reality Technology in Knowledge-based Training System can convert the tacit knowledge to the explicit knowledge to different levels of operator. The trainee can capture the basic operation skill through the web-enabled and knowledge-based training system. Moreover, the system can provide the working experience and operation history about the production and tool application to the trainee through RFID technology. They can quickly and conveniently search their target tools that will apply the real manufacturing processes without any human-being supervising. The cost of training resource can be saved, because the workload of supervisor or senior operation is reduced. The senior operation can report the updating and real-time situation of production and tools through RFID technology with knowledge-based training system. The closed loop knowledge can enhance the precision level of analysis results of production system. The industry can be sustainable development through this system.","2157-362X","978-1-4244-8503-1","10.1109/IEEM.2010.5674534","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5674534","RFID;virtual reality technology;knowledge-based training system","Training;Knowledge engineering;Radiofrequency identification;Manufacturing;Computer numerical control;Knowledge based systems;Process control","continuing professional development;industrial training;intelligent tutoring systems;Internet;manufacturing industries;production engineering computing;radiofrequency identification;sustainable development;virtual reality","virtual reality technology;professional training system;professional knowledge enhancement;critical success factor;manufacturing industry;traditional training system;scientific method;tacit knowledge;knowledge-based training system;explicit knowledge;Web-enabled training system;RFID technology;manufacturing processes;human-being supervision;training resource;closed loop knowledge;production system;sustainable development","","2","","14","","23 Dec 2010","","","IEEE","IEEE Conferences"
"VR training system with adaptive operational assistance considering straight-line transfer operation","M. Yoneda; F. Arai; T. Fukuda; K. Miyata; T. Naito","Dept. of Micro Syst. Eng., Nagoya Univ., Japan; NA; NA; NA; NA","8th IEEE International Workshop on Robot and Human Interaction. RO-MAN '99 (Cat. No.99TH8483)","6 Aug 2002","1999","","","142","147","This paper deals with an operational assistance system of a rough terrain crane. A proper control rule to operate the payload in the straight-line motion is proposed. The system assists straight-line operation with force display based on the rule. The strength of assistance can be adapted to operator's skill level by changing the gain of force display. We present some experiments on a crane simulator, and show the effectiveness of the proposed operational assistance system.","","0-7803-5841-4","10.1109/ROMAN.1999.900330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=900330","","Virtual reality;Adaptive systems;Cranes;Control systems;Automatic control;Displays;Proposals;Payloads;Systems engineering and theory;Motion control","cranes;computer based training;virtual reality;force feedback;simulation;adaptive systems","training;operational assistance system;straight-line motion;force display;operator skill;crane simulator;virtual reality","","1","","6","","6 Aug 2002","","","IEEE","IEEE Conferences"
"No transfer of gains after a single training session within a virtual environment to fundamental tests of stability","O. Elion; Y. Bahat; I. Siev-Ner; I. Sela; A. Karni; P. L. Weiss","The CAREN VR Lab, The C Sheba Medical Centre, Tel Hashomer, Israel; The CAREN VR Lab, The C Sheba Medical Centre, Tel Hashomer, Israel; The CAREN VR Lab, The C Sheba Medical Centre, Tel Hashomer, Israel; Dept. of Neurobiology and Ethology and Dept. of Learning Disabilities, University of Haifa, Israel; Dept. of Neurobiology and Ethology and Dept. of Learning Disabilities, University of Haifa, Israel; Dept. of Occupational Therapy, University of Haifa, Israel","2009 Virtual Rehabilitation International Conference","24 Jul 2009","2009","","","136","139","How specific are postural and balance control skills? An important issue for the establishment of effective training and retraining (rehabilitation) programs is whether skills gained while training in laboratory settings can be transferred to performance gains in somewhat different conditions (including every-day life). While there is much evidence showing that for volitional motor tasks the gains in performance (procedural, implicit, knowledge) accrued in practice may not always be transferable to novel task conditions, it is not clear whether the (implicit) knowledge gained in learning postural adjustments can be transferred to measures of balance (reaction to external perturbations) that have not been trained. The objective of the current study was to elucidate what aspects of a postural skill learned within a virtual environment (VE) by healthy adults may be transferable to the performance of standard tests of postural adjustments. Sixteen healthy young adults, aged 20-40 years (mean alpha SD = 29.8 alpha 2.8 years), were pseudo-randomly assigned to either a training group (Group A) or a no-training, control group (Group B). Group A performed a single training session in a VE in which maintenance of stability on a platform, while travelling along a road scenario and reaching for visual targets (secondary task) were required. Each participant underwent 8 consecutive runs of the task (2:48 m per run). A balance assessment with a given set of perturbations was performed before and after training as well as at 24 hours and 4 weeks post-training. Group B underwent the same assessments but without VE training. The results showed that the Center of Pressure (CoP) displacement tended to decrease over successive balance assessments in both groups, however, this decrease was not statistically significant. Moreover, there was no clear advantage for Group A. Thus, the postural adjustment gains were not transferred to the balance assessment tests. Non-volitional balance control gains are, in this respect, similar to gains attained in a volitional manual task learning.","2331-9569","978-1-4244-4188-4","10.1109/ICVR.2009.5174220","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5174220","Postural adjustments;Procedural knowledge;specificity;transfer","Virtual environment;Testing;Stability;Performance gain;Delay effects;Medical tests;Virtual reality;Laboratories;Gain measurement;Aging","biomechanics;computer based training;medical computing;patient rehabilitation;virtual reality","balance control skills;postural control skills;single training session;retraining programs;rehabilitation programs;virtual environment;stability;postural adjustment learning;healthy adults;visual target reaching;road scenario;center of pressure displacement","","","","23","","24 Jul 2009","","","IEEE","IEEE Conferences"
"Facial Expression Recognition Under Partial Occlusion from Virtual Reality Headsets based on Transfer Learning","B. Houshmand; N. Mefraz Khan","Ryerson University,Data Science,Toronto,Canada; Ryerson University,Electrical and Computer Engineering,Toronto,Canada","2020 IEEE Sixth International Conference on Multimedia Big Data (BigMM)","20 Oct 2020","2020","","","70","75","Facial expressions of emotion are a major channel in our daily communications, and it has been subject of intense research in recent years. To automatically infer facial expressions, convolutional neural network based approaches has become widely adopted due to their proven applicability to Facial Expression Recognition (FER) task.On the other hand Virtual Reality (VR) has gained popularity as an immersive multimedia platform, where FER can provide enriched media experiences. However, recognizing facial expression while wearing a head-mounted VR headset is a challenging task due to the upper half of the face being completely occluded. In this paper we attempt to overcome these issues and focus on facial expression recognition in presence of a severe occlusion where the user is wearing a head-mounted display in a VR setting. We propose a geometric model to simulate occlusion resulting from a Samsung Gear VR headset that can be applied to existing FER datasets. Then, we adopt a transfer learning approach, starting from two pretrained networks, namely VGG and ResNet. We further fine-tune the networks on FER+ and RAF-DB datasets. Experimental results show that our approach achieves comparable results to existing methods while training on three modified benchmark datasets that adhere to realistic occlusion resulting from wearing a commodity VR headset. Code for this paper is available at: https://github.com/bita-github/MRP-FER.","","978-1-7281-9325-0","10.1109/BigMM50055.2020.00020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9232653","Facial expression recognition;Facial occlusion;Transfer learning;VR","Face recognition;Headphones;Solid modeling;Feature extraction;Training;Virtual reality;Systematics","convolutional neural nets;emotion recognition;face recognition;helmet mounted displays;learning (artificial intelligence);virtual reality","transfer learning approach;commodity VR headset;partial occlusion;virtual reality headsets;convolutional neural network;facial expression recognition task;head-mounted VR headset;samsung gear VR headset;FER datasets;immersive multimedia platform;head-mounted display;RAF-DB datasets","","1","","25","","20 Oct 2020","","","IEEE","IEEE Conferences"
"Integration of Advanced Technology in Initial Flight Training","E. Pennington; R. Hafer; E. Nistler; T. Seech; C. Tossell",United States Air Force Academy (USAFA); United States Air Force Academy (USAFA); United States Air Force Academy (USAFA); United States Air Force Academy (USAFA); United States Air Force Academy (USAFA),"2019 Systems and Information Engineering Design Symposium (SIEDS)","13 Jun 2019","2019","","","1","5","As virtual reality and artificial intelligence technologies continue to advance, the United States Military is quickly integrating these capabilities into initial flight training through efforts like the Air Force's Pilot Training Next (PTN) program. A persistent issue, however, has been a lack of data guiding (1) the ideal degree of integration into traditional pilot training and (2) the optimal amount of structure for student pilots' training experience. The goal of this study was to evaluate the aforementioned PTN model when applied to the U.S. Air Force Academy's flight training program with special emphasis on the ideal degree of structure for airmanship success. To this end, a quasi-experimental approach was utilized, which included 60 USAFA cadets enrolled in the Powered Flight Program who were pseudo-randomly assigned to three independent groups with varying degrees of structure. The groups (i.e., High Structured, Scaffolded, and Low Structured Groups) represented a spectrum of VR-training curriculum structure ranging from a rigid, lineal objective-completion model (akin to traditional flight training) to an unguided, Montessori-like model. With group assignment as the independent variable, live-flight performance was used as the dependent variable, which was quantified using flight grade cards, number of “landing tabs” (i.e., modified solos) awarded, and a subjective Instructor Pilot rating. Subjective feedback was also obtained from students in each condition. Initial effectiveness data indicated an increased level of perceived self-efficacy in coordination with increased virtual reality simulator time as well as an accelerated rate of positive transfer to real aircraft from the strictly structured and scaffolded groups. The results of this study allow for initial recommendations for forthcoming airmanship training and undergraduate pilot training augmentation efforts across the Department of Defense.","","978-1-7281-0998-5","10.1109/SIEDS.2019.8735628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8735628","","Training;Military aircraft;Artificial intelligence;Virtual reality;Solid modeling;Aircraft;Manuals","aerospace simulation;artificial intelligence;computer based training;military computing;virtual reality","advanced technology;initial flight training;artificial intelligence technologies;United States Military;traditional pilot training;VR-training curriculum structure;flight grade cards;Air Force Academy;virtual reality;pilot training next program;flight training program;undergraduate pilot training augmentation;airmanship training;powered flight program","","2","","8","","13 Jun 2019","","","IEEE","IEEE Conferences"
"Augmented reality for skill transfer in assembly task","N. Pathomaree; S. Charoenseang","Inst. of Field Robotics, King Mongkut's Univ. of Technol., Bangkok, Thailand; Inst. of Field Robotics, King Mongkut's Univ. of Technol., Bangkok, Thailand","ROMAN 2005. IEEE International Workshop on Robot and Human Interactive Communication, 2005.","3 Oct 2005","2005","","","500","504","In this research, an augmented reality is proposed to enhance the skill transfer in the assembly task. In this system, a user can see the additional graphics information superimposed on the real world scenes. Graphical instructions and virtual objects are used for advising the user with the assembly steps and the targeted positions in assembly task. Furthermore, the system's judgment component can guide the user for the sequences of assembly and check whether the user performs actions correctly. The experimental results show that the training system with augmented reality has high percentages of transferability and high transfer effectiveness ratio. The system can also reduce assembly completion times and the number of assembly steps. Moreover, the questionnaire results show that the users are very satisfied with this kind of system. Therefore, the training system embedded with an augmented reality would be a new trend to improve the user's skills.","1944-9437","0-7803-9274-4","10.1109/ROMAN.2005.1513829","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1513829","","Augmented reality;Robotic assembly;Assembly systems;Layout;Robot sensing systems;Virtual reality;Computer graphics;Medical robotics;Intrusion detection;Cameras","augmented reality;industrial training;assembling;computer aided instruction;engineering education;production engineering","augmented reality;skill transfer;assembly task;training system;graphical instructions;virtual objects","","24","2","12","","3 Oct 2005","","","IEEE","IEEE Conferences"
"Greater Transfer to Walking of Lower Extremity Training with Robotics and Virtual Reality than Robotics Training Alone: Preliminary Findings","A. Mirelman; J. E. Deutsch; P. Bonato","Sch. of Health Related Professions, Univ. of Medicine & Dentistry of New Jersey, Newark, NJ; Sch. of Health Related Professions, Univ. of Medicine & Dentistry of New Jersey, Newark, NJ; NA","2006 International Workshop on Virtual Rehabilitation","9 Oct 2006","2006","","","155","159","Virtual reality systems have been used to deliver goal directed repetitive training to promote rehabilitation of individuals post-stroke. Lower extremity training of individuals post-stroke who used a robot coupled with virtual environment has been shown to transfer to improved overground locomotion. To isolate the active components of training in this study we compared the outcomes of training with the robot-virtual reality (VR) system to the robot alone. Four individuals post-stroke participated in a four-week training protocol. One group trained with the robot-VR system and the other group with the robot alone. The improvement in walking speed and endurance for the robot-VR group was greater than the robot group alone. Adherence as well as the number of exercises performed in each session was comparable for the two groups. The duration of training sessions was comparable at the beginning of the study. However, subjects in the robot group reported higher fatigue and produced 16% fewer minutes of training towards the end of the study. These findings support the use of virtual environments coupled with a robot for transfer of training from the virtual to the real world environment","2331-9569","1-4244-0280-8","10.1109/IWVR.2006.1707545","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1707545","","Legged locomotion;Extremities;Virtual reality;Rehabilitation robotics;Virtual environment;Motion analysis;Robot kinematics;Protocols;Dentistry;Hospitals","computer based training;medical computing;medical robotics;patient rehabilitation;virtual reality","lower extremity training;robotics;virtual reality;repetitive training;post-stroke rehabilitation;virtual environment;overground locomotion;walking speed;walking endurance;fatigue","","","","19","","9 Oct 2006","","","IEEE","IEEE Conferences"
"A conceptual model of agumented virtual and reality in cadet training","J. Tuta; L. Luić; Ž. Car","Media and Communication, University North,Koprivnica,Croatia; Media and Communication, University North,Koprivnica,Croatia; University of Zagreb,Faculty of Electrical Engineering and Computing,Zagreb,Croatia","2019 3rd European Conference on Electrical Engineering and Computer Science (EECS)","20 Nov 2020","2019","","","128","133","Through digital communication in the educational process, its stakeholders, professors and students, become creators of new information practices, which in involve modern technologies augmented reality (AR) virtual reality (VR). The research objective was aimed at detecting AR and VR information concepts important for determining students' digital intelligence in the digital creativity domain. In the education of the cadets, some issues have been observed acknowledged, particularly the issues of defining the set of information which is necessary to be transferred to the cadets by AR and VR and the issue of detecting feedback expressed through the learning outcomes previously acquired. The main research challenge is correlation of information sets and how to structure them into a standard cadet training information model. The research was conducted by using the method of content analysis of software solutions and the questionnaire method. The cadets and expert at military academy have been selected as the research sample as they undergo through both the process of acquiring theoretical knowledge as well as practical training. The paper presents the research aimed at VR prototype development and its evaluation with two cadets generations and military professionals, who were introduced to VR technology in different ways. The obtained research results present basis for an AR / VR conceptual model to be further defined, that will contain set of abstract elements, relationships, and information that depict a complex real cadet training system. In this sense, this paper represents an initial step in defining the framework of a standard AR / VR information model in the military training that can be further developed by creating additional categories of data that do not appear in any of the existing information models.","","978-1-7281-6109-9","10.1109/EECS49779.2019.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9257549","communication;conceptual model;virtual reality;augmented reality;cadet training;military","Training;Prototypes;Solid modeling;Military aircraft;Military computing;Augmented reality;Three-dimensional displays","augmented reality;computer based training;military computing","digital communication;educational process;information practices;VR information concepts;digital creativity domain;information sets;standard cadet training information model;questionnaire method;military academy;VR prototype development;VR technology;VR conceptual model;VR information model;military training;agumented reality;cadet generations;virtual reality;digital intelligence;content analysis;software solutions;military professionals;AR conceptual model;abstract elements;complex real cadet training system;standard AR information model","","","","16","","20 Nov 2020","","","IEEE","IEEE Conferences"
"On-Road Evaluation of Autonomous Driving Training","D. Sportillo; A. Paljic; L. Ojeda","PSL Research University, Center for Robotics, MINES ParisTech Groupe PSA, Paris, France; PSL Research University, Center for Robotics, MINES ParisTech, Paris, France; Groupe PSA, Velizy-Villacoublay, France","2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","25 Mar 2019","2019","","","182","190","Driver interaction with increasingly automated vehicles requires prior knowledge of system capabilities, operational know-how to use novel car equipment and responsiveness to unpredictable situations. With the purpose of getting drivers ready for autonomous driving, in a between-subject study sixty inexperienced participants were trained with an on-board video tutorial, an Augmented Reality (AR) program and a Virtual Reality (VR) simulator. To evaluate the transfer of training to real driving scenarios, a test drive on public roads was conducted implementing, for the first time in these conditions, the Wizard of Oz (WoZ) protocol. Results suggest that VR and AR training can foster knowledge acquisition and improve reaction time performance in take-over requests. Moreover, participants' behavior during the test drive highlights the ecological validity of the experiment thanks to the effective implementation of the WoZ methodology.","2167-2148","978-1-5386-8555-6","10.1109/HRI.2019.8673277","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8673277","Automated Vehicles;Virtual Reality;Augmented Reality;Transfer of Training;TOR;Wizard of Oz;Human-Vehicle Interaction","Automobiles;Training;Autonomous vehicles;Roads;Automation;Augmented reality","augmented reality;computer based training;traffic engineering computing","driving scenarios;public roads;knowledge acquisition;road evaluation;autonomous driving training;driver interaction;car equipment;on-board video tutorial;VR training;between-subject study;virtual reality simulator;augmented reality program;WoZ protocol;Wizard of Oz;AR training","","3","","36","","25 Mar 2019","","","IEEE","IEEE Conferences"
"The effects of presentation method and simulation fidelity on psychomotor education in a bimanual metrology training simulation","J. Bertrand; A. Bhargava; K. C. Madathil; A. Gramopadhye; S. V. Babu","Clemson University, USA; Clemson University, USA; Clemson University, USA; Clemson University, USA; Clemson University, USA","2017 IEEE Symposium on 3D User Interfaces (3DUI)","6 Apr 2017","2017","","","59","68","In this study, we empirically evaluated the effects of presentation method and simulation fidelity on task performance and psychomotor skills acquisition in an immersive bimanual simulation towards precision metrology education. In a 2 × 2 experiment design, we investigated a large-screen immersive display (LSID) with a head-mounted display (HMD), and the presence versus absence of gravity. Advantages of the HMD include interacting with the simulation in a more natural manner as compared to using a large-screen immersive display due to the similarities between the interactions afforded in the virtual compared to the real-world task. Suspending the laws of physics may have an effect on usability and in turn could affect learning outcomes. Our dependent variables consisted of a pre and post cognition questionnaire, quantitative performance measures, perceived workload and system usefulness, and a psychomotor assessment to measure to what extent transfer of learning took place from the virtual to the real world. Results indicate that the HMD condition was preferable to the immersive display in several metrics while the no-gravity condition resulted in users adopting strategies that were not advantageous for task performance.","","978-1-5090-6716-9","10.1109/3DUI.2017.7893318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7893318","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, augmented, and virtual realities","Solid modeling;Training;Aerospace electronics;Resists;Metrology;Visualization;Gravity","computer based training;digital simulation;helmet mounted displays;measurement;virtual reality","presentation method;simulation fidelity;psychomotor education;bimanual metrology training simulation;psychomotor skill acquisition;immersive bimanual simulation;precision metrology education;large-screen immersive display;LSID;head-mounted display;HMD;no-gravity condition","","3","","36","","6 Apr 2017","","","IEEE","IEEE Conferences"
"Small Marker Tracking with Low-Cost, Unsynchronized, Movable Consumer Cameras For Augmented Reality Surgical Training","N. Rewkowski; A. State; H. Fuchs","UNC Chapel Hill, UMD College Park; UNC Chapel Hill; UNC Chapel Hill","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","90","95","Surgeons improve their skills through repetition of training tasks in order to operate on living patients, ideally receiving timely, useful, and objective performance feedback. However, objective performance measurement is currently difficult without 3D visualization, with effective surgical training apparatus being extremely expensive or limited in accessibility. This is problematic for medical students, especially in situations such as the COVID-19 pandemic in which they are needed by the community but have few ways of practicing without lab access. In this work, we propose and prototype a system for augmented reality (AR) visualization of laparoscopic training tasks using cheap and widely-compatible borescopes, which can track small objects typical of surgical training. We use forward kinematics for calibration and multi-threading to attempt synchronization in order to increase compatibility with consumer applications, resulting in an effective AR simulation with low-cost devices and consumer software, while also providing dynamic camera and marker tracking. We test the system with a typical peg transfer task on the HoloLens 1 and MagicLeap One.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288414","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality; Computing methodologies;Artificial intelligence;Computer vision;Computer vision problems;Tracking","Training;Visualization;Three-dimensional displays;Surgery;Cameras;Task analysis;Augmented reality","augmented reality;computer based training;medical computing;medical image processing;object tracking;surgery","MagicLeap One;HoloLens 1;surgical training apparatus;peg transfer task;dynamic camera;consumer software;low-cost devices;AR simulation;consumer applications;widely-compatible borescopes;laparoscopic training tasks;augmented reality visualization;COVID-19 pandemic;medical students;objective performance measurement;objective performance feedback;augmented reality surgical training;movable consumer cameras;marker tracking","","","","35","","16 Dec 2020","","","IEEE","IEEE Conferences"
"Influences on the Elicitation of Interpersonal Space with Virtual Humans","D. M. Krum; S. Kang; T. Phan","University of Southern California, Institute for Creative Technologies; University of Southern California, Institute for Creative Technologies; University of Southern California, Institute for Creative Technologies","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","223","9","The emergence of low cost virtual and augmented reality systems has encouraged the development of immersive training applications for medical, military, and many other fields. Many of the training scenarios for these various fields may require the presentation of realistic interactions with virtual humans. It is thus vital to determine the critical factors of fidelity required in those interactions to elicit naturalistic behavior on the part of trainees. Negative training may occur if trainees are inadvertently influenced to react in ways that are unexpected and unnatural, hindering proper learning and transfer of skills and knowledge back into real world contexts. In this research, we examined whether haptic priming (presenting an illusion of virtual human touch at the beginning of the virtual experience) and different locomotion techniques (either joystick or physical walking) might affect proxemic behavior in human users. The results of our study suggest that locomotion techniques can alter proxemic behavior in significant ways. Haptic priming did not appear to impact proxemic behavior, but did increase rapport and other subjective social measures. The results suggest that designers and developers of immersive training systems should carefully consider the impact of even simple design and fidelity choices on trainee reactions in social interactions.","","978-1-5386-3365-6","10.1109/VR.2018.8446235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446235","Virtual humans;virtual reality;immersive training;fidelity;proxemics;haptic priming;locomotion techniques.: Human-centered computing-Human Computer Interaction (HCI)-Interaction Paradigms-Virtual Reality;Human-centered computing-Interaction design-Interaction design process and methods-User interface design","Haptic interfaces;Training;Legged locomotion;Virtual environments;Atmospheric measurements;Particle measurements","augmented reality;haptic interfaces;interactive devices;training","elicitation;interpersonal space;virtual humans;augmented reality systems;immersive training applications;training scenarios;realistic interactions;naturalistic behavior;negative training;proper learning;virtual human touch;virtual experience;human users;impact proxemic behavior;immersive training systems;trainee reactions;social interactions;locomotion techniques","","","","28","","30 Aug 2018","","","IEEE","IEEE Conferences"
"IEEE Standard for Augmented Reality Learning Experience Model","",,"IEEE Std 1589-2020","16 Apr 2020","2020","","","1","48","Augmented Reality (AR) promises to provide significant boosts in operational efficiency by making information available to employees needing task support in context in real time. To support according implementations of AR training systems,this document proposes an overarching integrated conceptual model that describes interactions between the physical world, the user, and digital information, the context for AR-assisted learning and other parameters of the environment. It defines two data models and their binding to XML and JSON for representing learning activities (also known as employee tasks and procedures) and the learning environment in which these tasks are performed (also known as the workplace). The interoperability specification and standard is presented in support of an open market where interchangeable component products provide alternatives to monolithic Augmented Reality-assisted learning systems. Moreover, it facilitates the creation of experience repositories and online marketplaces for Augmented Reality-enabled learning content. Specific attention was given to reuse and repurposing of existing learning content and catering to `mixed' experiences combining real world learner guidance with the consumption (or production) of traditional contents such as instructional video material or learning apps and widgets.;Augmented Reality (AR) promises to provide significant boosts in operational efficiency by making information available to employees needing task support in context in real time. To support according implementations of AR training systems,this document proposes an overarching integrated conceptual model that describes interactions between the physical world, the user, and digital information, the context for AR-assisted learning and other parameters of the environment. It defines two data models and their binding to XML and JSON for representing learning activities (also known as employee tasks and procedures) and the learning environment in which these tasks are performed (also known as the workplace). The interoperability specification and standard is presented in support of an open market where interchangeable component products provide alternatives to monolithic Augmented Reality-assisted learning systems. Moreover, it facilitates the creation of experience repositories and online marketplaces for Augmented Reality-enabled learning content. Specific attention was given to reuse and repurposing of existing learning content and catering to ‘mixed’ experiences combining real world learner guidance with the consumption (or production) of traditional contents such as instructional video material or learning apps and widgets.","","978-1-5044-6448-2","10.1109/IEEESTD.2020.9069498","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9069498","Augmented Reality;E-Learning;Workplace Training;Learning Activity;Learning Experience;Performance Support;Immersive Learning Environment;Mixed Reality","IEEE Standards;Augmented reality;Training data;Learning systems;Electronic learning","augmented reality;computer based training;formal specification;open systems;XML","JSON;XML;monolithic augmented reality-assisted learning;augmented reality-enabled learning;augmented reality learning experience model;AR training systems;integrated conceptual model;operational efficiency;IEEE standard;experience repositories;interoperability specification;learning environment;learning activities;data models;AR-assisted learning","","","","","","16 Apr 2020","","","IEEE","IEEE Standards"
"Research on 10kV Line Breaker Check Training System Based on Virtual Reality","X. Xu; L. Shen; S. Li; S. Wang",Shibei Power Supply Company of SMEPC; Shibei Power Supply Company of SMEPC; Shibei Power Supply Company of SMEPC; Shibei Power Supply Company of SMEPC,"2019 International Conference on Smart Grid and Electrical Automation (ICSGEA)","14 Nov 2019","2019","","","18","21","The training is the important means to improve power system operators' quality and ensure the safe, stable and reliable operation of power system. The job of 10kV line breaker check is one of the most important tasks of relay protection, and the training effect of this job is directly related to the work efficiency and quality of relay protection employees. However, in the training for relay protection trainees, it is impossible to carry out the actual operation in the substation considering the safety factor, and the construction of simulated substation costs a lot. To solve this problem, this paper uses Unity to develop a 10kV line breaker check training system based on virtual reality (VR). The training system development tools, 10kV line breaker check project, the training system structure and function design are introduced in the paper. Practical application shows that the training system is simple to use, easy to learn, can timely and quickly transfer data and results, which has achieved a good training effect.","","978-1-7281-4463-4","10.1109/ICSGEA.2019.00013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8901373","10kV line breaker check;relay protection;virtual reality","","circuit breakers;computer based training;power engineering computing;power engineering education;power supply quality;power system reliability;power system stability;relay protection;virtual reality","safe operation;stable operation;relay protection employees;relay protection trainees;virtual reality;training system development tools;training system structure;function design;training effect;power system operators;line breaker check project;voltage 10.0 kV","","","","11","","14 Nov 2019","","","IEEE","IEEE Conferences"
"ROV simulation validation and verification","B. Fletcher","Imetrix Inc., Cataumet, MA, USA","Oceans '97. MTS/IEEE Conference Proceedings","6 Aug 2002","1997","2","","1064","1069 vol.2","The TRANSoM (Training for Remote Sensing and Manipulation) program, sponsored by the Office of Naval Research, is developing a Virtual Environment based training system for remotely operated vehicle (ROV) pilots. A key feature of this system is the simulation of the vehicle in the created environment. It is imperative that the simulation be of sufficient fidelity so as to provide an effective training tool for the real systems. To this end, a dynamic model has been created, which may be tailored based on individual vehicle characteristics. Currently, this simulation is being evaluated in comparison with the performance of the Imetrix Talon ROV which is being used as the basis for the training transfer tests. The performance of the actual and simulated ROV are being compared both qualitatively and quantitatively. It is important to determine the correct ""look and feel"" of the simulation to the user, as well as measuring the actual dynamic responses of the vehicle and simulation. Results of the testing are being incorporated into the dynamic model to refine the fidelity and flexibility of the simulation.","","0-7803-4108-2","10.1109/OCEANS.1997.624139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=624139","","Remotely operated vehicles;Vehicle dynamics;Displays;Sensor phenomena and characterization;Sensor systems;Virtual environment;Testing;Sonar;Control system synthesis;Remote sensing","virtual reality;computer based training;telecontrol;dynamic response;training;remote sensing;naval engineering computing;simulation;intelligent tutoring systems;military computing","remotely operated vehicle simulation;virtual environment based training system;pilot training;TRANSoM program;effective training tool;dynamic model;individual vehicle characteristics;simulation validation;simulation verification;Imetrix Talon ROV;look and feel;actual dynamic responses;fidelity;flexibility;reality-based system;intelligent tutoring system;expert assessment;simulation software","","2","3","7","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Augmented Cues Facilitate Learning Transfer from Virtual to Real Environments","N. Cooper; F. Milella; I. Cant; C. Pinto; M. White; G. Meyer",NA; NA; NA; NA; NA; NA,"2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","194","198","The aim of this study was to investigate whether augmented cues that have previously been shown to enhance performance and user satisfaction in VR training translate into performance improvements in real environments. Subjects were randomly allocated into 3 groups. Group 1 were trained to perform a real tyre change, group 2 were trained in a conventional VR setting, while group 3 were trained in VR with augmented cues. After training participants were tested on a real tyre change task. Overall time to completion was recorded as objective measure; subjective ratings of presence, perceived workload and discomfort were recorded using questionnaires. The performances of the three groups were compared. Overall, participants who received VR training performed significantly faster on the real task than participants who completed the real tyre change only. The difference between the virtual reality training groups was found to be not significant. However, participants who were trained with augmented cues performed the real tyre change with fewer errors than participants in the minimal cues training group. Systematic differences in subjective ratings that reflected objective performance were also observed.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836496","virtual reality;training transfer;multisensory feedback;augmented cues;performance;presence;workload;simulation sickness","Training;Solid modeling;Virtual reality;Atmospheric measurements;Particle measurements;Computational modeling;Wheels","augmented reality;computer based training","augmented cues;learning transfer;virtual environments;real environments;VR training","","4","","31","","2 Feb 2017","","","IEEE","IEEE Conferences"
"Virtual Reality Based Knowledge Acquisition and Job Training for Advanced Casting Skills","K. Watanuki; K. Kojima","Saitama University, Japan; Saitama University, Japan","16th International Conference on Artificial Reality and Telexistence--Workshops (ICAT'06)","12 Feb 2007","2006","","","666","671","The environment where Japanese industry has beenpaid with respect is changing tremendously due to the globalization of economics, where Asian countries are undergoing economical and technical development as well as advancing in information technology. For example, in the design of custom-made casting product, a designer whom lacking of casting knowledge may not be able to produce a good design. In order to obtain a good design and manufacturing result, it is necessary to equip the designer and manufacturer with a support system related to casting design or so called, knowledge transfer and creation system. In recent years, the design supporting system using VR technology is developed, and introduced in the manufacturing industry. The merit of using VR system is being able to carry out the stereoscopy of the product model drawn by 3D CAD, and to carry out the design review of the product model in the same size as thing. However, since many systems extend the display of the conventional 3D CAD, they cannot input annotation and so on directly in VR environment. In this paper, the system which can input and display the annotation in VR environment is developed. By drawing annotation to the product model displayed on VR environment, sharing of technical tacit knowledge and engineers' communication are promoted, and engineers becomes possible gaining physical tacit knowledge.","","0-7695-2754-X","10.1109/ICAT.2006.147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4089335","","Virtual reality;Knowledge acquisition;Casting;Environmental economics;Manufacturing;Design automation;Knowledge engineering;Industrial training;Industrial economics;Globalization","CAD;casting;computer aided instruction;multimedia systems;production engineering computing;virtual reality","virtual reality;knowledge acquisition;job training;advanced casting skills;Japanese industry;Asian countries;information technology;custom-made casting product;casting knowledge;casting design;knowledge transfer;design supporting system;manufacturing industry;VR system;3D CAD;technical tacit knowledge","","3","","4","","12 Feb 2007","","","IEEE","IEEE Conferences"
"Virtual Training: Learning Transfer of Assembly Tasks","P. Carlson; A. Peters; S. B. Gilbert; J. M. Vance; A. Luse","Department of Human-Computer Interaction (HCI), Iowa State University, Ames, IA; Department of Human-Computer Interaction (HCI), Iowa State University, Ames, IA; Department of Industrial and Manufacturing Systems Engineering, Iowa State University, Ames, IA; Department of Mechanical Engineering, Iowa State University, Ames, IA; Department of Management Science and Information Systems, Oklahoma State University, Stillwater, OK","IEEE Transactions on Visualization and Computer Graphics","29 Apr 2015","2015","21","6","770","782","In training assembly workers in a factory, there are often barriers such as cost and lost productivity due to shutdown. The use of virtual reality (VR) training has the potential to reduce these costs. This research compares virtual bimanual haptic training versus traditional physical training and the effectiveness for learning transfer. In a mixed experimental design, participants were assigned to either virtual or physical training and trained by assembling a wooden burr puzzle as many times as possible during a twenty minute time period. After training, participants were tested using the physical puzzle and were retested again after two weeks. All participants were trained using brightly colored puzzle pieces. To examine the effect of color, testing involved the assembly of colored physical parts and natural wood colored physical pieces. Spatial ability as measured using a mental rotation test, was shown to correlate with the number of assemblies they were able to complete in the training. While physical training outperformed virtual training, after two weeks the virtually trained participants actually improved their test assembly times. The results suggest that the color of the puzzle pieces helped the virtually trained participants in remembering the assembly process.","1941-0506","","10.1109/TVCG.2015.2393871","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7014246","learning transfer;haptics;assembly;Learning transfer;Haptics;virtual reality;assembly;training","Training;Assembly;Virtual environments;Color;Haptic interfaces;Testing;Educational institutions","computer based training;virtual reality","virtual training;learning transfer;assembly tasks;assembly worker training;virtual reality;virtual bimanual haptic training;physical training;wooden burr puzzle;physical puzzle;colored physical parts;natural wood colored physical pieces;spatial ability;mental rotation;puzzle pieces;virtually trained participants;assembly process","","34","","56","","19 Jan 2015","","","IEEE","IEEE Journals"
"Virtual reality and medicine: from training systems to performance machines","J. M. Rosen; D. R. Laub; S. D. Pieper; A. M. Mecinski; H. Soltanian; M. A. McKenna; D. Chen; S. L. Delp; J. P. Loan; C. Basdogan","Div. of Plastic & Reconstructive Surgery, Dartmouth-Hitchcock Med. Centre, Lebanon, NH, USA; Div. of Plastic & Reconstructive Surgery, Dartmouth-Hitchcock Med. Centre, Lebanon, NH, USA; NA; NA; NA; NA; NA; NA; NA; NA","Proceedings of the IEEE 1996 Virtual Reality Annual International Symposium","6 Aug 2002","1996","","","5","13","The paper reviews a decade of work in applying virtual reality to medicine. Beginning with a brief history of simulations and surgery, we present a background to surgery simulators and then discuss the problem of limited human body models in past systems. We present our work at developing human body models beginning with the first virtual reality leg simulator in 1989. This model allowed simple tendon transfers and osteotomies with the computer able to predict the resulting mechanics and ability to walk. We also discuss the leg model's evolution into a performance machine which will allow a surgeon to predict position and subsequent function of an Anterior Cruciate Ligament (ACL) repair. This is paralleled by Department of Defense work on a leg model that can have a simulated wound and predicts blood loss and its ability to function. We review computer aided surgery and virtual reality technologies. We then present our work in plastic surgery computer aided planning and predict the importance of this work for surgical training.","","0-8186-7296-X","10.1109/VRAIS.1996.490505","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=490505","","Virtual reality;Biological system modeling;Surgery;Predictive models;Medical simulation;Computational modeling;Leg;Humans;History;Tendons","medical computing;virtual reality;digital simulation;biomechanics;computer aided instruction;biomedical education","virtual reality;medicine;training systems;performance machines;surgery simulators;limited human body models;leg simulator;simple tendon transfers;osteotomies;Anterior Cruciate Ligament repair;simulated wound;blood loss;computer aided surgery;plastic surgery computer aided planning;surgical training","","6","2","28","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Large-scale Virtual Reality micro-robotic cell injection training","S. Faroque; B. Horan; M. Mortimer; M. Pangestu","CADET Virtual Reality Lab, School of Engineering, Deakin University, Geelong, Australia; CADET Virtual Reality Lab, School of Engineering, Deakin University, Geelong, Australia; CADET Virtual Reality Lab, School of Engineering, Deakin University, Geelong, Australia; Department of Obstetrics and Gynaecology, Monash University, Melbourne, Australia","2016 World Automation Congress (WAC)","6 Oct 2016","2016","","","1","6","Currently the micro-robotic cell injection procedure is performed manually by professional bio-operators. It is a challenging task requiring advanced skills including the ability to precisely control the movement of a micropipette. Developing these skills requires both lengthy and intensive training, and significant practical experience. This paper extends upon our previous work in desktop Virtual Reality (VR) cell injection training to introduce a large-scale VR micro-robotic cell injection system. Through utilization of large visual displays and the large workspace INCA 6D haptic device, the proprioception related to large arm movements (and corresponding visual representation) and the resulting movement of the micropipette in relation to the cell aims to provide the user with a better understanding of the spatial relationship between the micropipette and cell. The haptic device can be operated either with or without haptic guidance. When enabled, haptic guidance is provided in the form of virtual fixtures (VFs) and force feedback to assist the user in following the ideal trajectory towards the penetration point, applying appropriate force for penetration and stopping the micropipette's tip at the suitable deposition point. A user evaluation was conducted to study the usability of the system. Eighteen participants took part in the experiments and were randomly divided into six groups based on the display and haptic guidance modes assigned. The results demonstrated that the large-scale VR micro-robotic cell injection system is a feasible and effective method for bio-operator training where it is suggested that the skills and knowledge acquired can be transferred to the real-world task.","","978-1-8893-3551-3","10.1109/WAC.2016.7583006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7583006","Micro-robot;cell injection;virtual reality;haptics;skill training","Image edge detection;Visualization;Robots","computer based training;haptic interfaces;large-scale systems;medical computing;medical robotics;microrobots;virtual reality","large-scale virtual reality;microrobotic cell injection training;bio-operators;micropipette;intensive training;INCA 6D haptic device;virtual fixtures;VF;user evaluation","","3","","18","","6 Oct 2016","","","IEEE","IEEE Conferences"
"A virtual reality based exercise system for hand rehabilitation post-stroke: transfer to function","S. V. Adamovich; A. S. Merians; R. Boian; M. Tremaine; G. S. Burdea; M. Recce; H. Poizner","Dept. of Biomedical Eng., New Jersey Inst. of Technol., Newark, NJ, USA; NA; NA; NA; NA; NA; NA","The 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","14 Mar 2005","2004","2","","4936","4939","We present preliminary results from a virtual reality (VR)-based system for hand rehabilitation that uses a CyberGlove and a Rutgers Master II-ND haptic glove. This system trains finger range of motion, finger flexion speed, independence of finger motion and finger strength. Eight chronic post-stroke subjects participated. In keeping with variability in both the lesion site and in initial upper extremity function, each subject showed improvement on a unique combination of movement parameters in VR training. These improvements transferred to gains on clinical tests, as well as to significant reductions in task completion times for the prehension of real objects. These results are indicative of the potential feasibility of this exercise system for rehabilitation in patients with hand dysfunction resulting from neurological impairment.","","0-7803-8439-3","10.1109/IEMBS.2004.1404364","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1404364","stroke;hand function;virtual reality (VR);CyberGlove;Rutgers Master II-ND;grasping","Virtual reality;Fingers;Data gloves;Biomedical engineering;Lesions;Medical treatment;Fractionation;Grasping;Kinematics;Kinetic theory","patient rehabilitation;virtual reality;biomechanics;data gloves","virtual reality;exercise system;post-stroke hand rehabilitation;CyberGlove;Rutgers Master II-ND haptic glove;finger flexion speed;finger motion;finger strength;hand dysfunction;neurological impairment","","32","","17","","14 Mar 2005","","","IEEE","IEEE Conferences"
"Exploring social presence transfer in real-virtual human interaction","S. Daher; K. Kim; M. Lee; A. Raij; R. Schubert; J. Bailenson; G. Welch",University of Central Florida; University of Central Florida; University of Central Florida; University of Central Florida; University of Central Florida and UNC-Chapel Hill; Stanford University; University of Central Florida,"2016 IEEE Virtual Reality (VR)","7 Jul 2016","2016","","","165","166","We explore whether a peripheral observation of apparent mutual social presence between a real human (RH) and a virtual human (VH) can in turn increase a subject's sense of social presence with the VH. In other words, we explore whether social presence can “transfer” from one RH-VH interaction to another. Specifically, we carried out an experiment where human subjects were asked to play a game with a VH. As they entered the game room, approximately half of the subjects were exposed to a brief but apparently engaging conversation between an RH and the VH. The subjects who were exposed to the brief RH-VH interaction had significantly higher measures of both emotional connection and the attentional allocation dimension of social presence for the VH, compared to those who were not. We describe the motivation, the experiment, and the results.","2375-5334","978-1-5090-0836-0","10.1109/VR.2016.7504705","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504705","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems — Artificial, Augmented, and Virtual Realities;J.4 [Computer Applications]: Social and Behavioral Sciences — Psychology","Games;Electronic mail;Psychology;Resource management;Medical services;Virtual environments;Training","computer games;graphical user interfaces;social sciences computing;virtual reality","attentional allocation dimension;emotional connection;apparently engaging conversation;game room;RH-VH interaction;apparent mutual social presence;peripheral observation;real-virtual human interaction;social presence transfer","","2","","7","","7 Jul 2016","","","IEEE","IEEE Conferences"
"Development of Virtual Reality Serious Game for Underground Rock-Related Hazards Safety Training","Z. Liang; K. Zhou; K. Gao","School of Resources and Safety Engineering, Central South University, Changsha, China; School of Resources and Safety Engineering, Central South University, Changsha, China; School of Resources and Safety Engineering, Central South University, Changsha, China","IEEE Access","30 Aug 2019","2019","7","","118639","118649","Traditional safety training media to transfer safety knowledge specific to the rock-related hazards in underground mines are mainly video or manuals, which are inefficient and bring a poor training experience. In this paper, we designed and developed a serious game based on virtual reality (VR) technology in order to efficiently transfer safety knowledge and enable enhanced interactive safety training. For different training purposes and users, we designed two modes, one for professional scaling training suitable for novice scalers, the other for rock-related hazards perception training suitable for other miners. Our game is built based on game engine-Unity3D and equipped with HTC VIVE to improve immersion. The game pipeline is to have trainees basically understand safety knowledge through guided interaction and then make a self-adaptive practice to fully master it. We evaluated the effectiveness of our game, and the results of the comparative experiment show that our game is more efficient than the instructional video in both training modes. The application of our game is proven to have the potential to change the safety situation of underground mines and evaluate the level of safety awareness and risk aversion of the miners in the future.","2169-3536","","10.1109/ACCESS.2019.2934990","Central South University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8795446","Safety training;underground mining;virtual reality;rock-related hazards;serious game","Games;Training;Rocks;Hazards;Virtual reality;Accidents","computer based training;design engineering;health hazards;industrial training;mining;mining industry;occupational safety;risk management;rocks;serious games (computing);virtual reality","underground mines;professional scaling training;game engine-Unity3D;risk aversion;virtual reality serious game design;hazards perception training;underground rock;HTC VIVE equipment","","3","","48","CCBY","13 Aug 2019","","","IEEE","IEEE Journals"
"Virtual Reality for training - The impact of smell on presence, cybersickness, fatigue, stress and knowledge transfer","D. Narciso; M. Bessa; M. Melo; J. Vasconcelos-Raposo","UTAD,Engineering Department,Vila Real,Portugal; UTAD,Engineering Department,Vila Real,Portugal; INESC TEC,Porto,Portugal; UTAD,Departament of Education and Psychology,Vila Real,Portugal","2019 International Conference on Graphics and Interaction (ICGI)","14 Jan 2020","2019","","","115","121","The area of professional training using virtual reality technologies has received considerable investment due to the advantages that virtual reality provides over traditional training. In this paper, we present an experiment whose goal was to analyse the impact that an additional stimulus has on the effectiveness of a virtual environment designed to train firefighters. The additional stimulus is a smell, more specifically the smell of burnt wood, which is consistent with the audiovisual content presented, and the effectiveness of the VE is measured through participant's feeling of presence, cybersickness, fatigue, stress and transfer of knowledge. The results indicate that, although the VE was successful in transferring knowledge, the addition of smell did not influence any of the measured variables. In the discussion section, we present the various factors that we believe have influenced this result. As future work, more experiments will be performed, with other stimuli, to understand better which stimuli increase participant's feeling of presence in the VE.","","978-1-7281-6378-9","10.1109/ICGI47575.2019.8955071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8955071","Virtual Reality;Olfactory Sense;Multisensory Stimulation","Training;Olfactory;Fatigue;Stress;Knowledge transfer;Atmospheric measurements","computer based training;continuing professional development;virtual reality","smell;stress;professional training;virtual reality technologies;additional stimulus;virtual environment;cybersickness;fatigue;knowledge transfer;firefighters;audiovisual content","","1","","44","","14 Jan 2020","","","IEEE","IEEE Conferences"
"Training the Hubble space telescope flight team","R. B. Loftin; P. Kenney","Houston Univ., TX, USA; NA","IEEE Computer Graphics and Applications","6 Aug 2002","1995","15","5","31","37","As the results demonstrate, members of the flight team judged, on average, that the use of a virtual environment for training had a positive effect on their job performance during the HST repair and maintenance mission. Moreover, audio and visual cues provided a positive aid in using the virtual environment. The discomfort experienced by some of the participants did not pose a serious problem with training transfer, but further study should be devoted to reducing these effects. The positive experiences reported here have broadened and deepened the interest of NASA in the use of VR technology as a training tool.<>","1558-1756","","10.1109/38.403825","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=403825","","Telescopes;Space technology;Virtual environment;NASA;Space missions;Personnel;Data visualization;Aerospace simulation;Space shuttles;Research and development","virtual reality;computer based training;training;computer aided instruction;aerospace computing","Hubble space telescope flight team;virtual environment;repair;maintenance mission;training transfer","","61","5","11","","6 Aug 2002","","","IEEE","IEEE Magazines"
"Navigating in natural environments: a virtual environment training transfer study","R. P. Darken; W. P. Banker","Dept. of Comput. Sci., Naval Postgraduate Sch., Monterey, CA, USA; NA","Proceedings. IEEE 1998 Virtual Reality Annual International Symposium (Cat. No.98CB36180)","6 Aug 2002","1998","","","12","19","The ability to use virtual environments as either an abstraction of a space, similar to a map, or as a simulation of the space itself has suggested to many that it would be a useful tool in terrain familiarization of unknown environments. Up to this point, all research in this area has focused on building interiors and urban environments which are significantly different from natural environments in terms of navigation cues and useful wayfinding techniques. The experiment we present uses a virtual environment, as compared to a map only or real-world conditions on navigation tasks in a natural environment. We show that navigation ability is more important to performance than the training method, with the virtual environment being most effective for intermediate orienteers as compared to advanced or beginner orienteers.","","0-8186-8362-7","10.1109/VRAIS.1998.658417","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=658417","","Navigation;Virtual environment;Visualization;Costs;Testing;Computer science","virtual reality;navigation;computer based training;human factors","natural environment navigation;virtual environment;training transfer;spatial abstraction;spatial simulation;terrain familiarization;unknown environments;interiors;urban environments;navigation cues;wayfinding techniques;performance;intermediate orienteers","","19","","6","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Improving wheelchair driving performance in a virtual reality simulator","P. S. Archambault; C. Bigras","McGill University,School of Physical and Occupational Therapy,Montreal,Canada; McGill University,School of Physical and Occupational Therapy,Montreal,Canada","2019 International Conference on Virtual Rehabilitation (ICVR)","13 Feb 2020","2019","","","1","2","In this study, we measured if practice of a wheelchair activity in a virtual reality simulator (entering an elevator) improved wheelchair positioning skills in naïve, healthy adults. Performance was assessed immediately after practice, two days later (retention) and in a real-world equivalent task (transfer). The influence of augmented feedback on retention and transfer was also assessed. Forty participants were randomized to either an augmented feedback group (who received information on collisions and on task completion time) and a no-feedback group. Following training, both groups improved their wheelchair positioning abilities. Learning was maintained at retention and skills transferred to the real-world wheelchair. Augmented feedback did not procure any additional effects. Practice in a virtual reality simulator significantly improved wheelchair positioning skills. Higher performance gains could be achieved by providing task-specific feedback.","2331-9569","978-1-7281-1285-5","10.1109/ICVR46560.2019.8994644","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994644","power wheelchair;simulator;performance;learning;transfer","","computer simulation;feedback;handicapped aids;virtual reality;wheelchairs","no-feedback group;wheelchair positioning abilities;virtual reality simulator;task-specific feedback;wheelchair activity;augmented feedback group;wheelchair positioning skills;wheelchair driving performance","","","","8","","13 Feb 2020","","","IEEE","IEEE Conferences"
"Conditions that Facilitate Transfer of Learning in Virtual Environment","C. Bossard; G. Kermarrec","European Center for virtual reality, BP 38, F-29280 Plouzané, France, Tel: 02 98 05 89 89 ; fax: 02 98 05 89 79. E-mail: bossard@enib.fr; LISyC, Eur. Center for Virtual Reality, Plouzane","2006 2nd International Conference on Information & Communication Technologies","16 Oct 2006","2006","1","","604","609","The aim of all education is to apply what we learn in different contexts, to recognize and to extend such learning to new situations. Particularly, virtual environments for learning are used to construct competences. Researches in cognitive psychology and education show acquisitions as linked to initial context. It provides a challenge for virtual reality in education or training. This paper discusses how new perspectives in cognitive psychology influence and promote conditions that facilitate transfer of learning by the use of virtual environment","","0-7803-9521-2","10.1109/ICTTA.2006.1684440","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1684440","","Virtual environment;Psychology;Management training;Virtual reality;Computer science education;Employment;Knowledge management;Computer simulation;Mathematics;Problem-solving","computer aided instruction;psychology;virtual reality","learning transfer;virtual reality;education;training;cognitive psychology","","1","","36","","16 Oct 2006","","","IEEE","IEEE Conferences"
"Transfer Learning of Air Combat Behavior","A. Toubman; J. J. Roessingh; P. Spronck; A. Plaat; J. Van Den Herik","Dept. of Training, Simulation, & Operator Performance, Netherlands Aerosp. Centre NLR, Amsterdam, Netherlands; Dept. of Training, Simulation, & Operator Performance, Netherlands Aerosp. Centre NLR, Amsterdam, Netherlands; Tilburg center for Cognition & Commun., Tilburg Univ., Tilburg, Netherlands; Leiden Inst. of Adv. Comput. Sci., Leiden Univ., Leiden, Netherlands; Leiden Inst. of Adv. Comput. Sci., Leids Universitair Medisch Centrum, Leiden, Netherlands","2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)","3 Mar 2016","2015","","","226","231","Machine learning techniques can help to automatically generate behavior for computer generated forces inhabiting air combat training simulations. However, as the complexity of scenarios increases, so does the time to learn optimal behavior. Transfer learning has the potential to significantly shorten the learning time between domains that are sufficiently similar. In this paper, we transfer air combat agents with experience fighting in 2-versus-1 scenarios to various 2-versus-2 scenarios. The performance of the transferred agents is compared to that of agents that learn from scratch in the 2v2 scenarios. The experiments show that the experience gained in the 2v1 scenarios is very beneficial in the plain 2v2 scenarios, where further learning is minimal. In difficult 2v2 scenarios transfer also occurs, and further learning ensues. The results pave the way for fast generation of behavior rules for air combat agents for new, complex scenarios using existing behavior models.","","978-1-5090-0287-0","10.1109/ICMLA.2015.61","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7424313","reinforcement learning;transfer learning;air combat;training simulations;computer generated forces","Atmospheric modeling;Lead;Learning (artificial intelligence);Missiles;Training;Computational modeling;Adaptation models","aerospace computing;aerospace simulation;digital simulation;learning (artificial intelligence);military aircraft;military computing;multi-agent systems","transfer learning;air combat behavior;machine learning techniques;computer generated forces;air combat training simulations;2-versus-1 air combat scenarios;2-versus-2 air combat scenarios;air combat agents","","3","","16","","3 Mar 2016","","","IEEE","IEEE Conferences"
"A visual/haptic interface to virtual environment (WYSIWYF display) and its application","Y. Yokokohji","Dept. of Mech. Eng., Kyoto Univ., Japan","Proceedings 1998 IEEE and ATR Workshop on Computer Vision for Virtual Reality Based Human Communications","6 Aug 2002","1998","","","99","104","VR training or skill transfer via virtual environment is a kind of human communication from one (expert) to others (trainee). To build a VR training system for visuo-motor skills, a visual interface should be correctly registered to a haptic interface so that the visual sensation and the haptic sensation are consistent spatially and temporally. Ideally a visual/haptic interface should be configured in such a way that what you see is what you feel as it is in the real life situations. In this paper, a reasonable method to realize correct visual/haptic registration is introduced. This method provides correct visual/haptic registration using a vision-based object tracking technique and a video keying technique. The first prototype called WYSIWYF Display has been built and the proposed concept was demonstrated. The paper then discusses a potential application to VR training using the WYSIWYF Display.","","0-8186-8283-3","10.1109/CVVRHC.1998.660376","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=660376","","Haptic interfaces;Virtual environment;Displays;Cameras;Rendering (computer graphics)","virtual reality;graphical user interfaces","visual/haptic interface;virtual environment;WYSIWYF display;virtual reality;visuo-motor skills;visual interface;video keying technique","","2","","19","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Haptic-enabled driving training system","R. H. Osgouei; H. Lee; S. Choi","Haptics and Virtual Reality Laboratory (HVRLab), Department of Computer Science and Engineering, Pohang University of Science and Technology (POSTECH), Gyungbuk, 790-784, Republic of Korea; Haptics and Virtual Reality Laboratory (HVRLab), Department of Computer Science and Engineering, Pohang University of Science and Technology (POSTECH), Gyungbuk, 790-784, Republic of Korea; Haptics and Virtual Reality Laboratory (HVRLab), Department of Computer Science and Engineering, Pohang University of Science and Technology (POSTECH), Gyungbuk, 790-784, Republic of Korea","2013 IEEE RO-MAN","15 Oct 2013","2013","","","302","303","The objective of the current work is a driving training system to capture and transfer skills from the expert to the novice drivers. The emphasis is on the haptic feedback applied on the steering wheel and the accelerator pedal to improve trainee's performance. For capturing skills, driving signals of an expert driver, performing a given task using a developed driving simulator, are recorded as reference trajectories. For transferring, two different methods are considered: guidance to assist and disturbance to distract following the reference. For evaluation, two performance measures are assumed: trajectory-based and model-based. They are used not only to evaluate the progress of the trainee but also to tune the gain of controllers delivering haptic feedback.","1944-9437","978-1-4799-0509-6","10.1109/ROMAN.2013.6628494","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6628494","","Haptic interfaces;Training;Hidden Markov models;Vehicles;Wheels;Torque;Trajectory","computer based training;digital simulation;haptic interfaces;steering systems;wheels","haptic-enabled driving training system;skill transfer;novice drivers;haptic feedback;steering wheel;accelerator pedal;skill capturing;driving signals;expert driver;driving simulator;reference trajectories;guidance method;disturbance method;trajectory-based performance measure;model-based performance measure;trainee performance;controller gain","","","1","9","","15 Oct 2013","","","IEEE","IEEE Conferences"
"Training Assistant for LACT Process Through Augmented Reality","Y. Y. Montoya; C. G. Pillajo; J. S. Ortiz","Universidad Politécnica Salesiana,Quito,Ecuador; Universidad Politécnica Salesiana,Quito,Ecuador; Universidad de las Fuerzas Armadas ESPE,Sangolquí,Ecuador","2020 15th Iberian Conference on Information Systems and Technologies (CISTI)","15 Jul 2020","2020","","","1","6","This article proposes the development of a 3D augmented reality app for mobile devices focused on staff training (training of operators) in the oil industry on the operation of Lease Automatic Custody Transfer Units (LACT Units). First, existing information about LACT Units was collected to define the basic and specific parameters for the virtual creation of a 3D model of the LACT Units (CAD files) which allows the visualization of the equipment and instruments commonly used in the LACT Units, also through the Unity 3D graphic engine a specific sequence of operation is defined attached to a real system. The application focuses on the recognition of P&ID through a smartphone allowing users to make changes in the variables involved in the process, e.g., pressure, temperature and flow, such that, if the user makes any changes to the variables, the system responds according to these changes based on mathematical models of the plant, achieving a more realistic experience between the user and the process.","2166-0727","978-989-54659-0-3","10.23919/CISTI49556.2020.9141081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141081","Augmented Reality;LACT Unit;P & ID;Unity 3D","Three-dimensional displays;Oils;Training;Animation;Solid modeling;Augmented reality;Hydrocarbons","augmented reality;computer based training;continuing professional development;data visualisation;industrial training;mobile computing;personnel;petroleum industry;production engineering computing;production equipment;smart phones;solid modelling","Unity 3D graphic engine;training assistant;LACT process;staff training;lease automatic custody transfer units;LACT units;3D augmented reality app;mobile devices;oil industry;3D model;CAD files;equipment visualization;smartphone","","","","16","","15 Jul 2020","","","IEEE","IEEE Conferences"
"Developing an CNC lathe augmented reality application for industrial maintanance training","O. Güler; I. Yücedağ","Electrical-Electronic and Computer Engineering, Duzce University, Duzce, Turkey; Computer Engineering, Duzce University, Duzce, Turkey","2018 2nd International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT)","9 Dec 2018","2018","","","1","6","In this study, developing an augmented reality training application for CNC (computer numerical control) lathe looms for industrial maintenance and repair training was described. The content has been developed for the CNC LATHE TEARS module, which is trained in the field of Machine Technologies to be operated on mobile like smart phone, tablet, etc. devices. First a training scenario was prepared for the development of the application. Then three dimensional model of a CNC lathe was modelled. Models designed to develop the augmented reality application have been transferred to the Unity3D game engine software, and using the Vuforia plug-in, a marker-based augmented reality application has been developed to work on android operating system based mobile devices like smartphone, tablet, etc. It is considered that using the developed application in the training of the students of the Machine Technologies Area in the institutions providing vocational and technical education in the official and private institutions affiliated to the Ministry of National Education, motivation of the students and the success rates of the courses will increase. At the same time, the developed application will provide facilitate the training of the users, increase the quality in production and faster maintenance and installation.","","978-1-5386-4184-2","10.1109/ISMSIT.2018.8567255","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8567255","augmented reality;CNC Lathe;mobile software;interactive system","Training;Maintenance engineering;Software;Augmented reality;Cameras;Computer numerical control","augmented reality;computer based training;computerised numerical control;maintenance engineering;mobile computing;production engineering computing;smart phones","industrial maintanance training;augmented reality training application;computer numerical control;industrial maintenance;repair training;CNC LATHE TEARS module;Unity3D game engine software;marker-based augmented reality application;mobile devices;Android operating system;machine technologies area","","","","22","","9 Dec 2018","","","IEEE","IEEE Conferences"
"Interactive 3D virtual environments for industrial operation training and maintenance","J. El-Chaar; C. R. Boer; P. Pedrazzoli; S. Mazzola; G. D. Maso","University of Applied Sciences of Southern Switzerland - Institute CIM for Sustainable Innovation, SUPSI - ICIMSI, Manno, Switzerland; University of Applied Sciences of Southern Switzerland - Institute CIM for Sustainable Innovation, SUPSI - ICIMSI, Manno, Switzerland; University of Applied Sciences of Southern Switzerland - Institute CIM for Sustainable Innovation, SUPSI - ICIMSI, Manno, Switzerland; Technology Transfer System s.r.l., Milan, Italy; Technology Transfer System s.r.l., Milan, Italy","The Proceedings of 2011 9th International Conference on Reliability, Maintainability and Safety","11 Aug 2011","2011","","","1376","1381","Interactive 3D virtual environments provide an enabling circumstances for innovation and evolution in education system, training, maintenance and repair operations of industrial plants. In fact, technique like complete 3D simulation of products processes and manufacturing facilities promotes a new approach to technical documentation and assistance, where the user can be easily guided even through the most complex and critical operations. This work introduces the main characteristics of the Virtual Environments in contexts of education-centred and training-centred. Also, it presents the work done in relation to the design and implementation of a SW platform integrating the very latest in 3D modeling, 3D animation and simulation, and human-machine interface technologies. The platform finds a vast number of applications: industrial system design, assembling, operation, training and maintenance. The study also reveals how virtualization of the maintenance environment allows off-site collaborators to monitor and assist with repairs.","","978-1-61284-666-8","10.1109/ICRMS.2011.5979485","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5979485","Virtual Reality;3-D Modelling;Simulation;Virtual Environment;Training;Maintenance;Remote Maintenance","Training;Three dimensional displays;Maintenance engineering;Animation;Virtual environments;Libraries","computer based training;interactive systems;maintenance engineering;production engineering computing;virtual reality","interactive 3D virtual environments;industrial operation training;industrial operation maintenance;education system;industrial plants;manufacturing facilities;technical documentation;3D animation;3D simulation;3D modeling;human-machine interface;industrial system design","","8","","12","","11 Aug 2011","","","IEEE","IEEE Conferences"
"Cellular automata simulation on FPGA for training neural networks with virtual world imagery","O. Van Acker; O. Lachish; G. Burnett","Department of Computer Science and Information Systems, Birkbeck, University of London, London, United Kingdom; Department of Computer Science and Information Systems, Birkbeck, University of London, London, United Kingdom; Enhyper Ltd., London, United Kingdom","2017 IEEE Conference on Computational Intelligence and Games (CIG)","26 Oct 2017","2017","","","304","305","We present ongoing work on a tool that consists of two parts: (i) A raw micro-level abstract world simulator with an interface to (ii) a 3D game engine, translator of raw abstract simulator data to photorealistic graphics. Part (i) implements a dedicated cellular automata (CA) on reconfigurable hardware (FPGA) and part (ii) interfaces with a deep learning framework for training neural networks. The bottleneck of such an architecture usually lies in the fact that transferring the state of the whole CA significantly slows down the simulation. We bypass this by sending only a small subset of the general state, which we call a 'locus of visibility', akin to a torchlight in a darkened 3D space, into the simulation. The torchlight concept exists in many games but these games generally only simulate what is in or near the locus. Our chosen architecture will enable us to simulate on a micro level outside the locus. This will give us the advantage of being able to create a larger and more fine-grained simulation which can be used to train neural networks for use in games.","2325-4289","978-1-5386-3233-8","10.1109/CIG.2017.8080450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8080450","Cellular Automata;FPGA;Simulation;Machine learning;Neural networks;Unreal Engine","Neural networks;Games;Engines;Field programmable gate arrays;Computer architecture;Training;Automata","cellular automata;computer games;computer graphics;digital simulation;field programmable gate arrays;learning (artificial intelligence);virtual reality","cellular automata simulation;FPGA;virtual world imagery;raw microlevel abstract world simulator;raw abstract simulator data;photorealistic graphics;dedicated cellular automata;reconfigurable hardware;deep learning framework;darkened 3D space;fine-grained simulation;neural network training;3D game engine","","","","6","","26 Oct 2017","","","IEEE","IEEE Conferences"
"Evaluating simulator-based training of skill-based control behavior using multimodal operator models","D. M. Pool; G. A. Harder; H. J. Damveld; M. M. van Paassen; M. Mulder","Control & Simulation, Department Control & Operations, Delft University of Technology, The Netherlands; Control & Simulation, Department Control & Operations, Delft University of Technology, The Netherlands; Control & Simulation, Department Control & Operations, Delft University of Technology, The Netherlands; Control & Simulation, Department Control & Operations, Delft University of Technology, The Netherlands; Control & Simulation, Department Control & Operations, Delft University of Technology, The Netherlands","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","4 Dec 2014","2014","","","3132","3137","This paper describes a novel method for analyzing the training effectiveness for skill-based manual control tasks based on multimodal human operator models. For skill-based tracking tasks, it is known that the adopted human operator dynamics can be modeled accurately with multimodal human operator models. In this paper, estimated human operator model parameters are used to explicitly quantify the changes that occur in the operator's use of visual and motion feedback during skill-acquisition and transfer. A quasi-transfer-of-training experiment is described, in which inexperienced participants were trained to perform an aircraft pitch attitude tracking task, either in a fixed-base or in moving-base simulator environment. After the training phase, the participants were transferred to the other simulator setting, to reveal possible transfer effects. Preliminary results from one participant in each experiment group indicate that the fitted models are successful in revealing the changes that occur in the multimodal manual control characteristics of the participants, and show that convergence to a final skill-based control strategy requires significant training. Furthermore, the presented results suggest that there might be limited direct transfer from training in a fixed-base environment to a moving-base environment.","1062-922X","978-1-4799-3840-7","10.1109/SMC.2014.6974409","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974409","","Training;Visualization;Tracking;Dynamics;Human factors;Delays;Atmospheric measurements","aerospace computing;aircraft control;attitude control;computer based training;control engineering computing;digital simulation","simulator-based training;skill-based manual control behavior;multimodal human operator models;skill-based tracking tasks;human operator dynamics;visual feedback;motion feedback;skill-acquisition;quasitransfer-of-training experiment;aircraft pitch attitude tracking task;fixed-base simulator environment;moving-base simulator environment","","2","","13","","4 Dec 2014","","","IEEE","IEEE Conferences"
"VR-OOS: The DLR's virtual reality simulator for telerobotic on-orbit servicing with haptic feedback","M. Sagardia; K. Hertkorn; T. Hulin; S. Schätzle; R. Wolff; J. Hummel; J. Dodiya; A. Gerndt","German Aerospace Center (DLR), Muenchener Str. 20, 82234 Wessling, Germany; German Aerospace Center (DLR), Muenchener Str. 20, 82234 Wessling, Germany; German Aerospace Center (DLR), Muenchener Str. 20, 82234 Wessling, Germany; German Aerospace Center (DLR), Muenchener Str. 20, 82234 Wessling, Germany; German Aerospace Center (DLR), Lilienthalplatz 7, 38108 Braunschweig, Germany; German Aerospace Center (DLR), Lilienthalplatz 7, 38108 Braunschweig, Germany; German Aerospace Center (DLR), Lilienthalplatz 7, 38108 Braunschweig, Germany; German Aerospace Center (DLR), Lilienthalplatz 7, 38108 Braunschweig, Germany","2015 IEEE Aerospace Conference","8 Jun 2015","2015","","","1","17","The growth of space debris is becoming a severe issue that urgently requires mitigation measures based on maintenance, repair, and de-orbiting technologies. Such on-orbit servicing (OOS) missions, however, are delicate and expensive. Virtual Reality (VR) enables the simulation and training in a flexible and safe environment, and hence has the potential to drastically reduce costs and time, while increasing the success rate of future OOS missions. This paper presents a highly immersive VR system with which satellite maintenance procedures can be simulated interactively using visual and haptic feedback. The system can be used for verification and training purposes for human and robot systems interacting in space. Our framework combines unique realistic virtual reality simulation engines with advanced immersive interaction devices. The DLR bimanual haptic device HUG is used as the main user interface. The HUG is equipped with two light-weight robot arms and is able to provide realistic haptic feedback on both human arms. Additional devices provide vibrotactile and electrotactile feedback at the elbow and the fingertips. A particularity of the realtime simulation is the fusion of the Bullet physics engine with our haptic rendering algorithm, which is an enhanced version of the Voxmap-Pointshell Algorithm. Our haptic rendering engine supports multiple objects in the scene and is able to compute collisions for each of them within 1 msec, enabling realistic virtual manipulation tasks even for stiff collision configurations. The visualization engine ViSTA is used during the simulation to achieve photo-realistic effects, increasing the immersion. In order to provide a realistic experience at interactive frame rates, we developed a distributed system architecture, where the load of computing the physics simulation, haptic feedback and visualization of a complex scene is transferred to dedicated machines. The implementations are presented in detail and the performance of the overall system is validated. Additionally, a preliminary user study in which the virtual system is compared to a physical test bed shows the suitability of the VR-OOS framework.","1095-323X","978-1-4799-5380-6","10.1109/AERO.2015.7119040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7119040","","Computational modeling;Force;Haptic interfaces;Robots;Satellites;Solid modeling;Space vehicles","aerospace computing;aerospace robotics;aerospace safety;haptic interfaces;realistic images;real-time systems;rendering (computer graphics);space debris;telerobotics;virtual reality","DLR virtual reality simulator;telerobotic on-orbit servicing missions;space debris;mitigation measures;repair;de-orbiting technologies;OOS missions;immersive VR system;satellite maintenance procedures;visual feedback;robot systems;realistic virtual reality simulation engines;immersive interaction devices;DLR bimanual haptic device HUG;user interface;robot arms;realistic haptic feedback;vibrotactile feedback;electrotactile feedback;realtime simulation;Bullet physics engine;haptic rendering algorithm;Voxmap-Pointshell algorithm;haptic rendering engine;realistic virtual manipulation tasks;stiff collision configurations;visualization engine ViSTA;photo-realistic effects;realistic experience;interactive frame rates;distributed system architecture;physics simulation;complex scene;virtual system;VR-OOS framework","","9","1","43","","8 Jun 2015","","","IEEE","IEEE Conferences"
"An Object State Estimation for the Peg Transfer Task in Computer-Guided Surgical Training","K. Meisner; M. Hong; J. W. Rozenblit","Universität der Bundeswehr,Department of Computer Science,Neubiberg,Germany,85579; University of Arizona,Department of Electrical and Computer Engineering,Tucson,AZ,USA; University of Arizona,Department of Electrical and Computer Engineering,Tucson,AZ,USA","2020 Spring Simulation Conference (SpringSim)","3 Sep 2020","2020","","","1","12","Computer-based simulators have been developed to enhance training experiences in laparoscopic surgical skills training. Most simulators can evaluate a trainee's performance objectively. However, only few simulators can provide active guidance features such as audio and visual guidance. In this paper, an object state estimation and tracking method is presented to support visual and force guidance for computer-assisted surgical trainer (CAST) using image processing schemes in real-time fashion given a specific object transfer task. The experimental results show that the proposed tracking method reaches 100 frame per seconds and estimates an object state effectively for the standard laparoscopy peg transfer task.","","978-1-56555-370-5","10.22360/SpringSim.2020.MSM.004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9185423","simulation-based surgical training;object recognition;object state detection","Image color analysis;Training;Instruments;Task analysis;Surgery;Image segmentation;State estimation","biomedical education;computer based training;medical computing;medical robotics;surgery","object state estimation;computer-guided surgical training;computer-based simulators;training experiences;laparoscopic surgical skills training;trainee;active guidance features;audio guidance;visual guidance;tracking method;force guidance;computer-assisted surgical trainer;specific object transfer task;standard laparoscopy peg transfer task","","","","25","","3 Sep 2020","","","IEEE","IEEE Conferences"
"Enhancing A Laparoscopy Training System with Augmented Reality Visualization","H. Jiang; S. Xu; A. State; F. Feng; H. Fuchs; M. Hong; J. Rozenblit","Department of Computer Science, University of North Carolina, Chapel Hill, NC, USA; Department of Computer Science, University of North Carolina, Chapel Hill, NC, USA; Department of Computer Science, University of North Carolina, Chapel Hill, NC, USA; Department of Computer Science, University of North Carolina, Chapel Hill, NC, USA; Department of Computer Science, University of North Carolina, Chapel Hill, NC, USA; Dept. of Electrical and Computer Engineering, University of Arizona, Tucson, AZ, USA; Dept. of Electrical and Computer Engineering, University of Arizona, Tucson, AZ, USA","2019 Spring Simulation Conference (SpringSim)","10 Jun 2019","2019","","","1","12","We report work in progress towards a system for laparoscopy training that is enhanced with an augmented reality display. The system can be used to perform peg-transfer training tasks using a Microsoft Hololens AR device, with full 6 degrees of freedom (DoF) shared presence with the pegboard workspace. This mode is in contrast to the conventional visualization, whose views are solely through a 2D or stereo laparoscope. In order to achieve this enhanced visualization, the system extracts the pose of the triangular prism being manipulated, and of the laparoscopic instruments with which the user manipulates the prism. These two objects are added to a CAD model of a (fixed) pegboard, and all the objects are visualized within the AR display. In the near future we expect to conduct user studies measuring accuracy and time-to-completion of this peg-transfer task using these new enhancements and compare it to conventional visualization techniques.","","978-1-5108-8388-8","10.23919/SpringSim.2019.8732876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8732876","laparoscopic;augmented reality;visualization","Laparoscopes;Training;Visualization;Three-dimensional displays;Cameras;Minimally invasive surgery","augmented reality;biomedical education;CAD;computer based training;data visualisation;feature extraction;medical computing;pose estimation;stereo image processing;surgery","laparoscopy training system;augmented reality visualization;peg-transfer training tasks;Microsoft Hololens AR device;CAD model;laparoscopic surgery;laparoscopic trainer system;3D visualization;triangular prism pose estimation","","1","","34","","10 Jun 2019","","","IEEE","IEEE Conferences"
"Flexible transfer syntax for interoperable training networks","M. Bassiouni; M. Loper","Dept. of Comput. Sci., Central Florida Univ., Orlando, FL, USA; NA","Proceedings of MILCOM '94","6 Aug 2002","1994","","","205","209 vol.1","Abstract/transfer syntaxes are used in the presentation layer of OSI communication networks to achieve data interoperability among heterogeneous nodes. We discuss the problems of using ASN.1 in the distributed interactive simulation (DIS) environment and present an approach for a modified transfer syntax that allows for the flexible decoding of transmitted protocol data units (PDUs) at the receiving host.<>","","0-7803-1828-5","10.1109/MILCOM.1994.473942","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=473942","","Computational modeling;Encoding;Decoding;Bit error rate;Peer to peer computing;Computer simulation;Communication networks;Protocols;ISO standards;Proposals","open systems;abstract data types;protocols;digital simulation;simulation;distributed processing;interactive systems;decoding;internetworking;training","flexible transfer syntax;interoperable training networks;OSI communication networks;presentation layer;heterogeneous nodes;ASN.1;distributed interactive simulation environment;modified transfer syntax;flexible decoding;transmitted PDU;receiving host;abstract syntaxes;computer communications","","","1","9","","6 Aug 2002","","","IEEE","IEEE Conferences"
"A virtual environment for learning to pilot remotely operated vehicles","N. J. Pioch; B. Roberts; D. Zeltzer","BBN Corp., Cambridge, MA, USA; NA; NA","Proceedings. International Conference on Virtual Systems and MultiMedia VSMM '97 (Cat. No.97TB100182)","6 Aug 2002","1997","","","218","226","Remotely operated vehicles (ROVs) are used extensively for underwater searching and salvage, inspection, surveying, scientific exploration and mine countermeasures. ROV pilots must learn to rely on limited data from video and sonar displays and a few other positional indicators to maintain a sense of their vehicle, its tether and its surroundings. Pilot training typically occurs on-the-job, where equipment is placed at risk, controlled learning situations are hard to create, and time for instruction is minimal. The TRANSoM (TRAiNing for remote Sensing and Manipulation) project is developing a training environment that combines two emerging technologies to overcome these limitations. A virtual environment (VE) simulates the ROV and its surroundings, and also has instructional enhancements such as external views of the ROV, directional cues and alternate modes of interaction with the vehicle, e.g. a head-tracked head-mounted display (HMD). An intelligent tutoring system (ITS) monitors student pilot behavior and offers verbal and graphical feedback, a mission review and a performance assessment. Near-transfer experiments comparing the utility of different artificial viewpoints have been completed, with full transfer experiments involving a real ROV to follow.","","0-8186-8150-0","10.1109/VSMM.1997.622350","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=622350","","Virtual environment;Remotely operated vehicles;Inspection;Sonar equipment;On the job training;Remote sensing;Intelligent systems;Artificial intelligence;Computer displays;Feedback","marine systems;virtual reality;intelligent tutoring systems;telecontrol;computer based training;control engineering computing","virtual environment;remotely operated vehicle simulation;pilot training;underwater vehicles;video displays;sonar displays;positional indicators;TRANSoM project;remote sensing;remote manipulation;instructional enhancements;external views;directional cues;interaction modes;head-tracked head-mounted display;intelligent tutoring system;student pilot behavior monitoring;verbal feedback;graphical feedback;mission review;performance assessment;near-transfer experiments;artificial viewpoints","","5","","15","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Phantom-based multimodal interactions for medical education and training: the Munich knee joint simulator","R. Riener; M. Frey; T. Proll; F. Regenfelder; R. Burgkart","Autom. Control Lab., Swiss Fed. Inst. of Technol., Zurich, Switzerland; NA; NA; NA; NA","IEEE Transactions on Information Technology in Biomedicine","7 Jun 2004","2004","8","2","208","216","Simulation environments based on virtual reality technologies can support medical education and training. In this paper, the novel approach of an ""interactive phantom"" is presented that allows a realistic display of haptic contact information typically generated when touching and moving human organs or segments. The key idea of the haptic interface is to attach passive phantom objects to a mechanical actuator. The phantoms look and feel as real anatomical objects. Additional visualization of internal anatomical and physiological information and sound generated during the interaction with the phantom yield a multimodal approach that can increase performance, didactic value, and immersion into the virtual environment. Compared to classical approaches, this multimodal display is convenient to use, provides realistic tactile properties, and can be partly adjusted to different, e.g., pathological properties. The interactive phantom is exemplified by a virtual human knee joint that can support orthopedic education, especially for the training of clinical knee joint evaluation. It is suggested that the technical principle can be transferred to many other fields of medical education and training such as obstetrics and dentistry.","1558-0032","","10.1109/TITB.2004.828885","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1303564","","Knee;Medical simulation;Imaging phantoms;Displays;Haptic interfaces;Humans;Virtual reality;Educational technology;Actuators;Visualization","bone;orthopaedics;dentistry;biomedical education;training;phantoms;haptic interfaces;biomechanics;virtual reality;display devices;actuators;medical robotics;digital simulation;computer animation","phantom-based multimodal interaction;medical education;medical training;Munich knee joint simulator;virtual reality technologies;VR;haptic contact information;mechanical actuator;internal anatomical information;physiological information;multimodal sound approach;didactic value;realistic tactile properties;pathological properties;virtual human knee joint;orthopedic education;clinical knee joint evaluation;obstetrics;dentistry;acoustic display;animation;biomechanics;graphical display;multimodal display;robotics","Computer Graphics;Computer Simulation;Education, Medical;Environment;Germany;Humans;Knee Joint;Models, Anatomic;Models, Biological;Online Systems;Phantoms, Imaging;Robotics;Robotics;Teaching;User-Computer Interface","21","","33","","7 Jun 2004","","","IEEE","IEEE Journals"
"An introduction to Augmented Reality with applications in aeronautical maintenance","M. Hincapié; A. Caponio; H. Rios; E. González Mendívil","Instituto Tecnològico y de Estudios Superiores de Monterrey, Nuevo Leòn, Mexìco; Instituto Tecnològico y de Estudios Superiores de Monterrey, Nuevo Leòn, Mexìco; Instituto Tecnològico y de Estudios Superiores de Monterrey, Nuevo Leòn, Mexìco; Instituto Tecnològico y de Estudios Superiores de Monterrey, Nuevo Leòn, Mexìco","2011 13th International Conference on Transparent Optical Networks","1 Aug 2011","2011","","","1","4","Augmented Reality is a breakthrough technology that could considerably ease execution of complex operations. Augmented Reality mixes virtual and actual reality, making available to the user new tools to ensure efficiency in the transfer of knowledge for several processes and in several environments. Various solutions based on Augmented Reality have been proposed by the research community: particularly in maintenance operations Augmented Reality tools have offered new perspectives and have promised dramatic improvements. On the other side Augmented Reality is an extremely demanding technology and, at the present day, it is still affected by serious flaws that undermine its implementations in the industrial context. This paper presents examples of Augmented Reality applications and shows the feasibility of Augmented Reality solutions in maintenance tasks, underlining advantages it could introduce. At the same time the principal flaws of Augmented Reality are commented and possible lines of investigation are suggested.","2161-2064","978-1-4577-0882-4","10.1109/ICTON.2011.5970856","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5970856","Augmented Reality;Maintenance operations","Maintenance engineering;Augmented reality;Hardware;Training;Manufacturing;Cameras;Industries","aerospace computing;aircraft maintenance;augmented reality","augmented reality;aeronautical maintenance;virtual reality;actual reality","","30","1","14","","1 Aug 2011","","","IEEE","IEEE Conferences"
"Keyboard control method for virtual reality micro-robotic cell injection training","S. Faroque; B. Horan; M. Joordens","School of Engineering, Deakin University Geelong, VIC, Australia; School of Engineering, Deakin University Geelong, VIC, Australia; School of Engineering, Deakin University Geelong, VIC, Australia","2015 10th System of Systems Engineering Conference (SoSE)","9 Jul 2015","2015","","","416","421","The rapid development of virtual reality offers significant potential for skills training applications. Our ongoing work proposes virtual reality operator training for the micro-robotic cell injection procedure. The interface between the operator and the system can be achieved in many different ways. The computer keyboard is ubiquitous in its use for everyday computing applications and also commonly utilized in virtual reality systems. Based on the premise that most people have experience in using a computer keyboard, as opposed to more sophisticated input devices, this paper considers the feasibility of using a keyboard to control the micro-robot for cell injection. In this study, thirteen participants underwent the experimental evaluation. The participants were asked to perform three simulated trial sessions in a virtual micro-robotic cell injection environment. Each session consisted of ten cell injection trials and relevant data for each trial were recorded and analyzed. Results showed participants' performance improvement after the three sessions. It was also observed that participants intuitively controlled multiple axes of the micro-robot simultaneously despite the absence of instruction on how to do so. This continued throughout the experiments and suggests skills transfer from other keyboard based interactions. Based on the results provided, it is suggested that keyboard control is a feasible, simple and low-cost control method for the virtual micro-robot.","","978-1-4799-7611-9","10.1109/SYSOSE.2015.7151946","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7151946","Cell injection;virtual reality;micromanipulation;micro-robot;skills training","Keyboards;Haptic interfaces;Training;Systems engineering and theory;Computers;Virtual environments","biomedical education;cellular biophysics;computer based training;keyboards;microrobots;virtual reality","keyboard control method;virtual reality microrobotic cell injection training;skill training applications;virtual reality operator training;microrobotic cell injection procedure;ubiquitous computer keyboard;input devices;keyboard based interactions;low-cost control method","","1","","15","","9 Jul 2015","","","IEEE","IEEE Conferences"
"Simulation and applications of the ship central cooling system in DMS2016 marine engineering simulator","S. Changjian; S. Jianbo","Marine Engineering college, Dalian Maritime University, Dalian, 116026, China; Marine Engineering college, Dalian Maritime University, Dalian, 116026, China","2017 36th Chinese Control Conference (CCC)","11 Sep 2017","2017","","","10495","10498","Based on the analysis of the structure and mechanism of the ship cooling water system and the modular modeling method, the mathematical model of the cooling water system suitable for real-time simulation calculation is established, and the pipe network calculation is used to obtain the flow and each pipe's node pressure. The simulation data of the ship cooling water system are obtained by using Visual C ++ programming software, and the accuracy of the mathematical model is verified by comparing the simulation data with real ship data. The mathematical model can be used to describe the flow distribution, pressure variation and heat transfer in the ship cooling water system. The distributed visual simulation system interface developed by object-oriented technology is used to realize the dynamic operation of the cooling water system and ensure the simulation accuracy. The system has been successfully applied to DMS2016 large-scale marine engine simulator, and used in the crew teaching and training, and achieved significant results.","1934-1768","978-988-15639-3-4","10.23919/ChiCC.2017.8029029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8029029","Ship central cooling system;mathematical model;simulator;crew training","","cooling;digital simulation;heat transfer;marine engineering;object-oriented methods;pipes;ships;visual programming","mathematical model;simulation data;distributed visual simulation system interface;cooling water system;simulation accuracy;DMS2016 large-scale marine engine simulator;ship central cooling system;DMS2016 marine engineering simulator;modular modeling method;real-time simulation calculation;pipe network calculation;pipe node pressure;real ship data;Visual C ++ programming software;flow distribution;pressure variation;heat transfer;object-oriented technology;crew teaching;crew training","","","","6","","11 Sep 2017","","","IEEE","IEEE Conferences"
"Mixed reality in education, entertainment, and training","C. E. Hughes; C. B. Stapleton; D. E. Hughes; E. M. Smith","Univ. of Central Florida, Orlando, FL, USA; Univ. of Central Florida, Orlando, FL, USA; Univ. of Central Florida, Orlando, FL, USA; Univ. of Central Florida, Orlando, FL, USA","IEEE Computer Graphics and Applications","7 Nov 2005","2005","25","6","24","30","Transferring research from the laboratory to mainstream applications requires the convergence of people, knowledge, and conventions from divergent disciplines. Solutions involve more than combining functional requirements and creative novelty. To transform technical capabilities of emerging mixed reality (MR) technology into the mainstream involves the integration and evolution of unproven systems. For example, real-world applications require complex scenarios (a content issue) involving an efficient iterative pipeline (a production issue) and driving the design of a story engine (a technical issue) that provides an adaptive experience with an after-action review process (a business issue). This article describes how a multi-disciplinary research team transformed core MR technology and methods into diverse urban terrain applications. These applications are used for military training and situational awareness, as well as for community learning to significantly increase the entertainment, educational, and satisfaction levels of existing experiences in public venues.","1558-1756","","10.1109/MCG.2005.139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1528429","mixed reality;augmented reality;augmented virtuality;scripting;multisensory;multimodal","Virtual reality;Auditory displays;Space technology;Computer displays;Computer science education;Portals;Haptic interfaces;Marine animals;Oceans;Augmented reality","augmented reality;educational computing;entertainment;military computing","mixed reality;education;entertainment;military training;MR technology;urban terrain applications;community learning","Computer Graphics;Computer Simulation;Computer-Assisted Instruction;Education;Models, Theoretical;Multimedia;Recreation;Systems Integration;Teaching;User-Computer Interface","105","","12","","7 Nov 2005","","","IEEE","IEEE Magazines"
"Region-Specific Automated Feedback in Temporal Bone Surgery Simulation","S. Wijewickrema; I. Ioannou; Y. Zhou; P. Piromchai; J. Bailey; G. Kennedy; S. O'Leary","Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Comput. & Inf. Syst., Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Comput. & Inf. Syst., Univ. of Melbourne, Melbourne, VIC, Australia; Centre for the Study of Higher Educ., Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia","2015 IEEE 28th International Symposium on Computer-Based Medical Systems","27 Jul 2015","2015","","","310","315","The use of virtual reality simulators for surgical training has gained popularity in recent years, with an ever increasing body of evidence supporting the benefits and validity of simulation-based training. However, a crucial component of effective skill acquisition has not been adequately addressed, namely the provision of timely performance feedback. The utility of a surgical simulator is limited if it still requires the presence of experts to guide trainees. Automated feedback that emulates the advise provided by experts is necessary to facilitate independent learning. We propose an automated system that provides region-specific feedback on surgical technique within a temporal bone surgery simulator. The design of this system allows easy transfer of feedback models to multiple temporal bone specimens in the simulator. The system was validated by an expert otologist and was found to provide highly accurate and timely feedback.","2372-9198","978-1-4673-6775-2","10.1109/CBMS.2015.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7167506","Automated Feedback in Surgery Simulation;Simulation-Based Surgical Training;Virtual Reality Temporal Bone Surgery","Surgery;Bones;Measurement;Accuracy;Solid modeling;Force;Anatomical structure","biomedical education;bone;computer based training;ear;educational aids;feedback;medical computing;surgery;teaching;virtual reality","region-specific automated surgical feedback;temporal bone surgery simulation;virtual reality simulator;surgical training;simulation-based training;effective skill acquisition;timely performance feedback;surgical simulator utility limitation;independent learning facilitation;temporal bone surgery simulator design;feedback model transfer;temporal bone specimen;system validation;otology","","4","","14","","27 Jul 2015","","","IEEE","IEEE Conferences"
"Effectiveness of Virtual Versus Physical Training: The Case of Assembly Tasks, Trainer's Verbal Assistance, and Task Complexity","K. Koumaditis; F. Chinello; P. Mitkidis; S. Karg",Aarhus University; Aarhus University; Aarhus University; Aarhus University,"IEEE Computer Graphics and Applications","24 Aug 2020","2020","40","5","41","56","Virtual immersive training (VIT) systems based on gamification of tasks are increasingly employed to train assembly workers. In this article, we present a study that compares the effectiveness of virtual and physical training for teaching a bimanual assembly task and in a novel approach, we introduce task complexity (TCXB) as an indicator of assembly errors during final assembly. In a between-subjects experiment, 100 participants were trained to assemble a 3-D cube in one of the four conditions (physical, virtual and with trainer's verbal assistance or not). The results demonstrate that the best-performing conditions, both in terms of successful assemblies and time performance, are the ones that the physical objects are included in the training, whereas no significant difference is found when the trainer's verbal assistance is present or absent during training. Additionally, we address the validity of a practical TCXB CXB list as a tool for supporting the design of VIT systems.","1558-1756","","10.1109/MCG.2020.3006330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9130859","learning transfer;virtual reality;assembly;task complexity;training","Training;Task analysis;Complexity theory;Animation;Testing;Software tools;Virtual environments","assembling;computer based training;industrial training;personnel;teaching;virtual reality","VIT systems;physical training;task complexity;virtual immersive training systems;assembly workers;bimanual assembly task;TCXB CXB list;trainer verbal assistance;teaching process","","","","20","IEEE","1 Jul 2020","","","IEEE","IEEE Magazines"
"IMA-VR: A multimodal virtual training system for skills transfer in Industrial Maintenance and Assembly tasks","T. Gutiérrez; J. Rodríguez; Y. Vélaz; S. Casado; A. Suescun; E. J. Sánchez","LABEIN-TECNALIA, Spain; Department of Applied Mechanics, CEIT and TECNUN, Spain; Department of Applied Mechanics, CEIT and TECNUN, Spain; LABEIN-TECNALIA, Spain; Department of Applied Mechanics, CEIT and TECNUN, Spain; Department of Applied Mechanics, CEIT and TECNUN, Spain","19th International Symposium in Robot and Human Interactive Communication","11 Oct 2010","2010","","","428","433","Industrial Maintenance and Assembly is a very complex task involving both cognitive skills (procedural skills) and motor skills (fine motor control and bi-manual coordination skills). This paper presents a controlled multimodal training system, for transferring the motor and cognitive skills involved in these tasks. The new platform provides different multimodal aids and learning strategies that help and guide the users during their training process. One of the main features of this system is its flexibility to adapt itself to the task demands and to the users' preferences and needs supporting different configurations. To address bi-manual operations the platform offers different alternatives, one of them is a set-up composed of a haptic device to track the motion of the operator's dominant hand and simulate the physical interaction within the virtual environment, together with a marker-less motion capture system to track the motion of the other hand in real time.","1944-9437","978-1-4244-7990-0","10.1109/ROMAN.2010.5598643","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5598643","","Haptic interfaces;Training;Assembly;Rendering (computer graphics);Visualization;Force;Message systems","assembling;computer based training;haptic interfaces;maintenance engineering;production engineering computing;virtual reality","multimodal virtual training system;skills transfer;industrial maintenance task;industrial assembly task;multimodal aids;learning strategy;haptic device;marker-less motion capture system;IMA-VR training system;virtual reality","","20","","18","","11 Oct 2010","","","IEEE","IEEE Conferences"
"VREX: Virtual reality education expansion could help to improve the class experience (VREX platform and community for VR based education)","L. Ying; Z. Jiong; S. Wei; W. Jingchun; G. Xiaopeng","School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; Dept. for Cyber Online Popularization of Science, Chinese Science and Technology Museum, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China","2017 IEEE Frontiers in Education Conference (FIE)","14 Dec 2017","2017","","","1","5","This paper proposed an innovative education platform-VREX (Virtual Reality based Education eXpansion), with combination of online and offline, to improve the curriculum building and teaching experience. VREX is based on Virtual Reality (VR) and we believe VR can revolutionize the education ecosystem. With some trials, we found VR can be used to promote curriculum effectiveness in an immersive environment so that students can have intuitive sense to understand some abstract knowledge, which is always hard for teachers to describe. We have tried to transfer slides into VR scenes, for the students to learn knowledge in a rather real but totally virtual world. The main contributions were made: (1) VREX build an open and immersion virtual O2O classroom with internet and VR devices so that real classrooms might be used in a different way in the future. (2) VREX provides a distributed mode for students to experience an interactive learning process at anytime, anywhere and any-frequency. (3) VREX can be used to support education in different disciplines, from K-12 to Universities, and we provided some practical cases, like `Marine Life' to show creatures in deep sea, which provides immersive experience to makes students feel they were there. Finally, the feasibility and advantage of VREX are proved by the actual statistical data in the 3rd season 2017.","","978-1-5090-5920-1","10.1109/FIE.2017.8190660","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8190660","Virtual Reality;Immersion;Interaction;Virtual classroom;VR Cloud Platform","Cloud computing;Games;Computer architecture;Hardware;Courseware;Training","computer aided instruction;educational courses;interactive systems;Internet;teaching;virtual reality","immersive experience;virtual reality education expansion;VR based education;innovative education platform-VREX;curriculum building;teaching experience;education ecosystem;VR scenes;immersion virtual O2O classroom;class experience improvement;VREX platform;open virtual O2O classroom;interactive learning process","","5","","10","","14 Dec 2017","","","IEEE","IEEE Conferences"
"Conceptualization of an ICU Infrastructure for Simulation Based Education in Medical Engineering & eHealth","M. Forjan; V. David; M. Wagner; L. Dolesch; M. Lechner; S. Sauermann","Department Life Sciences, University of Applied Sciences Technikum Wien, Vienna, Austria; Department Life Sciences, University of Applied Sciences Technikum Wien, Vienna, Austria; Division of Neonatology, Pediatric Intensive Care and Neuropediatrics, Medical University of Vienna, Vienna, Austria; gsm Gesellschaft für Sicherheit in der Medizintechnik GmbH, Vienna, Austria; gsm Gesellschaft für Sicherheit in der Medizintechnik GmbH, Vienna, Austria; Department Life Sciences, University of Applied Sciences Technikum Wien, Vienna, Austria","2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","7 Oct 2019","2019","","","4186","4189","The use of simulation-based training is gaining importance in medical as well as engineering related education. The complex environment of an intensive care unit is characterized by a high need of interaction between clinical as well as technical components and views. These diverse interactions and the connected requirements are the focus for the presented simulation infrastructure, enabling research, education and training. The presented concept of a modular and flexible intensive care environment provides a high degree of interoperability and flexibility for individual research questions and full support of connectivity for typical clinical workflows. The presented simulation and testing bed will allow both, education for engineering and medical students using patient simulation and simultaneous data transfer as well as research on medical workflows, infrastructural demands and connectivity conformance questions.","1558-4615","978-1-5386-1311-5","10.1109/EMBC.2019.8856949","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8856949","","Training;Solid modeling;Medical devices;Interoperability;Laboratories;Biomedical imaging","biomedical education;computer based training;health care;medical computing;patient care;patient monitoring","medical students;patient simulation;medical workflows;infrastructural demands;connectivity conformance questions;ICU infrastructure;simulation based education;medical engineering;simulation-based training;engineering related education;intensive care unit;diverse interactions;connected requirements;simulation infrastructure;modular care environment;flexible intensive care environment;interoperability;clinical workflows;testing bed;eHealth","Critical Care;Education, Medical;Humans;Intensive Care Units;Patient Simulation;Simulation Training;Telemedicine","","","12","","7 Oct 2019","","","IEEE","IEEE Conferences"
"The Design and Evaluation of a Computerized and Physical Simulator for Training Clinical Prostate Exams","G. J. Gerling; S. Rigsbee; R. M. Childress; M. L. Martin","Dept. of Syst. & Inf. Eng., Univ. of Virginia, Charlottesville, VA; Dept. of Syst. & Inf. Eng., Univ. of Virginia, Charlottesville, VA; Sch. of Nursing, Univ. of Virginia, Charlottesville, VA; Sch. of Med., Univ. of Virginia, Charlottesville, VA","IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans","18 Feb 2009","2009","39","2","388","403","The most effective screening for prostate cancer combines the prostate specific antigen blood test with the digital rectal examination (DRE). In performing a DRE, two sequential tasks are completed: ( task a) palpating the prostate to identify abnormalities and ( task b) linking identified abnormalities to a disease diagnosis. At present, clinicians find too few abnormalities and have variable rates of detection, due in part to the inadequacy of training simulators. The Virginia Prostate Examination Simulator (VPES) was designed, built, and tested to address the inadequacies of current simulators by incorporating the design requirements of the basic elements of accurate anatomy, multiple and reconfigurable scenarios of graded difficulty, and technique and performance feedback. We compared the training effectiveness of the VPES with two commercial simulators in an experiment of 36 medical and nurse practitioner students. Results indicate each type of training simulator-improved abilities, in general. Upon closer analysis, however, the following key patterns emerge: 1) Across all types of training, more deficiencies lie in skill-based rather than rule-based decision making, which improves only for VPES trainees; 2) only VPES training transfers both to other simulators and previously unencountered scenarios; 3) visual feedback may increase the number of abnormalities reported yet hinder the ability to discriminate; and 4) applied finger pressure did not correlate with the ability to identify abnormalities.","1558-2426","","10.1109/TSMCA.2008.2009769","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4729621","Evaluation;haptics;medical;nursing;simulation;simulator;tactile;training","Physics computing;Computational modeling;Computer simulation;Medical simulation;Testing;Feedback;Prostate cancer;Blood;Joining processes;Diseases","cancer;digital simulation;medical diagnostic computing","computerized simulator;physical simulator;clinical prostate exams;prostate cancer screening;prostate specific antigen blood test;digital rectal examination;disease diagnosis;training simulators;Virginia prostate examination simulator;accurate anatomy;decision making;VPES trainees;visual feedback","","24","","57","","22 Dec 2008","","","IEEE","IEEE Journals"
"The Effect of Virtual Reality on Knowledge Transfer and Retention in Collaborative Group-Based Learning for Neuroanatomy Students","V. Souza; A. Maciel; L. Nedel; R. Kopper; K. Loges; E. Schlemmer","Institute of Informatics (INF), Federal University of Rio Grande do Sul (UFRGS),Porto Alegre,Brazil; Institute of Informatics (INF), Federal University of Rio Grande do Sul (UFRGS),Porto Alegre,Brazil; Institute of Informatics (INF), Federal University of Rio Grande do Sul (UFRGS),Porto Alegre,Brazil; University of North Carolina at Greensboro (UNCG),Department of Computer Science,Greensboro,USA; University of Vale do Rio dos Sinos (UNISINOS),São Leopoldo,Brazil; University of Vale do Rio dos Sinos (UNISINOS),São Leopoldo,Brazil","2020 22nd Symposium on Virtual and Augmented Reality (SVR)","23 Nov 2020","2020","","","92","101","There are many uses for virtual reality (VR) in education, and there is a consensus about its contribution in the teaching and learning processes. However, the majority of the studies assess the effectiveness of an individual learning in VR, and there is a need to explore more on the effects of VR using different levels of immersion and collaboration. This paper presents an experiment to investigate knowledge transfer in a group-based learning game. We introduce a VR serious game to support teaching and learning processes in neuroanatomy health education. A between-subjects experiment was conducted with 23 students to jointly assess learning, knowledge retention, and sense of presence. As a control condition, grouped students assembled a physical model of the human brain, while in the experimental condition, a virtual brain was assembled. In each group, one participant assembled the brain, while the others observed and verbally collaborated in a group-based learning strategy. Results shown high mean scores in the virtual condition. When comparing the knowledge test performance before and immediately after the experiment, we found significant difference only for the virtual condition. The same can be observed for retention. Because of the promising results achieved and motivated by the need of more engaging new tools for remote learning - fully used in quarantine conditions, such as the current one because of the Covid-19 pandemic - we conducted a pilot user study to evaluate the learning effect of a remote version of our collaborative VR game.","","978-1-7281-9231-4","10.1109/SVR51698.2020.00028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262701","Virtual Reality;Presence;User Evaluation","Education;Games;Training;Neuroanatomy;Collaboration;Three-dimensional displays;Solid modeling","computer aided instruction;human factors;serious games (computing);teaching;virtual reality","virtual condition;remote learning;learning effect;collaborative VR game;virtual reality;knowledge transfer;collaborative group-based learning;neuroanatomy students;teaching;learning processes;individual learning;VR serious game;neuroanatomy health education;between-subjects experiment;knowledge retention;control condition;grouped students;virtual brain;knowledge test performance","","","","44","","23 Nov 2020","","","IEEE","IEEE Conferences"
"A framework for dynamic visualisation in simulation based instructional training","B. Helfesrieder; V. Shankararaman","Dept. of Comput. Sci., Hertfordshire Univ., Hatfield, UK; NA","SMC'98 Conference Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.98CH36218)","6 Aug 2002","1998","2","","1501","1505 vol.2","Work by researchers in the area of simulation based instruction has shown that the visual presentation of the simulated domain in terms of emphasising domain concepts, changing the level of detail or reducing the complexity of a presentation plays an important role for effective instruction and knowledge transfer. Earlier approaches have tackled this important instructional aspect by creating several different simulations of the same domain or by manually assembling several views of the simulation in order to present instructionally valuable variations of the simulated domain to the trainee. In contrast to that, we propose a framework which builds on the concepts of data-enrichment of the domain simulation, a higher level descriptive definition and characterisation of different views and a query-based assembling mechanism for generating a specific view, thus automating the process of view generation. The implementation of this framework is achieved through the ADVISE (Adaptive Visual Simulation Environment) prototype system. The ADVISE system allows the characterisation and enrichment of domain simulation data and provides an integrated view-specification and view-visualisation suite. The underlying simulation model is based on the behaviourally described object approach and hence domain-independent.","1062-922X","0-7803-4778-1","10.1109/ICSMC.1998.728098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=728098","","Visualization;Computational modeling;Character generation;Assembly;Computer simulation;Knowledge transfer;Numerical simulation;Computer science;Educational institutions;Virtual prototyping","computer aided instruction;digital simulation;data visualisation","dynamic visualisation;simulation based instruction;visual presentation;knowledge transfer;data enrichment;query-based assembling mechanism;view generation;ADVISE;Adaptive Visual Simulation Environment;prototype system;view specification;view visualisation;simulation based training","","","1","12","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Toward machine mediated training of motor skills. Skill transfer from human to human via virtual environment","Y. Yokokohji; R. L. Hollis; T. Kanade; K. Henmi; T. Yoshikawa","Dept. of Mech. Eng., Kyoto Univ., Japan; NA; NA; NA; NA","Proceedings 5th IEEE International Workshop on Robot and Human Communication. RO-MAN'96 TSUKUBA","6 Aug 2002","1996","","","32","37","We investigate a possibility of skill mapping from human to human via a visual/haptic display system. Our goal in the future is to develop a training system for motor skills such as surgical operations. We have proposed a new concept of visual/haptic display called a WYSIWYF Display; (What You See Is What You Feel). The proposed concept ensures correct visual/haptic registration which is important for effective hand-eye coordination training. Using the prototype WYSIWYF display, we did a preliminary experiment of skill training. Our idea of skill transfer is very simple; basically it is a ""record-and-replay"" strategy. Questions are ""What is the essential data to be recorded for transferring the skill?"" and ""What is the best way to provide the data to the trainee?"". Several methods were tried but no remarkable result was obtained, presumably because the chosen task was too simple.","","0-7803-3253-9","10.1109/ROMAN.1996.568646","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=568646","","Humans;Robot kinematics;Displays;Intelligent robots;Haptic interfaces;Virtual reality;Prototypes;Medical robotics;Surgery;Mechanical engineering","computer based training;virtual reality","machine mediated training;motor skills;skill transfer;virtual environment;skill mapping;visual/haptic display system;surgical operations;WYSIWYF Display;What You See Is What You Feel;hand-eye coordination training;record-and-replay strategy","","44","","21","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Animations of Medical Training Scenarios in Immersive Virtual Environments","I. V. Alexandrova; M. Rall; M. Breidt; U. Kloos; G. Tullius; H. H. Bulthoff; B. J. Mohler","Max Planck Inst. for Biol. Cybern., Tubingen, Germany; Med. Sch., Center for Patient Safety & Simulation, Univ. of Tubingen, Tubingen, Germany; Max Planck Inst. for Biol. Cybern., Tubingen, Germany; Reutlingen Univ., Germany; Reutlingen Univ., Germany; Max Planck Inst. for Biol. Cybern., Tubingen, Germany; Max Planck Inst. for Biol. Cybern., Tubingen, Germany","2011 Workshop on Digital Media and Digital Content Management","21 Jul 2011","2011","","","9","12","Medical training centers often provide various simulations for students and professionals. Their goal is not only to make trainees practice specific scenarios but also to help them effectively transfer the acquired skills to the real world. Having in mind that virtual environments have already been acknowledged for their potential to improve the medical training process, we propose an approach for rapid generation of animated medical scenarios, which can be used as an additional training tool that fits into the time frame of a semester training program.","","978-1-4577-0271-6","10.1109/DMDCM.2011.64","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5959667","medical simulation;virtual humans;motion capture","Training;Animation;Solid modeling;Cameras;Medical services;Synchronization;Pipelines","computer animation;computer based training;medical administrative data processing;virtual reality","medical training scenario;immersive virtual environments;animated medical scenarios;semester training program","","3","","8","","21 Jul 2011","","","IEEE","IEEE Conferences"
"Digital Twin and Virtual Reality for Safety Training","T. Kaarlela; S. Pieskä; T. Pitkäaho","Centria University of Applied Sciences,Ylivieska,Finland; Centria University of Applied Sciences,Ylivieska,Finland; Centria University of Applied Sciences,Ylivieska,Finland","2020 11th IEEE International Conference on Cognitive Infocommunications (CogInfoCom)","2 Nov 2020","2020","","","000115","000120","In this paper, our latest research related to digital twins and virtual reality environments for safety training purposes will be described and evaluated. We will present three practical use cases to outline the current maturity level of virtual reality technology for industrial environments. Two of our use cases are virtual reality applications for safety and emergency training scenarios. In addition, one use case is the implementation of a digital twin for off-site safety training. This use case presents a seamless real-time transfer of data between the physical and virtual worlds. Use cases were developed based on the needs of, and in co-operation with, local small and medium-sized enterprises (SMEs). The proposed affordable and simple approaches provide virtual safety training solutions that can be utilized by SMEs of different industries.","2380-7350","978-1-7281-8213-1","10.1109/CogInfoCom50765.2020.9237812","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237812","","Training;Digital twin;Virtual environments;Real-time systems;Production facilities;Safety;Task analysis","computer based training;industrial training;production engineering computing;safety;small-to-medium enterprises;virtual reality","digital twin;industrial environments;virtual reality;emergency training scenarios;off-site safety training;physical worlds;virtual worlds;virtual safety training;real-time data transfer;use cases;small and medium-sized enterprises;SME","","","","34","","2 Nov 2020","","","IEEE","IEEE Conferences"
"Implementing overground turning on a linear treadmill","H. Park; S. H. Chae; J. W. Yoon; J. Kim; A. Sudduth; C. Stanley","Department of Mechanical Engineering, KAIST, Daejeon, Korea; Department of Mechanical Engineering, KAIST, Daejeon, Korea; Department of Mechanical Engineering, Gyeongsang National University, Jinju, Korea; Department of Robotics Engineering, DGIST, Daegu, Korea; Rehabilitation Medicine Department, National Institutes of Health, Bethesda, USA; Rehabilitation Medicine Department, National Institutes of Health, Bethesda, USA","2015 12th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)","17 Dec 2015","2015","","","390","391","The purpose of treadmill-based locomotor training is to transfer walking skills obtained from training to real world walking (overground: OG). For optimal skill transfer, treadmill-based training should simulate OG as closely as possible. The constant speed of a standard treadmill encourages automaticity rather than engagement and fails to simulate the variable speeds encountered during OG walking. Our effort to overcome this limitation has focused on developing user-driven treadmill (UDT) velocity control schemes that allow the user to freely change walking speed and feel the same inertial force that they feel during OG walking. In this study, we have combined the user driven treadmill control with the virtual reality (VR) display to simulate realistic turning in a safe environment.","","978-1-4673-7971-7","10.1109/URAI.2015.7358882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358882","Gait Rehabilitation;Turning;User-driven Treadmill;Virtual Reality","Turning;Legged locomotion;Virtual reality;Electronic mail;Training;Velocity control","force control;gait analysis;patient rehabilitation;velocity control;virtual reality","overground turning;linear treadmill;treadmill-based locomotor training;walking skills;optimal skill transfer;user-driven treadmill;velocity control;inertial force;virtual reality;VR display;walking speed","","","","4","","17 Dec 2015","","","IEEE","IEEE Conferences"
"Use of a new tracking system based on ArToolkit for a surgical simulator: accuracy test and overall evaluation","J. de Siebenthal; F. Langlotz","Maurice E. Muller Inst. for Biomech., Bern Univ., Switzerland; Maurice E. Muller Inst. for Biomech., Bern Univ., Switzerland","The First IEEE International Workshop Agumented Reality Toolkit,","6 Jan 2003","2002","","","6 pp.","","Computer assisted surgery (CAS) uses expensive tracking systems, such as Optotrak (Northern Digital, Canada). These cameras use infra-red (IR) light detection and give sub-millimeter accuracy for the tracking of surgical tools in a real surgical context. In simulation, such accuracy is not mandatory. To replace the standard tracking systems used in CAS simulation, this paper promotes the use of video tracking systems that are easy to set up and less expensive. This work was motivated by the 5/sup th/ European Framework project VOEU that is aiming to produce new training tools for orthopedic surgery. One problems to solve is to provide an autonomous system for supporting surgeons in learning CAS procedures, since new training components are frequently requested. Such training technologies can be used during surgical lessons given to medical students, or are delivered to surgeons for preparing a real CAS procedure. Due to new computer technologies based on PCs, surgical simulators can be built at low cost featuring video tracking. Tracking is a key part of each CAS simulator, since surgical tools are used and need to be located in space. Several test series were carried out according to confidence values given by the ArToolkit library to evaluate its accuracy regarding various different parameters (size of markers, video cameras, volume of interest). The simulator implementation proposes a new interface for ArToolkit displaying a 3D scene without showing the image sequence captured by the video camera. The implemented 3D module is entirely based on an OpenInventor (SGI, USA) engine and can easily be included as a subcomponent of any complex user interface. One to several tools can be displayed in real time allowing the completion of each step of a common CAS procedure.","","0-7803-7680-3","10.1109/ART.2002.1106959","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1106959","","System testing;Content addressable storage;Computational modeling;Cameras;Infrared detectors;Space technology;Medical simulation;Context-aware services;Orthopedic surgery;Biomedical imaging","surgery;image sequences;orthopaedics;optical tracking;digital simulation;training;biomedical education;augmented reality;video signal processing;medical image processing;microcomputer applications","computer assisted surgery;ArToolkit;surgical simulator;video tracking systems;orthopedic surgery;training tools;autonomous system;medical students;PC;confidence values;3D scene;image sequence;video camera;OpenInventor engine;user interface","","2","","12","","6 Jan 2003","","","IEEE","IEEE Conferences"
"Incorporation of motor control and motor learning principles into VR applications","M. F. Levin; S. K. Subramanian; M. T. Robert","School of Physical and Occupational Therapy, McGill University; Department of Neuroscience, University of Montreal; Integrated Program in Neuroscience, McGill University","2015 International Conference on Virtual Rehabilitation (ICVR)","17 Dec 2015","2015","","","2","2","The primary focus of rehabilitation for individuals with motor deficits is the relearning of specific motor skills and daily tasks. Rehabilitation strives to take advantage of neuroplastic processes during recovery, a process that can be addressed by creating enriched training environments using virtual reality (VR) based simulations. The objectives of this workshop are to review motor control and motor learning principles, to discuss how they can be exploited by VR training environments and to provide examples of how these principles have been incorporated into different VR simulations for improving upper limb motor recovery. The workshop includes a practical component in which participants will design a specific intervention for improving a typical motor problem incorporating motor control and motor learning principles, in both a VR-based and a non-VR-based clinical application. Finally, we will discuss the limitations of the current technologies with respect to their effectiveness and transfer of learning to daily life tasks.","2331-9569","978-1-4799-8984-3","10.1109/ICVR.2015.7358630","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358630","","Motor drives;Neuroscience;Training;Solid modeling;Conferences;Medical treatment;Virtual reality","bioelectric potentials;learning (artificial intelligence);neurophysiology;patient rehabilitation;virtual reality","motor control principles;motor learning principles;patient rehabilitation;neuroplastic processes;virtual reality based simulations;upper limb motor recovery","","","","","","17 Dec 2015","","","IEEE","IEEE Conferences"
"A Training System of Orientation and Mobility for Blind People Using Acoustic Virtual Reality","Y. Seki; T. Sato","Human Technology Research Institute, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Ibaraki, Japan; College of Rehabilitation for the Blind, National Rehabilitation Center for Persons with Disabilities, Tokorozawa, Saitama, Japan","IEEE Transactions on Neural Systems and Rehabilitation Engineering","7 Feb 2011","2011","19","1","95","104","A new auditory orientation training system was developed for blind people using acoustic virtual reality (VR) based on a head-related transfer function (HRTF) simulation. The present training system can reproduce a virtual training environment for orientation and mobility (O&M) instruction, and the trainee can walk through the virtual training environment safely by listening to sounds such as vehicles, stores, ambient noise, etc., three-dimensionally through headphones. The system can reproduce not only sound sources but also sound reflection and insulation, so that the trainee can learn both sound location and obstacle perception skills. The virtual training environment is described in extensible markup language (XML), and the O&M instructor can edit it easily according to the training curriculum. Evaluation experiments were conducted to test the efficiency of some features of the system. Thirty subjects who had not acquired O&M skills attended the experiments. The subjects were separated into three groups: a no-training group, a virtual-training group using the present system, and a real-training group in real environments. The results suggested that virtual-training can reduce “veering” more than real-training and also can reduce stress as much as real training. The subjective technical and anxiety scores also improved.","1558-0210","","10.1109/TNSRE.2010.2064791","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5559478","Auditory orientation;blindness;head-related transfer function;obstacle perception;orientation and mobility;sound localization;stress pulse ratio","Training;Roads;Coils;Magnetic heads;Acoustics;Knee;Stress measurement","biomechanics;computer based training;handicapped aids;headphones;hearing;medical computing;virtual reality;XML","mobility;blind people;acoustic virtual reality;auditory orientation training system;head-related transfer function;HRTF simulation;listening;headphones;extensible markup language;XML","Acoustic Stimulation;Acoustics;Blindness;Computer-Assisted Instruction;Equipment Design;Equipment Failure Analysis;Therapy, Computer-Assisted;User-Computer Interface","35","","18","","30 Aug 2010","","","IEEE","IEEE Journals"
"AMIRE - authoring mixed reality","P. Grimm; M. Haller; V. Paelke; S. Reinhold; C. Reimann; R. Zauner",NA; NA; NA; NA; NA; NA,"The First IEEE International Workshop Agumented Reality Toolkit,","6 Jan 2003","2002","","","2 pp.","","This paper describes the requirements of a training demonstrator based on mixed reality in the context of the AMIRE project. The overall objective and idea of the AMIRE project is to define and implement a software system that allows content experts to easily design and implement mixed reality applications without detailed knowledge about the underlying base technologies of MR. Therefore, it describes a generic framework that allows an easy communication between the objects (MR components) used in the AMIRE applications. The AMIRE framework uses a component oriented technology and consists of a the minimal set of components required for a demonstrator, a reusable GEM collection and a visual authoring tool for building MR applications. For the realization of the AMIRE framework we also require an object tracking system that is cheap and easy to use. These are features of the ARToolkit library. Most of the current MR applications focus on the development of AR base technologies, like a lot of projects in the area of research and development of AR and MR applications. Many European projects mainly focus on the development of MR applications for a special domain (e.g. technical maintenance), such as ARVIKA, STAR, etc. But none of these projects focused on a structured authoring approach with reusable components and Gems. Due to the complexity of MR/AR applications only MR experts are able to develop MR/AR applications and prototyping of MR based applications becomes a very difficult task, because most research institutes have to develop (these applications from scratch.","","0-7803-7680-3","10.1109/ART.2002.1107008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1107008","","Virtual reality;Production;Application software;Software systems;Libraries;Research and development;Prototypes;Runtime;Programming profession;Licenses","authoring systems;augmented reality;software tools","training demonstrator;mixed reality;AMIRE project;software system;GEM collection;object tracking system;AR base technologies;generic framework;component oriented technology","","10","","","","6 Jan 2003","","","IEEE","IEEE Conferences"
"Hovercraft training simulator delay compensation design based on McFarland","L. Juan; L. Qing; C. Xinghua","College of Automation, Harbin Engineering University, Heilongjiang, Harbin 150001; College of Automation, Harbin Engineering University, Heilongjiang, Harbin 150001; College of Automation, Harbin Engineering University, Heilongjiang, Harbin 150001","2012 IEEE International Conference on Mechatronics and Automation","27 Aug 2012","2012","","","1021","1025","The hovercraft is a high-performance amphibious ship. Hovercraft training simulator (HTS) is a virtual reality device in which a human being is able to feel as if they are actually driving the real Hovercraft. The transfer delay in the HTS is the main reason of degrading its performance and affecting its real-time which comes from many sources. To reduce the transfer delay effects, the improved McFarland compensator was used for HTS. It is an integral method, which doesn't involve the process of kinetic equation solver in the HTS. Three coefficients of the corresponding consecutive velocity are used to predict the next states. These three factors determine the compensation ability of the compensator. The improved McFarland compensator makes up for the limitation that classic McFarland compensator can only be used to compensate for a fixed input of the simulation systems. Analysis of simulation results shows that the improved McFarland compensator is an effectively delay compensation, and can meet our demands.","2152-744X","978-1-4673-1278-3","10.1109/ICMA.2012.6283390","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6283390","Hovercraft;Simulator;Transfer Delay;McFarland compensator","Delay;High temperature superconductors;Training;Mathematical model;Equations;Vehicles;Visualization","control engineering computing;control system synthesis;delays;hovercraft;integral equations;training;virtual reality","hovercraft training simulator;HTS;delay compensation design;amphibious ship;virtual reality;transfer delay effects;McFarland compensator;integral method;kinetic equation solver","","","","14","","27 Aug 2012","","","IEEE","IEEE Conferences"
"Motion-based virtual reality cognitive training targeting executive functions in acquired brain injury community-dwelling individuals: A feasibility and initial efficacy pilot","G. Shochat; S. Maoz; A. Stark-Inbar; B. Blumenfeld; D. Rand; S. Preminger; Y. Sacher","Department of Traumatic Brain Injury, Loewenstein Rehabilitation Center, Ra'anana, Israel; Intendu Ltd., Herzliya, Israel; Intendu Ltd., Herzliya, Israel; Intendu Ltd., Herzliya, Israel; Department of Occupational Therapy, Tel Aviv University, Israel; Intendu Ltd., Herzliya, Israel; Department of Traumatic Brain Injury, Loewenstein Rehabilitation Center, Ra'anana, Israel","2017 International Conference on Virtual Rehabilitation (ICVR)","14 Aug 2017","2017","","","1","8","Acquired brain injury (ABI) is a leading cause of long-term cognitive disability, often involving deficits in executive functions (EF). ABI patients usually stop receiving cognitive treatment when leaving the rehabilitation facility or shortly thereafter, due to the high cost of therapy sessions and the mobility requirement to access therapy. Software solutions offer a promising tool for accessible and affordable cognitive rehabilitation in the home environment. However, research provides limited evidence for effective transfer of benefits from computerized cognitive training to real-life functions. Virtual reality (VR) exergames using motion-interaction offer a more realistic and natural training environment, and are therefore expected to facilitate a more effective transfer. Although commercial exergames may bring about some cognitive gains, they usually do not target cognitive functions directly. Here we describe a novel exergames platform, the Active Brain Trainer (ABT), designed to directly target EF, using games in multiple realistic contexts. The software adapts in real-time to the patient's behavior, providing feedback and rewards, and hence may enhance usability and compliance. The primary goal of the current study is to assess the feasibly and acceptability of this platform for community-dwelling ABI patients during the chronic phase. A secondary goal is to assess the initial efficacy on EF and functional benefits from program training. Participants were instructed to use the games for 15-20 sessions. Neuropsychological assessments of EF and daily life functions were performed before and after training. Participants also filled a satisfaction questionnaire following training. All training and assessments were conducted in the participants' homes. Game performance was recorded throughout training sessions. Preliminary results from the six ABI patients who successfully completed the program so far show no adverse effects. Participants reported enjoyment and satisfaction from training. Participants performed increasingly more challenging EF tasks within game environments. Initial results show improvements in functional tasks and most executive neuropsychological assessments following training. Additional participants are currently being trained to increase the power of the results. These preliminary findings support the feasibility and potential efficacy of the motion-based cognitive training of EF for community-dwelling individuals with ABI.","2331-9569","978-1-5090-3053-8","10.1109/ICVR.2017.8007530","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007530","cognitive training;exergames;motion-based;acquired brain injury;community-dwelling;executive functions","Games;Training;Avatars;Radiation detectors;Brain injuries;Medical treatment;Atmospheric measurements","brain;cognition;computer games;injuries;medical computing;neurophysiology;patient rehabilitation;virtual reality","motion-based virtual reality cognitive training;executive functions;acquired brain injury community-dwelling individuals;ABI;long-term cognitive disability;rehabilitation facility;therapy sessions;mobility requirement;home environment;computerized cognitive training;VR exergames;motion interaction;active brain trainer;ABT;chronic phase;neuropsychological assessments;daily life functions;game environments;functional tasks","","","","69","","14 Aug 2017","","","IEEE","IEEE Conferences"
"Application of Augmented Reality in Engineering Graphics Education","Heen Chen; Kaiping Feng; Chunliu Mo; Siyuan Cheng; Zhongning Guo; Yizhu Huang","Faculty of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; Faculty of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; Faculty of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; Faculty of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; Faculty of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; Faculty of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China","2011 IEEE International Symposium on IT in Medicine and Education","16 Jan 2012","2011","2","","362","365","Engineering graphics (EG) is the subject of transferring information from design into manufacture. Developing ability to create and read graphical representation of engineering structure is essential for individual. Therefore, training engineers able to use the graphical language to communicate is vital in every engineering college. However, in the classroom, where lecture time is limited, it is hard for the instructors to illustrate clearly the relationship between the 3D geometry and their 2D projection using only one kind of presenting technique. This work gives a brief insight into the potential and challenges of using Augmented Reality (AR) in Engineering Graphics Education. An AR-based system specifically designed for EG instruction were studied and developed. The system aims at improving the spatial awareness and interest of learning. Our own interest is to apply the AR system to Engineering Graphics instruction and provide the students with their own unique discovery path. The AR application enables faster comprehension of complex spatial problems and relationships which will benefit the students greatly during their learning processes. The AR-based method is proved to be effective teaching aids for engineering graphics courses and applying AR technology to support learning activities may become a trend in the future.","","978-1-61284-704-7","10.1109/ITiME.2011.6132125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6132125","Engineering Graphics Education;Augmented reality;Computer vision;Teaching reform","Three dimensional displays;Education;Solid modeling;Cameras;Computational modeling;Augmented reality","augmented reality;computational geometry;computer science education;engineering education;engineering graphics;solid modelling;teaching","augmented reality;engineering graphics education;information transfer;graphical representation;engineering structure;graphical language;engineering college;3D geometry;2D projection;AR-based system;engineering graphics instruction;teaching aids","","19","","9","","16 Jan 2012","","","IEEE","IEEE Conferences"
"The role of dimensional symmetry on bimanual psychomotor skills education in immersive virtual environments","J. Bertrand; D. Brickler; S. Babu; K. Madathil; M. Zelaya; T. Wang; J. Wagner; A. Gramopadhye; J. Luo",Clemson University; Clemson University; Clemson University; Clemson University; Clemson University; Clemson University; Clemson University; Clemson University; Clemson University,"2015 IEEE Virtual Reality (VR)","27 Aug 2015","2015","","","3","10","The need for virtual reality applications for education and training involving bimanual dexterous activities has been increasing in recent years. However, it is unclear how the amount of correspondence between a virtual interaction metaphor to the real-world equivalent, otherwise known as dimensional symmetry, affects bimanual pscyhomotor skills training and how skills learned in the virtual simulation transfer to the real world. How does the number of degrees of freedom enhance or hinder the learning process? Does the increase in dimensional symmetry affect cognitive load? In an empirical evaluation, we compare the effectiveness of a natural 6-DOF interaction metaphor to a simplified 3-DOF metaphor. Our simulation interactively educates users in the step-by-step process of taking a precise measurement using calipers and micrometers in a simulated technical workbench environment. We conducted a usability study to evaluate the user experience and pedagogical benefits using measures including a pre and post cognition questionnaire over all levels of Bloom's taxonomy, workload assessment, system usability, and real world psychomotor assessment tasks. Results from the pre and post cognition questionnaires suggest that learning outcomes improved throughout all levels of Bloom's taxonomy for both conditions, and trends in the data suggest that the 6-DOF metaphor was more effective in real-world skill transference compared to the 3-DOF metaphor.","2375-5334","978-1-4799-1727-3","10.1109/VR.2015.7223317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223317","Bimanual interaction;psychomotor skills education;dimensional symmetry","Atmospheric measurements;Particle measurements;Instruments;Training;Metrology;Solid modeling","computer aided instruction;user interfaces;virtual reality","dimensional symmetry role;bimanual psychomotor skills education;immersive virtual environment;virtual reality applications;education application;training application;virtual simulation;learning process;cognitive load;natural 6-DOF interaction;degrees-of-freedom;calipers;micrometers;user experience;pedagogical benefits;psychomotor assessment tasks;Bloom taxonomy;bimanual dexterous activities","","9","","27","","27 Aug 2015","","","IEEE","IEEE Conferences"
"“Woodlands” - a Virtual Reality Serious Game Supporting Learning of Practical Road Safety Skills","K. Szczurowski; M. Smith","Department of Informatics, Institute of Technology Blanchardstown, Dublin, Ireland; Department of Informatics, Institute of Technology Blanchardstown, Dublin, Ireland","2018 IEEE Games, Entertainment, Media Conference (GEM)","1 Nov 2018","2018","","","1","9","In developed societies road safety skills are taught early and often practiced under the supervision of a parent, providing children with a combination of theoretical and practical knowledge. At some point children will attempt to cross a road unsupervised, at that point in time their safety depends on the effectiveness of their road safety education. To date, various attempts to supplement road safety education with technology were made. Most common approach focus on addressing declarative knowledge, by delivering road safety theory in an engaging fashion. Apart from expanding on text based resources to include instructional videos and animations, some stakeholders (e.g.: Irish Road Safety Authority) attempt to take advantage of game-based learning [1]. However, despite the high capacity for interaction being common in Virtual Environments, available game-based solutions to road safety education are currently limited to delivering and assessing declarative knowledge. With recent advancements in the field of Virtual Reality (VR) Head Mounted Displays, procedural knowledge might also be addressed in Virtual Environments. This paper describes the design and development process of a computer-supported learning system that attempts to address psycho-motor skills involved in crossing a road safely, changing learners' attitude towards road safety best practices, and enabling independent practice of transferable skills. By implementing game-based learning principles and following best practice for serious game design (such as making educational components essential to successful game-play, or instructional scaffolding) we hope to make it not only more effective, but also engaging, allowing us to rely on learners' intrinsic motivation [2], to increase their independent practice time and provide them with feedback that will help to condition safe behaviour and increase retention. Presence in Virtual Reality might evoke responses to Virtual Environment as if it was real (RAIR) [3] and enable learners to truly experience learning scenarios. In consequence leading to formation of autobiographical memories constructed from multisensory input, which should result in an increased knowledge retention and transfer [4].","","978-1-5386-6304-2","10.1109/GEM.2018.8516493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516493","Virtual Reality;VR;Road Safety;Serious Game;Experiential Learning;Game-Based Learning;Virtual Environment","Games;Road safety;Virtual environments;Training","computer aided instruction;helmet mounted displays;road safety;serious games (computing);virtual reality","road safety education;declarative knowledge;road safety theory;road safety best practices;serious game design;virtual reality serious game;virtual environment;virtual reality head mounted displays;Woodlands;game-based learning","","4","","34","","1 Nov 2018","","","IEEE","IEEE Conferences"
"Performing distributed simulation with RESTful Web-services","K. Al-Zoubi; G. Wainer","Dept. of Systems and Computer Engineering Carleton University Centre of Visualization and Simulation (V-Sim), 1125 Colonel By Dr. Ottawa, ON, Canada; Dept. of Systems and Computer Engineering Carleton University Centre of Visualization and Simulation (V-Sim), 1125 Colonel By Dr. Ottawa, ON, Canada","Proceedings of the 2009 Winter Simulation Conference (WSC)","11 Mar 2010","2009","","","1323","1334","Distributed simulations are mainly used to interoperate heterogeneous simulators or geographically distributed models. We present here RESTful-CD++, the first distributed simulation middleware based on REST (Representational State Transfer) Web-services. RESTful-CD++ middleware enables heterogeneous independent-developed simulation components to interoperate with much flexibility and simplicity. REST has the potential to advance distributed simulation state-of-the-art towards plug-and-play or automatic/semi-automatic interoperability. This because of its lightweight approach hides internal software implementation by using universal uniform interface and describing connectivity semantics in form of messages, usually XML. In contrast, other approaches expose functionalities in heterogeneous RPCs that often reflect internal implementation and describe semantics in form of procedure parameters. Further, REST enables simulations to mashup with Web 2.0 applications, which makes simulation in link with any device attached to the Web dynamically at runtime. The CD++ tool is now the first simulation engine to use RESTful middleware to perform distributed simulation in large-scale.","1558-4305","978-1-4244-5771-7","10.1109/WSC.2009.5429650","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5429650","","Computational modeling;Computer simulation;Middleware;Industrial training;Computer languages;Distributed computing;XML;Management training;Simple object access protocol;Discrete event simulation","digital simulation;Internet;middleware;open systems;user interfaces;Web services;XML","restful Web-services;interoperate heterogeneous simulators;geographically distributed models;distributed simulation middleware;representational state transfer Web-services;RESTful-CD++ middleware;heterogeneous independent-developed simulation components;semiautomatic interoperability;plug-and-play interoperability;universal uniform interface;XML;Web 2.0","","6","1","20","","11 Mar 2010","","","IEEE","IEEE Conferences"
"Applying Entertaining Aspects of Serious Game in Medical Training: Systematic Review and Implementation","R. S. Torres; F. L. S. Nunes","Lab. de Aplic. de Inf. em Saude, Univ. de Sao Paulo, Sao Paulo, Brazil; Lab. de Aplic. de Inf. em Saude, Univ. de Sao Paulo, Sao Paulo, Brazil","2011 XIII Symposium on Virtual Reality","14 Jul 2011","2011","","","18","27","Virtual Reality (VR) has been widely used for medical area applications in order to help students and health care professionals to practice procedures before execute them on real patients. The evaluation of the user's learning is a very important step in any educational process, including systems for medical training. Serious Games are intended to employ entertaining aspects to training, knowledge transfer and simulations. This category of software can provide more motivation in the use of tools for training and also help in the evaluation of the learner. The aim of this paper is to present a serious game as a way to enhance the user experience in the use of medical training tools that use VR. This serious game contains entertaining aspects that are designed to stimulate the student to perform virtually the examination of breast biopsy.","","978-0-7695-4445-8","10.1109/SVR.2011.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5951831","framework;realidade virtual;serious games","Games;Instruments;Training;Software;Virtual reality;Mice;Application programming interfaces","biomedical education;computer based training;computer games;medical computing;virtual reality","serious game;medical training;virtual reality;educational process;knowledge transfer","","4","","21","","14 Jul 2011","","","IEEE","IEEE Conferences"
"Assessing quality of pilot training with use of mathematical analyses","M. Jirgl; J. Boril; R. Jalovecky","Faculty of Electrical Engineering and Communication, Brno University of Technology, Technická 3082/12, Brno 616 00, Czech Republic; Faculty of Military Technology, University of Defence, Kounicova 65, Brno 66210, Czech Republic; Faculty of Military Technology, University of Defence, Kounicova 65, Brno 66210, Czech Republic","2016 17th International Conference on Mechatronics - Mechatronika (ME)","30 Jan 2017","2016","","","1","6","This paper provides information on methods of measuring pilots' reactions to a changed flight parameter while being tested on simulators. The calculations are made on the grounds of mathematical algorithms modeling human behavior. The prepared mathematical models of behavior are based on transfer functions. The subsequent analysis aimed at acquiring time constants that shall appropriately characterize the state of pilot training is made in the MATLAB simulation environment. Future pilots studying at the University of Defence undergo, always after each period designated to their practical training, several sets of testing measurements. The testing was running on two different simulators, i.e. built on a fixed and movable platform. The obtained results indicate that individual pilots gradually improve their flying skills.","","978-8-0010-5883-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7827799","pilot training;mathematical analyses;human behavior model;flight simulators;pilots' reactions","Training;Mathematical model;Testing;Atmospheric modeling;Employment;Airplanes;Analytical models","aerospace computing;aerospace simulation;aerospace testing;computer based training;digital simulation;mathematical analysis;mathematics computing;transfer functions","pilot training;mathematical analysis;pilot reactions;changed flight parameter;mathematical models;transfer functions;MATLAB simulation environment;University of Defence;testing measurements;flying skills","","","","15","","30 Jan 2017","","","IEEE","IEEE Conferences"
"AR-based training and support of assembly workers in automobile industry","J. Fruend; M. Grafe; C. Matysczok; A. Vienenkoetter","Heinz Nixdorf Inst., Paderborn Univ., Germany; Heinz Nixdorf Inst., Paderborn Univ., Germany; Heinz Nixdorf Inst., Paderborn Univ., Germany; Heinz Nixdorf Inst., Paderborn Univ., Germany","The First IEEE International Workshop Agumented Reality Toolkit,","6 Jan 2003","2002","","","2 pp.","","In this paper, we present an interactive and context sensitive AR-system, which provides workers at the assembly line with all necessary information. Each assembly step of the components and the used tools is displayed using animations, 3D-objects and texts and inserted into the workers field of view via a small HMS. An corresponding Ar-system is used for the education and training of new workers. The complex steps of assembly processes are displayed using the same 3D-objects and texts. Thus staff working at manufacturing systems or assembly lines can be trained with a low degree of personal supervision. Every worker is able to assembly every structural component or automobile part at any time.","","0-7803-7680-3","10.1109/ART.2002.1106989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1106989","","Industrial training;Automobiles;Application software;Animation;Assembly systems;Automotive components;Multimedia databases;Manufacturing systems;Manufacturing industries;Vehicle dynamics","augmented reality;computer based training;assembling;automobile industry","augmented reality;automobile industry;training;support;context sensitive;assembly line;manufacturing systems;product planning;manufacturing","","2","","5","","6 Jan 2003","","","IEEE","IEEE Conferences"
"Coherent Rendering of Virtual Smile Previews with Fast Neural Style Transfer","V. Vasiliu; G. Sörös","Kapanu AG, Switzerland and EPFL, Switzerland; Kapanu AG, Switzerland and Nokia Bell Labs, Hungary","2019 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","30 Dec 2019","2019","","","66","73","Coherent rendering in augmented reality deals with synthesizing virtual content that seamlessly blends in with the real content. Unfortunately, capturing or modeling every real aspect in the virtual rendering process is often unfeasible or too expensive. We present a post-processing method that improves the look of rendered overlays in a dental virtual try-on application. We combine the original frame and the default rendered frame in an autoencoder neural network in order to obtain a more natural output, inspired by artistic style transfer research. Specifically, we apply the original frame as style on the rendered frame as content, repeating the process with each new pair of frames. Our method requires only a single forward pass, our shallow architecture ensures fast execution, and our internal feedback loop inherently enforces temporal consistency.","1554-7868","978-1-7281-0987-9","10.1109/ISMAR.2019.00-25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943754","augmented reality;coherent rendering;style transfer;convolutional neural network;autoencoder","Rendering (computer graphics);Image color analysis;Dentistry;Training;Augmented reality;Cameras;Task analysis","augmented reality;neural nets;rendering (computer graphics)","rendered frame;artistic style transfer research;autoencoder neural network;original frame;dental virtual try-on application;rendered overlays;post-processing method;virtual rendering process;virtual content;augmented reality;fast neural style transfer;virtual smile previews;coherent rendering","","1","","34","","30 Dec 2019","","","IEEE","IEEE Conferences"
"Persistent issues in the application of virtual environment systems to training","J. K. Caird","Dept. of Psychol., Calgary Univ., Alta., Canada","Proceedings Third Annual Symposium on Human Interaction with Complex Systems. HICS'96","6 Aug 2002","1996","","","124","132","The flexible constellation of technologies that comprise virtual environment (VE) systems provide many new opportunities for training. However, the lessons learned from decades of research in flight and driving simulation seem largely forgotten. This review recalls a set of long-term issues that will constrain the application of VE systems to training. In particular, the issues of cost effectiveness, interface usability, transfer of training, transfer theory, and training feedback are addressed. Training and research decisions that do not consider these issues are likely to result in programs and recommendations that do little to efficiently improve skills and knowledge.","","0-8186-7493-8","10.1109/HUICS.1996.549502","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=549502","","Virtual environment;Costs;Computer graphics;Force feedback;Psychology;Aerospace simulation;Usability;Computational modeling;Image generation;Physics computing","virtual reality","virtual environment systems;training;long-term issues;cost effectiveness;interface usability;transfer theory;training feedback","","8","31","79","","6 Aug 2002","","","IEEE","IEEE Conferences"
"The Impact of Haptic and Visual Feedback on Teaching","K. Qi; D. Borland; E. Jackson; N. L. Williams; J. Minogue; T. C. Peck","Davidson College; RENCI, UNC Chapel Hill; North Carolina State University; University of Maryland,College Park; North Carolina State University; Davidson College","2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)","11 May 2020","2020","","","612","613","Haptic feedback, an important aspect of learning in virtual reality, has been demonstrated in contexts such as surgical training. However, deploying haptic feedback in other educational practices remains understudied. Haptically-enabled science simulations enable students to experience abstract scientific concepts through concrete and observable lessons in which students can physically experience the concepts being taught through haptic feedback. The present study aims to investigate the effect of an educational simulation on the understanding of basic physics concepts related to buoyancy. Specifically, we hypothesize that a simulation with visual and haptic feedback will improve participant learning transfer.","","978-1-7281-6532-5","10.1109/VRW50115.2020.00157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9090605","Human computer interaction (HCI);Interaction paradigms;Virtual reality;Education;Interactive learning environments","Haptic interfaces;Visualization;Training;Buoyancy;Solid modeling;Liquids","computer aided instruction;educational courses;haptic interfaces;physics education;teaching;virtual reality","haptic feedback;haptically-enabled science simulations;visual feedback;teaching;virtual reality learning;participant learning transfer;educational practices;physics concepts;buoyancy","","","","5","","11 May 2020","","","IEEE","IEEE Conferences"
"The participatory design of a simulation training game","H. Lukosch; T. van Ruijven; A. Verbraeck","Delft University of Technology, Jaffalaan 5 2600 GA Delft, The Netherlands; Delft University of Technology, Jaffalaan 5 2600 GA Delft, The Netherlands; Delft University of Technology Jaffalaan 5 2600 GA Delft, The Netherlands","Proceedings of the 2012 Winter Simulation Conference (WSC)","21 Feb 2013","2012","","","1","11","Serious games show to have positive impact on training results. Advantages of simulation games lay in the provision of a safe training environment, where users are able to play, test and probe without serious consequences. At the same time, it is important to engage learners by providing a motivating, challenging environment, which becomes meaningful to the player when skills and knowledge acquired within the game are transferrable to real work tasks. With the use of a participatory game design approach, we developed an immersive, meaningful virtual training environment to improve situational awareness skills. Feedback of game developers as well as from test groups shows that the participatory approach to game development lead to a meaningful experience within an authentic virtual training environment. High functional and physical fidelity, a high degree of realism, compared with challenging game elements makes the developed serious game an appropriate training tool for situational awareness skills.","1558-4305","978-1-4673-4782-2","10.1109/WSC.2012.6465218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6465218","","Games;Training;Security;Engines;Prototypes;Context;Educational institutions","computer based training;computer games;knowledge management;virtual reality","simulation training games;knowledge transfer;participatory game design approach;virtual training environment;situational awareness skills;game developers;test groups;game development;physical fidelity;functional fidelity;safe training environment","","13","","25","","21 Feb 2013","","","IEEE","IEEE Conferences"
"Immersive virtual environments for tacit knowledge transfer focusing on gestures: A workflow","H. Esmaeili; H. Thwaites; P. C. Woods","Centre for Research-Creation in Digital Media, School of Arts, Sunway University, Malaysia; Centre for Research-Creation in Digital Media, School of Arts, Sunway University, Malaysia; Faculty of Creative Multimedia, Multimedia University, Malaysia","2017 23rd International Conference on Virtual System & Multimedia (VSMM)","26 Apr 2018","2017","","","1","6","This study presents a workflow for creating immersive virtual environments for tacit knowledge transfer. The main focus is on gestures, which are related to skill, performance, or physical emotion (not facial) e.g. sports, martial arts, playing instruments, acting, etc. The initial idea behind this design is to provide a virtual practice environment mainly for actors in order to learn new gestures or moves. However, this virtual environment can also be used by many other target audiences based on their needs. Sometimes, ambiguity is part of knowledge transfer and becomes more salient or critical when it comes to tacit knowledge, especially at early stages of transfer. Performance while maintaining believable gesture is a must have requirement for actors. Visual references (mainly video in absence of trainer) are commonly used by actors in order to learn specific moves or gestures. However, videos are limited to 2D screen view (even if stereoscopic or 360°) and do not provide chance of studying a freezing moment from all angles, simultaneously. Although this can be partly mimicked using multi-camera rig, it is still limited to the number of shots taken and only provides a linear frame sequence (mostly used as VFX). Immersive virtual environments not only eliminate this limitation but also provide one to one scale experience. In this study, the process of creating such environment is discussed in detail. This includes planning, concept design, selecting tools, establishing the environment, properly selecting or creating the virtual character(s), capturing the motion or using existing ones from different Mocap libraries, actor's interaction with VR equipment, user experience, etc. In addition to studying reference moves and gestures (frame by frame and from any angle), the user is able to observe his/her performance in VR. This can be achieved using motion capture cameras installed at the practice location. The captured content is later assigned to the user's virtual representative i.e. a 3d character created based on his/her physical body features for side by side analysis with the reference. This provides countless interaction possibilities that cannot be achieved in the real world. Few examples are: multiplying the reference character and freeze two or more different moments (frames) and create a walkthrough, creating an immersive timeline based on the actor's progress (also requires multiplying), assigning reference moves to the user's avatar to be compared with his/her movements by himself/herself or anyone else (different from side by side comparison with the reference character), and many others. What has been discussed above is fully illustrated and described in this paper including detailed figures. The contribution of this study can be extended to various fields from acting and sport to stop motion and creative art, as the processes presented in the paper are designed in the most affordable way, using hardware and software currently available to basic users.","2474-1485","978-1-5386-4494-2","10.1109/VSMM.2017.8346255","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8346255","immersive virtual environments;immersive virtual reality;tacit knowledge transfer;gesture;virtual reality;mocap;learning in virtual reality;htc vive;oculus rift;unity;steam vr","Teleportation;Knowledge transfer;Observers;Virtual environments;Art;Tools;Three-dimensional displays","gesture recognition;virtual reality","reference character;reference moves;immersive virtual environments;tacit knowledge transfer;virtual practice environment;believable gesture;virtual character;virtual representative","","1","","10","","26 Apr 2018","","","IEEE","IEEE Conferences"
"Closing the Skills Gap: Construction and Engineering Education Using Mixed Reality – A Case Study","W. Wu; A. Tesei; S. Ayer; J. London; Y. Luo; V. Gunji","Dept. of Construction Mgmt, Cal. State University, Fresno Fresno, CA, USA; Dept. of Construction Mgmt, Cal. State University, Fresno Fresno, CA, USA; Del E. Webb School of Construction, Arizona State University, Tempe, AZ, USA; Ira A. Fulton Schools of Engineering, The Polytechnic School, Mesa, AZ, USA; Dept. of Construction Mgmt, Cal. State University, Fresno Fresno, CA, USA; Dept. of Computer Science, Cal. State University, Fresno, Fresno, CA, USA","2018 IEEE Frontiers in Education Conference (FIE)","7 Mar 2019","2018","","","1","5","This research work-in-progress paper investigated the application of emerging mixed reality (MR) technology in construction and engineering education. The construction industry is facing a severe shortage of skilled workforce. As the baby boomers are retiring, the younger generation, especially college students, are often criticized for their lack of professional experience and career-specific competency. To close the skills gap and accelerate the transition of college students to competent workforce, this paper proposed a new genre of learning and professional training using MR. The main promise of the MR technology resides in its ability to augment virtual contents on top of the physical reality to facilitate tacit knowledge learning, and simulate learning activities that traditionally can only be obtained from actual professional experience. An undergraduate wood framing lab was designed as a case study to explore how students might perform in this new learning and training environment. Specifically, the case study investigated if MR would facilitate student design comprehension and transfer such understanding into the knowledge and skills needed to build the wood structure. A randomly selected student control group was given traditional paper-based construction drawings to perform the same tasks with other student groups with various visualization technology assistance. Project performance and behavior of student groups were compared to determine if there was a significant difference between the control group and the experiment groups. A pair of pre- and post-survey on MR-intervened learning experience was also conducted to explore student perceptions towards this new genre of learning and training. The research design proposed in this work-in-progress study and its preliminary results could be a good reference and foundation to future research in this arena.","2377-634X","978-1-5386-1174-6","10.1109/FIE.2018.8658992","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658992","mixed reality;construction;workforce;skills;learning","Virtual reality;Two dimensional displays;Training;Solid modeling;Buildings;Engineering education","augmented reality;computer based training;construction industry;design engineering;educational courses;engineering education;further education;knowledge management;professional aspects;termination of employment;wood","mixed reality;case study;construction industry;skilled workforce;baby boomers;college students;career-specific competency;professional training;physical reality;undergraduate wood framing lab;wood structure;visualization technology assistance;construction engineering education;retirement;augment virtual contents;knowledge learning;design engineering;paper-based construction drawings;student behavior","","2","","19","","7 Mar 2019","","","IEEE","IEEE Conferences"
"Virtual Reality medical training system for anatomy education","J. Falah; S. Khan; T. Alfalah; S. F. M. Alfalah; W. Chan; D. K. Harrison; V. Charissis","School of Engineering and Built Environment, Glasgow Caledonian University, Glasgow, UK; School of Engineering and Built Environment, Glasgow Caledonian University, Glasgow, UK; School of Business, Applied Science University, Amman, Jordan; King Abdullah II School for Information Technology University of Jordan, Amman, Jordan; School of Engineering and Built Environment, Glasgow Caledonian University, Glasgow, UK; School of Engineering and Built Environment, Glasgow Caledonian University, Glasgow, UK; School of Engineering and Built Environment, Glasgow Caledonian University, Glasgow, UK","2014 Science and Information Conference","9 Oct 2014","2014","","","752","758","Medical education is a dynamic field that witnesses continuous evolution and development. The employment of Virtual Reality (VR) based visualization and training environments in the delivery of anatomy teaching transfers the learning experience from one that involves memorising the structures without a true understanding of the 3-Dimensional (3D) relations, to a process that involves a thorough understanding of the structure based on visualisation rather than memorising, which makes the learning process more efficient and enjoyable, and less time consuming. This paper describes the development of a Virtual Reality and 3D visualisation system for anatomy teaching. The developed system offers a real-time 3D representation of the heart in an interactive VR environment that provides self-directed learning and assessment tools through a variety of interfaces and functionalities. To ensure the accuracy and precision of the developed system it was evaluated by a group of medical professionals.","","978-0-9893193-1-7","10.1109/SAI.2014.6918271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6918271","Medical Education;Virtual Reality;Anatomy;3D;Heart","Heart;Three-dimensional displays;Solid modeling;Educational institutions;Biomedical imaging;Visualization","biomedical education;computer based training;data visualisation;medical computing;virtual reality","virtual reality;medical training system;anatomy education;medical education;training environments;3-dimensional relations;3D visualisation system","","18","","25","","9 Oct 2014","","","IEEE","IEEE Conferences"
"Sport-specific virtual reality to identify profiles of anterior cruciate ligament injury risk during unanticipated cutting","A. W. Kiefer; C. DiCesare; S. Bonnette; K. Kitchen; B. Gadd; S. Thomas; K. D. Barber Foss; G. D. Myer; M. A. Riley; P. Silva","Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Department of Psychology, Center for Cognition, Action, & Perception, University of Cincinnati, OH USA; Department of Psychology, Center for Cognition, Action, & Perception, University of Cincinnati, OH USA","2017 International Conference on Virtual Rehabilitation (ICVR)","14 Aug 2017","2017","","","1","8","Female athletes are at an increased risk of anterior cruciate ligament (ACL) injury in competitive sport during running, jumping and cutting tasks. This risk is due to deficits in posterior chain and hip recruitment associated with aberrant frontal knee loads. The identification of these risk factors has led to targeted neuromuscular training (NMT) interventions to enhance hip neuromuscular control during such tasks. Despite the successful modification of ACL injury risk factors following NMT, the transfer of these corrected movement patterns to the sport-specific contexts has not been directly evaluated. Sport-specific virtual reality (VR) may provide the best method to measure training transfer to realistic sport performance, while still allowing appropriate experimental control and high-fidelity performance measurements. The current study examined the effect of a biofeedback-driven augmented NMT (aNMT) on skill transfer of ACL-injury resistant movement patterns during performance of sport-specific VR scenarios. Five trained athletes participated, and their performance on an unanticipated cutting task was assessed in VR prior to and after six weeks of aNMT. A significant 87% reduction in internal hip rotation was observed on the plant leg during the loading phase of cutting (p = .05), along with an observed 116% reduction during the push-off phase (p = .02), from pre- to post-training. A non-significant trend of a 19% reduction in knee abduction was also observed (p = .15). This study is the first that has utilized free ambulatory wireless VR to assess injury risk in athletes during performance of sport-specific tasks. The reduction in internal hip rotation and knee abduction align with previous findings on laboratory based tests. The current results are the first step in the validation of sport-specific VR as a tool for understanding injury risk during simulation of real-world sport performance.","2331-9569","978-1-5090-3053-8","10.1109/ICVR.2017.8007511","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007511","anterior cruciate ligament;virtual reality;sport;cutting;soccer","Injuries;Hip;Training;Neuromuscular;Biomechanics;Knee;Virtual reality","biomechanics;injuries;medical computing;muscle;neurophysiology;patient rehabilitation;sport;virtual reality","sport-specific virtual reality;anterior cruciate ligament injury risk;unanticipated cutting;female athletes;posterior chain;hip recruitment;aberrant frontal knee loads;neuromuscular training;biofeedback-driven augmented NMT;hip neuromuscular control;corrected movement patterns;sport-specific contexts;realistic sport performance;ACL-injury resistant movement patterns;push-off phase;free ambulatory wireless VR;internal hip rotation;knee abduction","","1","","62","","14 Aug 2017","","","IEEE","IEEE Conferences"
"Virtual surgery system for abdominal organs based on VR helmet","M. Liu; J. Deng; Y. Wang; X. Zhang; X. Zhang","School of Computer, Electronics and Information, Guangxi University, Nanning, Guangxi 530004, P. R. China; School of Computer, Electronics and Information, Guangxi University, Nanning, Guangxi 530004, P. R. China; School of Computer, Electronics and Information, Guangxi University, Nanning, Guangxi 530004, P. R. China; School of Computer, Electronics and Information, Guangxi University, Nanning, Guangxi 530004, P. R. China; Guangxi Key Laboratory of Multimedia Communications and Network Technology, Guangxi University, Nanning, Guangxi 530004, P. R. China","2018 International Workshop on Advanced Image Technology (IWAIT)","31 May 2018","2018","","","1","4","Now Days doctors interpret the human body abdomen via CT images, which is always lack of intuitive, three-dimensional viewing. Statistics show that 80% of clinical errors are caused by human error. Therefore surgical training for young surgeons is very important to their experience growth. In order to observe the body structure of the human body efficiently and improve the technical proficiency of doctors, this paper designs a surgical system for abdominal organs based on VR helmet. Using 3D Labeling algorithm and time varying phase difference algorithm, the system can automatically segment the organs in medical image and transfer the reconstruction of the human abdominal body into three-dimensional model, from which a VR helmet could perform a real-time visualization of the human organs in different viewpoints. Our system provides a virtual tool set (scalpel, surgical clamp) that enable the use of collision detection and cutting algorithm to achieve the cutting effects of the abdominal organs. Experimental results show that our system are robust to achieve the establishment of three-dimensional abdominal organ model, and virtual surgery tools could help doctors to simulate the operation completely together with the use of force-feedback device.","","978-1-5386-2615-3","10.1109/IWAIT.2018.8369801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8369801","Three-dimensional reconstruction;VR helmet;Virtual surgery","Surgery;Solid modeling;Three-dimensional displays;Biomedical imaging;Tools;Computed tomography;Labeling","biological organs;computerised tomography;force feedback;image segmentation;medical image processing;surgery;virtual reality","virtual surgery tools;three-dimensional abdominal organ model;cutting algorithm;collision detection;surgical clamp;virtual tool set;human organs;three-dimensional model;human abdominal body;medical image;phase difference algorithm;3D Labeling algorithm;body structure;young surgeons;surgical training;human error;clinical errors;three-dimensional viewing;CT images;human body abdomen;VR helmet;abdominal organs;virtual surgery system","","1","","10","","31 May 2018","","","IEEE","IEEE Conferences"
"Training with Virtual Operating Room Teammates to Influence Team Behaviors","B. Lok","Univ. of Florida, Gainesville, FL, USA","2016 International Conference on Collaboration Technologies and Systems (CTS)","6 Mar 2017","2016","","","615","616","Imagine you are an operating room nurse. Could training with virtual human teammates empower you to speak up to a bullying teammate? Could virtual teammates change the way you speak as to reduce errors? How about learn new patient safety policies or efficiently transfer care?In this talk, we will explore the emerging area of using virtual humans to subtly influence healthcare teams' teamwork and communication skills. This application of virtual humans could have significant patient safety impact as teamwork and communication is the top reason for adverse events in critical care areas, such as the emergency room, intensive care unit, and operating room.","","978-1-5090-2300-4","10.1109/CTS.2016.0115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7871053","","Training;Virtual reality;Teamwork;Surgery;Virtual groups;Computers","health care;human computer interaction;team working;training;virtual reality","virtual operating room teammates;team behaviors;patient safety policies;virtual humans;healthcare team teamwork;healthcare communication skills;team training","","","","5","","6 Mar 2017","","","IEEE","IEEE Conferences"
"Modulation Recognition of Underwater Acoustic Communication Signals Based on Data Transfer","N. Jiang; B. Wang","PLA Strategic Support Force, Information Engineering University, Zhengzhou, China; PLA Strategic Support Force, Information Engineering University, Zhengzhou, China","2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)","5 Aug 2019","2019","","","243","246","In practical applications, there are few labeled training samples in modulation recognition of underwater acoustic communication signals. In order to solve the problem, a data transfer learning method is proposed. The underwater noise in the actual water area is superimposed on the simulation signals to form the training set. The power spectrums of signals are performed as the input of the sparse autoencoder (SAE) network for training. The experimental results show that, when the channel is in good condition, for 2FSK, 4FSK, 8FSK, BPSK, OFDM and LFM, the proposed method can improve the recognition rate to a certain extent compared with the training method without data transfer.","","978-1-5386-8178-7","10.1109/ITAIC.2019.8785698","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8785698","modulation recognition;SAE;data transfer","Modulation;Underwater acoustics;Training;OFDM;Data transfer;Feature extraction;Signal to noise ratio","acoustic noise;acoustic signal processing;frequency shift keying;geophysical signal processing;modulation;OFDM modulation;phase shift keying;telecommunication computing;underwater acoustic communication;unsupervised learning;wireless channels","underwater acoustic communication signals;data transfer learning method;underwater noise;actual water area;simulation signals;training set;2FSK;4FSK;training method;modulation recognition;labeled training samples;LFM;OFDM;BPSK;8FSK;SAE network;sparse autoencoder network;power spectrums;recognition rate improvement","","","","10","","5 Aug 2019","","","IEEE","IEEE Conferences"
"Quality of service support of distributed interactive virtual environment applications in IP networks","Hong Yu; Quanyou Zhou; D. Makrakis; N. D. Georganas; E. Petriu","Broadband Wireless & Internetworking Res. Lab., Ottawa Univ., Ont., Canada; NA; NA; NA; NA","2001 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing (IEEE Cat. No.01CH37233)","7 Aug 2002","2001","1","","196","199 vol.1","This paper reports on the performance of Distributed Interactive Virtual Environment (DIVE) applications, deployed through Internet. Our goal is to understand the behaviour of a DIVE application, its interaction with competing traffic streams, as well as its network resource requirements for a satisfactory performance. As DIVE is becoming the building block of new applications and services, impacting several existing or new and growing sectors of our economy (email electronic commerce, tele-training, transportation), it is important that we understand the resource requirements of these applications, as well as the ""stress"" they will impose on the network.","","0-7803-7080-5","10.1109/PACRIM.2001.953556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=953556","","Quality of service;Virtual environment;Intelligent networks;IP networks;Diffserv networks;Internet;Application software;Telecommunication traffic;Computational modeling;Asynchronous transfer mode","distributed processing;virtual reality;Internet;quality of service;computer network management","Distributed Interactive Virtual Environment applications;Internet;DIVE application;competing traffic streams;network resource requirements;DiffServ;quality of service","","2","","6","","7 Aug 2002","","","IEEE","IEEE Conferences"
"Anthropomorphic robotic system with 6 DOF for space positioning in the virtual reality applications for human machine interaction","M. Chavez-Gamboa; I. Herrera-Aguilar; O. Sandoval-Gonzalez; F. Malagon-Gonzalez; J. M. Jacinto-Villegas","The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico; The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico; The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico; The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico; The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico","CONIELECOMP 2013, 23rd International Conference on Electronics, Communications and Computing","13 Jun 2013","2013","","","212","217","This paper presents a spatial hand tracking system using a 6 DOF anthropomorphic robot applied in human machine interaction. The main objective of this mechatronic system is to obtain information about the spatial position of a user's hand movements in order to be used like a skills trainer to accelerate the skills transfer from the machine to the human by integrating the laws of physics of virtual objects and adapting different design techniques and use of computer software for three-dimensional virtual reality.","","978-1-4673-6155-2","10.1109/CONIELECOMP.2013.6525788","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6525788","DOF;virtual reality;skills transfer;upper limbs;physical human-computer interaction;computational design","Virtual environments;Robots;Sensors;Software;Assembly;Kinematics","anthropology;gesture recognition;human-robot interaction;mechatronics;position control;robots;virtual reality","6 DOF anthropomorphic robotic system;space positioning;virtual reality applications;human machine interaction;spatial hand tracking system;mechatronic system;user hand movements;virtual objects;computer software;three-dimensional virtual reality","","","","18","","13 Jun 2013","","","IEEE","IEEE Conferences"
"Intelligent Robotic Peg-in-Hole Insertion Learning Based on Haptic Virtual Environment","Y. Chen; X. Han; M. Okada; Y. Chen; F. Naghdy","School of Information Science and Engineering, Central South University, Changsha, 410083, China. cyt28@126.com; School of Information Science and Engineering, Central South University, Changsha, 410083, China; School of Information, Production and Systems, Waseda University, Kitakyushu, 808-0135, Japan. okada@okada-lab.org; School of Electrical, Computer and Telecommunication Engineering, University of Wollongong, NSW, 2522, Australia. ycquiet@126.com; School of Electrical, Computer and Telecommunication Engineering, University of Wollongong, NSW, 2522, Australia","2007 10th IEEE International Conference on Computer-Aided Design and Computer Graphics","26 Dec 2007","2007","","","355","360","A new approach is explored to transfer human manipulation skills to a robotics system. A skill acquisition algorithm utilizes the position and contact force/torque data generated in the virtual environment combined with a priori knowledge about the task to generate the skills required to perform such a task. Such skills are translated into actual robotic trajectories for implementation in real time. The peg-in-hole insertion problem is used as a case study. The results are reported.","","978-1-4244-1578-6","10.1109/CADCG.2007.4407908","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4407908","","Intelligent robots;Haptic interfaces;Virtual environment;Humans;Imaging phantoms;Friction;Torque;Training data;Force feedback;Solid modeling","haptic interfaces;intelligent robots;learning (artificial intelligence);manipulators;rendering (computer graphics);virtual reality","intelligent robotic peg-in-hole insertion learning;haptic virtual environment;human manipulation skills;skill acquisition algorithm","","4","","12","","26 Dec 2007","","","IEEE","IEEE Conferences"
"VR-Goggles for Robots: Real-to-Sim Domain Adaptation for Visual Control","J. Zhang; L. Tai; P. Yun; Y. Xiong; M. Liu; J. Boedecker; W. Burgard","Department of Computer Science, University of Freiburg, Breisgau, Germany; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong; Department of Computer Science, University of Freiburg, Breisgau, Germany; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong; Department of Computer Science, University of Freiburg, Breisgau, Germany; Department of Computer Science, University of Freiburg, Breisgau, Germany","IEEE Robotics and Automation Letters","11 Feb 2019","2019","4","2","1148","1155","In this letter, we deal with the reality gap from a novel perspective, targeting transferring deep reinforcement learning (DRL) policies learned in simulated environments to the real-world domain for visual control tasks. Instead of adopting the common solutions to the problem by increasing the visual fidelity of synthetic images output from simulators during the training phase, we seek to tackle the problem by translating the real-world image streams back to the synthetic domain during the deployment phase, to make the robot feel at home. We propose this as a lightweight, flexible, and efficient solution for visual control, as first, no extra transfer steps are required during the expensive training of DRL agents in simulation; second, the trained DRL agents will not be constrained to being deployable in only one specific real-world environment; and third, the policy training and the transfer operations are decoupled, and can be conducted in parallel. Besides this, we propose a simple yet effective shift loss that is agnostic to the downstream task, to constrain the consistency between subsequent frames which is important for consistent policy outputs. We validate the shift loss for artistic style transfer for videos and domain adaptation, and validate our visual control approach in indoor and outdoor robotics experiments.","2377-3766","","10.1109/LRA.2019.2894216","Shenzhen Science and Technology Innovation Commission; German Research Foundation; Research Grant Council of Hong Kong SAR Government, China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8620258","Deep learning in robotics and automation;visual-based navigation;model learning for control","Visualization;Training;Robots;Adaptation models;Semantics;Task analysis;Navigation","control engineering computing;learning (artificial intelligence);mobile robots;robot vision;virtual reality","VR-goggles;real-to-sim domain adaptation;deep reinforcement learning policies;simulated environments;real-world domain;visual control tasks;visual fidelity;synthetic images output;training phase;real-world image streams;synthetic domain;expensive training;trained DRL agents;real-world environment;policy training;transfer operations;consistent policy outputs;artistic style transfer;visual control approach;indoor robotics experiments;outdoor robotics experiments;synthetic image output;real-world image stream translation;DRL agent training;shift loss;domain adaptation","","12","","30","","20 Jan 2019","","","IEEE","IEEE Journals"
"Can immersive type of Virtual Reality bring EMG pattern changes post facial palsy?","U. Qidwai; M. S. Ajimsha","KINDI Lab for Computing Research, Department of Computer Science & Engineering, Qatar University, Doha, Qatar; Physiotherapy Specialist, Dept. of Physical Therapy, Hamad Medical Corporation, Doha, Qatar","2015 Science and Information Conference (SAI)","3 Sep 2015","2015","","","756","760","The loss of facial expression via facial paralysis is a devastating condition, both functionally and aesthetically. However, given the life-long plasticity of the brain one could assume that recovery could be facilitated by the harnessing of mechanisms underlying neuronal reorganization. Currently it is not clear how this reorganization can be mobilized. Novel technology based neurorehabilitation techniques hold promise to address this issue. In this paper an immersive Virtual Reality (VR) based system is presented that is based on a number of hypotheses related to the neural structures targeted for recovery/reorganization, the structure of training system, and the role of individualization. The purpose of this paper is to examine the effects of an immersive type virtual reality (VR) intervention on activation of facial upper quadrant muscles following facial palsy in comparison with a control program. The key components of an immersive Virtual Reality (VR) based system and its effectiveness on facial palsy rehabilitation has been described in the form of experimental findings. Experimental trial was performed on an individual with facial upper quadrant muscles weakness due to facial palsy in a crossover study methodology with and without VR. EMG patterns from the facial upper quadrant muscles were recorded and analyzed for results. This trial has plotted a positive relationship between VR and facial upper quadrant muscles activation following a neurological impetus. The results reported here also show a consistent transfer of movement kinematics between physical and virtual tasks. EMG analysis has shown progressing improvement in the muscle activation in response to the challenging and impulsive activities in the virtual environment provided by the immersive VR devise.","","978-1-4799-8547-0","10.1109/SAI.2015.7237227","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7237227","Facial palsy;Virtual Reality;EMG-based measurements;Impulsive impetus","Muscles;Virtual reality;Electromyography;Training;Medical treatment;Neuroplasticity;Psychology","brain;electromyography;medical disorders;medical signal processing;neurophysiology;patient rehabilitation;virtual reality","EMG pattern;facial expression;facial paralysis;life-long plasticity;brain;neuronal reorganization;neurorehabilitation technique;neural structure recovery;neural structure reorganization;immersive virtual reality system;facial upper quadrant muscles;facial palsy rehabilitation;facial upper quadrant muscle weakness;neurological impetus;movement kinematics;physical task;virtual task;EMG analysis;muscle activation;impulsive activity;virtual environment","","","","19","","3 Sep 2015","","","IEEE","IEEE Conferences"
"Thermal Characterization of a Virtual Reality Headset during Transient and Resting Operation","R. McAfee; C. Haxton; M. Harrison; J. Gess","Oregon State University,204 Rogers Hall, Corvallis,OR,97331; Oregon State University,204 Rogers Hall, Corvallis,OR,97331; Oregon State University,204 Rogers Hall, Corvallis,OR,97331; Oregon State University,204 Rogers Hall, Corvallis,OR,97331","2020 36th Semiconductor Thermal Measurement, Modeling & Management Symposium (SEMI-THERM)","17 Jul 2020","2020","","","131","136","Virtual Reality (VR) is a powerful tool for maintenance process development, engineering design, pedagogy, and combat training. The evolution of the gaming industry has driven the demand for comfortable and reliable VR performance. By using the headset's user datasheet defined MicroController Unit's (MCU) operational temperature, the thermal resistance of the headset used in this study was found to have an external resistance, Rja, of 29.1 K/W, but 28.6% of this heat load is transmitted to the user. Relying on the user's body, specifically the forehead, as a heat sink results in uncomfortable perspiration during usage. Collected data show that after 2 hours of operation, the temperature increases 2.8°C on average when the headset is removed from the user and placed at rest while still operational. The maximum temperature increase is 5.6°C at the top of the VR headset, the surface nearest the internal MCU. This temperature spike proves that the headset needs more effective convective surface area in order to maintain a steady and comfortable operational temperature during “headset on” and “headset off” usage as the user's body was not available as a heat sink in the latter mode. A copper sheet has been added inside the headset to thermally connect all of the external surfaces on the device, effectively increasing the optimal convective heat transfer by 61%. The temperature nearest the MCU dropped 6.5°C with the improved thermal management solution and users reported a 25% reduction in perspiration during prolonged use.","","978-0-578-43862-7","10.23919/SEMI-THERM50369.2020.9142850","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9142850","Wearable;thermal management;consumer products;Virtual Reality;comfort measurements;free convection;heat transfer","Headphones;Temperature measurement;Heating systems;Temperature distribution;Convection;Forehead","convection;cooling;heat sinks;microcontrollers;thermal resistance;virtual reality","optimal convective heat transfer;comfortable operational temperature;steady temperature;temperature spike;VR headset;maximum temperature increase;heat sink results;heat load;external resistance;thermal resistance;MCU;MicroController Unit's operational temperature;reliable VR performance;comfortable VR performance;maintenance process development;resting operation;virtual Reality headset;thermal characterization;time 2.0 hour","","","","8","","17 Jul 2020","","","IEEE","IEEE Conferences"
"Deep Transfer Learning-Based Adaptive Beamforming for Realistic Communication Channels","H. Yang; J. Jee; G. Kwon; H. Park","Korea Advanced Institute of Science and Technology (KAIST),School of Electrical Engineering,Daejeon,South Korea; Korea Advanced Institute of Science and Technology (KAIST),School of Electrical Engineering,Daejeon,South Korea; Korea Advanced Institute of Science and Technology (KAIST),School of Electrical Engineering,Daejeon,South Korea; Korea Advanced Institute of Science and Technology (KAIST),School of Electrical Engineering,Daejeon,South Korea","2020 International Conference on Information and Communication Technology Convergence (ICTC)","21 Dec 2020","2020","","","1373","1376","Recently, in a massive multiple-input multipleoutput (MIMO) system, deep learning (DL)-based beamforming method has been proposed for reducing the overhead associated with downlink training and uplink feedback. However, the DL-based approach is sensitive to the variation of the communication environment and requires a huge number of training data to ensure a certain level of performance. To reduce the number of required channel data for training a deep neural network (DNN), we introduce deep transfer learning (DTL), which exploits the information from the pre-trained DNN for training other DNNs to find the beamforming vector in the specific channel. Through DTL, DNN can be trained suitably for the communication environment at each BS with fewer channel data. Moreover, we propose `step-by-step' DTL to flexibly apply DTL considering the uncertainties of the realistic system. Simulation results show that DTL has better performance than the conventional DLapproaches even with a small amount number of channel data. Therefore, the DTL-based approach can be a good framework to train DNN when high overhead occurs or designing the beamformer is complicated such as a massive MIMO system.","2162-1233","978-1-7281-6758-9","10.1109/ICTC49870.2020.9289412","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9289412","Beamforming;Massive MIMO;Deep Learning;Transfer Learning","Training;Uncertainty;Array signal processing;Simulation;Neural networks;Training data;Uplink","array signal processing;feedback;learning (artificial intelligence);MIMO communication;neural nets;telecommunication computing;wireless channels","channel data;step-by-step DTL;realistic system;DTL-based approach;massive MIMO system;deep transfer learning;adaptive beamforming;realistic communication channels;downlink training;uplink feedback;communication environment;training data;required channel data;deep neural network;pre-trained DNN;beamforming vector","","","","10","","21 Dec 2020","","","IEEE","IEEE Conferences"
"Thinking Penguin: Multimodal Brain–Computer Interface Control of a VR Game","R. Leeb; M. Lancelle; V. Kaiser; D. W. Fellner; G. Pfurtscheller","Center for Neuroprosthetics, École Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland; Nanyang Technological University, Singapore, Singapore; Laboratory of Brain-Computer Interfaces, Institute for Knowledge Discovery, Graz University of Technology, Graz, Austria; Institute of Computer Graphics and Knowledge Visualization, Graz University of Technology, Austria; Emeritus Professor at the Laboratory of Brain-Computer Interfaces, Institute for Knowledge Discovery, Graz University of Technology, Graz, Austria","IEEE Transactions on Computational Intelligence and AI in Games","10 Jun 2013","2013","5","2","117","128","In this paper, we describe a multimodal brain-computer interface (BCI) experiment, situated in a highly immersive CAVE. A subject sitting in the virtual environment controls the main character of a virtual reality game: a penguin that slides down a snowy mountain slope. While the subject can trigger a jump action via the BCI, additional steering with a game controller as a secondary task was tested. Our experiment profits from the game as an attractive task where the subject is motivated to get a higher score with a better BCI performance. A BCI based on the so-called brain switch was applied, which allows discrete asynchronous actions. Fourteen subjects participated, of which 50% achieved the required performance to test the penguin game. Comparing the BCI performance during the training and the game showed that a transfer of skills is possible, in spite of the changes in visual complexity and task demand. Finally and most importantly, our results showed that the use of a secondary motor task, in our case the joystick control, did not deteriorate the BCI performance during the game. Through these findings, we conclude that our chosen approach is a suitable multimodal or hybrid BCI implementation, in which the user can even perform other tasks in parallel.","1943-0698","","10.1109/TCIAIG.2013.2242072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6418003","Brain–computer interfaces (BCI);brain switch;game;hybrid BCI;multimodal;multitasking;virtual reality (VR)","Games;Electroencephalography;Electrodes;Training;Brain computer interfaces;Educational institutions;Feature extraction","brain-computer interfaces;computer games;virtual reality","thinking penguin game;multimodal brain computer interface control;VR game;highly immersive CAVE;virtual environment;virtual reality game;jump action;game controller;BCI performance;discrete asynchronous action;visual complexity;task demand;joystick control;hybrid BCI implementation","","49","","51","","23 Jan 2013","","","IEEE","IEEE Journals"
"Beyond DoD: non-defense training and education applications of DIS","E. A. Fitzsimmons; J. D. Fletcher","Office of Sci. & Technol. Policy, Washington, DC, USA; NA","Proceedings of the IEEE","6 Aug 2002","1995","83","8","1179","1187","Networked simulation for education and training is discussed as a functional capability though which distributed interactive simulation (DIS) may find application in the non-defense world. Effectiveness of networked simulation in defense education and training applications has yet to be conclusively demonstrated, but studies completed thus far have yielded positive results. Results from non-defense applications are also likely to be positive. The characteristics of networked simulation that are relevant to its transfer to non-defense applications include a focus on group performance, physical dispersion of participants, requirements for real-time response, emergent task environments, visual task environments, accessible performance data, provisions for practice, immersive realism, and interactions with many entities. These characteristics are matched with potential, non-defense applications of networked simulation such as training for crews, teams, and units, edutainment, education, training, school-to-work transitions, and lifelong learning. Remaining issues include further development of technical standards, legal standards, research and development, fiscal and regulatory policies, and development of the communications infrastructure.<>","1558-2256","","10.1109/5.400457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=400457","","US Department of Defense;Computational modeling;Computer simulation;Communication standards;Standards development;Computer networks;Military computing;Safety;Stress;Law","computer based training;training;computer aided instruction;digital simulation;simulation;standards;interactive systems;legislation;groupware;local area networks","nondefense training applications;nondefense education applications;DIS;functional capability;networked simulation;distributed interactive simulation;group performance;physical participant dispersion;real-time response;emergent task environments;visual task environments;accessible performance data;practice provisions;immersive realism;interactions;crews;teams;units;edutainment;school-to-work transitions;lifelong learning;technical standards","","4","","22","","6 Aug 2002","","","IEEE","IEEE Journals"
"A semi-physical virtual simulation system for AUV","Wang Hong-jian; Shi Xiao-cheng; Zhao Jie; Li Juan; Fu Ming-yu","Dept, of Mechatronic Eng., Harbin Inst. of Technol., China; Dept, of Mechatronic Eng., Harbin Inst. of Technol., China; Dept, of Mechatronic Eng., Harbin Inst. of Technol., China; NA; NA","Oceans '04 MTS/IEEE Techno-Ocean '04 (IEEE Cat. No.04CH37600)","14 Mar 2005","2004","3","","1560","1563 Vol.3","Just as Healey and Brutzman(1997) stated that ""... a critical bottleneck exists in AUV design and development"". Integrated simulator testing of AUV software and hardware is a broad and versatile method that supports rapid diagnosis and robust correction of system faults in the lab environment. So a semi-physical virtual simulation system for AUV is developed based on software developing platform-MultiGen Creator and Vega, and acts as an effective capable tool for long range training and intelligent behavioral operation for AUV. It is the objective of such design and development work to simulate a large-scale oceanic environment and to demonstrate a dynamic procedure of AUV under the control of the autonomous planning technology and the dynamic controlling technology. Some schemes about hardware topology architecture and software architecture of AUV simulation system are presented in the paper. Some mathematic models of AUV motion, the method of space consistency in visual simulation and data transfer mechanisms are also detailed introduced. All of above-mentioned forms a basis for integrating the intelligence technology and virtual simulation technology into the semi-physical simulation system. Finally, some real-time operational experiment results are presented at form of three-dimensional graphics, which is simulating the ocean exploration progress of AUV in virtual reality under the control of intelligence. The result shows that the simulation system is reasonable and reliable, that the mathematics model and simulation algorithm completely satisfy the real-time requirement, and that the simulation system can realistically demonstrate the simulation process of AUV. This semi-physical simulation system has been successfully applied to validate the correctness, validity and practicability for the autonomous planning algorithms and dynamic control algorithm of a certain AUV","","0-7803-8669-8","10.1109/OCEANS.2004.1406354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1406354","","Space technology;Marine technology;Hardware;Mathematics;Mathematical model;Heuristic algorithms;Software testing;System testing;Fault diagnosis;Robustness","oceanographic equipment;oceanographic techniques;remotely operated vehicles;test equipment;underwater vehicles;virtual reality","semiphysical virtual simulation system;autonomous underwater vehicle;integrated simulator testing;AUV software;AUV hardware;MultiGen Creator;Vega;long range training;intelligent behavioral operation;oceanic environment simulation;autonomous planning algorithm;dynamic control algorithm;hardware topology architecture;software architecture;mathematical model;AUV motion;visual simulation;data transfer;real-time operational experiment;3D graphics;ocean exploration;virtual reality","","1","","9","","14 Mar 2005","","","IEEE","IEEE Conferences"
"Transfer from a simulation environment to a live robotic environment: Are certain demographics better?","P. L. McDermott; A. Fisher; T. Carolan; M. R. Gronowski; M. Gacy; M. Overstreet","Alion Science and Technology 4949 Pearl East Circle, Suite 200; Alion Science and Technology 4949 Pearl East Circle, Suite 200; Alion Science and Technology 4949 Pearl East Circle, Suite 200; Alion Science and Technology 4949 Pearl East Circle, Suite 200; Alion Science and Technology 4949 Pearl East Circle, Suite 200; Alion Science and Technology 4949 Pearl East Circle, Suite 200","2012 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","30 Jul 2012","2012","","","191","192","The ability to remotely operate an unmanned vehicle while simultaneously looking for suspicious targets and then classifying those targets is not a trivial skill. This study looked at different training approaches to make better use of simulation as a first training step. When transferring to a live environment, the operators could be grouped into two categories according to whether they passed live training criteria or not. There were clear performance differences between these groups. The group that failed to pass criteria had poorer performance overall, more SA errors, and spent more time in training. Post-hoc analysis showed differences in the demographics between those who passed and those that did not. Male participants and younger participants were more likely to achieve criteria. There were no differences in gaming experience and perceived sense of direction.","2167-2148","978-1-4503-1063-5","10.1145/2157689.2157750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249521","Situation awareness;learning curves;demographics;sense of direction;teleoperation","Training;Robot sensing systems;USA Councils;Human factors;Land vehicles","digital simulation;remotely operated vehicles;telerobotics","simulation environment;live robotic environment;remote operation;unmanned vehicle;suspicious targets;target classification;live training criteria;post-hoc analysis;demographics;male participants;younger participants;gaming experience;perceived direction sense","","","","4","","30 Jul 2012","","","IEEE","IEEE Conferences"
"Perceptually Augmented Simulator Design","T. Edmunds; D. K. Pai","University of British Columbia, Vancouver; University of British Columbia, Vancouver","IEEE Transactions on Haptics","9 Mar 2012","2012","5","1","66","76","Training simulators have proven their worth in a variety of fields, from piloting to air-traffic control to nuclear power station monitoring. Designing surgical simulators, however, poses the challenge of creating trainers that effectively instill not only high-level understanding of the steps to be taken in a given situation, but also the low-level “muscle-memory” needed to perform delicate surgical procedures. It is often impossible to build an ideal simulator that perfectly mimics the haptic experience of a surgical procedure, but by focussing on the aspects of the experience that are perceptually salient we can build simulators that effectively instill learning. We propose a general method for the design of surgical simulators that augment the perceptually salient aspects of an interaction. Using this method, we can increase skill-transfer rates without requiring expensive improvements in the capability of the rendering hardware or the computational complexity of the simulation. In this paper, we present our decomposition-based method for surgical simulator design, and describe a user-study comparing the training effectiveness of a haptic-search-task simulator designed using our method versus an unaugmented simulator. The results show that perception-based task decomposition can be used to improve the design of surgical simulators that effectively impart skill by targeting perceptually significant aspects of the interaction.","2329-4051","","10.1109/TOH.2011.42","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5975145","Haptic I/O;artificial;augmented;and virtual realities;life and medical sciences;surgical simulation.","Haptic interfaces;Surgery;Training;Needles;Rendering (computer graphics);Surface roughness;Rough surfaces","augmented reality;computer based training;haptic interfaces;medical computing;surgery","perceptually augmented simulator design;training simulator;air-traffic control;piloting;nuclear power station monitoring;surgical simulator;low-level muscle-memory;surgical procedure;haptic experience;salient interaction aspect;skill-transfer rate;rendering hardware;computational complexity;decomposition-based method;user study;haptic-search-task simulator;unaugmented simulator;perception-based task decomposition","","2","","21","","4 Aug 2011","","","IEEE","IEEE Journals"
"Parameter evaluation for virtual Laparoscopic simulation","S. B. Mansoor; Z. Mukhtar; M. Malik; Z. Amjad; H. Qureshi","School of EECS, National university of Sciences & Technology, Islamabad, Pakistan; School of EECS, National university of Sciences & Technology, Islamabad, Pakistan; School of EECS, National university of Sciences & Technology, Islamabad, Pakistan; School of EECS, National university of Sciences & Technology, Islamabad, Pakistan; School of EECS, National university of Sciences & Technology, Islamabad, Pakistan","2011 7th International Conference on Emerging Technologies","20 Oct 2011","2011","","","1","6","Virtual Reality based surgical simulators have become quite common for training of surgeons for different surgical skills. Simulators have been widely used particularly in minimal invasive surgery. In this paper we find parameters that would be required to create a real time working simulation for exercises given in the Fundamentals of Laparoscopic Surgery curriculum. We use peg transfer exercise as our example in this work and create simulations for parameter analysis using SOFA, an open source surgical framework [1]. The parameters we choose are generic and can be used to create other more complex simulations like cholecystectomy [2] (gall bladder removal) and appendectomy (appendix removal). We show the implementation of these parameters and their behavior in a virtual reality surgical simulation. This work can be used by researchers and developers to choose the right parameters in the context of the simulation they are developing. It also shows the cost and behavior of achieving good visualization (frames per second), physical characteristics and a realistic behavioral model to be used in simulations for training purposes.","","978-1-4577-0768-1","10.1109/ICET.2011.6048481","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6048481","Surgical Simulations;Virtual Reality;Biomechanical Modeling;Laparoscopic Surgery","Solid modeling;Surgery;Finite element methods;Computational modeling;Floors;Springs;Deformable models","data visualisation;digital simulation;medical computing;surgery;virtual reality","parameter evaluation;virtual laparoscopic simulation;virtual reality based surgical simulator;surgical skills;laparoscopic surgery curriculum;peg transfer exercise;parameter analysis;SOFA;open source surgical;complex simulation;cholecystectomy;appendectomy;realistic behavioral model","","","","15","","20 Oct 2011","","","IEEE","IEEE Conferences"
"Training strategies for learning a 3D trajectory with accuracy","J. Rodríguez; T. Gutiérrez; S. Casado; E. J. Sánchez","Department of Applied Mechanics, CEIT - University of Navarra, Spain; LABEIN-TECNALIA, Spain; LABEIN-TECNALIA, Spain; Department of Applied Mechanics, CEIT - University of Navarra, Spain","2010 IEEE International Symposium on Haptic Audio Visual Environments and Games","9 Nov 2010","2010","","","1","6","The goal of this study was to evaluate different learning conditions for motor skill transfer. The study was divided into two experiments with the same task: learning a 3D trajectory with accuracy. The first experiment was focused on evaluating the efficiency of three feedback schemes for the target trajectory: visual, haptic and visual-haptic feedback. The second experiment was focused on analyzing the influence of decreasing the feedback during the training process. The results suggest that the best learning condition for learning a 3D trajectory with accuracy is to provide visual-haptic feedback, which facilitates the understanding of the dimension and orientation of each trajectory segment and solves any visual discrepancies that may exist. Furthermore, although continuous feedback can create dependences in users and impede the transfer of motor skills, feedback based on user request can also be dangerous since users can create a wrong mental representation that keep them from replicating the trajectory accurately. Therefore, when the performance of a task depends on references created during the training process, it seems appropriate for the system to provide automatic feedback based on user performance.","","978-1-4244-6509-5","10.1109/HAVE.2010.5623979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5623979","virtual training;motor skill transfer;virtual teaching;haptic feedback","Trajectory;Haptic interfaces;Visualization;Training;Three dimensional displays;Accuracy;Shape","haptic interfaces;knowledge representation;training;virtual reality;visual perception","training strategy;3D trajectory;motor skill transfer;visual-haptic feedback;trajectory segment;visual discrepancy;virtual reality","","3","","13","","9 Nov 2010","","","IEEE","IEEE Conferences"
"Approach on a new methodology for skills transfer using a parallel planar robot with visuo-vibrotactile feedback","P. Humblot-Niño; O. Sandoval-González; I. Herrera-Aguilar; D. Rangel-Peñuelas; A. Flores-Cuautle; B. González-Sánchez","División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México; División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México; División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México; División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México; CONACYT - División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México; División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México","2017 14th International Conference on Electrical Engineering, Computing Science and Automatic Control (CCE)","16 Nov 2017","2017","","","1","5","An approach of a new methodology for skills transfer from machine to human is proposed in this research. This methodology transmits a haptic feed-back using vibrotactile perception to transfer motor skills using a parallel planar robot and virtual reality environments. During the experimentation, the participants tried to learn a specific motion trajectory given by the system. During the process, the system computes the current position and generates a vibrotactile feed-back proportional to the error computed between the actual and the desired position of the motion trajectory. The results of the user studies showed this system can help with learning new skills.","","978-1-5386-3406-6","10.1109/ICEEE.2017.8108861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8108861","Skill Transfer;Parallel Planar Robot;Methodology","Haptic interfaces;Virtual environments;Robot sensing systems;Training;End effectors;Trajectory","feedback;haptic interfaces;human computer interaction;human-robot interaction;position control;virtual reality","haptic feedback;motion trajectory;visuo-vibrotactile feedback;virtual reality environments;parallel planar robot;motor skills;vibrotactile perception;skills transfer","","","","16","","16 Nov 2017","","","IEEE","IEEE Conferences"
"ECG-Based Virtual Pathology Stethoscope Tracking Using Transfer Learning","H. Yhdego; N. Kidane; F. Mckenzie; M. Audette","Old Dominion University,Norfolk,VA,USA; Old Dominion University,Norfolk,VA,USA; Old Dominion University,Norfolk,VA,USA; Old Dominion University,Norfolk,VA,USA","2020 Spring Simulation Conference (SpringSim)","3 Sep 2020","2020","","","1","7","Standardized Patient (SP) based medical simulation is commonly used to teach bedside skills. However, SPs are typically healthy individuals, and the number and range of conditions they can portray are limited. Our research aims to improve the cardiac auscultation (CA) skills of medical students by utilizing a modified stethoscope in tandem with SP. This technology introduces the potential to augment virtual pathology sounds on otherwise healthy SP. In this study, CNN models, previously trained on large-scale image datasets, are transferred to identify the four CA sites. We applied the pre-trained CNN models of ResNet50, InceptionV3, and Alexnet, to the ECG recordings from the CA regions, which are converted to images using a wavelet scalogram. Moreover, data augmentation is performed to supplement limited labeled data. Experimental results illustrate data augmentation with InceptionV3 and Resnet50 models leads to a better performance than our previously reported methods, between 93% and 95% F1 score.","","978-1-56555-370-5","10.22360/SpringSim.2020.MSM.009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9185471","ECG;Transfer Learning;Clinical Simulation;Auscultation;Stethoscope Tracking","Electrocardiography;Stethoscope;Feature extraction;Medical diagnostic imaging;Continuous wavelet transforms;Computer architecture","bioacoustics;biomedical education;convolutional neural nets;electrocardiography;learning (artificial intelligence);medical computing;medical signal processing;teaching","wavelet scalogram;Alexnet;standardized patient based medical simulation;Resnet50;data augmentation;ECG recordings;InceptionV3;pretrained CNN models;large-scale image datasets;virtual pathology sounds;modified stethoscope;medical students;cardiac auscultation skills;bedside skills;transfer learning;ECG-based virtual pathology stethoscope tracking","","","","15","","3 Sep 2020","","","IEEE","IEEE Conferences"
"Transfer Learning of a Temporal Bone Performance Model via Anatomical Feature Registration","Y. Zhou; I. Ioannou; S. Wijewickrema; J. Bailey; P. Piromchai; G. Kennedy; S. OLeary","Dept. of Comput. & Inf. Syst., Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Comput. & Inf. Syst., Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Centre for the Study of Higher Educ., Univ. of Melbourne, Melbourne, VIC, Australia; NA","2014 22nd International Conference on Pattern Recognition","6 Dec 2014","2014","","","1916","1921","Evaluation of the outcome (end-product) of surgical procedures carried out in virtual reality environments is an essential part of simulation-based surgical training. Automated end-product assessment can be carried out by performance classifiers built from a set of expert performances. When applied to temporal bone surgery simulation, these classifiers can evaluate performance on the bone specimen they were trained on, but they cannot be extended to new specimens. Thus, new expert performances need to be recorded for each new specimen, requiring considerable time commitment from time-poor expert surgeons. To eliminate this need, we propose a transfer learning framework to adapt a classifier built on a single temporal bone specimen to multiple specimens. Once a classifier is trained, we translate each new specimens' features to the original feature space, which allows us to carry out performance evaluation on different specimens using the same classifier. In our experiment, we built a surgical end-product performance classifier from 16 expert trials on a simulated temporal bone specimen. We applied the transfer learning approach to 8 new specimens to obtain machine generated end-products. We also collected end-products for these 8 specimens drilled by a single expert. We then compared the machine generated end-products to those drilled by the expert. The drilled regions generated by transfer learning were similar to those drilled by the expert.","1051-4651","978-1-4799-5209-0","10.1109/ICPR.2014.335","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977047","transfer learning;anatomy registration;automatic evaluation","Surgery;Bones;Anatomical structure;Solid modeling;Adaptation models;Decision trees;Training","bone;feature extraction;image classification;image registration;learning (artificial intelligence);medical image processing;surgery;virtual reality","temporal bone performance model;anatomical feature registration;surgical procedures;virtual reality environments;simulation-based surgical training;automated end-product assessment;performance classifiers;temporal bone surgery simulation;bone specimen;time-poor expert surgeons;transfer learning framework;surgical end-product performance classifier;transfer learning approach;machine generated end-products","","","","17","","6 Dec 2014","","","IEEE","IEEE Conferences"
"Real-Time Evaluation and Visualization of Learner Performance in a Mixed-Reality Environment for Clinical Breast Examination","A. Kotranza; D. S. Lind; B. Lok","University of Florida, Gainesville; Medical College of Georgia, Augusta; University of Florida, Gainesville","IEEE Transactions on Visualization and Computer Graphics","16 May 2012","2012","18","7","1101","1114","We investigate the efficacy of incorporating real-time feedback of user performance within mixed-reality environments (MREs) for training real-world tasks with tightly coupled cognitive and psychomotor components. This paper presents an approach to providing real-time evaluation and visual feedback of learner performance in an MRE for training clinical breast examination (CBE). In a user study of experienced and novice CBE practitioners (n = 69), novices receiving real-time feedback performed equivalently or better than more experienced practitioners in the completeness and correctness of the exam. A second user study (n = 8) followed novices through repeated practice of CBE in the MRE. Results indicate that skills improvement in the MRE transfers to the real-world task of CBE of human patients. This initial case study demonstrates the efficacy of MREs incorporating real-time feedback for training real-world cognitive-psychomotor tasks.","1941-0506","","10.1109/TVCG.2011.132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5963665","Mixed and augmented reality;information visualization;life and medical sciences.","Breast;Sensors;Real time systems;Visualization;Training;Data models;Humans","biomedical education;computer based training;data visualisation;medical computing;patient diagnosis;virtual reality","real-time evaluation;learner performance visualization;mixed-reality environment;clinical breast examination;real-time user performance feedback;real-world tasks training;tightly coupled cognitive components;psychomotor components;visual feedback;MRE;human patients;real-world cognitive-psychomotor tasks","Breast;Computer Graphics;Computer-Assisted Instruction;Feedback, Sensory;Female;Humans;Medical Informatics Applications;Models, Anatomic;Palpation;Pressure;User-Computer Interface","9","","35","","28 Jul 2011","","","IEEE","IEEE Journals"
"Assistive VR Gym: Interactions with Real People to Improve Virtual Assistive Robots","Z. Erickson; Y. Gu; C. C. Kemp","Georgia Institute of Technology,Health-care Robotics Lab,Atlanta,GA,USA; Georgia Institute of Technology,Health-care Robotics Lab,Atlanta,GA,USA; Georgia Institute of Technology,Health-care Robotics Lab,Atlanta,GA,USA","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","14 Oct 2020","2020","","","299","306","Versatile robotic caregivers could benefit millions of people worldwide, including older adults and people with disabilities. Recent work has explored how robotic caregivers can learn to interact with people through physics simulations, yet transferring what has been learned to real robots remains challenging. Virtual reality (VR) has the potential to help bridge the gap between simulations and the real world. We present Assistive VR Gym (AVR Gym), which enables real people to interact with virtual assistive robots. We also provide evidence that AVR Gym can help researchers improve the performance of simulation-trained assistive robots with real people. Prior to AVR Gym, we trained robot control policies (Original Policies) solely in simulation for four robotic caregiving tasks (robot-assisted feeding, drinking, itch scratching, and bed bathing) with two simulated robots (PR2 from Willow Garage and Jaco from Kinova). With AVR Gym, we developed Revised Policies based on insights gained from testing the Original policies with real people. Through a formal study with eight participants in AVR Gym, we found that the Original policies performed poorly, the Revised policies performed significantly better, and that improvements to the biomechanical models used to train the Revised policies resulted in simulated people that better match real participants. Notably, participants significantly dis-agreed that the Original policies were successful at assistance, but significantly agreed that the Revised policies were successful at assistance. Overall, our results suggest that VR can be used to improve the performance of simulation-trained control policies with real people without putting people at risk, thereby serving as a valuable stepping stone to real robotic assistance.","1944-9437","978-1-7281-6075-7","10.1109/RO-MAN47096.2020.9223609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9223609","","","biomechanics;geriatrics;handicapped aids;humanoid robots;learning (artificial intelligence);medical computing;medical robotics;mobile robots;virtual reality","simulated robots;simulated people;simulation-trained control policies;robotic assistance;virtual assistive robots;versatile robotic caregivers;physics simulations;simulation-trained assistive robots;robot control policies;robotic caregiving tasks;drinking;assistive VR gym;revised policies;AVR gym","","","","48","","14 Oct 2020","","","IEEE","IEEE Conferences"
"A Novel Robot Teaching System Based on Mixed Reality","Y. Xu; C. Yang; X. Liu; Z. Li","Key Lab of Autonomous Systems and Networked Control, School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; Key Lab of Autonomous Systems and Networked Control, School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; Hohai University, Jiangsu, China; Key Lab of Autonomous Systems and Networked Control, School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China","2018 3rd International Conference on Advanced Robotics and Mechatronics (ICARM)","13 Jan 2019","2018","","","250","255","In this paper, we have developed a robot teaching system where the robot learns the point-to-point motions from human demonstrations. In the demonstration phase, the operator's gestures and palm position are used to guide the robot to complete the task. At the same time, the scene of robots and its work environment, and the virtual model of the palms are integrated into Unity. Then the mixed reality scene is transferred to a virtual reality(VR) helmet, which provides operator real-time visual feedback. In the learning and reproduction phase, the Extreme Learning Machine(ELM) is used to generate a new trajectory from the training data. The experimental result shows that the robot teaching system based on mixed reality has more realistic and natural interaction. And the learning algorithm based on ELM has a good fitting ability.","","978-1-5386-7066-8","10.1109/ICARM.2018.8610861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8610861","Robot Teaching;Mixed Reality;Teaching by Demonstration;Extreme Learning Machine","Robot kinematics;Education;Zirconium;Service robots;Virtual reality;End effectors","gesture recognition;human-robot interaction;learning (artificial intelligence);virtual reality","reproduction phase;novel robot teaching system;point-to-point motions;human demonstrations;demonstration phase;mixed reality scene;operator real-time visual feedback;extreme learning machine;virtual reality helmet","","2","","22","","13 Jan 2019","","","IEEE","IEEE Conferences"
"Training and development tool for the open innovation quality management system","K. Zgodavova; A. Sutoova","Technical University of Kosice, Faculty of Materials, Metallurgy and Recycling, Institute of Materials and Quality Engineering, Kosice, Slovakia; Technical University of Kosice, Faculty of Materials, Metallurgy and Recycling, Institute of Materials and Quality Engineering, Kosice, Slovakia","2017 15th International Conference on Emerging eLearning Technologies and Applications (ICETA)","9 Nov 2017","2017","","","1","4","The purpose of the paper is to contribute to learning, knowledge creation and knowledge transfer obtained through a web-based role-play simulation environment as a training and development tool for the new phenomena of Open Innovation (OI) concepts of organizations. This paper is based on the survey realized within the OI-NET project. Learning objectives for OI course were chosen by the expert team of the project. A new approach to education using OIMS-RPS has been tested on a sample of PhD students from different study fields at the University. The study is limited by the complexity of the actual Open Innovation environment, measurability of any real enhancement achieved and the possible verification of empirical results.","","978-1-5386-3296-3","10.1109/ICETA.2017.8102543","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8102543","","Technological innovation;Organizations;ISO Standards;Education;Standards organizations;Quality management","computer based training;digital simulation;educational courses;innovation management;quality management","development tool;OI-NET project;learning objectives;OI course;open innovation quality management system;knowledge creation;knowledge transfer;training tool;Web-based role-play simulation environment;OIMS-RPS","","","","16","","9 Nov 2017","","","IEEE","IEEE Conferences"
"Control of Dual-User Haptic Training System With Online Authority Adjustment: An Observer-Based Adaptive Robust Scheme","M. Motaharifar; H. D. Taghirad; K. Hashtrudi-Zaad; S. F. Mohammadi","Advanced Robotics and Automated Systems (ARAS), Industrial Control Center of Excellence, Faculty of Electrical Engineering, K. N. Toosi University of Technology, Tehran, Iran; Advanced Robotics and Automated Systems (ARAS), Industrial Control Center of Excellence, Faculty of Electrical Engineering, K. N. Toosi University of Technology, Tehran, Iran; Department of Electrical and Computer Engineering, BioRobotics Research Laboratory, Queen’s University, Kingston, ON, Canada; Translational Ophthalmology Research Center, Farabi Eye Hospital, Tehran University of Medical Sciences, Tehran, Iran","IEEE Transactions on Control Systems Technology","8 Oct 2020","2020","28","6","2404","2415","The design problem for the control a dual-user haptic surgical training system is studied in this article. The system allows the trainee to perform the task on a virtual environment, while the trainer is able to interfere in the operation and correct probable mistakes made by the trainee. The proposed methodology allows the trainer to transfer the task authority to or from the trainee in real time. The robust adaptive nature of the controller ensures position tracking. The stability of the closed-loop system is analyzed using the input-to-output stability approach and the small-gain theorem. Simulation and experimental results are presented to validate the effectiveness of the proposed control scheme.","1558-0865","","10.1109/TCST.2019.2946943","National Institute for Medical Research Development (NIMAD); Tehran University of Medical Sciences, Tehran, Iran; K. N. Toosi University of Technology, Tehran, Iran Research Grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886365","Dual-user haptics;robust adaptive control;stability;surgical training;task dominance","Haptic interfaces;Task analysis;Training;Stability analysis;Force;Robots;Surgery","adaptive control;closed loop systems;computer based training;control system synthesis;haptic interfaces;human computer interaction;medical control systems;robust control;surgery;virtual reality","control scheme;online authority adjustment;observer-based adaptive robust scheme;dual-user haptic surgical training system;virtual environment;task authority;closed-loop system;dual-user haptic training system control;design problem;position tracking;robust adaptive controller;input-to-output stability approach;small-gain theorem","","","","22","IEEE","30 Oct 2019","","","IEEE","IEEE Journals"
"Enabling virtual assembly training in and beyond the automotive industry","A. Stork; N. Sevilmis; D. Weber; D. Gorecky; C. Stahl; M. Loskyll; F. Michel","Interactive Engineering, Technologies, Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany; Interactive Engineering, Technologies, Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany; Interactive Engineering, Technologies, Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany; Innovative Factory Systems, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany; Innovative Factory Systems, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany; Innovative Factory Systems, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany; Augmented Vision, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany","2012 18th International Conference on Virtual Systems and Multimedia","3 Dec 2012","2012","","","347","352","Virtual assembly training systems show a high potential to complement or even replace physical setups for training of assembly processes in and beyond the automotive industry. The precondition for the breakthrough of virtual training is that it overcomes the problems of former approaches. The paper presents the design approach taken during the development of a game-based, virtual training system for procedural assembly knowledge in the EU-FP7 project VISTRA. One key challenge to address when developing virtual assembly training is the extensive authoring effort for setting up virtual environments. Although knowledge from the product and manufacturing design is available and could be used for virtual training, a concept for integration of this data is still missing. This paper presents the design of a platform which transfers available enterprise data into a unified model for virtual training and thus enables virtual training of workers at the assembly line before the physical prototypes exist. The data requirements and constraints stemming from industrial partners involved in the project will be discussed. A second hurdle for virtual training is the insufficient user integration and acceptance. In this context, the paper introduces an innovative hardware set-up for game-based user interaction, which has been chosen to enhance user involvement and acceptance of virtual training.","","978-1-4673-2563-9","10.1109/VSMM.2012.6365944","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365944","Data Integration;Industrial Training;PLM;User-Interaction;Virtual Reality","Training;Assembly;Data models;Solid modeling;Hardware;Production;Geometry","assembling;automobile industry;business data processing;computer based training;data integration;human factors;product design;virtual manufacturing;virtual reality","automotive industry;virtual assembly training systems;game-based virtual training system;procedural assembly knowledge;EU-FP7 project;VISTRA;virtual environments;manufacturing design;product design;data integration;enterprise data;unified model;assembly line;user integration;game-based user interaction;user involvement;user acceptance","","26","","12","","3 Dec 2012","","","IEEE","IEEE Conferences"
"Multi-User Virtual System for Training of the Production and Bottling Process of Soft Drinks","J. I. Zambrano; D. A. Bermeo; C. A. Naranjo; V. H. Andaluz","Universidad de las Fuerzas Armadas ESPE,Sangolquí,Ecuador; Universidad de las Fuerzas Armadas ESPE,Sangolquí,Ecuador; Universidad de las Fuerzas Armadas ESPE,Sangolquí,Ecuador; Universidad de las Fuerzas Armadas ESPE,Sangolquí,Ecuador","2020 15th Iberian Conference on Information Systems and Technologies (CISTI)","15 Jul 2020","2020","","","1","7","The project consists of developing a virtual operational training system for the production and bottling process carried out in the soft drinks factory. For the virtualization of the industrial process, mathematical modeling is considered using a transfer function of the first order with downtime and control in relation to the flow plants that make up the substance mixing station in the company, for this, dynamic data and behaviors of the fully automated flow plants within the university are used and not the conventional station existing in the company, since its machines and data are kept confidential In addition, 3D CAD design techniques, electric diagrams of the process and instrumentation (P&ID) are used, all in order for multiple users to have immersive experiences sensory and can interact with each other within a virtual environment.","2166-0727","978-989-54659-0-3","10.23919/CISTI49556.2020.9141140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141140","Virtual environment;Production and bottling process;Unity 3D;Multiple users;Training;4.0 Industry","Process control;Mathematical model;Training;Production facilities;Virtual environments;Industries","beverage industry;bottling;CAD;chemioception;computer based training;industrial plants;instrumentation;mathematical analysis;mixing;production engineering computing;virtual reality;virtualisation","mathematical modeling;transfer function;substance mixing station;3D CAD design techniques;multiuser virtual system;bottling process;virtual operational training system;soft drinks factory;virtualization;industrial process;automated flow plants;production process;electric diagrams;instrumentation;sensory experience","","","","17","","15 Jul 2020","","","IEEE","IEEE Conferences"
"FoodChangeLens: CNN-Based Food Transformation on HoloLens","S. Naritomi; R. Tanno; T. Ege; K. Yanai","Dept. of Inf., Univ. of Electro-Commun., Tokyo, Japan; Technol. Dev., NTT Commun. Corp., Tokyo, Japan; Dept. of Inf., Univ. of Electro-Commun., Tokyo, Japan; Dept. of Inf., Univ. of Electro-Commun., Tokyo, Japan","2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","17 Jan 2019","2018","","","197","199","In this demonstration, we implemented food category transformation in mixed reality using both image generation and HoloLens. Our system overlays transformed food images to food objects in the AR space, so that it is possible to convert in consideration of real shape. This system has the potential to make meals more enjoyable. In this work, we use the Conditional CycleGAN trained with a large-scale food image data collected from the Twitter Stream for food category transformation which can transform among ten kinds of foods mutually keeping the shape of a given food. We show the virtual meal experience which is food category transformation among ten kinds of typical Japanese foods: ramen noodle, curry rice, fried rice, beef rice bowl, chilled noodle, spaghetti with meat source, white rice, eel bowl, and fried noodle. Note that additional results including demo videos can be see at https://negi111111.github.io/FoodChangeLensProjectHP/.","","978-1-5386-9269-1","10.1109/AIVR.2018.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613665","Deep Learning, Convolutional Neural Network, Generative Adversarial Networks, HoloLens, Food Image Transfer","Virtual reality;Transforms;Geometry;Image generation;Conferences;Shape;Training","convolutional neural nets;food products;learning (artificial intelligence);social networking (online);virtual reality","CNN-based food transformation;HoloLens;food category transformation;food images;food objects;large-scale food image data;typical Japanese foods;FoodChangeLens;conditional CycleGAN;Twitter stream;virtual meal experience","","","","5","","17 Jan 2019","","","IEEE","IEEE Conferences"
"Communication mission-type orders to virtual commanders","M. S. Kleiner; S. A. Carey; J. Beach","Logicon RDA, New Haven, CT, USA; NA; NA","1998 Winter Simulation Conference. Proceedings (Cat. No.98CH36274)","6 Aug 2002","1998","1","","881","885 vol.1","We discuss issues in modeling C4I and cognitive processes in next generation simulations and applications to Force XXI command and control. We propose a modification to the way military operations orders are written and published to achieve simulation/C4I interoperability. We suggest that the standard five-paragraph format be retained but that significant structure be applied to its free text components. We also propose a significant reduction in the size and content of divisional and corps orders, while promoting increased clarity and conciseness in them. We discuss issues related to the transfer of this initiative to field usage. We also address its impact on the next generation of simulations and training in a digitized force structure.","","0-7803-5133-9","10.1109/WSC.1998.745085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=745085","","Computational modeling;Computer simulation;Command and control systems;Context modeling;Runtime;Data mining;Large-scale systems;Humans;Data communication;Natural languages","digital simulation;military computing;computer based training;command and control systems","communication mission-type orders;virtual commanders;C4I modeling;cognitive processes;next generation simulations;Force XXI;command and control;military operations;interoperability;training","","","","","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Neural network training using ant algorithm in ATM traffic control","Zhangsu-Bing; Liu Ze-Min","Beijing Univ. of Posts & Telecommun., China; NA","ISCAS 2001. The 2001 IEEE International Symposium on Circuits and Systems (Cat. No.01CH37196)","7 Aug 2002","2001","3","","157","160 vol. 2","To maintain the QoS using the traditional mathematical approaches to build an efficient network traffic controller in ATM traffic control is a difficult task. The advantage of using NNs is that the QoS can be accurately estimated without detailed user action models or knowledge about the switching system architecture. The disadvantage is that it will take longer time to train with ATM network changes. In this paper, we use an algorithm in neural network weights training for ATM Call Admission Control (CAC) and Usage Parameter Control (UPC). The simulation results show that this approach is efficient and feasible.","","0-7803-6685-9","10.1109/ISCAS.2001.921270","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=921270","","Neural networks;Intelligent networks;Traffic control;Asynchronous transfer mode;Communication system traffic control;Heuristic algorithms;Telecommunication control;Switching systems;Intserv networks;Packet switching","digital simulation;asynchronous transfer mode;telecommunication congestion control;neural nets;learning (artificial intelligence);digital communication;B-ISDN","neural network training;ATM traffic control;QoS;network traffic controller;user action models;Call Admission Control;Usage Parameter Control;simulation","","2","","11","","7 Aug 2002","","","IEEE","IEEE Conferences"
"The use of simulation to calculate the labor requirements in an intermodal rail terminal","B. C. Kulick; J. T. Sawyer","Autom. Associates, Inc., Solana Beach, CA, USA; NA","Proceeding of the 2001 Winter Simulation Conference (Cat. No.01CH37304)","6 Aug 2002","2001","2","","1038","1041 vol.2","An intermodal rail terminal is a facility where the transfer of cargo occurs between truck and rail. The operations within these terminals involve many resources and operating rules. The ability of a terminal to respond to activity peaks that occur as a result of train arrivals and departures is critical. In order to explore how operations can be improved given the dynamics of resource and demand interactions, a simulation model was developed to assist in understanding and exploring areas where throughput can be improved. The model was constructed such that capacity issues could be explored incrementally. The first focus was for understanding if efficient deployment of labor resources could provide desired throughput.","","0-7803-7307-3","10.1109/WSC.2001.977411","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=977411","","Rails;Containers;Cranes;Throughput;Resource management;Strips;Automation;Availability;Productivity;Terminology","railways;logistics data processing;personnel;digital simulation;distributive data processing","intermodal rail terminal;cargo transfer;train arrivals;train departures;resource interactions;demand interactions;simulation model;labor requirements","","1","","","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Simulating perception with interactive virtual environments","K. Mania","Dept. of Informatics, Sussex Univ., Brighton, UK","2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)","7 Mar 2005","2004","3","","2770","2776 vol.3","Computer graphics algorithms have for long dealt with simulation of physics: simulation of the geometry of a real-world space, simulation of the light propagation in a real environment and simulation of motor actions with appropriate tracking. Perception principles have subsequently been incorporated into rendering algorithms in order to save rendering computation and produce photorealistic images from a human rather than a machine point of view. With virtual environment (VE) simulator technologies simulating real-world task situations mainly for transfer of training, the research community is challenged to produce a complex system. Furthermore, accurate simulation of physics is often not required in order to induce reality. Much less detail is adequate. This paper is going to review research literature exploring behavioral fidelity and reality benchmarking in interactive VEs focusing on results from two studies aiming to simulate perceptual processes. Study 1 investigates spatial awareness based on merging episodic information with spatial preconceptions and Study 2 looks at subjective impressions of illumination.","1062-922X","0-7803-8566-7","10.1109/ICSMC.2004.1400752","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1400752","","Virtual environment;Computational modeling;Solid modeling;Computer simulation;Physics;Rendering (computer graphics);Computer graphics;Computational geometry;Optical propagation;Humans","virtual reality;computer vision;large-scale systems;visual perception;human factors;digital simulation","interactive virtual environments;perception simulation;computer graphics algorithms;geometry simulation;light propagation simulation;photorealistic images;virtual environment simulator technologies;complex system;episodic information;spatial preconceptions;behavioral fidelity;reality benchmarking","","1","","29","","7 Mar 2005","","","IEEE","IEEE Conferences"
"Advantages of Virtual Reality in the Teaching and Training of Radiation Protection during Interventions in Harsh Environments","A. Cryer; G. Kapellmann-Zafra; S. Abrego-Hernández; H. Marin-Reyes; R. French","Department of Physics and Astronomy, University of Sheffield; Department of Physics and Astronomy, University of Sheffield; Department of Physics and Astronomy, University of Sheffield; Department of Physics and Astronomy, University of Sheffield; Department of Physics and Astronomy, University of Sheffield","2019 24th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)","17 Oct 2019","2019","","","784","789","Human interventions in radioactive environments have high stakes. They are often time-sensitive and radiation exposure must be minimised for the safety of personnel. Existing sites were not developed with remote decommissioning in mind, therefore human intervention remains the preferred approach for dexterous manual labour over robotic systems. For ageing sites, knowledge transfer after retirement is an increasingly relevant problem for maintenance and decommissioning tasks, where new workers lack the in-depth “on the ground” experience of the installation. Virtual Reality provides workers the agency to explore an accurate representation of the area, enabling them to gain experience without undue radiation exposure. This paper explores and discusses the teaching and training applications of a Virtual Reality environment with integrated radiation dose maps, and looks at where the system may be developed further.","1946-0759","978-1-7281-0303-7","10.1109/ETFA.2019.8869433","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869433","","Detectors;Task analysis;Solid modeling;Virtual reality;Training;Headphones;Large Hadron Collider","dosimetry;fission reactor decommissioning;personnel;radiation protection;virtual reality","radiation protection;harsh environments;human intervention;radioactive environments;remote decommissioning;dexterous manual labour;robotic systems;maintenance tasks;decommissioning tasks;teaching applications;training applications;virtual reality environment;integrated radiation dose maps;maintenance","","","","28","","17 Oct 2019","","","IEEE","IEEE Conferences"
"Skill transfer in a simulated underactuated dynamic task","M. K. O'Malley; A. Gupta","Mech. Eng. & Material Sci., Rice Univ., Houston, TX, USA; Mech. Eng. & Material Sci., Rice Univ., Houston, TX, USA","The 12th IEEE International Workshop on Robot and Human Interactive Communication, 2003. Proceedings. ROMAN 2003.","19 Dec 2003","2003","","","315","320","Machine-mediated teaching of dynamic task completion is typically implemented with passive intervention via virtual fixtures or active assist by means of record and replay strategies. During interaction with a real dynamic system however, the user relies on both visual and haptic feedback in order to elicit desired motions. This work investigates skill transfer from assisted to unassisted modes for a Fitts' type targeting task with an underactuated dynamic system. Performance, in terms of between target tap times, is measured during an unassisted baseline session and during various types of assisted training sessions. It is hypothesized that passive and active assist modes that are implemented during training of a dynamic task could improve skill transfer to a real environment or unassisted simulation of the task. Results indicate that transfer of skill is slight but significant for the assisted training modes.","","0-7803-8136-X","10.1109/ROMAN.2003.1251864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1251864","","Haptic interfaces;Education;Displays;Fixtures;Humans;Virtual reality;Force feedback;Shape control;Control systems;Mechanical engineering","haptic interfaces;computer based training;virtual reality;learning (artificial intelligence)","underactuated dynamic system;Fitts' type;skill transfer;haptic feedback","","3","","22","","19 Dec 2003","","","IEEE","IEEE Conferences"
"Robot Patient Design to Simulate Various Patients for Transfer Training","Z. Huang; C. Lin; M. Kanai-Pak; J. Maeda; Y. Kitajima; M. Nakamura; N. Kuwahara; T. Ogata; J. Ota","School of Automation, Guangdong University of Technology, Guangzhou, China; Research into Artifacts, Center for Engineering, University of Tokyo, Chiba, Japan; Kanto Gakuin University, Yokohama, Japan; Faculty of Nursing, Tokyo Ariake University of Medical and Health Sciences, Tokyo, Japan; Faculty of Nursing, Tokyo Ariake University of Medical and Health Sciences, Tokyo, Japan; Faculty of Nursing, Tokyo Ariake University of Medical and Health Sciences, Tokyo, Japan; Department of Advanced Fibro-Science, Kyoto Institute of Technology, Kyoto, Japan; Research into Artifacts, Center for Engineering, University of Tokyo, Chiba, Japan; Research into Artifacts, Center for Engineering, University of Tokyo, Chiba, Japan","IEEE/ASME Transactions on Mechatronics","13 Oct 2017","2017","22","5","2079","2090","To improve the patient transfer skill of nursing education students, we developed a robot patient that can simulate three categories of patients: 1) patients whose movements are affected by paralysis; 2) patients whose movements are sensitive to pain with painful expression; and 3) patients whose movements are constrained by medical devices. By practicing with the robot patient, nursing students can learn the skills required for interacting with various patients. To simulate trunk movements of these different patients, novel waist and hip joints with hardware-inherent compliance and force-sensing capability were proposed. In addition, control methods were developed and the parameters were tuned based on actual patient videos. To evaluate the developed robot, nursing teachers performed trials of transferring the robot patient as they would transfer an actual patient. The nursing teachers scored the robot patients based on a checklist. Moreover, subjective evaluations of a questionnaire were performed by the nursing teachers. The results showed that the nursing teachers performed most of the required skills of the checklist and agreed regarding the learning effectiveness of the robot. They recommended training nursing students using the robot patient in the questionnaire. Finally, hugging speed comparison showed that the nurses slow down the speed when dealing with a robot patient with painful expression.","1941-014X","","10.1109/TMECH.2017.2730848","Japan Society for the Promotion of Science KAKENHI; National Science Foundation of China; Natural Science Foundation of Guangdong Province, China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990192","Compliant joint;patient transfer;robot patient;various patients","Training;Medical services;Robot sensing systems;Hip;Force","biomedical education;computer aided instruction;control system synthesis;educational robots;human-robot interaction;medical computing;medical robotics;patient care","nursing teachers;robot patient design;patient transfer skill;nursing education students;force-sensing capability;control parameter tuning;transfer training","","","","48","Traditional","24 Jul 2017","","","IEEE","IEEE Journals"
"The wobbly table: Increased social presence via subtle incidental movement of a real-virtual table","M. Lee; K. Kim; S. Daher; A. Raij; R. Schubert; J. Bailenson; G. Welch",University of Central Florida; University of Central Florida; University of Central Florida; University of Central Florida; University of Central Florida and UNC-Chapel Hill; Stanford University; University of Central Florida,"2016 IEEE Virtual Reality (VR)","7 Jul 2016","2016","","","11","17","While performing everyday interactions, we often incidentally touch and move objects in subtle ways. These objects are not necessarily directly related to the task at hand, and the movement of an object might even be entirely unintentional. If another person is touching the object at the same time, the movement can transfer through the object and be experienced - however subtly - by the other person. For example, when one person hands a drink to another, at some point both individuals will be touching the glass, and consequently exerting small (often unnoticed) forces on the other person. Despite the frequency of such subtle incidental movements of shared objects in everyday interactions, few have examined how these movements affect human-virtual human (VH) interaction. We ran an experiment to assess how presence and social presence are affected when a person experiences subtle, incidental movement through a shared real-virtual object. We constructed a real-virtual room with a table that spanned the boundary between the real and virtual environments. The participant was seated on the real side of the table, which visually extended into the virtual world via a projection screen, and the VH was seated on the virtual side of the table. The two interacted by playing a game of “Twenty Questions,” where one player asked the other a series of 20 yes/no questions to deduce what object the other player was thinking about. During the game, the “wobbly” group of subjects experienced subtle incidental movements of the real-virtual table: the entire real-virtual table tilted slightly away/toward the subject when the virtual/real human leaned on it. The control group also played the same game, except the table did not wobble. Results indicate that the wobbly group had higher presence and social presence with the virtual human in general, with statistically significant increases in presence, co-presence, and attentional allocation. We present the experiment and results, and discuss some potential implications for virtual human systems and some potential future studies.","2375-5334","978-1-5090-0836-0","10.1109/VR.2016.7504683","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504683","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems — Artificial, Augmented and Virtual Realities;J.4 [Computer Applications]: Social and Behavioral Sciences — Psychology","Electronic mail;Measurement by laser beam;Virtual environments;Games;Training;Haptic interfaces;Force","human computer interaction;virtual reality","wobbly table;social presence;real-virtual table;subtle incidental movement;object movement;human-virtual human interaction;human-VH interaction;shared real-virtual object;real-virtual room;projection screen;virtual world;Twenty Questions game","","17","","42","","7 Jul 2016","","","IEEE","IEEE Conferences"
"Packet network simulation: speedup and accuracy versus timing granularity","Jong Suk Ahn; P. B. Danzig","Dept. of Comput. Eng., Dongguk Univ., Seoul, South Korea; NA","IEEE/ACM Transactions on Networking","6 Aug 2002","1996","4","5","743","757","This paper describes a new technique that can speedup simulation of high-speed, wide-area packet networks by one to two orders of magnitude. Speedup is achieved by coarsening the representation of network traffic from packet-by-packet to train-by-train, where a train represents a cluster of closely spaced packets. Coarsening the timing granularity creates longer trains and makes the simulation proceed more quickly since the cost of processing trains is independent of train size. Coarsening the timing granularity introduces, of course, a degree of approximation. This paper presents experiments that evaluate our coarse time-grain simulation technique for first in/first out (FIFO) switched, TCP/IP, and asynchronous transfer mode (ATM) networks carrying a mix of data and streaming traffic. We show that delay, throughput, and loss rate can frequently be estimated within a few percent via coarse time-grain simulation. This paper also describes how to apply coarse time-grain simulation to other switch disciplines. Finally, this paper introduces three more simulation techniques which together can double the performance of well written packet simulators without trading with the simulation accuracy. These techniques reduce the number of outstanding simulation events and reduce the cost of manipulating the event list.","1558-2566","","10.1109/90.541322","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=541322","","Accuracy;Timing;Telecommunication traffic;Traffic control;Costs;Asynchronous transfer mode;Delay estimation;Switches;TCPIP;Throughput","asynchronous transfer mode;packet switching;digital simulation;simulation;wide area networks;computational complexity;switching networks;delays;channel capacity;transport protocols","packet network simulation;speedup;accuracy;timing granularity;high-speed wide-area packet networks;representation;network traffic;train;closely spaced packets;approximation;first in/first out switched network;Internet protocol network;asynchronous transfer mode networks;ATM networks;delay;throughput;loss rate;time-grain simulation;performance;TCP/IP;FIFO","","35","3","28","","6 Aug 2002","","","IEEE","IEEE Journals"
"Virtual Reality as Cost Effective Tool for Distance Healthcare","R. Papara; R. Galatus; L. Buzura","Technical University of Cluj-Napoca,Memorandumului 28th, Cluj-Napoca,Romania; Technical University of Cluj-Napoca,Memorandumului 28th, Cluj-Napoca,Romania; Technical University of Cluj-Napoca,Memorandumului 28th, Cluj-Napoca,Romania","2020 22nd International Conference on Transparent Optical Networks (ICTON)","22 Sep 2020","2020","","","1","6","VR can provide a rich, interactive environment in distance assisted actions for serious games in healthcare. The location-based decisions can be transferred for distance-based assisted decisions, when the specialists cannot be present in time at the probe/case location. The specialists can consult at distance, a probe in the real lab, by using images that are taken with high resolution cameras and that are sent over the internet. In advanced healthcare the virtual environment is conducted by a surgeon and decision is transmitted to a robotic instrument that mimics the actions. In this case the cost effective solution refers to regular healthcare activity such as visual assisted diagnosis in real time, training of the specialists, assessing a situation and give an expert opinion on it, future actions and treatment. The advancement in technology allowed VR systems to run on personal computers thus decreasing the implementation cost for a sophisticated system. In the present implementation, a cost-effective solution is presented. The solution is easy to use by the medical specialists and is helpful to compensate the time-delay for the doctor mobility at the probe/case location. A user-friendly interface was developed in order to facilitate the communication between a specialist in the lab and the expert at distance, using the immersive technology of VR, in order to replicates an environment via computer-simulated reality.","2161-2064","978-1-7281-8423-4","10.1109/ICTON51198.2020.9203420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9203420","virtual reality;interface for communication;camera distance-assisted diagnosis;smartphone assisted;real time transmission;healthcare","Medical services;Glass;Webcams;Software;Probes;Robots","health care;Internet;virtual reality","virtual reality;cost effective tool;distance healthcare;interactive environment;distance assisted actions;serious games;location-based decisions;distance-based assisted decisions;high resolution cameras;virtual environment;surgeon;robotic instrument;regular healthcare activity;visual assisted diagnosis;VR systems;implementation cost;cost-effective solution;time-delay;computer-simulated reality","","","","11","","22 Sep 2020","","","IEEE","IEEE Conferences"
"Driver's gaze zone estimation by transfer learning","I. R. Tayibnapis; M. Choi; S. Kwon","DGIST, Daegu, Republic of Korea; DGIST, Daegu, Republic of Korea; DGIST, Daegu, Republic of Korea","2018 IEEE International Conference on Consumer Electronics (ICCE)","29 Mar 2018","2018","","","1","5","Estimating driver's gaze zone has very important role to support advanced driver assistant system (ADAS). The gaze estimation can monitor the driver focus and indirectly control the user interface/user experience (UI/UX) on a windshield using augmented reality-head up display (AR-HUD). However, to train gaze zone estimator as a classification task, someone pays huge costs to gather a large amount of annotated dataset. To reduce the labor work, we used a transfer-learning method using pre-trained CNN model to project the gaze estimation task by regression on mobile devices that have large and reliable dataset into new classification task to overcome lack of annotated dataset for gaze zone estimation. We tested the proposed method to our own building simulation test bed. The result is shown in validation accuracy around 99.01 % and test accuracy with unseen driver around 60.25 % for estimating 10 gaze zones in-vehicle.","2158-4001","978-1-5386-3025-9","10.1109/ICCE.2018.8326308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8326308","","Estimation;Tablet computers;Support vector machines;Automobiles;Mobile handsets;Feature extraction","augmented reality;driver information systems;gaze tracking;head-up displays;human computer interaction;learning (artificial intelligence);mobile computing;motion estimation;neural nets;pattern classification;regression analysis;traffic engineering computing;user interfaces","transfer learning;advanced driver assistant system;augmented reality-head up display;gaze zone estimator;classification task;user interface;user experience;driver gaze zone estimation;pre-trained CNN model;regression;mobile devices","","","","16","","29 Mar 2018","","","IEEE","IEEE Conferences"
"SSVEP Stimulus Layout Effect on Accuracy of Brain-Computer Interfaces in Augmented Reality Glasses","X. Zhao; C. Liu; Z. Xu; L. Zhang; R. Zhang","School of Information Engineering, Zhengzhou University, Zhengzhou, China; School of Information Engineering, Zhengzhou University, Zhengzhou, China; Henan Key Laboratory of Brain Science and Brain–Computer Interface Technology, School of Electrical Engineering, Zhengzhou University, Zhengzhou, China; Henan Key Laboratory of Brain Science and Brain–Computer Interface Technology, School of Electrical Engineering, Zhengzhou University, Zhengzhou, China; Henan Key Laboratory of Brain Science and Brain–Computer Interface Technology, School of Electrical Engineering, Zhengzhou University, Zhengzhou, China","IEEE Access","13 Jan 2020","2020","8","","5990","5998","Steady-state visual evoked potentials-based brain-computer interfaces (SSVEP-BCI) has the advantage of high information transfer rate (ITR) and little user training, and it has a high application value in the field of disability assistance and human-computer interaction. Generally SSVEP-BCI requires a personal computer screen (PC) to display several repetitive visual stimuli for inducing the SSVEP response, which reduces its portability and flexibility. Using augmented reality (AR) glasses worn on the head to display the repetitive visual stimuli could solve the above drawbacks, but whether it could achieve the same accuracy as PC screen in the case of reduced brightness and increased interference is unknown. In current study, we firstly designed 4 stimulus layouts and displayed them with Microsoft HoloLens (AR-SSVEP) glasses, comparison analysis showed that the classification accuracies are influenced by the stimulus layout when the stimulus duration is less than 3s. When the stimulus duration exceeds 3s, there is no significant accuracy difference between the 4 layouts. Then we designed a similar experimental paradigm on PC screen (PC-SSVEP) based on the best layout of AR. Classification results showed that AR-SSVEP achieved similar accuracy with PC-SSVEP when the stimulus duration is more than 3s, but when the stimulus duration is less than 2s, the accuracy of AR-SSVEP is lower than PC-SSVEP. Brain topological analysis indicated that the spatial distribution of SSVEP responses is similar, both of which are strongest in the occipital region. Current study indicated that stimulus layout is a key factor when building SSVEP-BCI with AR glasses, especially when the stimulation time is short.","2169-3536","","10.1109/ACCESS.2019.2963442","National Natural Science Foundation of China; Key Project at Central Government Level; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8947980","Steady-state visual evoked potentials (SSVEP);brain–computer interfaces (BCI);augmented reality (AR);optical see-through (OST);human–computer interaction","Layout;Glass;Visualization;Electroencephalography;Correlation;Microsoft Windows;Brain-computer interfaces","augmented reality;brain;brain-computer interfaces;electroencephalography;glass;handicapped aids;medical signal processing;neurophysiology;visual evoked potentials","SSVEP stimulus layout effect;augmented reality glasses;steady-state visual evoked potentials-based brain-computer interfaces;high information transfer rate;high application value;disability assistance;human-computer interaction;personal computer screen;repetitive visual stimuli;SSVEP response;PC screen;classification accuracies;stimulus duration;significant accuracy difference;PC-SSVEP;AR-SSVEP achieved similar accuracy;brain topological analysis;building SSVEP-BCI;stimulus layouts;time 3.0 s;time 2.0 s","","","","45","CCBY","1 Jan 2020","","","IEEE","IEEE Journals"
"Language therapy of aphasia supported by augmented reality applications","D. Antkowiak; C. Kohlschein; R. Krooß; M. Speicher; T. Meisen; S. Jeschke; C. J. Werner","RWTH Aachen University, Institute of Information Management in Mechanical Engineering, Aachen, Germany; RWTH Aachen University, Institute of Information Management in Mechanical Engineering, Aachen, Germany; Bitstars GmbH, Aachen, Germany; Bitstars GmbH, Aachen, Germany; RWTH Aachen University, Institute of Information Management in Mechanical Engineering, Aachen, Germany; RWTH Aachen University, Institute of Information Management in Mechanical Engineering, Aachen, Germany; Department of Neurology, University Hospital RWTH Aachen, Aachen, Germany","2016 IEEE 18th International Conference on e-Health Networking, Applications and Services (Healthcom)","21 Nov 2016","2016","","","1","6","In Europe there are more than 580 000 people who suffer from aphasia - an acquired speech and language disorder that occurs because of brain damage, primarily as a result of a stroke. Especially with regards to demographic change, health care systems have to face present and future challenges to improve aphasia therapy. Thereby, immediate therapeutic measures are decisive for best possible and long-term success in language therapy. Regarding essential requirements, on the one hand, therapy intensity and frequency have to be increased significantly while on the other hand, measures need to be adjusted along everyday activities. A very promising approach to meet this requirements are augmented reality applications. They can be used to create a highly natural exercise situation, in which patients interact and practice with their personal possessions at home. This facilitates the successful and continuous transfer of learnings for the patient, contrary to being solely dependent on clinical therapy units. This paper gives an overview of the concept of a real-time software providing augmented and dynamic language therapy, which is interactive and utilizes simple user interface design, for home-based training.","","978-1-5090-3370-6","10.1109/HealthCom.2016.7749511","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7749511","Aphasia therapy;augmented reality;therapy frequency;speech recognition;3D scanning;3D tracking","Medical treatment;Augmented reality;Training;Context;Speech;Cognition","augmented reality;brain;medical computing;medical disorders;patient treatment","aphasia language therapy;augmented reality applications;language disorder;speech disorder;brain damage;stroke;real-time software;dynamic language therapy;user interface design;home-based training","","3","","42","","21 Nov 2016","","","IEEE","IEEE Conferences"
"Incision Sensor Using Conductive Tape for Cricothyrotomy Training Simulation With Quantitative Feedback","B. Ahn; W. Choi; M. P. Ottensmeyer; H. Jung","Robotics Research and Development Group, Korea Institute of Industrial Technology, Ansan-si, South Korea; Robotics Research and Development Group, Korea Institute of Industrial Technology, Ansan-si, South Korea; Department of Radiology, Medical Device and Simulation Laboratory, Massachusetts General Hospital, Cambridge, MA, USA; Department of Mechanical Engineering, Konkuk University, Seoul, South Korea","IEEE Access","5 Feb 2019","2019","7","","12947","12958","Cricothyrotomy procedures, involving risky incisions on the neck skin and internal membranes, require rigorous training. In this paper, a novel incision sensor measuring the incision path in a cricothyrotomy training simulation is proposed. The sensor provides quantitative feedback to trainees on their incision practice, enhancing the effectiveness of the simulation. The sensor measures the electric potential, which decreases monotonically along the direction of current flow on the conductive material at the incision point, and converts it to coordinate values, based on the relationship between the electric potential and the position. The sensor comprises three layers of conductive tape, which are electrically isolated by two dielectric layers, and is fabricated as a thin film. The first two conductive layers (driving layers) are alternately energized to create distributions of electric potential in the x or y directions across the sensor plane. The third conductive layer (sensing layer), placed under the driving layers, transfers the electric potential to the output channel of the sensor at the point where a metal blade creates a short circuit between the energized driving layer and the sensing layer. The alternating measurements are converted to x and y coordinates of the incision position. The experiments for characterization and performance validation were performed using sensor prototypes fabricated with the proposed design and fabrication procedures. The experimental results show that the proposed sensor facilitates the measurement of the incision paths aligned with and diagonal to the x andy axes within root mean square errors of 0.98 and 1.03 mm, respectively.","2169-3536","","10.1109/ACCESS.2019.2891958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8607980","Conductive tape;cricothyrotomy simulation;incision sensor;medical simulation","Electric potential;Training;Skin;Robot sensing systems;Electrodes;Coordinate measuring machines","biological techniques;biomedical transducers;blades;computerised instrumentation;conducting materials;dielectric materials;electric potential;electric variables measurement;mean square error methods;medical computing;membranes;thin film sensors","conductive tape;cricothyrotomy training simulation;quantitative feedback;cricothyrotomy procedures;conductive material;dielectric layers;conductive layer;sensing layer;energized driving layer;electric potential measurement;incision sensor;membranes;incision path measurement;thin film fabrication;electric potential distribution;metal blade;root mean square errors","","1","","28","","10 Jan 2019","","","IEEE","IEEE Journals"
"Transferring bioelasticity knowledge through haptic interaction","M. Nakao; K. Minato; T. Kuroda; M. Komori; H. Oyama; T. Takahashi","Nara Inst. of Sci. & Technol., Japan; Nara Inst. of Sci. & Technol., Japan; NA; NA; NA; NA","IEEE MultiMedia","7 Aug 2006","2006","13","3","50","60","This study establishes a practical environment for transferring knowledge on bioelasticity between expert and trainee medical practitioners. Through haptic interaction with a deformable virtual anatomical model, experts set the model's elasticity conditions by simulating a surgical procedure. Trainees experience the elasticity by attempting the same surgical manipulation","1941-0166","","10.1109/MMUL.2006.70","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1667976","computer-assisted instruction;physically based modeling;virtual reality;life and medical sciences","Haptic interfaces;Elasticity;Biomedical imaging;Deformable models;Medical simulation;Surgery;Education;Diseases;Surges;Hospitals","computer based training;haptic interfaces;medical computing;physiological models;surgery;virtual reality","bioelasticity knowledge transfer;haptic interaction;medical training;deformable virtual anatomical model;surgery simulation","","12","","23","","7 Aug 2006","","","IEEE","IEEE Magazines"
"Towards automatic generation of multimodal AR-training applications and workflow descriptions","T. Engelke; S. Webel; U. Bockholt; H. Wuest; N. Gavish; F. Tecchia; C. Preusche","Fraunhofer IGD, Germany; Fraunhofer IGD, Germany; Fraunhofer IGD, Germany; Fraunhofer IGD, Germany; Technion-Israel, Institute of Technology, Israel; PERCRO - Scuola Superiore Sant'Anna, Italy; German Aerospace Center (DLR), Germany","19th International Symposium in Robot and Human Interactive Communication","11 Oct 2010","2010","","","434","439","Augmented Reality (AR) is a technology which has become very popular in the last years. In this context also the idea of using of AR for training applications has become very important. AR offers a large potential for training only if the training is well focused to the skills that have to be trained and if the training protocol is well designed. On the other hand, the generation of the training content to be transferred via AR is a comprehensive problem that is addressed in this paper. Thus, this paper tries to describe the whole chain of implementations and general aspects involved in the creation of AR training applications, including examples for used multimodal devices. This chain starts with the capturing of expert actions to be hold in the ""digital representation of skill"". The digital representation of skill is transferred to the training protocol that specifies the storyboard of the AR training session. The paper includes two different implementations of AR training systems and describes the general idea of informational abstraction from low level data up to interaction and from design to application.","1944-9437","978-1-4244-7990-0","10.1109/ROMAN.2010.5598613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5598613","","Training;Augmented reality;Protocols;Assembly;Solid modeling;Haptic interfaces;Maintenance engineering","augmented reality;computer aided instruction","multimodal AR-training applications;workflow descriptions;augmented reality;training protocol;digital representation","","2","","21","","11 Oct 2010","","","IEEE","IEEE Conferences"
"Exploiting Transfer Learning for Emotion Recognition Under Cloud-Edge-Client Collaborations","D. Wu; X. Han; Z. Yang; R. Wang","Chongqing Key Laboratory of Optical Communication and Networks, Chongqing Key Laboratory of Ubiquitous Sensing and Networking, School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Optical Communication and Networks, Chongqing Key Laboratory of Ubiquitous Sensing and Networking, School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Optical Communication and Networks, Chongqing Key Laboratory of Ubiquitous Sensing and Networking, School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China","IEEE Journal on Selected Areas in Communications","14 Jan 2021","2021","39","2","479","490","Emerging virtual reality/augmented reality games and self-driving cars necessitate accurate/responsive/private emotion recognition. Usually, traditional emotion recognition models are deployed at central servers, which results in the lack of abilities in generalization and covering the individual variation of clients. This paper proposes a responsive, localized, and private transfer learning based emotion recognition framework under the cloud-edge-client collaborations. Additionally, a 3-dimensional channel mapping method is designed to aggregate features extracted from electroencephalogram (EEG) signals for the generic emotion recognition model, which is further localized and personalized using transfer learning. Simulation results validate the performance of the proposed TLER framework in reducing model training time and improving emotion recognition accuracy.","1558-0008","","10.1109/JSAC.2020.3020677","National Natural Science Foundation of China; Science and Technology Research Program of Chongqing Municipal Education Commission; Natural Science Foundation of Chongqing of China; Science and Technology Research Program of Chongqing Municipal Education Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187207","Electroencephalogram;emotion recognition;transfer learning;cloud-edge-client collaboration","Brain modeling;Emotion recognition;Electroencephalography;Feature extraction;Machine learning;Collaboration;Scalp","augmented reality;cloud computing;computer games;electroencephalography;emotion recognition;feature extraction;learning (artificial intelligence);medical signal processing","cloud-edge-client collaborations;self-driving cars;3-dimensional channel mapping;responsive transfer learning based emotion recognition;localized transfer learning based emotion recognition;private transfer learning based emotion recognition;electroencephalogram signals;feature extraction;TLER framework;virtual reality-augmented reality games","","1","","43","IEEE","7 Sep 2020","","","IEEE","IEEE Journals"
"Component based video communication tool for collaborative virtual environment","H. Sakamoto; Y. Okada; T. Shimokawa; K. Ushijima","Graduate Sch. of Inf. Sci. & Electr. Eng., Kyushu Univ., Fukuoka, Japan; NA; NA; NA","Proceedings 15th International Conference on Information Networking","7 Aug 2002","2001","","","375","380","This paper treats a component based video communication tool for collaborative virtual environments. Especially the authors propose a new concept and its realization mechanisms for easy construction of distributed 3D graphics applications using video communications, e.g., network meeting, conference, and training in a 3D virtual space. If a software component is represented as a visible, manually operable object, users can make its copy and transfer it to another computer easily and rapidly. If a facility that manages video/audio data is realized as such a object, even end-users can easily and rapidly build networked video communication environments through the copy-and-transfer operation. To clarify an availability of this concept, the authors employ the IntelligentBox system as a research platform. The authors introduced a video communication facility as a software component into the IntelligentBox system. IntelligentBox has provided a network communication facility as a software component. Using these components, it will be possible to build collaborative virtual environments, which support video communications, through copy-and-transfer operations.","","0-7695-0951-7","10.1109/ICOIN.2001.905454","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=905454","","Collaborative tools;Videoconference;Intelligent systems;Virtual environment;Computer graphics;Application software;Management training;Communication system operations and management;Computer network management;Environmental management","visual communication;virtual reality;groupware;computer graphics;information networks","component based video communication tool;collaborative virtual environment;distributed 3D graphics applications;network meeting;conference;training;3D virtual space;visible manually operable object;video/audio data management;networked video communication environments;copy-and-transfer operation;IntelligentBox system;research platform;information network technologies;broadband networks","","1","","11","","7 Aug 2002","","","IEEE","IEEE Conferences"
"Simulating asynchronous, decentralized military command and control","T. Lee; S. Ghosh","Arizona State Univ., AZ, USA; NA","IEEE Computational Science and Engineering","6 Aug 2002","1996","3","4","69","79","The pace and scope of modern warfare have made some aspects of traditional, centralized decision making obsolete. A decentralized scheme grants greater autonomy to fighting units, which process data locally for efficient decision making. In experimental simulations using a decentralized algorithm, units react to information faster in both offensive and defensive scenarios. We used asynchronous, distributed, discrete event simulation techniques to model the command and control problem. These algorithms are appropriate for problems involving discrete data transfer, geographically dispersed decision making entities, asynchronously generated stimuli, and data feedback. To compare our algorithm with traditional algorithms and identify scenarios for which it is effective, we used a loosely coupled parallel processor as a simulation testbed. To the best of our knowledge, this research is the first attempt to scientifically model decentralized C/sup 3/ and assess its performance through extensive parallel simulation. State-of-the-art battlefield simulators such as Simnet and CATT provide training environments in which human operators make the decisions. In contrast, our testbed provides an automated environment for fast, efficient, accurate warfare modeling. By ""accurate"" we mean spatial and timing resolution; we do not claim to represent all battlefield details, such as terrain.","1558-190X","","10.1109/99.556514","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=556514","","Command and control systems;Decision making;Discrete event simulation;Feedback;Humans;Automatic testing;Timing;Spatial resolution","command and control systems;discrete event simulation;distributed algorithms;parallel programming;computer based training;computer aided instruction","asynchronous decentralized military command and control simulation;modern warfare modelling;decentralized scheme;fighting units;decision making;experimental simulations;decentralized algorithm;defensive scenarios;discrete event simulation techniques;discrete data transfer;geographically dispersed decision making entities;asynchronously generated stimuli;data feedback;loosely coupled parallel processor;simulation testbed;decentralized C/sup 3/;parallel simulation;battlefield simulators;Simnet;CATT;automated environment;training environments","","5","","9","","6 Aug 2002","","","IEEE","IEEE Magazines"
"Motor learning of the upper limb in children with cerebral palsy after virtual and physical training intervention","M. T. Robert; R. Guberek; M. F. Levin; H. Sveistrup","Integrated Program of Neuroscience, School of P & OT, and Feil/Oberfeld/CRIR Research Centre, McGill University and Jewish Rehabilitation Hospital, Montreal, Canada; Integrated Program of Neuroscience, School of P & OT, and Feil/Oberfeld/CRIR Research Centre, McGill University and Jewish Rehabilitation Hospital, Montreal, Canada; Integrated Program of Neuroscience, School of P & OT, and Feil/Oberfeld/CRIR Research Centre, McGill University and Jewish Rehabilitation Hospital, Montreal, Canada; Faculty of Health Sciences, University of Ottawa, Ottawa, Canada","2013 International Conference on Virtual Rehabilitation (ICVR)","14 Nov 2013","2013","","","194","195","Evidence for improvement and retention of upper limb kinematics in children with cerebral palsy (CP) is scarce especially following training interventions using virtual environments. Children with CP were randomly allocated to one of two groups: task-oriented training with or without trunk restraint. For both groups, training was done in both virtual and physical environments. Motor improvements were retained 3 months after the intervention and transferred to a similar task. Sensory status was related to learning and retention of kinematics. Training in combined virtual and physical environments led to learning and retention of movement patterns in children with CP.","2331-9569","978-1-4799-0774-8","10.1109/ICVR.2013.6662125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6662125","Cerebral Palsy;Motor learning;Upper limb","Training;Kinematics;Virtual environments;Educational institutions;Pediatrics;Games;Motor drives","medical computing;patient rehabilitation;virtual reality","motor learning;upper limb learning;children with cerebral palsy;virtual training intervention;physical training intervention;upper limb kinematics;virtual environments;task-oriented training;trunk restraint;sensory status;kinematics learning;kinematics retention","","1","","7","","14 Nov 2013","","","IEEE","IEEE Conferences"
"Perceptually augmented simulator design through decomposition","T. Edmunds; D. K. Pai","Rutgers University, USA; University of British Columbia, USA","World Haptics 2009 - Third Joint EuroHaptics conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems","3 Apr 2009","2009","","","505","510","We approach the problem of determining a general method for augmenting haptic simulators to amplify the perceptually salient aspects of the interaction that induce effective skill transfer. Using such a method, we seek to simplify the design of haptic simulators that can improve training effectiveness without requiring expensive improvements in the capability of the rendering hardware. We present a decomposition approach to the automated design of perceptually augmented simulations, and we describe a user-study of the training effectiveness of a search-task simulator designed using our approach vs. an un-augmented simulator. The results indicate that our decomposition approach allows existing psychophysical findings to be leveraged in the design of haptic simulators that effectively impart skill by targeting perceptually significant aspects of the interaction.","","978-1-4244-3858-7","10.1109/WHC.2009.4810890","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810890","","Haptic interfaces;Engines;Shape;Analytical models;Surface texture;Hardware;Surgery;Jamming;Virtual environment;Teleoperators","augmented reality;haptic interfaces;rendering (computer graphics)","perceptually augmented simulator design;haptic simulators augmentation;rendering hardware;search-task simulator","","1","","14","","3 Apr 2009","","","IEEE","IEEE Conferences"
"Expert user validation of transplant management procedure simulations","B. Borro-Escribano; J. Torrente; A. del Blanco; B. Fernandez-Manjon; I. Martinez-Alpuente; R. Matesanz","Department of Software Engineering and Artificial Intelligence, Complutense University of Madrid Madrid, Spain; Department of Software Engineering and Artificial Intelligence, Complutense University of Madrid Madrid, Spain; Department of Software Engineering and Artificial Intelligence, Complutense University of Madrid Madrid, Spain; Department of Software Engineering and Artificial Intelligence, Complutense University of Madrid Madrid, Spain; Organización Nacional de Trasplantes (ONT) Madrid, Spain; Organización Nacional de Trasplantes (ONT) Madrid, Spain","2014 IEEE 3nd International Conference on Serious Games and Applications for Health (SeGAH)","26 Mar 2015","2014","","","1","8","The Spanish National Transplant Organization (ONT) in collaboration with the e-UCM research group of the Complutense University of Madrid has developed three screen-based simulations representing the ONT supra-hospital deceased donation management processes. As the ONT is using these game-like simulations as a support tool for its instructional approach, it was necessary to perform a validation of these simulations to assure the knowledge had been correctly represented. This paper describes the methodology followed to validate and estimate how accurately this ONT complex knowledge has been captured (including some tacit knowledge used by the transplant coordination experts) and transferred into these screen-based simulations. We present the results obtained from the validation done with 15 ONT experts and how their feedback was used to improve the simulations.","","978-1-4799-4823-9","10.1109/SeGAH.2014.7067099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7067099","knowledge validation;screen-based simulation;transplant procedure","Games;Usability;Interviews;Computational modeling;Hospitals;Training","computer aided instruction;computer games;digital simulation;expert systems;hospitals;knowledge representation;medical computing;user interfaces","expert user validation;transplant management procedure simulation;Spanish National Transplant Organization;e-UCM research group;screen-based simulation;ONT suprahospital deceased donation management process game-like simulation;instructional approach;knowledge representation","","1","","26","","26 Mar 2015","","","IEEE","IEEE Conferences"
"An assessment of resource exploitation using artificial intelligence based traffic control strategies","V. Catania; G. Ficili; D. Panno","Ist. di Inf. e Telecommun., Catania Univ., Italy; NA; NA","Proceedings Second IEEE Symposium on Computer and Communications","6 Aug 2002","1997","","","162","166","We assess the application of artificial intelligence techniques to the complex problem of traffic control in ATM networks. The paper deals with the close link between call admission control and usage parameter control and proposes a simulation-based analysis to demonstrate how inefficiency on the part of policing affects bandwidth allocation. To take this into account, the paper proposes a framework for traffic control in which the CAC and policing functions are both based on artificial intelligence techniques, i.e. neural networks and fuzzy logic. In this way it is possible to train the neural network in such a way as to take into account the real behavior of the policer. As the results obtained show this allows us to implement traffic management strategies which can improve the exploitation of network resources.","","0-8186-7852-6","10.1109/ISCC.1997.615989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=615989","","Artificial intelligence;Traffic control;Communication system traffic control;Asynchronous transfer mode;Neural networks;Telecommunication traffic;Call admission control;Fuzzy logic;Resource management;Quality of service","asynchronous transfer mode;learning (artificial intelligence);neural nets;telecommunication computing;telecommunication congestion control;telecommunication traffic;fuzzy logic;telecommunication network management;digital simulation;simulation","resource exploitation;artificial intelligence based traffic control;ATM networks;call admission control;usage parameter control;simulation based analysis;bandwidth allocation;policing;neural networks;fuzzy logic;neural network training;traffic management;network resources;performance degradation","","","3","8","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Mapping distributed interactive simulation network requirements onto broadband networks and services","T. L. Gehl","IBM, Federal Syst. Co., USA","Proceedings of ICC/SUPERCOMM'94 - 1994 International Conference on Communications","6 Aug 2002","1994","","","154","159 vol.1","Just imagine, being able to immerse yourself into a virtual world where you could see the results of your actions with respect to other realistic entities (i.e. people, machines, environments) in a particular scenario. Then, imagine the expansion of this virtual world through the interaction of real-time distributed simulations. This interaction of real-time distributed simulations could greatly enhance education and training, operational verification of design, and mission rehearsal functions needed to support the defense and commercial industries. Through the advancements in technologies (i.e. visual systems, host processors, databases, and networks), we can now realize the expectations of this virtual world. This paper addresses the network requirements for a federal government initiative called Distributed Interactive Simulation (DIS). Through our discussion of the DIS environment, we will identify the services and performance capabilities required of advanced network architectures, and relate these requirements to the proposed capabilities of the standard-based broadband technologies of asynchronous transfer mode (ATM) and synchronous optical network (SONET). We map the DIS network requirements to the capabilities inherent to these broadband technologies, and specify the access of those capabilities from the DIS application through the broadband network and services.<>","","0-7803-1825-0","10.1109/ICC.1994.369004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=369004","","Broadband communication;Computational modeling;Computer simulation;Protocols;Distributed computing;Application software;Industrial training;Visual databases;Asynchronous transfer mode;Space technology","B-ISDN;asynchronous transfer mode;SONET;digital simulation;telecommunication computing;interactive systems","distributed interactive simulation;broadband networks;broadband services;real-time distributed simulations;federal government initiative;performance;network architectures;asynchronous transfer mode;synchronous optical network;ATM;SONET;B-ISDN","","","","2","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Maintenance of Complex Machines in Electric Power Systems Using Virtual Reality Techniques","B. Arendarski; W. Termath; P. Mecking","Fraunhofer Institute for Factory Operation and Automation (IFF), Sandtorstrasse 22, 39106 Magdeburg, Germany. bartlomiej.arendarski@iff.fraunhofer.de; Fraunhofer Institute for Factory Operation and Automation (IFF), Sandtorstrasse 22, 39106 Magdeburg, Germany; RWE Rhein-Ruhr-Netzservice GmbH, Reeser Landstrasse 41, 46483 Wesel, Germany","Conference Record of the 2008 IEEE International Symposium on Electrical Insulation","18 Jul 2008","2008","","","483","487","This paper illustrates how virtual reality (VR) techniques can be used in electric power systems visualization and how this can increase effectiveness of vocational training in field of power industry. The content of this article is based on a project oriented to specialized staff members, dealing with maintenance, repairs and diagnostics of complex machines such transformers and generators. Introducing a scheme that integrates VR technologies to electrical machines and equipment provides an efficient tool for implementing operator training methods. Three-dimensional (3D) visualization brings a new ways of knowledge transfer and education regarding complex equipment.","1089-084X","978-1-4244-2091-9","10.1109/ELINSL.2008.4570378","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4570378","","Virtual reality;Vocational training;Industrial training;Visualization;Transformers;Power system planning;Design engineering;Computational modeling;Testing;Power system modeling","electric generators;power systems;transformers;virtual reality","electric power systems;virtual reality;complex machines maintenance;power industry;transformers;generators;3D visualization","","17","","10","","18 Jul 2008","","","IEEE","IEEE Conferences"
"Games and Learning Alliance (GaLA) Supporting Education and Training through Hi-Tech Gaming","F. Bellotti; R. Berta; A. De Gloria","Dynatech - Dept. of Naval, Electr. & Inf. Technol. Eng., Univ. of Genoa, Genoa, Italy; Dynatech - Dept. of Naval, Electr. & Inf. Technol. Eng., Univ. of Genoa, Genoa, Italy; Dynatech - Dept. of Naval, Electr. & Inf. Technol. Eng., Univ. of Genoa, Genoa, Italy","2012 IEEE 12th International Conference on Advanced Learning Technologies","16 Aug 2012","2012","","","740","741","Games and Learning Alliance (GaLA) is the EU Network of Excellence on serious games (SG). The main expected outcome is the set-up a Virtual Research Centre (VRC) aimed at integrating, harmonizing and coordinating research on SGs and disseminating knowledge, best practices and tools as a reference point at an international level. The other two key focuses of the project are (1) the support to deployment in the actual educational and training settings and (2) the fostering of innovation and knowledge transfer through research-business dialogue. The NoE is composed of organizations that aim to integrate their activities and resources in a long-term view. A long-term perspective is systematically pursued as GaLA sets-up an infrastucture and aims at making it viable and sustainable. The major expected outcomes include: the European Society on Serious Games; the European conference on Serious Games; journal special issues; the Virtual Research Environment (VRE); the SG Living Labs (SG LLs); a MSc programme on SGs, with the relevant didactic tools; PhD projects on SGs; the schools (alignment and summer) on SGs.","2161-377X","978-1-4673-1642-2","10.1109/ICALT.2012.146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6268245","Serious Games;Technology Enhanced Learning;Virtual Research Environment;Virtual research Center;Living Labs","Games;Europe;Educational institutions;Training;Best practices;Industries;Media","computer aided instruction;computer games;interactive programming;knowledge management;virtual reality","games and learning alliance;serious game;EU network;virtual research centre;VRC;training;knowledge transfer;innovation;research-business dialogue;NoE;GaLA;virtual research environment;SG;VRE;hi-tech game","","7","","2","","16 Aug 2012","","","IEEE","IEEE Conferences"
"Monitoring rehabilitation training for hemiplegic patients by using a tri-axial accelerometer","Y. Higashi; M. Sekimoto; F. Horiuchi; T. Kodama; T. Yuji; T. Fujimoto; M. Sekine; T. Tamura","Fujimoto Hayasuzu Hosp., Miyazaki, Japan; Fujimoto Hayasuzu Hosp., Miyazaki, Japan; Fujimoto Hayasuzu Hosp., Miyazaki, Japan; Fujimoto Hayasuzu Hosp., Miyazaki, Japan; Fujimoto Hayasuzu Hosp., Miyazaki, Japan; Fujimoto Hayasuzu Hosp., Miyazaki, Japan; NA; NA","2001 Conference Proceedings of the 23rd Annual International Conference of the IEEE Engineering in Medicine and Biology Society","7 Nov 2002","2001","2","","1472","1474 vol.2","In rehabilitation training for hemiplegic patients, bed-to-wheelchair transfer is most important and allows a patient's early independence. We developed a monitoring system for transfer training that is quantitative and uses accelerometry. Two tri-axial accelerometers were attached to the subjects, at the head and waist. Subjects were trained in moving from a sitting position to standing, then turning through, about 90 degrees, and then sitting on the bed. The acceleration signals at the two sites were recorded via a multi-telemeter system, converted to a digital signal, and stored in a computer. Data were analysed by LabView and displayed on the computer screen as real time motion. The system can be operated by one staff member, and the patients did not feel restricted. We were able to evaluate the time course of the signals, and phase-plane locus of the vertical, lateral and horizontal directions of the signals. The transfer of hemiplegic patients occurred in two motions: a standing-up motion, and a sitting-down motion. Accordingly, we observed twin peaks in the plot of the original signal. In contrast, healthy volunteers moved smoothly and twin peaks were not present.","1094-687X","0-7803-7211-5","10.1109/IEMBS.2001.1020482","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1020482","","Patient monitoring;Accelerometers;Acceleration;Data analysis;Charge coupled devices;Charge-coupled image sensors;Transmitters;Microcomputers;Computer displays;Telemetry","patient rehabilitation;patient monitoring;accelerometers;biomedical telemetry;data analysis;medical computing;training","rehabilitation training;hemiplegic patients;tri-axial accelerometer;bed-to-wheelchair transfer;patient independence;monitoring system;sitting position;standing;turning;acceleration signals;multi-telemeter system;LabView;real time motion;CCD camera;time course evaluation;phase-plane locus","","1","","2","","7 Nov 2002","","","IEEE","IEEE Conferences"
"Keynote 1: Internet of Things(IoT) and augmented reality for e-learning","N. S. C. Babu",C-DAC Bangalore,"2017 5th National Conference on E-Learning & E-Learning Technologies (ELELTECH)","19 Oct 2017","2017","","","1","10","With the advent of the Internet of Things (IOT) technology, we will be expecting all the smart devices around us to provide various services in real-time. When this IoT technology is combined with Augmented Reality (AR), it will provide end users with real time as well as real world information. One of the prime advantages of AR combining with IoT is the bridging of the gap between the real and digital worlds around us. The ease of downloading features and scope of dynamic usage which AR brings to the smart devices and is expected to bring to the IoT is beyond human imagination! The education sector is expected to gain significantly using these technologies. The goal of technology in education is to make, learning easier, faster and more engaging for the students and to equip the instructor with powerful tools to provide more relevant courseware to their students. With introducing AR in education, we shall be able to provide contextually aware, more relevant, engaging and interactive courseware to the students, which would keep them interested in subject. Also, through IoT, the physical devices can provide context that the AR ecosystem would use for contextually aware rendering of multimedia content. Medical education domain is expected to gain significantly using IOT and AR. It is also observed that the training in the areas of equipment maintenance could gain significantly by applying these technologies judiciously. For eg. The conventional software virtual lab solution does not provide a real feel of performing an experiment. However, using IOT and AR technology, a sensor enabled Hardware based real lab environment can be created for performing the volumetric analysis experiments in chemistry by using WATER instead of Chemicals. C-DAC has developed few AR products in education domain - AR Board, AR Book and AR Game. AR Board is a virtual writing board on which a user can write with a laser pointer. It uses projection based AR Technology by creating a virtual environment for contextual information presentation, and facilitates real-time interaction with the content. AR Book is a standard book that has been instrumented with AR markers printed, which when scanned would show augmented, 3D interactive content, videos, audio and animations contextually, on a printed book, thus adding new dimensionality to it. AR Game is a game based learning mobile application that can be used by students for learning through playing, and for evaluating their knowledge. The technology of these products has been transferred to industry for their further development and proliferation to various educational institutes.","","978-1-5386-1922-3","10.1109/ELELTECH.2017.8074987","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8074987","","","augmented reality;biomedical education;computer aided instruction;computer games;Internet of Things;mobile computing","augmented reality;smart devices;IoT technology;education sector;medical education domain;Internet of Things technology;IoT;e-learning;AR technology;AR board;AR book;AR game;game based learning mobile application","","1","","","","19 Oct 2017","","","IEEE","IEEE Conferences"
"Development of a mathematical model of a train in the energy point of view for the international conference on control, automation and systems 2007 (ICCAS 2007)","Daeki Hong; Hyeongcheol Lee; Jaeho Kwak","Department of Electrical Engineering, Hanyang University, Seoul, Korea; Division of Electrical Control and Instrumentation Biomedical Engineering Hanyang University, Seoul, Korea; Vehicle Dynamics Research Team, Korea Railroad Research Institute, Seoul, Korea","2007 International Conference on Control, Automation and Systems","26 Dec 2007","2007","","","350","355","This paper presents a mathematical model and simulation program of an electric train with regenerative braking system by using Matlab/Simulink in the energy generation, consumption and transfer point of view. This paper also determines the specifications of each component of the electric train by using the developed program. The electric train model and simulation program consist of the speed profile of the electric train, longitudinal dynamics of the electric train, wheel dynamics with brake system, and electric system such as the motor/generator and the energy storage. This paper also provides observation of the energy consumption and regeneration ratios of the energy storage equipped electric train. The simulation results are compared with the test results to verify the simulation program.","","978-89-950038-6-2","10.1109/ICCAS.2007.4406936","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4406936","Electric Train;Energy Saving;Braking Energy;Energy Train Modeling","Mathematical model;Control system synthesis;Automatic control;Automation;Vehicle dynamics;Energy storage;Energy consumption;Rail transportation;Automatic generation control;Electronic mail","brakes;digital simulation;electric vehicles;mathematics computing;power consumption;railway engineering;regenerative braking;wheels","electric train model;simulation program;mathematical model;Matlab/Simulink;energy generation;energy consumption;energy transfer;longitudinal dynamics;wheel dynamics;regenerative braking system","","","1","13","","26 Dec 2007","","","IEEE","IEEE Conferences"
"Effects of mobile AR-enabled interactions on retention and transfer for learning in art museum contexts","Weiquan Lu; Linh-Chi Nguyen; Teong Leong Chuah; Ellen Yi-Luen Do","Keio-NUS CUTE Center, Interactive and Digital Media Institute, National University of Singapore, Singapore; Keio-NUS CUTE Center, Interactive and Digital Media Institute, National University of Singapore, Singapore; Keio-NUS CUTE Center, Interactive and Digital Media Institute, National University of Singapore, Singapore; Keio-NUS CUTE Center, Interactive and Digital Media Institute, National University of Singapore, Singapore","2014 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design (ISMAR-MASH'D)","27 Oct 2014","2014","","","3","11","In this paper, we describe an experiment to study the effect of mobile Augmented Reality (AR) on learning in art museum contexts. We created six original paintings and placed them in a mini art museum. We then created an AR application on the iPad to enable the artist to visually augment each painting by introducing animation. We then measured the ability of the visitors to remember the appearance of the paintings after 24 hours, as well as their ability to objectify the paintings. Experiment results show that while AR does improve retention and transfer of such art information, the benefits of AR are mediated by other factors such as interference from other elements of the exhibition, as well as subjects' own prior art experience and training. The use of AR may also produce unexpected benefits, such as providing users with a new perspective of the artwork, as well as increasing their curiosity and encouraging them to experiment with the technology. Such benefits may potentially improve the chances for learning and analytical activities to take place.","2381-8360","978-1-4799-6887-9","10.1109/ISMAR-AMH.2014.6935432","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6935432","Evaluation;Learning;Museums;Software","Painting;Art;Tablet computers;Animation;Protocols;Context;Training","augmented reality;computer aided instruction;computer animation;mobile computing;museums","mobile AR enabled interaction;augmented reality;art museum context;learning;mini art museum;iPad;animation;art experience;art training","","2","","19","","27 Oct 2014","","","IEEE","IEEE Conferences"
"A Deep Cybersickness Predictor Based on Brain Signal Analysis for Virtual Reality Contents","J. Kim; W. Kim; H. Oh; S. Lee; S. Lee",Yonsei University; Yonsei University; Electronics & Telecommunications Research Institute; Yonsei University; Yonsei University. Korea,"2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","10579","10588","What if we could interpret the cognitive state of a user while experiencing a virtual reality (VR) and estimate the cognitive state from a visual stimulus? In this paper, we address the above question by developing an electroencephalography (EEG) driven VR cybersickness prediction model. The EEG data has been widely utilized to learn the cognitive representation of brain activity. In the first stage, to fully exploit the advantages of the EEG data, it is transformed into the multi-channel spectrogram which enables to account for the correlation of spectral and temporal coefficient. Then, a convolutional neural network (CNN) is applied to encode the cognitive representation of the EEG spectrogram. In the second stage, we train a cybersickness prediction model on the VR video sequence by designing a Recurrent Neural Network (RNN). Here, the encoded cognitive representation is transferred to the model to train the visual and cognitive features for cybersickness prediction. Through the proposed framework, it is possible to predict the cybersickness level that reflects brain activity automatically. We use 8-channels EEG data to record brain activity while more than 200 subjects experience 44 different VR contents. After rigorous training, we demonstrate that the proposed framework reliably estimates cognitive states without the EEG data. Furthermore, it achieves state-of-the-art performance comparing to existing VR cybersickness prediction models.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.01068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010856","","Electroencephalography;Brain modeling;Spectrogram;Visualization;Predictive models;Solid modeling;Feature extraction","cognition;convolutional neural nets;electroencephalography;image sequences;medical image processing;recurrent neural nets;video signal processing;virtual reality","VR video sequence;recurrent neural network;cognitive representation;visual features;cognitive features;cybersickness level;brain activity;8-channels EEG data;cognitive state;deep cybersickness predictor;brain signal analysis;virtual reality contents;visual stimulus;VR cybersickness prediction model;multichannel spectrogram;spectral coefficient;temporal coefficient;convolutional neural network;electroencephalography;EEG spectrogram","","7","","32","","27 Feb 2020","","","IEEE","IEEE Conferences"
"Disaster Management Simulation and research integration's Virtual Test Bed proposal for The Chilean National Research Center for Integrated Natural Disaster Management (CIGIDEN)","A. Vásquez; L. F. Robledo","Department of Computer Science, Pontificia Universidad Catolica de Chile, Santiago, CHILE; Department of Engineering Science, Universidad Andres Bello, Santiago, CHILE","2016 Winter Simulation Conference (WSC)","19 Jan 2017","2016","","","3028","3039","The Chilean National Research Center for Integrated Natural Disaster Management, CIGIDEN, was created in 2011 to develop, integrate, and transfer scientific knowledge to reduce the social consequences of extreme natural events. As one of its transfer products, CIGIDEN created a Disaster Management Simulation Lab (DMSLab) to deliver a practical training solution for disaster management. We propose a Virtual Test Bed to support the DMSLab by providing a simulation based, multi-disciplinary risk analysis platform. It will strengthen CIGIDEN's transfer and research integration capabilities, offering the tools and methodologies already being developed by the Center for emergency-based decision-making, optimization through simulation and humanitarian aid. A case study of a virtual disaster scenario developed with the Chilean National Emergency Office (ONEMI) is presented, to illustrate how the Virtual Test Bed can support research application in real scenarios.","1558-4305","978-1-5090-4486-3","10.1109/WSC.2016.7822337","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822337","","Training;Disaster management;Decision making;Protocols;Emergency services;Optimization;Organizations","decision making;digital simulation;emergency management;knowledge management;risk analysis;virtual instrumentation","Chilean National Research Center for Integrated Natural Disaster Management;CIGIDEN;scientific knowledge transfer;scientific knowledge development;social consequences;extreme natural events;Disaster Management Simulation Lab;training solution;virtual test bed;DMSLab;simulation based multidisciplinary risk analysis;scientific knowledge integration;emergency-based decision-making optimization;humanitarian aid;Chilean National Emergency Office;ONEMI","","","","43","","19 Jan 2017","","","IEEE","IEEE Conferences"
"On-line simultaneous learning and recognition of everyday activities from virtual reality performances","T. Bates; K. Ramirez-Amaro; T. Inamura; G. Cheng","Institute for Cognitive Systems, Technical University of Munich, Arcisstraße 21, 80333 Munich Germany; Institute for Cognitive Systems, Technical University of Munich, Arcisstraße 21, 80333 Munich Germany; National Institute of Informatics, 2 Chome-2-1-2 Hitotsubashi, Chiyodaku, Tokyo 100-0003, Japan; Institute for Cognitive Systems, Technical University of Munich, Arcisstraße 21, 80333 Munich Germany","2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","14 Dec 2017","2017","","","3510","3515","Capturing realistic human behaviors is essential to learn human models that can later be transferred to robots. Recent improvements in virtual reality (VR) head-mounted displays provide a viable way to collect natural examples of human behavior without the difficulties often associated with capturing performances in a physical environment. We present a realistic, cluttered, VR environment for experimentation with household tasks paired with a semantic extraction and reasoning system able to utilize data collected in real-time and apply ontology-based reasoning to learn and classify activities performed in VR. The system performs continuous segmentation of the motions of users' hands and simultaneously classifies known actions while learning new ones on demand. The system then constructs a graph of all related activities in the environment through its observations, extracting the task space utilized by observed users during their performance. The action recognition and learning system was able to maintain a high degree of accuracy of around 92% while dealing with a more complex and realistic environment compared to earlier work in both physical and virtual spaces.","2153-0866","978-1-5386-2682-5","10.1109/IROS.2017.8206193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8206193","","Motion segmentation;Training;Cognition;Avatars;Semantics","helmet mounted displays;image recognition;learning (artificial intelligence);ontologies (artificial intelligence);virtual reality","virtual reality performances;realistic human behaviors;human models;robots;virtual reality head;human behavior;physical environment;VR environment;household tasks;semantic extraction;reasoning;continuous segmentation;task space;observed users;action recognition;learning system;complex environment;realistic environment;physical spaces;virtual spaces;on-line simultaneous learning","","10","","14","","14 Dec 2017","","","IEEE","IEEE Conferences"
"A Tangible Interface for Learning Recursion and Functional Programming","J. D. T. Vidarte; C. Rinderknecht; J. Kim; H. Kim","Dept. of Adv. Technol. Fusion, Konkuk Univ., Seoul, South Korea; Dept. of Internet & Multimedia Eng., Konkuk Univ., Seoul, South Korea; Dept. of Internet & Multimedia Eng., Konkuk Univ., Seoul, South Korea; Dept. of Internet & Multimedia Eng., Konkuk Univ., Seoul, South Korea","2010 International Symposium on Ubiquitous Virtual Reality","26 Aug 2010","2010","","","32","35","Recursion is a powerful programming technique which is notoriously difficult to master, especially in functional languages because they prominently feature structural recursion as the main control-flow mechanism. We propose several hypotheses to understand the issue and put some to the test by designing an open-source interactive interface based on a tangible block-world with augmented reality and software feedback. Stacks of blocks are used as an analogy for the list data structure, which enables the simplest form of structural recursion. After using this application, students are expected to transfer their training to directly write recursive programs in sequential Erlang, a purely functional language.","","978-1-4244-7702-9","10.1109/ISUVR.2010.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5557937","functional programming;tangible user interface;block world;augmented reality;software feedback","Augmented reality;Visualization;Programming profession;Multimedia communication;Training","augmented reality;data structures;functional programming;program control structures;public domain software;user interfaces","tangible interface;functional programming;control flow mechanism;open source interactive interface;tangible block world;augmented reality;software feedback;data structure;recursive programs;Erlang;sequential Erlang;functional language;structural recursion","","2","","23","","26 Aug 2010","","","IEEE","IEEE Conferences"
"WAVE: Interactive Wave-based Sound Propagation for Virtual Environments","R. Mehra; A. Rungta; A. Golas; M. Lin; D. Manocha",UNC Chapel Hill; UNC Chapel Hill; UNC Chapel Hill; UNC Chapel Hill; UNC Chapel Hill,"IEEE Transactions on Visualization and Computer Graphics","20 Mar 2015","2015","21","4","434","442","We present an interactive wave-based sound propagation system that generates accurate, realistic sound in virtual environments for dynamic (moving) sources and listeners. We propose a novel algorithm to accurately solve the wave equation for dynamic sources and listeners using a combination of precomputation techniques and GPU-based runtime evaluation. Our system can handle large environments typically used in VR applications, compute spatial sound corresponding to listener's motion (including head tracking) and handle both omnidirectional and directional sources, all at interactive rates. As compared to prior wave-based techniques applied to large scenes with moving sources, we observe significant improvement in runtime memory. The overall sound-propagation and rendering system has been integrated with the Half-Life 2 game engine, Oculus-Rift head-mounted display, and the Xbox game controller to enable users to experience high-quality acoustic effects (e.g., amplification, diffraction low-passing, high-order scattering) and spatial audio, based on their interactions in the VR application. We provide the results of preliminary user evaluations, conducted to study the impact of wave-based acoustic effects and spatial audio on users' navigation performance in virtual environments.","1941-0506","","10.1109/TVCG.2015.2391858","Advanced Simulation and Training; ARO Contracts; National Science Foundation; Impulsonic Inc.; Acoustect SDK; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7014276","Sound propagation;dynamic sources;spatial sound;Sound propagation;dynamic sources;directivity;spatial sound;Helmholtz equation","Runtime;Acoustics;Vectors;Transfer functions;Virtual environments;Linear systems;Navigation","acoustic wave propagation;graphics processing units;rendering (computer graphics);virtual reality;wave equations","WAVE;interactive wave-based sound propagation;virtual environments;dynamic sources;wave equation;GPU-based runtime evaluation;VR applications;omnidirectional sources;rendering system;Half-Life 2 game engine;Oculus-Rift head-mounted display;Xbox game controller;high-quality acoustic effects;spatial audio;wave-based acoustic effects;user navigation performance","Acoustic Stimulation;Adult;Algorithms;Computer Graphics;Female;Humans;Male;Sound;User-Computer Interface;Video Games;Young Adult","20","","43","","19 Jan 2015","","","IEEE","IEEE Journals"
"Multimedia tele-surgery using high speed optical fiber network and its application to intravascular neurosurgery - system configuration and computer networked robotic implementation","F. Arai; M. Tanimoto; T. Fukuda; K. Shimojima; H. Matsuura; M. Negoro","Dept. of Micro Syst. Eng., Nagoya Univ., Japan; Dept. of Micro Syst. Eng., Nagoya Univ., Japan; Dept. of Micro Syst. Eng., Nagoya Univ., Japan; Dept. of Micro Syst. Eng., Nagoya Univ., Japan; Dept. of Micro Syst. Eng., Nagoya Univ., Japan; NA","Proceedings of IEEE International Conference on Robotics and Automation","6 Aug 2002","1996","1","","878","883 vol.1","We propose a multimedia tele-surgery system for training, diagnosis, and assistance in surgery. To realize this system, a high speed optical fiber network with asynchronous transfer mode (ATM) is used to provide high quality moving pictures. We designed a new teleoperation system based on ATM, which is different from the conventional one that is based on Ethernet. We built a prototype of the virtual simulator system for the intravascular neurosurgery that consists of a 3D-computer graphics simulator and two types of joysticks. The joysticks are used for the controller and force display of catheter head direction, position, and orientation. A visual assistance method is proposed to assist the operator. We performed teleoperation experiments between Nagoya and Tokyo, about 350 km apart from each other, using high speed optical fiber network, and evaluated the effectiveness of the proposed system.","1050-4729","0-7803-2988-0","10.1109/ROBOT.1996.503883","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=503883","","Optical fiber networks;Asynchronous transfer mode;Force control;Multimedia systems;Surgery;Ethernet networks;Virtual prototyping;Neurosurgery;Graphics;Displays","surgery;telerobotics;multimedia communication;asynchronous transfer mode;optical fibre networks;optical fibre communication;virtual reality;solid modelling;medical computing","multimedia tele-surgery system;optical fiber network;intravascular neurosurgery;asynchronous transfer mode;teleoperation;virtual simulator;3D-computer graphics simulator;joysticks;visual assistance","","24","","12","","6 Aug 2002","","","IEEE","IEEE Conferences"
"The use of structured digital road network data bases for dispatching and routeing of emergency service","J. G. Linders","Dept. of Comput. & Inf. Sci., Guelph Univ., Ont., Canada","Conference Record of papers presented at the First Vehicle Navigation and Information Systems Conference (VNIS '89)","6 Aug 2002","1989","","","A54","A59","The author describes the development of a digital road network database for the Region of Waterloo, Ont. from National Topographic Service 1:50000 digital map files. The system was developed for use in conjunction with a positionally based emergency location code assigned to rural properties in the Region, and is being extended to other areas. Real-time dispatching and routeing of emergency service vehicles from a digital database have been demonstrated for over 10000 nodes and 13000 road segments. The database is being enhanced to incorporate a variety of attribute data which can be used by all emergency service agencies. A full set of network functions is included for dispatching, routeing network flow, simulation and training, etc. The road data can be structured to accommodate arbitrarily large networks by using an embedded hypergraph model. Other potential applications are based on use of automatic vehicle location as an onboard facility in conjunction with the database.<>","","0-9692316-2-8","10.1109/VNIS.1989.98824","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=98824","","Dispatching;Emergency services;Routing;Information science;Road vehicles;Transfer functions;Snow;Decision making;Manuals;Delay","data structures;digital simulation;dispatching;emergency services;flow simulation;geographic information systems;real-time systems;road vehicles;training","structured digital road network data bases;digital map files;emergency location code;routeing of emergency service vehicles;network functions;dispatching;simulation;training;embedded hypergraph model;automatic vehicle location","","1","1","5","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Communications realism for network simulations","K. H. Brockel; C. Sheth; W. P. Sudnikovich; J. Pasirstein; R. Wood; A. Huynh; A. Mack; H. Drucker","Space & Terrestrial Commun. Directorate, US Army Commun.-Electron. Command, Fort Monmouth, NJ, USA; Space & Terrestrial Commun. Directorate, US Army Commun.-Electron. Command, Fort Monmouth, NJ, USA; Space & Terrestrial Commun. Directorate, US Army Commun.-Electron. Command, Fort Monmouth, NJ, USA; NA; NA; NA; NA; NA","Proceedings of MILCOM '95","6 Aug 2002","1995","2","","484","490 vol.2","The digital battlefield will present unprecedented requirements for the transfer of digital information (voice, data, and imagery). Realizing the vision of the Army's 21st century information transport architecture will require application of advanced modeling and simulation technology for performing architecture analysis, ""what-if"" drills, systems design, testing, and user training. The models and simulations must include communications realism, which is a simulation feature through which a synthetic environment reflects the same communications problems that exist in a real environment. Communications realism for link-level simulations has been achieved in the Integrated Terrain-Environment-Multipath Model (ITEMM). The paper describes the ITEMM, its real-time simulation algorithms, and work in progress to evolve these into a Real-Time Communications network Simulator (RTCNS) for use in a distributed interactive simulation (DIS) environment. It also describes how communication realism has been modeled for stationary and moving platforms and provides a detailed technical description of real-time simulation algorithms developed for modeling mobile radio links.","","0-7803-2489-7","10.1109/MILCOM.1995.483514","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=483514","","Mobile communication;Analytical models;Computational modeling;Performance analysis;System testing;Military computing;Radio communication;Performance evaluation;Information analysis;System analysis and design","military communication;military computing;digital simulation;simulation;multipath channels;digital radio;land mobile radio;radiowave propagation;radio networks;radio links;telecommunication computing","network simulations;digital battlefield;digital information transfer;mobile radio links;voice;data;information transport architecture;US Army;distributed interactive simulation environment;imagery;architecture analysis;systems design;testing;user training;communications realism;synthetic environment;link-level simulations;Integrated Terrain-Environment-Multipath Model;ITEMM;real-time simulation algorithms;Real-Time Communications Network Simulator;distributed interactive simulation","","","1","7","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Clinical Evaluation of a Colonoscopy Simulator with Improved Haptics","S. Y. Yi; H. S. Woo; W. Ahn; J. K. Joo; D. Y. Lee","Department of Internal Medicine, Ewha Womans University, Seoul, Republic of Korea. syy@ewha.ac.kr; Department of Mechanical Engineering, KAIST, Daejeon, Republic of Korea. freely@kaist.ac.kr, sokna@kaist.ac.kr, mechychan@kaist.ac.kr; Department of Mechanical Engineering, KAIST, Daejeon, Republic of Korea. sokna@kaist.ac.kr, freely@kaist.ac.kr, mechychan@kaist.ac.kr; Department of Mechanical Engineering, KAIST, Daejeon, Republic of Korea. mechychan@kaist.ac.kr, freely@kaist.ac.kr, sokna@kaist.ac.kr; Department of Mechanical Engineering, KAIST, Daejeon, Republic of Korea. lee.dooyong@kaist.ac.kr, freely@kaist.ac.kr, sokna@kaist.ac.kr, mechychan@kaist.ac.kr","IECON 2006 - 32nd Annual Conference on IEEE Industrial Electronics","16 Apr 2007","2006","","","4125","4129","This paper presents a clinical evaluation of a newly-developed colonoscopy training simulator that includes a specialized haptic interface to transfer force-feedback through a long and flexible colonoscope tube. The colonoscopy simulator has a 2-DOF haptic device with folding guides, which can transfer large decoupled forces of the colonoscopy simulation to the user. Centerline-based parametric colon models are developed to compute collision detection and response in real-time. The clinical study included 22 subjects consisting of colonoscopy experts (n=3), fellows (n=4), residents (n=6), and medical school students (n=9). The study shows that the developed colonoscopy simulator can effectively improve the skills of the residents and medical school students, although no statistically significant training-effects can be established for the fellows","1553-572X","978-1-5090-9155-3","10.1109/IECON.2006.347723","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4153452","","Colonoscopy;Haptic interfaces;Medical simulation;Computational modeling;Medical diagnostic imaging;Colon;Endoscopes;Computer simulation;Graphics;Gastrointestinal tract","biomedical education;computer based training;endoscopes;haptic interfaces;medical computing","clinical evaluation;colonoscopy simulator;haptic interface;colonoscope tube;centerline-based parametric colon models;collision detection","","","1","10","","16 Apr 2007","","","IEEE","IEEE Conferences"
"3D Hand Pose Estimation with a Single Infrared Camera via Domain Transfer Learning","G. Park; T. -K. Kim; W. Woo",KAIST UVR Lab.; Imperial College London & KAIST; KAIST UVR Lab.,"2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","14 Dec 2020","2020","","","588","599","Previous methods successfully estimated 3D hand poses from unblurred depth images with slow and smooth hand motions. However, the performance drops when the depth images are contaminated by motion blur due to fast hand motion. In this paper, we exploit an infrared (IR) image input, which is weakly blurred under fast hand motion. The proposed method is based on domain transfer learning from depth to infrared images. Note we do not have IR images with hand skeletons, thus proposing self-supervision rather than direct supervision using the skeleton labels. We train a Hand Image Generator (HIG) and two Hand Pose Estimators (HPEs) on paired depth and infrared images via self-supervision using a consistency loss, guided by an existing HPE trained on paired depth and hand skeleton entries. The IR-based HPE is then refined on the weakly blurred infrared images. The qualitative and quantitative experiments demonstrate that the proposed method accurately estimates 3D hand poses under motion blur by fast hand motion, while existing depth-based methods fail. Our solution therefore supports fast 3D manipulation of virtual objects for augmented reality applications. Our model and dataset are publicly available for future research.1","1554-7868","978-1-7281-8508-8","10.1109/ISMAR50242.2020.00086","National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284791","Computing methodologies;Computer vision problems;Deep learning","Solid modeling;Three-dimensional displays;Pose estimation;Network architecture;Cameras;Skeleton;Augmented reality","augmented reality;cameras;computer vision;feature extraction;image colour analysis;image motion analysis;image segmentation;image sensors;infrared imaging;learning (artificial intelligence);object detection;object tracking;pose estimation","3D hand pose estimation;single infrared camera;domain transfer learning;unblurred depth images;slow hand motions;smooth hand motions;motion blur;fast hand motion;infrared image input;IR images;hand skeletons;hand pose estimators;paired depth;hand skeleton entries;weakly blurred infrared images;depth-based methods;fast 3D manipulation;hand image generator","","","","60","","14 Dec 2020","","","IEEE","IEEE Conferences"
"Short Video Datasets Show Potential for Outfits in Augmented Reality","A. Jong; T. -S. Moh","San José State University,Department of Computer Science,San José,CA; San José State University,Department of Computer Science,San José,CA","2019 International Conference on High Performance Computing & Simulation (HPCS)","9 Sep 2020","2019","","","201","208","We investigate the usage of short video datasets in place of large image datasets for outfit transfer. We replicate the warp stage of prior work, SwapNet, while swapping out the 800K-image DeepFashion dataset for two 5-minute videos. By successfully training the warp stage on video, we show that the previously proposed transfer technique for images has potential to apply to subjects in motion. In addition, specifically for video applications, we show the model need not be trained on a comprehensive dataset; instead the model only needs videos for the source outfit and target subject. Our results show promise for the usage of video datasets in future work to achieve fully-textured outfit transfer. We expect the implications of convenient-to-collect video datasets to appeal to small companies that lack resources to collect and annotate big data. If combined with high performance computing, faster training times in the cloud could lead to frictionless user experiences.","","978-1-7281-4484-9","10.1109/HPCS48598.2019.9188236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9188236","virtual try-on;clothing outfit transfer;image-to-image translation;generative video","Clothing;Training;Image segmentation;Gallium nitride;Generative adversarial networks;Generators;Companies","augmented reality;Big Data;image recognition;learning (artificial intelligence);video signal processing","short video datasets;image datasets;warp stage;800K-image DeepFashion dataset;video applications;convenient-to-collect video dataset","","","","20","","9 Sep 2020","","","IEEE","IEEE Conferences"
"The role of feedback on cognitive motor learning in children with cerebral palsy: A protocol","M. T. Robert; M. F. Levin; R. Guberek; K. Sambasivan; M. F. Levin","Integrated Program of Neuroscience and CRIR, McGill University, Montreal, Canada; Integrated Program of Neuroscience and CRIR, McGill University, Montreal, Canada; School of Physical and Occupational Therapy and CRIR, McGill University, Montreal, Canada; School of Physical and Occupational Therapy and CRIR, McGill University, Montreal, Canada; School of Physical and Occupational Therapy and CRIR, McGill University, Montreal, Canada","2015 International Conference on Virtual Rehabilitation (ICVR)","17 Dec 2015","2015","","","141","142","Evidence of provision of extrinsic feedback for improvement and retention of upper limb kinematics in children with cerebral palsy (CP) is scarce, especially following training interventions using virtual environments. Benefits of using a virtual environment can range from increasing the participant's motivation to the ease of adapting extrinsic feedback for optimizing motor learning. In the proposed research, children with CP will be randomly allocated to one of three groups: no additional feedback, continuous feedback and faded feedback. For all groups, upper-limb motor training will be done in a virtual environment using the Jintronix virtual reality system. Motor improvements will be evaluated after an 8 hour training intervention and motor learning will be evaluated after one month. Transfer of motor gains to performance of a similar upper-limb task will also be used to assess learning. Findings from this research will provide crucial information on which frequency of feedback should be used to optimize motor learning and upper-limb rehabilitation in children with CP.","2331-9569","978-1-4799-8984-3","10.1109/ICVR.2015.7358617","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358617","Cerebral Palsy;Motor learning;Upper limb;Feedback","","feedback;medical computing;medical disorders;neurophysiology;patient rehabilitation;virtual reality","upper-limb rehabilitation;upper-limb task;Jintronix virtual reality system;upper-limb motor training;faded feedback;continuous feedback;additional feedback;extrinsic feedback;virtual environment;training intervention;upper limb kinematics retention;upper limb kinematics improvement;cerebral palsy;cognitive motor learning;time 8 h;time 1 month","","1","","7","","17 Dec 2015","","","IEEE","IEEE Conferences"
"Towards Fine-Grained Human Pose Transfer With Detail Replenishing Network","L. Yang; P. Wang; C. Liu; Z. Gao; P. Ren; X. Zhang; S. Wang; S. Ma; X. Hua; W. Gao","Video Coding Laboratory, Institute of Digital Media, Peking University (PKU-IDM-VCL), Beijing, China; Video Coding Laboratory, Institute of Digital Media, Peking University (PKU-IDM-VCL), Beijing, China; School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China; Video Coding Laboratory, Institute of Digital Media, Peking University (PKU-IDM-VCL), Beijing, China; Video Coding Laboratory, Institute of Digital Media, Peking University (PKU-IDM-VCL), Beijing, China; School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China; Institute of Digital Media, Peking University, Beijing, China; Institute of Digital Media, Peking University, Beijing, China; Video Coding Laboratory, Institute of Digital Media, Peking University (PKU-IDM-VCL), Beijing, China; Institute of Digital Media, Peking University, Beijing, China","IEEE Transactions on Image Processing","29 Jan 2021","2021","30","","2422","2435","Human pose transfer (HPT) is an emerging research topic with huge potential in fashion design, media production, online advertising and virtual reality. For these applications, the visual realism of fine-grained appearance details is crucial for production quality and user engagement. However, existing HPT methods often suffer from three fundamental issues: detail deficiency, content ambiguity and style inconsistency, which severely degrade the visual quality and realism of generated images. Aiming towards real-world applications, we develop a more challenging yet practical HPT setting, termed as Fine-grained Human Pose Transfer (FHPT), with a higher focus on semantic fidelity and detail replenishment. Concretely, we analyze the potential design flaws of existing methods via an illustrative example, and establish the core FHPT methodology by combing the idea of content synthesis and feature transfer together in a mutually-guided fashion. Thereafter, we substantiate the proposed methodology with a Detail Replenishing Network (DRN) and a corresponding coarse-to-fine model training scheme. Moreover, we build up a complete suite of fine-grained evaluation protocols to address the challenges of FHPT in a comprehensive manner, including semantic analysis, structural detection and perceptual quality assessment. Extensive experiments on the DeepFashion benchmark dataset have verified the power of proposed benchmark against start-of-the-art works, with 12%-14% gain on top-10 retrieval recall, 5% higher joint localization accuracy, and near 40% gain on face identity preservation. Our codes, models and evaluation tools will be released at https://github.com/Lotayou/RATE.","1941-0042","","10.1109/TIP.2021.3052364","National Natural Science Foundation of China; High-performance Computing Platform of Peking University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9335507","Image generation;pose transfer;detail replenishment","Semantics;Strain;Solid modeling;Faces;Protocols;Media;Hybrid power systems","feature extraction;information retrieval;Internet;learning (artificial intelligence);object detection;object tracking;pose estimation;virtual reality","perceptual quality assessment;replenishing network;fine-grained evaluation protocols;coarse-to-fine model training scheme;feature transfer;content synthesis;core FHPT methodology;potential design flaws;detail replenishment;semantic fidelity;fine-grained human pose transfer;HPT setting;real-world applications;visual quality;style inconsistency;content ambiguity;detail deficiency;HPT methods;user engagement;production quality;fine-grained appearance details;visual realism;virtual reality;online advertising;media production;fashion design","","","","43","IEEE","25 Jan 2021","","","IEEE","IEEE Journals"
"Development of a brachial plexus blocker prototype","S. C. Monteiro","Escola Superior de Tecnologia e Gestão - Instituto Politécnico de Bragança, Alameda de Santa Apolónia, 5300-253 Bragança, Bragança, Portugal","2017 12th Iberian Conference on Information Systems and Technologies (CISTI)","13 Jul 2017","2017","","","1","6","Although the area of surgical simulation has been the subject of study in recent years, it is still necessary to develop artificial experimental models with a perspective to dismiss the use of biological models. Since this makes the simulators more real, transferring the environment of the health professional to a physical or virtual reality, an anesthetic prototype has been developed, where the motor response is replicated when the brachial plexus is subjected to a proximal nervous stimulus. Using action-research techniques, with this simulator it was possible to validate that the human nerve response can be replicated, which will aid the training of health professionals, reducing possible risks in a surgical environment.","","978-9-8998-4347-9","10.23919/CISTI.2017.7976010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7976010","Anesthesia;Simulation;brachial plexus blockade;Arduino;3D Print","Visualization;Solid modeling;Biological system modeling;Monitoring;Three-dimensional displays;Brachytherapy;Adaptation models","computer based training;digital simulation;medical computing;professional aspects;surgery;virtual reality","brachial plexus blocker prototype;surgical simulation;biological models;physical system;virtual reality;anesthetic prototype;motor response;proximal nervous stimulus;action-research techniques;human nerve response;health professional training;risk reduction;surgical environment","","","","8","","13 Jul 2017","","","IEEE","IEEE Conferences"
"Changes in Subjective Understanding of an Accident and Risk Awareness in First-Year Nursing Students Following Medical Accident Simulation-Based Experimental Learning","T. Yoneda; K. Itami; O. Yasuhara; K. Seki; Y. Kawabata; T. Maesako; L. Zhe","Sch. of Human Nursing, Univ. of Shiga Prefecture, Hikone, Japan; Sch. of Human Nursing, Univ. of Shiga Prefecture, Hikone, Japan; Sch. of Human Nursing, Univ. of Shiga Prefecture, Hikone, Japan; Sch. of Human Nursing, Univ. of Shiga Prefecture, Hikone, Japan; Sch. of Human Nursing, Univ. of Shiga Prefecture, Hikone, Japan; Sch. of Human Sci., Osaka Univ., Suita, Japan; Sch. of Human Sci., Osaka Univ., Suita, Japan","2017 International Conference of Educational Innovation through Technology (EITT)","12 Mar 2018","2017","","","159","164","Novice nurses with little professional experience tend to feature frequently in reported medical accidents and near-miss incidents in Japanese healthcare facilities. According to our previous survey, approximately 40% to 70% of nursing students experience near-miss incidents during their clinical training. Many of these incidents in nursing settings occur while providing assistance for wheelchair transfer or bathing. Fostering observational skills to enable accurate risk area identification is a requirement from the stage of basic education for the provision of safe medical care to patients. In the present study, we devised and implemented experimental learning aimed at first-year nursing students that incorporated medical accident reenactments and simulations using simulated patients. The results showed significant post-learning increases in both subjective understanding and the frequency of risk area identification, suggesting that experimental learning improves nursing student comprehension and skill in responding to perceived risks.","","978-1-5386-0629-2","10.1109/EITT.2017.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8308531","risk awareness;simulation-based training;experimental learning;medical safety training;nursing students","Accidents;Medical services;Biomedical imaging;Wheelchairs;Training;Safety","biomedical education;computer aided instruction;health care;medical computing;patient care;patient monitoring","professional experience;reported medical accidents;Japanese healthcare facilities;wheelchair transfer;accurate risk area identification;safe medical care;experimental learning;medical accident reenactments;simulated patients;subjective understanding;nursing student comprehension;perceived risks;medical accident simulation;nursing student experience","","","","15","","12 Mar 2018","","","IEEE","IEEE Conferences"
"Laboratory framework TEAM for investigating the dependability issues of microprocessor systems","A. Jasnetski; R. Ubar; A. Tsertov; H. Kruus","Tallinn University of Technology, Dept. of Comp. Engineering, Estonia; Tallinn University of Technology, Dept. of Comp. Engineering, Estonia; Testonica Lab OÜ, Tallinn, Estonia; Tallinn University of Technology, Dept. of Comp. Engineering, Estonia","10th European Workshop on Microelectronics Education (EWME)","14 Aug 2014","2014","","","80","83","We propose a laboratory research and student training oriented framework consisting of Test Evaluation Automated Means (TEAM) as a set of tools for evaluating the quality of test programs for microprocessors and systems. TEAM enables students to learn and analyze the dependability issues of microprocessor systems, to create their own designs and develop test programs, to analyze the quality of testing, and to make decisions about improving the testability of systems. The tool set in TEAM is mostly open and consists of the assembly level test converter, register transfer level test program simulator, global test converter into local test sequences for modules of the system, and gate-level fault simulator. The general ideas of hands-on laboratory training supported by TEAM are outlined. The research tasks of test program generation can be set up in a way that enables a competition between students, and as a consequence, motivates them to better understand the problems of testing of complex systems and their dependability.","","978-1-4799-4016-5","10.1109/EWME.2014.6877400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6877400","microprocessor systems;behaviour level test generation;register transfer and gate level simulation;high-level decision diagrams","Program processors;Microprocessors;Logic gates;Educational institutions;Training;Built-in self-test","circuit simulation;computer aided instruction;electronic engineering education;integrated circuit design;integrated circuit reliability;integrated circuit testing;microprocessor chips;student experiments","TEAM laboratory framework;microprocessor systems;student training oriented framework;test evaluation automated means;test program quality evaluation;dependability analysis;assembly level test converter;register transfer level test program simulator;global test converter;local test sequences;gate-level fault simulator;hands-on laboratory training;complex system testing","","1","","20","","14 Aug 2014","","","IEEE","IEEE Conferences"
"Evaluating exemplary training accelerators for Programming-by-Demonstration","T. Hulin; V. Schmirgel; E. Yechiam; U. E. Zimmermann; C. Preusche; G. Pöhler","Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; KUKA Roboter GmbH, Germany; Faculty of Industrial Engineering and Management, Technion, Israel; KUKA Roboter GmbH, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Otto-von-Guericke University, Magdeburg, Germany","19th International Symposium in Robot and Human Interactive Communication","11 Oct 2010","2010","","","440","445","Robot Programming by Demonstration requires comprehending the usage of a robotic system. This article is about accelerating the training of these skills, using the example of a DLR/KUKA light-weight robot. An augmented reality and a virtual reality setup are presented that aim to demonstrate and evaluate skills transfer of two different sub-tasks of this system: Avoiding robot singularities and setting correct compliance parameters. For this purpose training accelerators are introduced for visualising robot singularities, exploring robot singularities and feeling compliance parameters. An evaluation procedure for all three accelerators is suggested and has been performed on the first two. As interesting evaluation result a contrast to the Cognitive Theory of Multimedia Learning hypothesis could be observed: Additional visual information on the robot singularities impairs the participants' performance.","1944-9437","978-1-4244-7990-0","10.1109/ROMAN.2010.5598611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5598611","","Robots;Visualization;Training;Haptic interfaces;Games;Joints;Collision avoidance","augmented reality;automatic programming;industrial robots;robot programming","exemplary training accelerators;robot programming by demonstration;DLR/KUKA light-weight robot;augmented reality;virtual reality;robot singularities;multimedia learning hypothesis;cognitive theory","","6","1","21","","11 Oct 2010","","","IEEE","IEEE Conferences"
"Fast power control for GSM HBS using training sequences","M. I. Silventoinen; P. A. Ranta; M. Raitola","Nokia Res. Center, Espoo, Finland; NA; NA","1997 IEEE 47th Vehicular Technology Conference. Technology in Motion","6 Aug 2002","1997","3","","1689","1693 vol.3","We investigate the usage of fast power control (PC) in Global System for Mobile Communications (GSM) based home base station (HBS) system to alleviate Rayleigh fading for slow moving mobile stations (MS). Low-speed MSs suffer from Rayleigh fading most due to the long periods they spend in the fading dips. Especially, if the system does not employ other techniques to combat Rayleigh fading, such as frequency hopping (FH), the negative effects of the fading are serious. To implement the signalling for fast PC, we propose the usage of training sequences to transfer the power control information over the GSM radio interface. The benefits of this method are various: the transfer of the PC commands will be fast, reliable and the pay load of the frame is not wasted. The magnitude of the improvement was assessed by simulating the link using the COSSAP simulating tool. The conclusion was that the fast PC will increase the link capacity and partly compensates the lack of frequency hopping.","1090-3038","0-7803-3659-3","10.1109/VETEC.1997.605846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=605846","","Power control;GSM;Rayleigh channels;Frequency;Mobile communication;Base stations;Interference;Channel allocation;Spread spectrum communication;Telephone sets","cellular radio;telecommunication control;power control;fading;Rayleigh channels;telecommunication signalling;radio networks;telecommunication computing;digital simulation;simulation;multipath channels;land mobile radio;radiofrequency interference","GSM HBS;training sequences;fast power control;Global System for Mobile Communications;home base station;Rayleigh fading multipath channel;slow moving mobile stations;system performance;signalling;radio interface;COSSAP simulating tool;link capacity;mobile communications networks;interference","","1","12","7","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Visual and Haptic Error Modulating Controllers for Robotic Gait Training","P. Tsangaridis; D. Obwegeser; S. Maggioni; R. Riener; L. Marchal-Crespo","Department of Health Sciences and Technology (HEST), Sensory-Motor Systems (SMS) Lab, Zurich, ETH, Switzerland; Department of Health Sciences and Technology (HEST), Sensory-Motor Systems (SMS) Lab, Zurich, ETH, Switzerland; Department of Health Sciences and Technology (HEST), Sensory-Motor Systems (SMS) Lab, Zurich, ETH, Switzerland; Department of Health Sciences and Technology (HEST), Sensory-Motor Systems (SMS) Lab, Zurich, ETH, Switzerland; University of of Bern, The Gerontechnology and Rehabilitation group, ARTORG Center for Biomedical Engineering Research, Switzerland","2018 7th IEEE International Conference on Biomedical Robotics and Biomechatronics (Biorob)","11 Oct 2018","2018","","","1050","1055","Robotic algorithms that augment movement errors have been proposed as promising training strategies to enhance motor training and neurorehabilitation. However, research effort has mainly focused on rehabilitation of upper limbs. In this study, we investigated the effect of training with novel error modulating strategies on learning an asymmetric gait pattern. Thirty healthy young participants walked in the robotic exoskeleton Lokomat, while learning a foot target-tracking task which required an increased hip and knee flexion in the dominant leg. Learning with three different strategies was evaluated: (i) No guidance: no disturbance/guidance was applied, (ii) Haptic error amplification: dangerous and discouraging large errors were limited with haptic guidance, while awareness of task relevant errors was enhanced with error amplification, and (iii) Visual error amplification: visually perceived errors were amplified in a virtual reality environment. We also evaluated whether increasing the movement variability during training by adding randomly-varying haptic disturbances on top of the other training strategies further enhanced learning. We found that training with the novel haptic error amplification strategy limited large errors during training, did not hamper learning and enhanced transfer of the learned asymmetric gait pattern. Training with visual error amplification, on the other hand, increased errors during training and hampered motor learning. Adding haptic disturbances did not have a significant effect on learning. The novel haptic error modulating controller that amplifies small task-relevant errors while limiting large errors provided the best framework to enhance motor learning.","2155-1782","978-1-5386-8183-1","10.1109/BIOROB.2018.8488011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8488011","","Training;Haptic interfaces;Legged locomotion;Visualization;Task analysis;Trajectory","gait analysis;haptic interfaces;learning (artificial intelligence);medical robotics;neurophysiology;patient rehabilitation;virtual reality","task-relevant errors;visual error modulating controllers;haptic error modulating controllers;novel haptic error modulating controller;hampered motor learning;increased errors;learned asymmetric gait pattern;enhanced transfer;novel haptic error amplification strategy;enhanced learning;haptic disturbances;visually perceived errors;visual error amplification;task relevant errors;haptic guidance;disturbance/guidance;different strategies;knee flexion;increased hip;foot target-tracking task;robotic exoskeleton Lokomat;thirty healthy young participants;motor training;promising training strategies;augment movement errors;robotic algorithms;robotic gait training","","","","26","","11 Oct 2018","","","IEEE","IEEE Conferences"
"Online simulation of pedestrian flow in public buildings","Hanisch; Tolujew; Richter; Schulze","Oper. & Autom. IFF, Fraunhofer-Inst. for Factory, Magdeburg, Germany; Oper. & Autom. IFF, Fraunhofer-Inst. for Factory, Magdeburg, Germany; Oper. & Autom. IFF, Fraunhofer-Inst. for Factory, Magdeburg, Germany; NA","Proceedings of the 2003 Winter Simulation Conference, 2003.","30 Jan 2004","2003","2","","1635","1641 vol.2","Online simulation of pedestrian flow in public buildings is a new tool which can be especially useful for improving the aspects of safety and short-term planning in the phase of organizing and operating large public buildings. These might be places such as a train station, an airport or a shopping center. We provide an insight into the different concepts of pedestrian flow simulation. Special emphasis is placed on explaining the mesoscopic approach as applied to the area of traffic simulation. This approach is transferred to the context of analyzing and predicting the pedestrian flow. A first prototypical implementation of a simulation supported control center is briefly presented, also.","","0-7803-8131-9","10.1109/WSC.2003.1261613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1261613","","Buildings;Safety;Airports;Traffic control;Virtual prototyping;Information systems;Air traffic control;Advertising;Shape;Context modeling","digital simulation;Internet;traffic engineering computing","online simulation;pedestrian flow;public buildings;short-term planning;traffic simulation","","12","","14","","30 Jan 2004","","","IEEE","IEEE Conferences"
"Sim2Real Predictivity: Does Evaluation in Simulation Predict Real-World Performance?","A. Kadian; J. Truong; A. Gokaslan; A. Clegg; E. Wijmans; S. Lee; M. Savva; S. Chernova; D. Batra","Facebook AI Research, Menlo Park, CA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Facebook AI Research, Menlo Park, CA, USA; Facebook AI Research, Menlo Park, CA, USA; Facebook AI Research, Menlo Park, CA, USA; Oregon State University, Corvallis, OR, USA; Facebook AI Research, Menlo Park, CA, USA; Facebook AI Research, Menlo Park, CA, USA; Facebook AI Research, Menlo Park, CA, USA","IEEE Robotics and Automation Letters","26 Aug 2020","2020","5","4","6670","6677","Does progress in simulation translate to progress on robots? If one method outperforms another in simulation, how likely is that trend to hold in reality on a robot? We examine this question for embodied PointGoal navigation - developing engineering tools and a research paradigm for evaluating a simulator by its sim2real predictivity. First, we develop Habitat-PyRobot Bridge (HaPy), a library for seamless execution of identical code on simulated agents and robots - transferring simulation-trained agents to a LoCoBot platform with a one-line code change. Second, we investigate the sim2real predictivity of Habitat-Sim M. Savva et al., for PointGoal navigation. We 3D-scan a physical lab space to create a virtualized replica, and run parallel tests of 9 different models in reality and simulation. We present a new metric called Sim-vs-Real Correlation Coefficient (SRCC) to quantify predictivity. We find that SRCC for Habitat as used for the CVPR19 challenge is low (0.18 for the success metric), suggesting that performance differences in this simulator-based challenge do not persist after physical deployment. This gap is largely due to AI agents learning to exploit simulator imperfections - abusing collision dynamics to `slide' along walls, leading to shortcuts through otherwise non-navigable space. Naturally, such exploits do not work in the real world. Our experiments show that it is possible to tune simulation parameters to improve sim2real predictivity (e.g. improving SRCCSucc from 0.18 to 0.844) - increasing confidence that in-simulation comparisons will translate to deployed systems in reality.","2377-3766","","10.1109/LRA.2020.3013848","NSF; Air Force Research Laboratory; Defense Advanced Research Projects Agency; ONR YIPs; ARO PECASE; Amazon Catalyst; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9158349","Visual-based navigation;reinforcement learning","Robots;Navigation;Task analysis;Predictive models;Correlation;Measurement","artificial intelligence;collision avoidance;computer simulation;human-robot interaction;learning (artificial intelligence);mobile robots;multi-agent systems;virtual reality","one-line code change;simulation predict Real-world performance;embodied PointGoal navigation;Habitat-PyRobot Bridge;robots-transferring simulation-trained agents;LoCoBot platform;Sim-vs-Real Correlation Coefficient;Habitat-Sim M. Savva et al;Sim2Real Predictivity;virtualized replica;SRCC;AI agents learning;HaPy;agent simulation","","3","","37","IEEE","4 Aug 2020","","","IEEE","IEEE Journals"
"Simulation studies in a hot mill facility","L. C. Giussani","Daxus Corp., Pittsburgh, PA, USA","1991 Winter Simulation Conference Proceedings.","6 Aug 2002","1991","","","474","481","The author illustrates several phases of a simulation study done in a hot mill facility for a prominent US steel producer. The first phase of the study focuses on operational and material handling issues for the hot mill banding, weighing, and marking stations. The next phase provides additional support for the objectives of the first phase, along with technology transfer and training to support practical operations at the client's site. The final phase addresses strategic issues at downstream operations from the hot mill banding, weighing, and marking line, and the impact of any operational strategy on the whole system. The models for this project have been developed using the AUTOMOD II simulation software and were executed on an IRIS-Silicon Graphics workstation. The focus of the present work is to interpret the results obtained in the first completed phase and to share the experience of the whole project in terms of lessons learned. The author also points out the extensibility and the synergistic advantages that can be obtained by focusing at an early stage on the customer's short- and long-term goals and objectives.<>","","0-7803-0181-1","10.1109/WSC.1991.185649","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=185649","","Milling machines;Materials handling;Metals industry;Coils;Steel;Investments;Material storage;Analytical models;Technology transfer;Iris","digital simulation;hot working;steel industry","hot mill facility;US steel producer;material handling;technology transfer;training;hot mill banding;weighing;marking line;operational strategy;AUTOMOD II simulation software;IRIS-Silicon Graphics workstation","","1","1","5","","6 Aug 2002","","","IEEE","IEEE Conferences"
"LadderNet: Knowledge Transfer Based Viewpoint Prediction in 360◦ Video","P. Zhao; Y. Zhang; K. Bian; H. Tuo; L. Song","Peking University, Beijing, China; Peking University, Beijing, China; Peking University, Beijing, China; iQIYI Co. Ltd., Beijing, China; Peking University, Beijing, China","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","16 Apr 2019","2019","","","1657","1661","In the past few years, virtual reality (VR) has become an enabling technique, not only for enriching our visual experience but also for providing new channels for businesses. Untethered mobile devices are the main players for watching 360-degree content, thereby the precision of predicting the future viewpoints is one key challenge to improve the quality of the playbacks. In this paper, we investigate the image features of the 360-degree videos and the contextual information of the viewpoint trajectories. Specifically, we design ladder convolution to adapt for the distorted image, and propose LadderNet to transfer the knowledge from the pre-trained model and retrieve the features from the distorted image. We then combine the image features and the contextual viewpoints as the inputs for long short-term memory (LSTM) to predict the future viewpoints. Our approach is compared with several state-of-the-art viewpoint prediction algorithms over two 360-degree video datasets. Results show that our approach can improve the Intersection over Union (IoU) by at least 5% and meeting the requirements of the playback of 360-degree video on mobile devices.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682776","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682776","Untethered virtual reality;image distortion;viewpoint prediction","Trajectory;Streaming media;Strips;Kernel;Convolution;Mobile handsets;Shape","feature extraction;learning (artificial intelligence);mobile computing;user interfaces;video cameras;video recording;video signal processing;virtual reality","LadderNet;pre-trained model;distorted image;image features;contextual viewpoints;future viewpoints;state-of-the-art viewpoint prediction algorithms;360-degree video datasets;playback;knowledge transfer based viewpoint prediction;virtual reality;enabling technique;visual experience;untethered mobile devices;main players;360-degree content;contextual information;viewpoint trajectories;design ladder convolution;intersection over union;IoU","","3","","19","","16 Apr 2019","","","IEEE","IEEE Conferences"
"Virtual vs. experiment, programmable vs. wired logic, hardware vs. software in teaching digital control for electrochemical engineering","D. Mihai; C. Constantinescu","Craiova Univ., Romania; Craiova Univ., Romania","The IEEE Region 8 EUROCON 2003. Computer as a Tool.","3 Dec 2003","2003","2","","7","11 vol.2","Based on industrial, academic and research experience, the authors make an evaluation of basic components involved in training students of electrochemical profiles for the digital control field. The best equilibrium between old and new solutions (from device to equipment) as well as the optimal weights for physical experiments and computer simulation are major issues for certifying a good training level.","","0-7803-7763-X","10.1109/EURCON.2003.1248122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1248122","","Programmable control;Hardware;Education;Digital control;Industrial training;Logic;Computer industry;Industrial control;Application software;Automotive engineering","training;student experiments;control engineering education;digital control;mechanical engineering;electrical engineering;digital simulation;control engineering computing;automation","programmable logic;wired logic;hardware;software;digital control teaching;electrochemical engineering;digital control field;optimal weight;automation;programming language;transfer function;computer simulation;physical experiment;virtual methods","","1","","8","","3 Dec 2003","","","IEEE","IEEE Conferences"
"A novel development tool of fuzzy neural networks","Meng Joo Er; Jun Liao; Jianya Lin; Maolin Ni","Sch. of Electr. & Electron. Eng., Nanyang Technol. Univ., Singapore; NA; NA; NA","Proceedings of the 2000 American Control Conference. ACC (IEEE Cat. No.00CH36334)","6 Aug 2002","2000","4","","2458","2462 vol.4","To facilitate the transfer of technology emerging from theoretical research into fuzzy neural networks (FNN) for industrial applications, a fuzzy neural networks system for the automatic generation (FNNAGS) is proposed. In FNNAGS, the fuzzy model constructed by the system can be expressed as either a Mamdani model or a Takagi-Sugeno model, according to the preference of the user. Off-line design and online applications are incorporated into an interactive software system. In the stage of off-line design, only the training data need to be provided in order to construct a process model. Users do not need to give the initial fuzzy partitions, membership functions or fuzzy logic rules. These initial parameters will be set up automatically by the FNNAGS, in accordance with the properties of the training data. After off-line design has been completed, the model can be expressed as a fuzzy rule base, which can be used to control, estimate, identify or predict a process or giant through an application interface between FNNAGS and the external world.","0743-1619","0-7803-5519-9","10.1109/ACC.2000.878623","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=878623","","Fuzzy neural networks;Fuzzy control;Training data;Fuzzy logic;Fuzzy systems;Takagi-Sugeno model;Application software;Software systems;Predictive models;Automatic control","technology transfer;fuzzy neural nets;digital simulation;learning (artificial intelligence);multilayer perceptrons;object-oriented methods","development tool;technology transfer;Mamdani model;Takagi-Sugeno model;interactive software system;off-line design;training data;process model;fuzzy rule base","","","","10","","6 Aug 2002","","","IEEE","IEEE Conferences"
"VBR traffic prediction in ATM system","W. Lobejko","Mil. Commun. Inst., Zegrze, Poland","MILCOM 97 MILCOM 97 Proceedings","6 Aug 2002","1997","3","","1585","1588 vol.3","This paper presents new ATM (asynchronous transfer mode) VBR (variable bit rate) traffic prediction using an artificial neural network (ANN). The paper describes a model of the neural network and its training algorithm. It discusses a new method of designing the neural network using genetic algorithms and it explains the mechanism of three main genetic operations: selection, crossover and mutation. Computer simulation results are presented. It is shown that the neural network can predict the VBR traffic by learning the relationship between ATM traffic variations.","","0-7803-4249-6","10.1109/MILCOM.1997.645034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=645034","","Telecommunication traffic;Traffic control;Asynchronous transfer mode;Artificial neural networks;Bit rate;Design methodology;Algorithm design and analysis;Genetic algorithms;Genetic mutations;Computer simulation","telecommunication traffic;genetic algorithms;asynchronous transfer mode;neural nets;telecommunication computing","VBR traffic prediction;ATM system;asynchronous transfer mode;variable bit rate traffic;artificial neural network;ANN;training algorithm;design;genetic algorithms;selection;crossover;mutation;traffic variations","","2","","3","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Towards understanding the capability of spatial audio feedback in virtual environments for people with visual impairments","M. Dong; R. Guo",Kennesaw State University; Kennesaw State University,"2016 IEEE 2nd Workshop on Everyday Virtual Reality (WEVR)","23 Feb 2017","2016","","","15","20","This research analyzes if and how the Head Related Transfer Function (HRTF) can be used to support effective Human-Computer Interaction when people in a Virtual Environment (VE) without visual feedback. If sounds can be located in a VE by using HRTF only, designing and developing considerably safer but diversified training environments might greatly benefit individuals with visual impairments. To investigate this, we ran 2 usability studies: 1) to ascertain whether the HRTF could provide sufficient position information in VEs; 2) to learn whether the HRTF could provide sufficient distance and direction information in VEs. The results showed that a continuous audio feedback could help navigate in a VE without vision feedback.","","978-1-5090-0840-7","10.1109/WEVR.2016.7859538","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7859538","Assistive technology; HRTF; 3D Audio; user study","Visualization;Training;Three-dimensional displays;Virtual environments;Navigation;Headphones;Haptic interfaces","feedback;human computer interaction;transfer functions;virtual reality;vision defects","spatial audio feedback;virtual environments;visual impairments;head related transfer function;HRTF;human-computer interaction;VE;diversified training environments might;position information;direction information","","1","","19","","23 Feb 2017","","","IEEE","IEEE Conferences"
"Design of Novel Teaching Episodes in Medical Education Using Emerging Experiential Digital Assets: Technology Enabled Medical Education Beyond the Gimmicky","P. E. Antoniou; E. Dafli; P. D. Bamidis","Med. Phys. Lab., Univ. of Thessaloniki Thessaloniki, Thessaloniki, Greece; Med. Phys. Lab., Univ. of Thessaloniki Thessaloniki, Thessaloniki, Greece; Med. Phys. Lab., Univ. of Thessaloniki Thessaloniki, Thessaloniki, Greece","2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing","28 Dec 2015","2015","","","1560","1565","Medical education has always been about experiential hands on training to prepare future doctors to create the necessary skillset to deal with the sensitive and immediate nature of their work. Contemporary experiential technologies such as Virtual and Augmented reality offer a realistic but consequence free test-bed in which to interact safely and cope with emotional challenges pertaining to the realistic tasks simulated through these media. This work describes the design guidelines and workflow for incorporating these novel virtual assets in medical education through serious role play learning episodes. This approach consists of the case selection, the identification of roles, information flow and narrative requirements, implementation of technological narrative tools and implementation of the learning episode. Using a specific example of case transfer through this model we describe the process, outline implementation, assessment and technological considerations. Finally rationale for this work as a counterweight to technological hype fluctuations and integration of these media into the mainstream curricula is discussed.","","978-1-5090-0154-5","10.1109/CIT/IUCC/DASC/PICOM.2015.360","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363280","Autgmented Reality;Virtual Reality;Serious Role","Medical services;Context;Training;Solid modeling;Virtual reality;Biomedical monitoring","augmented reality;biomedical education;medical computing","narrative tool;information flow;consequence free test-bed;augmented reality;virtual reality;contemporary experiential technology;gimmicky;experiential digital asset;medical education","","3","","28","","28 Dec 2015","","","IEEE","IEEE Conferences"
"Co-presentation of force cues for skill transfer via shared-control systems","D. Powell; M. K. O'Malley","Rice University, USA; Rice University, USA","2010 IEEE Haptics Symposium","8 Apr 2010","2010","","","453","456","During training and rehabilitation with haptic devices, it is often necessary to simultaneously present force cues arising from different haptic models (such as guidance cues and environmental forces). Multiple force cues are typically summed to produce a single output force, which conveys only relative information about the original force cues and may not be useful to trainees. Two force co-presentation paradigms are proposed as potential solutions to this problem: temporal separation of force cues, where one type of force is overlaid with the other in staggered pulses, and spatial separation, where the forces are presented via multiple haptic devices. A generalized model for separating task and guidance forces in a virtual environment is also proposed. In a pilot study where sixteen participants were trained in a dynamic target-hitting task using these co-presentation paradigms, simple summation was in fact most effective at eliciting skill transfer in most respects. Spatial separation imposed the lowest overall workload on participants, however, and might thus be more appropriate than summation in tasks with other significant physical or mental demands. Temporal separation was relatively inferior at eliciting skill transfer, but it is hypothesized that this paradigm would have performed considerably better in a non-rhythmic task, and the need for further research is indicated.","2324-7355","978-1-4244-6822-5","10.1109/HAPTIC.2010.5444619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444619","","Haptic interfaces;Virtual environment;Fixtures;Education;Performance evaluation;Manipulator dynamics;Displays;USA Councils;Force control;Feedback","haptic interfaces;virtual reality","force cues;skill transfer;shared-control systems;haptic devices;guidance cues;environmental forces;virtual environment;copresentation paradigms","","1","","7","","8 Apr 2010","","","IEEE","IEEE Conferences"
"Effect of interface type in the VR-based acquisition of pedestrian skills in persons with ASD","M. Saiano; E. Garbarino; S. Lumachi; S. Solari; V. Sanguineti","Dept of Informatics, Bioengineering, Robotics and Systems Engineering, University of Genoa, Via all'Opera Pia 13, 16145, Italy; Dept. of Primary Care, ASL3 Genovese, Genoa, Italy; Philos Counseling Academy, Genoa, Italy; Dept. of Education Sciences, University of Genoa, Corso A. Podestá 2, Italy; Dept of Informatics, Bioengineering, Robotics and Systems Engineering, University of Genoa, Via all'Opera Pia 13, 16145, Italy","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","5 Nov 2015","2015","","","5728","5731","Possession of `social' skills is crucial for persons with autism spectrum disorders (ASD) to maintain a certain independence and a better quality of life, and interaction with virtual environments seems an effective learning aid. In a previous study, we reported that in adults with ASD interaction with a virtual environment (a virtual city) is beneficial to the acquisition of pedestrian skills (street crossing and street navigation). Interaction was based on a gesture-based interface (Microsoft Kinect). Here we compare the learning performance when the same virtual environment is operated by a gamepad interface. We used exactly the same training protocol and data analysis than the original study. We found that both interface types are effective in the acquisition of street crossing and city navigation skills. The gamepad interface seems easier to use (thus leading to faster interaction), but gesture-based interfaces are superior in terms of transfer of the learned skills to real road environments (as reported by parents and caregivers).","1558-4615","978-1-4244-9271-8","10.1109/EMBC.2015.7319693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7319693","","Nickel;Virtual environments;Training;Navigation;Autism;Protocols","computer games;data analysis;learning (artificial intelligence);medical diagnostic computing;medical disorders;virtual reality","interface type effect;VR-based acquisition;pedestrian skills;autism spectrum disorders;quality-of-life;virtual environments;effective learning aid;ASD interaction;street crossing;street navigation;gesture-based interface;Microsoft Kinect;learning performance;gamepad interface;training protocol;data analysis","Accidents, Traffic;Autism Spectrum Disorder;Humans;Pedestrians;Quality of Life;User-Computer Interface","3","","11","","5 Nov 2015","","","IEEE","IEEE Conferences"
"A Heuristic Force Model for Haptic Simulation of Nasogastric Tube Insertion Using Fuzzy Logic","K. Choi; X. He; V. C. L. Chiang; Z. Deng; J. Qin","Centre for Smart Health, School of Nursing, Hong Kong Polytechnic University, Hung Hom, Hong Kong; Centre for Smart Health, School of Nursing, Hong Kong Polytechnic University, Hung Hom, Hong Kong; Centre for Smart Health, School of Nursing, Hong Kong Polytechnic University, Hung Hom, Hong Kong; School of Digital Media, Jiangnan University, Wuxi, China; Centre for Smart Health, School of Nursing, Hong Kong Polytechnic University, Hung Hom, Hong Kong","IEEE Transactions on Haptics","19 May 2017","2016","9","3","295","310","Nasogastric tube (NGT) placement is an essential clinical skill. The training is conventionally performed on rubber mannequins albeit practical limitations. Computer simulation with haptic feedback can potentially offer a more realistic and accessible training method. However, the complex interactions between the tube and the nasogastric passage make it difficult to model the haptic feedback during NGT placement. In this paper, a fuzzy-logic-based approach is proposed to directly transfer the experience of clinicians in NGT placement into the simulation system. Based on their perception of the varying tactile sensation and the conditions during NGT placement, the membership functions and fuzzy rules are defined to develop the force model. Forces created using the model are then combined with friction forces to drive the haptic device and render the insertion forces in real time. A prototype simulator is developed based on the proposed force model and the implementation details are presented. The usability of the prototype is also evaluated by clinical teachers. The proposed methodology has the potential for developing computerized NGT placement training methods for clinical education. It is also applicable for simulation systems involving complicated force interactions or computation-expensive models.","2329-4051","","10.1109/TOH.2016.2550044","SAR; Polytechnic University; Outstanding Youth Fund of the Jiangsu Province; Scholarship of Centre for Smart Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7448448","Fuzzy logic;force modeling;nasogastric tube intubation;haptic rendering","Force;Computational modeling;Haptic interfaces;Electron tubes;Training;Real-time systems;Finite element analysis","feedback;fuzzy logic;medical computing","heuristic force model;haptic simulation;nasogastric tube insertion;rubber mannequins albeit practical limitations;computer simulation;haptic feedback;realistic training method;complex interactions;nasogastric passage;fuzzy-logic-based approach;tactile sensation;fuzzy rules;friction forces;haptic device;insertion forces;prototype simulator;clinical teachers;computerized NGT placement;clinical education;training methods;complicated force interactions;computation-expensive models","Clinical Competence;Computer Simulation;Feedback;Friction;Fuzzy Logic;Heuristics;Humans;Intubation, Gastrointestinal;Mechanical Phenomena;Preceptorship;Touch;User-Computer Interface","1","","50","","6 Apr 2016","","","IEEE","IEEE Journals"
"A new symbolic program package for the interactive design of analog circuits","A. Liberatore; A. Luchetta; S. Manetti; M. C. Piccirilli","Florence Univ., Italy; NA; NA; NA","Proceedings of ISCAS'95 - International Symposium on Circuits and Systems","6 Aug 2002","1995","3","","2209","2212 vol.3","A new program package which constitutes an environment for the interactive exploration and improvement of analog circuit topologies is presented in this paper. The environment is provided with functionalities which permit the graphical schematic entry of the circuit, the symbolic analysis, the approximation of the symbolic results, the use of an external numerical simulator and the graphical postprocessing of both the symbolic and numerical simulation results. These functionalities allow us to immediately evaluate the influence of both topology and component value changes on the circuit behavior. The result is useful for educational/training purposes and for the interactive synthesis of new high-performance analog circuits.","","0-7803-2570-2","10.1109/ISCAS.1995.523866","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=523866","","Packaging;Analog circuits;Numerical simulation;Circuit simulation;Circuit topology;Circuit analysis;Analytical models;Performance analysis;Network topology;Transfer functions","software packages;circuit CAD;analogue circuits;network topology;circuit analysis computing;digital simulation","symbolic program package;interactive design;analog circuits;circuit topologies;functionalities;graphical schematic entry;symbolic analysis;external numerical simulator;graphical postprocessing;component value changes;training purposes","","21","1","4","","6 Aug 2002","","","IEEE","IEEE Conferences"
"The design of an object-oriented simulation tool for evaluating ATM network resource control schemes","J. Soldatos; D. Vergados; E. Vayias; N. Mitrou","Dept. of Electr. Eng. & Comput. Sci., Nat. Tech. Univ. of Athens, Greece; NA; NA; NA","1999 2nd International Conference on ATM. ICATM'99 (Cat. No.99EX284)","6 Aug 2002","1999","","","204","211","Changing the algorithmic components of ATM equipment such as ATM switches, requires full access to the switch control software, which is not available in most commercial products. Hence, most researchers still resort to simulation in order to evaluate new traffic control algorithms. This paper presents the architecture of an ATM simulator that operates at the call level, exposes the power of such a tool in evaluating different control architectures for ATM networks, and presents the status of a prototype implementation. ATM simulators based on the proposed architecture include a Web-based component (Java applet) which acts as user interface. This component enables tele-training and dissemination of important simulation results to remote sites.","","0-7803-5428-1","10.1109/ICATM.1999.786804","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=786804","","Object oriented modeling;Asynchronous transfer mode;Switches;Telecommunication control;Routing;Telecommunication switching;Java;User interfaces;Resource management;Computational modeling","object-oriented methods;software tools;digital simulation;telecommunication computing;asynchronous transfer mode;telecommunication control;telecommunication traffic;Java;distance learning","object-oriented simulation tool;ATM network resource control schemes;ATM switches;switch control software;traffic control algorithms;ATM simulator;call level;control architectures;prototype implementation;Web-based component;Java applet;user interface;tele-training;remote sites","","","","25","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Teaching a Robot to Grasp Real Fish by Imitation Learning from a Human Supervisor in Virtual Reality","J. S. Dyrstad; E. Ruud Øye; A. Stahl; J. Reidar Mathiassen","SINTEF Ocean AS, Trondheim, Norway; SINTEF Ocean AS, Trondheim, Norway; Department of Engineering Cybernetics, NTNU, Trondheim, Norway; SINTEF Ocean AS, Trondheim, Norway","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","6 Jan 2019","2018","","","7185","7192","We teach a real robot to grasp real fish, by training a virtual robot exclusively in virtual reality. Our approach implements robot imitation learning from a human supervisor in virtual reality. A deep 3D convolutional neural network computes grasps from a 3D occupancy grid obtained from depth imaging at multiple viewpoints. In virtual reality, a human supervisor can easily and intuitively demonstrate examples of how to grasp an object, such as a fish. From a few dozen of these demonstrations, we use domain randomization to generate a large synthetic training data set consisting of 100 000 example grasps of fish. Using this data set for training purposes, the network is able to guide a real robot and gripper to grasp real fish with good success rates. The newly proposed domain randomization approach constitutes the first step in how to efficiently perform robot imitation learning from a human supervisor in virtual reality in a way that transfers well to the real world.","2153-0866","978-1-5386-8094-0","10.1109/IROS.2018.8593954","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593954","","Robots;Task analysis;Three-dimensional displays;Grippers;Grasping;Cameras;Virtual reality","convolutional neural nets;grippers;learning (artificial intelligence);mobile robots;pose estimation;virtual reality","teaching;gripper;domain randomization approach;depth imaging;3D occupancy grid;robot imitation learning;deep 3D convolutional neural network;virtual robot;grasp real fish;virtual reality;human supervisor","","2","","19","","6 Jan 2019","","","IEEE","IEEE Conferences"
"A Two-Phase Transfer Learning-Based Power Spectrum Maps Reconstruction Algorithm for Underlay Cognitive Radio Networks","X. Han; L. Xue; Y. Xu; Z. Liu","Electronic Countermeasure College, National University of Defense Technology, Hefei, China; Electronic Countermeasure College, National University of Defense Technology, Hefei, China; Electronic Countermeasure College, National University of Defense Technology, Hefei, China; Electronic Countermeasure College, National University of Defense Technology, Hefei, China","IEEE Access","13 May 2020","2020","8","","81232","81245","In the underlay cognitive radio networks, the power spectrum maps (PSMs) estimation is the main challenge in sensing the idle wireless radio resources. Traditional deep learning-based algorithms achieve good estimation performance, under the hypothesis that the training data must be independent and identically distributed (i.i.d.) with the PSMs in the target region. However, collecting the PSMs training data is not an easy task, which is time-consuming and requires a numerous number of sensing devices. For this reason, we propose a two-phase transfer learning generative adversarial network (TPTL-GAN) for the PSMs reconstruction task. The proposed algorithm relaxes the i.i.d. assumption in traditional deep learning-based algorithms, allowing us to estimate the PSMs based on the simulated or previously collected training data, which share similar rather than strictly identical distribution with the target data. In the first phase of the TPTL-GAN algorithm, we design a domain projecting (DP) framework to project the source domain to the adjacent domain. In the second phase, we propose a domain completing (DC) framework, which extracts helpful radio environment features from the adjacent domain and reconstructs the PSMs in the target domain. Through the above two phases, the proposed algorithm provides a more accurate PSMs reconstruction performance than the traditional methods, as verified by the simulation results.","2169-3536","","10.1109/ACCESS.2020.2991183","Technology Funds of Fundamental Research Strengthening Plan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9081914","Cognitive radio networks;deep learning;power spectrum;transfer learning;wireless communication","Training data;Estimation;Cognitive radio;Task analysis;Interpolation;Feature extraction","cognitive radio;learning (artificial intelligence);neural nets;radio networks;radio spectrum management;telecommunication computing;wireless channels","power spectrum maps reconstruction algorithm;two-phase transfer learning;accurate PSMs reconstruction performance;target domain;helpful radio environment features;adjacent domain;TPTL-GAN algorithm;simulated collected training data;PSMs reconstruction task;generative adversarial network;PSMs training data;good estimation performance;traditional deep learning-based algorithms;idle wireless radio resources;power spectrum maps estimation;underlay cognitive radio networks","","1","","32","CCBY","29 Apr 2020","","","IEEE","IEEE Journals"
"Using of social networks in educational process","N. Kalinenko; V. Krasnopolsky; V. Kukharenko; A. Serebryakov","Volodymyr Dahl East Ukrainian National University, Molodizhnyi kvartal, 20-a, Luhansk, 91034, Ukraine; Volodymyr Dahl East Ukrainian National University, Molodizhnyi kvartal, 20-a, Luhansk, 91034, Ukraine; National Technical University “Kharkiv Polytechnic Institute”, 21, Frunze Street, 61002, Ukraine; Volodymyr Dahl East Ukrainian National University, Molodizhnyi kvartal, 20-a, Luhansk, 91034, Ukraine","2013 IEEE 7th International Conference on Intelligent Data Acquisition and Advanced Computing Systems (IDAACS)","14 Nov 2013","2013","02","","781","784","The learning process can now be described as targeted joint activities of the teacher and students in the educational environment. Education - a purposeful process of bilateral activities of the teacher and the student in the transfer and assimilation of knowledge. Development of Personal Learning Environment in virtual reality plays the key role.","","978-1-4799-1429-6","10.1109/IDAACS.2013.6663031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6663031","personal environment;virtual reality;mind mapping;social networks;web services;online learning;information technologies;educational environment","Social network services;Training;Materials;Educational institutions;Communities;Internet","computer aided instruction;social networking (online);virtual reality","social networks;educational process;learning process;educational environment;bilateral activity process;virtual reality;personal learning environment development","","1","","4","","14 Nov 2013","","","IEEE","IEEE Conferences"
"Robust Impedance Control for Dual User Haptic Training System","R. Heidari; M. Motaharifar; H. D. Taghirad","Advanced Robotics and Automated Systems (ARAS), Industrial Control Center of Excellence (ICCE), Faculty of Electrical Engineering, K.N. Toosi University of Technology,Tehran,Iran; Advanced Robotics and Automated Systems (ARAS), Industrial Control Center of Excellence (ICCE), Faculty of Electrical Engineering, K.N. Toosi University of Technology,Tehran,Iran; Advanced Robotics and Automated Systems (ARAS), Industrial Control Center of Excellence (ICCE), Faculty of Electrical Engineering, K.N. Toosi University of Technology,Tehran,Iran","2019 7th International Conference on Robotics and Mechatronics (ICRoM)","20 Apr 2020","2019","","","181","185","In this paper, an impedance controller with switching parameters for a dual-user haptic training system is introduced. The trainer and the trainee are connected through their haptic consoles, and the trainee performs the surgical procedure on the environment. The trainer can intervene in the procedure by pressing a mechanical pedal; thus, the control parameters are switched to transfer the authority over the task from the trainee to the trainer. The stability of each subsystem and the closed-loop stability of the overall system are investigated. The simulation results verify the performance of the proposed controller.","2572-6889","978-1-7281-6604-9","10.1109/ICRoM48714.2019.9071859","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9071859","Teleoperation;Dual-user;MIS;Surgery training;Impedance control;Dwell time","Haptic interfaces;Impedance;Surgery;Training;Mathematical model;Stability analysis;Force","closed loop systems;computer based training;control engineering computing;haptic interfaces;mechanical stability;medical computing;medical control systems;robot dynamics;robust control;surgery;switching systems (control);telerobotics","haptic consoles;robust impedance control;dual user haptic training system;surgical procedure;mechanical pedal;closed-loop stability;switching parameters;teleoperation methods","","","","19","","20 Apr 2020","","","IEEE","IEEE Conferences"
"Learning Safety Equipment Detection using Virtual Worlds","M. di Benedetto; E. Meloni; G. Amato; F. Falchi; C. Gennaro","National Research Council, Institute of Information Science and Technologies, Italy; Università di Pisa, Italy; National Research Council, Institute of Information Science and Technologies, Italy; National Research Council, Institute of Information Science and Technologies, Italy; National Research Council, Institute of Information Science and Technologies, Italy","2019 International Conference on Content-Based Multimedia Indexing (CBMI)","21 Oct 2019","2019","","","1","6","Nowadays, the possibilities offered by state-of-the-art deep neural networks allow the creation of systems capable of recognizing and indexing visual content with very high accuracy. Performance of these systems relies on the availability of high quality training sets, containing a large number of examples (e.g. million), in addition to the the machine learning tools themselves. For several applications, very good training sets can be obtained, for example, crawling (noisily) annotated images from the internet, or by analyzing user interaction (e.g.: on social networks). However, there are several applications for which high quality training sets are not easy to be obtained/created. Consider, as an example, a security scenario where one wants to automatically detect rarely occurring threatening events. In this respect, recently, researchers investigated the possibility of using a visual virtual environment, capable of artificially generating controllable and photo-realistic contents, to create training sets for applications with little available training images. We explored this idea to generate synthetic photo-realistic training sets to train classifiers to recognize the proper use of individual safety equipment (e.g.: worker protection helmets, high-visibility vests, ear protection devices) during risky human activities. Then, we performed domain adaptation to real images by using a very small image data set of real-world photographs. We show that training with the generated synthetic training set and using the domain adaptation step is an effective solution to address applications for which no training sets exist.","1949-3991","978-1-7281-4673-7","10.1109/CBMI.2019.8877466","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877466","Deep Learning;Virtual Dataset;Transfer Learning;Domain Adaptation;Safety Equipment Detection","Training;Safety;Games;Engines;Head;Neural networks;Visualization","feature extraction;image classification;learning (artificial intelligence);neural nets;occupational safety;virtual reality","visual virtual environment;photo-realistic training sets;high-visibility vests;safety equipment detection;virtual worlds;machine learning tools;classifier training;deep neural network training;individual safety equipment recognition;risky human activities","","2","","27","","21 Oct 2019","","","IEEE","IEEE Conferences"
"Perceptual Rendering for Learning Haptic Skills","T. Edmunds; D. K. Pai","Rutgers University, e-mail: tedmunds@cs.rutgers.edu; University of British Columbia, Rutgers University, e-mail: pai@cs.ubc.ca","2008 Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems","31 Mar 2008","2008","","","225","230","We approach the problem of creating haptic simulators that effectively impart skill without requiring high-fidelity devices by identifying perceptually salient events that signal transitions in the interaction. By augmenting these events, we seek to overcome deficiencies in the fidelity of the rendering hardware. We present an extension of event-based haptic rendering to non- collision events, and we describe a user-study of the training effectiveness of passive force-field haptic simulation vs. active event- augmented simulation in a tool-manipulation task. The results indicate that active augmentation improves skill transfer without requiring an increase in the quality of the rendering device.","2324-7355","978-1-4244-2005-6","10.1109/HAPTICS.2008.4479948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4479948","","Haptic interfaces;Discrete event simulation;Bones;Hardware;Humans;Feedback;Surgery;Surges;Signal processing;Shape","computer graphic equipment;haptic interfaces;learning (artificial intelligence);manipulators;rendering (computer graphics);virtual reality","perceptual rendering hardware;haptic skill learning;signal transitions;event-based haptic rendering;noncollision events;training;passive force-field haptic simulation;event-augmented simulation;tool-manipulation task","","9","","18","","31 Mar 2008","","","IEEE","IEEE Conferences"
"Street Crossing by Typically Developed Children in Real and Virtual Environments","O. Bart; N. Katz; P. L. Tamar; W. W. Josman; N. Josman","Dept. of Occupational Therapy, Tel Aviv Univ.; NA; NA; NA; NA","2006 International Workshop on Virtual Rehabilitation","9 Oct 2006","2006","","","42","46","Pedestrian injury is the second leading cause of death and serious injury among children between the ages of 5 and 14. The existing methods for teaching children how to cross the street safely are difficult to transfer to real life situations. The objective of this study was to evaluate the effectiveness of a virtual reality (VR) environment in teaching children how to cross a street safely. Eighty-six children (55 girls and 31 boys), aged 7-12 years, participated in the study. The children were observed while crossing a real street and tested on a test in the virtual environment (VE) prior to and following VR training. The children in the training group significantly improved their street crossing abilities in the VR simulation as well as in the real street crossing in comparison to the control group. Street crossing became safer with age however, no differences were found between boys and girls. This low-cost and readily available street crossing simulation had a positive effect on children's street crossing behavior and on their self-reported satisfaction","2331-9569","1-4244-0280-8","10.1109/IWVR.2006.1707525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1707525","","Injuries;Virtual reality;Safety;Medical treatment;Education;Road accidents;Testing;Aging;Virtual environment;Cancer","computer aided instruction;psychology;road safety;road traffic;teaching;virtual reality","street crossing;pedestrian injury;teaching;virtual reality environment;street safety","","1","","44","","9 Oct 2006","","","IEEE","IEEE Conferences"
"Scalable sim-to-real transfer of soft robot designs","S. Kriegman; A. M. Nasab; D. Shah; H. Steele; G. Branin; M. Levin; J. Bongard; R. Kramer-Bottiglio",University of Vermont; Yale University; Yale University; Yale University; Yale University; Tufts University; University of Vermont; Yale University,"2020 3rd IEEE International Conference on Soft Robotics (RoboSoft)","15 Jun 2020","2020","","","359","366","The manual design of soft robots and their controllers is notoriously challenging, but it could be augmented-or, in some cases, entirely replaced-by automated design tools. Machine learning algorithms can automatically propose, test, and refine designs in simulation, and the most promising ones can then be manufactured in reality (sim2real). However, it is currently not known how to guarantee that behavior generated in simulation can be preserved when deployed in reality. Although many previous studies have devised training protocols that facilitate sim2real transfer of control polices, little to no work has investigated the simulation-reality gap as a function of morphology. This is due in part to an overall lack of tools capable of systematically designing and rapidly manufacturing robots. Here we introduce a low cost, open source, and modular soft robot design and construction kit, and use it to simulate, fabricate, and measure the simulation-reality gap of minimally complex yet soft, locomoting machines. We prove the scalability of this approach by transferring an order of magnitude more robot designs from simulation to reality than any other method. The kit and its instructions can be found here: github.com/skriegman/sim2real4designs.","","978-1-7281-6570-7","10.1109/RoboSoft48309.2020.9116004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9116004","","","augmented reality;CAD;learning (artificial intelligence);manufacturing systems;mobile robots","training protocols;sim2real transfer;simulation-reality gap;modular soft robot design;construction kit;scalable sim-to-real transfer;automated design tools;machine learning;minimally complex yet soft;locomoting machines;rapid manufacturing","","1","","37","","15 Jun 2020","","","IEEE","IEEE Conferences"
"Instruction Manual for Product Assembly Process Based on Augmented Visualization","B. Li; Q. Dong; J. Dong; J. Wang; W. Li; S. Li","Beijing Institute of Mechanical Equipment, Beijing, China; Beijing Institute of Mechanical Equipment, Beijing, China; Beijing Institute of Mechanical Equipment, Beijing, China; Department of Industrial and Manufacturing System Engineering, Huazhong University of Science and Technology, Wuhan, China; Department of Industrial and Manufacturing System Engineering, Huazhong University of Science and Technology, Wuhan, China; Department of Industrial and Manufacturing System Engineering, Huazhong University of Science and Technology, Wuhan, China","2018 Chinese Automation Congress (CAC)","24 Jan 2019","2018","","","3248","3253","Augmented reality application in product assembly can notably improve the operation efficiency of shop floor workers in training or onsite work. The assembly manual system based on augmented reality technology is more complex than paper manual and virtual three-dimensional manual. This research work introduces a general two stages procedure for application of augmented assembly manual system. The relationship of assembly activities is described and the IDEF0 function diagram for augmented assembly application is presented. A detailed system framework for augmented assembly manual application is proposed and two stand alone experimental systems with file transfer mechanism are developed to instruct and assistant labours in assembly work at shop floor workstations.","","978-1-7281-1312-8","10.1109/CAC.2018.8623583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8623583","Augmented reality;Visualization manual;Assembly process;Workstation","Manuals;Active appearance model;Solid modeling;Visualization;Augmented reality;Workstations;Three-dimensional displays","assembling;augmented reality;production engineering computing;user manuals","stand alone experimental systems;assembly work;augmented visualization;augmented reality application;shop floor workers;augmented reality technology;three-dimensional manual;general two stages procedure;augmented assembly manual system;IDEF0 function diagram;detailed system framework;product assembly process instruction manual","","","","25","","24 Jan 2019","","","IEEE","IEEE Conferences"
"Dynamic modeling and control simulation of a haptic device","B. Behzadpour; M. Moghaddam; M. Arbabtafti","Mechatronics Lab in Mechanical Engineering Department, Tarbiat Modares University, Tehran, Iran; Mechanical Engineering Department, Tarbiat Modares University, Tehran, Iran; Mechanical Engineering Department, Shahid Rajaee Teacher Training University, Tehran, Iran","2011 IEEE International Conference on Robotics and Biomimetics","12 Apr 2012","2011","","","2993","2998","In this paper dynamic modeling, simulation and control of a six-DOF haptic interface are discussed, And two control strategies (the admittance control method and the impedance Control with Force Feedback method) are used for the applications of human/virtual environment, interaction. The simulated results of the admittance control are compered with the impedance control with force feedback. In this paper the Adams/Controls, part of the MD Adams software is used for modeling the dynamic behavior of the haptic device. The Adams model of the haptic interface is transferred directly to the MATLAB/Simulink environment. Then the simulation of the virtual environment and the controller design are performed in the MATLAB Simulink environment. In fact a real-time connection between the dynamic model and the controller is made by connection of the two software. Feedback linereazation method is used to control of position in the admitance control method. Then, dynamic equations of the haptic interface is derived, and integrated with the feedback linearization controller.","","978-1-4577-2138-0","10.1109/ROBIO.2011.6181483","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6181483","Haptic Interface;Impedance Control;Admittance Control;Real-Time;Feedback Linearization","Haptic interfaces;Impedance;Admittance;Mathematical model;Software;Equations;Force","control engineering computing;control system synthesis;force feedback;haptic interfaces;human computer interaction;position control;virtual reality","dynamic modeling;control simulation;haptic device;six-DOF haptic interface;control strategy;admittance control method;impedance control;force feedback method;human-virtual environment;Adams-controls;MD Adams software;dynamic behavior;MATLAB environment;Simulink environment;controller design;real-time connection;feedback linereazation method;position control;dynamic equations;feedback linearization controller","","4","","8","","12 Apr 2012","","","IEEE","IEEE Conferences"
"Study on effects of network characteristics on cooperation performance in a desktop CVE system","Chen Ling; Chen Gen-Cai; Chen Hong; Xu Xiao-Lei; Chen Chun","Coll. of Comput. Sci. & Technol., Zhejiang Univ., Hangzhou, China; Coll. of Comput. Sci. & Technol., Zhejiang Univ., Hangzhou, China; Coll. of Comput. Sci. & Technol., Zhejiang Univ., Hangzhou, China; Coll. of Comput. Sci. & Technol., Zhejiang Univ., Hangzhou, China; Coll. of Comput. Sci. & Technol., Zhejiang Univ., Hangzhou, China","8th International Conference on Computer Supported Cooperative Work in Design","8 Nov 2004","2004","1","","121","126 Vol.1","The influences of network characteristics (e.g. latency, packet loss) on the task performance in desktop collaborative virtual environment (CVE) systems were studied. In the experiment, two remote partners worked together to manipulate shared virtual objects over a network, and a network emulator was utilized to simulate the real network. The task in the experiment was to minimize the time to transfer a frame through a rod with no collisions. The performance of human subjects was measured and analyzed quantitatively as a function of network latency and packet loss rate. The experiment results show that the delay had little effect on the task performance while the network latency was less than 200 ms and it was acceptable while the network latency was less than 500 ms; the packet loss had no effect on the task performance while there were 20 state update messages received and it was acceptable while there were more than 10 state update messages received.","","0-7803-7941-1","10.1109/CACWD.2004.1349000","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1349000","","Intelligent networks;Performance loss;Collaboration;Industrial training;Virtual environment;Delay effects;Navigation;Educational institutions;Computer science;Collaborative work","groupware;virtual reality;computer networks;delays;digital simulation;user interfaces","network characteristics;cooperation performance;desktop CVE system;collaborative virtual environment;shared virtual objects;network emulator;network simulation;network latency;packet loss rate;state update messages","","1","","11","","8 Nov 2004","","","IEEE","IEEE Conferences"
"RoboTHOR: An Open Simulation-to-Real Embodied AI Platform","M. Deitke; W. Han; A. Herrasti; A. Kembhavi; E. Kolve; R. Mottaghi; J. Salvador; D. Schwenk; E. VanderBilt; M. Wallingford; L. Weihs; M. Yatskar; A. Farhadi",University of Washington; PRIOR @ Allen Institute for AI; PRIOR @ Allen Institute for AI; PRIOR @ Allen Institute for AI; University of Washington; PRIOR @ Allen Institute for AI; PRIOR @ Allen Institute for AI; University of Washington; PRIOR @ Allen Institute for AI; PRIOR @ Allen Institute for AI; PRIOR @ Allen Institute for AI; University of Washington; PRIOR @ Allen Institute for AI; PRIOR @ Allen Institute for AI; University of Washington,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","3161","3171","Visual recognition ecosystems (e.g. ImageNet, Pascal, COCO) have undeniably played a prevailing role in the evolution of modern computer vision. We argue that interactive and embodied visual AI has reached a stage of development similar to visual recognition prior to the advent of these ecosystems. Recently, various synthetic environments have been introduced to facilitate research in embodied AI. Notwithstanding this progress, the crucial question of how well models trained in simulation generalize to reality has remained largely unanswered. The creation of a comparable ecosystem for simulation-to-real embodied AI presents many challenges: (1) the inherently interactive nature of the problem, (2) the need for tight alignments between real and simulated worlds, (3) the difficulty of replicating physical conditions for repeatable experiments, (4) and the associated cost. In this paper, we introduce RoboTHOR to democratize research in interactive and embodied visual AI. RoboTHOR offers a framework of simulated environments paired with physical counterparts to systematically explore and overcome the challenges of simulation-to-real transfer, and a platform where researchers across the globe can remotely test their embodied models in the physical world. As a first benchmark, our experiments show there exists a significant gap between the performance of models trained in simulation when they are tested in both simulations and their carefully constructed physical analogs. We hope that RoboTHOR will spur the next stage of evolution in embodied computer vision.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00323","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157346","","Robots;Navigation;Artificial intelligence;Task analysis;Computational modeling;Visualization;Training","artificial intelligence;computer vision;image recognition;interactive systems;public domain software;robot vision;virtual reality","interactive visual AI;open simulation-to-real embodied AI platform;embodied visual AI;embodied computer vision;simulation-to-real transfer;simulated environments;RoboTHOR;visual recognition ecosystems","","1","","79","","5 Aug 2020","","","IEEE","IEEE Conferences"
"Driver Pose Estimation Using Recurrent Lightweight Network and Virtual Data Augmented Transfer Learning","Y. Liu; P. Lasang; S. Pranata; S. Shen; W. Zhang","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Panasonic Research and Development Center Singapore, Singapore; Panasonic Research and Development Center Singapore, Singapore; Panasonic Research and Development Center Singapore, Singapore; Panasonic Research and Development Center Singapore, Singapore","IEEE Transactions on Intelligent Transportation Systems","2 Oct 2019","2019","20","10","3818","3831","Driver poses recognition contains three tasks such as body joint, head angle, and face landmark estimation, which is of paramount interest for the advanced driver assistance systems (ADAS). Recently proposed methods intend to use deeper and more complicated networks to achieve better performance, which leads to heavy models that are not feasible for the resource limited applications such as ADAS. To resolve this issue, we have worked on the following aspects: 1) a lightweight network model, which is referred to as recurrent multi-task thin net (RM-ThinNet), has been proposed which was especially designed for the computationally and memory limited devices; 2) a recurrent structure has been introduced to handle the scale difference and dependency between different tasks, and this recurrence ensures the different tasks are accomplished at different stages and their outputs can augment each other; and 3) a virtual data synthesization pipeline and a couple transfer learning method have been presented, by which network can be learnt effectively by relatively a small number of real data. Comparisons with the state-of-the-art methods reveal the superiority of the proposed method and competitive performance can be achieved with smaller model size and faster speed.","1558-0016","","10.1109/TITS.2019.2921325","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8743560","Driver joints detection;head angle estimation;face landmark localization;transfer learning","Pose estimation;Task analysis;Face;Computational modeling;Data models;Training","augmented reality;driver information systems;face recognition;learning (artificial intelligence);pose estimation","driver pose estimation;recurrent lightweight network;virtual data augmented transfer learning;body joint;head angle;face landmark estimation;advanced driver assistance systems;ADAS;deeper networks;resource limited applications;lightweight network model;recurrent multitask thin net;RM-ThinNet;memory limited devices;recurrent structure;virtual data synthesization pipeline;transfer learning method","","2","","75","","21 Jun 2019","","","IEEE","IEEE Journals"
"Interactive educational system for coal combustion modeling in power plant boilers","M. Gayer; P. Slavik; F. Hrdlicka","Comput. Sci. & Eng. Dept., Czech Tech. Univ., Prague, Czech Republic; NA; NA","The IEEE Region 8 EUROCON 2003. Computer as a Tool.","3 Dec 2003","2003","2","","220","224 vol.2","We present our educational system for interactive education of combustion processes. The system is built on several concepts used mainly in the computer graphics area (fluid simulator, particle system) and combustion simulation field (simplified combustion process model and heat transfer engine). Together they combine unique and original concepts that offer real-time simulation and visualization of the combustion process. The user may have immediate interaction during simulation and visualization - e.g. changing coal inlets and combustible properties and other input parameters during simulation. The system allows real-time monitoring of about 40 basic cell volume characteristics inside the boiler and 10 pulverized coal particle characteristics. All these features are available immediately, without needing to wait hours for complex calculations to finish. The system is especially suitable for interactive education purposes in power-engineering.","","0-7803-7763-X","10.1109/EURCON.2003.1248187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1248187","","Combustion;Power system modeling;Power generation;Boilers;Computational modeling;Computer simulation;Heat engines;Visualization;Computer science education;Computer graphics","computer aided instruction;computer based training;user interfaces;interactive systems;power plants;combustion;modelling","interactive educational system;coal combustion modeling;power plant boilers;educational system;interactive education;combustion processes;computer graphics area;fluid simulator;particle system;combustion simulation field;simplified combustion process model;heat transfer engine;real-time simulation;combustion process visualization;coal inlets;combustible properties;input parameters;real-time monitoring;cell volume characteristics;pulverized coal particle characteristics;power-engineering","","","","11","","3 Dec 2003","","","IEEE","IEEE Conferences"
"Haptics Assisted Training (HAT) System for children's handwriting","Y. Kim; M. Collins; W. Bulmer; S. Sharma; J. Mayrose","Tactus Technologies, Inc., 2350 North Forest Road, Suite 16A, Getzville, NY 14068, USA; Tactus Technologies, Inc., 2350 North Forest Road, Suite 16A, Getzville, NY 14068, USA; Tactus Technologies, Inc., 2350 North Forest Road, Suite 16A, Getzville, NY 14068, USA; Tactus Technologies, Inc., 2350 North Forest Road, Suite 16A, Getzville, NY 14068, USA; 414 Upton Hall, Buffalo State College, State University of New York, Buffalo, NY 14222, USA","2013 World Haptics Conference (WHC)","7 Oct 2013","2013","","","559","564","We present Haptics Assisted Training (HAT) System, a force feedback workstation for transferring and improving handwriting skill. The HAT system is the first practical handwriting training system whose usability was tested both in typical and special education classrooms of a local school district. Simulating the role of occupational therapists (OT), the HAT system guides the user's hand along the sequence of strokes of the reference handwriting recorded by an expert or teacher. Since the handwriting data is formatted as a set of ordered paths, it can teach any form of pen strokes, such as words, shapes, and even drawings. Training tasks are presented as a 3D game which captures children's attention and more effective visual motor integration (VMI) is anticipated than traditional paper materials. In this paper we describe the design and implementation of the prototype. We also report a comparative study on handwriting performance of twenty participants grouped into four categories by education types (special vs. typical) and haptic devices (Phantom Omni™ vs. Novint Falcon™). As a result, we observed that the children quickly adjusted themselves to the system, and they sustained engagement at the word-writing tasks without any intervention. Results also showed improvements in tracing precision on the HAT system over time. Details of the results and lessons learned from the study are discussed.","","978-1-4799-0088-6","10.1109/WHC.2013.6548469","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6548469","Haptics;handwriting;children;skill;training;game;visual motor integration;VMI;dysgraphia","Haptic interfaces;Writing;Training;Games;Force;Educational institutions","computer aided instruction;force feedback;handicapped aids;haptic interfaces","Haptics Assisted Training system;HAT system;children handwriting;force feedback workstation;handwriting skill transfer;handwriting skill improvement;handwriting training system;special education classroom;local school district;occupational therapy;user hand guidance;stroke sequence;handwriting data;pen stroke;shapes;drawing;3D game;children attention;visual motor integration;VMI;handwriting performance;typical education;haptic device;Phantom Omni;Novint Falcon;word-writing task;tracing precision","","1","","21","","7 Oct 2013","","","IEEE","IEEE Conferences"
"A Digital-Twin-Assisted Fault Diagnosis Using Deep Transfer Learning","Y. Xu; Y. Sun; X. Liu; Y. Zheng","School of Business Administration, South China University of Technology, Guangzhou, China; School of Business Administration, Guangzhou University, Guangzhou, China; School of Business Administration, South China University of Technology, Guangzhou, China; School of Business Administration, South China University of Technology, Guangzhou, China","IEEE Access","21 Feb 2019","2019","7","","19990","19999","Digital twin is a significant way to achieve smart manufacturing, and provides a new paradigm for fault diagnosis. Traditional data-based fault diagnosis methods mostly assume that the training data and test data are following the same distribution and can acquire sufficient data to train a reliable diagnosis model, which is unrealistic in the dynamic changing production process. In this paper, we present a two-phase digital-twin-assisted fault diagnosis method using deep transfer learning (DFDD), which realizes fault diagnosis both in the development and maintenance phases. At first, the potential problems that are not considered at design time can be discovered through front running the ultra-high-fidelity model in the virtual space, while a deep neural network (DNN)-based diagnosis model will be fully trained. In the second phase, the previously trained diagnosis model can be migrated from the virtual space to physical space using deep transfer learning for real-time monitoring and predictive maintenance. This ensures the accuracy of the diagnosis as well as avoids wasting time and knowledge. A case study about fault diagnosis using DFDD in a car body-side production line is presented. The results show the superiority and feasibility of our proposed method.","2169-3536","","10.1109/ACCESS.2018.2890566","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598879","Digital twin;deep transfer learning;fault diagnosis;smart manufacturing","Fault diagnosis;Data models;Manufacturing;Training data;Maintenance engineering;Predictive models;Solid modeling","fault diagnosis;learning (artificial intelligence);neural nets;production engineering computing;virtual reality","deep transfer learning;digital twin;reliable diagnosis model;two-phase digital-twin-assisted fault diagnosis method;virtual space;data-based fault diagnosis methods;fidelity model;deep neural network based diagnosis model;smart manufacturing;DFDD;production process;real-time monitoring;predictive maintenance;DNN","","17","","51","","1 Jan 2019","","","IEEE","IEEE Journals"
"Wearable Brain–Computer Interface Instrumentation for Robot-Based Rehabilitation by Augmented Reality","P. Arpaia; L. Duraccio; N. Moccaldi; S. Rossi","Department of Electrical Engineering and Information Technology, Universita’ degli Studi di Napoli Federico II, Naples, Italy; Centro Regionale di Competenza Tecnologie Scarl, Naples, Italy; Department of Electrical Engineering and Information Technology, Universita’ degli Studi di Napoli Federico II, Naples, Italy; Department of Electrical Engineering and Information Technology, Universita’ degli Studi di Napoli Federico II, Naples, Italy","IEEE Transactions on Instrumentation and Measurement","11 Aug 2020","2020","69","9","6362","6371","An instrument for remote control of the robot by wearable brain-computer interface (BCI) is proposed for rehabilitating children with attention-deficit/hyperactivity disorder (ADHD). Augmented reality (AR) glasses generate flickering stimuli, and a single-channel electroencephalographic BCI detects the elicited steady-state visual evoked potentials (SSVEPs). This allows benefiting from the SSVEP robustness by leaving available the view of robot movements. Together with the lack of training, a single channel maximizes the device's wearability, fundamental for the acceptance by ADHD children. Effectively controlling the movements of a robot through a new channel enhances rehabilitation engagement and effectiveness. A case study at an accredited rehabilitation center on ten healthy adult subjects highlighted an average accuracy higher than 83%, with information transfer rate (ITR) up to 39 b/min. Preliminary further tests on four ADHD patients between six- and eight-years old provided highly positive feedback on device acceptance and attentional performance.","1557-9662","","10.1109/TIM.2020.2970846","project Advanced Virtual AdaptiveTechnologies e-hEAlth (AVATEA, CUP. B13D18000130007) POR FESRCAMPANIA 2014/2020; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8977500","Augmented reality (AR);brain-computer interfaces;rehabilitation robotics;smart devices","Electroencephalography;Visualization;Instruments;Glass;Robot sensing systems;Electrodes","augmented reality;brain;brain-computer interfaces;electroencephalography;handicapped aids;medical disorders;medical signal processing;neurophysiology;patient rehabilitation;visual evoked potentials","available the view;robot movements;single channel;device;ADHD children;rehabilitation engagement;accredited rehabilitation center;ADHD patients;wearable brain-computer interface instrumentation;robot-based rehabilitation;remote control;augmented reality glasses;single-channel electroencephalographic BCI;steady-state visual evoked potentials;SSVEPs;SSVEP robustness","","3","","53","IEEE","31 Jan 2020","","","IEEE","IEEE Journals"
"LORM: Learning to Optimize for Resource Management in Wireless Networks With Few Training Samples","Y. Shen; Y. Shi; J. Zhang; K. B. Letaief","Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong","IEEE Transactions on Wireless Communications","8 Jan 2020","2020","19","1","665","679","Effective resource management plays a pivotal role in wireless networks, which, unfortunately, typically results in challenging mixed-integer nonlinear programming (MINLP) problems. Machine learning-based methods have recently emerged as a disruptive way to obtain near-optimal performance for MINLPs with affordable computational complexity. There have been some attempts in applying such methods to resource management in wireless networks, but these attempts require huge amounts of training samples and lack the capability to handle constrained problems. Furthermore, they suffer from severe performance deterioration when the network parameters change, which commonly happens and is referred to as the task mismatch problem. In this paper, to reduce the sample complexity and address the feasibility issue, we propose a framework of Learning to Optimize for Resource Management (LORM). In contrast to the end-to-end learning approach adopted in previous studies, LORM learns the optimal pruning policy in the branch-and-bound algorithm for MINLPs via a sample-efficient method, namely, imitation learning. To further address the task mismatch problem, we develop a transfer learning method via self-imitation in LORM, named LORM-TL, which can quickly adapt a pre-trained machine learning model to the new task with only a few additional unlabeled training samples. Numerical simulations demonstrate that LORM outperforms specialized state-of-the-art algorithms and achieves near-optimal performance, while providing significant speedup compared with the branch-and-bound algorithm. Moreover, LORM-TL, by relying on a few unlabeled samples, achieves comparable performance with the model trained from scratch with sufficient labeled samples.","1558-2248","","10.1109/TWC.2019.2947591","General Research Funding from the Research Grants Council of Hong Kong; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8879693","Resource allocation;mixed-integer nonlinear programming;wireless communications;few-shot learning;transfer learning","Resource management;Optimization;Machine learning algorithms;Wireless networks;Training;Machine learning;Heuristic algorithms","computational complexity;integer programming;learning (artificial intelligence);nonlinear programming;radio networks;telecommunication computing;tree searching","end-to-end learning approach;optimal pruning policy;branch-and-bound algorithm;MINLP;sample-efficient method;imitation learning;task mismatch problem;transfer learning method;named LORM-TL;pre-trained machine;additional unlabeled training samples;achieves near-optimal performance;unlabeled samples;sufficient labeled samples;wireless networks;effective resource management;mixed-integer nonlinear programming problems;machine learning-based methods;affordable computational complexity;constrained problems;severe performance deterioration;network parameters change;sample complexity","","14","","35","IEEE","22 Oct 2019","","","IEEE","IEEE Journals"
"The Simulation of Business Processes in Education","M. A. Arango Arango; J. P. Rios Rodriguez","Facultad de Ingenierías, Universidad de Medellín/ Universidad Nacional de Colombia, Medellín, Colombia; Centro de Comercio, Servicio Nacional de Aprendizaje (SENA), Medellín, Colombia","2019 14th Iberian Conference on Information Systems and Technologies (CISTI)","15 Jul 2019","2019","","","1","5","Education as a basis for the development of societies requires that educational institutions due to the phenomenon of globalization include and generate changes in their teaching processes to be at the forefront. For this reason, this article aims to highlight the benefits of the incorporation of educational software, designed for the accounting and financial area as a didactic tool in the transfer and appropriation of knowledge that contributes to improving learning and knowing the different business processes by means of simulation. In this sense, this writing encourages the use of educational software for teaching business processes.","2166-0727","978-9-8998-4349-3","10.23919/CISTI.2019.8760766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8760766","Training by competition;Accounting simulator;Business management","Software;Business;Education;Information systems;Hardware;Globalization;Tools","computer aided instruction;educational institutions;financial data processing;teaching","financial accounting simulator;educational institutions;teaching processes;educational software;financial area;globalization;business processes","","","","","","15 Jul 2019","","","IEEE","IEEE Conferences"
"Haptic Microrobotic Cell Injection System","A. Ghanbari; B. Horan; S. Nahavandi; X. Chen; W. Wang","Department of Mechanical Engineering, University of Canterbury, Christchurch, New Zealand; School of Engineering, Deakin University, Geelong, Australia; Centre for Intelligent Systems Research, Deakin University, Melbourne, Australia; Department of Mechanical Engineering, University of Canterbury, Christchurch, New Zealand; Department of Mechanical Engineering, University of Canterbury, Christchurch, New Zealand","IEEE Systems Journal","22 May 2014","2014","8","2","371","383","Microrobotic cell injection is the subject of increasing research interest. At present, an operator relies completely on visual information and can be subject to low success rates, poor repeatability, and extended training times. This paper focuses on increasing operator performance during cell injection in two ways. First, our completed haptic cell injection system aims to increase the operator's performance during real-time cell injection. Haptic bilateralism is investigated and a mapping framework provides an intuitive method for manoeuvring the micropipette in a manner similar to handheld needle insertion. Volumetric virtual fixtures are then introduced to haptically assist the operator to penetrate the cell at the desired location. The performance of the volumetric virtual fixtures is also discussed. Second, the haptically enabled cell injection system is replicated as a virtual environment facilitating virtual offline operator training. Virtual operator training utilizes the same mapping framework and haptic virtual fixtures as the physical system allowing the operator to train offline and then directly transfer their skills to real-time cell injection.","1937-9234","","10.1109/JSYST.2012.2206440","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6255757","Haptic cell injection;haptic virtual fixtures;virtual cell injection;virtual operator training;Haptic cell injection;haptic virtual fixtures;virtual cell injection;virtual operator training","Haptic interfaces;Micromanipulators;Hip;Joints;Phantoms;Kinematics;Training","biology computing;control engineering computing;haptic interfaces;microrobots;virtual reality","haptic microrobotic cell injection system;visual information;operator performance;realtime cell injection;haptic bilateralism;mapping framework;micropipette manoeuver;handheld needle insertion;volumetric virtual fixtures;virtual environment;haptic virtual fixtures","","30","","39","","31 Jul 2012","","","IEEE","IEEE Journals"
"Deep Transfer Learning-Based Downlink Channel Prediction for FDD Massive MIMO Systems","Y. Yang; F. Gao; Z. Zhong; B. Ai; A. Alkhateeb","Institute for Artificial Intelligence, Tsinghua University (THUAI), Beijing, China; Institute for Artificial Intelligence, Tsinghua University (THUAI), Beijing, China; self-employed, China; State Key Laboratory of Rail Traffic Control and Safety, Beijing Jiaotong University, Beijing, China; School of Electrical, Computer, and Energy Engineering, Arizona State University, Tempe, AZ, USA","IEEE Transactions on Communications","15 Dec 2020","2020","68","12","7485","7497","Artificial intelligence (AI) based downlink channel state information (CSI) prediction for frequency division duplexing (FDD) massive multiple-input multiple-output (MIMO) systems has attracted growing attention recently. However, existing works focus on the downlink CSI prediction for the users under a given environment and is hard to adapt to users in new environment especially when labeled data is limited. To address this issue, we formulate the downlink channel prediction as a deep transfer learning (DTL) problem, and propose the direct-transfer algorithm based on the fully-connected neural network architecture, where the network is trained in the manner of classical deep learning and is then fine-tuned for new environments. To further improve the transfer efficiency, we propose the meta-learning algorithm that trains the network by alternating inner-task and across-task updates and then adapts to a new environment with a small number of labeled data. Simulation results show that the direct-transfer algorithm achieves better performance than the deep learning algorithm, which implies that the transfer learning benefits the downlink channel prediction in new environments. Moreover, the meta-learning algorithm significantly outperforms the direct-transfer algorithm, which validates its effectiveness and superiority.","1558-0857","","10.1109/TCOMM.2020.3019077","National Key Research and Development Program of China; National Natural Science Foundation of China; Beijing Municipal Natural Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9175003","Deep transfer learning (DTL);meta-learning;few-shot learning;downlink CSI prediction;FDD;massive MIMO","Downlink;Prediction algorithms;Uplink;Machine learning;MIMO communication;Task analysis;Training","channel estimation;deep learning (artificial intelligence);frequency division multiplexing;MIMO communication;neural net architecture;telecommunication computing","deep learning algorithm;downlink channel prediction;metalearning algorithm;direct-transfer algorithm;FDD massive MIMO systems;frequency division duplexing massive multiple-input multiple-output systems;deep transfer learning problem;fully-connected neural network architecture;transfer efficiency improvement;artificial intelligence;downlink channel state information prediction;CSI prediction;DTL;alternating inner-task;across-task updates;labeled data","","4","","50","IEEE","24 Aug 2020","","","IEEE","IEEE Journals"
"The transfer of non-visual spatial knowledge between real and virtual mazes via sensory substitution","D. Chebat; S. Maidenbaum; A. Amedi","Visual and Cognitive Neuroscience Laboratory (VCN Lab), Department of Behavioral Sciences & Psychology, Ariel University, Israel; The Department of Medical Neurobiology, Institute for Medical Research Israel-Canada (IMRIC), Faculty of Medicine, The Hebrew University of Jerusalem, Hadassah Ein Kerem, Israel; The Department of Medical Neurobiology, Institute for Medical Research Israel-Canada (IMRIC), Faculty of Medicine, The Hebrew University of Jerusalem, Hadassah Ein Kerem, Israel","2017 International Conference on Virtual Rehabilitation (ICVR)","14 Aug 2017","2017","","","1","7","Many attempts are being made to ease navigation for people who are blind, both in terms of spatial learning and of navigation. One promising approach is the use of virtual environments for safe and versatile training. While it is known that humans can transfer non-visual spatial knowledge between real and virtual environments, limitations of these studies typically include results obtained mainly in simple environments, using mainly blindfolded-sighted participants and different methods of sensory input for real and virtual environments. In this study, participants with a wide range of visual experience use the EyeCane and Virtual EyeCane to solve complex Hebb-Williams mazes in real and virtual environments. The EyeCane and its virtual counterpart are minimalistic sensory substitution devices that code single-point distance information into sound. We test whether participants improve performance in the real-to-virtual sequence: solve a real maze and subsequently improve performance in the virtual maze. We also test whether participants can sole a virtual maze and subsequently improve performance in the virtual world: the virtual-to-real sequence. We find that participants can use sensory substitution guided navigation to extract spatial information from the virtual world and apply it to significantly improve their behavioral performance in the real world and vice versa. Our results demonstrate transfer in both direction, strengthening and extending the existing literature in terms of complexity, parameters, input-matching and varying levels of visual experience.","2331-9569","978-1-5090-3053-8","10.1109/ICVR.2017.8007542","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007542","Virtual Reality;assistive technology;Sensory Substitution;blind;Congenital Blindness;Low Vision;Acquired Blindness;Visual Rehabilitation;Environmental Rehabilitation;Spatial knowledge;Perceptual Learning;Maze Learning","Navigation;Virtual environments;Training;Visualization;Blindness;Meters","handicapped aids;medical computing;patient rehabilitation;virtual reality","nonvisual spatial knowledge transfer;real mazes;virtual mazes;sensory substitution;blind people;spatial learning;navigation;virtual environments;blindfolded-sighted participants;EyeCane;Virtual EyeCane;complex Hebb-Williams mazes;single-point distance information coding;input matching","","1","","36","","14 Aug 2017","","","IEEE","IEEE Conferences"
"Neural-network-based call admission control in ATM networks with heterogeneous arrivals","J. M. Hah; P. L. Tien; M. C. Yuang","Dept. of Comput. Sci. & Inf. Eng., Nat. Chiao Tung Univ., Hsinchu, Taiwan; NA; NA","Proceedings of LCN - 21st Annual Conference on Local Computer Networks","6 Aug 2002","1996","","","259","266","Call admission control (CAC) has been accepted as a potential solution for supporting diverse, heterogeneous traffic sources demanding different quality of services in asynchronous transfer mode (ATM) networks. Besides, CAC is required to consume a minimum of time and space to make call acceptance decisions. We present an efficient neural-network-based CAC (NNCAC) mechanism for ATM networks with heterogeneous arrivals. All heterogeneous traffic calls are initially categorized into various classes. Based on the number of calls in each class, the NNCAC efficiently and accurately estimates the cell delay and cell loss ratio of each class in real time by means of a pre-trained neural network. According to our decent study which exhibits the superiority of the employment of analysis-based training data over simulation-based data, we particularly construct the training data from heterogeneous-arrival dual-class queueing model M/sup [N1]/+I/sup [N2]//D/1/K, where M and I represent the Bernoulli process and interrupted Bernoulli process, and N/sub 1/ and N/sub 2/ represent the corresponding numbers of calls, respectively. Analytic results of the queueing model are confirmed by simulation results. Finally, we demonstrate the profound agreement of our neural-network-based estimated results with analytic results, justifying the viability of our NNCAC mechanism.","0742-1303","0-8186-7617-5","10.1109/LCN.1996.558154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=558154","","Call admission control;Asynchronous transfer mode;Traffic control;Delay estimation;Training data;Analytical models;Queueing analysis;Communication system traffic control;Quality of service;Telecommunication traffic","asynchronous transfer mode;telecommunication computing;telecommunication congestion control;telecommunication traffic;delays;queueing theory;backpropagation;multilayer perceptrons;telecommunication networks","neural network based call admission control;ATM networks;heterogeneous arrivals;heterogeneous traffic sources;quality of services;asynchronous transfer mode;heterogeneous traffic calls;cell delay;cell loss ratio;pretrained neural network;analysis-based training data;simulation-based data;dual-class queueing model;Bernoulli process;interrupted Bernoulli process;simulation results;backpropagation","","","1","26","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Evaluation of learner's skills in the context of dynamic and complex systems","K. Yacef; L. Alem","Thomson Radar Australia Corp., Australia; NA","1996 IEEE International Conference on Systems, Man and Cybernetics. Information Intelligence and Systems (Cat. No.96CH35929)","6 Aug 2002","1996","3","","2200","2204 vol.3","The air traffic control (ATC) operational skills are developed using simulation of authentic problems. Such authentic problems have enormous potential for learning as they are real and will probably arise in the controller's real work. Resolving authentic problems on a simulator encourages transfer by demonstrating when the knowledge is useful and by showing the effect of the learner's actions. However this process is difficult, since authentic problems tend to require a wide range of knowledge which often lead the learner in activities beyond their abilities. Some support is required for learning from simulation to occur. Sometimes this support is provided by human tutors (in ATC training for example this support is provided by a human instructor sitting at the back of the controller during the running of an exercise on the simulator), this support could also be given by a computer learning environment. This paper presents an intelligent simulator-based learning environment for air traffic controllers which provides a protected and guided environment to the learner. One central element of this environment is the ability to evaluate the learner's skills. We describe our approach to the evaluation of learner's skills, which uses task performance as well as situation complexity and degree of task practice as a means for building an overlay model of the learner.","1062-922X","0-7803-3280-6","10.1109/ICSMC.1996.565492","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=565492","","Humans;Problem-solving;Availability;Intelligent systems;Context modeling;Intelligent structures;Performance evaluation;Air traffic control","air traffic control;aerospace simulation;digital simulation;computer based training;computer aided instruction;user modelling","learner skill evaluation;dynamic complex systems;air traffic control;ATC;human tutors;intelligent simulator-based learning environment;task performance;situation complexity","","1","1","14","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Cyber laboratory for hardware logic experiments: A seamless integration of actual laboratory and remote laboratory","N. Koike","Faculty of Computer and Information Sciences, Hosei University, 3-7-2 Kajino-cho, Koganei-shi, Tokyo 184-8584, Japan","2012 International Conference on Information Technology Based Higher Education and Training (ITHET)","23 Jul 2012","2012","","","1","5","Cyber Laboratory for FPGA-based logic design course is underdevelopment. It combines the existing actual hardware laboratory and the remote laboratory, with newly designed CAD services and FPGA-run services realized in the form of the Web Services. A Cloud-storage is employed to transfer large CAD files and simulation data files among laboratory FPGA-Platforms and student laptop/desktop home PCs. Design Files can be shared among students, TAs and Teachers for further consultations. Students can easily migrate from actual laboratory to remote laboratory and vice versa. The Cyber laboratory takes advantage of student PCs' active participations in the remote laboratory mode to off-load time consuming tasks, such as logic simulation, from actual laboratory's FPGA-design platforms. It is also effective to avoid network latency and to improve interactive response. Cyber laboratory uses commercial Verilog-HDL logic synthesis tools, FPGA Test-beds and logic analyzers, those are tightly integrated into specific hardware platforms and difficult to decouple. So, actual laboratory organization is still plays an important role in the remote laboratory mode. CAD Web services and FPGA-run Web services are developed to combine remote student PCs with actual laboratory FPGA-Platforms. Those handle compilation, FPGA-run and logic analyzer setup/measure tasks in the form of the Web services. As the laboratory FPGA-Platforms have to serve in two ways: actual laboratory services and remote laboratory services, two separate Virtual Machines are prepared for all laboratory PCs in the form of VM PC clusters. A VM managing PC handles the allocations of VMs to laboratory PCs, according to the usage of PCs. When the actual laboratory is in use, most PCs are assigned as the actual lab VMs. During off-class hours or at night-time, most PCs run the remote service VMs. In this way, a scalable and efficient FPGA based logic design cyber laboratory can be realized.","","978-1-4673-2334-5","10.1109/ITHET.2012.6246013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6246013","FPGA design course;Web Services;Cloud storage;Remote Laboratory;Virtual Machine;PC clusters","Servers;Field programmable gate arrays;Remote laboratories;Cloud computing;Hardware","cloud computing;computer aided instruction;educational courses;electronic engineering education;field programmable gate arrays;hardware description languages;logic CAD;logic simulation;student experiments;virtual machines;Web services","cyber laboratory;hardware logic experiment;actual laboratory service;remote laboratory service;FPGA-based logic design course;hardware laboratory;cloud-storage;CAD file;simulation data file;laboratory FPGA-platform;student laptop/desktop;home PC;design file;logic simulation;FPGA-design platform;Verilog-HDL logic synthesis tool;FPGA test-bed;logic analyzer;hardware platform;laboratory organization;CAD Web service;FPGA-run Web service;virtual machine;VM PC cluster","","5","","4","","23 Jul 2012","","","IEEE","IEEE Conferences"
"Video game experience and basic robotic skills","A. Tanaka; R. Smith; C. Hughes","The Nicholson Center, Florida Hospital, Celebration, US; The Nicholson Center, Florida Hospital, Celebration, US; Department of Computer Science, The University of Central Florida, Orlando, US","2016 IEEE International Conference on Serious Games and Applications for Health (SeGAH)","10 Oct 2016","2016","","","1","6","Virtual reality simulators have emerged as valuable tools for standardized and objective robotic surgery skill training and assessments. In recent years the idea of using video game technology in surgical education for laparoscopy has also been explored, however few have attempted to make a connection between video game experience and robotic surgical skills. Thus, the current study aims to examine the performance of video gamers in a virtual reality robotic surgery simulator. Furthermore, the video gamers' performance was compared to that of medical students, expert robotic surgeons, and “laypeople.” The purpose of this study is to demonstrate that video gamers acquire perceptual and psychomotor skills through video game play, similar to those used by robotic surgeons. Subjects completed a demographic questionnaire and performed three computer-based perceptual tests: a Flanker compatibility task, a subsidizing task, and a Multiple Object Tracking test. Participants then performed two warm-up exercises and eight trials of two core exercises on a robotic surgery simulator. After completing all trials, participants completed a post-questionnaire regarding their experience with the system. Expert video gamers (n=40), medical students (n=24), laypeople (n=42) and expert robotic surgeons (n=16) were recruited. Medical students and gamers were significantly faster than experts in the Flanker Task. The experts were significantly slower than the all other groups in the subsidizing task. Experts scored significantly higher, were significantly more efficient, and were significantly faster than laypeople, medical students, and gamers in the first trial of Ring & Rail 1 and Suture Sponge. In trial eight of the simulation exercises, the experts performed significantly better than most groups in all of the metrics. Contrary to prior literature in laparoscopy, this study was unable to validate enhanced abilities of video gamers in a robotic surgery simulator. This study does further demonstrate that the transfer of skills developed through video game play is relevant to the surgical technique. This may be due to the differences of the systems and how the users interact within them. In a society where video games have become an integral past time, it is important to determine the role that video games play in the perceptual and psychomotor development of users. These findings can be generalized to domains outside of medicine that utilize robotic and computer-controlled systems, speaking to the scope of the gamers' abilities and pointing to the capacity within these systems.","","978-1-5090-2210-6","10.1109/SeGAH.2016.7586262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586262","","Surgery;Robots;Measurement;Games;Training;Rails;Cameras","biomedical education;computer aided instruction;computer games;educational robots;human-robot interaction;medical computing;medical robotics;surgery;virtual reality","video game experience;basic robotic skills;virtual reality robotic surgery simulator;standardized robotic surgery skill training;objective robotic surgery skill training;standardized robotic surgery skill assessment;objective robotic surgery skill assessment;surgical education;laparoscopy;video game technology;perceptual skill acquisition;psychomotor skill acquisition;computer-based perceptual tests;flanker compatibility task;subsidizing task;multiple object tracking test;computer-controlled systems","","1","","17","","10 Oct 2016","","","IEEE","IEEE Conferences"
"A Comparative Study of Haptic Stiffness Identification by Veterinarians and Students","N. Forrest; S. Baillie; P. Kalita; H. Z. Tan","University of London, London; University of London, London; The MathWorks, Inc., Natick; Purdue University, West Lafayette","IEEE Transactions on Haptics","9 Jun 2011","2011","4","2","78","87","Palpation is an important clinical skill in both veterinary and medical health professions. The present study compares the ability of practicing veterinarians and veterinary students to identify the stiffness of virtual surfaces through palpation. An absolute identification paradigm was used where a force-feedback haptic device rendered virtual surfaces with five levels of stiffness within a “clinically relevant” range (0.2-0.5 N/mm). The mean information transfer was 0.97 bits (almost two perfectly identifiable stiffness levels) for 12 veterinarians and 0.58 bits (one correctly identified level) for 14 veterinary students. Although the difference between the two groups was significant (p <; 0.001), neither group was able to reliably identify more than two levels of stiffness, indicating that the success of veterinarians in clinical practice probably relies on additional properties such as size, shape, and texture. Analyses of force versus time and displacement versus time recordings suggest that the superior performance of the veterinarians may be partially attributable to motor strategy. Specifically, veterinarians used a greater mean maximum force (2.0 N) compared to students (1.6 N) (p <; 0.05). However, further studies are required to investigate motor strategy in more detail. The implications of our findings for veterinary education and quantitative skill assessment are discussed.","2329-4051","","10.1109/TOH.2010.57","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5669308","Stiffness perception;stiffness identification;comparison of users;veterinary medicine;education;training.","Haptic interfaces;Force;Training;Measurement;Phantoms;Medical diagnostic imaging;Testing","biomedical education;computer based training;force feedback;haptic interfaces;rendering (computer graphics);statistical analysis;veterinary medicine;virtual reality","haptic stiffness identification;veterinarian;palpation;clinical skill;veterinary profession;medical health profession;veterinary student;identification paradigm;force-feedback haptic device;virtual surface rendering;mean information transfer;clinical practice;motor strategy;mean maximum force;veterinary education;quantitative skill assessment;veterinary medicine;training","","12","","34","","17 Dec 2010","","","IEEE","IEEE Journals"
"Asynchronous BCI Based on Motor Imagery With Automated Calibration and Neurofeedback Training","R. Kus; D. Valbuena; J. Zygierewicz; T. Malechka; A. Graeser; P. Durka","Faculty of Physics, University of Warsaw, Warsaw, Poland; Institute of Automation, University of Bremen, Bremen, Germany; Faculty of Physics, University of Warsaw, Warsaw, Poland; Institute of Automation, University of Bremen and the Friedrich Wilhelm Bessel Institute m.b.H., Bremen, Germany; Institute of Automation, University of Bremen, Bremen, Germany; Faculty of Physics, University of Warsaw, Warsaw, Poland","IEEE Transactions on Neural Systems and Rehabilitation Engineering","15 Nov 2012","2012","20","6","823","835","A new multiclass brain-computer interface (BCI) based on the modulation of sensorimotor oscillations by imagining movements is described. By the application of advanced signal processing tools, statistics and machine learning, this BCI system offers: 1) asynchronous mode of operation, 2) automatic selection of user-dependent parameters based on an initial calibration, 3) incremental update of the classifier parameters from feedback data. The signal classification uses spatially filtered signals and is based on spectral power estimation computed in individualized frequency bands, which are automatically identified by a specially tailored AR-based model. Relevant features are chosen by a criterion based on Mutual Information. Final recognition of motor imagery is effectuated by a multinomial logistic regression classifier. This BCI system was evaluated in two studies. In the first study, five participants trained the ability to imagine of the right hand, left hand and feet in response to visual cues. The accuracy of the classifier was evaluated across four training sessions with feedback. The second study assessed the information transfer rate (ITR) of the BCI in an asynchronous application. The subjects' task was to navigate a cursor along a computer rendered 2-D maze. A peak information transfer rate of 8.0 bit/min was achieved. Five subjects performed with a mean ITR of 4.5 bit/min and an accuracy of 74.84%. These results demonstrate that the use of automated interfaces to reduce complexity for the intended operator (outside the laboratory) is indeed possible. The signal processing and classifier source code embedded in BCI2000 is available from https://www.brain-project.org/downloads.html.","1558-0210","","10.1109/TNSRE.2012.2214789","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6311479","Brain–computer interface (BCI);electro encephalography (EEG);event-related synchronization and desynchronization (ERD/ERS);motor imagery;neurofeedback","Brain computer interfaces;Training;Calibration;Electroencephalography;Neurofeedback","augmented reality;brain-computer interfaces;calibration;electroencephalography;learning (artificial intelligence);medical signal processing;neurophysiology;oscillations;regression analysis;signal classification","multiclass asynchronous brain-computer interface;automated calibration;motor imagery;neurofeedback training;sensorimotor oscillation modulation;advanced signal processing tools;statistics;machine learning;user-dependent parameter automatic selection;classifier parameters;feedback data;signal classification;filtered signals;spectral power estimation;individualized frequency bands;tailored AR-based model;mutual information;multinomial logistic regression classifier;right hand movements;left hand movement;feet movement;transfer rate;computer rendered 2D maze;classifier source code;EEG data;movement imagination;BCI2000","Adult;Algorithms;Brain-Computer Interfaces;Calibration;Computer Graphics;Cortical Synchronization;Cues;Electroencephalography;Female;Humans;Imagination;Joints;Joints;Logistic Models;Male;Movement;Neurofeedback;Neurofeedback;Photic Stimulation;Psychomotor Performance;User-Computer Interface;Young Adult","38","","45","","24 Sep 2012","","","IEEE","IEEE Journals"
"On the way to pole position: The effect of tire grip on learning to drive a racecar","S. de Groot; J. C. F. de Winter","Department of BioMechanical Engineering, Delft University of Technology, The Netherlands; Department of BioMechanical Engineering, Delft University of Technology, The Netherlands","2011 IEEE International Conference on Systems, Man, and Cybernetics","21 Nov 2011","2011","","","133","138","Racecar drivers could benefit from new training methods for learning to drive fast lap times. Inspired by the learning-from-errors principle, this simulator-based study investigated the effect of the tire-road friction coefficient on the training effectiveness of a car racing task. Three groups of 15 inexperienced racecar drivers (low grip (LG), 66% of normal grip; normal grip (NG); high grip (HG), 150% of normal grip) completed four practice sessions of 10 minutes in a Formula 3 car on an oval track of 800 m. After the practice sessions, two retention sessions followed: a retention session with normal grip in a Formula 3 car and another retention session with a Formula 1 car. The results showed that LG was significantly slower than HG in the first retention session. Furthermore, LG reported a higher confidence and lower frustration than NG and HG after each of the two retention sessions. In conclusion, practicing with low grip, as compared to practicing with normal or high grip, resulted in increased confidence but slower lap times.","1062-922X","978-1-4577-0653-0","10.1109/ICSMC.2011.6083655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6083655","learning from errors;simulator-based training;racecar driving;learning;retention;transfer;task difficulty","Vehicles;Mercury (metals);Training;Friction;Wheels;Tires;Helicopters","digital simulation;friction;traffic engineering computing;tyres","pole position;tire grip;racecar drivers;training methods;fast lap times;learning from errors principle;tire-road friction coefficient;car racing task;Formula 3 car;oval track;LG;retention sessions","","1","","15","","21 Nov 2011","","","IEEE","IEEE Conferences"
"Application of artificial neural networks modelling to spray impingement heat transfer","M. M. Awais; M. A. Aamir; A. Aamir","Dept. of Comput. Sci., LUMS, Lahore, Pakistan; NA; NA","Proceedings. IEEE International Multi Topic Conference, 2001. IEEE INMIC 2001. Technology for the 21st Century.","7 Aug 2002","2001","","","282","291","Artificial neural networks (ANN) models were developed and applied to water spray cooling heat flux predictions. The model was applied to all the three regimes of heat transfer, namely nucleate boiling (where surface temperature is less than the one at critical heat flux), transition (where the surface temperature is less than the Leidenfrost temperature) and the film boiling (where the wall temperature is greater than the Leidenfrost temperature). The ANN model is well trained and proves to be an alternative numerical modelling technique to computational fluid dynamics (CFD) with numerical predictions comparable to the CFD predictions, but in real time mode.","","0-7803-7406-1","10.1109/INMIC.2001.995352","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=995352","","Artificial neural networks;Spraying;Heat transfer;Temperature;Predictive models;Computational fluid dynamics;Water heating;Cooling;Computational modeling;Numerical models","cooling;sprays;heat transfer;digital simulation;neural nets;temperature control","neural networks;water spray cooling;heat flux predictions;heat transfer;nucleate boiling;Leidenfrost temperature;computational fluid dynamics;modelling","","","","16","","7 Aug 2002","","","IEEE","IEEE Conferences"
"Construction safety education model based on second life","Q. Le; Chan-Sik Park","Department of Architectural Engineering, Chung-Ang University, Seoul, South Korea; Department of Architectural Engineering, Chung-Ang University, Seoul, South Korea","Proceedings of IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE) 2012","24 Nov 2012","2012","","","H2C-1","H2C-5","Construction industry is a very complicated and complex environment that causes high accident rate. The development of advanced virtual world has become an important issue for safety education in order to reduce dangerous occurrence in the construction site. However, most researchers on virtual world still have limitations such as the offline virtual world simulation, the low level of interaction between users in virtual world, and so on. With the regard to this issue, this paper proposes the adoption online 3D world Second Life (SL) platform which allows students to perform role-playing, dialogic learning, and social interaction for efficient and effective construction safety and health education. In this approach, construction safety education model based on Second Life (CSESL) is developed, which consists of the following three modules: 1) Safety information and knowledge preparation to understand the critical causes of accident in construction site; 2) Collaborative simulation for safety case study to transfer unsafe case or dangerous occurrence information to 3D modeling; 3) Reflection on safety lesson for education and training to enhance practical safety knowledge by participating in 3D inspection game. The CSESL advantages and disadvantages are identified by testing the model using a real case scenario. This study presents the potentials and benefits of SL which could enhance construction safety and health education.","","978-1-4673-2418-2","10.1109/TALE.2012.6360336","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360336","construction safety and health;virtual environment;Second Life;education","Safety;Solid modeling;Collaboration;Accidents;Second Life;Training","accidents;computer aided instruction;computer games;construction industry;digital simulation;engineering education;occupational health;occupational safety;solid modelling;virtual reality","construction safety education model;Second Life;construction industry;virtual world;role-playing;dialogic learning;social interaction;construction health education;safety information;knowledge preparation;construction accident;collaborative simulation;3D modeling;safety lesson;3D inspection game","","4","","14","","24 Nov 2012","","","IEEE","IEEE Conferences"
"A novel and pedagogical approach to teach PID controller with LabVIEW signal express","S. Ramasamy; H. V. Pradhan; P. Ramanathan; P. Arulmozhivarman; R. Tatavarti","School of Electrical Engineering, VIT University, Vellore, India-632014; School of Electrical Engineering, VIT University, Vellore, India-632014; School of Electrical Engineering, VIT University, Vellore, India-632014; School of Electrical Engineering, VIT University, Vellore, India-632014; School of Electrical Engineering, VIT University, Vellore, India-632014","2012 IEEE International Conference on Engineering Education: Innovative Practices and Future Trends (AICERA)","20 Sep 2012","2012","","","1","8","A novel and Pedagogical approach for teaching the PID controller and its tuning parameters to the students and trainee engineers working in Control and Automation Engineering is presented. In short, a trainer/simulator for Proportional- Integral-Derivative Controller is developed. A third order system (Transfer Function) was used. However, there is no limiting factor in using the higher order system in the simulator. Ziegler- Nichols tuning method was used to obtain the optimum or initial values of the PID Controller. LabVIEW Signal Express software developed by NI was used. In specific, the control & design kit module was used. Graphical Interface along with the tuning knobs of the three term controller was highly helpful in finalizing the PID Parameters.","","978-1-4673-2269-0","10.1109/AICERA.2012.6306684","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6306684","PID Control;Feedback Control;Control System Design - LabVIEW;Tuning of PID Controller;Controller Response","Control systems;Tuning;Process control;Steady-state;Educational institutions;Computational modeling","computer aided instruction;control engineering computing;control engineering education;graphical user interfaces;teaching;three-term control;transfer functions;virtual instrumentation","pedagogical approach;PID controller teaching;LabVIEW Signal Express;tuning parameters;trainee engineers;automation engineering;trainer-simulator;proportional-integral-derivative controller;third order system;transfer function;Ziegler-Nichols tuning method;graphical interface;three term controller","","2","","10","","20 Sep 2012","","","IEEE","IEEE Conferences"
"Towards understanding the differences of using 3D auditory feedback in virtual environments between people with and without visual impairments","M. Dong; H. Wang; R. Guo","Kennesaw State University; Georgia State University, GA, USA; Kennesaw State Univ., Kennesaw, GA, USA","2017 IEEE 3rd VR Workshop on Sonic Interactions for Virtual Environments (SIVE)","17 Apr 2017","2017","","","1","5","The research objective was to exploration to determine any differences of using a generic Head Related Transfer Function (HRTF) to simulate 3D auditory feedback in Virtual Environments (VEs) without visual feedback between people with and without Visual Impairments (VI). To investigate this, we designed and developed a usability study which included the two tasks of recognizing the positions and distinguishing the moving directions of 3D sound sources in a VE. We conducted this study with 20 participants using VI (7 males and 13 females), and 18 participants without VI (7 males and 11 females). The results indicated different experiences in the VE between people with VI and without VI.","","978-1-5386-0459-5","10.1109/SIVE.2017.7901608","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7901608","Assistive technology;HRTF;3D Audio;user study;Human-center computing;Interaction devices;Accessibility;Accessibility technologies","Three-dimensional displays;Visualization;Virtual environments;Training;Headphones;Estimation;Haptic interfaces","handicapped aids;virtual reality;vision defects","3D auditory feedback;virtual environments;people with visual impairments;head related transfer function;HRTF;3D auditory feedback simulate;VE;visual feedback;VI;3D sound sources;assistive technology","","1","","18","","17 Apr 2017","","","IEEE","IEEE Conferences"
"Learning Illumination from a Limited Field-of-View Image","Y. -k. Sun; D. Li; S. Liu; T. -C. Cao; Y. -S. Hu","Huazhong University of Science and Technology,School of Computer Science and Technology; Huazhong University of Science and Technology,School of Computer Science and Technology; Huazhong University of Science and Technology,School of Computer Science and Technology; Huazhong University of Science and Technology,School of Computer Science and Technology; Huazhong University of Science and Technology,School of Computer Science and Technology","2020 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)","9 Jun 2020","2020","","","1","6","Illumination estimation is a crucial part of augmented reality since it can make the virtual object look more realistic. However, single image-based lighting estimation is challenging due to the limited information. Here we combine deep learning with the spherical harmonic (SH) lighting which is widely used in precomputed radiance transfer. Specifically, a convolutional neural network that predicts SH coefficients from an image is designed, trained and tested. Moreover, we construct a new dataset for training SH coefficients based on the existing panorama dataset. The method in this work can finally predict realistic lighting from a single, limited field-of-view image, and it presents better results in some cases compared with previous research.","","978-1-7281-1485-9","10.1109/ICMEW46912.2020.9105957","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9105957","Scene understanding;illumination estimation;deep learning","Lighting;Training;Cameras;Estimation;Agriculture;Mathematical model;Two dimensional displays","augmented reality;image colour analysis;image reconstruction;image representation;image sensors;learning (artificial intelligence);lighting;neural nets;rendering (computer graphics)","limited field-of-view image;illumination estimation;augmented reality;virtual object;deep learning;spherical harmonic lighting;precomputed radiance transfer;convolutional neural network;training SH coefficients;existing panorama dataset;realistic lighting;single image-based lighting estimation","","","","23","","9 Jun 2020","","","IEEE","IEEE Conferences"
"Design of Practical Information Multidimensional Integration System for Higher Vocational Ideological and Political Courses Facing Big Data","X. Ding",Suzhou Polytechnic Institute of Agriculture,"2019 International Conference on Virtual Reality and Intelligent Systems (ICVRIS)","5 Dec 2019","2019","","","386","390","In view of the fact that the current information integration system can not quickly integrate a large number of chaotic practical information, this paper designs a multi-dimensional integration system of practical information for ideological and political courses in higher vocational colleges. The main control chip, TMS320C6748, is used to control the whole operation of the system. The physical server stores the information data and communicates with the serial port to transfer the data. Through the method of FPGA, the cluttered practical information data is filtered. According to the principle of Bayesian algorithm, the filtered information data is classified and the information data is preprocessed. In the SQL database, XML technology is used to parse and transform the pre-processed information and data. The data transformed into XML format is unified. According to the set multi-dimensional integration rules, data streams are split in the middle layer of the database and then merged is omorphically and heterogeneously. The data is loaded and stored in the integrated database, and finally the integration of information and data is completed. The design of multi-dimensional integration system is completed through hardware and software design. Comparing with the current information integration system, the experiment verifies the speed of information integration time of the designed multi-dimensional integration system. When integrating different amounts of practical information, the integration time of the designed multi-dimensional integration system is about one third of that of the current information integration system.","","978-1-7281-5050-5","10.1109/ICVRIS.2019.00100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920804","big data;higher vocational ideological and political course;multidimensional integration;system design","Databases;XML;Servers;Information filters;Big Data;Education","Big Data;computer aided instruction;data analysis;data mining;digital signal processing chips;educational courses;educational institutions;field programmable gate arrays;SQL;vocational training;XML","cluttered practical information data;filtered information data;pre-processed information;set multidimensional integration rules;data streams;integrated database;current information integration system;information integration time;designed multidimensional integration system;practical information multidimensional integration system;political courses facing big data;chaotic practical information","","","","10","","5 Dec 2019","","","IEEE","IEEE Conferences"
"Free response evaluation via neural network for an IMathAS system","N. Wiggins; M. Smith","Industrial Manufacturing and Systems Engineering, Texas Tech University,Lubbock,TX; Industrial Manufacturing and Systems Engineering, Texas Tech University,Lubbock,TX","2019 IEEE International Symposium on Measurement and Control in Robotics (ISMCR)","13 Jan 2020","2019","","","D1-1-1","D1-3-5","A fully interactive class with mixed reality and simulation learning should provide many free response types for students to learn beyond numerical answers and multiple choice. Essay and string responses in the IMathAS homework system have to be manually graded, making the free response questions difficult to generate instant feedback. The ability to write questions with automatic feedback during active lecture offer improvements to the current systems and provide an opportunity for critical thinking to occur. The following study provides framework for an interpretive neural network to be implemented into any IMathAS system. These responses can be in the form of equations, words and sentences, or pictures. Findings show that correctly trained networks using manually graded artifacts can be more than 90% accurate in providing feedback to a correct answer in student practice, allowing for lessons that guide students towards correct and well-phrased answers using their own words, and can even assign partial credit. The findings imply that Marzano's taxonomy level of analysis can be reached using the IMathAS system and that critical thinking methods can be directly applied for scoring. When integrated into the existing system, simulation-based or mixed reality homework can have free responses and the grades can be transferred via learning tool interoperability connection into the institutional learning management system for direct scoring in the gradebook.","","978-1-7281-4899-1","10.1109/ISMCR47492.2019.8955695","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8955695","neural networks;mixed reality education application;critical thinking;undergraduate education","Neural networks;Mathematical model;Training;Tungsten;Software","computer aided instruction;interactive systems;Internet;open systems","IMathAS homework system;interpretive neural network;IMathAS system;critical thinking methods;mixed reality homework;institutional learning management system;free response evaluation;simulation learning;interactive class;learning tool interoperability connection","","","","16","","13 Jan 2020","","","IEEE","IEEE Conferences"
"A Cognitive ML Agent for Airborne Networking","F. D. Kronewitter; S. Lee; K. Oliphant",Fuse Integration; Fuse Integration; Fuse Integration,"MILCOM 2019 - 2019 IEEE Military Communications Conference (MILCOM)","5 Mar 2020","2019","","","115","120","This conference note describes a Deep Reinforcement Learning architecture specifically designed to improve wireless network performance over a heterogeneous airborne wireless network consisting of multiple waveforms, antennas, platforms, link protocols, frequencies, spatial transmission, and codes. The cooperative optimization of this high dimensional space is a difficult problem which obviously has a highly correlated characterization where human network operators cannot possibly capture these correlations. Model-free Reinforcement Learning techniques represent a potential solution to our problem. Specifically, we use Deep Q-Learning Networks (DQN) to improve networking performance. We have developed a high-fidelity network simulation tool we call Tactical Airborne Network Simulator (TANS) which we use to train our neural network before deploying to the field where the asset is deployed to some mission which is hopefully somewhat similar to the scenarios used for training. By utilizing the model developed under the TANS training scenarios for the target mission scenario our learning technique gets a head start, rather than using a truly model-free approach. Our technique is codified in the ML community as “Deep Transfer Learning” [4] where terms and metrics have been examined. This paper represents an initial investigation into both the decision support agent architecture and the ML technique. Upcoming research will be described below including our vision for an expanded agent architecture as well as ideas for improved ML techniques which ultimately will result in better wireless network performance. Here we demonstrate a minor throughput performance improvement of 4% using a proof of concept agent over the use of a standard unassisted network. We improved the throughput from 309kbps to 324 kbps.","2155-7586","978-1-7281-4280-7","10.1109/MILCOM47813.2019.9020975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9020975","Airborne Networking;Machine Learning;Deep Q-Learning Networks","Antennas;Atmospheric modeling;Training;Orbits;Routing protocols;Learning (artificial intelligence);Bandwidth","aerospace simulation;aircraft communication;data visualisation;decision support systems;learning (artificial intelligence);military communication;multi-agent systems;neural nets;optimisation;radio networks;software agents;telecommunication computing","cognitive ML agent;deep reinforcement learning architecture;heterogeneous airborne wireless network;high dimensional space;highly correlated characterization;human network operators;model-free reinforcement learning techniques;high-fidelity network simulation tool;neural network;TANS training scenarios;model-free approach;decision support agent architecture;expanded agent architecture;improved ML techniques;throughput performance improvement;standard unassisted network;deep transfer learning;tactical airborne network simulator;deep Q-learning networks;wireless network performance improvement;cooperative optimization","","","","16","","5 Mar 2020","","","IEEE","IEEE Conferences"
"Simple Modeling Method for Complex Processes to Improve Teaching in Engineering","J. Tisza; D. Ortega; J. Asencio","Universidad Nacional de Ingeniería,Fac. Ingeniería Eléctrica y Electrónica,Lima,Perú; Universidad Nacional de Ingeniería,Fac. Ingeniería Eléctrica y Electrónica,Lima,Perú; Universidad Nacional de Ingeniería,Fac. Ingeniería Eléctrica y Electrónica,Lima,Perú","2020 IEEE International Symposium on Accreditation of Engineering and Computing Education (ICACIT)","9 Dec 2020","2020","","","1","4","This document will present a simple method for modeling complex multiple input and output (MIMO) processes to improve the teaching of engineering students. The proposed method allows us to improve the application of theoretical and academic knowledge in real industrial processes. The method can be applied in professional training subjects in various branches of engineering, especially those that develop analysis and design of instrumentation, control, automation, and process optimization systems. Improving teaching is because there is a closer approximation of the process model used in the academic field with that found in the industry. COMSOL (finite element simulation software) and MATLAB are used as tools and the advantages of the method in simplicity, flexibility, versatility, and effectiveness in engineering education are developed.","","978-1-7281-7118-0","10.1109/ICACIT50253.2020.9277681","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9277681","Modeling;transfer function;MIMO processes;MATLAB;COMSOL Multiphysics","Mathematical model;Matlab;Atmospheric modeling;Transfer functions;Software;MIMO communication;Tools","computer aided instruction;engineering education;finite element analysis;Matlab;MIMO systems;teaching","academic knowledge;industrial processes;professional training subjects;process optimization systems;teaching improvement;COMSOL;finite element simulation software;engineering education;multiple input and multiple output process;MIMO;engineering students;theoretical knowledge;MATLAB","","","","13","","9 Dec 2020","","","IEEE","IEEE Conferences"
"Advances in virtual design and visual center concepts","S. V. Wunnava; M. Rosario; K. Gandham","Dept. of Electr. & Comput. Eng., Florida Int. Univ., Miami, FL, USA; Dept. of Electr. & Comput. Eng., Florida Int. Univ., Miami, FL, USA; Dept. of Electr. & Comput. Eng., Florida Int. Univ., Miami, FL, USA","Proceedings of SOUTHEASTCON '96","6 Aug 2002","1996","","","107","110","Innovations in interactive audio, video, and data transfer have given rise to a multitude of new applications such as screen sharing, multimedia, and distributed processing. At Florida International University Electrical and Computer Engineering Laboratories, work has been in progress to define and develop the virtual design center (VDC), and virtual visual center (VVC) concepts with the help of network interactive audio, video, and data transfer mechanisms on the existing phone lines using the ISDN (integrated services digital network). The VDC would become the next generation design tool for engineering, software, hardware, and system design. The VVC would become the next generation remote monitoring and control operation. Day care centers where children of working parents usually spend their time can be easily networked together so that the working parents can talk and see their children from remote locations. The VVC would also help monitor elderly persons in nursing homes. The elderly people do not have to be isolated, but be active members in the interactive audio and video based VVC. The authors present the hardware and software requirements of the VDC and WC realizations. The operational models of the VDC and WC are also discussed with the associated results. Additional applications, such as teletraining centers (TTC) using the VDC concepts and telesecurity centers (TSC) using the VVC concepts, are examined.","","0-7803-3088-9","10.1109/SECON.1996.510037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=510037","","Video sharing;Application software;Design engineering;ISDN;Hardware;Remote monitoring;Senior citizens;Optical wavelength conversion;Technological innovation;Multimedia systems","multimedia communication;telecommunication computing;ISDN;telephone lines;telephone networks;interactive video;telecontrol;software engineering;training","interactive audio;interactive video;interactive data transfer;screen sharing;multimedia;distributed processing;Florida International University;virtual design center;virtual visual center;integrated services digital network;telephone lines;ISDN;design tool;engineering design;software design;telesecurity centers;system design;remote monitoring;remote control;day care centers;elderly persons;nursing homes;teletraining centers;children","","","1","5","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Dance Dance Generation: Motion Transfer for Internet Videos","Y. Zhou; Z. Wang; C. Fang; T. Bui; T. L. Berg",University of North Carolina at Chapel Hill; Adobe Research; ByteDance AI Lab; Adobe Research; University of North Carolina at Chapel Hill,"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)","5 Mar 2020","2019","","","1208","1216","This work presents computational methods for transferring body movements from one person to another with videos collected in the wild. Specifically, we train a personalized model on a single video from the Internet which can generate videos of this target person driven by the motions of other people. Our model is built on two generative networks: a human (foreground) synthesis net which generates photo-realistic imagery of the target person in a novel pose, and a fusion net which combines the generated foreground with the scene (background), adding shadows or reflections as needed to enhance realism. We validate the the efficacy of our proposed models over baselines with qualitative and quantitative evaluations as well as a subjective test.","2473-9944","978-1-7281-5023-9","10.1109/ICCVW.2019.00153","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9022584","Motion transfer;Personalized;Video frame synthesis","Videos;Internet;Three-dimensional displays;Image segmentation;Task analysis;Smoothing methods;Face","computer animation;humanities;image motion analysis;image sequences;Internet;realistic images;rendering (computer graphics);solid modelling;video signal processing;virtual reality","body movements;personalized model;generative networks;human synthesis net;photo-realistic imagery;fusion net;dance dance generation;motion transfer;Internet videos","","1","","26","","5 Mar 2020","","","IEEE","IEEE Conferences"
"Demodulation for wireless ATM network using modified SOM network","Jiang Li; Qilian Liang; M. T. Manry","Dept. of Electr. Eng., Texas Univ., Arlington, TX, USA; Dept. of Electr. Eng., Texas Univ., Arlington, TX, USA; Dept. of Electr. Eng., Texas Univ., Arlington, TX, USA","2004 IEEE International Conference on Acoustics, Speech, and Signal Processing","30 Aug 2004","2004","5","","V","669","We study the demodulation problem in time division multiple access (TDMA) wireless asynchronous transfer mode (ATM) networks, where Rician flat fading channels are considered. A linear interpolation with decision feedback combined with a modified version of the self-organizing-map (LIDF-SOM) demodulator is proposed for such a system. We obtain the training sequence by exploiting medium access control (MAC) and data link control (DLC) protocols such that a semi-blind adaptive demodulator is implemented. Simulation results show that LIDF-SOM obtains 0.4-1.0 dB gain over Rician fading channels as compared to LIDF alone.","1520-6149","0-7803-8484-9","10.1109/ICASSP.2004.1327199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1327199","","Demodulation;Asynchronous transfer mode;Time division multiple access;Rician channels;Media Access Protocol;Fading;Interpolation;Feedback;Access protocols;Programmable control","Rician channels;demodulation;asynchronous transfer mode;self-organising feature maps;time division multiple access;radio networks;adaptive systems;telecommunication computing","demodulation;wireless ATM network;modified SOM network;self-organizing-map;TDMA;time division multiple access;Rician flat fading channels;Rician channels;linear interpolation;decision feedback;training sequence;medium access control protocols;MAC protocols;data link control protocols;semi-blind adaptive demodulator;Rician fading channels","","1","","9","","30 Aug 2004","","","IEEE","IEEE Conferences"
"Deep Transfer Learning-Assisted Signal Detection for Ambient Backscatter Communications","C. Liu; X. Liu; Z. Wei; D. W. Kwan Ng; J. Yuan; Y. -C. Liang","School of Electrical Engineering and Telecommunications, the University of New South Wales,Australia; Dalian University of Technology,China; School of Electrical Engineering and Telecommunications, the University of New South Wales,Australia; School of Electrical Engineering and Telecommunications, the University of New South Wales,Australia; School of Electrical Engineering and Telecommunications, the University of New South Wales,Australia; University of Electronic Science and Technology of China,China","GLOBECOM 2020 - 2020 IEEE Global Communications Conference","15 Feb 2021","2020","","","1","6","Existing tag signal detection algorithms inevitably suffer from a high bit error rate (BER) due to the difficulties in estimating the channel state information (CSI). To eliminate the requirement of channel estimation and to improve the system performance, in this paper, we adopt a deep transfer learning (DTL) approach to implicitly extract the features of communication channel and directly recover tag symbols. Inspired by the powerful capability of convolutional neural networks (CNN) in exploring the features of data in a matrix form, we design a novel covariance matrix aware neural network (CMNet)-based detection scheme to facilitate DTL for tag signal detection, which consists of offline learning, transfer learning, and online detection. Specifically, a CMNet-based likelihood ratio test (CMNet-LRT) is derived based on the minimum error probability (MEP) criterion. Taking advantage of the outstanding performance of DTL in transferring knowledge with only a few training data, the proposed scheme can adaptively fine-tune the detector for different channel environments to further improve the detection performance. Finally, extensive simulation results demonstrate that the BER performance of the proposed method is comparable to that of the optimal detection method with perfect CSI.","2576-6813","978-1-7281-8298-8","10.1109/GLOBECOM42002.2020.9348274","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9348274","","Simulation;Bit error rate;Transfer learning;Detectors;Feature extraction;Covariance matrices;Signal detection","backscatter;channel estimation;covariance matrices;error statistics;learning (artificial intelligence);neural nets;signal detection;telecommunication computing;wireless channels","ambient backscatter communications;tag signal detection algorithms;high bit error rate;channel state information;channel estimation;system performance;deep transfer learning approach;DTL;communication channel;tag symbols;powerful capability;convolutional neural networks;matrix form;novel covariance matrix aware neural network-based detection scheme;offline learning;online detection;CMNet-based likelihood ratio test;CMNet-LRT;minimum error probability criterion;different channel environments;detection performance;BER performance;optimal detection method","","","","17","","15 Feb 2021","","","IEEE","IEEE Conferences"
"Specification and design of a new haptic interface for maxillo facial surgery","F. Gosselin; F. Ferlay; S. Bouchigny; C. Mégard; F. Taha","CEA, LIST, Interactive Robotics Laboratory, 18, route du Panorama, BP6, 92265 Fontenay-aux-Roses, France; CEA, LIST, Sensory and Ambient Interfaces Laboratory, 18, route du Panorama, BP6, 92265 Fontenay-aux-Roses, France; CEA, LIST, Sensory and Ambient Interfaces Laboratory, 18, route du Panorama, BP6, 92265 Fontenay-aux-Roses, France; CEA, LIST, Sensory and Ambient Interfaces Laboratory, 18, route du Panorama, BP6, 92265 Fontenay-aux-Roses, France; Amiens University Hospital, Department of Oral and Maxillofacial Surgery, Place Victor Pauchet, 80054, France","2011 IEEE International Conference on Robotics and Automation","18 Aug 2011","2011","","","737","744","Multimodal VR training platforms appear as a very promising complement to traditional learning methods for the transfer of skills. The environment is fully controlled and the content of the application, as well as the feedbacks, can be tuned to the performances and progress of the user. The efficiency of this approach depends however on the ability to realistically reproduce the situations encountered in the real world. If not, users could develop false perception-action loops or illusionary conjunctions. This would be detrimental for the transfer of the training to the real world. Our institute, the Lab of applied research on Software-Intensive Technologies from the French Atomic Energy Commission, CEA, LIST, is currently developing such a platform for the training of maxillo facial surgery. As no existing haptic device fits the requirements of this application, we specifically developed a new interface. This paper presents its specification, design and performances.","1050-4729","978-1-61284-385-8","10.1109/ICRA.2011.5980052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5980052","","Surgery;Wrist;Haptic interfaces;Training;Robots;Actuators;Bones","CAD;haptic interfaces;medical computing;surgery;virtual reality","haptic interface;maxillo facial surgery;multimodal VR training;Lab of applied research on Software-Intensive Technologies;French Atomic Energy Commission;CEA;LIST","","10","1","17","","18 Aug 2011","","","IEEE","IEEE Conferences"
"K-12 School/Industry Partnership for Modeling and Simulation","S. Gross; E. Park; A. Pickl; T. Storck","Academia Group, The MathWorks GmbH, Munich, Germany; Academia Group, The MathWorks GmbH, Munich, Germany; Mathematics and Physics, Rupprecht-Gymnasium München, Munich, Germany; Mathematics and Physics, Rupprecht-Gymnasium München, Munich, Germany","2019 IEEE Global Engineering Education Conference (EDUCON)","30 May 2019","2019","","","1241","1249","In this paper we present the multi-year collaboration between Rupprecht-Gymnasium München, a preuniversity school (K-12) in Bavaria, Germany, and MathWorks, an international scientific computing company. The school is STEM-focused and a member of the German national STEM school excellence network MINT-EC; they prepare students aged 10 to 18 for university careers. We highlight the starting motivation for the partners and describe several building blocks and initiatives including curricular and extracurricular activities for students as well as teacher training that became part of the collaboration. We also discuss future steps for the partners and how this project could be transferred to other schools.","2165-9567","978-1-5386-9506-7","10.1109/EDUCON.2019.8725207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725207","K-12;pre-university;STEM;modeling;simulation;engineering tools;collaboration;computational thinking","Mathematical model;Matlab;Software packages;Collaboration;Seminars;Computational modeling;STEM","computer aided instruction;computer science education;educational institutions;further education;STEM;teacher training;teaching","K-12 School/Industry Partnership;multiyear collaboration;Rupprecht-Gymnasium München;preuniversity school;Bavaria;Germany;MathWorks;international scientific computing company;STEM-focused;German national STEM school excellence network MINT-EC;university careers;starting motivation;building blocks;curricular activities;extracurricular activities;teacher training","","","","26","","30 May 2019","","","IEEE","IEEE Conferences"
"Remote laboratory experiments in electrical engineering education","I. Gustavsson","Dept. of Telecommun. & Signal Process., Blekinge Inst. of Technol., Ronneby, Sweden","Proceedings of the Fourth IEEE International Caracas Conference on Devices, Circuits and Systems (Cat. No.02TH8611)","7 Aug 2002","2002","","","I025","I025","A remote or online laboratory is a laboratory where one can access experiments and instruments or other equipment from outside over the Internet. Laboratories for undergraduate education or vocational training in basic electrical engineering are easy to control remotely. One cannot see or hear the electrical current, so there is no need for sound or video transmission. Computer-based instruments do not have any control buttons or displays on the front panel. They have virtual front panels on the host computer only and those panels can be moved to a remote computer screen. However, the manual forming of circuits and connecting of test probes cannot be transferred. These actions must be performed in another way in a remote laboratory. Remotely controllable switch matrices must be used. In the remote laboratory at BTH (Blekinge Institute of Technology) a client/server architecture is used. The student makes all the settings wanted on the client computer and then sends them to a lab server. The server makes measurements requested and returns the data obtained. The whole procedure takes only a second or two. A number of clients can access the experiments simultaneously. The laboratory is used in ordinary courses for on-campus students. They access the laboratory from a computer hall or from elsewhere outside the university. Due to the low number of bytes transferred, a 56 kbit modem is sufficient.","","0-7803-7380-4","10.1109/ICCDCS.2002.1004082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1004082","","Remote laboratories;Electrical engineering education;Instruments;Computer displays;Circuit testing;Switches;Internet;Computer science education;Control engineering education;Vocational training","virtual instrumentation;electronic engineering education;computer aided instruction;client-server systems;probes;peripheral interfaces;circuit testing","remote laboratory experiments;electrical engineering education;online laboratory;experiment access;instrument access;Internet;undergraduate education;vocational training;electrical engineering training;computer-based instruments;virtual front panels;host computer;remote computer screen;manual circuit forming;test probe connection;remotely controllable switch matrices;client/server architecture;student client computer settings;lab server;server measurements;on-campus students;modem","","25","1","6","","7 Aug 2002","","","IEEE","IEEE Conferences"
"Prenatal to postnatal transfer of motor skills through motor-compatible sensory representations","T. A. Mann; Y. Choe","Department of Computer Science and Engineering, Texas A&M University, College Station, TX 77843; Department of Computer Science and Engineering, Texas A&M University, College Station, TX 77843","2010 IEEE 9th International Conference on Development and Learning","20 Sep 2010","2010","","","185","190","How can sensory-motor skills developed as a fetus transfer to postnatal life? We investigate a simulated reaching task by training controllers under prenatal conditions (i.e. confined space) and evaluating them based on postnatal conditions (i.e. targets outside of the confined training space). One possible solution is to identify a sensory representation that is easy to extrapolate over. We compared two kinds of sensory representations: world-centered sensory representation based on Cartesian coordinates and agent-centered sensory representation based on polar coordinates. Despite similar performance under prenatal conditions, controllers using agent-centered sensory representation had significantly better performance than controllers using world-centered sensory representation under postnatal conditions. It turns out that the success of the agent-centered sensory representation is (in part) due to being complementary to the action encodings. Further analysis shows that the action encodings (i.e. changes in joint angles) were highly predictive of the change in state when agent-centered sensory representation was used (but not world-centered). This suggests that a powerful strategy for transferring sensory-motor skills to postnatal life involves selecting a sensory representation that complements the action encodings used by an agent.","2161-9476","978-1-4244-6902-4","10.1109/DEVLRN.2010.5578844","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5578844","","Joints;Optical wavelength conversion;Training;Elbow;Shoulder;Encoding;Fetus","biomechanics;cognition;medical computing;obstetrics;paediatrics","prenatal transfer;postnatal transfer;motor skills;motor-compatible sensory representations;sensory-motor skills;fetus;reaching task;extrapolation;Cartesian coordinates;agent-centered sensory representation;action encodings","","4","","18","","20 Sep 2010","","","IEEE","IEEE Conferences"
"Human Action Recognition Based on a Two-stream Convolutional Network Classifier","V. de Oliveira Silva; F. de Barros Vidal; A. R. Soares Romariz","Department of Electrical Engineering, University of Brasília, Brasília, Brazil; Department of Computer Science, University of Brasília, Brasília, Brazil; Department of Electrical Engineering, University of Brasília, Brasília, Brazil","2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA)","18 Jan 2018","2017","","","774","778","Currently, video generation devices are simpler to manipulate, more portable and with lower prices. This allowed easy storage and transmission of large amounts of media, such as videos, which has facilitated the analysis of information, independent of human assistance for evaluation and exhaustive search of videos. Virtual reality, robotics, tele-medicine, humanmachine interface and tele-surveillance are applications for these techniques. This paper describes a method for human action recognition in videos using two convolutional neural networks (CNNs). The first one Spatial Stream (trained with frames of the video) and the second one Temporal Stream, trained with stacks of Dense Optical Flow (DOF). Both streams were trained separately and from both of them we generated a classification histogram based on the most frequent class assignment. For final classification, those histograms were combined to produce a single output. The technique was tested in two public action video datasets: Weizmann and UCF Sports. We achieve 84.44% of accuracy on Weizmann dataset for Spatial stream and 78.46% on UCF Sports dataset. For the Weizmann dataset we obtained 91.11% with networks combination.","","978-1-5386-1418-1","10.1109/ICMLA.2017.00-64","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260728","Human action recognition;Convolutional Neural networks;Dense Optical Flow;Transfer Learning","Histograms;Streaming media;Training;Image recognition;Kernel","feature extraction;image classification;image motion analysis;image recognition;image representation;image sequences;learning (artificial intelligence);neural nets;object recognition;video signal processing;virtual reality","videos;virtual reality;tele-medicine;humanmachine interface;tele-surveillance;human action recognition;convolutional neural networks;Spatial Stream;Temporal Stream;Dense Optical Flow;public action video datasets;Weizmann dataset;networks combination;two-stream convolutional network classifier;video generation devices;human assistance;exhaustive search;spatial stream","","2","","29","","18 Jan 2018","","","IEEE","IEEE Conferences"
"Measuring Anthropometric Data for HRTF Personalization","M. Rothbucher; T. Habigt; J. Habigt; T. Riedmaier; K. Diepold","Inst. for Data Process., Tech. Univ. Munchen, Munich, Germany; Inst. for Data Process., Tech. Univ. Munchen, Munich, Germany; Inst. for Data Process., Tech. Univ. Munchen, Munich, Germany; Inst. for Data Process., Tech. Univ. Munchen, Munich, Germany; Inst. for Data Process., Tech. Univ. Munchen, Munich, Germany","2010 Sixth International Conference on Signal-Image Technology and Internet Based Systems","17 Feb 2011","2010","","","102","106","Nowadays, multimodal human-like sensing, e.g. vision, haptics and audition seeks to improve interaction between an operator (human) and a teleoperator (robot) in human centered robotic systems. Head Related Transfer Function (HRTF) based sound rendering techniques, which seek to create a realistic virtual auditory space for listeners, have become a prominent concept in human robot interaction. Applications that demand high quality 3D sound synthesis are usually based on measured HRTFs of listeners. Recently, researchers propose to construct a set of personalized HRTFs using multiple linear regression models between anthropometric data and measured HRTFs, which implies the existence of a training HRTF dataset together with the corresponding anthropometric data. This paper focuses on the measurement of Head-Related transfer Functions (HRTFs) and the corresponding anthropometric data of a listener. Several state-of-the-art techniques of measuring the HRTFs are described. For measuring the anthropometric data, we develop a low budget approach, which enables us to measure the anthropometry of a person within short time at a high accuracy, whereas the hardware costs for the scanning system are significantly reduced.","","978-1-4244-9527-6","10.1109/SITIS.2010.27","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5714537","","Three dimensional displays;Measurement by laser beam;Solid modeling;Anthropometry;Transfer functions;Lasers;Ear","acoustic signal processing;acoustic waves;anthropometry;ear;humanoid robots;human-robot interaction;regression analysis;rendering (computer graphics);solid modelling;transfer functions;virtual reality","anthropometric data measurement;HRTF personalization;multimodal human-like sensing;human centered robotic system;head related transfer function;sound rendering technique;virtual auditory space;human robot interaction;high quality 3D sound synthesis;multiple linear regression model;HRTF dataset;state-of-the-art technique;hardware cost","","3","9","15","","17 Feb 2011","","","IEEE","IEEE Conferences"
"Multimodal interface for temporal pattern based interactive large volumetric visualization","P. Kumar; A. Agrawal; S. Prasad","Indian Institute of Information Technology, Allahabad, India; Indian Institute of Information Technology, Allahabad, India; Nanyang Technical University, Singapore","TENCON 2017 - 2017 IEEE Region 10 Conference","21 Dec 2017","2017","","","1239","1244","Scientific data visualization is a prominent area of research in the development of Virtual Reality Applications in order to make it more interactive and robotic. But the efficient interaction with the large size of medical data is a challenging task to diagnose virtual surgerical environment learning for a Physician. In this paper, we proposed a multimodal interface for GPU-accelerated interactive large scale volumetric data rendering to overcome this limitation. The large data has been pre-processed by octree method. An improved raycasting algorithm is used in association with a transfer function classification method for the effective rendering. The temporal data is used for defining gestures, retrieving in a pattern from the wearable device for providing multimodality with the large rendered data. A gesture vocabulary has been defined by these patterns for the navigation in visualizing the large scale medical data, which consists of five complex interactive postures used for Normal, Picking, Rotation, Dragging, and Zooming gestures. These gesture vocabularies have been categorized by kNN classification method of pattern recognition. Experimental results of the proposed approach are analyzed with the help of various ANOVA and T-testing graphs using SPSS 20 version tool and confidence interval of interaction with hand gestures vocabulary. The results of proposed approach are further compared with the existing approaches in which Microsoft Kinect and P5 dataglove have been used. The proposed system has been navigated by the DG5 VHand 2.0 Bluetooth version hand dataglove as wearable assistive device to achieve an effective interaction. The system has been tested on 10 different sizes of volume datasets ranging from 10MB to 3.15 GB. The scope of this paper is basically to develop system training with robotic arm in medical domain.","2159-3450","978-1-5090-1134-6","10.1109/TENCON.2017.8228047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8228047","Hand DataGlove;Volume Rendering;Human-Computer Interaction;Multimodal Inteface;Medical Dataset;Large scale","Data visualization;Three-dimensional displays;Virtual reality;Rendering (computer graphics);Thumb;Vocabulary;Biomedical imaging","Bluetooth;data gloves;data visualisation;feature extraction;gesture recognition;human computer interaction;interactive systems;medical computing;octrees;pattern classification;rendering (computer graphics);surgery;virtual reality","multimodal interface;temporal pattern;interactive large volumetric visualization;scientific data visualization;interactive large scale volumetric data rendering;octree method;improved raycasting algorithm;transfer function classification method;wearable device;multimodality;rendered data;gesture vocabulary;complex interactive postures;kNN classification method;pattern recognition;DG5 VHand 2.0 Bluetooth version hand dataglove;wearable assistive device;virtual reality applications;zooming gesture;normal gesture;picking gesture;rotation gesture;dragging gesture;hand gesture vocabulary;virtual surgical environment","","1","","17","","21 Dec 2017","","","IEEE","IEEE Conferences"
"Mobility Management With Transferable Reinforcement Learning Trajectory Prediction","Z. Zhao; M. Karimzadeh; L. Pacheco; H. Santos; D. Rosário; T. Braun; E. Cerqueira","School of Electronic and Information Engineering, Beihang University, Beijing, China; Institute of Computer Science, University of Bern, Bern, Switzerland; Institute of Computer Science, University of Bern, Bern, Switzerland; Institute of Computer Science, University of Bern, Bern, Switzerland; Institute of Technology, Federal University of Pará, Belem, Brazil; Institute of Computer Science, University of Bern, Bern, Switzerland; Institute of Technology, Federal University of Pará, Belem, Brazil","IEEE Transactions on Network and Service Management","9 Dec 2020","2020","17","4","2102","2116","Future mobile networks will enable the massive deployment of mobile multimedia applications anytime and anywhere. In this context, mobility management schemes, such as handover and proactive multimedia service migration, will be essential to improve network performance. In this article, we propose a proactive mobility management approach based on group user trajectory prediction. Specifically, we introduce a mobile user trajectory prediction algorithm by combining the Long-Short Term Memory networks (LSTM) with Reinforcement Learning (RL) to automate the model training procedure. We further develop a group user trajectory predictor to reduce prediction calculation overheads of users with similar movement patterns. To validate the impact of the proposed mobility management approach, we present a virtual reality (VR) service migration scheme built on the top of the proactive handover mechanism that benefits from trajectory predictions. Experiment results validate our predictor's outstanding accuracy and its impacts on enhancing handover and service migration performance to provide quality of service assurance.","1932-4537","","10.1109/TNSM.2020.3034482","Beihang Zhuobai program; Orange research project Context Awareness Engine; CAPES—Finance Code 001; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9244233","Mobility management;trajectory prediction;reinforcement learning;transfer learning;service migration","Trajectory;Mobile handsets;Streaming media;Handover;Computer architecture;Prediction algorithms","learning (artificial intelligence);mobility management (mobile radio);multimedia communication;telecommunication computing;virtual reality","mobile multimedia applications;proactive multimedia service migration;network performance;proactive mobility management approach;group user trajectory prediction;mobile user trajectory prediction algorithm;long-short term memory networks;model training procedure;group user trajectory predictor;virtual reality service migration scheme;proactive handover mechanism;service migration performance;future mobile networks;transferable reinforcement learning trajectory prediction","","","","48","IEEE","29 Oct 2020","","","IEEE","IEEE Journals"
"The feasibility of applying the neural network technology to the automatic time report system","Chia-Shu Liao; Huang-Tien Lin; Fang-Dar Chu; Jiang-Lin Shi; Chia-Lu Ho","Telecommun. Labs., Chunghwa Telecom Co. Ltd., China; NA; NA; NA; NA","IEEE Instrumentation and Measurement Technology Conference Sensing, Processing, Networking. IMTC Proceedings","6 Aug 2002","1997","2","","1122","1125 vol.2","Utilizing neural network technology, the automatic time report (embryo) system was modified by ChunghWa Telecom. This paper shows how the neural network technology is applied to simulate the operations of supervision and error detection. One may find that the automatic time report system is more complete and suitable for users.","1091-5281","0-7803-3747-6","10.1109/IMTC.1997.612375","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=612375","","Neural networks;Telecommunications;Embryo;Telephony;Broadcasting;Automatic control;Control systems;Laboratories;Physiology;Psychology","synchronisation;telecommunication computing;clocks;time measurement;error detection codes;telecommunication control;simulation;neural nets;decoding;code convertors;telephony","neural network technology;automatic time report system;embryo system;supervision;error detection;simulation;synchronization;time signal;inverse transfer training rule;sigmoid function;multilayer network;time decoding unit;computer control;speaking clock;ACON model;supernet","","","","3","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Modeling liquid phase oxygenation process using neural network","Jiabao Zhu; Zhengzhi Han; Jin Xiao; Ming Rao","Dept. of Chem. Eng., Alberta Univ., Edmonton, Alta., Canada; NA; NA; NA","Proceedings of International Conference on Neural Networks (ICNN'97)","6 Aug 2002","1997","2","","844","847 vol.2","This paper describes a modeling application for LPO (liquid phase oxygenation) process using backpropagation neural network. An integrated neural professional II/sup TM/ based software for developing neural network models is developed for this project. In this software, a visual data processing method for improving the effects of training, a correlation analyzer that can be used to help simplify the model's inputs/outputs structure and a training kit are all included. The satisfactory result is reached by selecting different structures and variables of the neural networks. At last, an online upgrading scheme is proposed and has shown the great potential in simulation.","","0-7803-4122-8","10.1109/ICNN.1997.616134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=616134","","Neural networks;Neurons;Backpropagation;Productivity;Temperature;Chemical processes;History;Transfer functions;Intelligent networks;Laboratories","oxidation;production engineering computing;petroleum industry;chemical industry;neural nets;digital simulation;backpropagation;correlation methods;graphical user interfaces","liquid phase oxygenation process;LPO;backpropagation neural network;integrated neural professional II based software;visual data processing method;correlation analyzer;input/output structure;training kit;online upgrading scheme","","","","3","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Human Adaptation to Interaction Forces in Visuo-Motor Coordination","F. C. Huang; R. B. Gillespie; A. D. Kuo","Dept. of Mech. Eng., Michigan Univ., Ann Arbor, MI; NA; NA","IEEE Transactions on Neural Systems and Rehabilitation Engineering","18 Sep 2006","2006","14","3","390","397","We tested whether humans can learn to sense and compensate for interaction forces in contact tasks. Many tasks, such as use of hand tools, involve significant interaction forces between hand and environment. One control strategy would be to use high hand impedance to reduce sensitivity to these forces. But an alternative would be to learn feedback compensation for the extrinsic dynamics and associated interaction forces, with the potential for lower control effort. We observed subjects as they learned control of a ball-and-beam system, a visuo-motor task where the goal was to quickly position a ball rolling atop a rotating beam, through manual rotation of the beam alone. We devised a ball-and-beam apparatus that could be operated in a real mode, where a physical ball was present; or in a virtual training mode, where the ball's dynamics were simulated in real time. The apparatus presented the same visual feedback in all cases, and optionally produced haptic feedback of the interaction forces associated with the ball's motion. Two healthy adult subject groups, vision-only and vision-haptics (each n=10), both trained for 80 trials on the simulated system, and then were evaluated on the real system to test for skill transfer effects. If humans incorporate interaction forces in their learning, the vision-haptics group would be expected to exhibit a smoother transfer, as quantified by changes in completion time of a ball-positioning task. During training, both groups adapted well to the task, with reductions of 64%-70% in completion time. At skill transfer to the real system, the vision-only group had a significant 35% increase in completion time (p<0.05). There was no significant change in the vision-haptics group, indicating that subjects had learned to compensate for interaction forces. These forces could potentially be incorporated in virtual environments to assist with motor training or rehabilitation","1558-0210","","10.1109/TNSRE.2006.881533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703571","Feedback control;haptic interface;motor adaptation;motor control;object manipulation;upper extremity","Humans;Force feedback;Haptic interfaces;Neurofeedback;Muscles;Force control;Virtual environment;Sensor arrays;Testing;Impedance","biomechanics;feedback;haptic interfaces;medical control systems;patient rehabilitation;virtual reality;vision","human adaptation;interaction forces;visuo-motor coordination;contact tasks;hand tools;high hand impedance;feedback compensation;ball-and-beam system;visual feedback;haptic feedback;ball-positioning task;motor training;rehabilitation","Adaptation, Physiological;Feedback;Humans;Motor Skills;Movement;Muscle, Skeletal;Musculoskeletal Equilibrium;Stress, Mechanical;Task Performance and Analysis;Touch;Upper Extremity;Visual Perception","15","","20","","18 Sep 2006","","","IEEE","IEEE Journals"
"Deep Learning Based Resource Allocation in NOMA Wireless Power Transfer Networks","R. Lin; Y. Zhao; L. Tian; M. Liu; B. Chen; Y. Zhu; J. Tang","China Southern Power Grid Extra High Voltage Transmission Company,Guangzhou,China; South China University of Technology School of Electronic and Information Engineering,Guangzhou,China; China Southern Power Grid Extra High Voltage Transmission Company,Guangzhou,China; China Southern Power Grid Extra High Voltage Transmission Company,Guangzhou,China; China Southern Power Grid Extra High Voltage Transmission Company,Guangzhou,China; China Southern Power Grid Extra High Voltage Transmission Company,Guangzhou,China; South China University of Technology School of Electronic and Information Engineering,Guangzhou,China","2019 IEEE 3rd International Electrical and Energy Conference (CIEEC)","27 Apr 2020","2019","","","2098","2103","This paper investigates resource allocation of simultaneous wireless information and power transfer (SWIPT) in non-orthogonal multiple access (NOMA) system with power splitting (PS) technology. Our goal is to optimize both the harvested energy and the transmission rate subject to the minimum requirements on each user's harvested energy and transmission rate. Considering the battery is capable of storing power which is converted into throughput in reverse link, we establish the equivalent-sum-rate (ESR) maximazation function by combining the transformed throughput and the transmission rate with a weight coefficient. Since the formulated nonconvex problem is difficult to solve, we develop a deep learning-based approach to obtain an efficient resource allocation strategy. In particular, deep belief network (DBN), which comprises preparing data samples, training and running, has been adopted. The simulation results verify the effectiveness of the proposed DBN-based scheme, and prove that the ESR performance of the considered NOMA-SWIPT is better than that of the OFDMA-SWIPT.","","978-1-7281-1675-4","10.1109/CIEEC47146.2019.CIEEC-2019727","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9076986","Non-orthogonal multiple access (NOMA);deep learning;simultaneous wireless information and power transfer (SWIPT)","","belief networks;concave programming;energy harvesting;learning (artificial intelligence);multi-access systems;radiofrequency power transmission;resource allocation;telecommunication computing;telecommunication power management","NOMA wireless power transfer networks;nonorthogonal multiple access system;power splitting technology;energy harvesting;transmission rate;reverse link;equivalent-sum-rate maximazation function;transformed throughput;nonconvex problem;deep learning-based approach;resource allocation strategy;deep belief network;DBN-based scheme;NOMA-SWIPT;simultaneous wireless information and power transfer;ESR maximization function","","1","","14","","27 Apr 2020","","","IEEE","IEEE Conferences"
"HeuRL: A Heuristically Initialized Reinforcement Learning Method for Autonomous Driving Control Task","J. Xu; J. Yuan","Global Innovation Exchange Institute, Tsinghua University, Beijing, 100084, China; Global Innovation Exchange Institute, Tsinghua University, Beijing, 100084, China","2018 International Conference on Control and Robots (ICCR)","15 Nov 2018","2018","","","57","62","Although reinforcement learning (RL) shows great intelligence in many simulation tasks, it hasn't been widely applied in real-world vehicle control tasks due to the simulation-to-real-world (Sim2Real) transferring difficulties. Vehicle models and road conditions in real world can be very different from those in simulators. As a result, the RL models trained by simulators usually fail and need to be trained again under a new environment, which is dangerous and time-consuming. Some hand-craft heuristic methods, by contrast, are independent of environmental characters and perform more reliably in an unfamiliar situation. In this paper, we introduce a heuristically initialized RL model (HeuRL), which sped up the learning convergence by 4 times and decreased the collisions by 90% during the training process under a new environment. The experiments were conducted in The Open Racing Car Simulator (TORCS), an open-source platform for real-time car racing simulation.","","978-1-5386-8243-2","10.1109/ICCR.2018.8534494","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8534494","robotic control;autonomous driving;artificial intelligence;reinforcement learning;simulator","Automobiles;Sensors;Wheels;Autonomous vehicles;Brakes;Target tracking","automobiles;digital simulation;learning (artificial intelligence);mobile robots;public domain software;road traffic control","heuristically initialized reinforcement learning method;autonomous driving control task;real-world vehicle control tasks;Sim2Real;vehicle models;road conditions;heuristically initialized RL model;HeuRL;learning convergence;real-time car racing simulation;open racing car simulator;simulation-to-real-world;open-source platform","","","","11","","15 Nov 2018","","","IEEE","IEEE Conferences"
"Qualitative Prediction and Recognition of ongoing Human Action Sequences Using Deep Neural Networks","M. V. K; R. K. Thandil; M. B. K. P","Sullamussalam Science College,Department of Computer Science,Areekode,India; Sullamussalam Science College,Department of Computer Science,Areekode,India; Sullamussalam Science College,Department of Computer Science,Areekode,India","2020 3rd International Conference on Intelligent Sustainable Systems (ICISS)","18 Jan 2021","2020","","","605","610","Human action detection (HAD) is an important research area in the recent decades that can be applied in many applications such as security, gaming, virtual reality interfaces, surveillance systems, etc. The authors have used object detection algorithms with deep neural network-based classifiers in this experiment. Further, the proposed research work aims to explore the solutions for object detection in HAD. The model has been provided with a set of images, wherein each image, a person will be performing an activity such as standing, sitting, bending, waving, or sleeping. The label of an image will be the activity that is being performed in those images. The model will learn this relationship, and then it can predict the label of an input that it has never seen. The model is trained and tested with a dataset consisting of random images downloaded from the internet.","","978-1-7281-7089-3","10.1109/ICISS49785.2020.9315962","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9315962","Object detection;human action recognition;faster R-CNN;machine learning;transfer learning","Training;Computational modeling;Object detection;Proposals;Solid modeling;Feature extraction;Predictive models","deep learning (artificial intelligence);image motion analysis;image recognition;image sequences;object detection;virtual reality","human action sequences;human action detection;virtual reality interfaces;surveillance systems;object detection algorithms;deep neural network-based classifiers;random images;qualitative prediction;HAD;internet","","","","25","","18 Jan 2021","","","IEEE","IEEE Conferences"
"Spectrum sensing based on deep learning classification for cognitive radios","S. Zheng; S. Chen; P. Qi; H. Zhou; X. Yang","Science and Technology on Communication Information Security Control Laboratory, Jiaxing 314033, China; Science and Technology on Communication Information Security Control Laboratory, Jiaxing 314033, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an 710071, China; Science and Technology on Communication Information Security Control Laboratory, Jiaxing 314033, China; Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education of China, Xidian University, Xi'an 710071, China; Science and Technology on Communication Information Security Control Laboratory, Jiaxing 314033, China","China Communications","2 Mar 2020","2020","17","2","138","148","Spectrum sensing is a key technology for cognitive radios. We present spectrum sensing as a classification problem and propose a sensing method based on deep learning classification. We normalize the received signal power to overcome the effects of noise power uncertainty. We train the model with as many types of signals as possible as well as noise data to enable the trained network model to adapt to untrained new signals. We also use transfer learning strategies to improve the performance for real-world signals. Extensive experiments are conducted to evaluate the performance of this method. The simulation results show that the proposed method performs better than two traditional spectrum sensing methods, i.e., maximum-minimum eigenvalue ratio-based method and frequency domain entropy-based method. In addition, the experimental results of the new untrained signal types show that our method can adapt to the detection of these new signals. Furthermore, the real-world signal detection experiment results show that the detection performance can be further improved by transfer learning. Finally, experiments under colored noise show that our proposed method has superior detection performance under colored noise, while the traditional methods have a significant performance degradation, which further validate the superiority of our method.","1673-5447","","10.23919/JCC.2020.02.012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9020304","spectrum sensing;deep learning;convolutional neural network;cognitive radio;spectrum management","Sensors;Machine learning;Training;Adaptation models;Feature extraction;Cognitive radio;Uncertainty","cognitive radio;eigenvalues and eigenfunctions;entropy;learning (artificial intelligence);radio spectrum management;signal classification;signal denoising;signal detection;telecommunication computing","deep learning classification;received signal power;noise power uncertainty;noise data;trained network model;transfer learning strategies;untrained signal types;real-world signal detection experiment results;cognitive radios;classification problem","","3","","","","2 Mar 2020","","","IEEE","IEEE Magazines"
"Analysis of KUMA system developed for e-Learning","Y. Ohshima; K. Kozono; S. Kamaga; T. Kiyan; M. Suemitsu; H. Akiyama","Faculty of Engineering, Sojo University, 4-22-1 Ikeda, Kumamoto-shi, 860-0082, JAPAN; Department of Administration, Prefectural University of Kumamoto, 3-1-100 Tsukide, Kumamoto-shi, 862-8502, JAPAN; Department of Culture and Language, Shokei University, 6-5-1 Nirenoki, Kumamoto-shi, 861-8538, JAPAN; Graduate School of Science and Technology, Kumamoto University, 860-8555, JAPAN; Graduate School of Science and Technology, Kumamoto University, 860-8555, JAPAN; Graduate School of Science and Technology, Kumamoto University, 860-8555, JAPAN","2011 International Conference on Information Technology Based Higher Education and Training","15 Sep 2011","2011","","","1","3","When an instructor creates an educational content with narration on Microsoft PowerPoint, it is the easiest method that he/she uses one's built-in feature of recording narration because there is no need to install any other software. We constructed the content authoring system for e-Learning, named Kumamoto Universal and Multipurpose Authoring (KUMA) system, which is based on cloud computing. Using the system, an instructor only has to upload the slide with narration created on PowerPoint to the system, and then he/she can publish a Windows Media streaming video and a PDF slide. The application of the system is the website of streaming video lectures contributed by researchers in the field of pulsed power, which we call “Streaming Book on Pulsed Power Engineering”. Another application of it is the website of video lectures for graduate students as a part of blended learning. To deliver streaming videos to more than 100 students simultaneously, we need to configure quality of encoding streaming videos and estimate the amount of transferring data and the network traffic load. The purpose of this study is to examine the traffic load for streaming e-Learning content in applications of KUMA system. In this work, we use Windows Media Load Simulator to simulate the connections from more than 100 students.","","978-1-4577-1672-0","10.1109/ITHET.2011.6018689","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6018689","","Streaming media;Media;Educational institutions;Servers;Electronic learning;Telecommunication traffic","authoring systems;cloud computing;computer aided instruction;media streaming;Web sites","KUMA system analysis;e-learning;educational content;Microsoft PowerPoint;Kumamoto Universal and Multipurpose Authoring;cloud computing;Windows Media streaming video;PDF slide;Web site;video lectures;blended learning;network traffic load;Windows Media Load Simulator;content authoring system","","3","","14","","15 Sep 2011","","","IEEE","IEEE Conferences"
"Furthering Service 4.0: Harnessing Intelligent Immersive Environments and Systems","A. Pena-Rios; H. Hagras; G. Owusu; M. Gardner","Intelligent Environments Research Group, University of Essex, Colchester, United Kingdom; Intelligent Environments Research Group, University of Essex, Colchester, United Kingdom; Business Modelling and Operational Transformation Practice, British Telecom, Ipswich, United Kingdom; Intelligent Environments Research Group, University of Essex, Colchester, United Kingdom","IEEE Systems, Man, and Cybernetics Magazine","17 Jan 2018","2018","4","1","20","31","With the increasing complexity of service operations in different industries and more advanced uses of specialized equipment and procedures, the great current challenge for companies is to increase employees' expertise and their ability to maintain and improve service quality. In this regard, Service 4.0 aims to support and promote innovation in service operations using emergent technology. Current technological innovations present a significant opportunity to provide on-site, real-time support for field service professionals in many areas. It should be no surprise, then, that intelligent immersive environments have the potential to enhance service operations by improving customer service and increasing overall efficiency. Intelligent immersive systems combine immersive technologies with computational intelligence mechanisms to produce adaptive, context-aware environments for advanced decisionmaking support. Such technologies, e.g., mixed reality (MR) and augmented reality (AR), can potentially enhance working environments, optimizing resources by reducing time and location restrictions, leading to much faster knowledge transfer and a deeper understanding of different processes. These methods can also promote faster response times to provide field service technicians with on-the-job assistance in unfamiliar situations.","2333-942X","","10.1109/MSMC.2017.2769199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260586","","Maintenance engineering;Training;Virtual reality;Tracking;Complexity theory;Industries;Service-oriented systems engineering","augmented reality;customer services;innovation management;knowledge management;personnel;ubiquitous computing","real-time support;service operations;customer service;intelligent immersive systems;computational intelligence mechanisms;context-aware environments;advanced decisionmaking support;field service technicians;service quality;technological innovations;intelligent immersive environments;employee expertise","","4","","70","","17 Jan 2018","","","IEEE","IEEE Magazines"
"Spatially Separated Cutaneous Haptic Guidance for Training of a Virtual Sensorimotor Task","C. Smith; E. Pezent; M. K. O’Malley","Rice University,Mechatronics and Haptic Interfaces Laboratory,Houston,77005; Rice University,Mechatronics and Haptic Interfaces Laboratory,Houston,77005; Rice University,Mechatronics and Haptic Interfaces Laboratory,Houston,77005","2020 IEEE Haptics Symposium (HAPTICS)","7 May 2020","2020","","","974","979","Haptic devices enable multi-modal feedback to a user when training to perform novel motor skills in controlled, virtual environments. Haptic feedback has been proposed as a means to provide additional guidance cues that might improve training efficacy; however, recent studies have identified drawbacks to haptic guidance, including reliance on guidance forces and an inability to distinguish between forces that are part of the virtual environment and those that communicate task completion strategies. Recently, we proposed a novel approach to providing haptic guidance that separates task and guidance forces. We used a kinesthetic haptic interface to communicate task forces and a spatially separated tactile skin-stretch device to transmit guidance forces. Our experiments showed that feed-forward control using this paradigm was effective for improving performance in a trajectory following task. In this paper, we explore the potential for spatially separated cutaneous haptic guidance to train a user to optimally control an inverted pendulum system. We present and execute a task and training protocol designed to determine whether error-based haptic feedback provided cutaneously can accelerate learning of a task, and whether participants can retain or transfer task skills even after guidance is no longer present. We found that subject performance improved while spatially separated cutaneous haptic guidance was active. Despite this finding, performance in the pendulum balancing task was not affected once the haptic assistance was removed.","2324-7355","978-1-7281-0234-4","10.1109/HAPTICS45997.2020.ras.HAP20.11.2032900c","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9086314","","","feedforward;haptic interfaces;pendulums;virtual reality","spatially separated cutaneous haptic guidance;virtual sensorimotor task;haptic devices;virtual environments;guidance cues;guidance forces;kinesthetic haptic interface;task forces;spatially separated tactile skin-stretch device;error-based haptic feedback;haptic assistance;multimodal feedback;feed-forward control;inverted pendulum system","","","","27","","7 May 2020","","","IEEE","IEEE Conferences"
"ImmerVol: An immersive volume visualization system","N. M. Khan; M. Kyan; L. Guan","Department of Electrical and Computer Engineering, Ryerson University, Canada; Department of Electrical and Computer Engineering, Ryerson University, Canada; Department of Electrical and Computer Engineering, Ryerson University, Canada","2014 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA)","23 Jun 2014","2014","","","24","29","Volume visualization is a popular technique for analyzing 3D datasets, especially in the medical domain. An immersive visual environment provides easier navigation through the rendered dataset. However, visualization is only one part of the problem. Finding an appropriate Transfer Function (TF) for mapping color and opacity values in Direct Volume Rendering (DVR) is difficult. This paper combines the benefits of the CAVE Automatic Virtual Environment with a novel approach towards TF generation for DVR, where the traditional low-level color and opacity parameter manipulations are eliminated. The TF generation process is hidden behind a Spherical Self Organizing Map (SSOM). The user interacts with the visual form of the SSOM lattice on a mobile device while viewing the corresponding rendering of the volume dataset in real time in the CAVE. The SSOM lattice is obtained through high-dimensional features extracted from the volume dataset. The color and opacity values of the TF are automatically generated based on the user's perception. Hence, the resulting TF can expose complex structures in the dataset within seconds, which the user can analyze easily and efficiently through complete immersion.","2377-9322","978-1-4799-2614-5","10.1109/CIVEMSA.2014.6841433","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6841433","","Image color analysis;Rendering (computer graphics);Lattices;Data visualization;Vectors;Training;Three-dimensional displays","data visualisation;feature extraction;image colour analysis;medical computing;opacity;rendering (computer graphics);self-organising feature maps;transfer functions;vectors","ImmerVol;immersive volume visualization system;3D datasets analysis;medical domain;navigation;rendered dataset;transfer function;color values;opacity values;direct volume rendering;DVR;CAVE;automatic virtual environment;spherical self organizing map;SSOM;feature extraction","","","","19","","23 Jun 2014","","","IEEE","IEEE Conferences"
"Transfer Learning-Based Microfluidic Design System for Concentration Generation∗","W. Ji; T. -Y. Ho; H. Yao","Tsinghua University,Department of Computer Science and Technology; National Tsing Hua University,Department of Computer Science; Tsinghua University,Department of Computer Science and Technology","2020 57th ACM/IEEE Design Automation Conference (DAC)","9 Oct 2020","2020","","","1","6","Due to the complexity of human physiology and variability among individuals, e.g., genes, environment, lifestyle exposures, etc., personalized medicine has attracted great interest in the past few years. For synthesizing personalized medicine, it is critical to prepare customized samples with specific concentrations by microfluidic biochips because of the advantages in saving costly reagents and rare samples. The current state-of-the-art of concentration generation for microfluidic biochips is to construct a database by random design methods. However, due to the complex multidimentional parameters such as molecule diameters, inlets, outlets, etc, the whole process is error prone and time consuming. To speedup database construction and reduce the errors in concentration generation, this paper proposes the first transfer learning-based method based on an artificial neural network model (ANN). Given an initial ANN model, transfer learning method can fine-tune weights of ANN to obtain all ANN models needed in the database, which can significantly reduce the amount of required training data. Computational simulation results show that the time for database construction is reduced from several months to 2 days, and the query error is reduced by 83% compared with the existing method.","0738-100X","978-1-7281-1085-1","10.1109/DAC18072.2020.9218722","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9218722","Microfluidic biochips;Concentration generation;Transfer learning","","learning (artificial intelligence);medical computing;microfluidics;neural nets;physiology;random processes","database construction;concentration generation;artificial neural network model;ANN models;transfer learning-based microfluidic design system;specific concentrations;microfluidic biochips;random design methods;complex multidimentional parameters;personalized medicine synthesis","","","","21","","9 Oct 2020","","","IEEE","IEEE Conferences"
"Transfer Learning for Semi-Supervised Automatic Modulation Classification in ZF-MIMO Systems","Y. Wang; G. Gui; H. Gacanin; T. Ohtsuki; H. Sari; F. Adachi","College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; Faculty of Electrical Engineering and Information Technology, RWTH Aachen University, Aachen, Germany; Department of Information and Computer Science, Keio University, Yokohama, Japan; College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; Research Organization of Electrical Communication (ROEC), Tohoku University, Sendai, Japan","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","12 Jun 2020","2020","10","2","231","239","Automatic modulation classification (AMC) is an essential technology for the non-cooperative communication systems, and it is widely applied into various communications scenarios. In the recent years, deep learning (DL) has been introduced into AMC due to its outstanding identification performance. However, it is almost impossible to implement previously proposed DL-based AMC algorithms without large number of labeled samples, while there are generally few labeled sample and large unlabel samples in the realistic communication scenarios. In this paper, we propose a transfer learning (TL)-based semi-supervised AMC (TL-AMC) in a zero-forcing aided multiple-input and multiple-output (ZF-MIMO) system. TL-AMC has a novel deep reconstruction and classification network (DRCN) structure that consists of convolutional auto-encoder (CAE) and convolutional neural network (CNN). Unlabeled samples flow from CAE for modulation signal reconstruction, while labeled samples are fed into CNN for AMC. Knowledge is transferred from the encoder layer of CAE to the feature layer of CNN by sharing their weights, in order to avoid the ineffective feature extraction of CNN under the limited labeled samples. Simulation results demonstrated the effectiveness of TL-AMC. In detail, TL-AMC performs better than CNN-based AMC under the limited samples. What's more, when compared with CNN-based AMC trained on massive labeled samples, TL-AMC also achieved the similar classification accuracy at the relative high SNR regime.","2156-3365","","10.1109/JETCAS.2020.2992128","Project Funded by the National Science and Technology Major Project of the Ministry of Science and Technology of China; National Natural Science Foundation of China; Jiangsu Specially Appointed Professor; Innovation and Entrepreneurship of Jiangsu High-level Talent; Six Top Talents Program of Jiangsu; 1311 Talent Plan of Nanjing University of Posts and Telecommunications; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9085414","Automatic modulation classification;deep learning;convolutional neural network;transfer learning;multiple-input and multiple-output","Modulation;MIMO communication;Receiving antennas;Transmitting antennas;Equalizers","convolutional neural nets;cooperative communication;feature extraction;learning (artificial intelligence);MIMO communication;modulation;pattern classification;signal reconstruction;telecommunication computing","deep learning;AMC algorithms;generally few labeled sample;large unlabel samples;realistic communication scenarios;transfer learning-based semisupervised AMC;TL-AMC;deep reconstruction;unlabeled samples;modulation signal reconstruction;CNN-based AMC;massive labeled samples;semisupervised automatic modulation classification;ZF-MIMO systems;noncooperative communication systems;communications scenarios","","10","","46","IEEE","4 May 2020","","","IEEE","IEEE Journals"
"Upper Limb Rehabilitation System for Stroke Survivors Based on Multi-Modal Sensors and Machine Learning","S. Miao; C. Shen; X. Feng; Q. Zhu; M. Shorfuzzaman; Z. Lv","School of Data Science and Software Engineering, Qingdao University, Qingdao, China; School of Data Science and Software Engineering, Qingdao University, Qingdao, China; Department of Rehabilitation, Affiliated Hospital of Qingdao University, Qingdao, China; Department of Rehabilitation, Affiliated Hospital of Qingdao University, Qingdao, China; Department of Computer Science, College of Computers and Information Technology, Taif University, Taif, Saudi Arabia; School of Data Science and Software Engineering, Qingdao University, Qingdao, China","IEEE Access","23 Feb 2021","2021","9","","30283","30291","Nowadays, rehabilitation training for stroke survivors is mainly completed under the guidance of the physician. There are various treatment ways, however, most of them are affected by various factors such as experience of physician and training intensity. The treatment effect cannot be fed back in time, and objective evaluation data is lacking. In addition, the treatment method is complicated, costly, and highly dependent on physicians. Moreover, stroke survivors' compliance is poor, which leads to various limitations. This paper combines the Internet-of-Things, machine learning, and intelligence system technologies to design a smartphone-based intelligence system to help stroke survivors to improve upper limb rehabilitation. With the built-in multi-modal sensors of the smart phone, training action data of users can be obtained, and then transfer to the server through the Internet. This research presents a DTW-KNN joint algorithm to recognize accuracy of rehabilitation actions and classify to multiple training completion levels. The experimental results show that the DTW-KNN algorithm can evaluate the rehabilitation actions, the accuracy rates of the classification in excellent, good, and normal are 85.7%, 66.7%, and 80% respectively. The intelligence system presented in this paper can help stroke survivors to proceed rehabilitation training independently and remotely, which reduces medical costs and psychological burden.","2169-3536","","10.1109/ACCESS.2021.3055960","Taif University Researchers Supporting Project number, Taif University, Taif, Saudi Arabia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9343271","Machine learning;multi-modal sensor;Internet-of-Things;upper limb rehabilitation;intelligent system","Stroke (medical condition);Training;Medical services;Sensors;Servers;Machine learning;Robots","biomedical measurement;diseases;intelligent sensors;Internet of Things;medical computing;nearest neighbour methods;patient rehabilitation;patient treatment;smart phones;time warp simulation","upper limb rehabilitation;stroke survivors;machine learning;rehabilitation training;smartphone-based intelligence system;multiple training completion levels;Internet-of-things;built-in multimodal sensors;DTW-KNN algorithm;dynamic time warping;K-nearest neighbor","","","","46","CCBY","1 Feb 2021","","","IEEE","IEEE Journals"
"Human-like Planning for Reaching in Cluttered Environments","M. Hasan; M. Warburton; W. C. Agboh; M. R. Dogar; M. Leonetti; H. Wang; F. Mushtaq; M. Mon-Williams; A. G. Cohn","University of Leeds,School of Computing,UK; University of Leeds,School of Psychology,UK; University of Leeds,School of Computing,UK; University of Leeds,School of Computing,UK; University of Leeds,School of Computing,UK; University of Leeds,School of Computing,UK; University of Leeds,School of Psychology,UK; University of Leeds,School of Psychology,UK; University of Leeds,School of Computing,UK","2020 IEEE International Conference on Robotics and Automation (ICRA)","15 Sep 2020","2020","","","7784","7790","Humans, in comparison to robots, are remarkably adept at reaching for objects in cluttered environments. The best existing robot planners are based on random sampling of configuration space- which becomes excessively high-dimensional with large number of objects. Consequently, most planners often fail to efficiently find object manipulation plans in such environments. We addressed this problem by identifying high-level manipulation plans in humans, and transferring these skills to robot planners. We used virtual reality to capture human participants reaching for a target object on a tabletop cluttered with obstacles. From this, we devised a qualitative representation of the task space to abstract the decision making, irrespective of the number of obstacles. Based on this representation, human demonstrations were segmented and used to train decision classifiers. Using these classifiers, our planner produced a list of waypoints in task space. These waypoints provided a high-level plan, which could be transferred to an arbitrary robot model and used to initialise a local trajectory optimiser. We evaluated this approach through testing on unseen human VR data, a physics-based robot simulation, and a real robot (dataset and code are publicly available1). We found that the human-like planner outperformed a state-of-the-art standard trajectory optimisation algorithm, and was able to generate effective strategies for rapid planning- irrespective of the number of obstacles in the environment.","2577-087X","978-1-7281-7395-5","10.1109/ICRA40945.2020.9196665","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9196665","","Task analysis;Planning;Robots;Testing;Feature extraction;Trajectory;Standards","collision avoidance;decision making;dexterous manipulators;grippers;learning (artificial intelligence);planning (artificial intelligence);robot programming;robot vision;trajectory control;virtual reality","decision making;decision classifiers;cluttered environments;robot planners;random sampling;object manipulation plans;virtual reality;trajectory optimisation;physics based robot simulation;human-like planning;depth camera;Robotiq two finger gripper","","","","31","","15 Sep 2020","","","IEEE","IEEE Conferences"
"Self-Supervised Pose Adaptation for Cross-Domain Image Animation","C. Wang; C. Xu; D. Tao","School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW, Australia; School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW, Australia; School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW, Australia","IEEE Transactions on Artificial Intelligence","25 Nov 2020","2020","1","1","34","46","Image animation is to animate a still image of the object of interest using poses extracted from another video sequence. Through training on a large-scale video dataset, most existing approaches aim to explore disentangled appearance and pose representations of training frames. Then, the desired output with a specific appearance and pose can be synthesized via recombining learned representations. However, in some real-world applications, test images may lack the corresponding video ground-truth or follow a different distribution than the distribution of the training video frames (i.e., different domains), which largely limit the performance of existing methods. In this paper, we propose domain-independent pose representations that are compatible with and accessible by still images from a different domain. Specifically, we devise a two-stage self-supervised pose adaptation framework for general image animation tasks. A domain-independent pose adaptation generative adversarial network (DIPA-GAN) and a shuffle-patch generative adversarial network (Shuffle-patch GAN) are proposed to penalize the rationality of the synthesized frame's pose and appearance, respectively. Finally, experiments evaluated on various image animation tasks, which include same/cross-domain moving objects, facial expression transfer and human pose retargeting, demonstrate the superiority of the proposed framework over prior literature. Impact Statement-Image animation is a popular technology in video production. Benefiting from the rapid development of artificial intelligence (AI), recent image animation algorithms have been widely used in real-world applications, such as virtual AI news anchor, virtual try-on, and face swapping. However, most existing methods are designed for specific cases. To animate a new portrait, users are asked to collect hundreds of images of the same person and train a new model. The technology proposed in this paper overcomes these training limitations and generalizes image animations. In the challenging cross-domain facial expression transfer task, the user study demonstrated that our technology achieved more than 20% increase in animation success rate. The proposed technology could benefit users in a wide variety of industries including movie production, virtual reality, social media and online retail.","2691-4581","","10.1109/TAI.2020.3031581","Australian Research Council Projects; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229197","Adversarial learning;deep learning;representation learning","Animation;Task analysis;Training;Generative adversarial networks;Artificial intelligence;Solid modeling;Adaptation models","computer animation;face recognition;feature extraction;image classification;image motion analysis;image sequences;learning (artificial intelligence);neural nets;pose estimation;video signal processing;virtual reality","cross-domain image animation;video sequence;large-scale video dataset;learned representations;adaptation framework;general image animation tasks;adaptation generative adversarial network;shuffle-patch generative adversarial network;synthesized frame;video production;animation success rate;cross-domain facial expression transfer task;image animation algorithm;video ground-truth","","","","59","IEEE","19 Oct 2020","","","IEEE","IEEE Journals"
"Computer-mediated communication in education","Sun Lin; Huang Hui; Wang Wenbo; Liu Hao","Modeling and Simulation Teaching and Research Section , Department of Communication Command, PLA Communication Command Academy, Wuhan, Hubei Province, 430010, China; Training Department , PLA Communication Command Academy, Wuhan, Hubei Province, 430010, China; Department of information and computing, Wuhan university of science and technology, Hubei 430065, China; Military Branches and Services Teaching and Research Section, PLA Nanchang Military Academy, Nanchang, Jiangxi, 330103, China","2010 Second International Conference on Computational Intelligence and Natural Computing","22 Nov 2010","2010","2","","121","123","Synchronous communication techniques allow participants to contribute from locations at the same time. The tools available include chat, desktop videoconferencing and GroupWare. Although these online techniques are probably the most similar to face to face teaching., it cannot be assumed that traditional teaching skills will necessarily transfer successfully or easily. This paper examines some of the potential strategies in the use of synchronous computer-mediated communication in education.","","978-1-4244-7706-7","10.1109/CINC.2010.5643772","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643772","synchronous communication techniques;computer mediated communication;education","Education;Instruments;Computer mediated communication;Servers;Remote laboratories;Frequency measurement;Computational modeling","computer aided instruction;computer mediated communication;groupware;teleconferencing;video communication","computer-mediated communication;education;face-to-face teaching;synchronous communication techniques;chat;desktop videoconferencing;groupware","","","","7","","22 Nov 2010","","","IEEE","IEEE Conferences"
"Speech control of robotic hand augmented with 3D animation using neural network","R. Ismail; M. Ariyanto; W. Caesarendra; I. Haryanto; H. K. Dewoto; Paryanto","Center for Biomechanics, Biomaterial, Biomechatronics and Biosignal Processing (CBIOM3S), Diponegoro University, Semarang, Indonesia; Center for Biomechanics, Biomaterial, Biomechatronics and Biosignal Processing (CBIOM3S), Diponegoro University, Semarang, Indonesia; Center for Biomechanics, Biomaterial, Biomechatronics and Biosignal Processing (CBIOM3S), Diponegoro University, Semarang, Indonesia; Department of Mechanical Engineering, Diponegoro University, Semarang, Indonesia; Department of Mechanical Engineering, Diponegoro University, Semarang, Indonesia; Department of Mechanical Engineering, Diponegoro University, Semarang, Indonesia","2016 IEEE EMBS Conference on Biomedical Engineering and Sciences (IECBES)","6 Feb 2017","2016","","","335","340","In this paper, speech control of robotic hand augmented with 3D animation system has been proposed and presented. Artificial neural network is employed for speech recognition method with tansig and softmax transfer function in hidden layer and output layer. Stream processing method is incorporated for processing the input signal in real time. Thirteen features in frequency domain and time domain that are commonly used in the EMG analysis are utilized in this system. To reduce the influence of noise, voice in noisy environment in the room is recorded as training data set. From the experimental results in offline speech recognition, ANN can recognize the voice command with very high accuracy. In the online real time speech recognition incorporating stream processing, the recognition accuracy decreased about 10%. The proposed speech control of robotic hand augmented with 3D animation is reliable enough with noisy environment.","","978-1-4673-7791-1","10.1109/IECBES.2016.7843469","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7843469","Speech control;artificial neural network;stream processing;robotic hand;3D animation","Robots;Speech recognition;Three-dimensional displays;Animation;Speech;Artificial neural networks;Training","augmented reality;computer animation;electromyography;feature extraction;medical robotics;medical signal processing;neural nets;signal denoising;speech;speech recognition;time-frequency analysis","speech control;3D animation;augmented robotic hand;artificial neural network;tansig;softmax transfer function;hidden layer;output layer;stream processing;input signal processing;frequency-domain features;time-domain features;EMG analysis;noisy environment;training data set;offline speech recognition;online real time speech recognition;recognition accuracy","","3","","14","","6 Feb 2017","","","IEEE","IEEE Conferences"
"An integrated surgical planning and virtual training system using a force feedback haptic device for dental implant surgery","C. Xiaojun; L. Yanping; W. Chengtao; W. Yiqun; W. Xudong; S. Guofang","Institute of Biomedical Manufacturing and Life Quality Engineering, State Key Lab of Mechanical System and Vibration, School of Mechanical Engineering, Shanghai Jiao Tong University; Institute of Biomedical Manufacturing and Life Quality Engineering, State Key Lab of Mechanical System and Vibration, School of Mechanical Engineering, Shanghai Jiao Tong University; Institute of Biomedical Manufacturing and Life Quality Engineering, State Key Lab of Mechanical System and Vibration, School of Mechanical Engineering, Shanghai Jiao Tong University; Shanghai Ninth People's Hospital, Shanghai Jiao Tong University School of Medicine; Shanghai Ninth People's Hospital, Shanghai Jiao Tong University School of Medicine; Shanghai Ninth People's Hospital, Shanghai Jiao Tong University School of Medicine","2010 International Conference on Audio, Language and Image Processing","10 Jan 2011","2010","","","1257","1261","The application of dental implants proposes a successful treatment both partially and fully edentulous patients. However, the placement of implants is not without risk due to anatomically complex operation sites in the cranio-maxillofacial region. Therefore, in the field of oral implantology, there is a trend towards computer-aided implant surgery. In this study, an integrated surgical planning and virtual training system is presented. With the introduction of DLL (Dynamic Link Libraries) and some well-known free, open source software libraries such as VTK, ITK, and QT, a modular software named CAPPOIS (Computer Assisted Preoperative Planning for Oral Implant Surgery) was developed for preoperative planning, including medical image importing, image segmentation and 3D-Reconstruction, 2D/3D geometrical measurements, optimization design of the position and orientation of oral implants, etc. Then, the following virtual surgical training system is developed based on the force feedback haptic device, i.e., Omega.3, and the software toolkit of CHAI3D. With the use of this system, the resulting data of the preoperative planning can be transferred, and surgical simulation of the plan can be vividly realized. In this way, the surgeon can grasp the feel of osteotomy procedure, gain experience and therefore improve his skills during the actual dental implant surgery. This pilot study proves helpful for the inexperienced surgeons; however, more clinical cases will be conducted to demonstrate its feasibility and reliability.","","978-1-4244-5858-5","10.1109/ICALIP.2010.5685115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5685115","","Surgery;Implants;Solid modeling;Planning;Three dimensional displays;Training;Software","dentistry;force feedback;haptic interfaces;medical computing;prosthetics;software libraries","integrated surgical planning;virtual training system;force feedback haptic device;dental implant surgery;cranio-maxillofacial region;oral implantology;computer-aided implant surgery;DLL;dynamic link libraries;open source software libraries;VTK;ITK;QT;CAPPOIS;computer assisted preoperative planning;oral implant surgery;osteotomy procedure","","7","","12","","10 Jan 2011","","","IEEE","IEEE Conferences"
"Virtual Laboratories in Biotechnology are Significant Educational Informatics Tools","R. Radhamani; A. Divakar; A. A. Nair; A. Sivadas; G. Mohan; N. Nizar; B. Nair; K. Achuthan; S. Diwakar","Amrita Vishwa Vidyapeetham, School of Biotechnology, Amritapuri campus, Clappana P.O., Kollam, Kerala, 690 525, India; Amrita Vishwa Vidyapeetham, School of Biotechnology, Amritapuri campus, Clappana P.O., Kollam, Kerala, 690 525, India; Amrita Vishwa Vidyapeetham, School of Biotechnology, Amritapuri campus, Clappana P.O., Kollam, Kerala, 690 525, India; Amrita Vishwa Vidyapeetham, School of Biotechnology, Amritapuri campus, Clappana P.O., Kollam, Kerala, 690 525, India; Amrita Vishwa Vidyapeetham, School of Biotechnology, Amritapuri campus, Clappana P.O., Kollam, Kerala, 690 525, India; Amrita Vishwa Vidyapeetham, School of Biotechnology, Amritapuri campus, Clappana P.O., Kollam, Kerala, 690 525, India; Amrita Vishwa Vidyapeetham, School of Biotechnology, Amritapuri campus, Clappana P.O., Kollam, Kerala, 690 525, India; Amrita Vishwa Vidyapeetham, Center for Cybersecurity Systems and Networks, Amritapuri campus, Clappana P.O., Kollam, Kerala, 690 525, India; Amrita Vishwa Vidyapeetham, School of Biotechnology, Amritapuri campus, Clappana P.O., Kollam, Kerala, 690 525, India","2018 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","2 Dec 2018","2018","","","1547","1551","With recent advances in information and communication technologies (ICT), visual perception of knowledge has been crucial in education system. In developing nations, such as India, Government has added initiatives for improving the quality of education, by providing computer-based education to geographically constrained and economically challenged areas, at a minimal cost. For augmenting laboratory training, a national mission project, Virtual laboratories, was launched by India's Ministry of Human Resource Development (MHRD)'s National Mission on Education through Information and Communication Technology (NME-ICT). Through user-interactive animations, mathematical simulations and remote experiments, over 360+ experiments for more than 30 topics, web-based labs were developed and deployed in science and engineering discipline for usage by student-teacher communities. Using pedagogical aspects, this paper reviews the impact of virtual laboratories as an adaptive learning tool and its role in knowledge transfer in a blended classroom environment using cell biology and molecular biology virtual tools. Studies indicate the use of ICT-based virtual lab repository in complementing laboratory skillset and as teaching tools for disseminating online education via Massive Open Online Courses (MOOCs).","","978-1-5386-5314-2","10.1109/ICACCI.2018.8554596","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8554596","virtual laboratories;knowledge transfer;blended learning;skill training;online platform","","biotechnology;computer aided instruction;educational courses;Internet;laboratories;teaching","virtual laboratories;education system;computer-based education;economically challenged areas;national mission project;NME-ICT;user-interactive animations;adaptive learning tool;molecular biology virtual tools;ICT-based virtual lab repository;teaching tools;online education;laboratory training;India;Ministry of Human Resource Development;National Mission on Education through Information and Communication Technology;educational informatics tools;Web-based labs;knowledge transfer;cell biology;massive open online courses;MOOCs","","1","","31","","2 Dec 2018","","","IEEE","IEEE Conferences"
"Multi-User Hybrid Beamforming System Based on Deep Neural Network in Millimeter-Wave Communication","L. Sung; D. Cho","Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea","IEEE Access","22 May 2020","2020","8","","91616","91623","Millimeter-wave (mmWave) communication with a large bandwidth can result in a significantly improved data rate in wireless communications. To overcome high path-loss in the mmWave frequency band, beamforming technology is necessary. Especially, there has been widespread interest in development of hybrid beamforming (HB) technologies, in view of reducing cost and power consumption in massive multiple input multiple output (MIMO) systems. Some of existing researches on HB algorithms assumed perfect channel state information (CSI) and the others used beam training process in case of assuming imperfect CSI. When beam training process is used, enough beam training has to be conducted to achieve sufficient system performance in massive MIMO systems, which results in significant training overhead. Thus, it is necessary to reduce beam training complexity. Compared to state-of-the-art technology, we propose a multi-user HB system using codebooks based on a deep neural network (DNN) in this paper. In our proposed scheme, beam codewords for the base station (BS) and all users can be inferred using limited beam training in cases when the channel state information (CSI) is unknown. In order to apply the proposed scheme to situations where the CSI is unknown, reference radio frequency (RF) beamformers were introduced. Also, the proposed DNN structure is designed considering introduced reference RF beamformers. By using the proposed DNN with reference RF beamformers, the proposed system can inferred optimal beam codewords with limited beam training. Results obtained from simulations indicate that the proposed scheme can achieve almost the same performance as a conventional scheme with less beam training complexity. We also show that the performances achieved by the proposed scheme are gradually increased as training epoch is increased, eventually converging to a steady-state value.","2169-3536","","10.1109/ACCESS.2020.2990317","BK21 PLUS and Institute for Information and Communications Technology Promotion (IITP) Grant; Korean Government (MSIT), Development of Simultaneous Wireless Information and Power Transfer System Using Same Resource Based on Multiple Antennas; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9078064","Hybrid beamforming;deep neural network;limited feedback beamforming;mmWave communication","Training;Array signal processing;Radio frequency;Antenna arrays;Millimeter wave communication;Discrete Fourier transforms;Antenna radiation patterns","array signal processing;communication complexity;learning (artificial intelligence);millimetre wave communication;network coding;neural nets;telecommunication computing;wireless channels","deep neural network;base station;optimal beam codewords;beam training complexity;millimeter-wave communication;wireless communications;mmWave frequency band;hybrid beamforming technologies;massive multiple input multiple output systems;perfect channel state information;beam training process;imperfect CSI;massive MIMO systems;radiofrequency beamformers;DNN;BS;HB technologies;RF beamformers","","","","25","CCBY","24 Apr 2020","","","IEEE","IEEE Journals"
"Deep UL2DL: Data-Driven Channel Knowledge Transfer From Uplink to Downlink","M. S. Safari; V. Pourahmadi; S. Sodagari","Electrical Engineering Department, Amirkabir University of Technology, Tehran, Iran; Electrical Engineering Department, Amirkabir University of Technology, Tehran, Iran; Electrical Engineering Department, California State University, Long Beach, CA, USA","IEEE Open Journal of Vehicular Technology","22 Jan 2020","2020","1","","29","44","To remove the need for signaling overhead of feedback channels for transmitter channel state information (CSI) in Frequency Division Duplexing (FDD), we propose using convolutional neural networks and generative adversarial networks (GANs) to infer the downlink (DL) CSI by observing the uplink (UL) CSI. Our data-driven scheme exploits the fact that both DL and UL channels share the same propagation environment. As such, we extracted the environment information from UL channel response to a latent domain and then transferred the derived environment information from the latent domain to predict the DL channel. To prevent incorrect latent domain and the problem of oversimplistic assumptions, we did not use any specific parametric model and, instead, used data-driven approaches to discover the underlying structure of data without any prior model assumptions. To overcome the challenge of capturing the UL-DL joint distribution, we used a mean square error-based variant of the GAN structure with improved convergence properties called boundary equilibrium GAN. For training and testing we used simulated data of Extended Vehicular-A (EVA) and Extended Typical Urban (ETU) models. Simulation results verified that our methods can accurately infer and predict the downlink CSI from the uplink CSI for different multipath environments.","2644-1330","","10.1109/OJVT.2019.2962631","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944056","Channel Prediction;Convolutional Neural Networks;Deep Learning;Downlink;FDD Systems;Generative Adversarial Networks;Uplink","Generative adversarial networks;Transmitters;Covariance matrices;Training;Uplink;Downlink;Convolutional neural networks","convolutional neural nets;learning (artificial intelligence);mean square error methods;radiowave propagation;telecommunication computing;vehicular ad hoc networks;wireless channels","ETU models;extended typical urban models;EVA models;extended vehicular-A models;FDD;DL channel response;data-driven approaches;boundary equilibrium GAN structure;deep UL2DL;generative adversarial networks;convolutional neural networks;frequency division duplexing;transmitter channel state information;feedback channels;data-driven channel knowledge transfer;multipath environments;uplink CSI;downlink CSI;mean square error-based variant;UL-DL joint distribution;UL channel response;propagation environment","","4","","33","CCBY","27 Dec 2019","","","IEEE","IEEE Journals"
"A neural-net based fuzzy admission controller for an ATM network","Ray-Guang Cheng; Chung-Ju Chang","Dept. of Commun. Eng., Nat. Chiao Tung Univ., Hsinchu, Taiwan; Dept. of Commun. Eng., Nat. Chiao Tung Univ., Hsinchu, Taiwan","Proceedings of IEEE INFOCOM '96. Conference on Computer Communications","6 Aug 2002","1996","2","","777","784 vol.2","This paper proposes a neural fuzzy connection admission control (NFCAC) scheme, which combines benefits of fuzzy logic controller and learning abilities of the neural-net, to solve the connection admission control (CAC) problems in ATM networks. Fuzzy logic systems have been successfully applied to deal with the traffic control related problems and provided a robust mathematical framework for dealing with ""real-world"" imprecision; multilayer neural networks are capable of producing complex decisions with arbitrarily nonlinear boundaries and they have been used as a solution for CAC. However, the application of a neural network or a fuzzy logic system to CAC presents some difficulties in a real system operation. The proposed NFCAC solves the difficulties by combining the benefits of the existing traffic control mechanisms, linguistic control strategy of the fuzzy logic controller and the learning ability of the neural net. Simulation results show that the proposed NFCAC saves a large amount of training time and simplifies the design procedure of a CAC controller but provides a superior system utilization, while keeping the QoS contract, than either the neural network or fuzzy logic system does.","0743-166X","0-8186-7293-5","10.1109/INFCOM.1996.493375","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=493375","","Fuzzy control;Fuzzy neural networks;Traffic control;Fuzzy logic;Asynchronous transfer mode;Communication system traffic control;Neural networks;Control systems;Quality of service;Communication system control","asynchronous transfer mode;telecommunication congestion control;telecommunication networks;telecommunication computing;fuzzy neural nets;multilayer perceptrons;fuzzy logic;telecommunication traffic","fuzzy admission controller;fuzzy logic systems;neural fuzzy connection admission control;fuzzy logic controller;learning abilities;connection admission control;ATM networks;traffic control;multilayer neural networks;nonlinear boundaries;traffic control mechanisms;linguistic control strategy;simulation results;training time;design procedure;CAC controller;system utilization;QoS contract","","9","","17","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Skill generalization relevant to robotic neuro-rehabilitation","D. Bansal; R. Kenyon; J. L. Patton","University of Illinois-Chicago, USA; University of Illinois-Chicago, USA; University of Illinois-Chicago, USA","2010 Annual International Conference of the IEEE Engineering in Medicine and Biology","11 Nov 2010","2010","","","2250","2254","Upper limb extremity rehabilitation practices are increasingly involving robotic interaction for repetitive practice, and there is increasing skepticism whether such systems can provide the relevant practice that can be generalized (or transferred) to functional activities in the real world. Most importantly, will patients be able to generalize in three critical ways: (1) to unpracticed directions, (2) to unpracticed movement distances, and (3) to unpracticed weight-eliminated conditions? Rather than presuming that patients could generalize in three conditions, this study tested whether there was any evidence of such generalization ability in healthy individuals. We found that there was some evidence in all conditions except for the ability of healthy subjects to generalize to large movements after practicing small. Such results suggest that larger robotic systems are advantageous for training the functional motions that can include large actions.","1558-4615","978-1-4244-4123-5","10.1109/IEMBS.2010.5627308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5627308","","Training;Gravity;Visualization;Virtual reality;Performance evaluation;Robot sensing systems","medical robotics;neurophysiology;patient rehabilitation;robot kinematics;virtual reality","skill generalization;robotic neuro-rehabilitation;upper limb extremity rehabilitation;robotic interaction;repetitive practice;unpracticed directions;unpracticed movement distances;unpracticed weight-eliminated condition","Activities of Daily Living;Adult;Algorithms;Arm Injuries;Equipment Design;Female;Humans;Male;Motor Activity;Movement;Movement Disorders;Nervous System;Robotics;Upper Extremity","","","19","","11 Nov 2010","","","IEEE","IEEE Conferences"
"Virtual Multi-Interaction for Rehabilitation Robotics","W. Li; A. Rovetta; X. Ding; L. Chen; Y. Han","Beijing Microelectron. Technol. Inst., Beijing, China; School of Mechanical Engineering and Automation, Beihang University,Beijing, BJ,P.R.China,10086; School of Mechanical Engineering and Automation, Beihang University,Beijing, BJ,P.R.China,10086; Beijing Microelectronics Technology Institute,Beijing, BJ,P.R.China,10076; Beijing Microelectronics Technology Institute,Beijing, BJ,P.R.China,10076","2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM)","14 Sep 2020","2020","","","204","208","This article is to develop an intelligent exoskeleton to support the wearable, interactive and customizable path on the rehabilitation needs of falling foot. In collaboration with engineers and doctors from Milan and Beijing, it is to realize an active device that performs function adapting perfectly to the anatomical characteristics of each subject, and it would supply greater possibilities and flexibility. Traditional devices are passive rigid orthoses (AFO) and active peroneal stimulation systems (FES). Although simple and cheap, AFO system can bring about phenomena of adaptation at the central level that gradually decrease muscle activity over time. More is the stiffness in the path. FES devices ensure a more natural movement of the foot but without control autonomy. Moreover, the efficiency is always limited with high costs. According analysis of the path, anatomy and biomechanics of the calf, considering combination of sensing and interaction technologies and devices, it focuses on using MEMS inertial sensors and force sensors to make a fusion and measure state of the calf's motion and attitude. It also uses 3D printing to construct lightweight and customable structures. The mobile device is used as local center to transfer data and feedback with Bluetooth and Internet, to give instruction and detect emotion with voice. Virtual Reality is used to build training scenes combined with rehabilitation plan, connections and feedbacks are also built between vision and motion states to form closed loop control. It expounds system construction, virtual scene construction, control method design, system tests, etc. according rehabilitation application, and preliminary application data indicates that the whole system works well with low cost and high efficiency.","","978-1-7281-6479-3","10.1109/ICARM49381.2020.9195384","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195384","","Exoskeletons;Cloud computing;Servers;Robots;Software;Training;Control systems","biomechanics;Bluetooth;closed loop systems;feedback;force sensors;Internet;medical robotics;microsensors;muscle;neuromuscular stimulation;patient rehabilitation;virtual reality","system construction;closed loop control;motion states;virtual reality;mobile device;lightweight structures;force sensors;MEMS inertial sensors;biomechanics;FES devices;muscle activity;central level;active peroneal stimulation systems;passive rigid orthoses;anatomical characteristics;intelligent exoskeleton;rehabilitation robotics;virtual multiinteraction;rehabilitation application;control method design;virtual scene construction","","","","13","","14 Sep 2020","","","IEEE","IEEE Conferences"
"Remote teaching via ISDN2 and desktop conferencing","N. Davis","Sch. of Educ., Exeter Univ., UK","IEE Colloquium on Educational and Training Applications of ISDN (Integrated Services Digital Network) (Digest no.1993/162)","6 Aug 2002","1993","","","4/1","4/3","The Desktop Conferencing project is based at Exeter University School of Education using International Computers Limited (ICL) and Fujitsu desktop conferencing systems linked with British Telecom's integrated services digital network (ISDN2) lines. The systems are set up in three locations: the University and two schools. The project is being used to enhance teaching and learning between university staff, student teachers, school pupils and school teachers. Consultants have also participated in education-industry links through desktop conferencing. Desktop conferencing uses a pair of telephone lines to link participants at either end, sharing both voice and computer systems. Teacher and student can run the same software together, see the same screen, discuss it and even key in changes. In addition a flipchart facility is available and files can be transferred extremely quickly. The author presents case studies which are drawn from group work, business studies and science.<>","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=230860","","Computer aided instruction;Collaborative work;ISDN;Multimedia systems;Teleconferencing","computer aided instruction;groupware;ISDN;multimedia systems;teleconferencing","ISDN;voice systems;multimedia communication;remote teaching;ISDN2;Exeter University School of Education;International Computers Limited;ICL;Fujitsu;desktop conferencing systems;integrated services digital network;schools;teaching;learning;university staff;student teachers;school pupils;school teachers;education-industry links;telephone lines;computer systems;flipchart facility;case studies;group work;business studies;science","","","13","","","6 Aug 2002","","","IET","IET Conferences"
"A robust RBF neural net Bayesian estimator for channel equalization","D. Khedim; A. Benyettou; M. Woolfson","Dept. of Comput. Sci., Univ. of Sci. & Technol. of Oran Mohamed Boudiaf, Algeria; Dept. of Comput. Sci., Univ. of Sci. & Technol. of Oran Mohamed Boudiaf, Algeria; NA","First International Symposium on Control, Communications and Signal Processing, 2004.","27 Sep 2004","2004","","","287","290","The characteristic (transfer function) of a dispersive M-ary channel equalizer designed through a Bayesian estimator, a performance indicator that is not trivial to obtain for M>2 due to intersymbol interference (ISI), is investigated. A set of curves is obtained and interpreted. Implementation through a radial basis function neural network is considered. It is shown that because network centers endure updating with different rates, the equalizer characteristic errates off the optimum, causing thus the symbol error rate and/or the training time to increase. A solution, based on incorporating an underlying symmetry in the channel response levels into the updating algorithm, brings the characteristic uniformly closer to the optimal one. It is also provided a strategy endowing the network with self-initializing. Simulation results are presented for a channel with sufficient ISI strength.","","0-7803-8379-6","10.1109/ISCCSP.2004.1296280","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1296280","","Robustness;Neural networks;Bayesian methods;Equalizers;Dispersion;Intersymbol interference;Additive noise;Delay estimation;Laboratories;Error analysis","radial basis function networks;belief networks;channel estimation;transfer functions;intersymbol interference;dispersive channels;telecommunication computing","RBF neural net Bayesian estimator;channel equalization;transfer function;M-ary channel equalizer;intersymbol interference;radial basis function neural network;channel response levels","","","","6","","27 Sep 2004","","","IEEE","IEEE Conferences"
"Implementation of data driven control system of DC motor by using system identification process","Y. Naung; A. Schagin; H. L. Oo; K. Z. Ye; Z. M. Khaing","Department of Automatic Control System and Control, National Research University of Electronic Technology, Zelenograd, Moscow, Russia; Department of Automatic Control System and Control, National Research University of Electronic Technology, Zelenograd, Moscow, Russia; Department of Automatic Control System and Control, National Research University of Electronic Technology, Zelenograd, Moscow, Russia; Department of Automatic Control System and Control, National Research University of Electronic Technology, Zelenograd, Moscow, Russia; Department of Automatic Control System and Control, National Research University of Electronic Technology, Zelenograd, Moscow, Russia","2018 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (EIConRus)","15 Mar 2018","2018","","","1801","1804","This paper presents data driven control system of DC motor by using system identification process. In this paper we use component base modeling similar to real DC motor by using simscape electronic systems for obtaining the input voltage and output speed of DC motor, the system identification toolbox and the nonlinear autoregressive with exogenous input (NARX) neural network for identification and obtaining the model of an object. The object model and training the neural network for data driven control system are developed by using MATLAB/SIMULINK platform. So, simulation results of this paper present the advantage of the suggested control method and the acceptable accuracy with respect to dynamic characteristics of the system.","","978-1-5386-4340-2","10.1109/EIConRus.2018.8317455","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8317455","data driven control system;system identification;(NARX) neural network;dc motor;pid controller;simscape electronic systems","DC motors;Mathematical model;System identification;Control systems;Transfer functions;Process control;Neural networks","autoregressive processes;control engineering computing;control system synthesis;DC motors;digital simulation;electric machine analysis computing;identification;machine control;neural nets;neurocontrollers","data driven control system;DC motor;system identification process;simscape electronic systems;system identification toolbox;nonlinear autoregressive with exogenous input neural network;NARX;MATLAB/SIMULINK platform","","7","","6","","15 Mar 2018","","","IEEE","IEEE Conferences"
"Clinical and neurophysiologic responses to recovery-oriented virtual rehabilitation of hand function in a person with subacute stroke: A case study","G. Fluet; J. Patel; A. Merians; Q. Qiu; M. Yarossi; S. Adamovich; E. Tunik; S. Massood","Department of Rehabilitation & Movement Sciences, Rutgers The State University of New Jersey, 65 Bergen St., Newark, NJ, USA; Department of Rehabilitation & Movement Sciences, Rutgers The State University of New Jersey, 65 Bergen St., Newark, NJ, USA; Department of Rehabilitation & Movement Sciences, Rutgers The State University of New Jersey, 65 Bergen St., Newark, NJ, USA; Department of Rehabilitation & Movement Sciences, Rutgers The State University of New Jersey, 65 Bergen St., Newark, NJ, USA; Department of Rehabilitation & Movement Sciences, Rutgers The State University of New Jersey, 65 Bergen St., Newark, NJ, USA; Department of Rehabilitation & Movement Sciences, Rutgers The State University of New Jersey, 65 Bergen St., Newark, NJ, USA; Department of Rehabilitation & Movement Sciences, Rutgers The State University of New Jersey, 65 Bergen St., Newark, NJ, USA; Acute Rehabilitation Unit, Saint Joseph's Wayne Hospital, 224 Hamburg Turnpike, Wayne NJ, USA","2015 International Conference on Virtual Rehabilitation (ICVR)","17 Dec 2015","2015","","","191","198","The need to quickly discharge patients following stroke from acute rehabilitation facilities to the home has resulted in an intense focus on restoring safe and independent, if not normal, motor function. Rehabilitation of hand function in patients with upper limb impairment is often de-prioritized to allow for an emphasis on practicing activities necessary for a safe discharge to the home, such as walking and bed mobility. This case study describes a patient with slow recovering hand motor function (hand sub-section of Fugl-Meyer examination score = 2 on post-stroke day 37) following a stroke. The patient received an intensive eight-session intervention that focused on the recovery of finger extension, finger individuation and pinch-grasp force modulation as well as the recovery of proximal upper extremity movement. Over the eight sessions, the patient demonstrated a dramatic increase in hand function and a corresponding expansion of the cortical motor map area representing several key muscles of the paretic hand. Recovery of hand function and motor map expansion continued after discharge through the three-month retention testing. Gains in motor control transferred to clinically meaningful hand function measured at the activity level.","2331-9569","978-1-4799-8984-3","10.1109/ICVR.2015.7358570","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358570","virtual reality;robot;stroke;rehabilitation","Thumb;Training;Force;Solid modeling;Atmospheric measurements","diseases;gait analysis;medical disorders;neurophysiology;patient rehabilitation;virtual reality","neurophysiologic responses;recovery-oriented virtual rehabilitation;subacute stroke;upper limb impairment;walking;bed mobility;hand motor function recovery;finger extension recovery;pinch-grasp force modulation;proximal upper extremity movement recovery;cortical motor map area;muscles;paretic hand;three-month retention testing;time 37 day;time 3 month","","1","","40","","17 Dec 2015","","","IEEE","IEEE Conferences"
"Control of FES using reinforcement learning: accelerating the learning rate","A. Thrasher; B. Andrews; F. Wang","Biomed. Eng., Alberta Univ., Edmonton, Alta., Canada; NA; NA","Proceedings of the 19th Annual International Conference of the IEEE Engineering in Medicine and Biology Society. 'Magnificent Milestones and Emerging Opportunities in Medical Engineering' (Cat. No.97CH36136)","6 Aug 2002","1997","4","","1774","1776 vol.4","Prior knowledge can be used to accelerate the process of reinforcement learning. An adaptive fuzzy logic controller designed to control the swing phase of paraplegic gait was trained on a computer model using reinforcement learning. Instead of starting from scratch with generic fuzzy rules, the controller was jump-started in two different ways with experienced rules. First, supervised learning was used to initially train the controller, then two system parameters were altered and the reinforcement learning algorithm proceeded to find an optimal solution. This required a total of 34 simulation cycles. The same task, using reinforcement learning alone, required almost 150 cycles. Second, the trained controller was transferred to two individuals of differing body mass and height. It required less than 20 additional cycles to converge in both cases. By placing the controller initially closer to an optimal solution, jump-starting greatly reduces the number of simulation cycles required.","1094-687X","0-7803-4262-3","10.1109/IEMBS.1997.757070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=757070","","Acceleration;Control systems;Hip;Optimal control;Automatic control;Muscles;Knee;Supervised learning;Electrodes;Legged locomotion","fuzzy control;biocontrol;neuromuscular stimulation;adaptive control;learning (artificial intelligence);controllers;digital simulation;physiological models;biomechanics;bioelectric phenomena","FES control;learning rate acceleration;adaptive fuzzy logic controller;paraplegic gait swing phase control;body mass;height;optimal solution;simulation cycles;generic fuzzy rules;supervised learning;functional electrical stimulation;experienced rules;computer model;system parameters;reinforcement learning algorithm","","1","","9","","6 Aug 2002","","","IEEE","IEEE Conferences"
"ATM call admission control using neural networks","S. A. Youssef; I. W. Habib; T. N. Saadawi","City Coll. of New York, NY, USA; City Coll. of New York, NY, USA; City Coll. of New York, NY, USA","Proceedings of MILCOM '95","6 Aug 2002","1995","1","","1","5 vol.1","We propose a novel call admission control (CAC) algorithm for ATM networks using neural networks (NNs). The proposed algorithm employs neural networks to calculate the bandwidth required for heterogeneous multimedia traffic with multiple quality of service (QOS) requirements. The NN controller calculates the required bandwidth per call from online measurement of the traffic via its count process, instead of relying on simple parameters such as the peak and average bit rate and burst length. In order to simplify the design and obtain a small reaction time, the controller was realized using a hierarchical structure of a bank of small size, parallel NN units. Each unit is a feed forward backpropagation NN that has been trained to learn the complex nonlinear function that relates different traffic patterns and their required QOS with the corresponding bandwidth. A large set of training data that represents different traffic patterns with different QOS requirement has been used to ensure that the NN can generalize and produce accurate results when confronted with new test data. The reported results prove that the NN approach is extremely effective in achieving more accurate results than other traditional methods that are based upon mathematical or simulation approximations.","","0-7803-2489-7","10.1109/MILCOM.1995.483260","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=483260","","Call admission control;Neural networks;Quality of service;Bandwidth;Communication system traffic control;Length measurement;Bit rate;Size control;Feeds;Backpropagation","asynchronous transfer mode;switching networks;telecommunication networks;telecommunication congestion control;feedforward neural nets;backpropagation;telecommunication traffic;multimedia communication;telecommunication computing","parallel neural networks;ATM networks;call admission control algorithm;bandwidth;heterogeneous multimedia traffic;quality of service;QOS;neural network controller;online traffic measurement;count process;design;reaction time;hierarchical structure;feedforward neural network;backpropagation neural network;nonlinear function;traffic patterns;training data;test data","","2","","9","","6 Aug 2002","","","IEEE","IEEE Conferences"
"The Simulation Laboratory Platform Based on Multisim for Electronic Engineering Education","K. M. Noga; B. Palczynska","Department of Ship Automation, Gdynia Maritime University, Gdynia, Poland; Department of Marine Telecommunications, Gdynia Maritime University, Gdynia, Poland","2018 International Conference on Signals and Electronic Systems (ICSES)","25 Oct 2018","2018","","","269","274","This paper presents the simulation laboratory platform, including the advanced examples of the NI Multisim environment assigned for an electronic engineering education, a digital signal processing especially. A methodology of teaching of the digital signal processing for both electrical and electronic specializations requires the use a virtual platform, that creates a bridge between theoretical lectures in classes and practical application in the design, prototyping, and testing of electrical and electronic circuits in laboratories. In the article, exemplary solutions of the Multisim applications used in classes of the digital signal processing during the engineering courses at the Faculty of Electrical Engineering in Gdynia Maritime University are presented and discussed. The application of the presented teaching methodology gives excellent didactic results. It indicates that the experimental teaching based on development platforms such as the Multisim provides students with a comprehensive and creative approach to learning and knowledge transfer during the theoretical lectures. It is also a good training for work with real electrical and electronic systems.","2474-2465","978-1-5386-6768-2","10.1109/ICSES.2018.8507313","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8507313","digital signal processing;Multisim software;simulation","Education;Digital signal processing;Finite impulse response filters;IIR filters;Modulation;Analog-digital conversion;Digital-analog conversion","computer aided instruction;educational courses;educational institutions;electronic engineering computing;electronic engineering education;signal processing;student experiments;teaching","simulation laboratory platform;electronic engineering education;NI Multisim environment;electrical specializations;electronic specializations;virtual platform;theoretical lectures;electrical circuits;electronic circuits;laboratories;Multisim applications;engineering courses;presented teaching methodology;development platforms;electrical systems;electronic systems;Faculty of Electrical Engineering;digital signal processing teaching","","1","","24","","25 Oct 2018","","","IEEE","IEEE Conferences"
"Radial basis functions for bandwidth estimation in ATM networks using RBF neural network","S. A. Youssef; I. W. Habib; T. N. Saadawi","Dept. of Electr. Eng., City Coll. of New York, NY, USA; NA; NA","MILCOM 97 MILCOM 97 Proceedings","6 Aug 2002","1997","1","","493","497 vol.1","It is known that some types of variable bit rate (VBR) video traffic exhibit strong long term correlations and non-stationary behavior. Estimation of an accurate amount of bandwidth to support this traffic has been a challenging task using conventional algorithmic approaches. We show that radial basis function neural networks (RBFNN) are capable of learning the non-linear multi-dimensional mapping between different video traffic patterns, quality of service (QoS) requirements and the required bandwidth to support each call. In addition, the RBFNN model adopts to new traffic scenarios and still produces accurate results. This approach bypass the modeling approach which requires detailed knowledge about the traffic statistical patterns. Our method employs ""on-line"" measurements of the traffic count process over a monitoring period. In order to simplify the design of the RBFNN, the input traffic is preprocessed through a lowpass filter in order to smooth all high frequency fluctuations. A large set of training data, representing different traffic patterns with different QoS requirements, was used to ensure that the RBFNN can generalize and produce accurate results when confronted with new data. The reported results prove that the neurocomputing approach is effective in achieving more accurate results than other traditional methods, based upon mathematical or simulation analysis. This is primarily due to the fact that the unique learning and adaptive capabilities of NN enable them to extract and memorize rules from previous experience.","","0-7803-4249-6","10.1109/MILCOM.1997.648770","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=648770","","Bandwidth;Traffic control;Telecommunication traffic;Quality of service;Bit rate;Radial basis function networks;Monitoring;Data preprocessing;Filters;Frequency","asynchronous transfer mode;telecommunication networks;telecommunication computing;telecommunication traffic;feedforward neural nets;learning (artificial intelligence);adaptive systems;visual communication","bandwidth estimation;ATM networks;RBF neural network;variable bit rate;VBR video traffic;long term correlations;nonstationary behavior;radial basis function neural networks;nonlinear multi-dimensional mapping;video traffic patterns;quality of service;QoS requirements;RBFNN model;on-line measurements;traffic count process;input traffic;lowpass filter;training dat;HF fluctuations smoothing;neurocomputing approach;adaptive capabilities;rules","","","","4","","6 Aug 2002","","","IEEE","IEEE Conferences"
"A neurocomputing controller for bandwidth allocation in ATM networks","S. A. Youssef; I. W. Habib; T. N. Saadawi","Dept. of Electr. Eng., City Univ. of New York, NY, USA; NA; NA","IEEE Journal on Selected Areas in Communications","6 Aug 2002","1997","15","2","191","199","We propose a new neurocomputing call admission control (CAC) algorithm for asynchronous transfer mode (ATM) networks. The proposed algorithm employs neural networks (NNs) to calculate the bandwidth required to support multimedia traffic with multiple quality-of-service (QoS) requirements. The NN controller calculates the bandwidth required percall using on-line measurements of the traffic via its count process, instead of relying on simple parameters such as the peak, average bit rate and burst length. Furthermore, to enhance the statistical multiplexing gain, the controller calculates the gain obtained from multiplexing multiple streams of traffic supported on separate virtual paths (i.e., class multiplexing). In order to simplify the design and obtain a small reaction time, the controller is realized using a hierarchical structure of a bank of small size, parallel NN units. Each unit is a feed-forward back-propagation NN that has been trained to, learn the complex nonlinear function relating different traffic patterns and QoS, with the corresponding received capacity. The reported results prove that the neurocomputing approach is effective in achieving more accurate results than other conventional methods that are based upon mathematical or simulation analysis. This is primarily due to the unique learning and adaptive capabilities of NNs that enable them to extract and memorize rules from previous experience. Evidently such unique capabilities poise NNs to solve many of the problems encountered in the development of a coherent ATM traffic management strategy.","1558-0008","","10.1109/49.552069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=552069","","Channel allocation;Asynchronous transfer mode;Neural networks;Bandwidth;Communication system traffic control;Traffic control;Call admission control;Quality of service;Length measurement;Bit rate","asynchronous transfer mode;telecommunication network management;telecommunication computing;telecommunication congestion control;neurocontrollers;feedforward neural nets;backpropagation;telecommunication traffic;multimedia communication","bandwidth allocation;ATM networks;neurocomputing controller;call admission control algorithm;asynchronous transfer mode;neural networks;multimedia traffic;multiple quality of service;QoS requirement;online traffic measurements;count process;statistical multiplexing gain;virtual paths;traffic class multiplexing;reaction time;hierarchical structure;parallel neural network units;feedforward backpropagation neural network;complex nonlinear function;traffic patterns;received capacity;ATM traffic management","","21","","20","","6 Aug 2002","","","IEEE","IEEE Journals"
"Automatic Lung Cancer Prediction from Chest X-ray Images Using the Deep Learning Approach","W. Ausawalaithong; A. Thirach; S. Marukatat; T. Wilaiprasitporn","Kamnoetvidya Science Academy, Rayong, Thailand; Kamnoetvidya Science Academy, Rayong, Thailand; National Electronics and Computer Technology Center, Patumthani, Thailand; School of Information Science and Technology, Vidyasirimedhi Institute of Science and Technology, Rayong, Thailand","2018 11th Biomedical Engineering International Conference (BMEiCON)","13 Jan 2019","2018","","","1","5","Since, cancer is curable when diagnosed at an early stage, lung cancer screening plays an important role in preventive care. Although both low dose computed tomography (LDCT) and computed tomography (CT) scans provide greater medical information than normal chest x-rays, access to these technologies in rural areas is very limited. There is a recent trend toward using computer-aided diagnosis (CADx) to assist in the screening and diagnosis of cancer from biomedical images. In this study, the 121-layer convolutional neural network, also known as DenseNet-121 by G. Huang et. al., along with the transfer learning scheme is explored as a means of classifying lung cancer using chest x-ray images. The model was trained on a lung nodule dataset before training on the lung cancer dataset to alleviate the problem of using a small dataset. The proposed model yields 74.43±6.01% of mean accuracy, 74.96±9.85% of mean specificity, and 74.68±15.33% of mean sensitivity. The proposed model also provides a heatmap for identifying the location of the lung nodule. These findings are promising for further development of chest x-ray-based lung cancer diagnosis using the deep learning approach. Moreover, they solve the problem of a small dataset.","2334-3052","978-1-5386-5724-9","10.1109/BMEiCON.2018.8609997","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8609997","","Cancer;Lung;X-ray imaging;Training;Sensitivity;Computed tomography;Task analysis","cancer;computerised tomography;feature extraction;learning (artificial intelligence);lung;medical computing;medical image processing;neural nets;patient diagnosis;tumours","chest x-ray images;deep learning approach;lung cancer screening;preventive care;computed tomography;greater medical information;normal chest x-rays;rural areas;computer-aided diagnosis;biomedical images;121-layer convolutional neural network;DenseNet-121;transfer learning scheme;lung nodule dataset;lung cancer dataset;mean accuracy;mean specificity;mean sensitivity;chest x-ray-based lung cancer diagnosis;automatic lung cancer prediction","","3","","23","","13 Jan 2019","","","IEEE","IEEE Conferences"
"Developing Competence Assessment Procedure for Spinal Anaesthesia","D. Zhang; D. Albert; C. Hockemeyer; D. Breen; Z. Kulcsár; G. Shorten; A. Aboulafia; E. Lövquist","Graz Univ., Graz; Graz Univ., Graz; Graz Univ., Graz; NA; NA; NA; NA; NA","2008 21st IEEE International Symposium on Computer-Based Medical Systems","15 Jul 2008","2008","","","397","402","Traditional approaches of assessment in the medical domain are insufficient for evaluating trainees' technical skills. Currently, many European medical training bodies are attempting to introduce competence-based training programmes for technical skills as well as other domains (e.g., communication, professional behaviour, clinical cognition). These efforts are limited due to the absence of appropriate assessment tools. Based on Competence-based Knowledge Space Theory (CbKST), a collaborative project MedCAP intends to develop a valid and reliable competence assessment procedure for one important medical skill, spinal anaesthesia. The paper briefly overviews the current states of training and assessment for medical procedural skills, describes the core ideas of CbKST, and introduces the ongoing project that will transfer the innovative approach of CbKST in personalized learning and competence assessment to the medical domain.","1063-7125","978-0-7695-3165-6","10.1109/CBMS.2008.25","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4562024","competence assessment procedure;spinal anaesthesia","Hospitals;Fatigue;Needles;Cognition;Collaboration;Reliability theory;Medical simulation;Human factors;Spinal cord;Abdomen","biomedical education;computer aided instruction;medical computing","spinal anaesthesia;trainee technical skills;European medical training;competence-based training programmes;competence-based knowledge space theory;collaborative project MedCAP;reliable competence assessment procedure;CbKST","","3","","28","","15 Jul 2008","","","IEEE","IEEE Conferences"
"HC-130H GPS upgrade: a case study incorporating digital avionics into the cockpit","R. M. Palatka","2100 Second St SW, Washington, DC, USA","Proceedings of 14th Digital Avionics Systems Conference","6 Aug 2002","1995","","","239","244","When designed in the late 1970's, the avionics suite for the US Coast Guard's HC-130H fleet contained state of the art components. Although the rapid advancement of electronics technology soon surpassed that employed in some of these units, the suites remained highly functional and economically feasible into the late 1980's. A desire to improve joint operability between the various military services coupled with the opportunity to capitalize on the advanced characteristics of current avionics components combined to enhance the viability of the Coast Guard's wish to upgrade the capabilities of its fleet. The Coast Guard finalized the plans and designs which incorporated digital avionics into a suite which formerly contained only analog components. The nonrecurring engineering necessary to perform this integration included the design of several new subsystems to allow for the interface between existing components and the new digital data bus. This case study reviews the project which encompassed the specification, engineering, testing, prototyping, and fielding of this combined system. In addition, it shall also review the documentation, simulation, and training associated with a project of this scope.","","0-7803-3050-1","10.1109/DASC.1995.482834","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=482834","","Global Positioning System;Computer aided software engineering;Aerospace electronics;Satellite broadcasting;Aircraft navigation;Radio navigation;US Department of Defense;Government;Design engineering;FAA","helicopters;military avionics;Global Positioning System;aircraft displays;aerospace simulation;aircraft computers;aircraft control;aircraft navigation;computerised navigation;aircraft communication;military aircraft;telecommunication computing","HC-130H GPS upgrade;cockpit digital avionics;digital data bus;prototyping;combined system;documentation;simulation;training;US Coast Guard;installation project;control display navigation unit;interface shipset;military aircraft;data transfer module;testing;autopilot","","","","4","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Rate regulation with feedback controller in ATM networks-a neural network approach","Y. -. Liu; C. Douligeris","Dept. of Electr. & Comput. Eng., Miami Univ., Coral Gables, FL, USA; NA","IEEE Journal on Selected Areas in Communications","6 Aug 2002","1997","15","2","200","208","We propose the use of an artificial neural network (ANN) technique for a rate-based feedback controller in asynchronous transfer mode (ATM) networks. A leaky bucket (LB) mechanism is used for cell discarding, when the traffic violates a predefined threshold. Since the network cannot rely on the user's compliance with its declared parameters, it is extremely difficult to select the best threshold value and depletion rate for the LB. We propose an ANN model which monitors the status of the LB and predicts the possible cell discarding at the LB in the near future. The source rate is regulated to a certain amount depending on the feedback signal ""strength"" when possible cell discarding is detected. The lower the value carried in the feedback cell, the higher the possibility of cell discarding and, subsequently, the higher the probability that the traffic is regulated to a lower rate. Our model considers the propagation delay time of the feedback signal making our approach more realistic. This mechanism is transparent to the source if the LB is correctly set up and the traffic follows its declared parameters. We use the same trained ANN for different MPEG traces and the results of a simulation study suggest that our mechanisms provide simple and effective traffic management for ATM networks. Cell loss rate due to the congestion shows a two to five times improvement compared with the static approach, while transmission delays introduced by our ANN controller are also smaller than in the static approach. Channel utilization is also improved, showing that our mechanisms provides a better alternative to static feedback controllers.","1558-0008","","10.1109/49.552070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=552070","","Adaptive control;Intelligent networks;Neural networks;Traffic control;Asynchronous transfer mode;Communication system traffic control;Artificial neural networks;Switches;B-ISDN;Predictive models","asynchronous transfer mode;telecommunication congestion control;telecommunication computing;telecommunication traffic;controllers;delays;telecommunication network management;feedforward neural nets;backpropagation","feedback controller;rate regulation;ATM networks;ANN;artificial neural network;depletion rate;threshold value;ANN model;cell discarding;source rate;feedback signal strength;feedback cell;propagation delay time;traffic parameters;MPEG traces;simulation study;traffic management;cell loss rate;congestion;channel utilization;feedforward error backpropagation network","","31","5","23","","6 Aug 2002","","","IEEE","IEEE Journals"
"Comparison of neural models of UWB and 60GHz in-car transmission channels","M. Kotol; Z. Raida","Department of Radio Electronics, Brno University of Technology, Brno, Czech Republic; Department of Radio Electronics, Brno University of Technology, Brno, Czech Republic","2016 International Conference on Broadband Communications for Next Generation Networks and Multimedia Applications (CoBCom)","20 Oct 2016","2016","","","1","4","Knowledge of characteristics of the transmission channel is advantageous for the selection of a suitable location of transmitting and receiving antennas, choice of the carrier frequency and the transmission parameters such as bit rate, modulation type, coding, etc. However, the description of properties of the transmission channel can be computationally time consuming, and the computational complexity increases with the increasing frequency. The transmission channel can be modeled by an artificial neural network to reduce the computational complexity compared to the analysis using full-wave simulation programs (CST, HFSS, etc.). Two neural network architectures were selected (a feed-forward one and a radial basis function one) to model an in-car transmission channel. For each neural model, a study of the model error, the speed of training and the network complexity is given.","","978-1-5090-2270-0","10.1109/COBCOM.2016.7593493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7593493","Artificial neural network;feed-forward network;radial basis function network;transmission channel measurement;estimation of in-car channel parameters;transfer function","Antenna measurements;Artificial neural networks;Frequency measurement;Training;Transmitting antennas;Automobiles;Frequency response","computational complexity;millimetre wave antennas;neural nets;on-board communications;receiving antennas;telecommunication computing;transmitting antennas;ultra wideband communication;wireless channels","computational complexity reduction;artificial neural network;computational complexity;transmitting antenna location selection;receiving antenna location selection;in-car transmission channel;UWB neural model;frequency 60 GHz","","1","","6","","20 Oct 2016","","","IEEE","IEEE Conferences"
"Shape Localization and Recognition Using a Magnetorheological-Fluid Haptic Display","R. Rizzo; A. Musolino; L. A. Jones","Department of Engineering for Energy and Systems, University of Pisa, Pisa, Italy; Department of Engineering for Energy and Systems, University of Pisa, Pisa, Italy; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA","IEEE Transactions on Haptics","18 Jun 2018","2018","11","2","317","321","Smart materials such as magnetorheological fluids (MRF) offer an interesting technology for use in haptic displays as changes in the magnetic field are rapid, reversible, and controllable. These interfaces have been evaluated in a number of medical and surgical simulators where they can provide cues regarding the viscoelastic properties of tissues. The objective of the present set of experiments was first to determine whether a shape embedded in the MRF could be precisely localized and second whether 10 shapes rendered in a MRF haptic display could be accurately identified. It was also of interest to determine how the information transfer associated with this type of haptic display compares to that achieved using other haptic channels of communication. The overall performance of participants at identifying the shapes rendered in the MRF was good with a mean score of 73 percent correct and an Information Transfer (IT) of 2.2 bits. Participants could also localize a rigid object in the display accurately. These findings indicate that this technology has potential for use in training manual palpation skills and in exploring haptic shape perception in dynamic environments.","2329-4051","","10.1109/TOH.2017.2771420","Università di Pisa; US National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8101013","Touch-based properties and capabilities of the human user;hardware and software that enable touch-based interactions with real;remote;and virtual environments;tactile communication","Haptic interfaces;Shape;Fluids;Coils;Magnetic fields;Surgery;Actuators","biological tissues;haptic interfaces;magnetic fluids;magnetorheology;medical computing;shape recognition;viscoelasticity","manual palpation skills training;haptic channels;tissues viscoelastic properties;shape recognition;MRF haptic display;surgical simulators;medical simulators;magnetic field;magnetorheological fluids;smart materials;magnetorheological-fluid haptic display;shape localization;haptic shape perception;information transfer","Adult;Electromagnetic Phenomena;Electronics, Medical;Female;Form Perception;Humans;Male;Touch Perception;User-Computer Interface;Young Adult","2","","36","","9 Nov 2017","","","IEEE","IEEE Journals"
"Deep Learning-Based End-to-End Wireless Communication Systems With Conditional GANs as Unknown Channels","H. Ye; L. Liang; G. Y. Li; B. Juang","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Transactions on Wireless Communications","8 May 2020","2020","19","5","3133","3143","In this article, we develop an end-to-end wireless communication system using deep neural networks (DNNs), where DNNs are employed to perform several key functions, including encoding, decoding, modulation, and demodulation. However, an accurate estimation of instantaneous channel transfer function, i.e., channel state information (CSI), is needed in order for the transmitter DNN to learn to optimize the receiver gain in decoding. This is very much a challenge since CSI varies with time and location in wireless communications and is hard to obtain when designing transceivers. We propose to use a conditional generative adversarial net (GAN) to represent channel effects and to bridge the transmitter DNN and the receiver DNN so that the gradient of the transmitter DNN can be back-propagated from the receiver DNN. In particular, a conditional GAN is employed to model the channel effects in a data-driven way, where the received signal corresponding to the pilot symbols is added as a part of the conditioning information of the GAN. To address the curse of dimensionality when the transmit symbol sequence is long, convolutional layers are utilized. From the simulation results, the proposed method is effective on additive white Gaussian noise (AWGN) channels, Rayleigh fading channels, and frequency-selective channels, which opens a new door for building data-driven DNNs for end-to-end communication systems.","1558-2248","","10.1109/TWC.2020.2970707","Intel Corporation; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8985539","Channel GAN;CNN;end-to-end communication system;channel coding","Gallium nitride;Transmitters;Receivers;Wireless communication;Training;Maximum likelihood decoding","AWGN channels;channel estimation;error statistics;learning (artificial intelligence);neural nets;radio transceivers;Rayleigh channels;telecommunication computing;transfer functions","convolutional layers;AWGN channels;end-to-end wireless communication systems;conditional generative adversarial net;decoding;receiver gain;CSI;channel state information;instantaneous channel transfer function;key functions;deep neural networks;unknown channels;deep learning;data-driven DNNs;frequency-selective channels;Rayleigh fading channels;additive white Gaussian noise channels;conditioning information;received signal;channel effects;conditional GAN;receiver DNN;transmitter DNN","","9","","38","CCBY","6 Feb 2020","","","IEEE","IEEE Journals"
"Tractor Assistant Driving Control Method Based on EEG Combined With RNN-TL Deep Learning Algorithm","W. Lu; Y. Wei; J. Yuan; Y. Deng; A. Song","College of Engineering, Nanjing Agricultural University, Nanjing, China; College of Engineering, Nanjing Agricultural University, Nanjing, China; School of Education Science, Nanjing Normal University, Nanjing, China; College of Engineering, Michigan State University, East Lansing, MI, USA; School of Instrument Science and Engineering, Southeast University, Nanjing, China","IEEE Access","16 Sep 2020","2020","8","","163269","163279","Nowadays, fieldwork is often accompanied by tight schedules, which tends to strain the shoulder muscles due to high-intensity work. Moreover, it is difficult and stressful for the disabled to drive agricultural machinery. Besides, current artificial intelligence technology could not fully realize tractor autonomous driving because of a high uncertain filed environment and short interruptions of satellite navigation signal shaded by trees. To reduce manual operations, a tractor assistant driving control method was proposed based on the human-machine interface utilizing the electroencephalographic (EEG) signal. First, the EEG signals of the tractor drivers were collected by a low-cost brain-computer interface (BCI), followed by denoising using a wavelet packet. Then the spectral features of EEG signals were calculated and extracted as the input of Recurrent Neural Network (RNN). Finally, the EEG-aided RNN driving model was trained for tractor driving robot control such as straight going, brake, left turn, and right turn operations, which control accuracy was 94.5% and time cost was 0.61 ms. Also, 8 electrodes were selected by the PCA algorithm for the design of a portable EEG controller. And the control accuracy reached 93.1% with the time cost of 0.48 ms. To solve the incomplete driving data set in the actual world because some driving manners may cause dangerous or even death, RNN-TL algorithm was employed by creating the complete driving data in the virtual environment followed by transferring the driving control experience to the actual world with small actual driving data set in the field, which control accuracy was 93.5% and time consumption was 0.48 ms. The experimental results showed the feasibility of the proposed tractor driving control method based on EEG signal combined with RNN-TL deep learning algorithm which can work with the displacement error less than 6.7 mm when the tractor speed is less than 50 km/h.","2169-3536","","10.1109/ACCESS.2020.3021051","National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; Three New Agricultural Project in Jiangsu Province; Asia Hub NAU-MSU Joint Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186275","Electroencephalographic (EEG);brain-computer interface (BCI);recurrent neural network (RNN);assistant driving;driving robot","Agricultural machinery;Electroencephalography;Wavelet transforms;Feature extraction;Brain-computer interfaces;Manipulators","agricultural machinery;brain-computer interfaces;control engineering computing;electroencephalography;learning (artificial intelligence);mobile robots;principal component analysis;recurrent neural nets;signal processing;virtual reality","EEG-aided RNN driving model;recurrent neural network;virtual environment;tractor speed;tractor driving control method;driving control experience;RNN-TL algorithm;driving manners;driving data;portable EEG controller;PCA algorithm;robot control;RNN driving model;low-cost brain-computer interface;tractor drivers;EEG signal;electroencephalographic signal;human-machine interface;satellite navigation signal;tractor autonomous driving;artificial intelligence technology;agricultural machinery;high-intensity work;RNN-TL deep learning algorithm;tractor assistant driving control method","","","","41","CCBY","3 Sep 2020","","","IEEE","IEEE Journals"
"A Deep Learning-Based Approach to Power Minimization in Multi-Carrier NOMA With SWIPT","J. Luo; J. Tang; D. K. C. So; G. Chen; K. Cumanan; J. A. Chambers","School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electrical and Electronic Engineering, The University of Manchester, Manchester, U.K.; Department of Engineering, University of Leicester, Leicester, U.K.; Department of Electronic Engineering, University of York, York, U.K.; Department of Engineering, University of Leicester, Leicester, U.K.","IEEE Access","14 Feb 2019","2019","7","","17450","17460","Simultaneous wireless information and power transfer (SWIPT) and multi-carrier non-orthogonal multiple access (MC-NOMA) are promising technologies for future fifth generation and beyond wireless networks due to their potential capabilities in energy-efficient and spectrum-efficient system designs, respectively. In this paper, the joint downlink resource allocation problem for a SWIPT-enabled MC-NOMA system with time switching-based receivers is investigated, where pattern division multiple access (PDMA) technique is employed. We focus on minimizing the total transmit power of the system while satisfying the quality-of-service requirements of each user in terms of data rate and harvested power. The corresponding optimization problem is a non-convex and a mixed integer programming problem which is difficult to solve. Different from the conventional iterative searching-based algorithms, we propose an efficient deep learning-based approach to determine an approximated optimal solution. Specifically, we employ a typical class of deep learning model, namely, deep belief network (DBN), where the detailed procedure of the developed approach consists of three parts, i.e., data preparation, training, and running. The simulation results demonstrate that the proposed DBN-based approach can achieve similar performance of power consumption to the exhaustive search method. Furthermore, the results also confirm that MC-NOMA with PDMA outperforms MC-NOMA with sparse code multiple access, single-carrier non-orthogonal multiple access, and orthogonal frequency division multiple access in terms of power consumption in SWIPT-enabled systems.","2169-3536","","10.1109/ACCESS.2019.2895201","National Natural Science Foundation of China; Natural Science Foundation of Guangdong Province; Guangzhou Science, Technology and Innovation Commission; Southeast University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8626195","Non-orthogonal multiple access (NOMA);simultaneous wireless information and power transfer (SWIPT);machine learning","NOMA;Resource management;Receivers;Wireless networks;Minimization;5G mobile communication","5G mobile communication;code division multiple access;concave programming;energy conservation;frequency division multiple access;integer programming;iterative methods;learning (artificial intelligence);OFDM modulation;quality of service;radio receivers;radiofrequency power transmission;resource allocation;search problems;telecommunication computing;telecommunication power management","quality-of-service requirements;mixed integer programming problem;conventional iterative searching-based algorithms;total transmit power minimization;optimization problem;nonconvex programming problem;energy-efficient system design;beyond wireless networks;spectrum-efficient system design;simultaneous wireless information-and-power transfer;exhaustive search method;data training;data running;pattern division multiple access technique;time switching-based receivers;SWIPT-enabled MC-NOMA system;joint downlink resource allocation problem;potential capabilities;future fifth generation;multicarrier NOMA;power minimization;orthogonal frequency division multiple access;single-carrier nonorthogonal multiple access;sparse code multiple access;PDMA;power consumption;DBN-based approach;deep belief network;deep learning model","","22","","36","","25 Jan 2019","","","IEEE","IEEE Journals"
"Artificial Neural Network and Mobile Applications in Medical Diagnosis","G. Pearce; J. Wong; L. Mirtskhulava; S. Al-Majeed; K. Bakuria; N. Gulua","Sch. of Eng. & Appl. Sci., Aston Univ., Birmingham, UK; Dept. of Cardiac, Thoracic & Vascular Surg., Nat. Univ. Heart Centre, Singapore, Singapore; Dept. of Comput. Sci., Iv. Javakhishvili Tbilisi State Univ., Tbilisi, Georgia; Syst. Eng. Dept., Mil. Technol. Coll., Muscat, Oman; Dept. of Inf. Technol., Georgian Tech. Univ., Tbilisi, Georgia; Fac. of Math. & Comput. Sci., Sokhumi State Univ., Tbilisi, Georgia","2015 17th UKSim-AMSS International Conference on Modelling and Simulation (UKSim)","26 Sep 2016","2015","","","61","64","The aim of this paper is to present a pilot study regarding the application of an ANN to stroke recognition and diagnosis. Our system makes use of a (i) a neural network that can be trained to recognize normal limb movements (for individual patients), which may then be coupled to (ii) a physical grid mattress that can be used in the patient's home. Any changes in the patient's movement could potentially indicate that stroke has occurred are transmitted to a mobile phone app. The latter in turn alerts a relative or ambulance to render rapid assistance to the individual. When stroke has occurred it is essential to transfer the patient to hospital very quickly in order that treatment can be given promptly. In the case of strokes that have arisen due to a blood clot in the cerebral circulation of the brain, a drug called Alteplase (an anti-thrombolytic) must be given within 4.5 hours of the stroke occurring to be maximally effective. Therefore it is important to know the exact time on stroke onset. Our system would record the time of onset of the stroke, by recognizing and recording abnormal changes in the individual's limb movements. A Feed forward neural network was used in our modeling.","","978-1-4799-8713-9","10.1109/UKSim.2015.34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7576522","artificial network model; stroke; soft sensors; mobile telemedicine systems","Computational modeling;Mathematical model;Computer science;Surgery;Information technology","feedforward neural nets;medical computing;mobile computing;patient diagnosis","artificial neural network;ANN;mobile phone application;medical diagnosis;limb movement recognition;feedforward neural network","","7","","12","","26 Sep 2016","","","IEEE","IEEE Conferences"
"ATM: Automated Trust Management for Mobile Ad Hoc Networks Using Support Vector Machine","W. Li; A. Joshi; T. Finin","Dept. of Comput. Sci. & Electr. Eng., Univ. of Maryland, Baltimore, MD, USA; Dept. of Comput. Sci. & Electr. Eng., Univ. of Maryland, Baltimore, MD, USA; Dept. of Comput. Sci. & Electr. Eng., Univ. of Maryland, Baltimore, MD, USA","2011 IEEE 12th International Conference on Mobile Data Management","3 Nov 2011","2011","1","","291","292","Mobile Ad-hoc Networks (MANETs) are extremely susceptible to various misbehaviors and a variety of trust management schemes have been proposed to detect and mitigate them. Most schemes rely on a set of pre-defined weights to determine how the extent of each misbehavior is used to evaluate the trustworthiness. However, due to the extremely dynamic nature of MANETs, it is not possible to determine a set of weights that are appropriate for all contexts. In this paper, an Automated Trust Management (ATM) system is described for MANETs that uses a support vector machine classifier to detect malicious MANET nodes. The ATM scheme is resilient to attempts by a malicious MANET node to hide its nature by varying its misbehavior patterns over time. The performance of the ATM scheme is evaluated via an extensive simulation study and compared with existing approaches.","2375-0324","978-0-7695-4436-6","10.1109/MDM.2011.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6068451","security;trust management;mobile ad hoc network;support vector machine","Ad hoc networks;Asynchronous transfer mode;Mobile computing;Support vector machines;Mobile communication;Training;Security","mobile ad hoc networks;pattern classification;support vector machines;telecommunication computing;telecommunication security","automated trust management;mobile ad-hoc network;MANET;trust management scheme;support vector machine classifier","","3","","8","","3 Nov 2011","","","IEEE","IEEE Conferences"
"Studying on emotion recognition model based on BP network in E-Learning","C. Jiao; W. Wang","Department of Information Engineering, Capital Normal University, Beijing, China; Department of Information Engineering, Capital Normal University, Beijing, China","2010 IEEE International Conference on Software Engineering and Service Sciences","19 Aug 2010","2010","","","103","106","This paper presents a new method of the Emotion Recognition Model using the BP Neural Network, in order that E-Learning system simulates the real teaching situation better. As result of the experiment, the model shows a high rate of recognition and better real-time performance.","2327-0594","978-1-4244-6055-7","10.1109/ICSESS.2010.5552285","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5552285","E-Learning;BP Neural Network;Emotional Cognition;Emotional Model","Emotion recognition;Artificial neural networks;Training;Electronic learning;Transfer functions;Mathematical model;Convergence","backpropagation;computer aided instruction;emotion recognition;neural nets","emotion recognition;BP neural network;e-learning system;backpropagation","","","","10","","19 Aug 2010","","","IEEE","IEEE Conferences"
"A study on artificial neural networks-based fever patient number forecast","Y. Mao","Department of Information Engineering, Shandong Jiaotong University, Jinan, China","2010 International Conference on Computer Application and System Modeling (ICCASM 2010)","4 Nov 2010","2010","9","","V9-163","V9-165","The abstract should summarize the contents of the paper and should contain at least 70 and at most 150 words. It should be set in 9-point font size and should be inset 1.0 cm from the right and left margins. There should be two blank (10-point) lines before and after the abstract. This document is in the required format. The number of fever patient increases in winter, this research aimed at advancing BP neural network's precision in forecast of fever patient number. The method of forecast of fever patient number was based on double-layers BP neural network. The method was used to predict the fever patient number of Shandong Chest Hospital. The hospital can increase doctor number according to the results. The results of the computer simulation showed that the method was applicable, the average relative tolerance was 8.76%. The BP neural network can be used for forecast of fever patient number.","2161-9077","978-1-4244-7237-6","10.1109/ICCASM.2010.5623061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5623061","component;BP neural network;fever patient number;prediction","Artificial neural networks;Neurons;Hospitals;Training;Heuristic algorithms;Transfer functions","backpropagation;medical computing;neural nets","artificial neural networks;fever patient number forecast;BP neural network;Shandong chest hospital","","","","2","","4 Nov 2010","","","IEEE","IEEE Conferences"
"Distributed teleoperation and collaborative environment for robotics E-learning and cooperation","M. K. Habib","Mechanical Engineering Department, School of Sciences and Engineering, The American University in Cairo, Egypt","2008 6th IEEE International Conference on Industrial Informatics","3 Sep 2008","2008","","","1358","1363","A new concept is developed that enables users to access remote virtual and real facilities through a Web-based collaborative intelligent environment. The developed system integrates a virtual laboratory with distributed real facilities to help in transferring theoretical knowledge into practice and enables geographically dispersed people to interact by immersing them in a shared 3D intelligent and collaborative environment. This intelligent environment enables individual users manipulating data, manipulating objects, remote diagnostics and analyses, and simultaneously control, monitor, view and discuss results within a team as if they are all were interacting with each other within the same place. This concept has been implemented and virtual robots that mimic a real robot structure with its control panel, operations and control features have been integrated with the environment. Authorized users can access both physical and virtual robots. The physical robots that can be fully distributed in terms of space have been integrated to facilitate tele- and collaborative control operations in real time through the developed interactive 3D intelligent and environment. Three modes of operations have been implemented, individual robot training mode through virtual robot models, multi user mode, and group-based training by instructor. In addition, the control of the real robot is facilitated by simulation and direct control while enabling monitoring during execution on real robots.","2378-363X","978-1-4244-2170-1","10.1109/INDIN.2008.4618315","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4618315","","","computer aided instruction;computer science education;control engineering computing;control engineering education;groupware;Internet;telerobotics;virtual reality","distributed teleoperation;collaborative environment;robotics e-learning;cooperation;remote virtual facilities;remote real facilities;Web-based collaborative intelligent environment;virtual laboratory;distributed real facilities;shared 3D intelligent environment;virtual robots;group-based training","","5","","3","","3 Sep 2008","","","IEEE","IEEE Conferences"
"The cost-effectiveness of a robot measuring vital signs in a rural medical practice","E. Broadbent; J. R. Orejana; H. S. Ahn; J. Xie; P. Rouse; B. A. MacDonald","University of Auckland, Auckland, New Zealand; University of Auckland, Auckland, New Zealand; University of Auckland, Auckland, New Zealand; University of Auckland, Auckland, New Zealand; University of Auckland, Auckland, New Zealand; University of Auckland, Auckland, New Zealand","2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","23 Nov 2015","2015","","","577","581","Robots have been proposed to reduce the costs of the provision of healthcare in rural settings, but as yet little research has tested this. This study investigated the feasibility and cost-effectiveness of a robot measuring routine vital signs in a family medicine clinic in a rural setting. The length of patient consultations was compared before (N = 85 patients) and after a robot was deployed in the clinic (N = 48 patients). A Cafero touchscreen robot took the patient's vital signs prior to the consultation and transferred the results to the medical professional's computer. Time-savings were calculated in New Zealand dollar terms and compared to the costs of the robot and its maintenance. Results showed that consultation lengths were cut by 18% on average (3 minutes and 13 seconds). If 20% of the clinics' annual consultations were augmented with the robot this translates to a total annual savings of NZ$19075. The annual cost of the robot was calculated to be NZ$9400 overs 5 years. Present value calculations of Benefit Cost result in a Benefit Cost ratio of 2.3. These results support the cost-effectiveness of the robot in a rural medical clinic. Further research is needed to improve the services provided by the robot and test it in a larger trial.","","978-1-4673-6704-2","10.1109/ROMAN.2015.7333668","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7333668","","Robots;Blood pressure;Computers;Hospitals;Pressure measurement;Training","health care;medical computing;medical robotics;touch sensitive screens","vital sign measuring robot;rural medical practice;healthcare;family medicine clinic;rural setting;patient consultations;Cafero touchscreen robot;medical professional computer;New Zealand dollar terms","","10","","13","","23 Nov 2015","","","IEEE","IEEE Conferences"
"Learning to recognize a sign from a single example","J. Lichtenauer; E. Hendriks; M. Reinders","Information & Communication Theory Group, Faculty of Electrical Engineering, Mathematics & Computer Science, Delft University of Technology, The Netherlands; Information & Communication Theory Group, Faculty of Electrical Engineering, Mathematics & Computer Science, Delft University of Technology, The Netherlands; Information & Communication Theory Group, Faculty of Electrical Engineering, Mathematics & Computer Science, Delft University of Technology, The Netherlands","2008 8th IEEE International Conference on Automatic Face & Gesture Recognition","10 Apr 2009","2008","","","1","6","We present a method to automatically construct a sign language classifier for a previously unseen sign. The only required input of a new sign is one example, performed by a sign language tutor. The method works by comparing the measurements of the new sign to signs that have been trained on a large number of persons. The parameters of the respective trained classifier models are used to construct a classification model for the new sign. We show that the performance of a classifier constructed from an instructed sign is significantly better than that of dynamic time warping (DTW) with the same sign. Using only a single example, the proposed method has a performance comparable to a regular training with five examples, while being more stable because of the larger source of information.","","978-1-4244-2153-4","10.1109/AFGR.2008.4813450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4813450","","Handicapped aids;Knowledge transfer;Hidden Markov models;Machine learning;Mathematics;Computer science;Information resources;History;Performance evaluation;Testing","computer aided instruction;image classification;object recognition;time warp simulation","sign language classifier;sign language tutor;classification model;dynamic time warping;sign language recognition method","","2","","9","","10 Apr 2009","","","IEEE","IEEE Conferences"
"A Supervised-Learning Detector for Multihop Distributed Reception Systems","S. Kim; S. Hong","Department of Electrical Engineering, Ajou University, Suwon, South Korea; Department of Electrical Engineering, Ajou University, Suwon, South Korea","IEEE Transactions on Vehicular Technology","12 Feb 2019","2019","68","2","1958","1962","We consider a multihop distributed uplink reception system in which K users transmit independent messages to one data center of Nr ≥ K receive antennas, with the aid of multihop intermediate relays. In particular, each antenna of the data center is equipped with one-bit analog-to-digital converts (ADCs) for the sake of power efficiency. In this system, it is extremely challenging to develop a low-complexity detector due to the nonlinearity of an end-to-end channel transfer function (created by relays' operations and one-bit ADCs). Furthermore, there is no efficient way to estimate such complex function with a limited number of training data. Motivated by this, we propose a supervised-learning (SL) detector by introducing a novel Bernoulli-like model in which training data is directly used to design a detector rather than estimating a channel transfer function. It is shown that the proposed SL detector outperforms the existing SL detectors based on Gaussian model for one-bit quantized (binary observation) systems. Furthermore, we significantly reduce the complexity of the proposed SL detector using the fast kNN algorithm. Simulation results demonstrate that the proposed SL detector can yield an attractive performance with a significantly lower complexity.","1939-9359","","10.1109/TVT.2018.2886330","Samsung Research Funding & Incubation Center of Samsung Electronics; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8573872","Multihop distributed reception system;data detection;classification;one-bit ADC","Detectors;Data centers;Data models;Complexity theory;Relays;Transfer functions;Uplink","analogue-digital conversion;antenna arrays;computer centres;learning (artificial intelligence);quantisation (signal);radio networks;radio receivers;receiving antennas;relay networks (telecommunication);signal detection;telecommunication computing;wireless channels","low-complexity detector;end-to-end channel transfer function;supervised-learning detector;SL detector;one-bit quantized systems;independent messages;data center;multihop intermediate relays;one-bit analog-to-digital converts;power efficiency;one-bit ADC;multihop distributed uplink reception system;receive antennas;Bernoulli-like model;fast kNN algorithm","","1","","18","","12 Dec 2018","","","IEEE","IEEE Journals"
"SDDC: A Software Defined Datacenter Experimental Framework","A. Darabseh; M. Al-Ayyoub; Y. Jararweh; E. Benkhelifa; M. Vouk; A. Rindos","Jordan Univ. of Sci. & Technol., Irbid, Jordan; Jordan Univ. of Sci. & Technol., Irbid, Jordan; Jordan Univ. of Sci. & Technol., Irbid, Jordan; Mobile Fusion Appl. Res. Centre, Staffordshire Univ., Stafford, UK; North Carolina State Univ., Raleigh, NC, USA; IBM Corp., Research Triangle Park, NC, USA","2015 3rd International Conference on Future Internet of Things and Cloud","26 Oct 2015","2015","","","189","194","The rapid growth and the distributed sites of the datacenters increase the complexity of control and management processes. A new paradigm which is called Software Defined Systems (SDSys) comes as a solution to reduce the overhead of datacenters management by abstracting all the control functionalities from the hardware devices and setting it inside a software layer. These functionalities are responsible for organizing and controlling the main blocks of the datacenter; network, storage, compute and security. The Software Defined Datacenter (SDD) integrates the software defined concepts into all of these main blocks. Transferring these concepts into workable systems requires checking several performance aspects and testing its correctness before building real systems. In this paper we introduce a novel experimental framework (SDDC) to provide a novel virtualized testbed environment for SDD systems. This work builds on the Mininet simulator, where its core components, the host, the switch and the controller, are customized to build the proposed experimental simulation framework for SDD. This simulator lets the users develop and test their own SDD solutions, and at the same time gives the researchers an experimentation tool for benchmarking purposes. The developed simulator could also be used as an educational tool to train students and novice researchers.","","978-1-4673-8103-1","10.1109/FiCloud.2015.127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7300817","","Software;Switches;Random access memory;Security;Topology;Network topology","cloud computing;computer centres;digital simulation","software defined data center;SDDC;software defined systems;SDSys;Mininet simulator;cloud computing","","24","1","25","","26 Oct 2015","","","IEEE","IEEE Conferences"
"Gibson Env: Real-World Perception for Embodied Agents","F. Xia; A. R. Zamir; Z. He; A. Sax; J. Malik; S. Savarese","Stanford Univ., Stanford, CA, USA; Stanford Univ., Stanford, CA, USA; Stanford Univ., Stanford, CA, USA; Stanford Univ., Stanford, CA, USA; Univ. of California, Berkeley, Berkeley, CA, USA; Stanford Univ., Stanford, CA, USA","2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition","16 Dec 2018","2018","","","9068","9079","Developing visual perception models for active agents and sensorimotor control in the physical world are cumbersome as existing algorithms are too slow to efficiently learn in real-time and robots are fragile and costly. This has given rise to learning-in-simulation which consequently casts a question on whether the results transfer to real-world. In this paper, we investigate developing real-world perception for active agents, propose Gibson Environment for this purpose, and showcase a set of perceptual tasks learned therein. Gibson is based upon virtualizing real spaces, rather than artificially designed ones, and currently includes over 1400 floor spaces from 572 full buildings. The main characteristics of Gibson are: I. being from the real-world and reflecting its semantic complexity, II. having an internal synthesis mechanism ""Goggles"" enabling deploying the trained models in real-world without needing domain adaptation, III. embodiment of agents and making them subject to constraints of physics and space.","2575-7075","978-1-5386-6420-9","10.1109/CVPR.2018.00945","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8579043","","Rendering (computer graphics);Cameras;Neural networks;Three-dimensional displays;Visualization;Physics;Robot sensing systems","learning (artificial intelligence);multi-agent systems;rendering (computer graphics);robot vision;virtual reality","physical world;robots;learning-in-simulation;real-world perception;active agents;Gibson Environment;visual perception models;sensorimotor control;floor spaces;perceptual task learning;space virtualization;semantic complexity;Goggles internal synthesis mechanism","","48","","100","","16 Dec 2018","","","IEEE","IEEE Conferences"
"Bandwidth allocation of variable bit rate video in ATM networks using radial basis function neural networks","S. A. Youssef; I. W. Habib; T. N. Saadawi","Dept. of Electr. Eng., City Coll. of New York, NY, USA; NA; NA","1999 IEEE International Conference on Communications (Cat. No. 99CH36311)","6 Aug 2002","1999","1","","152","156 vol.1","ATM supports a wide range of multimedia traffic. While ATM provides increased flexibility in supporting various types of traffic the traffic control problems become more difficult to solve when trying to achieve efficient use of network resources. One of such problem is the bandwidth allocation. This paper presents a new approach to the bandwidth allocation problem for video traffic using radial basis functions neural networks (RBFNN). Estimation of an accurate amount of bandwidth to support this traffic has been a challenging task using conventional algorithmic approaches. In this paper, we show that a radial basis function neural network (RBFNN) is capable of learning the non-linear multi-dimentional mapping between different multimedia traffic patterns quality of service (QoS) requirements and the required bandwidth to support each call. Our method employs ""on-line"" measurements of the traffic count process over a monitoring period which is determined such that the error in estimating the bandwidth is minimized to less than 3% of the actual value. In order to simplify the design of the RBFNN, the input traffic is preprocessed through a low pass filter in order to smooth all high frequency fluctuations. A large set of training data, representing different traffic patterns with different QoS requirements, was used to ensure that RBFNN can generalize and produce accurate results when confronted with new data. The reported results prove that the neurocomputing approach is effective in achieving more accurate results than other traditional methods, based upon mathematical or simulation.","","0-7803-5284-X","10.1109/ICC.1999.767912","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=767912","","Channel allocation;Bit rate;Communication system traffic control;Bandwidth;Telecommunication traffic;Quality of service;Traffic control;Radial basis function networks;Monitoring;Data preprocessing","bandwidth allocation;multimedia communication;visual communication;telecommunication control;radial basis function networks;telecommunication computing;asynchronous transfer mode;telecommunication traffic;quality of service","bandwidth allocation;variable bit rate video;ATM networks;radial basis function neural networks;multimedia traffic;traffic control;video traffic;RBFNN;nonlinear multi-dimentional mapping;multimedia traffic patterns;quality of service;monitoring;input traffic;low pass filter;high frequency fluctuations;neurocomputing approach","","","4","5","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Optimal Wireless Charging Inclusive of Intellectual Routing Based on SARSA Learning in Renewable Wireless Sensor Networks","N. Aslam; K. Xia; M. U. Hadi","School of Electronics and Information Engineering, Hebei University of Technology, Tianjin, China; School of Electronics and Information Engineering, Hebei University of Technology, Tianjin, China; Department of Electrical, Electronic and Information Engineering, Universita degli Studi di Bologna, Bologna, Italy","IEEE Sensors Journal","15 Aug 2019","2019","19","18","8340","8351","The next generation's sensor nodes will be more intelligent, energy conservative, and perpetual lifetime in the set-up of wireless sensor networks (WSNs). These sensors nodes are facing the overwhelming challenge of energy consumption which gradually decreases the lifetime of overall network. The wireless power transfer (WPT) is one of the most emerging technologies of energy harvesting that deploys at the heart of sensor nodes for efficient lifetime solution. A wireless portable charging device (WPCD) is drifting inside the WSN to recharge all the nodes which are questing for the eternal life. In this paper, we aspire to optimize a multi-objective function for charging trail of WPCD, and self-learning algorithm for data routing jointly. We formulated that the objective functions can optimize the fair energy consumption as well as maximize the routing efficiency of WPCD. The fundamental challenge of the problem is, to integrate the novel path for WPCD by applying the Nodal A* algorithm. We proposed a novel method of sensor node's training for intellectual data transmission by using of clustering and reinforcement learning (SARSA) defined as clustering SARSA (C-SARSA) along with an optimal solution of objective functions. The whole mechanism outperforms in terms of trade-off between energy consumption and stability (fair energy consumption among all nodes) of the WSN; moreover, it prolongs the lifetime of the WSN. The simulated results demonstrate that our proposed method did better than compared literature in terms of energy consumption, stability, and lifetime of the WSN.","1558-1748","","10.1109/JSEN.2019.2918865","Key Supporting Project of Joint Fund of the National Natural Science Foundation of China; Natural Science Foundation of Tianjin City; Natural Science Foundation of Hebei Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721665","Clustering;energy conservation;energy harvesting;machine learning (SARSA);wireless power transfer;wireless sensor network;wireless portable charging device","Wireless sensor networks;Energy consumption;Routing;Sensors;Batteries;Energy harvesting;Wireless communication","energy conservation;learning (artificial intelligence);optimisation;pattern clustering;radiofrequency power transmission;telecommunication computing;telecommunication network routing;telecommunication power management;wireless sensor networks","optimal wireless charging inclusive;intellectual routing;SARSA learning;renewable wireless sensor networks;sensor nodes;energy conservative;perpetual lifetime;sensors nodes;wireless power transfer;energy harvesting;efficient lifetime solution;wireless portable charging device;WPCD;WSN;multiobjective function;self-learning algorithm;data routing;objective functions;fair energy consumption;routing efficiency;sensor node;clustering;reinforcement learning","","5","","42","","24 May 2019","","","IEEE","IEEE Journals"
"Deep Learning for Ultra-Reliable and Low-Latency Communications in 6G Networks","C. She; R. Dong; Z. Gu; Z. Hou; Y. Li; W. Hardjawana; C. Yang; L. Song; B. Vucetic","Univ. of Sydney, Sydney, NSW, Australia; Univ. of Sydney, Sydney, NSW, Australia; Univ. of Sydney, Sydney, NSW, Australia; Univ. of Sydney, Sydney, NSW, Australia; Univ. of Sydney, Sydney, NSW, Australia; Univ. of Sydney, Sydney, NSW, Australia; Beihang Univ., Beijing, China; Peking Univ., Beijing, China; Univ. of Sydney, Sydney, NSW, Australia","IEEE Network","18 Sep 2020","2020","34","5","219","225","In future 6th generation networks, URLLC will lay the foundation for emerging mission-critical applications that have stringent requirements on end-to-end delay and reliability. Existing works on URLLC are mainly based on theoretical models and assumptions. The model-based solutions provide useful insights, but cannot be directly implemented in practice. In this article, we first summarize how to apply data-driven supervised deep learning and deep reinforcement learning in URLLC, and discuss some open problems of these methods. To address these open problems, we develop a multi-level architecture that enables device intelligence, edge intelligence, and cloud intelligence for URLLC. The basic idea is to merge theoretical models and realworld data in analyzing the latency and reliability and training deep neural networks (DNNs). Deep transfer learning is adopted in the architecture to fine-tune the pre-trained DNNs in non-stationary networks. Further considering that the computing capacity at each user and each mobile edge computing server is limited, federated learning is applied to improve the learning efficiency. Finally, we provide some experimental and simulation results and discuss some future directions.","1558-156X","","10.1109/MNET.011.1900630","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9136591","","Ultra reliable low latency communication;Deep learning;Computer architecture;6G mobile communication;Quality of service;Delays;Training","6G mobile communication;learning (artificial intelligence);neural nets;telecommunication computing","low-latency communications;6g networks;6th generation networks;URLLC;mission-critical applications;reliability;model-based solutions;data-driven supervised deep learning;deep reinforcement learning;multilevel architecture;device intelligence;edge intelligence;cloud intelligence;deep transfer learning;nonstationary networks;mobile edge computing server;federated learning;learning efficiency;pretrained DNN","","7","","15","","8 Jul 2020","","","IEEE","IEEE Magazines"
"A contention access protocol with dynamic bandwidth allocation for wireless ATM networks","M. C. Yuang; P. L. Tien; C. S. Chen","Dept. of Comput. Sci. & Inf. Eng., Nat. Chiao Tung Univ., Hsinchu, Taiwan; NA; NA","2000 IEEE International Conference on Communications. ICC 2000. Global Convergence Through Communications. Conference Record","6 Aug 2002","2000","1","","149","153 vol.1","We propose a new contention access protocol (CAP) augmented with a dynamic bandwidth allocator (DBA) for wireless ATM networks supporting ABR and signaling control (SCR) traffic. CAP incorporates a dynamic tree-splitting collision resolution algorithm parameterized by an optimal splitting depth (SD). DBA performs estimation and on-line prediction of ABR self-similar traffic characteristics. It in turn determines the optimal SD per frame, satisfying ABR throughput and SCR blocking probability requirements while retaining maximal aggregate throughput. Simulation results postulate the optimal SDs under various ABR and SCR traffic conditions. These results are then off-line trained and constructed by a backpropagation neural network (BPNN), which is used on-line for optimal bandwidth allocation.","","0-7803-6283-7","10.1109/ICC.2000.853082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=853082","","Access protocols;Channel allocation;Thyristors;Traffic control;Communication system traffic control;Throughput;Bandwidth;Road accidents;Signal resolution;Aggregates","asynchronous transfer mode;packet radio networks;bandwidth allocation;telecommunication traffic;probability;telecommunication signaling;optimization;backpropagation;telecommunication computing;neural nets;access protocols;land mobile radio","contention access protocol;dynamic bandwidth allocation;wireless ATM networks;dynamic tree-splitting collision resolution algorithm;signaling control traffic;ABR traffic;optimal splitting depth;on-line prediction;ABR self-similar traffic characteristics;traffic estimation;ABR throughput;blocking probability;maximal aggregate throughput;simulation results;backpropagation neural network;optimal bandwidth allocation;mobile terminals","","2","","18","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Performance Analysis of Deep Learning based on Recurrent Neural Networks for Channel Coding","R. Sattiraju; A. Weinand; H. D. Schotten","Chair for Wireless Communication & Navigation, University of Kaiserslautern; Chair for Wireless Communication & Navigation, University of Kaiserslautern; Chair for Wireless Communication & Navigation, University of Kaiserslautern","2018 IEEE International Conference on Advanced Networks and Telecommunications Systems (ANTS)","9 May 2019","2018","","","1","6","Channel Coding has been one of the central disciplines driving the success stories of current generation LTE systems and beyond. In particular, turbo codes are mostly used for cellular and other applications where a reliable data transfer is required for latency-constrained communication in the presence of data-corrupting noise. However, the decoding algorithm for turbo codes is computationally intensive and thereby limiting its applicability in hand-held devices. In this paper, we study the feasibility of using Deep Learning (DL) architectures based on Recurrent Neural Networks (RNNs) for encoding and decoding of turbo codes. In this regard, we simulate and use data from various stages of the transmission chain (turbo encoder output, Additive White Gaussian Noise (AWGN) channel output, demodulator output) to train our proposed RNN architecture and compare its performance to the conventional turbo encoder/decoder algorithms. Simulation results show, that the proposed RNN model outperforms the decoding performance of a conventional turbo decoder at low Signal to Noise Ratio (SNR) regions.","2153-1684","978-1-5386-8134-3","10.1109/ANTS.2018.8710159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8710159","","Decoding;Computer architecture;Logic gates;Long Term Evolution;Turbo codes;Training","AWGN channels;cellular radio;channel coding;decoding;learning (artificial intelligence);Long Term Evolution;recurrent neural nets;telecommunication computing;telecommunication network reliability;turbo codes","turbo codes;cellular applications;reliable data transfer;latency-constrained communication;data-corrupting noise;hand-held devices;Deep Learning architectures;Recurrent Neural Networks;encoding decoding;conventional turbo encoder/decoder algorithms;channel Coding;LTE systems;Additive White Gaussian Noise channel;turbo decoder","","2","","30","","9 May 2019","","","IEEE","IEEE Conferences"
"A Novel DNN Based Channel Estimator for Underwater Acoustic Communications with IM-OFDM","M. Zhou; J. Wang; H. Sun; J. Qi; X. Feng; H. Esmaiel","Xiamen University,Key Laboratory of Underwater Acoustic Communication and Marine Information Technology College of information science and technology,Xiamen,Fujian,China; Tianjin University of Technology,School of Electrical and Electronic Engineering,Tianjin,China; Xiamen University,Key Laboratory of Underwater Acoustic Communication and Marine Information Technology College of information science and technology,Xiamen,Fujian,China; Xiamen University,School of Electronic Science and Engineering(National Model Microelectronics College),Xiamen,Fujian,China; Xiamen University,Key Laboratory of Underwater Acoustic Communication and Marine Information Technology College of information science and technology,Xiamen,Fujian,China; Aswan University,Faculty of Engineering,Department of Electrical Engineering,Aswan,Egypt","2020 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)","20 Nov 2020","2020","","","1","6","Performance of acoustic communication system in shallow sea is influenced by complicated interferences. Multipath with large delays and strong reflections leads to serious transmission error. To support reliable and efficient transmission in the background above, in this paper, a deep learning based channel estimator for underwater index modulated orthogonal frequency division modulation (IMOFDM) is proposed. A deep neural network is designed and trained with real channels tested in Xiamen sea area. The extracted real channels are collected and analyzed, constituting a mixed database with the channels generated using real parameters. Via a half-physical simulation, the performance is evaluated with different channel estimators. The results prove stability of the performance with the proposed channel estimator in different communication distances of shallow water. In conclusion, the deep learning based underwater IMOFDM channel estimator obtains significant performance in target shallow sea scenarios, which is promising as a solution to the adaptive scheme in changing underwater environment.","","978-1-7281-7202-6","10.1109/ICSPCC50002.2020.9259486","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9259486","Underwater acoustic communications;IMOFDM;deep learning;channel estimation;sample generation","Channel estimation;Training;Detectors;Deep learning;Underwater acoustics;Transfer functions;Receivers","channel estimation;learning (artificial intelligence);neural nets;OFDM modulation;telecommunication computing;underwater acoustic communication;wireless channels","underwater acoustic communications;IM-OFDM;acoustic communication system;complicated interferences;strong reflections;serious transmission error;reliable transmission;deep learning based channel estimator;underwater index;orthogonal frequency division modulation;deep neural network;Xiamen sea area;different channel estimators;different communication distances;shallow water;IMOFDM channel estimator;target shallow sea scenarios;underwater environment","","","","18","","20 Nov 2020","","","IEEE","IEEE Conferences"
"Impact of MSRP protocol integration in e-learning platforms of universities","K. Sylla; M. Seck; S. Ouya; G. Mendy","Virtual University of Senegal, Department of Applied Mathematics and Computer Science; Laboratory LIRT, University Cheikh Anta DIOP (U.C.A.D.), Senegal; Laboratory LIRT, University Cheikh Anta DIOP (U.C.A.D.), Senegal; Laboratory LIRT, University Cheikh Anta DIOP (U.C.A.D.), Senegal","2018 20th International Conference on Advanced Communication Technology (ICACT)","26 Mar 2018","2018","","","732","737","This paper discusses a solution for digital universities to extend the functionality of their e-learning platforms to improve, not only their delivery model of instructional content, but also their way of assessing the knowledge of the students. Indeed, this paper proposes a solution for the platform of Moodle, allowing to create virtual classes, integrating the sharing and the control of screens, the transfer of files independently of their type and their size, the video, the audio, chat, different actors. This solution integrates an audio and video knowledge assessment tool for language lesson modules and enables learners to learn to communicate. Our solution is built around MSRP and WebSocket protocols, is used directly with current browsers as well as computers, smartphones and tablets. Our solution has allowed, among other things, language teachers and STEM to perform work online and face-to-face as it should without necessarily resorting to the MCQ or be obliged to modify the tests to take into account the difficulties related to the evaluation of programming and networking lessons.","","979-11-88428-01-4","10.23919/ICACT.2018.8323902","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8323902","E-learning;STEM;evaluation;Learning Management System;Virtual classroom;MSRP;WebSocket","Protocols;Electronic learning;Relays;Training;Computer architecture;Servers;Tools","computer aided instruction;educational courses;educational institutions;Internet","audio;video knowledge assessment tool;language lesson modules;MSRP protocol integration;e-learning platforms;digital universities;delivery model;instructional content;virtual classes;WebSocket protocols;MCQ;networking lessons;programming lessons;STEM","","1","","20","","26 Mar 2018","","","IEEE","IEEE Conferences"
"Machine Learning Detectors for MU-MIMO Systems With One-Bit ADCs","S. Kim; J. Chae; S. Hong","Department of Electrical and Computer Engineering, The Ohio State University, Columbus, OH, USA; Department of Electrical and Computer Engineering, Ajou University, Suwon, South Korea; Department of Electrical and Computer Engineering, Ajou University, Suwon, South Korea","IEEE Access","19 May 2020","2020","8","","86608","86616","We consider an uplink multiuser multiple-input multiple-output (MU-MIMO) system with one-bit analog-to-digital converters (ADCs). In this system, the construction of a low-complexity detector is quite challenging due to the non-linearity of an end-to-end channel transfer function. Recently, a supervised-learning (SL) detector was proposed by modeling the complex non-linear function as a tractable Bernoulli-mixture model. It achieves an optimal maximum-likelihood (ML) performance, provided the channel state information (CSI) is perfectly known at a receiver. However, when a system-size is large, SL detector is not practical because of requiring a large amount of labeled data (i.e., pilot signals) to estimate the model parameters. We address this problem by proposing a semi-supervised learning (SSL) detector in which both pilot signals (i.e., labeled data) and some part of data signals (i.e., unlabeled data) are used to estimate them via expectation-maximization (EM) algorithm. We further extend the proposed detector for time-varying channels, by leveraging the idea of online learning, which is called online-learning (OL) detector. Simulation results demonstrate that the proposed SSL detector can achieve the almost same performance of the corresponding SL detector with significantly lower pilot overhead. In addition, it is shown that the proposed OL detector is more robust to channel variations compared with the existing detectors.","2169-3536","","10.1109/ACCESS.2020.2987212","Samsung Research Funding and Incubation Center of Samsung Electronics; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9064574","Massive MIMO;one-bit ADC;MIMO detection;machine learning;semi-supervised learning;EM algorithm","Detectors;MIMO communication;Receiving antennas;Uplink;Training;Coherence","analogue-digital conversion;expectation-maximisation algorithm;learning (artificial intelligence);MIMO communication;mixture models;telecommunication computing;time-varying channels;wireless channels","data signals;time-varying channels;online-learning detector;SSL detector;OL detector;machine learning detectors;MU-MIMO systems;ADC;uplink multiuser multiple-input multiple-output system;analog-to-digital converters;low-complexity detector;channel transfer function;supervised-learning detector;nonlinear function;optimal maximum-likelihood performance;channel state information;pilot signals;semisupervised learning detector;Bernoulli-mixture model;expectation-maximization algorithm;EM algorithm;word length 1 bit","","","","22","CCBY","13 Apr 2020","","","IEEE","IEEE Journals"
"A GFK-Based SNR Adaptive DOA Estimation Method","Q. Tan; L. Zhu","National Key Laboratory of Science and Technology on Communications UESTC,Chengdu,China; National Key Laboratory of Science and Technology on Communications UESTC,Chengdu,China","2019 IEEE 19th International Conference on Communication Technology (ICCT)","2 Jan 2020","2019","","","233","238","This paper proposes a DOA estimation method based on geodesic flow kernel(GFK), which has signal-to-noise ratio(SNR) adaptability and good DOA estimation performance under the scene of low SNR in space communication. Different from other machine learning methods, the GFK-based DOA method does not need to use the training sample to train model in advance. In fact, this method uses transfer learning to treat the source domain sample and the target domain sample as two points in the high-dimension space, then looks for a geodesic manifold transform kernel function to transform the space of the source domain sample into the space of the target domain sample. After that we can use the direction-of-arrival label information of the source domain sample to estimate the direction of the test sample. The simulation results show that the proposed method has better accuracy under the same SNR than the traditional MUSIC method, meanwhile has low complexity.","2576-7828","978-1-7281-0535-2","10.1109/ICCT46805.2019.8947314","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8947314","DOA estimation;SNR adaptation;transfer learning;geodesic flow kernel","Direction-of-arrival estimation;Estimation;Signal to noise ratio;Arrays;Machine learning;Covariance matrices;Kernel","differential geometry;direction-of-arrival estimation;learning (artificial intelligence);space communication links;telecommunication computing","space communication;machine learning methods;GFK-based DOA method;GFK-based SNR adaptive DOA estimation method;geodesic flow kernel;signal-to-noise ratio adaptability;geodesic manifold transform kernel function;direction-of-arrival label information","","","","17","","2 Jan 2020","","","IEEE","IEEE Conferences"
"Towards Photo-Realistic Virtual Try-On by Adaptively Generating↔Preserving Image Content","H. Yang; R. Zhang; X. Guo; W. Liu; W. Zuo; P. Luo",Harbin Institute of Technology; SenseTime Research; SenseTime Research; SenseTime Research; Tencent AI Lab; Harbin Institute of Technology; The University of Hong Kong,"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","5 Aug 2020","2020","","","7847","7856","Image visual try-on aims at transferring a target clothes image onto a reference person, and has become a hot topic in recent years. Prior arts usually focus on preserving the character of a clothes image (e.g. texture, logo, embroidery) when warping it to arbitrary human pose. However, it remains a big challenge to generate photo-realistic try-on images when large occlusions and human poses are presented in the reference person. To address this issue, we propose a novel visual try-on network, namely Adaptive Content Generating and Preserving Network (ACGPN). In particular, ACGPN first predicts semantic layout of the reference image that will be changed after try-on (e.g.long sleeve shirt→arm, arm→jacket), and then determines whether its image content needs to be generated or preserved according to the predicted semantic layout, leading to photo-realistic try-on and rich clothes details. ACGPN generally involves three major modules. First, a semantic layout generation module utilizes semantic segmentation of the reference image to progressively predict the desired semantic layout after try-on. Second, a clothes warping module warps clothes image according to the generated semantic layout, where a second-order difference constraint is introduced to stabilize the warping process during training.Third, an inpainting module for content fusion integrates all information (e.g. reference image, semantic layout, warped clothes) to adaptively produce each semantic part of human body. In comparison to the state-of-the-art methods, ACGPN can generate photo-realistic images with much better perceptual quality and richer fine-details.","2575-7075","978-1-7281-7168-5","10.1109/CVPR42600.2020.00787","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9156594","","Semantics;Clothing;Layout;Task analysis;Shape;Visualization;Image segmentation","clothing;image segmentation;neural nets;pose estimation;realistic images;virtual reality","image content preservation;image visual try-on aims;target clothes image;photo-realistic try-on images;human poses;ACGPN;semantic layout generation module;semantic segmentation;photorealistic virtual try-on;clothes warping module;warps clothes image;visual try-on network;Adaptive Content Generating and Preserving Network","","4","","50","","5 Aug 2020","","","IEEE","IEEE Conferences"
"VITON: An Image-Based Virtual Try-on Network","X. Han; Z. Wu; Z. Wu; R. Yu; L. S. Davis","Univ. of Maryland, College Park, MD, USA; Univ. of Maryland, College Park, MD, USA; Univ. of Maryland, College Park, MD, USA; Univ. of Maryland, College Park, MD, USA; Univ. of Maryland, College Park, MD, USA","2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition","16 Dec 2018","2018","","","7543","7552","We present an image-based VIirtual Try-On Network (VITON) without using 3D information in any form, which seamlessly transfers a desired clothing item onto the corresponding region of a person using a coarse-to-fine strategy. Conditioned upon a new clothing-agnostic yet descriptive person representation, our framework first generates a coarse synthesized image with the target clothing item overlaid on that same person in the same pose. We further enhance the initial blurry clothing area with a refinement network. The network is trained to learn how much detail to utilize from the target clothing item, and where to apply to the person in order to synthesize a photo-realistic image in which the target item deforms naturally with clear visual patterns. Experiments on our newly collected Zalando dataset demonstrate its promise in the image-based virtual try-on task over state-of-the-art generative models.","2575-7075","978-1-5386-6420-9","10.1109/CVPR.2018.00787","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8578885","","Clothing;Three-dimensional displays;Shape;Task analysis;Two dimensional displays;Strain;Generators","clothing;electronic commerce;image colour analysis;image representation;learning (artificial intelligence);pose estimation;realistic images;virtual reality","VITON;clothing-agnostic;descriptive person representation;coarse synthesized image;photo-realistic image;clothing item;image-based virtual try-on network;online shopping;RGB images","","49","","52","","16 Dec 2018","","","IEEE","IEEE Conferences"
"Deep Learning Based Communication Over the Air","S. Dörner; S. Cammerer; J. Hoydis; S. t. Brink","Institute of Telecommunications, University of Stuttgart, Stuttgart, Germany; Institute of Telecommunications, University of Stuttgart, Stuttgart, Germany; Nokia Bell Labs, Nozay, France; Institute of Telecommunications, University of Stuttgart, Stuttgart, Germany","IEEE Journal of Selected Topics in Signal Processing","19 Feb 2018","2018","12","1","132","143","End-to-end learning of communications systems is a fascinating novel concept that has so far only been validated by simulations for block-based transmissions. It allows learning of transmitter and receiver implementations as deep neural networks (NNs) that are optimized for an arbitrary differentiable end-to-end performance metric, e.g., block error rate (BLER). In this paper, we demonstrate that over-the-air transmissions are possible: We build, train, and run a complete communications system solely composed of NNs using unsynchronized off-the-shelf software-defined radios and open-source deep learning software libraries. We extend the existing ideas toward continuous data transmission, which eases their current restriction to short block lengths but also entails the issue of receiver synchronization. We overcome this problem by introducing a frame synchronization module based on another NN. A comparison of the BLER performance of the “learned” system with that of a practical baseline shows competitive performance close to 1 dB, even without extensive hyperparameter tuning. We identify several practical challenges of training such a system over actual channels, in particular, the missing channel gradient, and propose a two-step learning procedure based on the idea of transfer learning that circumvents this issue.","1941-0484","","10.1109/JSTSP.2017.2784180","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8214233","Autoencoder;communication;deep learning;end-to-end learning;modulation;neural network;over-the-air;software-defined radio","Training;Receivers;Communication systems;Artificial neural networks;Hardware;Transmitters;Synchronization","learning (artificial intelligence);neural nets;radio receivers;software libraries;software radio;synchronisation;telecommunication computing","two-step learning procedure;end-to-end learning;communications systems;block-based transmissions;receiver implementations;deep neural networks;NNs;block error rate;over-the-air transmissions;open-source deep learning software libraries;continuous data transmission;receiver synchronization;frame synchronization module;transmitter implementations;off-the-shelf software-defined radios","","193","","33","","15 Dec 2017","","","IEEE","IEEE Journals"
"Lossy Information Transmission Method based on Semantic Computing Architecture","C. Wang; L. Qian; Y. Wei; L. Liu","Shanghai Jiao Tong University,Dept. of Electronic Engineering,Shanghai,China; Shanghai Jiao Tong University,Dept. of Electronic Engineering,Shanghai,China; Shanghai Jiao Tong University,Dept. of Electronic Engineering,Shanghai,China; Shanghai Jiao Tong University,Dept. of Electronic Engineering,Shanghai,China","2019 25th Asia-Pacific Conference on Communications (APCC)","9 Mar 2020","2019","","","78","82","Despite the substantial progress of communication with Shannon theory in recent years, there are still many development opportunities in the transmission process. In this paper, we focus on the convergence of communication and computing to reduce transfer bandwidth, which transfers feature instead of information. Specifically, we propose a framework based on the Generative Adversarial Networks (GANs) for the first time to transfer feature. The simulation test and result analysis show that the joint process of communication and the computing relied on knowledge architecture opens up new possibilities for improving communication capability and surpass the Shannon limit under certain circumstances.","2163-0771","978-1-7281-3679-0","10.1109/APCC47188.2019.9026544","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9026544","Semantic Communication;Generative Adversarial Network (GANs);convergence of communication and computing","Feature extraction;Image reconstruction;Semantics;Generators;Training;Loss measurement;Generative adversarial networks","information theory;neural nets;radio networks;telecommunication computing","lossy information transmission method;semantic computing architecture;Shannon theory;transmission process;generative adversarial networks;knowledge architecture;communication capability;Shannon limit","","","","11","","9 Mar 2020","","","IEEE","IEEE Conferences"
"Stereotypical Motor Movement Detection in Dynamic Feature Space","N. M. Rad; S. M. Kia; C. Zarbo; G. Jurman; P. Venuti; C. Furlanello","Fondazione Bruno Kessler, Trento, Italy; Univ. of Trento, Trento, Italy; Fondazione Bruno Kessler, Trento, Italy; Fondazione Bruno Kessler, Trento, Italy; Univ. of Trento, Trento, Italy; Fondazione Bruno Kessler, Trento, Italy","2016 IEEE 16th International Conference on Data Mining Workshops (ICDMW)","2 Feb 2017","2016","","","487","494","Stereotypical Motor Movements (SMMs) are abnormal postural or motor behaviors that interfere with learning and social interaction in Autism Spectrum Disorder patients. An automatic SMM detection system, employing inertial sensing technology, provides a useful tool for real-time alert on the onset of these atypical behaviors, therefore facilitating personalized intervention therapies. To tackle critical issues with inter-subject variability, in this study, we propose to combine long short-term memory (LSTM) with convolutional neural network (CNN) to model the temporal patterns in the sequence of multi-axes IMU signals. Our results, on one simulated and two experimental datasets, show that transferring the raw feature space to a dynamic feature space via the proposed architecture enhances the performance of automatic SMM detection system especially for skewed training data. These findings facilitate the application of SMM detection system in real-time scenarios.","2375-9259","978-1-5090-5910-2","10.1109/ICDMW.2016.0076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836707","Stereotypical Motor Movement;Wearable Sensors;Long Short-term Memory;Feature Learning;Human Activity Recognition","Feature extraction;Real-time systems;Accelerometers;Activity recognition;Detectors;Computer architecture","feedforward neural nets;learning (artificial intelligence);medical computing;medical disorders","stereotypical motor movement detection;abnormal postural behavior;abnormal motor behavior;learning;social interaction;autism spectrum disorder patients;inertial sensing technology;real-time alert;atypical behaviors;personalized intervention therapies;intersubject variability;long-short-term memory;LSTM;convolutional neural network;CNN;temporal patterns;multiaxis IMU signal sequence;raw feature space;dynamic feature space;skewed training data;automatic SMM detection system","","3","","43","","2 Feb 2017","","","IEEE","IEEE Conferences"
"Report on Basic Feedback Control Education and a Practical PID Tuning Method for Technical Staff and Operators","M. Nakaya; H. Yoshizumi","Marketing Headquarters,Yokogawa Electric Corporation,Musashino-shi,Tokyo,Japan,180-8750; Global Industrial Plant Division,Yokogawa Solution Service Corporation,Kita-ku,Japan,530-0001","2019 IEEE 15th International Conference on Control and Automation (ICCA)","14 Nov 2019","2019","","","746","751","Proportional-integral-derivative (PID) control is a technique commonly used in the process industry. Although an introduction to PID control is referenced in many textbooks, practical PID tuning techniques applicable to the manufacturing field have not yet been established. As a result PID controllers are often tuned through the experience and intuition of technical staff and operators. In this paper, we introduce a basic PID control lecture outline which avoids complex numerical formulas. In our lectures, trainees can visually learn PID control using a PID Excel simulator, able to simulate process behavior in the case of control parameters changes.Generally, PID tuning techniques are divided into two categories; open-loop and closed-loop types. In the open-loop type, a step response test is required for PID tuning. From this test, the process gain Kp, dead time L and the time constant T are obtained to determine the PID parameters. In practice, step response tests are rarely implemented in the manufacturing field, due to their direct disturbance to production activity. As an alternative method, PID parameters can be determined through consistent oscillation using proportional control alone in a closed loop. However, as consistent oscillation potentially damages the plant facility, this PID tuning method is also not accessible in the field. Therefore, we propose a practical PID tuning method using damped oscillation generated by proportional control. We believe that in light of advanced automatic PID tuning systems utilizing AI technology being introduced in the near future, current service business development in this sector has a tendency to hide the underlying basic technology. To prevent the future industry from becoming blind to basic process control technology, we aim to contribute to the transfer of PID parameters tuning techniques to technical staff and operators working in plants.","1948-3457","978-1-7281-1164-3","10.1109/ICCA.2019.8900005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900005","","Tuning;PD control;PI control;Process control;Manufacturing;Oscillators;Education","computer aided instruction;control engineering education;control system analysis computing;control system synthesis;feedback;manufacturing systems;process control;production engineering computing;spreadsheet programs;three-term control;tuning","practical PID tuning method;advanced automatic PID tuning systems;basic process control technology;PID parameters;technical staff;basic feedback control education;proportional-integral-derivative control;practical PID tuning techniques;manufacturing field;result PID controllers;basic PID control lecture outline;PID Excel simulator;control parameters changes;closed-loop types;open-loop type","","","","12","","14 Nov 2019","","","IEEE","IEEE Conferences"
"Strengthening study skills by using ERPsim as a new tool within the Pupils' academy of serious gaming","M. Utesch; R. Heininger; H. Krcmar","Staatliche Fachober- und Berufsoberschule, Technik München, Munich, Germany; Chair for Information Systems, Technical University of Munich (TUM) Munich, Germany; Chair for Information Systems, Technical University of Munich (TUM) Munich, Germany","2016 IEEE Global Engineering Education Conference (EDUCON)","23 May 2016","2016","","","592","601","Companies are currently calling for more and more graduates with good management and planning skills. But, studies show that rising student numbers lead to a high dropout rate. Thus, strengthening the study skills of the students plays a key role in reducing this dropout rate and should be a key objective of every education system. In particular, universities have the power to improve the study skills of pupils at an early stage through the designed programs and measures. With the Pupils' Academy Serious Gaming, the Department of Computer Science at the Technical University of Munich (TUM) has introduced an instrument to promote the study skills. This initiative aimed primarily at pupils of upper vocational schools (UVS). In addition to the study skills, thus the ability of more application-oriented knowledge transfer objectives and playful introduction to an important enterprise software can be achieved. This paper presents the Pupils' Academy based on the online SAP ERP Simulation Game ERPsim as an example of how the enterprise software SAP ERP is successfully applied to strengthen study skills. In addition, the pupils learn how to deal with the SAP platform and train skills like decision making, analysis, strategy development, data processing and presentation. The positive impact on study skills is evidenced with the help of a self-assessment by means of an IT-based survey carried out by the participating students. These examinations include the activities related to the two study skills time management and teamwork.","2165-9567","978-1-4673-8633-3","10.1109/EDUCON.2016.7474611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7474611","study skills;online business game;didactic framework;IT-based questionnaire;ERPsim;vocational school","Games;Software;Education;Teamwork;Laboratories;Companies","computer aided instruction;educational institutions;serious games (computing)","ERPsim;pupils academy;planning skills;dropout rate;education system;pupil academy serious gaming;Technical University of Munich;TUM;upper vocational schools;UVS;knowledge transfer objectives;enterprise software SAP ERP;decision making","","6","","31","","23 May 2016","","","IEEE","IEEE Conferences"
"DNN-Aided Block Sparse Bayesian Learning for User Activity Detection and Channel Estimation in Grant-Free Non-Orthogonal Random Access","Z. Zhang; Y. Li; C. Huang; Q. Guo; C. Yuen; Y. L. Guan","Xidian University, Xi’an, China; Xidian University, Xi’an, China; Singapore University of Technology and Design, Singapore; School of Electrical, Computer and Telecommunications Engineering, University of Wollongong, NSW, Australia; Singapore University of Technology and Design, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Vehicular Technology","17 Dec 2019","2019","68","12","12000","12012","In the upcoming Internet-of-Things (IoT) era, the communication is often featured by massive connection, sporadic transmission, and small-sized data packets, which poses new requirements on the delay expectation and resource allocation efficiency of the Random Access (RA) mechanisms of the IoT communication stack. A grant-free non-orthogonal random access (NORA) system is considered in this paper, which could simultaneously reduce the access delay and support more Machine Type Communication (MTC) devices with limited resources. In order to address the joint user activity detection (UAD) and channel estimation (CE) problem in the grant-free NORA system, we propose a deep neural network-aided message passing-based block sparse Bayesian learning (DNN-MP-BSBL) algorithm. In the DNN-MP-BSBL algorithm, the iterative message passing process is transferred from a factor graph to a deep neural network (DNN). Weights are imposed on the messages in the DNN and trained to minimize the estimation error. It is shown that the trained weights could alleviate the convergence problem of the MP-BSBL algorithm, especially on crowded RA scenarios. Simulation results show that the proposed DNN-MP-BSBL algorithm could improve the UAD and CE accuracy with a smaller number of iterations, indicating its advantages for low-latency grant-free NORA systems.","1939-9359","","10.1109/TVT.2019.2947214","National Natural Science Foundation of China; A*STAR AME IAF PP; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868222","Deep neural network;sparse Bayesian learning;grant-free;user activity detection;channel estimation","Bayes methods;Message passing;Channel estimation;Protocols;Neural networks;Internet of Things;Uplink","Bayes methods;channel estimation;iterative methods;learning (artificial intelligence);message passing;neural nets;resource allocation;telecommunication computing","Internet-of-Things era;massive connection;sporadic transmission;data packets;delay expectation;resource allocation efficiency;random access mechanisms;IoT communication stack;grant-free nonorthogonal random access system;machine type communication devices;user activity detection;channel estimation;grant-free NORA system;deep neural network;DNN-MP-BSBL algorithm;iterative message passing process;low-latency grant-free NORA systems;DNN-aided block sparse Bayesian learning;aided message passing;convergence problem","","7","","38","IEEE","14 Oct 2019","","","IEEE","IEEE Journals"
"A new bandwidth prediction based wireless Ad-Hoc video communication","R. Jiang; X. Tian; Y. Chen","The Institute of Advanced Digital Technologies & Instrumentation, Zhejiang University, China; The Institute of Advanced Digital Technologies & Instrumentation, Zhejiang University, China; The Institute of Advanced Digital Technologies & Instrumentation, Zhejiang University, China","2007 IET Conference on Wireless, Mobile and Sensor Networks (CCWMSN07)","20 Feb 2009","2007","","","1033","1038","In this paper, we propose a new bandwidth prediction and control scheme for transmission of real-time video stream over wireless ad hoc network. Our proposed strategy is based on cross-layer, feedback and neural network techniques. We first determine several relevant parameters which directly impact the quality of video transmission. We obtain the topology change, the signal power information by using cross-layer mechanism. We obtain the packet loss statistics and the network jitter from receiver feedback. Subsequently, we extract their relevant features from those sample data, and take them as the input for training data of the neural network. The predicted result of the neural network would be used as the bandwidth of mobile ad-hoc network (MANET). This parameter will be used to control video encoder to adjust the bit rates of real-time video stream. We have implemented an integrated video streaming system simulation for proving our proposed scheme. In contrast to the conventional transfer scheme, the results of our proposed control strategies indicate that there are considerable improvements in the packet loss and the real time visual quality.","0537-9989","978-0-86341-836-5","10.1049/cp:20070328","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4786382","Cross-Layer;Real-Time Video Streaming;MANET;IEEE802.11;Neural Network","","ad hoc networks;bandwidth allocation;mobile radio;neural nets;telecommunication computing;video coding;video communication;video streaming","bandwidth prediction;wireless ad-hoc video communication;real-time video stream;neural network techniques;feedback techniques;cross-layer techniques;video transmission;signal power information;network jitter;receiver feedback;mobile ad-hoc network;MANET;video encoder","","","","","","20 Feb 2009","","","IET","IET Conferences"
"RL-Routing: An SDN Routing Algorithm Based on Deep Reinforcement Learning","Y. -R. Chen; A. Rezapour; W. -G. Tzeng; S. -C. Tsai","Department of computer science, National Chiao Tung University, Taiwan; Department of computer science, National Chiao Tung University, Taiwan; Department of computer science, National Chiao Tung University, Taiwan; Department of computer science, National Chiao Tung University, Taiwan","IEEE Transactions on Network Science and Engineering","31 Dec 2020","2020","7","4","3185","3199","Communication networks are difficult to model and predict because they have become very sophisticated and dynamic. We develop a reinforcement learning routing algorithm (RLRouting) to solve a traffic engineering (TE) problem of SDN in terms of throughput and delay. RL-Routing solves the TE problem via experience, instead of building an accurate mathematical model. We consider comprehensive network information for state representation and use one-to-many network configuration for routing choices. Our reward function, which uses network throughput and delay, is adjustable for optimizing either upward or downward network throughput. After appropriate training, the agent learns a policy that predicts future behavior of the underlying network and suggests better routing paths between switches. The simulation results show that RL-Routing obtains higher rewards and enables a host to transfer a large file faster than Open Shortest Path First (OSPF) and Least Loaded (LL) routing algorithms on various network topologies. For example, on the NSFNet topology, the sum of rewards obtained by RL-Routing is 119.30, whereas those of OSPF and LL are 106.59 and 74.76, respectively. The average transmission time for a 40GB file using RL-Routing is 25.2 s. Those of OSPF and LL are 63 sand 53.4 s, respectively.","2327-4697","","10.1109/TNSE.2020.3017751","Ministry of Science and Technology; Ministry of Economic Affairs; Ministry of Education; Ministry of Education, Taiwan, R.O.C.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9171590","Cognitive sdn;deep reinforcement learning;routing algorithm;software defined networks.","Routing;Throughput;Delays;Reinforcement learning;Heuristic algorithms;Network topology;Control systems","deep learning (artificial intelligence);software defined networking;telecommunication computing;telecommunication network routing;telecommunication network topology;telecommunication traffic","deep reinforcement learning;communication networks;reinforcement learning routing algorithm;upward network throughput;downward network throughput;network topologies;SDN routing algorithm;RL-Routing;traffic engineering problem;one-to-many network configuration;NSFNet topology","","1","","35","IEEE","19 Aug 2020","","","IEEE","IEEE Journals"
"Robot teaching by teleoperation based on visual interaction and neural network learning","Y. Xu; C. Yang; J. Zhong; H. Ma; L. Zhao; M. Wang","Key Laboratory of Autonomous Systems and Networked Control, College of Automation Science and Engineering, South China University of Technology, Guangzhou, 510640 China; Key Laboratory of Autonomous Systems and Networked Control, College of Automation Science and Engineering, South China University of Technology, Guangzhou, 510640 China; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; School of Automation, Beijing Institution of Technology, Beijing 100081, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin 150001, China; Key Laboratory of Autonomous Systems and Networked Control, College of Automation Science and Engineering, South China University of Technology, Guangzhou, 510640 China","2017 9th International Conference on Modelling, Identification and Control (ICMIC)","22 Mar 2018","2017","","","1068","1073","Traditional methods of Robot teaching require human demonstrators to program with a teaching pendant, which is a complex and time-consuming exercise. In this paper, we propose a novel method based on teleoperation which allows a demonstrator to train robot in an intuitive way. More specifically, at the beginning the demonstrator controls a robot by visual interaction. And then a learning algorithm based on radial basis function (RBF) network is used to transfer the demonstrator's motions to the robot. To verify the effectiveness of this developed methods, several simulation experiments have been carried out which based on Microsoft Kinect Sensor and the Virtual Robot Experimentation Platform (V-REP). The experimental results show that this method has achieved satisfactory performance. With the help of this method, the robot can not only complete the task autonomously after teaching, but also can learn the details of demonstrator's behavior.","","978-1-5090-6575-2","10.1109/ICMIC.2017.8321615","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8321615","Robot Teaching;Teleoperation;radial basis function (RBF) network","Service robots;Education;Robot sensing systems;Radial basis function networks;Mathematical model","computer aided instruction;control engineering computing;learning (artificial intelligence);neural nets;radial basis function networks;robot programming;telerobotics","Robot teaching;teleoperation;visual interaction;neural network learning;human demonstrators;teaching pendant;learning algorithm;radial basis function network;Virtual Robot Experimentation Platform;V-REP","","1","","22","","22 Mar 2018","","","IEEE","IEEE Conferences"
"Fixed-Symbol Aided Random Access Scheme for Machine-to-Machine Communications","Z. Zhang; Y. Li; L. Liu; W. Hou","State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, China","IEEE Access","29 Apr 2019","2019","7","","52913","52928","The massiveness of devices in crowded Machine-to-Machine (M2M) communications brings new challenges to existing random-access (RA) schemes, such as heavy signaling overhead and severe access collisions. In order to reduce the signaling overhead, we propose a fixed-symbol aided RA scheme where active devices access the network in a grant-free method, i.e., data packets are directly transmitted in randomly chosen slots. To further address the access collision which impedes the activity detection, one fixed symbol is inserted into each transmitted data packet in the proposed scheme. An iterative message passing-based activity detection (MP-AD) algorithm is performed upon the received signal of this fixed symbol to detect the device activity in each slot. In addition, the deep neural network-aided MP-AD (DNN-MP-AD) algorithm is further designed to alleviate the correlation problem of the iterative message passing process. In the DNN-MP-AD algorithm, the iterative message passing process is transferred from a factor graph to a DNN. Weights are imposed on the messages in the DNN and further trained to improve the accuracy of the device activity detection. Finally, numerical simulations are provided for the throughput of the proposed RA scheme, the accuracy of the proposed MP-AD algorithm, and the improvement brought by the DNN-MP-AD algorithm.","2169-3536","","10.1109/ACCESS.2019.2912448","Key Industry Innovation Chain Project of Shaanxi; Fundamental Research Funds for the Central Universities of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8695167","M2M communications;random access;message passing detection;deep neural network","Machine-to-machine communications;Protocols;Message passing;Performance evaluation;Mathematical model;Matching pursuit algorithms;Correlation","correlation methods;graph theory;iterative methods;machine-to-machine communication;message passing;neural nets;telecommunication computing","device activity detection;RA scheme;DNN-MP-AD algorithm;fixed-symbol aided random access scheme;machine-to-machine communications;heavy signaling;active devices access;grant-free method;data packets;randomly chosen slots;access collision;fixed symbol;transmitted data packet;iterative message passing-based activity detection algorithm;received signal;deep neural network-aided MP-AD algorithm;iterative message passing process;factor graph","","2","","50","","22 Apr 2019","","","IEEE","IEEE Journals"
"GCLR: GNN-Based Cross Layer Optimization for Multipath TCP by Routing","T. Zhu; X. Chen; L. Chen; W. Wang; G. Wei","Department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei, China; Department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei, China; Department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei, China; Department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei, China; Department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei, China","IEEE Access","29 Jan 2020","2020","8","","17060","17070","Multipath TCP has attracted increasing attention as a promising technology for 5G networks. To fully utilize network interfaces on multi-homed terminals and the whole network resources, MPTCP is proposed as an extension of TCP to transfer packets concurrently over multiple paths. Cross layer optimization techniques have been applied for MPTCP such as routing and path management. However, existing multipath routing algorithms and network modeling techniques are facing the challenges of subflow asymmetry due to network heterogeneity, thus cannot handle routing optimization problems comprehensively. To address these problems, in this paper, firstly, a novel Graph Neural Network (GNN) based multipath routing model is proposed to explore the complications among links, paths, subflows and the MPTCP connection on various topologies. Leveraging the GNN model, expected throughput can be predicted with given network topology and multipath routes, which can further be the guidance for optimzing the multipath routing. Then, GCLR, a GNN based cross layer optimization system for MPTCP by routing, is proposed with the help of SDN (Software Defined Networking). According to simulation results, our off-line learned GNN model can predict the expected throughput of specific MPTCP connections with very low error. Besides, it's validated that the model has high generalization ability in terms of connection arbitrary and topology arbitrary, it can maintain MSE (mean squared error) at a low level when the situations are not seen during training, which is sufficient for throughput prediction in multipath routing decisions. Finally, the online routing optimization system is realized using SDN, experimental results show that our proposed routing optimization system can achieve significant throughput enhancement compared with traditional multipath routing algorithms.","2169-3536","","10.1109/ACCESS.2020.2966045","National Basic Research Program of China (973 Program); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8957071","Routing;multipath TCP;graph neural network;cross layer optimization;software defined networking","Routing;Throughput;Optimization;Cross layer design;Network topology;Bandwidth;Predictive models","graph theory;mobile radio;network interfaces;neural nets;optimisation;routing protocols;software defined networking;telecommunication computing;telecommunication network topology;telecommunication traffic;transport protocols","GCLR;GNN-based cross layer optimization;multipath TCP;network interfaces;multihomed terminals;cross layer optimization techniques;path management;subflow asymmetry;network heterogeneity;routing optimization problems;graph neural network;MPTCP connection;GNN model;network topology;multipath routes;software defined networking;MPTCP connections;online routing optimization system;multipath routing algorithms;5G networks;mean squared error","","","","48","CCBY","13 Jan 2020","","","IEEE","IEEE Journals"
"Table of contents","",,"2014 IIAI 3rd International Conference on Advanced Applied Informatics","1 Dec 2014","2014","","","v","xix","The following topics are dealt with: data mining; Japanese WordNet synonym misplacement detection; social network; recommender system; sentiment analysis; workshop-based instruction; Japanese public libraries; machine learning methods; collaborative Web presentation support system; SMS4 ultracompact hardware implementation; wireless sensor networks; personalized public transportation recommendation system; adaptive user interface; NIS-Apriori algorithm; GetRNIA software tool; rough set-based rule generation; tree-Ga bump hunting; neural network model; weighted citation network analysis; sound proofing ventilation unit; touch interaction; mutually dependent Markov decision processes; ozone treatment; dynamic query optimization; big data; learner activity recognition; IoT-security approach; nutrition-based vegetable production; farm product cultivation; polynomial time mat learning; C-deterministic regular formal graph system; article abstract key expression extraction; English text comprehension; online social games; knowledge creation; knowledge utilization; online stock trading; customer behavior analysis; project-based collaborative learning; in-field mobile game-based learning activities; e-portfolio system design; self-regulated learning ontological model; mobile augmented reality based scaffolding platform; context-aware mobile Japanese conversation learning system; English writing error classification; image processing; outside-class learning; exercise-centric teaching materials; UML modeling; online historical document reading literacy; MMORPG-based learning environment; computer courses; undergraduate education; energy management system; higher education; decentralised auction-based bandwidth allocation; wireless networked control systems; resource scheduling algorithm; embedded cloud computing; Poisson distribution; Japanese seismic activity; suspect vehicle detection; 3D network traffic visualization; Web information retrieval; agent based disaster evacuation assist system; electroencephalogram; random number generator; multiagent simulations; multicore environment; CPU scheduler; multithreaded processes; reserve-price biddings; real-time traffic signal control; evolutionary computation; robot-assisted rehabilitation system; hybrid automata; Batik motif classification; color-texture-based feature extraction; backpropagation; multimedia storytelling; e-tourism service; Web mining; search engine; simulation-based e-learning mobile application software; library classification training system; WebQuest learning strategy; context-aware ubiquitous English learning; support vector machine; RFID tag ownership transfer protocol; cognitive linguistics; collaborative software engineering learning; write-access reduction method; NVM-DRAM hybrid memory; garbage collection; parallel indexing scheme; lazy-updating snoop cache protocol; distributed storage system; ITS application; software engineering education; ophthalmic multimodal imaging system; injected bug classification; secure live virtual machine migration; flash memory management; genetic programming; heterogeneous databases; time series similarity search; concurrency control program generation; incremental data migration; multidatabase system; software release time decision making; analytic hierarchy process; interactive genetic algorithm; biometric intelligence; talking robots; archaeological ruin analysis; GIS; optical wireless pedestrian-support systems; visual impairment; extreme programming; Japanese e-commerce Web sites; Chinese sign language animation; hearing-impaired people mammography inspection; geographical maps; electroculogram; XML element retrieval technique; image recognition; reinforcement learning; ECU formal verification; gasoline direct injection engines; earthquake disaster simulation; smart devices for autistic children; RoboCup rescue simulation; inductive logic programming; master-slave asynchronous evolutionary hybrid algorithm; VANET routing optimization; and Web image sharing services.","","978-1-4799-4173-5","10.1109/IIAI-AAI.2014.4","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913248","","","agriculture;analytic hierarchy process;archaeology;augmented reality;automata theory;backpropagation;bandwidth allocation;Big Data;biometrics (access control);cache storage;citation analysis;cloud computing;computational complexity;computer animation;computer games;computer science education;concurrency control;consumer behaviour;data mining;data visualisation;distributed databases;DRAM chips;educational courses;electroencephalography;electronic commerce;electro-oculography;emergency management;energy management systems;engines;feature extraction;flash memories;formal verification;further education;genetic algorithms;geographic information systems;groupware;handicapped aids;human computer interaction;humanoid robots;image classification;image colour analysis;image texture;inductive logic programming;intelligent tutoring systems;Internet of Things;investment;library automation;linguistics;mammography;Markov processes;medical robotics;mobile computing;multi-agent systems;multimedia computing;multiprocessing systems;multi-threading;natural language processing;networked control systems;neural nets;object detection;ozonation (materials processing);patient rehabilitation;pedestrians;Poisson distribution;processor scheduling;public transport;query processing;random number generation;recommender systems;rescue robots;resource allocation;rough set theory;search engines;security of data;seismology;social networking (online);software prototyping;software tools;stock markets;storage management;support vector machines;teaching;telecommunication network routing;text analysis;time series;traffic control;traffic engineering computing;travel industry;trees (mathematics);Unified Modeling Language;unsupervised learning;user interfaces;vehicular ad hoc networks;ventilation;virtual machines;wireless sensor networks;XML","data mining;Japanese WordNet synonym misplacement detection;social network;recommender system;sentiment analysis;workshop-based instruction;Japanese public libraries;machine learning methods;collaborative Web presentation support system;SMS4 ultracompact hardware implementation;wireless sensor networks;personalized public transportation recommendation system;adaptive user interface;NIS-Apriori algorithm;GetRNIA software tool;rough set-based rule generation;tree-Ga bump hunting;neural network model;weighted citation network analysis;sound proofing ventilation unit;touch interaction;mutually dependent Markov decision processes;ozone treatment;dynamic query optimization;big data;learner activity recognition;IoT-security approach;nutrition-based vegetable production;farm product cultivation;polynomial time mat learning;C-deterministic regular formal graph system;article abstract key expression extraction;English text comprehension;online social games;knowledge creation;knowledge utilization;online stock trading;customer behavior analysis;project-based collaborative learning;in-field mobile game-based learning activities;e-portfolio system design;self-regulated learning ontological model;mobile augmented reality based scaffolding platform;context-aware mobile Japanese conversation learning system;English writing error classification;image processing;outside-class learning;exercise-centric teaching materials;UML modeling;online historical document reading literacy;MMORPG-based learning environment;computer courses;undergraduate education;energy management system;higher education;decentralised auction-based bandwidth allocation;wireless networked control systems;resource scheduling algorithm;embedded cloud computing;Poisson distribution;Japanese seismic activity;suspect vehicle detection;3D network traffic visualization;Web information retrieval;agent based disaster evacuation assist system;electroencephalogram;random number generator;multiagent simulations;multicore environment;CPU scheduler;multithreaded processes;reserve-price biddings;real-time traffic signal control;evolutionary computation;robot-assisted rehabilitation system;hybrid automata;Batik motif classification;color-texture-based feature extraction;backpropagation;multimedia storytelling;e-tourism service;Web mining;search engine;simulation-based e-learning mobile application software;library classification training system;WebQuest learning strategy;context-aware ubiquitous English learning;support vector machine;RFID tag ownership transfer protocol;cognitive linguistics;collaborative software engineering learning;write-access reduction method;NVM-DRAM hybrid memory;garbage collection;parallel indexing scheme;lazy-updating snoop cache protocol;distributed storage system;ITS application;software engineering education;ophthalmic multimodal imaging system;injected bug classification;secure live virtual machine migration;flash memory management;genetic programming;heterogeneous databases;time series similarity search;concurrency control program generation;incremental data migration;multidatabase system;software release time decision making;analytic hierarchy process;interactive genetic algorithm;biometric intelligence;talking robots;archaeological ruin analysis;GIS;optical wireless pedestrian-support systems;visual impairment;extreme programming;Japanese e-commerce Web sites;Chinese sign language animation;hearing-impaired people mammography inspection;geographical maps;electrooculogram;XML element retrieval technique;image recognition;reinforcement learning;ECU formal verification;gasoline direct injection engines;earthquake disaster simulation;autistic children;RoboCup rescue simulation;inductive logic programming;master-slave asynchronous evolutionary hybrid algorithm;VANET routing optimization;Web image sharing services","","","","","","1 Dec 2014","","","IEEE","IEEE Conferences"
"Table of contents","",,"2014 International Conference on Applied Electronics","19 Jan 2015","2014","","","vii","xii","The following topics are dealt with: high-speed analog-to-digital converters; nanometer CMOS technology; pseudo random code regeneration; oscillation frequency value; oscillation-based tests; reconfigurable filter structure; universal embedded controller; matrix converter; continuous-time sigma-delta modulator; integrated LC filter; human-robot cooperation; seismic sensor system; MEMS accelerometer; memristor pinched hysteresis loops; PV panels; MPPT controller; PV power system modelling; PLP feature extraction optimization; LVCSR recognition; MP3 data; dead-time compensation strategy; adaptive harmonic compensator; Cartesian genetic programming; desktop based real time oxygen auto-ventilation; gas monitoring system; homecare respiratory application; subband optimization; EEG-based classification; HART compatible HART line powered communication module; interactive hybrid control-flow checking method; polyphase FIR filter structure; VHDL language; FPGA; B3C converter; heat transfer; electronic system; moving object searching; virtual instrumentation; ISO26262 motorbikes; nonlinear stabilization; state space energy error feedback; quadrature oscillator; operational transresistance amplifier; quantum computation system emulator; low noise amplifier; SVPWM algorithm; H-bridge power inverter; LCL filter; 3D machine vision system; contact strips inspection; railway vehicle current collectors; wrist cuff method; mean arterial pressure; dual-cuff blood pressure system; contactless electrical energy transfer; varying air gap; resonant converter; nonlinear inductance; programmable PWM modulator; OPWM test platform; 3D FEM simulation; EMC testing; input current harmonics; voltage-source active rectifier; motion detection system; NiTi pressure sensors; phase coupled oscillator; dissipation normal form; space vector pulse width modulation; RF circuits response; software defined radio system; adaptive mechanical model; cardiovascular system; RF network combiner; wireless multicommunication system; smart households; graph method; SI circuit solution; M-FSK intrapulse modulation analysis; subspectral decomposition method; small loop antennas parameter measurement; GTEM cell; radio frequency energy harvesting system; boost power factor correction topology; average current control; critical conduction mode; EKF based position estimators; speed estimators; sensorless DTC; permanent magnet synchronous machines; E-D-Mode InAlN-GaN HFET inverter; low frequency amplifier; real-time multicore systems; genetic algorithm; runnable sequencing; bandgap voltage reference; high-order temperature compensation; two stepped system; train dynamic motion; wheel slip; CAN nodes health monitoring; ADS-B channel; electrical resistance measurement; contact resistance; sensor fusion; IR sensors; Kalman filter;CMOS class-AB amplifier; rendering moving sound source; headphone-based virtual acoustic reality; high spectral quality sinusoidal oscillator; energy based amplitude control; wireless electronic systems; physiological parameters measuring; hidden pacemaker pulses detection; wavelet transform; Hilbert transform; feedback control; electrospinning process; iterated maps; nonlinear dynamics generation; genetic reasoning; finger sign identification; forearm electromyogram; statistical multirate high-resolution signal reconstruction; empirical mode decomposition based denoising approach; RF signal denoising; OFDM system; AWGN channels; feedforward approach; DC cancellation; fully-differential instrumentation amplifiers; fuzzy expert systems; and human gait phase.","1803-7232","978-8-0261-0277-9","10.1109/AE.2014.7011653","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7011653","","","AWGN channels;carrier transmission on power lines;CMOS integrated circuits;compensation;computer vision;contact resistance;electric current control;electric resistance measurement;electroencephalography;electromagnetic compatibility;electromyography;electrospinning;energy harvesting;expert systems;feature extraction;field programmable gate arrays;fingerprint identification;finite element analysis;FIR filters;frequency shift keying;gait analysis;genetic algorithms;graph theory;high electron mobility transistors;Hilbert transforms;human-robot interaction;infrared detectors;instrumentation amplifiers;Kalman filters;loop antennas;low noise amplifiers;matrix convertors;maximum power point trackers;memristors;microsensors;motorcycles;multiprocessing systems;OFDM modulation;operational amplifiers;oscillators;permanent magnet machines;photovoltaic power systems;power factor correction;pressure sensors;PWM invertors;random number generation;rectifiers;resonant power convertors;sensor fusion;sensorless machine control;sigma-delta modulation;signal denoising;signal reconstruction;software radio;synchronous machines;TEM cells;traction current collection;ventilation;virtual instrumentation;virtual reality;wavelet transforms","high-speed analog-to-digital converters;nanometer CMOS technology;pseudo random code regeneration;oscillation frequency value;oscillation-based tests;reconfigurable filter structure;universal embedded controller;matrix converter;continuous-time sigma-delta modulator;integrated LC filter;human-robot cooperation;seismic sensor system;MEMS accelerometer;memristor pinched hysteresis loops;PV panels;MPPT controller;PV power system modelling;PLP feature extraction optimization;LVCSR recognition;MP3 data;dead-time compensation strategy;adaptive harmonic compensator;Cartesian genetic programming;desktop based real time oxygen auto-ventilation;gas monitoring system;homecare respiratory application;subband optimization;EEG-based classification;HART compatible HART line powered communication module;interactive hybrid control-flow checking method;polyphase FIR filter structure;VHDL language;FPGA;B3C converter;heat transfer;moving object searching;virtual instrumentation;ISO26262 motorbikes;nonlinear stabilization;state space energy error feedback;quadrature oscillator;operational transresistance amplifier;quantum computation system emulator;low noise amplifier;SVPWM algorithm;H-bridge power inverter;LCL filter;3D machine vision system;contact strips inspection;railway vehicle current collectors;wrist cuff method;mean arterial pressure;dual-cuff blood pressure system;contactless electrical energy transfer;varying air gap;resonant converter;nonlinear inductance;programmable PWM modulator;OPWM test platform;3D FEM simulation;EMC testing;input current harmonics;voltage-source active rectifier;motion detection system;NiTi pressure sensors;phase coupled oscillator;dissipation normal form;space vector pulse width modulation;RF circuits response;software defined radio system;adaptive mechanical model;cardiovascular system;RF network combiner;wireless multicommunication system;smart households;graph method;SI circuit solution;M-FSK intrapulse modulation analysis;subspectral decomposition method;small loop antennas parameter measurement;GTEM cell;radio frequency energy harvesting system;boost power factor correction topology;average current control;critical conduction mode;EKF based position estimators;speed estimators;sensorless DTC;permanent magnet synchronous machines;E-D-Mode InAlN-GaN HFET inverter;low frequency amplifier;real-time multicore systems;genetic algorithm;runnable sequencing;bandgap voltage reference;high-order temperature compensation;two stepped system;train dynamic motion;wheel slip;CAN nodes health monitoring;ADS-B channel;electrical resistance measurement;contact resistance;sensor fusion;IR sensors;Kalman filter;CMOS class-AB amplifier;rendering moving sound source;headphone-based virtual acoustic reality;high spectral quality sinusoidal oscillator;energy based amplitude control;wireless electronic systems;physiological parameters measuring;hidden pacemaker pulses detection;wavelet transform;Hilbert transform;feedback control;electrospinning process;iterated maps;nonlinear dynamics generation;genetic reasoning;finger sign identification;forearm electromyogram;statistical multirate high-resolution signal reconstruction;empirical mode decomposition based denoising approach;RF signal denoising;OFDM system;AWGN channels;feedforward approach;DC cancellation;fully-differential instrumentation amplifiers;fuzzy expert systems;human gait phase","","","","","","19 Jan 2015","","","IEEE","IEEE Conferences"
"Contents","",,"2011 11th International Conference The Experience of Designing and Application of CAD Systems in Microelectronics (CADSM)","7 Apr 2011","2011","","","IX","XVI","The main aim of CADSM Conference is to provide a possibility to discuss problems of optimization of technological processes of IC manufacturing, main aspects of the development of models and methods of microelectronics devices and technical systems, and, of course, problems that take place during microelectromechanical systems design. Traditionally, the problems of testing and reliability are considered within the framework of the Conference, as well as the new information technologies of automated design and development of learning systems. With an attempt to achieve these objectives, different aspects of the advanced microelectronic design, testing and manufacturing will be presented on the Conference. The topics of the Conference have been very carefully chosen, so that they reflect the crucial issues of CAD. The main topics to discuss this year are the following: 1. modelling and optimization for technological processes. 2. models and methods for radioelectronics device and system design. 3. design of specialized systems and devices. 4. optimal design problems. 5. CAD modern information technology. 6. models and methods for microelectromechanical systems. 7. applied and computer linguistics. The presented papers will cover different areas of design, analysis, simulation and testing of microelectronic circuits and microsystems, as well as power devices. Following our traditions, the discussion on training and technology transfer, as well as education and teaching experience, in the field of design and application of integrated circuits will be held.","","978-966-2191-17-2","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5744552","","","circuit CAD;circuit optimisation;computer aided instruction;electronic engineering education;integrated circuit design;integrated circuit manufacture;integrated circuit reliability;integrated circuit testing;micromechanical devices;teaching;technology CAD (electronics);technology transfer;VLSI","CAD systems;CADSM conference;IC manufacturing;microelectronics devices;microelectromechanical system design;integrated circuit testing;integrated circuit reliability;advanced microelectronic design;technological process modelling;radioelectronics device model;system design;optimal design problems;CAD modern information technology;computer linguistics;microelectronic circuit testing;technology transfer;teaching;power devices;VLSI circuit design","","","","","","7 Apr 2011","","","IEEE","IEEE Conferences"
