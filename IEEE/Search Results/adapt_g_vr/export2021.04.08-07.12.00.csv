"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Robotics and virtual reality: the development of a life-sized 3-D system for the rehabilitation of motor function","J. L. Patton; G. Dawe; C. Scharver; F. A. Mussa-Ivaldi; R. Kenyon","Rehabilitation Inst. of Chicago, IL, USA; NA; NA; NA; NA","The 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society","14 Mar 2005","2004","2","","4840","4843","We have been developing and combining state-of-art devices that allow humans to visualize and feel synthetic objects superimposed on the real world. This effort stems from the need of platform for extending experiments on motor control and learning to realistic human motor tasks and environments, not currently represented in the practice of research. This paper's goal is to outline our motivations, progress, and objectives. Because the system is a general tool, we also hope to motivate researchers in related fields to join in. The platform under development, an augmented reality system combined with a haptic-interface robot, will be a new tool for contributing to the scientific knowledge base in the area of human movement control and rehabilitation robotics. Because this is a prototype, the system will also guide new methods by probing the levels of quality necessary for future design cycles and related technology. Inevitably, it should also lead the way to commercialization of such systems.","","0-7803-8439-3","10.1109/IEMBS.2004.1404339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1404339","Human;Motor learning;Adaptation;Human-machine interface;Teaching;Neurorehabilitation","Rehabilitation robotics;Virtual reality;Humans;Visualization;Motor drives;Augmented reality;Robot control;Control systems;Prototypes;Commercialization","medical robotics;virtual reality;patient rehabilitation;haptic interfaces;biocontrol;biomechanics","rehabilitation robotics;virtual reality;life-sized 3-D system;motor control;motor learning;realistic human motor tasks;haptic-interface robot;human movement control","","13","","12","","14 Mar 2005","","","IEEE","IEEE Conferences"
"An intestinal surgery simulator: real-time collision processing and visualization","L. Raghupathi; L. Grisoni; F. Faure; D. Marchal; M. -. Cani; C. Chaillou","GRAVIR/IMAG Lab., Montbonnet, France; NA; NA; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","13 Sep 2004","2004","10","6","708","718","This research work is aimed toward the development of a VR-based trainer for colon cancer removal. It enables the surgeons to interactively view and manipulate the concerned virtual organs as during a real surgery. First, we present a method for animating the small intestine and the mesentery (the tissue that connects it to the main vessels) in real-time, thus enabling user interaction through virtual surgical tools during the simulation. We present a stochastic approach for fast collision detection in highly deformable, self-colliding objects. A simple and efficient response to collisions is also introduced in order to reduce the overall animation complexity. Second, we describe a new method based on generalized cylinders for fast rendering of the intestine. An efficient curvature detection method, along with an adaptive sampling algorithm, is presented. This approach, while providing improved tessellation without the classical self-intersection problem, also allows for high-performance rendering thanks to the new 3D skinning feature available in recent GPUs. The rendering algorithm is also designed to ensure a guaranteed frame rate. Finally, we present the quantitative results of the simulations and describe the qualitative feedback obtained from the surgeons.","1941-0506","","10.1109/TVCG.2004.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1333668","Index Terms- Virtual reality;physically-based modeling;animation;curve and surface representation.","Intestines;Visualization;Oncological surgery;Animation;Colon;Cancer;Stochastic processes;Object detection;Sampling methods;Algorithm design and analysis","data visualisation;virtual reality;cancer;surgery;computer animation;rendering (computer graphics);medical image processing;user interfaces;simulation;computational geometry;sampling methods","intestinal surgery simulator;real-time collision processing;real-time visualization;VR-based trainer;colon cancer removal;virtual organ;user interaction;virtual surgical tool;stochastic approach;self-colliding object;animation complexity;self-intersection problem;3D skinning feature;virtual reality;physically-based model","Algorithms;Biomedical Engineering;Colonic Neoplasms;Computer Graphics;Computer Simulation;Computer Systems;Computer-Assisted Instruction;Digestive System Surgical Procedures;Digestive System Surgical Procedures;Humans;Intestine, Small;Intestine, Small;Models, Anatomic;User-Computer Interface","34","3","41","","13 Sep 2004","","","IEEE","IEEE Journals"
"QoE-Driven Resource Allocation Optimized for Delay-Sensitive VR Video Uploading over Cellular Network","J. Yang; J. Luo; D. Meng; J. -N. Hwang","Chongqing University of Posts & Telecom, Chongqing,School of Communication and Information Engineering,China; Electronic Information and Networking Research Institute, Chongqing University of Posts & Telecom,Chongqing,China; University of Washington,Electrical Engineering Department,Seattle,USA; University of Washington,Electrical Engineering Department,Seattle,USA","2019 IEEE Symposium on Computers and Communications (ISCC)","27 Jan 2020","2019","","","1","6","Uploading Virtual Reality (VR) video over cellular networks is expected to boom in near future, as general consumers could generate high-quality VR videos with portable 360-degree cameras and are willing to share with others. Con-sequently, concerns of uplink bandwidth and delay arose for current popular technology of tile-based VR video streaming, which requires high quality video to transcode into multiple representations for further adaptive streaming. Motivated by this, we proposed a novel scheme for uplink delivery of tile-based VR video over cellular network, in which encoding bit rate of each tile is determined by uplink resource allocation (RA), and quality of content (QoC) contribution of each tile and channel quality of user equipments (UEs) are jointly considered during RA. Moreover, the RA problem is formulated as a frequency and time dependent non-deterministic polynomial(NP)-hard problem, which can be effectively solved by our proposed approximate convex algorithm. Simulation results show that the proposed algorithm can achieve higher utility, that is higher total quality of experience (QoE) for viewers.","2642-7389","978-1-7281-2999-0","10.1109/ISCC47284.2019.8969778","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8969778","VR video;quality of experience (QoE);resource allocation;SC-FDMA;saliency;utility optimization","Streaming media;Uplink;Bit rate;Encoding;Quality of experience;Downlink;Resource management","cellular radio;computational complexity;convex programming;delays;quality of experience;resource allocation;transcoding;video coding;video streaming;virtual reality","QoE-driven resource allocation;delay-sensitive VR video uploading;cellular network;high-quality VR videos;uplink bandwidth;tile-based VR video streaming;high quality video;adaptive streaming;uplink delivery;uplink resource allocation;channel quality;RA problem;quality of experience;portable 360-degree cameras;virtual reality video;transcoding;quality of content;user equipments;frequency-and-time dependent nondeterministic polynomial-hard problem;NP-hard problem;approximate convex algorithm","","1","","16","","27 Jan 2020","","","IEEE","IEEE Conferences"
"An Adaptive Sequential Learning Algorithm for Robust Estimation using the Fair Penalty Function","G. Deng","Department of Electronic Engineering, La Trobe University, Bundoora, Victoria 3086, Australia. d.deng@latrobe.edu.au","2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07","4 Jun 2007","2007","3","","III-737","III-740","In this paper we propose an alternative way to developing a robust and adaptive sequential algorithm for estimating the unknown impulse response of a linear system. Our approach is based on formulating the problem as a maximum penalized likelihood (MPL) problem. We use the Fair penalty function as the generalized log-likelihood and a quadratic function to play a regularization role. The MPL formulation also leads naturally to adaptive schemes for learning the regularization and scale parameters. The robustness of the proposed algorithm to impulsive noise is demonstrated through mathematical analysis and numerical simulations.","2379-190X","1-4244-0727-3","10.1109/ICASSP.2007.366785","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4217815","robust sequential learning;maximum penalized likelihood","Noise robustness;Signal processing algorithms;Least squares approximation;Linear systems;Adaptive filters;Iterative algorithms;Mathematical analysis;Numerical simulation;Supervised learning;Adaptive signal processing","computer science education;electrical engineering education;impulse noise;maximum likelihood estimation;numerical analysis;signal processing;transient response","adaptive sequential learning algorithm;robust estimation;fair penalty function;impulse response;maximum penalized likelihood;generalized log-likelihood;quadratic function;adaptive schemes;impulsive noise;mathematical analysis;numerical simulations","","","","8","","4 Jun 2007","","","IEEE","IEEE Conferences"
"Full-duplex multichannel communication: real-time implementations in a general framework","W. Herbordt; H. Buchner; W. Kellermann; R. Rabenstein; S. Spors; H. Teutsch","Telecommun. Lab., Erlangen-Nurnberg Univ., Erlangen, Germany; Telecommun. Lab., Erlangen-Nurnberg Univ., Erlangen, Germany; Telecommun. Lab., Erlangen-Nurnberg Univ., Erlangen, Germany; Telecommun. Lab., Erlangen-Nurnberg Univ., Erlangen, Germany; Telecommun. Lab., Erlangen-Nurnberg Univ., Erlangen, Germany; Telecommun. Lab., Erlangen-Nurnberg Univ., Erlangen, Germany","2003 International Conference on Multimedia and Expo. ICME '03. Proceedings (Cat. No.03TH8698)","18 Aug 2003","2003","3","","III","49","In this combustion, we embed full-duplex multichannel communication interfaces for tele-presence systems into a general framework. On the reproduction side, we consider a wide range of multichannel acoustic rendering techniques including traditional stereophony, '5.1' systems, and wave field synthesis using loud speaker arrays for sound immersion. On the recording side, microphone arrays are discussed for capturing clean desired signals with spatial information. Based on this general framework, real-time implementations of such full-duplex multichannel communication systems are then described. We combine wave field synthesis with multichannel acoustic echo cancellation and adaptive beamforming and discuss a real-time implementation on standard desktop and laptop PCs.","","0-7803-7965-9","10.1109/ICME.2003.1221245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1221245","","Acoustic waves;Signal synthesis;Microphone arrays;Combustion;Rendering (computer graphics);Loudspeakers;Acoustic arrays;Disk recording;Real time systems;Echo cancellers","telecommunication channels;computer interfaces;loudspeakers;microphones;echo suppression;array signal processing;laptop computers;virtual reality;acoustic signal processing","full-duplex multichannel communication system;communication interfaces;telepresence systems;multichannel acoustic rendering techniques;traditional stereophony;wave field synthesis;loud speaker arrays;sound immersion;microphone arrays;multichannel acoustic echo cancellation;adaptive beamforming;standard desktop;laptop PC","","1","","15","","18 Aug 2003","","","IEEE","IEEE Conferences"
"A hybrid-based 3D streaming framework for mobile devices over IoT environments","M. A. Ja'afreh; M. Aloqaily; I. A. Ridhawi; N. Mostafa","School of Electrical Engineering and Computer Science (EECS), University of Ottawa, Ottawa, Canada; College of Engineering and Technology, American University of the Middle East (AUM), Egaila, Kuwait; College of Engineering and Technology, American University of the Middle East (AUM), Egaila, Kuwait; College of Engineering and Technology, American University of the Middle East (AUM), Egaila, Kuwait","2018 Third International Conference on Fog and Mobile Edge Computing (FMEC)","31 May 2018","2018","","","211","216","Today, we are witnessing the evolution of the Internet of Things (IoT), where trillions of objects are interconnected and starting to re-define the design of the Internet and its services. In fact, IoT plays a prominent role in the realization of the smart city paradigm. One of the highly demanded services in a smart city infrastructure is to enable Networked Virtual Environment (NVE) class of applications, like collaborative Augmented Reality (AR), virtual walkthroughs, and Massively Multiplayer Online games (MMOGs), on mobile things. Perversely, pre-downloading and rendering a complex 3D graphics is very computationally intensive and neither commensurate with the current mobiles hardware specifications and their dynamic mobility natures nor with the available wireless bandwidth. In addition, most IoT environments are generally deployed via a service-centric architecture which obviously suffers from a single point of failure, service latency, and scalability issues between IoT gateways and mobile devices. In order to address these problems, a framework that combines the pros of both central and distributed based schemes has been proposed. The proposed hybrid framework, referred to as STREAMIT, facilitates the 3D texture streaming over thin devices to cope with the mobile hardware resources and alleviate the challenges of client-server and ad-hoc 3D streaming. In addition, STREAMIT implements adaptive strategies to select, prioritize, and convey 3D texture graphical objects that only contribute to the user's visible scene. STREAMIT has been evaluated using NS3 discrete network simulator where extensive experiments have confirmed big achievements in terms of resource utilization, latency, throughput, and overhead.","","978-1-5386-5896-3","10.1109/FMEC.2018.8364067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8364067","Internet of things;Networked Virtual Environment;3D streaming;Smart city;Mobile devices","Three-dimensional displays;Mobile handsets;Streaming media;Smart cities;Rendering (computer graphics);Real-time systems;Multimedia communication","augmented reality;client-server systems;computer games;Internet of Things;internetworking;mobile computing;smart cities;virtualisation","dynamic mobility natures;Internet of Things;Networked Virtual Environment;Massively Multiplayer Online games;STREAMIT hybrid framework;3D texture streaming;ad-hoc 3D streaming;NS3 discrete network simulator;current mobiles hardware specifications;complex 3D graphics;Multiplayer Online games;virtual walkthroughs;collaborative Augmented Reality;smart city infrastructure;smart city paradigm;hybrid-based 3D streaming framework;NS3 discrete network;3D texture graphical objects;client-server;mobile hardware resources;STREAMIT;central distributed based schemes;mobile devices;IoT gateways;service latency;service-centric architecture;IoT environments;available wireless bandwidth","","1","","15","","31 May 2018","","","IEEE","IEEE Conferences"
"A new approach to quantify elbow position sense using an exoskeleton and a virtual reality display","A. Deblock-Bellamy; C. S. Batcho; C. Mercier; A. K. Blanchette","CIRRIS, Universite Laval, Quebec city, Canada; CIRRIS, Universite Laval, Quebec city, Canada; CIRRIS, Universite Laval, Quebec city, Canada; CIRRIS, Universite Laval, Quebec city, Canada","2017 International Conference on Virtual Rehabilitation (ICVR)","14 Aug 2017","2017","","","1","2","Most of the proprioception assessments commonly used are not adapted for individuals who present multiple impairments after a stroke. Indeed, these assessments require certain motor or cognitive functions that are generally affected after a stroke. We have therefore developed a protocol, combining a robotic device and a virtual reality display, that enables the assessment of position sense without requiring active movement in the evaluated arm, involving the opposite arm or relying on working memory. As a preliminary step of validation, elbow joint position sense of healthy young adults was quantified and test-retest reliability was studied. Results show that this protocol can quantify elbow position sense of healthy young adults (mean detection threshold: around 7 degrees), with a fair to good test-retest reliability.","2331-9569","978-1-5090-3053-8","10.1109/ICVR.2017.8007518","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007518","Proprioception;assessment;reliability;robotics;virtual reality;upper limb","Reliability;Elbow;Exoskeletons;Protocols;Robot sensing systems;Virtual reality","medical robotics;patient rehabilitation;virtual reality","elbow position;exoskeleton;virtual reality display;proprioception assessments;cognitive functions;robotic device;working memory","","","","8","","14 Aug 2017","","","IEEE","IEEE Conferences"
"Fractional Horsepower Dynamometer - A General Purpose Hardware-In-The-Loop Real-Time Simulation Platform for Nonlinear Control Research and Education","Y. Tarte; Y. Chen; W. Ren; K. Moore","Student Member, IEEE, Center for Self-Organizing and Intelligent Systems (CSOIS), Dept. of Electrical and Computer Engineering, 4160 Old Main Hill, Utah State University, Logan, UT 84322-4160, USA; Senior Member, IEEE, Center for Self-Organizing and Intelligent Systems (CSOIS), Dept. of Electrical and Computer Engineering, 4160 Old Main Hill, Utah State University, Logan, UT 84322-4160, USA; Member, IEEE, Center for Self-Organizing and Intelligent Systems (CSOIS), Dept. of Electrical and Computer Engineering, 4160 Old Main Hill, Utah State University, Logan, UT 84322-4160, USA; Senior Member, IEEE, Division of Engineering, Colorado School of Mines, Golden, Colorado 80401-1887, USA. E-mail: yqchen@ece.usu.edu; Tel. (435)797-0148; Fax: (435)797-3054.","Proceedings of the 45th IEEE Conference on Decision and Control","7 May 2007","2006","","","3912","3917","A fractional horsepower dynamometer was developed as a general purpose hardware-in-the-loop real-time simulation platform to emulate mechanical nonlinearities such as frictions, state-dependent disturbances, etc. This lab system can be used as a research platform to test various nonlinear control schemes. This platform can also be used as a laboratory experiment for ECE5320 ""Mechatronics"" and ECE7330 ""Nonlinear and Adaptive Control"" courses at Utah State University. The novelty of this platform lies in its ability to generate an arbitrary external torque load disturbance, using a controllable hysteresis brake, to a DC motor plant. Therefore, many nonlinear systems and controls can be emulated physically. In this paper, we include some sample experimental results to show the versatility of the dynamometer in emulating nonlinearities and the effectiveness in real-time testing of advanced nonlinear control schemes","0191-2216","1-4244-0171-2","10.1109/CDC.2006.377021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4177998","Nonlinear control;adaptive control;hardware-in-the-loop real-time simulation;real-time control systems rapid prototyping","Nonlinear control systems;Control systems;Friction;System testing;Laboratories;Mechatronics;Adaptive control;DC generators;Torque control;Hysteresis","control engineering education;control nonlinearities;dynamometers;fractional-horsepower motors;nonlinear control systems","fractional horsepower dynamometer;hardware-in-the-loop real-time simulation;nonlinear control research;nonlinear control education;mechanical nonlinearities;torque load disturbance;controllable hysteresis brake;DC motor plant;nonlinear system;adaptive control","","23","","13","","7 May 2007","","","IEEE","IEEE Conferences"
"Transparent tactile feeling device for touch-screen interface","F. Arai; N. Iwata; T. Fukuda","Dept. of Micro-Nano Syst. Eng., Nagoya Univ., Japan; Dept. of Micro-Nano Syst. Eng., Nagoya Univ., Japan; Dept. of Micro-Nano Syst. Eng., Nagoya Univ., Japan","RO-MAN 2004. 13th IEEE International Workshop on Robot and Human Interactive Communication (IEEE Catalog No.04TH8759)","10 Jan 2005","2004","","","527","532","We propose a transparent tactile feeling input device on the touch-screen interface, which provides actual keystroke and tactile key feeling without preventing the function of the touch-screen interface. Without using mechatronics elements such as force sensor or actuators, the device can adapt to the touch-screen interface used in general. In order to realize tactile feeling of clicking, we referred to a specific shape of the conventional switch in design process, and formed structure of the input device with the transparent silicone elastomer. Consequently, the experiment shows transparent haptic device realized click feeling on the touch-screen display.","","0-7803-8570-5","10.1109/ROMAN.2004.1374816","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1374816","","Switches;Haptic interfaces;Force sensors;Computer displays;Feedback;Mechatronics;Actuators;Computer interfaces;Home computing;Personal digital assistants","touch sensitive screens;haptic interfaces;elastomers;touch (physiological)","transparent tactile feeling device;touch screen interface;mechatronics elements;transparent silicone elastomer;transparent haptic device;click feeling;touch screen display","","1","4","13","","10 Jan 2005","","","IEEE","IEEE Conferences"
"Dynamic Pose Tracking Performance Evaluation of HTC Vive Virtual Reality System","M. S. Ikbal; V. Ramadoss; M. Zoppi","Department of Mechanical, Energy, Management, and Transportation Engineering, PMAR Robotics Group, University of Genoa, Genoa, (GE), Italy; Department of Mechanical, Energy, Management, and Transportation Engineering, PMAR Robotics Group, University of Genoa, Genoa, (GE), Italy; Department of Mechanical, Energy, Management, and Transportation Engineering, PMAR Robotics Group, University of Genoa, Genoa, (GE), Italy","IEEE Access","6 Jan 2021","2021","9","","3798","3815","Virtual reality tracking devices are rapidly becoming the go-to system for cost-effective motion tracking solutions across different communities such as robotics, biomechanics, sports, rehabilitation, motion simulators, etc. This article focuses on the spatial tracking performance of HTC Vive's lighthouse tracking system (VLTS) devices (tracker, controller, and head mount display). A comprehensive literature survey on the performance analysis of VLTS on the various aspects is presented along with its shortcomings in terms of spatial tracking evaluation. The two key limitations have been identified: in static cases, there is a lack of standard procedures and criteria, and in dynamic cases, the entire study of spatial tracking. We address the first by assessing VLTS using the optical tracking system standard specified by ASTM International, and the latter by revising the standards to determine the upper-velocity limit for reliable tracking. The findings are substantiated with the trajectories of human wrist motion. Each evaluation's results are systematically analyzed with statistical hypothesis tests and criteria fulfillment. Comau NS16, an industrial serial robot, was used as the ground truth motion generator due to its repeatability and 6 degrees of workspace freedom. One of the major reasons for not having more generalized spatial tracking studies is that the tracking performance heavily depends on the configurations of the setup, work volume, environment, etc. Thus, the guidelines for configuring VLTS and the approach adapted from ASTM standards for evaluating VLTS for custom applications using our reported findings for both static and dynamic cases are included in the appendix.","2169-3536","","10.1109/ACCESS.2020.3047698","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9309218","Lighthouse tracking;motion tracking;performance evaluation and bench-marking;virtual reality and interfaces","Tracking;Standards;Performance evaluation;Dynamics;Service robots;Base stations;Virtual reality","biomechanics;CAD;collision avoidance;helmet mounted displays;industrial manipulators;manipulator kinematics;medical robotics;mobile robots;motion control;motion estimation;object tracking;optical tracking;patient rehabilitation;pose estimation;small-to-medium enterprises;target tracking;tracking;virtual reality","dynamic pose tracking performance evaluation;HTC Vive virtual reality system;virtual reality tracking devices;cost-effective motion;motion simulators;spatial tracking performance;HTC Vive's lighthouse tracking system;head mount display;comprehensive literature survey;performance analysis;VLTS;spatial tracking evaluation;static cases;standard procedures;dynamic cases;optical tracking system standard;upper-velocity limit;reliable tracking;human wrist motion;statistical hypothesis tests;criteria fulfillment;industrial serial robot;ground truth motion generator;generalized spatial tracking studies;ASTM standards","","","","35","CCBY","28 Dec 2020","","","IEEE","IEEE Journals"
"A generalized framework for interactive dynamic simulation for multirigid bodies","Wookho Son; Kyunghwan Kim; N. M. Amato; J. C. Trinkle","Virtual Reality Dept., Electron. & Telecommun. Res. Inst., Taejon, South Korea; NA; NA; NA","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","22 Mar 2004","2004","34","2","912","924","This paper presents a generalized framework for dynamic simulation realized in a prototype simulator called the Interactive Generalized Motion Simulator (I-GMS), which can simulate motions of multirigid-body systems with contact interaction in virtual environments. I-GMS is designed to meet two important goals: generality and interactivity. By generality, we mean a dynamic simulator which can easily support various systems of rigid bodies, ranging from a single free-flying rigid object to complex linkages such as those needed for robotic systems or human body simulation. To provide this generality, we have developed I-GMS in an object-oriented framework. The user interactivity is supported through a haptic interface for articulated bodies, introducing interactive dynamic simulation schemes. This user-interaction is achieved by performing push and pull operations via the PHANToM haptic device, which runs as an integrated part of I-GMS. Also, a hybrid scheme was used for simulating internal contacts (between bodies in the multirigid-body system) in the presence of friction, which could avoid the nonexistent solution problem often faced when solving contact problems with Coulomb friction. In our hybrid scheme, two impulse-based methods are exploited so that different methods are applied adaptively, depending on whether the current contact situation is characterized as ""bouncing"" or ""steady."" We demonstrate the user-interaction capability of I-GMS through online editing of trajectories of a 6-degree of freedom (dof) articulated structure.","1941-0492","","10.1109/TSMCB.2003.818434","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1275525","","Object oriented modeling;Biological system modeling;Haptic interfaces;Friction;Virtual prototyping;Virtual environment;Couplings;Robots;Humans;Imaging phantoms","multi-robot systems;mobile robots;digital simulation;object-oriented methods;haptic interfaces;virtual reality","interactive dynamic simulation;multirigid bodies;prototype simulator;Interactive Generalized Motion Simulator;virtual environments;free-flying rigid object;robotic systems;human body simulation;object-oriented framework;haptic interface;articulated bodies;PHANTOM haptic device;impulse-based methods","Algorithms;Biomechanics;Computer Simulation;Humans;Joints;Models, Biological;Movement;Nonlinear Dynamics;Robotics;User-Computer Interface","14","","62","","22 Mar 2004","","","IEEE","IEEE Journals"
"An infrastructure for realizing custom-tailored augmented reality user interfaces","W. Broll; I. Lindt; J. Ohlenburg; I. Herbst; M. Wittkamper; T. Novotny","Fraunhofer Inst. for Appl. Inf. Technol., St. Augustin, Germany; Fraunhofer Inst. for Appl. Inf. Technol., St. Augustin, Germany; Fraunhofer Inst. for Appl. Inf. Technol., St. Augustin, Germany; Fraunhofer Inst. for Appl. Inf. Technol., St. Augustin, Germany; Fraunhofer Inst. for Appl. Inf. Technol., St. Augustin, Germany; Fraunhofer Inst. for Appl. Inf. Technol., St. Augustin, Germany","IEEE Transactions on Visualization and Computer Graphics","26 Sep 2005","2005","11","6","722","733","Augmented reality (AR) technologies are rapidly expanding into new application areas. However, the development of AR user interfaces and appropriate interaction techniques remains a complex and time-consuming task. Starting from scratch is more common than building upon existing solutions. Furthermore, adaptation is difficult, often resulting in poor quality and limited flexibility with regard to user requirements. In order to overcome these problems, we introduce an infrastructure for supporting the development of specific AR interaction techniques and their adaptation to individual user needs. Our approach is threefold: a flexible AR framework providing independence from particular input devices and rendering platforms, an interaction prototyping mechanism allowing for fast prototyping of new interaction techniques, and a high-level user interface description, extending user interface descriptions into the domain of AR. The general usability and applicability of the approach is demonstrated by means of three example AR projects.","1941-0506","","10.1109/TVCG.2005.90","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512022","Index Terms- Distributed systems;distributed applications;multimedia information systems;artificial;augmented;and virtual realities;user interfaces;collaborative computing;graphics systems;distributed/network graphics;methodology and techniques;device independence;graphics data structures and data types;interaction techniques;three-dimensional graphics and realism;virtual reality.","Augmented reality;User interfaces;Virtual reality;Application software;Graphics;Prototypes;Computer interfaces;Wearable computers;Computer displays;Iris","augmented reality;data structures;groupware;human computer interaction;multimedia computing;rendering (computer graphics);user interfaces","custom-tailored augmented reality;user interface;rendering platform;interaction prototyping mechanism;distributed system;distributed application;multimedia information systems;artificial reality;augmented reality;virtual reality;collaborative computing;graphics system;distributed-network graphics;device independence;graphics data structure;data type;3D graphics","Algorithms;Computer Simulation;Computer Systems;Cybernetics;Data Display;Environment;Imaging, Three-Dimensional;Man-Machine Systems;Models, Theoretical;Online Systems;User-Computer Interface","18","13","44","","26 Sep 2005","","","IEEE","IEEE Journals"
"Time-Variant Visual Attention in 360-Degree Video Playback","H. Huang; J. Chen; H. Xue; Y. Huang; T. Zhao","College of Physics and Information Engineering, Fuzhou University, Fuzhou, China; College of Physics and Information Engineering, Fuzhou University, Fuzhou, China; College of Physics and Information Engineering, Fuzhou University, Fuzhou, China; College of Physics and Information Engineering, Fuzhou University, Fuzhou, China; College of Physics and Information Engineering, Fuzhou University, Fuzhou, China","2018 IEEE International Symposium on Haptic, Audio and Visual Environments and Games (HAVE)","29 Nov 2018","2018","","","1","5","The user visual attention has been playing an imperative role in visual Quality of Experience (QoE) modeling. In recent years, researchers have developed numerous visual attention models for images and videos. However, existing studies on visual attention generally perform on spatial domain (i.e. pictures) without consideration on time-variant user attention. Besides, the user attention on immersive video playback has not been well investigated in Virtual Reality (VR) environment. In this paper, we design subjective experiments to acquire the user attention during 360-degree video playback, in order to characterize the visual attention changes on time axis. We compare and model the temporal attentions in two scenarios: 360-degree video and conventional 2D video display. It is observed in video display, the user attention needs a short period (~ 30 seconds) to concentrate to a relatively stable level. Within this period, the user attention to 360-degree video is significantly lower than that to traditional 2D videos, which shows that the users are relatively difficult to adapt to VR display. Therefore, short videos less than 30 seconds, especially short 360-degree videos, are not preferable in subjective video quality assessment, although they have been tested in some scenarios. We hope this conclusion would conduce to QoE modeling during video display of VR environment.","","978-1-5386-5838-3","10.1109/HAVE.2018.8547419","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8547419","Virtual Reality (VR);360-degree video;visual attention;Quality of Experience (QoE);visual quality","Visualization;Two dimensional displays;Quality of experience;Resists;Solid modeling;Video recording;Quality assessment","data visualisation;quality of experience;video cameras;video signal processing;video streaming;virtual reality","time-variant visual attention;360-degree video playback;user visual attention;time-variant user attention;immersive video playback;visual attention changes;temporal attentions;video display;short videos;subjective video quality assessment;visual quality;visual attention models;quality of experience modeling;VR environment;QoE modeling;virtual reality environment","","1","","17","","29 Nov 2018","","","IEEE","IEEE Conferences"
"Toward Emotionally Adaptive Virtual Reality for Mental Health Applications","S. Bermúdez i Badia; L. V. Quintero; M. S. Cameirão; A. Chirico; S. Triberti; P. Cipresso; A. Gaggioli","Madeira Interactive Technologies Institute, Funchal, Portugal; Madeira Interactive Technologies Institute, Funchal, Portugal; Madeira Interactive Technologies Institute, Funchal, Portugal; Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy; Department of Oncology and Hemato-Oncology, University of Milan, Milan, Italy; Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy; Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy","IEEE Journal of Biomedical and Health Informatics","4 Sep 2019","2019","23","5","1877","1887","Here, we introduce the design and preliminary validation of a general-purpose architecture for affectivedriven procedural content generation in virtual reality (VR) applications in mental health and wellbeing. The architecture supports seven commercial physiological sensing technologies and can be deployed in immersive and nonimmersive VR systems. To demonstrate the concept, we developed the “The Emotional Labyrinth,” a non-linear scenario in which navigation in a procedurally generated three-dimensional maze is entirely decided by the user, and whose features are dynamically adapted according to a set of emotional states. During navigation, affective states are dynamically represented through pictures, music, and animated visual metaphors chosen to represent and induce affective states. The underlying hypothesis is that exposing users to multimodal representations of their affective states can create a feedback loop that supports emotional self-awareness and fosters more effective emotional regulation strategies. We carried out a first study to, first, assess the effectiveness of the selected metaphors in inducing target emotions, and second, identify relevant psycho-physiological markers of the emotional experience generated by the labyrinth. Results show that the Emotional Labyrinth is overall a pleasant experience in which the proposed procedural content generation can induce distinctive psychophysiological patterns, generally coherent with the meaning.","2168-2208","","10.1109/JBHI.2018.2878846","Fundação para a Ciência e Tecnologia; European Commission; Fondazione Cariplo; UCSC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516285","Emotion regulation;physiological computing;physiology-driven VR;procedural content generation","Physiology;Biological control systems;Games;Heart rate;Stress;Biomedical monitoring;Computer architecture","affective computing;computer animation;computer games;emotion recognition;health care;medical computing;music;physiology;psychology;user interfaces;virtual reality","mental health applications;general-purpose architecture;emotional states;affective states;music;emotional self-awareness;emotional experience;emotional adaptive virtual reality;physiological sensing technologies;The Emotional Labyrinth;visual metaphor animation;psycho-physiological markers","Adult;Electrocardiography;Electromyography;Emotions;Female;Humans;Male;Mental Health;Psychophysiology;Virtual Reality;Young Adult","","","74","Traditional","31 Oct 2018","","","IEEE","IEEE Journals"
"A Critical Review of Virtual Reality and Geographical Information Systems for Management of the Built Environment","R. Franklin; D. Heesom; A. Felton","University of Wolverhampton; Sch. of Eng. & the Built Environ., Wolverhampton Univ.; Sch. of Eng. & the Built Environ., Wolverhampton Univ.","Tenth International Conference on Information Visualisation (IV'06)","24 Jul 2006","2006","","","349","356","In the field of urban planning, virtual reality systems are currently used as a consultation tool providing the ability to demonstrate the impact of a proposal on the environment. VR simulation models can be driven in real time by the client and adapted by the designer in response to the feedback from architects, planners and also the general public. Within the planning process, GIS systems are often used to analyse geographic data and real time VR has been used as a medium to view the results of data calculations. However, previous initiatives that have integrated VR and GIS to assist in urban planning have focused primarily on the aesthetics of development locations. This paper proposes the development framework of a novel system that allows users to interact with 3D visual data and more traditional GIS data to perform complex 'what if' scenarios in real time. The results of the queries will then be visualised not as text or 2D information, but in real time 3D","2375-0138","0-7695-2602-0","10.1109/IV.2006.6","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1648284","","Virtual reality;Management information systems;Environmental management;Information management;Geographic Information Systems;Urban planning;Real time systems;Proposals;Feedback;Process planning","data visualisation;geographic information systems;town and country planning;virtual reality","virtual reality;geographical information system;urban planning;VR simulation model;GIS system;3D visual data;real time 3D visualisation","","3","","21","","24 Jul 2006","","","IEEE","IEEE Conferences"
"Computational Glasses: Vision Augmentations Using Computational Near-Eye Optics and Displays","J. Sutton; T. Langlotz; Y. Itoh",University of Otago; University of Otago; Tokyo Institute of Technology,"2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","9 Jan 2020","2019","","","438","442","Wearable computing devices are small enough that they can be worn on the body and are a constant companion to the user. While many wearable devices have been associated with monitoring health or managing diseases, head-mounted displays are traditionally linked to Augmented and Virtual Reality, and generally overlay 3D information that supports professionals or for edutainment. This is surprising as prescription glasses, their traditional siblings, are widely accepted as a standard device for managing focusing errors of the human eye. In this work, we want to make the case for Computational Glasses that utilise technologies from optical see-through head-mounted displays or computational optics to compensate visual impairments. We will introduce some of the seminal works in the field as well as introduce our own work in the field. We will also include some of the challenges for doing research on Computational Glasses as well as give an outlook for future developments.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951961","Computational-Glasses;Augmented-Human;OSTHMD;Near-Eye-Optics;Near-Eye-Display;Vision-Aid;Vision-Augmentation;Head-mounted-Displays","Glass;Prototypes;Cameras;Adaptive optics;Visualization;Image color analysis","augmented reality;handicapped aids;helmet mounted displays;wearable computers","Computational Glasses;vision augmentations;wearable computing devices;health monitoring;optical see-through head-mounted displays;prescription glasses;standard device;human eye;focusing error management;computational near-eye optics;disease management;visual impairment compensation;virtual reality;augmented reality;overlay 3D information;edutainment","","","","18","","9 Jan 2020","","","IEEE","IEEE Conferences"
"Control architecture of parallel and spherical driving simulators and related human factors","M. Maza; S. Val; S. Baselga","Transp. Area-Mechanical Eng. Dept., Zaragoza Univ., Spain; NA; NA","Proceedings 10th IEEE International Workshop on Robot and Human Interactive Communication. ROMAN 2001 (Cat. No.01TH8591)","6 Aug 2002","2001","","","541","545","Driving simulators are a powerful tool that enable one to carry out studies in different fields, like human behavior and response to stimuli, control algorithms to simulate vehicle motion with high fidelity, etc. Research on safety factors in land vehicles requires the use of advanced techniques. Thus, the implementation of a simulator motion base drive logic, able to imitate typical vehicle maneuvers, requires a good control architecture, giving the user a complete sensation of reality. In a general way, any land vehicle motion can be simulated by changing and adapting parameters either in the simulator motion base control algorithm or in the vehicle computer model. Thus, the authors developed two types of simulator architectures, based on the classical 6-DOF Stewart platform and on the original 4-DOF spherical platform. The experience gained in the last years with the development and use of such simulators leads to some interesting conclusions related to the general simulator architecture, control algorithms and related human factors.","","0-7803-7222-0","10.1109/ROMAN.2001.981960","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=981960","","Human factors;Computational modeling;Vehicle driving;Motion control;Biological system modeling;Automotive engineering;Land vehicles;Computer architecture;Computer simulation;Transportation","digital simulation;control system analysis computing;vehicles;mechanical engineering computing;human factors;motion control","control architecture;parallel driving simulators;spherical driving simulators;human behavior;control algorithms;vehicle motion simulation;land vehicles;advanced techniques;simulator motion base drive logic;typical vehicle maneuvers;land vehicle motion simulation;simulator motion base control algorithm;vehicle computer model;simulator architectures;classical 6-DOF Stewart platform;4-DOF spherical platform;simulator architecture;human factors","","1","","8","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Simulating Plant Growth with Multi-Agent System","J. Chen; H. Liu; X. Zhang","School of Information Science and Engineering, Shandong Normal University, Jinan, P.R.. China, 250014; Information Management College, Shandong Economy University, Jinan, P.R.. China, 250014. chenjie112358@163.com; School of Information Science and Engineering, Shandong Normal University, Jinan, P.R.. China, 250014; Information Management College, Shandong Economy University, Jinan, P.R.. China, 250014","2007 2nd International Conference on Pervasive Computing and Applications","29 Oct 2007","2007","","","44","49","Virtual reality technique is widely used in pervasive computing. Plant model is a hotspot study issue in this area. It has been generally recognized that 3D plant model based on growth can make the morphologies of plants lifelike. The paper has put forward a plant growing model based on evolvement of multi-agent system. With multi-agent system, plant growing process can be really simulated. Usually, a plant has many growth points which are growing synchronously. Grow points grow out branches and leaves, and germinate new grow points. Grow points are independent in behavior and adaptable to circumstance, they compete and co-operate with each other, and finally form the shape of plant. So it is nature to employ an agent to simulate behavior of growth point, and employ a multi-agent system to simulate behavior of plant growth system.","","978-1-4244-0970-9","10.1109/ICPCA.2007.4365410","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4365410","Plant Model;Multi-Agent System;Virtual Reality;Nature Scene Simulating","Multiagent systems;Computational modeling;Virtual reality;Layout;Pervasive computing;Logic;Educational institutions;Character recognition;Nonlinear dynamical systems;Chaos","botany;multi-agent systems;solid modelling;ubiquitous computing;virtual reality","multiagent system;virtual reality technique;pervasive computing;plant growing model;grow points;plant growth system","","1","","10","","29 Oct 2007","","","IEEE","IEEE Conferences"
"3D Interaction assistance through context-awareness","Y. Dennemont; G. Bouyer; S. Otmane; M. Mallem","IBISC Laboratory, Evry University, France; IBISC Laboratory, Evry University, France; IBISC Laboratory, Evry University, France; IBISC Laboratory, Evry University, France","2012 IEEE Virtual Reality Workshops (VRW)","12 Apr 2012","2012","","","103","104","This work focuses on enabling 3D interaction assistance by adding adaptivity depending on the tasks, objectives, and the general interaction context. We model the context using Conceptual Graphs (CG) based on an ontology. Including CG in our scene manager (Virtools) allows us to add semantic information and to describe the available tools. We handle rules leading to adaptation with a logic programming layer (Prolog+CG) included in the Amine platform. This project is a step towards Intelligent Virtual Environments, which proposes a hybrid solution by adding a separate semantic reasoning to classic environments. The first case study automatically manages few modalities depending on the distance to objects, user movement, available tools and modality risks.","2375-5334","978-1-4673-1246-2","10.1109/VR.2012.6180903","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180903","I.3.6 [Methodology and Techniques Subjects]: Interaction Techniques;[I.3.7]: Computer Graphics — Virtual reality;I.2.4 [Computing Methodologies]: Knowledge Representation Formalism and Methods","Context;Engines;Semantics;Cognition;Three dimensional displays;Usability;Visualization","human computer interaction;ontologies (artificial intelligence);PROLOG;ubiquitous computing;virtual reality","3D interaction assistance;context-awareness;conceptual graphs;ontology;scene manager;Virtools;logic programming layer;Prolog+CG;Amine platform;intelligent virtual environments;semantic reasoning","","","","7","","12 Apr 2012","","","IEEE","IEEE Conferences"
"Gyrolog – Creating a 3-Dimensional Digital Collection of Classical Gyro Instruments","M. Niklaus; K. Zhan; J. F. Wagner","University of Stuttgart,Chair of Adaptive Structures in Aerospace Engineering,70569 Stuttgart,GERMANY; University of Stuttgart,Chair of Adaptive Structures in Aerospace Engineering,70569 Stuttgart,GERMANY; University of Stuttgart,Chair of Adaptive Structures in Aerospace Engineering,70569 Stuttgart,GERMANY","2019 DGON Inertial Sensors and Systems (ISS)","30 Dec 2019","2019","","","1","23","Gyro instruments represent a demanding technology, which became increasingly important during the 20th century. Its significant influence on navigation and guidance of especially maritime and aerospace vehicles make them more and more interesting for historians of technology and museums. Furthermore, they form the essential background for understanding the origin of modern inertial systems.The Chair of Adaptive Structures in Aerospace Engineering of the University of Stuttgart maintains a unique, large collection of all kinds of classic, rotating mass gyro instruments like artificial horizons, directional gyros and rate gyros. The collection was established in the 1960s and was initially used for university teaching and research.To support historical as well as didactical research, it is intended to make these gyro instruments virtually available for experts, but also for a broader community in general. This is done by creating 3-dimensional (3D) digital models of the objects - the purpose of the current Gyrolog project at the University of Stuttgart.The highly complex structures of the gyro instruments represent especially demanding digitisation requirements. Therefore, a combination of methods from photogrammetry, endoscopy and computed tomography (CT) is employed. They aim at creating vectorised 3D models being usable for environments of Virtual Reality and Augmented Reality.It is planned to make the digital collection available via Internet by the library of the University of Stuttgart in 2020. The access of each instrument is enhanced by relevant metadata, regular photographs as well as details about specifications, origin, and usage.","2377-3480","978-1-7281-1935-9","10.1109/ISS46986.2019.8943640","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943640","","Instruments;Aerospace engineering;History;Education;Computed tomography;Three-dimensional displays;Computational modeling","aerospace computing;augmented reality;computerised tomography;digital libraries;gyroscopes;inertial navigation;Internet;meta data;museums;photogrammetry;teaching","Internet;augmented reality;virtual reality;University of Stuttgart;University of Stuttgart;computed tomography;endoscopy;photogrammetry;3-dimensional digital models;directional gyros;rotating mass gyro instruments;classic mass gyro instruments;museums;maritime aerospace vehicles;classical gyro instruments;3-dimensional digital collection;vectorised 3D models","","","","29","","30 Dec 2019","","","IEEE","IEEE Conferences"
"GestAR: Real Time Gesture Interaction for AR with Egocentric View","S. Hegde; R. Perla; R. Hebbalaguppe; E. Hassan","Smart Machines R&D Group, TCS Res., New Delhi, India; Smart Machines R&D Group, TCS Res., New Delhi, India; Smart Machines R&D Group, TCS Res., New Delhi, India; Smart Machines R&D Group, TCS Res., New Delhi, India","2016 IEEE International Symposium on Mixed and Augmented Reality (ISMAR-Adjunct)","2 Feb 2017","2016","","","262","267","The existing, sophisticated AR gadgets1 in the market today are mostly exorbitantly priced. This limits their usage for the upcoming academic research institutes and also their reach to the mass market in general. Among the most popular and frugal head mounts, Google Cardboard (GC) and Wearality2 are video-see-through devices that can provide immersible AR and VR experiences with a smartphone. Stereo-rendering of camera feed and overlaid information on smartphone helps us experience AR with GC. These frugal devices have limited user-input capability, allowing user interactions with GC such as head tilting, magnetic trigger and conductive lever. Our paper proposes a reliable and intuitive gesture based interaction technique for these frugal devices. The hand gesture recognition employs the Gaussian Mixture Models (GMM) based on human skin pixels and tracks segmented foreground using optical flow to detect hand swipe direction for triggering a relevant event. Realtime performance is achieved by implementing the hand gesture recognition module on a smartphone and thus reducing the latency. We augment real-time hand gestures as new GC's interface with its evaluation done in terms of subjective metrics and with the available user interactions in GC.","","978-1-5090-3740-7","10.1109/ISMAR-Adjunct.2016.0090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7836511","H.5.1 [Information Interfaces and Presentation]: Artificial;Augmented;and Virtual Realities—; H.5.2 [Information Interfaces and Presentation]: User Interfaces—Interaction Styles I.4.8 [Computing Methodologies]: Image Processing and Computer V","Gesture recognition;Feature extraction;Cameras;Magnetic resonance imaging;Inspection;Google;Adaptive optics","augmented reality;Gaussian processes;gesture recognition;image segmentation;image sequences;mixture models;rendering (computer graphics);stereo image processing;tracking","subjective metrics;GC interface;hand gesture recognition module;hand swipe direction detection;optical flow;segmented foreground tracking;human skin pixels;GMM;Gaussian mixture models;intuitive gesture based interaction;user interactions;smartphone helps;stereo-rendering;VR experiences;video-see-through devices;Wearality2;Google Cardboard;head mounts;AR gadgets;egocentric view;augmented reality;real time gesture interaction;GestAR","","7","","36","","2 Feb 2017","","","IEEE","IEEE Conferences"
"Visual Data Mining by Virtual Reality for Protein-Protein Interaction Networks","N. Aouaa; R. Gherbi; A. Meziane; H. Hadjar; I. Setitra","CERIST, Research Centre For Scientific And Technical Information, Algiers, Algeria, Université Abderrahmane Mira Béjaia - Rue Targa Ouzemour Béjaia, Algeria; Paris-Sud XI University, Orsay, France; CERIST, Research Centre For Scientific And Technical Information, Algiers, Algeria; CERIST, Research Centre For Scientific And Technical Information, Algiers, Algeria; CERIST, Research Centre For Scientific And Technical Information, Algiers, Algeria","2018 IEEE/ACS 15th International Conference on Computer Systems and Applications (AICCSA)","17 Jan 2019","2018","","","1","8","Currently, visualization techniques in the genetic field require a very important modeling phase in terms of resources. 2D based projections of traditional visualization techniques are rarely adapted to manage and process such huge mass of information. To overcome such limitation, we propose to use a new graph modeling technique. This, when used in conjunction with virtual reality technology, allows biologists to have a wide visibility and fluent exploration through several points of view and user interaction, thus enabling what we can call visual data mining of big scientific data. The general principle of our approach is to build a biological network model in the form of a graph with a spatial representation adapted to the visualization of biological networks in a virtual environment. The results show that the improvement of the node distribution algorithm allows a better and more intuitive visualization, compared to the equivalent two-dimensional visualization.","2161-5330","978-1-5386-9120-5","10.1109/AICCSA.2018.8612849","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8612849","virtual reality;visual data mining;big scientific data;protein interaction networks;user interaction","Proteins;Data visualization;Solid modeling;Virtual reality;Visualization;Biological system modeling","biology computing;data mining;data visualisation;distributed algorithms;graph theory;network theory (graphs);proteins;virtual reality","node distribution algorithm;two-dimensional visualization;virtual environment;biological network model;big scientific data;user interaction;virtual reality technology;graph modeling technique;2D based projections;genetic field;protein-protein interaction networks;visual data mining","","1","","21","","17 Jan 2019","","","IEEE","IEEE Conferences"
"A Framework for Scalable Virtual Worlds Using Spatially Organized P2P Networks","R. Cavagna; M. Abdallah; E. Buyukkaya; C. Bouville","IRISA, Rennes, France; IRISA, Rennes, France; IRISA, Rennes, France; IRISA, Rennes, France","2008 14th IEEE International Conference on Parallel and Distributed Systems","22 Dec 2008","2008","","","853","858","The general craze for virtual environments, the potential of augmented reality applications and the announced revolution of the Internet world (Web 2.0, Web 3D.0) are key points for the emergence of an 'ambient' Web which will make it possible for users to communicate, collaborate, entertain, work and exchange content. In this context, content storage, delivery, and reproduction are among the essential points for the deployment of a highly scalable platform of wide reality. In this paper, we propose a self-scalable peer-to-peer architecture for the navigation in network-based virtual worlds. To reach this goal, we propose a fully distributed and adaptive streaming method that quickly adapts the reproduced content according to user interaction. Our content delivery strategy has been implemented and tested on a dedicated simulator with a large 3D city model. The presented results show the efficiency of our strategy in very critical conditions.","1521-9097","978-0-7695-3434-3","10.1109/ICPADS.2008.125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4724407","virtual environments;peer-to-peer;self-scalabity;self-repartition;self-adaptation;self-distribution","Virtual environment;Cities and towns;Costs;Hardware;Network servers;Augmented reality;IP networks;Collaborative work;International collaboration;Context","augmented reality;peer-to-peer computing","scalable virtual worlds;spatially organized P2P networks;virtual environments;augmented reality;Internet world;peer-to-peer architecture;network-based virtual worlds;adaptive streaming method","","3","","17","","22 Dec 2008","","","IEEE","IEEE Conferences"
"QoE-Driven Resource Allocation Optimized for Uplink Delivery of Delay-Sensitive VR Video Over Cellular Network","J. Yang; J. Luo; D. Meng; J. Hwang","School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; Electronic Information and Networking Institute, Chongqing University of Posts and Telecommunications, Chongqing, China; Electrical Engineering Department, University of Washington, Seattle, WA, USA; Electrical Engineering Department, University of Washington, Seattle, WA, USA","IEEE Access","20 May 2019","2019","7","","60672","60683","Uploading virtual reality (VR) video over cellular networks is expected to boom in the near future, as general consumers could generate the high-quality VR videos with portable 360-degree cameras and are willing to share with others. Consequently, the concerns of uplink bandwidth and delay arose for current popular technology of tile-based VR video streaming, which requires high-quality video to transcode into multiple representations for further adaptive streaming. Motivated by this, we proposed a novel scheme for uplink delivery of tile-based VR video over cellular networks, in which encoding bit rate of each tile is determined by the uplink resource allocation (RA), and the quality of content (QoC) contribution of each tile and channel quality of user equipments (UEs) are jointly considered during RA. Moreover, the RA problem is formulated as a frequency and time dependent non-deterministic polynomial (NP)-hard problem. Furthermore, we propose three algorithms to explore solving the RA problem. The simulation results show that the proposed approximate convex algorithm with low-complexity can achieve higher utility, i.e., higher total quality of experience (QoE) for viewers.","2169-3536","","10.1109/ACCESS.2019.2915370","Chongqing Municipal Education Commission; Ministry of Education–China Mobile Research Fund Project; Chongqing Municipal Education Commission; Chongqing University of Posts and Telecommunications; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8715472","VR video;quality of experience (QoE);resource allocation;cellular network;saliency;utility optimization","Streaming media;Uplink;Bit rate;Bandwidth;Quality of experience;Cellular networks;Encoding","cellular radio;convex programming;quality of experience;resource allocation;video streaming;virtual reality","uplink delivery;delay-sensitive VR video;cellular network;virtual reality video;uplink resource allocation;channel quality;QoE-driven resource allocation;quality of experience;quality of content;VR video streaming","","1","","31","","15 May 2019","","","IEEE","IEEE Journals"
"From simulation to gaming: an object-oriented supply chain training library","A. Verbraeck; S. -. A. van Houten","Fac. of Technol., Policy & Manage., Delft Univ. of Technol., Netherlands; Fac. of Technol., Policy & Manage., Delft Univ. of Technol., Netherlands","Proceedings of the Winter Simulation Conference, 2005.","23 Jan 2006","2005","","","9 pp.","","The development of Web-enabled interactive training simulations is far from easy, especially when all models have to be developed from scratch for each training game. Actually, one would like to be able to reuse parts of existing, offline simulation models in an interactive setting. The challenge is how to setup simulation models or simulation libraries that are developed for offline simulations in such a way that they can be reused for online situations, and adapted for different educational settings. Using a supply chain context as an example, this paper shows how libraries of simulation components can be applied both for offline simulation studies and for online training. The paper also describes the other functionality that is needed to create a generally applicable component library for supply chain training simulations","1558-4305","0-7803-9519-0","10.1109/WSC.2005.1574525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1574525","","Object oriented modeling;Supply chains;Libraries;Supply chain management;Management training;Context modeling;Analytical models;Contracts;Logistics;Instruments","computer aided instruction;digital simulation;Internet;object-oriented programming;software libraries;supply chains;training","object-oriented supply chain training library;Web-enabled interactive training simulations;offline simulation models;simulation libraries;simulation component libraries;online training","","5","","20","","23 Jan 2006","","","IEEE","IEEE Conferences"
"Building a General Purpose Pedagogical Agent in a Web-Based Multimedia Clinical Simulation System for Medical Education","Y. Cheng; L. Chen; H. Huang; S. Weng; Y. Chen; C. Lin","Shu Te University, Kaohsiung; National Cheng Kung University, Tainan; National Cheng Kung University, Tainan; National Cheng Kung University, Tainan; National Cheng Kung University, Tainan; National Cheng Kung University, Tainan","IEEE Transactions on Learning Technologies","11 Sep 2009","2009","2","3","216","225","In medical education, pedagogical agents are widely used by computer learning systems to simulate tutors and/or mimic tutoring interactions, as well as offering just-in-time and adaptive feedback. Although the theoretical aspect of the pedagogical agents has been well-documented in literature, relatively fewer efforts have been made on how a pedagogical agent should be implemented in a real multimedia computerized simulation learning environment. In this paper, we propose a general purpose pedagogical agent architecture and implement it in the multimedia medical simulation Web-based learning system called health information network teaching system (HINTS) to further facilitate students' learning and thereby make the HINTS a more helpful educational tool. Our focus is the design of the general purpose pedagogical architecture and its implementation in a multimedia computerized simulation learning environment. A preliminary students' performance evaluation result is also reported. We analyzed how to evaluate the students' performance and how the hints were given by the pedagogical agent. The system has been installed in the National Cheng Kung University Medical Center, Tainan, Taiwan for trial purposes. Some experiments have been conducted and the results have shown that the pedagogical agent indeed help the students in their learning process.","1939-1382","","10.1109/TLT.2009.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4815202","e-Learning for medical education;pedagogical agent;computer-assisted learning;virtual peers;human-computer interaction;learning companions.","Education;Multimedia communication;Computational modeling;Multimedia systems;Laboratories;Medical diagnostic imaging;Data mining","biomedical education;computer aided instruction;digital simulation;hospitals;Internet;medical computing;multimedia computing;teaching","medical education;Web-based multimedia clinical simulation;general purpose pedagogical agent architecture;computer learning system;adaptive feedback;HINTS;health information network teaching system;National Cheng Kung University Medical Center;Taiwan","","21","","35","","17 Apr 2009","","","IEEE","IEEE Journals"
"An empirical evaluation of virtual hand techniques for 3D object manipulation in a tangible augmented reality environment","T. Ha; W. Woo","GIST U-VR Lab., 500-712, S. Korea; GIST U-VR Lab., 500-712, S. Korea","2010 IEEE Symposium on 3D User Interfaces (3DUI)","29 Apr 2010","2010","","","91","98","In this paper, we present a Fitts' law-based formal evaluation process and the corresponding results for 3D object manipulation techniques based on a virtual hand metaphor in a tangible augmented reality (TAR) environment. Specifically, we extend the design parameters of the 1D scale Fitts' law to 3D scale and then refine an evaluation model in order to bring generality and ease of adaptation to various TAR applications. Next, we implement and compare standard TAR manipulation techniques using a cup, a paddle, a cube, and a proposed extended paddle prop. Most manipulation techniques were well-modeled in terms of linear regression according to Fitts' law, with a correlation coefficient value of over 0.9. Notably, the throughput by ISO 9241-9 of the extended paddle technique peaked at around 1.39 to 2 times higher than in the other techniques, due to the instant 3D positioning of the 3D objects. In the discussion, we subsequently examine the characteristics of the TAR manipulation techniques in terms of stability, speed, comfort, and understanding. As a result, our evaluation process, results, and analysis can be useful in guiding the design and implementation of future TAR interfaces.","","978-1-4244-6847-8","10.1109/3DUI.2010.5444713","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444713","Augmented reality;tangible user interface;virtual hand technique;3D object manipulation;empirical evaluation;Fitts' law","Augmented reality;Stability;User interfaces;Guidelines;Keyboards;Mice;Cameras;Testing;Linear regression;Throughput","augmented reality;haptic interfaces;regression analysis","empirical evaluation;virtual hand techniques;3D object manipulation;tangible augmented reality environment;linear regression;tangible user interface;correlation coefficient","","15","2","30","","29 Apr 2010","","","IEEE","IEEE Conferences"
"Virtual Reality and Recommendation System to Design Mobility System","A. Gabriel; M. Ortiz","LCPI, Arts et Metiers ParisTech, Paris, France; ERPI, Univ. de Lorraine, Nancy, France","2017 13th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)","12 Apr 2018","2017","","","490","495","In the domain of urbanism and more particularly the design of mobility system, the end-users are poorly involved whereas they condition the success of new infrastructure. The generalization of policies for active mobility urges the importance of correctly design the system of mobility. The success goes through the consideration of end-user needs. However, there is always a gap between the needs of the users and reality. We assume that virtual reality can ease user-centered design approach by letting the users experiment the technical solutions. Although maps and mockup permit exchanges between designers and end-users to improve the final design, this research assume that immersive environment is more efficient. Virtual reality seems to be a relevant tool for a user-centered approach applied to mobility system. The difficulty remains providing the adapted information to the designers who are the responsible to make the decision of the solution. The aim is not only to use virtual reality in the design process but also suggests a methodology to imply users in the design process and assist the designer during the decision-making.","","978-1-5386-4283-2","10.1109/SITIS.2017.86","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8334792","virtual reality;recommandation system;mobility system","Virtual environments;Solid modeling;Tools;Legged locomotion;Decision making;Buildings","recommender systems;user centred design;virtual reality","virtual reality;recommendation system;active mobility;correctly design;end-user needs;user-centered design approach;user-centered approach;mobility system design","","","","34","","12 Apr 2018","","","IEEE","IEEE Conferences"
"Partially decentralised wireless routing for distributed augmented reality applications","J. Leskela","VTT Electron. & Infotech Res. Center, Oulu Univ., Finland","Proceedings of ICICS, 1997 International Conference on Information, Communications and Signal Processing. Theme: Trends in Information Systems Engineering and Wireless Multimedia Communications (Cat. ","6 Aug 2002","1997","1","","210","214 vol.1","Mobile communication can in general be divided into two categories. Centralised mobile communication interfaces the mobile terminals through base stations that are connected to a fixed network. A good example of a centralised mobile system is GSM. Decentralised mobile communication does not have the concept of a base station but the messages are relayed towards their destinations through other mobile terminals. This kind of approach has been considered, for example, in disaster information systems that cannot rely on the fixed infrastructures. This paper presents one routing solution to a wireless low-power picocell network where the flexibility of decentralised communication systems is required, together with the good connectivity brought by centralised and authorised networks. These features are applied in order to provide flexible communication between augmented reality services embedded to electromechanical products and the users wearing light weight virtual reality user interfaces. A routing mechanism that quickly adapts itself with low overhead is a key factor for the success of such an environment.","","0-7803-3676-3","10.1109/ICICS.1997.647089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=647089","","Routing;Augmented reality;Base stations;Mobile communication;User interfaces;GSM;Relays;Virtual reality;Network topology;Telecommunication traffic","cellular radio;land mobile radio;telecommunication network routing;user interfaces;virtual reality;radio networks;telecommunication computing;data visualisation","partially decentralised wireless routing;distributed augmented reality applications;centralised mobile communication interfaces;mobile terminals;base stations;fixed network;GSM;decentralised mobile communication;disaster information systems;wireless low-power picocell network;authorised networks;augmented reality services;electromechanical products;virtual reality user interfaces;visualisation tool","","1","","10","","6 Aug 2002","","","IEEE","IEEE Conferences"
"[DC] Self-Adaptive Technologies for Immersive Trainings","J. Heyse","Ghent University - imec, IDLab","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1381","1382","Online learning is the preferred option for professional training, e.g. Industry 4.0 or e-health, because it is more cost efficient than on-site organisation of realistic training sessions. However, current online learning technologies are limited in terms of personalisation, interactivity and immersiveness that are required by applications such as surgery and pilot training. Virtual Reality (VR) technologies have the potential to overcome these limitations. However, due to its early stage of research, VR requires significant improvements to fully unlock its potential. The focus of this PhD is to tackle research challenges to enable VR for online training in three dimensions: (1) dynamic adaptation of the training content for personalised trainings, by incorporating prior knowledge and context data into self-learning algorithms; (2) mapping of sensor data onto what happens in the VR environment, by focusing on motion prediction techniques that use past movements of the users, and (3) investigating immersive environments with intuitive interactions, by gaining a better understanding of human motion in order to improve interaction. The designed improvements will be characterised though a prototype VR training platform for multiple use cases. This work will not only advance the state of the art on VR training, but also on online e-learning applications in general.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798207","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality;Applied computing;Life and medical sciences;Health informatics","Training;Virtual reality;Tracking;Resists;Haptic interfaces;Surgery;Prototypes","computer based training;sensors;virtual reality","online training;training content;personalised trainings;context data;self-learning algorithms;sensor data;VR environment;motion prediction techniques;immersive environments;intuitive interactions;prototype VR training platform;online e-learning applications;immersive trainings;on-site organisation;immersiveness;surgery;pilot training;training sessions;online learning technologies;self-adaptive technologies;virtual reality technologies","","","","6","","15 Aug 2019","","","IEEE","IEEE Conferences"
"Development of a Gas Turbine Full Scope Simulator for Operator's Training","E. J. Roldán-Villasana; Y. Mendoza-Alegría; J. J. Zorrilla-Arena S.; M. J. G. Cardoso; R. Cruz-Cruz","Dept. de Simulacion, Inst. de Investig. Electr., Morelos; Dept. de Simulacion, Inst. de Investig. Electr., Morelos; Dept. de Simulacion, Inst. de Investig. Electr., Morelos; Dept. de Simulacion, Inst. de Investig. Electr., Morelos; NA","2008 Second UKSIM European Symposium on Computer Modeling and Simulation","16 Sep 2008","2008","","","376","381","In this paper the stages pursuit to develop a full scope gas-turbine power plant simulator are explained and the general characteristics of the simulator are described. Presently the simulator is being used in the National Centre for Operators' Training of the Utility Mexican Company. The simulator response was validated against data from the real plant, the Combined Cycle Power Plant ""El Sauz"" located in Queretaro, Mexico. The work was developed by the Simulation Department, of the Electrical Research Institute in Mexico.","","978-0-7695-3325-4","10.1109/EMS.2008.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4625303","Simulation;Modelling;Full Scope Simulator;Real Time Simulation;Gas Turbine","Mathematical model;Biological system modeling;Atmospheric modeling;Adaptation model;Process control;Integrated circuit modeling;Control systems","combined cycle power stations;computer aided instruction;gas turbine power stations;industrial training;power engineering computing","gas-turbine power plant simulator;National Centre for Operators Training;Utility Mexican Company;Combined Cycle Power Plant El Sauz;Queretaro;Mexico;Simulation Department;Electrical Research Institute","","1","","5","","16 Sep 2008","","","IEEE","IEEE Conferences"
"Haptic-enabled Collaborative Training with Generalized Force and Position Mappings","S. Moghimi; S. Sirouspour; P. Malysz","NA; Department of Electrical and Computer Engineering, McMaster University, Hamilton, Ontario, Canada. email: sirouspour@ece.mcmaster.ca; NA","2008 Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems","31 Mar 2008","2008","","","287","294","A control framework is introduced for collaborative training in haptic-enabled virtual environments. To increase the versatility of the proposed approach, the haptic interface control is separated from the virtual environment simulation, which can be of either impedance or admittance-type. Adaptive nonlinear controllers are developed to enforce desired linear-time-invariant and/or nonlinear static mappings among the users and the virtual task environment positions and forces. The controllers account for nonlinear models of the haptic devices and can cope with uncertainties present in the users and haptic devices dynamics. The performance and closed-loop stability of the proposed methods are demonstrated in two steps. First, using a Lyapunov analysis, the tracking behavior of the system is shown. Then given a priori known bounds on the users and environment parameters, the robust stability of the closed-loop system is analyzed based on the Nyquist envelops of interval plants and an off-axis circle criterion. Experimental results demonstrate the effectiveness of the proposed controllers.","2324-7355","978-1-4244-2005-6","10.1109/HAPTICS.2008.4479960","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4479960","Collaborative Training;Haptic-based Training;Collaborative Haptics;Adaptive Nonlinear Control;Circle Criterion","Collaboration;Haptic interfaces;Virtual environment;Impedance;Programmable control;Adaptive control;Force control;Uncertainty;Nonlinear dynamical systems;Stability","adaptive control;closed loop systems;computer based training;groupware;haptic interfaces;Lyapunov methods;nonlinear control systems;stability;virtual reality","haptic-enabled collaborative training;generalized force mapping;position mapping;haptic-enabled virtual environment;haptic interface control;impedance-type simulation;admittance-type simulation;adaptive nonlinear controllers;linear-time-invariant mapping;nonlinear static mapping;virtual task environment position;haptic devices;closed-loop stability;Lyapunov analysis;off-axis circle criterion","","17","1","23","","31 Mar 2008","","","IEEE","IEEE Conferences"
"Teaching High School Computer Science with Videos of Historical Figures -- An Augmented Reality Approach","C. Hsu; M. Chen; C. Wu","Grad. Inst. of Inf. & Comput. Educ., Nat. Taiwan Normal Univ., Taipei, Taiwan; Grad. Inst. of Inf. & Comput. Educ., Nat. Taiwan Normal Univ., Taipei, Taiwan; Grad. Inst. of Inf. & Comput. Educ., Nat. Taiwan Normal Univ., Taipei, Taiwan","2015 International Conference on Learning and Teaching in Computing and Engineering","18 Jun 2015","2015","","","22","25","This study investigated the effects of teaching history of computing with videos of historical figures. Augmented reality (AR) techniques were applied to assist student accessing the videos of historical figures while reading a printed textbook. Whenever a student was interested in a historical figure, one could use a tablet PC to scan the figure's picture, and the corresponding video about the person would then be played on the screen. We adapted thirteen videos of historical figures in computer network field and adopted a quasi-experimental method to evaluate the effectiveness of the AR-based learning approach. Two classes of high school students, with a total of 84 students, participated in the experiment. One class of the students used Tablet PCs to access the videos of historical figures, and the other class using traditional didactic instruction served as the control group. The data collected for analysis are students' achievement test scores and answers to a questionnaire, which consists of questions on attitudes toward learning, perspectives of nature of science, and perceptions on the AR activities. Our findings showed that the AR-based historical figure videos helped students comprehend learning contents and promoted their attitudes toward learning. Students appreciated the convenience of using AR tools to access the history videos. Future research should investigate other approaches to integrate AR with the videos of historical figure, and in general, to integrate AR with other media format of computing history.","","978-1-4799-9967-5","10.1109/LaTiCE.2015.30","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7126226","history of computing;videos;historical figures;augmented reality","Videos;History;Education;Computers;Augmented reality;Context;Computer networks","augmented reality;computer aided instruction;computer science education;notebook computers","high school computer science teaching;videos;historical figures;augmented reality approach;computing history;AR-based learning approach;printed textbook;tablet PC computer network field;quasiexperimental method;didactic instruction;AR activities;media format;learning contents","","2","","8","","18 Jun 2015","","","IEEE","IEEE Conferences"
"Surface Light Field Compression Using a Point Cloud Codec","X. Zhang; P. A. Chou; M. Sun; M. Tang; S. Wang; S. Ma; W. Gao","School of Electronics Engineering and Computer Science, Institute of Digital Media, Peking University, Beijing, China; Google Daydream Group, Seattle, WA, USA; Department of Electrical and Computer Engineering, University of Washington, Seattle, WA, USA; Department of Electrical and Computer Engineering, University of Washington, Seattle, WA, USA; School of Electronics Engineering and Computer Science, Institute of Digital Media, Peking University, Beijing, China; School of Electronics Engineering and Computer Science, Institute of Digital Media, Peking University, Beijing, China; School of Electronics Engineering and Computer Science, Institute of Digital Media, Peking University, Beijing, China","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","10 Mar 2019","2019","9","1","163","176","Light field (LF) representations aim to provide photo-realistic, free-viewpoint viewing experiences. However, the most popular LF representations are the images from multiple views. Multi-view image-based representations generally need to restrict the range or degrees of freedom of the viewing experience to what can be interpolated in the image domain, essentially because they lack explicit geometry information. We present a new surface LF (SLF) representation based on explicit geometry and a method for SLF compression. First, we map the multi-view images of a scene onto a 3-D geometric point cloud. The color of each point in the point cloud is a function of viewing direction known as a view map. We represent each view map efficiently in a B-Spline wavelet basis. This representation is capable of modeling diverse surface materials and complex lighting conditions in a highly scalable and adaptive manner. The coefficients of the B-Spline wavelet representation are then compressed spatially. To increase the spatial correlation and, thus, improve compression efficiency, we introduce a smoothing term to make the coefficients more similar across the 3-D space. We compress the coefficients spatially using existing point cloud compression methods. On the decoder side, the scene is rendered efficiently from any viewing direction by reconstructing the view map at each point. In contrast to multi-view image-based LF approaches, our method supports photo-realistic rendering of real-world scenes from arbitrary viewpoints, i.e., with an unlimited six degrees of freedom. In terms of rate and distortion, experimental results show that our method achieves superior performance with lighter decoder complexity compared with a reference image-plus-geometry compression scheme, indicating its potential in practical virtual and augmented reality applications.","2156-3365","","10.1109/JETCAS.2018.2883479","National Natural Science Foundation of China; Top-Notch Young Talents Program of China; High-Performance Computing Platform of Peking University; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8546779","Surface light field;point cloud compression;virtual reality;augmented reality;free-viewpoint;full 6DoF","Image coding;Three-dimensional displays;Cameras;Transforms;Rendering (computer graphics);Splines (mathematics);Surface waves","augmented reality;geometry;image coding;image colour analysis;image representation;interpolation;realistic images;rendering (computer graphics);splines (mathematics);wavelet transforms","surface light field compression;point cloud codec;light field representations;photo-realistic viewpoint viewing experiences;free-viewpoint viewing experiences;multiple views;image-based representations;image domain;explicit geometry information;surface LF representation;SLF compression;multiview images;3-D geometric point cloud;viewing direction;diverse surface materials;complex lighting conditions;B-Spline wavelet representation;compression efficiency;image-based LF approaches;photo-realistic rendering;reference image-plus-geometry compression scheme;point cloud compression methods;augmented reality applications;virtual reality","","3","","34","","27 Nov 2018","","","IEEE","IEEE Journals"
"Enactive Approach to Assess Perceived Speed Error during Walking and Running in Virtual Reality","T. Perrin; H. A. Kerhervé; C. Faure; A. Sorel; B. Bideau; R. Kulpa","Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France; Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France; Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France; Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France; Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France; Inria, Univ Rennes, M2S - EA 7470, Rennes, F-35000, France","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","622","629","The recent development of virtual reality (VR) devices such as head mounted displays (HMDs) increases opportunities for applications at the confluence of physical activity and gaming. Recently, the fields of sport and fitness have turned to VR, including for locomotor activities, to enhance motor and energetic resources, as well as motivation and adherence. For example, VR can provide visual feedbacks during treadmill running, thereby reducing monotony and increasing the feeling of movement and engagement with the activity. However, the relevance of using VR tools during locomotion depends on the ability of these systems to provide natural immersive feelings, specifically a coherent perception of speed. The objective of this study is to estimate the error between actual and perceived locomotor speed in VE using an enactive approach, i.e. allowing an active control of the environment. Sixteen healthy individuals participated in the experiment, which consisted in walking and running on a motorized treadmill at speeds ranging from 3 to 11 km/h with 0.5 km/h increments, in a randomized order while wearing a HMD device (HTC Vive) displaying a virtual racetrack. Participants were instructed to match VE speed with what they perceived was their ac-tuallocomotion speed (LS), using a handheld Vive controller. They were able to modify the optic flow speed (OFS) with a 0.02 km/h increment/decrement accuracy. An optic flow multiplier (OFM) was computed based on the error between OFS and LS. It represents the gain that exists between the visually perceived speed and the real locomotion speed experienced by participants for each trial. For all conditions, the average of OFM was 1.00±.25 to best match LS. This finding is at odds with previous works reporting an underestimation of speed perception in VR. It could be explained by the use of an enactive approach allowing an active and accurate matching of visually and proprioceptively perceived speeds by participants. But above all, our study showed that the perception of speed in VR is strongly individual, with some participants always overestimating and others constantly underestimating. Therefore, a general OFM should not be used to correct speed in VE to ensure congruence in speed perception, and we propose the use of individual models as recommendations for setting up locomotion-based VR applications.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798209","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798209","Virtual reality;speed perception assessment;running in virtual environment;enaction;physical activity in VR","Legged locomotion;Adaptive optics;Resists;Optical feedback;Virtual environments;Visualization","gait analysis;helmet mounted displays;human factors;mechanoception;virtual reality","speed perception;visually perceived speeds;proprioceptively perceived speeds;locomotion-based VR applications;virtual reality devices;physical activity;locomotor activities;visual feedbacks;VR tools;natural immersive feelings;actual perceived locomotor speed;motorized treadmill;HMD device;virtual racetrack;VE speed;handheld Vive controller;optic flow speed;optic flow multiplier;visually perceived speed;locomotion speed;perceived speed error;velocity 0.5 km/h;velocity 0.02 km/h;velocity 3.0 km/h to 11.0 km/h","","","","35","","15 Aug 2019","","","IEEE","IEEE Conferences"
"3-D Tracking for Augmented Reality Using Combined Region and Dense Cues in Endoscopic Surgery","R. Wang; M. Zhang; X. Meng; Z. Geng; F. -Y. Wang","State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Journal of Biomedical and Health Informatics","10 Aug 2018","2018","22","5","1540","1551","An augmented reality (AR) technique has recently gained its popularity in minimally invasive surgery. Tracking is a crucial step to achieve precise AR. Besides optical tracking in traditional medical AR, visual tracking attracts a lot of attention due to its generality. Moreover, when the target organ's 3-D model can be obtained from preoperative images and under the model rigidity assumption, tracking is then converted into a problem of computing the six-degree-of-freedom pose of the 3-D model. In this paper, we introduce a robust tracking algorithm in our endoscopic AR system, where we combine the benefits of both region and dense cues in a unified framework. Each kind of cues alone may not be adequate for tracking in endoscopic surgery. However, they have complementary characteristics, with region cues being more robust to motion blur and fast motion, and dense cues being more accurate when motion is not large. We also propose an appearance model adaption method and an occlusion processing method to effectively handle occlusions. Experiments on both synthetic dataset and simulated surgical environment show the effectiveness and robustness of our proposed method. This work presents a novel tracking strategy in medical AR applications.","2168-2208","","10.1109/JBHI.2017.2770214","National High-tech R&D Program (863 Program); National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8096997","Augmented reality;dense cues;endoscopic surgery;region cues;tracking","Three-dimensional displays;Target tracking;Surgery;Solid modeling;Biomedical imaging;Robustness","augmented reality;endoscopes;image motion analysis;medical image processing;medical robotics;object detection;object tracking;optical tracking;surgery;tracking","endoscopic surgery;augmented reality technique;minimally invasive surgery;optical tracking;visual tracking;preoperative images;robust tracking algorithm;endoscopic AR system;appearance model adaption method","Algorithms;Computer Simulation;Endoscopy;Humans;Imaging, Three-Dimensional;Surgery, Computer-Assisted;Virtual Reality","","","36","","7 Nov 2017","","","IEEE","IEEE Journals"
"Definition of Test Criteria Based on the Scene Graph for VR Applications","A. Bezerra; M. E. Delamaro; F. L. S. Nunes","Inst. de Cienc. Matemdticas e de Comput. (ICMC), Univ. de Sao Paulo (USP), Sao Carlos, Brazil; Inst. de Cienc. Matemdticas e de Comput. (ICMC), Univ. de Sao Paulo (USP), Sao Carlos, Brazil; Inst. de Cienc. Matemdticas e de Comput. (ICMC), Univ. de Sao Paulo (USP), Sao Carlos, Brazil","2011 XIII Symposium on Virtual Reality","14 Jul 2011","2011","","","56","65","Virtual Reality applications are becoming more popular. In general, the development of these applications does not include a testing phase, or, at best, the evaluation is conducted only with the users. The activity of software testing has received considerable attention from researchers and software engineers who recognize its usefulness in creating quality products. However, the tests are expensive and prone to errors, which imposes the need to systematize and hence the definition of techniques to increase quality and productivity in their driving. Several testing techniques have been developed and have been used, each with its own characteristics in terms of effectiveness, cost, implementation stages, etc. Moreover, these techniques can also be adapted. In this paper, testing criteria based on scene graph are studied in order to ensure the quality of the Virtual Reality applications implementation. In addition, a proof of concept is presented, by using the defined criteria applied to a VR framework built to generate applications in the medical training area.","","978-0-7695-4445-8","10.1109/SVR.2011.34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5951835","Virtual reality;software testing;test criteria;test;scene graph","Software;Visualization;Instruments;Computational modeling;Java;Testing;Virtual reality","program testing;software quality;virtual reality","scene graph;VR applications;virtual reality applications;software testing;quality products;medical training area","","1","","32","","14 Jul 2011","","","IEEE","IEEE Conferences"
"Characteristic evaluation of the audio and visual system of haptic device","M. Ishihara; T. Komori","Dept. Innovative Electrical and Electronic Engineering, Oyama National College of Technology, 323-0806 JAPAN; Advanced Course of General Engineering Program, Oyama National College of Technology, 323-0806 JAPAN","2014 IEEE 3rd Global Conference on Consumer Electronics (GCCE)","5 Feb 2015","2014","","","356","357","This paper illustrates the effectiveness of a proactive data transfer scheme for adaptive display control in a distributed haptic system with virtual reality, which is an application using haptic, audio and visual media. Presentation experiments of an audio-visual stimulus were carried out using a computer graphics of a moving ball and its collision sound. The results obtained show that the sound image at the beginning of an audio-visual presentation is more strongly captured with the visual image than that at the ending, and that the sound image is perceived separately from the visual image even at the timing of the presentation positions of the audio and visual stimuli coincide with each other when the sound source is moving in the collision of the visual image.","2378-8143","978-1-4799-5145-1","10.1109/GCCE.2014.7031219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7031219","audio-visual;haptic;collision sound","Atmospheric measurements;Particle measurements;Interpolation;Phantoms;Quality of service;Distributed databases;Computers","audio-visual systems;computer graphics;haptic interfaces;virtual reality","characteristic evaluation;audio system;visual system;haptic device;proactive data transfer scheme;adaptive display control;distributed haptic system;virtual reality;audio media;visual media;audio-visual stimulus;computer graphics;moving ball;collision sound;sound image;audio-visual presentation;visual image;presentation positions;sound source","","1","","5","","5 Feb 2015","","","IEEE","IEEE Conferences"
"Effect of a 360 Degrees Panoramic Image System (360 PIS) on the Environment Recognition of Students with Moderate and Severe Mental Retardation in Special Education School","I. Cheng; H. Wang",Nat. Taiwan Normal Univ.; Nat. Taiwan Normal Univ.,"2008 Second IEEE International Conference on Digital Game and Intelligent Toy Enhanced Learning","8 Dec 2008","2008","","","52","56","The purpose of the study was to explore if students with moderate and severe mental retardation could take advantage of 360 PIS to enhance action capability in the environment? The study adopted an experimental design of multiple-probe-across-subject. The targets were four students with moderate and severe mental retardation from a special education school. The independent variable was the teaching system of ""The Environment Introduction of Yangming Park by 360 PISrdquo and the dependent variable were the learning results of the students on the 360 PIS, the ability of the students to recognize the real scenes after learning from the 360 PIS and to act independently in the real environment. Each student had to go through three stages of experiment: baseline, intervention and generalization period. The results of experiments were as follows: 1. After teaching, students with moderate and severe mental retardation could operate the 360 PIS and reach the learning level of proficiency. 2. Students with moderate and severe mental retardation could recognize the environment on 360 PIS. They could name the scenes and the locations of related passages on the panoramic image. Furthermore, they also could categorize the results from virtual to real environment, named the scenes and found out locations of passages. 3. Students with moderate and severe mental retardation could walk through two trails independently on 360 PIS and generalized the results from cyberspace to not yet experienced environment and walked through two trails.","","978-0-7695-3409-1","10.1109/DIGITEL.2008.23","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4700729","Virtual Reality;students with mental retardation;social adaptation","Image recognition;Virtual reality;Space technology;Layout;Computer science education;Costs;Computational modeling;Design for experiments;Educational institutions;Transportation","computer aided instruction;image recognition;virtual reality","panoramic image system;environment recognition;mental retardation;special education school;teaching system;scene recognition","","","","8","","8 Dec 2008","","","IEEE","IEEE Conferences"
"Motion adaptation on a wheelchair driving simulator","F. Goncalves; L. Trenoras; E. Monacelli; A. Schmid","Laboratoire d'Ingenierie des Systemes de Versailles 10-12 avenue de l'Europe, 78140 Velizy, France; Laboratoire d'Ingenierie des Systemes de Versailles 10-12 avenue de l'Europe, 78140 Velizy, France; Laboratoire d'Ingenierie des Systemes de Versailles 10-12 avenue de l'Europe, 78140 Velizy, France; Electricite de France 1 avenue du General de Gaulle 92140 Clamart, France","2014 2nd Workshop on Virtual and Augmented Assistive Technology (VAAT)","17 Apr 2014","2014","","","17","22","The objective of the AccesSim project is to design a wheelchair simulator using Virtual Reality and a robotic platform to detect and illustrate accessibility issues in complex environments. In order to be efficient, the robotic platform must provide haptic and vestibular feedbacks to different profile of end users: urbanists to wheelchair users. It must be modular and adaptable to each one of them. In this paper we focus our robotic platform capable of adapting its configuration and feedback rendering based on the user. The design of the platform is described. The capacity of the platform to reproduce the motion of a wheelchair in a specific study case is tested experimen-tally. Finally the results introduce the possibility of adapting the dynamic feedback rendering based on a specific user and environmental situations.","","978-1-4799-4070-7","10.1109/VAAT.2014.6799463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6799463","I.3.7 [COMPUTERS AND SOCIETY]: Social Issues — Assistive technologies for persons with disabilities;I.3.7 [COMPUTER GRAPHICS]: Three-Dimensional Graphics and Realism — Virtual reality;H.3.4 [INFORMATION STORAGE AND RETRIEVAL]: Systems and Software — Performance evaluation","Wheelchairs;Acceleration;Mobile robots;Dynamics;Robot sensing systems;Wheels","digital simulation;handicapped aids;medical robotics;virtual reality;wheelchairs","motion adaptation;wheelchair driving simulator;AccesSim project;virtual reality;robotic platform;haptic feedbacks;vestibular feedbacks;urbanists;dynamic feedback rendering;environmental situations","","1","","14","","17 Apr 2014","","","IEEE","IEEE Conferences"
"Using augmented reality in urban context: Georeferenced system for business localization using Google Glass","L. Ferrer; J. Garcia-Mancilla; V. M. Gonzalez; S. Bermudez; P. Bleier; C. Prieto","Department of Computer Science, Instituto Tecnológico Autonomo de México (ITAM) Mexico City, México; Department of Computer Science, Instituto Tecnológico Autonomo de México (ITAM) Mexico City, México; Department of Computer Science, Instituto Tecnológico Autonomo de México (ITAM) Mexico City, México; Department of Computer Science, Instituto Tecnológico Autonomo de México (ITAM) Mexico City, México; Department of Computer Science, Instituto Tecnológico Autonomo de México (ITAM) Mexico City, México; Department of Computer Science, Instituto Tecnológico Autonomo de México (ITAM) Mexico City, México","2015 IEEE First International Smart Cities Conference (ISC2)","28 Dec 2015","2015","","","1","6","Developing new paradigms of user interaction is always challenging. The introduction of the Google Glass platform presents a novel way to deliver content to users. Clearly, the Glass platform is not going to become a mainstream consumer electronics product as it is; however it was an experimental program from which important practical lessons can be learned. We, as part of the Google Glass Explorer Community, present this study as a contribution to the practical understanding of products that can be core for the development of micro-interaction-based interfaces for wearable gadgets in urban contexts. Throughout this paper we detail the development process of this kind of application by focusing on the challenges presented, the implementation and design decisions, and the usability tests we performed. The main results were that the use of the app is intuitive in general, but the users have problems identifying several components that were adapted for the size of the screen and the concept of the device.","","978-1-4673-6552-9","10.1109/ISC2.2015.7366157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7366157","Augmented reality;Google Glass;micro-interactions;georeferenced systems;usability test","5G mobile communication;Yttrium","augmented reality;geographic information systems;user interfaces;wearable computers","augmented reality;georeferenced system;business localization;user interaction;Google Glass explorer community;microinteraction-based interface;wearable gadget;usability test","","1","","10","","28 Dec 2015","","","IEEE","IEEE Conferences"
"In-Situ Labeling for Augmented Reality Language Learning","B. Huynh; J. Orlosky; T. Höllerer","University of California, Santa Barbara; Osaka University; University of California, Santa Barbara","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1606","1611","Augmented Reality is a promising interaction paradigm for learning applications. It has the potential to improve learning outcomes by merging educational content with spatial cues and semantically relevant objects within a learner's everyday environment. The impact of such an interface could be comparable to the method of loci, a well known memory enhancement technique used by memory champions and polyglots. However, using Augmented Reality in this manner is still impractical for a number of reasons. Scalable object recognition and consistent labeling of objects is a significant challenge, and interaction with arbitrary (unmodeled) physical objects in AR scenes has consequently not been well explored. To help address these challenges, we present a framework for in-situ object labeling and selection in Augmented Reality, with a particular focus on language learning applications. Our framework uses a generalized object recognition model to identify objects in the world in real time, integrates eye tracking to facilitate selection and interaction within the interface, and incorporates a personalized learning model that dynamically adapts to student's growth. We show our current progress in the development of this system, including preliminary tests and benchmarks. We explore challenges with using such a system in practice, and discuss our vision for the future of AR language learning applications.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798358","Human-centered computing;Mixed and augmented reality;Theory and algorithms for application domains;Semi-supervised learning","Three-dimensional displays;Real-time systems;Two dimensional displays;Labeling;Augmented reality;Object recognition;Cameras","augmented reality;computer aided instruction;linguistics;natural languages","language learning applications;generalized object recognition model;personalized learning model;augmented reality language learning;semantically relevant objects;memory champions;polyglots;scalable object recognition;arbitrary physical objects;in-situ object;memory enhancement technique","","2","","33","","15 Aug 2019","","","IEEE","IEEE Conferences"
"Impedance control approach vs. adaptive nonlinear design in simulated push-button haptic interface","B. Allotta; V. Colla; G. Bioli; F. Conticelli","Scula Superiore Sant'Anna, Pisa, Italy; NA; NA; NA","8th IEEE International Workshop on Robot and Human Interaction. RO-MAN '99 (Cat. No.99TH8483)","6 Aug 2002","1999","","","279","284","General purpose haptic interfaces are receiving increasing attention, because they can simulate different kinds of interaction between user and virtual objects/environments. The paper describes the control of a special-purpose haptic interface devoted to simulating the behavior of a push button, with the aim of performing user tests on different geometries and designs. The control task is to provide a reaction to the external solicitation as similar as possible to that of real buttons.","","0-7803-5841-4","10.1109/ROMAN.1999.900353","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=900353","","Impedance;Programmable control;Adaptive control;Haptic interfaces;Hardware;Force sensors;Force measurement;Springs;Testing;Geometry","haptic interfaces;force control;adaptive control;nonlinear control systems;virtual reality","impedance control approach;adaptive nonlinear design;simulated push-button haptic interface;virtual objects;virtual environments;user tests;control task","","","","8","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Adaptive, Computational and Intelligent systems in a Smart Grid education curriculum","G. K. Venayagamoorthy","Real-Time and Intelligent Systems Laboratory, Missouri University of Science and Technology, Rolla, 65409-0249 USA","IEEE PES General Meeting","30 Sep 2010","2010","","","1","2","This paper will present experiences from the introduction of five new, three hour, interdisciplinary courses at the Missouri University of Science and Technology, USA at the undergraduate and graduate levels. The new courses introduced include: Adaptive Devices, Circuits and Systems; Adaptive Critic Designs; Computational Intelligence (CI); CI Methods in Electric Power; and Power System Simulation. The idea of such integrated and interdisciplinary courses, especially at the undergraduate level, is to expose students to different disciplines at an early stage in their degree program and career that is critical today for the Smart Grid environment. The curriculum, possible assessment, implementation, and impacts of interdisciplinary courses for smart grid education will be presented.","1944-9925","978-1-4244-6551-4","10.1109/PES.2010.5589503","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5589503","Integrated and interdisciplinary courses;problem-based learning;projects;smart grid;power engineering education;undergraduate and graduate levels","Awards activities;USA Councils;Smart grids;Artificial neural networks;Adaptive systems;Computational intelligence","computer aided instruction;educational courses;power engineering education;smart power grids","smart grid;education curriculum;integrated and interdisciplinary courses;undergraduate level;degree program;adaptive systems;computational systems;intelligent systems","","2","","13","","30 Sep 2010","","","IEEE","IEEE Conferences"
"Analysis on the current condition of virtual reality and computer graphics and the applications on the digital media interaction","P. Wu","Shenyang Aerospace University, Liaoning province, Shenyang city, 110136, China","2016 International Conference on Inventive Computation Technologies (ICICT)","19 Jan 2017","2016","1","","1","6","In this paper, we conduct analysis on the current condition of virtual reality and the computer graphics and the applications on the digital media interaction. We proposed the systematic review of the digital media interaction modes with the theoretical analysis of the virtual reality and computer graphics. Multimedia gateway is a separate control of the entire media interaction center core components, has the media docking and adaptation, multimedia intelligent routing, configuration and management, and other functions and at the center of the centralized control of all media interaction, the configuration and management of multimedia intelligent routing. With this basis, we integrate the 3D reconstruction methodology to propose the new perspective of the digital media interaction paradigm. The man-machine interface design principles should include the basic principles of general interface design, analysis and man-machine interface specification and the type of interface requirements. Our review summarizes the characteristics of the method well and in the future, the VR integration with the multimedia system and optimized re-construction method and image representation algorithms will be considered.","","978-1-5090-1285-5","10.1109/INVENTIVE.2016.7823249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823249","Virtual Reality;Computer Graphics;Digital Media Interaction;Current Condition;Image Processing","Multimedia communication;Media;Three-dimensional displays;Solid modeling;Streaming media;Computers;Computer graphics","image reconstruction;image representation;man-machine systems;multimedia systems;user interfaces;virtual reality","virtual reality;computer graphics;digital media interaction center core components;media docking;media adaptation;multimedia intelligent routing;multimedia gateway;multimedia configuration;multimedia management;centralized control;3D reconstruction;man-machine interface specification;interface requirements;man-machine interface design principles;VR integration;optimized reconstruction;image representation","","","","47","","19 Jan 2017","","","IEEE","IEEE Conferences"
"Specular Reflections Removal for Endoscopic Image Sequences With Adaptive-RPCA Decomposition","R. Li; J. Pan; Y. Si; B. Yan; Y. Hu; H. Qin","State Key Laboratory of Virtual Reality Technology and Systems, Beijing Advanced Innovation Center for Biomedical Engineering, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, Beijing Advanced Innovation Center for Biomedical Engineering, Beihang University, Beijing, China; Department of Minimally Invasive Surgery, The First Affiliated Hospital of Zhengzhou University, Zhengzhou, China; Department of Gastroenterology and Hepatology, Chinese PLA General Hospital, Beijing, China; School of New Media Art and Design, Beihang University, Beijing, China; Department of Computer Science, Stony Brook University, The State University of New York at Stony Brook, Stony Brook, NY, USA","IEEE Transactions on Medical Imaging","3 Feb 2020","2020","39","2","328","340","Specular reflections (i.e., highlight) always exist in endoscopic images, and they can severely disturb surgeons' observation and judgment. In an augmented reality (AR)-based surgery navigation system, the highlight may also lead to the failure of feature extraction or registration. In this paper, we propose an adaptive robust principal component analysis (Adaptive-RPCA) method to remove the specular reflections in endoscopic image sequences. It can iteratively optimize the sparse part parameter during RPCA decomposition. In this new approach, we first adaptively detect the highlight image based on pixels. With the proposed distance metric algorithm, it then automatically measures the similarity distance between the sparse result image and the detected highlight image. Finally, the low-rank and sparse results are obtained by enforcing the similarity distance between the two types of images to fall within a certain range. Our method has been verified by multiple different types of endoscopic image sequences in minimally invasive surgery (MIS). The experiments and clinical blind tests demonstrate that the new Adaptive-RPCA method can obtain the optimal sparse decomposition parameters directly and can generate robust highlight removal results. Compared with the state-of-the-art approaches, the proposed method not only achieves the better highlight removal results but also can adaptively process image sequences.","1558-254X","","10.1109/TMI.2019.2926501","National Key R&D Program of China; National Natural Science Foundation of China; NSF, USA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8754735","Specular reflections;detection;highlight removal;robust principal component analysis","Image color analysis;Image sequences;Feature extraction;Navigation;Minimally invasive surgery;Matrix decomposition","augmented reality;endoscopes;feature extraction;image registration;image sequences;medical image processing;principal component analysis;surgery","similarity distance;endoscopic image sequences;optimal sparse decomposition parameters;specular reflections removal;augmented reality-based surgery navigation system;adaptive robust principal component analysis;sparse part parameter;sparse result image;adaptive-RPCA decomposition;adaptive-RPCA method;highlight image;feature extraction;feature registration;distance metric algorithm;minimally invasive surgery","Algorithms;Common Bile Duct;Endoscopy;Humans;Image Processing, Computer-Assisted;Principal Component Analysis","4","","48","IEEE","3 Jul 2019","","","IEEE","IEEE Journals"
"Locomotive Recalibration and Prism Adaptation of Children and Teens in Immersive Virtual Environments","H. Adams; G. Narasimham; J. Rieser; S. Creem-Regehr; J. Stefanucci; B. Bodenheimer",Dept. of Electrical Engineering and Computer ScienceVanderbilt University; Vanderbilt Institute for Digital Learning; Dept. of Psychology and Human DevelopmentVanderbilt University; Department of PsychologyUniversity of Utah; Department of PsychologyUniversity of Utah; Dept. of Electrical Engineering and Computer ScienceVanderbilt University,"IEEE Transactions on Visualization and Computer Graphics","13 Mar 2018","2018","24","4","1408","1417","As virtual reality expands in popularity, an increasingly diverse audience is gaining exposure to immersive virtual environments (IVEs). A significant body of research has demonstrated how perception and action work in such environments, but most of this work has been done studying adults. Less is known about how physical and cognitive development affect perception and action in IVEs, particularly as applied to preteen and teenage children. Accordingly, in the current study we assess how preteens (children aged 8-12 years) and teenagers (children aged 15-18 years) respond to mismatches between their motor behavior and the visual information presented by an IVE. Over two experiments, we evaluate how these individuals recalibrate their actions across functionally distinct systems of movement. The first experiment analyzed forward walking recalibration after exposure to an IVE with either increased or decreased visual flow. Visual flow during normal bipedal locomotion was manipulated to be either twice or half as fast as the physical gait. The second experiment leveraged a prism throwing adaptation paradigm to test the effect of recalibration on throwing movement. In the first experiment, our results show no differences across age groups, although subjects generally experienced a post-exposure effect of shortened distance estimation after experiencing visually faster flow and longer distance estimation after experiencing visually slower flow. In the second experiment, subjects generally showed the typical prism adaptation behavior of a throwing after-effect error. The error lasted longer for preteens than older children. Our results have implications for the design of virtual systems with children as a target audience.","1941-0506","","10.1109/TVCG.2018.2794072","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8267487","Virtual environments;perceptual-motor recalibration;perception;children","Legged locomotion;Visualization;Virtual environments;Biomechanics;Calibration;Electronic mail","gait analysis;virtual reality;visual perception","teenage children;visual information;normal bipedal locomotion;physical gait;adaptation paradigm;throwing movement;post-exposure effect;visually faster flow;visually slower flow;throwing after-effect error;virtual systems;locomotive recalibration;immersive virtual environments;action work;physical development;cognitive development;visual flow;virtual reality;prism adaptation behavior;time 8 year to 12 year;time 15 year to 18 year","Adaptation, Physiological;Adolescent;Child;Female;Humans;Male;Perception;Psychomotor Performance;User-Computer Interface;Virtual Reality;Walking","","","81","Traditional","23 Jan 2018","","","IEEE","IEEE Journals"
"[POSTER] Geometric Mapping for Color Compensation Using Scene Adaptive Patches","J. H. Lee; Y. H. Kim; Y. Y. Lee; K. H. Lee",NA; NA; NA; NA,"2015 IEEE International Symposium on Mixed and Augmented Reality","12 Nov 2015","2015","","","206","207","The SAR technique using a projector-camera system allows us to make various effect on a real scene without physical reconstitution. In order to project contents on a textured scene without color imperfections, geometric and radiometric compensation of a projection image should be conducted as preprocessing. In this paper, we present a new geometric mapping method for color compensation in the projector-camera system. We capture the scene and segment it into adaptive patch according to the scene structure using the SLIC segmentation. The piece-wise polynomial function is evaluated for each patch to find pixel-to-pixel correspondences between the measured and projection images. Finally, color compensation is performed by using a color mixing matrix. Experimental results show that our geometric mapping method establishes accurate correspondences and color compensation alleviates the color imperfections which is caused by texture of a general scene.","","978-1-4673-7660-0","10.1109/ISMAR.2015.67","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328107","","Image color analysis;Cameras;Augmented reality;Image segmentation;Polynomials;Calibration;Distortion","augmented reality;image colour analysis;image segmentation;image texture","scene adaptive patches;geometric mapping method;projector-camera system;SLIC segmentation;piece-wise polynomial function;pixel-to-pixel correspondences;color compensation;color mixing matrix;general scene texture;SAR technique;spatial augmented reality","","1","","6","","12 Nov 2015","","","IEEE","IEEE Conferences"
"Unified Neural Adaptive Control for Multiple Human–Robot–Environment Interactions","L. Han; W. Xu; P. Kang; H. Yuan","School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China","IEEE Transactions on Industrial Informatics","19 Nov 2020","2021","17","2","1166","1175","To go from human demonstration to robot independent operation, there are generally three phases of interaction to undergo, including human-robot interaction (HRI), human-robot-environment interaction (HREI), and robot-environment interaction (REI). Most existing methods address problems of a single stage. In this article, a unified neural adaptive control method that organically fuses multiple interactions is proposed. HRI, REI, and their coupling effects in HREI are comprehensively considered. First, the iterative least squares method is used for robot dynamics identification based on the linearized momentum observer. The accuracy of external force observation is improved to deal with dynamic uncertainties. The human force and the environmental force are achieved and decoupled by using only a force sensor, a momentum observer, and a selection matrix S. Next, the neural adaptive control method compensating position errors caused by the model uncertainty is addressed. The control system is proved to be stable based on the Lyapunov theorem. The trajectory tracking error under the model uncertainties is reduced. Then, the adaptive admittance control method is introduced. The interaction force of HRI is minimized and the interaction force control of REI is realized. Finally, the proposed method is verified by simulations and experiments.","1941-0050","","10.1109/TII.2020.2977051","National Key Research and Development Program of China; National Natural Science Foundation of China; Key Research and Development Program of Guangdong Province; Basic Research Program of Shenzhen; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9018090","Admittance control;human–robot–environment interaction (HREI);iterative least squares (ILS) method;momentum observer;neural adaptive control","Force;Dynamics;Adaptive control;Robot sensing systems;Observers;Adaptation models","adaptive control;force control;force sensors;human-robot interaction;Lyapunov methods;mobile robots;neurocontrollers;position control;robot dynamics","human-robot-environment interaction;robot independent operation;human demonstration;multiple human-robot-environment interactions;interaction force control;adaptive admittance control method;external force observation;robot dynamics identification;iterative least squares method;REI;HRI;unified neural adaptive control method","","","","29","IEEE","28 Feb 2020","","","IEEE","IEEE Journals"
"Network-Assisted Neural Adaptive Naked-Eye 3D Video Streaming Over Wireless Networks","Y. Liu; W. He; Y. Wang; H. Yang","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Access","7 Oct 2019","2019","7","","141363","141373","High quality transmission of Virtual Reality (VR) video depends strictly on bandwidth and delay requirements. It becomes possible with the maturity and commercialization of 5G technology. However, to transmit VR video streaming over wireless communication system, we must cope with the challenge that fluctuation exists in the wireless channel conditions. For example, available channel bandwidth, packet loss rate, and interference level may vary with time due to channel fading and user's mobility. The problem is more prominent when transmitting naked-eye 3D video which generally consists of multiple viewpoints with different resolutions. In order to optimize the quality of experience (QoE) of watching naked-eye VR video over wireless networks, this paper proposes a network-assisted neural adaptive video streaming algorithm (NAVSA). Specifically, we present a modified QoE function to describe the quality of naked-eye 3D streaming quantitatively, which not only considers the quality of naked-eye 3D video itself, but also considers the phenomenon of rebuffering and video fluctuation that occurs during video transmission. Next, with the network-assisted feedback, the physical layer information, the buffer occupancy of the video client, and the size of the next video chunk are collected to train a reinforcement learning model. Based on dynamic adaptive streaming over HTTP (DASH), the model can automatically choose appropriate viewpoints and resolutions corresponding to the current condition of the wireless networks such that the network capacity can be fully explored. To verify the performance of our proposed NAVSA, we simulate 3 naked-eye 3D video application scenarios on the NS3 platform. The results show that the performance of NAVSA is about 5~8% better than some state-of-the-art algorithms in wireless networks.","2169-3536","","10.1109/ACCESS.2019.2944437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852692","Reinforcement learning;adaptive transmission;naked-eye 3D;network assistance;wireless networks","Streaming media;Three-dimensional displays;Quality of experience;Wireless networks;Bandwidth;Adaptive systems;Reinforcement learning","5G mobile communication;bandwidth allocation;channel allocation;fading channels;learning (artificial intelligence);mobility management (mobile radio);neural nets;quality of experience;radiofrequency interference;transport protocols;video streaming;virtual reality","naked-eye 3D video;naked-eye 3D video application;5G technology;quality of experience;NAVSA;reinforcement learning model;dynamic adaptive streaming over HTTP;DASH;network-assisted neural adaptive video streaming algorithm;naked-eye VR video;channel bandwidth;wireless channel conditions;wireless communication system;Virtual Reality video;network-assisted neural adaptive naked-eye 3D video streaming;NS3 platform;wireless networks;network-assisted feedback;video transmission","","","","45","CCBY","30 Sep 2019","","","IEEE","IEEE Journals"
"A Structure to Integrate Natural Interaction into VR Systems for Education in Health","D. d. S. Ferreira; L. S. Machado","NA; Lab. de Tecnol. para o Ensino Virtual e Estatistica (LabTEVE), Univ. Fed. da Paraiba (UFPB), Joao Pessoa, Brazil","2013 XV Symposium on Virtual and Augmented Reality","7 Nov 2013","2013","","","208","211","The use of virtual reality (VR) systems for education can improve the learning process in health, providing more motivation and realism to users. In general, specific devices are used to increase immersion and, in general, demand an adaptation period. Natural Interaction (NI) can provide an intuitive way to interact in VR systems since it can improve and make the communication between users and the system easier. The present work investigated NI techniques provided by VR frameworks for health. As a result, was designed a structure to integrate NI techniques into a framework.","","978-0-7695-5001-5","10.1109/SVR.2013.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6655781","Natural Interaction;Virtual Reality;Optical Tracking;Health Education","Visualization;Education;Virtual reality;Three-dimensional displays;Mice;Nickel;Multimedia communication","biomedical education;computer aided instruction;health care;human computer interaction;medical computing;virtual reality","VR frameworks;NI techniques;user communication;natural Interaction;adaptation period;user realism;user motivation;learning process;health education;VR systems;virtual reality","","","","21","","7 Nov 2013","","","IEEE","IEEE Conferences"
"Self-Supervised Pose Adaptation for Cross-Domain Image Animation","C. Wang; C. Xu; D. Tao","School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW, Australia; School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW, Australia; School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW, Australia","IEEE Transactions on Artificial Intelligence","25 Nov 2020","2020","1","1","34","46","Image animation is to animate a still image of the object of interest using poses extracted from another video sequence. Through training on a large-scale video dataset, most existing approaches aim to explore disentangled appearance and pose representations of training frames. Then, the desired output with a specific appearance and pose can be synthesized via recombining learned representations. However, in some real-world applications, test images may lack the corresponding video ground-truth or follow a different distribution than the distribution of the training video frames (i.e., different domains), which largely limit the performance of existing methods. In this paper, we propose domain-independent pose representations that are compatible with and accessible by still images from a different domain. Specifically, we devise a two-stage self-supervised pose adaptation framework for general image animation tasks. A domain-independent pose adaptation generative adversarial network (DIPA-GAN) and a shuffle-patch generative adversarial network (Shuffle-patch GAN) are proposed to penalize the rationality of the synthesized frame's pose and appearance, respectively. Finally, experiments evaluated on various image animation tasks, which include same/cross-domain moving objects, facial expression transfer and human pose retargeting, demonstrate the superiority of the proposed framework over prior literature. Impact Statement-Image animation is a popular technology in video production. Benefiting from the rapid development of artificial intelligence (AI), recent image animation algorithms have been widely used in real-world applications, such as virtual AI news anchor, virtual try-on, and face swapping. However, most existing methods are designed for specific cases. To animate a new portrait, users are asked to collect hundreds of images of the same person and train a new model. The technology proposed in this paper overcomes these training limitations and generalizes image animations. In the challenging cross-domain facial expression transfer task, the user study demonstrated that our technology achieved more than 20% increase in animation success rate. The proposed technology could benefit users in a wide variety of industries including movie production, virtual reality, social media and online retail.","2691-4581","","10.1109/TAI.2020.3031581","Australian Research Council Projects; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229197","Adversarial learning;deep learning;representation learning","Animation;Task analysis;Training;Generative adversarial networks;Artificial intelligence;Solid modeling;Adaptation models","computer animation;face recognition;feature extraction;image classification;image motion analysis;image sequences;learning (artificial intelligence);neural nets;pose estimation;video signal processing;virtual reality","cross-domain image animation;video sequence;large-scale video dataset;learned representations;adaptation framework;general image animation tasks;adaptation generative adversarial network;shuffle-patch generative adversarial network;synthesized frame;video production;animation success rate;cross-domain facial expression transfer task;image animation algorithm;video ground-truth","","","","59","IEEE","19 Oct 2020","","","IEEE","IEEE Journals"
"Adaptive information density for augmented reality displays","M. Tatzgern; V. Orso; D. Kalkofen; G. Jacucci; L. Gamberini; D. Schmalstieg",Salzburg University of Applied Sciences; University of Padova; Graz University of Technology; University of Helsinki; University of Padova; Graz University of Technology,"2016 IEEE Virtual Reality (VR)","7 Jul 2016","2016","","","83","92","Augmented Reality (AR) browsers show geo-referenced data in the current view of a user. When the amount of data grows too large, the display quickly becomes cluttered. Clustering items by spatial and semantic attributes can temporarily alleviate the issue, but is not effective against an increasing amount of data. We present an adaptive information density display for AR that balances the amount of presented information against the potential clutter created by placing items on the screen. We use hierarchical clustering to create a level-of-detail structure, in which nodes closer to the root encompass groups of items, while the leaf nodes contain single items. Our method selects items and groups from different levels of this hierarchy based on user-defined preferences and on the amount of visual clutter caused by placing these items. The number of presented items is adapted during user interaction to avoid clutter. We compare our interface to a conventional AR browser interface in a qualitative user study. Users clearly preferred our interface, because it provided a better overview of the data and allowed for easier comparison. In a second study, we evaluated the effect of different degrees of clustering on search and recall tasks. Users generally made fewer errors, when using our interface for a search task, which indicates that the reduced clutter allowed them to stay focused on finding the relevant items.","2375-5334","978-1-5090-0836-0","10.1109/VR.2016.7504691","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504691","","Clutter;Data visualization;Visualization;Browsers;Semantics;Electronic mail;Clustering algorithms","augmented reality;computer displays;online front-ends;pattern clustering;user interfaces","adaptive information density display;augmented reality displays;AR browsers;geo-referenced data;items clustering;spatial attributes;semantic attributes;hierarchical clustering;level-of-detail structure;leaf nodes;user-defined preferences;visual clutter;AR browser interface;search-recall tasks","","8","","24","","7 Jul 2016","","","IEEE","IEEE Conferences"
"Hybrid metaheuristics for solving the quadratic assignment problem and the generalized quadratic assignment problem","A. Gunawan; K. M. Ng; K. L. Poh; H. C. Lau","Living Analytics Research Centre, School of Information Systems, Singapore Management University, 80 Stamford Road, Singapore 78902; Industrial and Engineering Department, National University of Singapore, Singapore; Industrial and Engineering Department, National University of Singapore, Singapore; Living Analytics Research Centre, School of Information Systems, Singapore Management University, 80 Stamford Road, Singapore 78902","2014 IEEE International Conference on Automation Science and Engineering (CASE)","30 Oct 2014","2014","","","119","124","This paper presents a hybrid metaheuristic for solving the Quadratic Assignment Problem (QAP). The proposed algorithm involves using the Greedy Randomized Adaptive Search Procedure (GRASP) to construct an initial solution, and then using a hybrid Simulated Annealing and Tabu Search (SA-TS) algorithm to further improve the solution. Experimental results show that the hybrid metaheuristic is able to obtain good quality solutions for QAPLIB test problems within reasonable computation time. The proposed algorithm is extended to solve the Generalized Quadratic Assignment Problem (GQAP), with an emphasis on modelling and solving a practical problem, namely an examination timetabling problem. We found that the proposed algorithm is able to perform better than the standard SA algorithm does.","2161-8089","978-1-4799-5283-0","10.1109/CoASE.2014.6899314","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6899314","","Benchmark testing;Linear programming;Simulated annealing;Standards;Educational institutions;Heuristic algorithms","education;quadratic programming;search problems;simulated annealing","hybrid metaheuristics;generalized quadratic assignment problem;greedy randomized adaptive search procedure;GRASP;hybrid simulated annealing and tabu search algorithm;SA-TS;good quality solutions;QAPLIB test problems;GQAP;examination timetabling problem;standard SA algorithm","","4","","23","","30 Oct 2014","","","IEEE","IEEE Conferences"
"Toed-in vs Parallel Displays in Video See-Through Head-Mounted Displays for Close-Up View","N. Cattari; F. Cutolo; R. D’amato; U. Fontana; V. Ferrari","Department of Translational Research and New Technologies in Medicine and Surgery, EndoCAS Centre, University of Pisa, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy; Department of Translational Research and New Technologies in Medicine and Surgery, EndoCAS Centre, University of Pisa, Pisa, Italy; Department of Information Engineering, University of Pisa, Pisa, Italy","IEEE Access","8 Nov 2019","2019","7","","159698","159711","In non-orthostereoscopic video see-through (VST) head-mounted displays (HMDs), the perception of the three-dimensional space is negatively altered by geometrical aberrations, which may lead to perceptual errors, problems of hand-eye coordination, and discomfort for the user. Parallax-free VST HMDs have been proposed, yet their embodiments are generally difficult to create. The present study investigates the guidelines for the development of non-orthostereoscopic VST HMDs capable of providing perceptually coherent augmentations for close-up views, hence specifically devoted to guide high-precision manual tasks. Our underlying rationale is that, under VST view, a perspective-preserving conversion of the camera frames is sufficient to restore the natural perception of the relative depths around a pre-defined working distance in non-orthostereoscopic VST HMDs. This perspective conversion needs to account for the geometry of the visor and the working distance. A simulation platform was designed to compare the on-image displacements between the direct view of the world and the perspective-corrected VST view, considering three different geometrical arrangements of cameras and displays. A user study with a custom-made VST HMD was then conducted to evaluate quantitatively and qualitatively which of the three configurations was the most effective in mitigating the impact of the geometrical aberrations around the reference distance. The results of the simulations and of the user study both proved that, in non-orthostereoscopic VST HMDs, display convergence can be prevented, as the perspective conversion of the camera frames is sufficient to restore the correct stereoscopic perception by the user in the peripersonal space.","2169-3536","","10.1109/ACCESS.2019.2950877","HORIZON2020 Project VOSTARS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8888173","Head-mounted display;stereoscopic displays;augmented reality;video see-through displays;orthoscopic view;optical aberrations","Optical distortion;Cameras;Optical imaging;Nonlinear optics;Adaptive optics;Optical sensors;Resists","aberrations;augmented reality;cameras;helmet mounted displays;stereo image processing;three-dimensional displays;video cameras;visual perception","display convergence;custom-made VST HMD;cameras;perspective-corrected VST view;direct view;perspective conversion;camera frames;perspective-preserving conversion;high-precision manual tasks;perceptually coherent augmentations;nonorthostereoscopic VST HMDs capable;parallax-free VST HMDs;hand-eye coordination;perceptual errors;geometrical aberrations;nonorthostereoscopic video;toed-in vs parallel displays","","4","","41","CCBY","31 Oct 2019","","","IEEE","IEEE Journals"
"NaviBoard and NaviChair: Limited Translation Combined with Full Rotation for Efficient Virtual Locomotion","T. Nguyen-Vo; B. E. Riecke; W. Stuerzlinger; D. -M. Pham; E. Kruijff","School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC, Canada; School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC, Canada; School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC, Canada; School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC, Canada; Institute of Visual Computing, Bonn-Rhein-Sieg University of Applied Sciences, Sankt Augustin, Germany","IEEE Transactions on Visualization and Computer Graphics","24 Nov 2020","2021","27","1","165","177","Walking has always been considered as the gold standard for navigation in Virtual Reality research. Though full rotation is no longer a technical challenge, physical translation is still restricted through limited tracked areas. While rotational information has been shown to be important, the benefit of the translational component is still unclear with mixed results in previous work. To address this gap, we conducted a mixed-method experiment to compare four levels of translational cues and control: none (using the trackpad of the HTC Vive controller to translate), upper-body leaning (sitting on a “NaviChair”, leaning the upper-body to locomote), whole-body leaning/stepping (standing on a platform called NaviBoard, leaning the whole body or stepping one foot off the center to navigate), and full translation (physically walking). Results showed that translational cues and control had significant effects on various measures including task performance, task load, and simulator sickness. While participants performed significantly worse when they used a controller with no embodied translational cues, there was no significant difference between the NaviChair, NaviBoard, and actual walking. These results suggest that translational body-based motion cues and control from a low-cost leaning/stepping interface might provide enough sensory information for supporting spatial updating, spatial awareness, and efficient locomotion in VR, although future work will need to investigate how these results might or might not generalize to other tasks and scenarios.","1941-0506","","10.1109/TVCG.2019.2935730","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809840","Adaptive control;cognitive informatics;human computer interaction;human factors;user interface;virtual reality","Legged locomotion;Task analysis;Navigation;Resists;Wheelchairs;Virtual reality;Input devices","virtual reality","physical translation;rotational information;translational component;mixed-method experiment;HTC Vive controller;NaviChair;NaviBoard;task performance;embodied translational cues;walking;translational body-based motion cues;virtual locomotion;gold standard;navigation;virtual reality;upper-body leaning;whole-body leaning;whole-body stepping;task load;simulator sickness;low-cost leaning interface;low-cost stepping interface;sensory information;spatial updating;spatial awareness","","","","50","IEEE","22 Aug 2019","","","IEEE","IEEE Journals"
"HySAR: Hybrid Material Rendering by an Optical See-Through Head-Mounted Display with Spatial Augmented Reality Projection","T. Hamasaki; Y. Itoh; Y. Hiroi; D. Iwai; M. Sugimoto",Keio University; Tokyo Institue of TechnologyRIKENKeio University; Keio University; Osaka University; Keio University,"IEEE Transactions on Visualization and Computer Graphics","13 Mar 2018","2018","24","4","1457","1466","Spatial augmented reality (SAR) pursues realism in rendering materials and objects. To advance this goal, we propose a hybrid SAR (HySAR) that combines a projector with optical see-through head-mounted displays (OST-HMD). In an ordinary SAR scenario with co-located viewers, the viewers perceive the same virtual material on physical surfaces. In general, the material consists of two components: a view-independent (VI) component such as diffuse reflection, and a view-dependent (VD) component such as specular reflection. The VI component is static over viewpoints, whereas the VD should change for each viewpoint even if a projector can simulate only one viewpoint at one time. In HySAR, a projector only renders the static VI components. In addition, the OST-HMD renders the dynamic VD components according to the viewer's current viewpoint. Unlike conventional SAR, the HySAR concept theoretically allows an unlimited number of co-located viewers to see the correct material over different viewpoints. Furthermore, the combination enhances the total dynamic range, the maximum intensity, and the resolution of perceived materials. With proof-of-concept systems, we demonstrate HySAR both qualitatively and quantitatively with real objects. First, we demonstrate HySAR by rendering synthetic material properties on a real object from different viewpoints. Our quantitative evaluation shows that our system increases the dynamic range by 2.24 times and the maximum intensity by 2.12 times compared to an ordinary SAR system. Second, we replicate the material properties of a real object by SAR and HySAR, and show that HySAR outperforms SAR in rendering VD specular components.","1941-0506","","10.1109/TVCG.2018.2793659","JSPS; JST CREST; JST PRESTO; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260968","Optical see-through displays;hybrid material rendering;spatial augmented reality","Augmented realtiy;Head-mounted displays;Rendering (computer graphics);Optical reflection;Adaptive optics","augmented reality;helmet mounted displays;rendering (computer graphics)","optical see-through head-mounted display;VD specular components;static VI components;view-dependent component;view-independent component;virtual material;hybrid SAR;spatial augmented reality projection;hybrid material rendering","","1","","37","Traditional","17 Jan 2018","","","IEEE","IEEE Journals"
"A Survey on Adaptive 360° Video Streaming: Solutions, Challenges and Opportunities","A. Yaqoob; T. Bi; G. -M. Muntean","Insight Centre for Data Analytics, Dublin City University, Dublin, Ireland; Performance Engineering Laboratory, Dublin City University, Dublin, Ireland; Performance Engineering Laboratory, Dublin City University, Dublin, Ireland","IEEE Communications Surveys & Tutorials","20 Nov 2020","2020","22","4","2801","2838","Omnidirectional or 360° video is increasingly being used, mostly due to the latest advancements in immersive Virtual Reality (VR) technology. However, its wide adoption is hindered by the higher bandwidth and lower latency requirements than associated with traditional video content delivery. Diverse researchers propose and design solutions that help support an immersive visual experience of 360° video, primarily when delivered over a dynamic network environment. This paper presents the state-of-the-art on adaptive 360° video delivery solutions considering end-to-end video streaming in general and then specifically of 360° video delivery. Current and emerging solutions for adaptive 360° video streaming, including viewport-independent, viewport-dependent, and tile-based schemes are presented. Next, solutions for network-assisted unicast and multicast streaming of 360° video content are discussed. Different research challenges for both on-demand and live 360° video streaming are also analyzed. Several proposed standards and technologies and top international research projects are then presented. We demonstrate the ongoing standardization efforts for 360° media services that ensure interoperability and immersive media deployment on a massive scale. Finally, the paper concludes with a discussion about future research opportunities enabled by 360° video.","1553-877X","","10.1109/COMST.2020.3006999","European Regional Development Fund through the Science Foundation Ireland (SFI) Research Centres Programme; Insight Centre for Data Analytics; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9133103","360° video streaming;virtual reality;HTTP adaptive streaming;MPEG-DASH;video tiling;viewport prediction;quality assessment;standards","Streaming media;Quality of service;Quality assessment;Real-time systems;Bandwidth;Quality of experience","multicast communication;open systems;video streaming;virtual reality","360° media services;360° video content;end-to-end video;adaptive 360° video delivery solutions;traditional video content delivery;immersive Virtual Reality technology;omnidirectional video;adaptive 360° video streaming","","1","","308","IEEE","3 Jul 2020","","","IEEE","IEEE Journals"
"A learning environment for augmented reality mobile learning","J. Cubillo; S. Martín; M. Castro; G. Diaz; A. Colmenar; I. Botički","Electrical and Computer Engineering Department, National University for Distance Education of Spain (UNED), Madrid, Spain; Electrical and Computer Engineering Department, National University for Distance Education of Spain (UNED), Madrid, Spain; Electrical and Computer Engineering Department, National University for Distance Education of Spain (UNED), Madrid, Spain; Electrical and Computer Engineering Department, National University for Distance Education of Spain (UNED), Madrid, Spain; Electrical and Computer Engineering Department, National University for Distance Education of Spain (UNED), Madrid, Spain; Department of Applied Computing, Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia","2014 IEEE Frontiers in Education Conference (FIE) Proceedings","19 Feb 2015","2014","","","1","8","There are many tools that enable the development of the augmented reality (AR) activities, some of them can even create and generate an AR experience where the incorporation of 3D objects is simple. However AR tools used in education are different from the general tools limited to the reproduction of virtual content. The purpose of this paper is to present a learning environment based on augmented reality, which can be used both by teachers to develop quality AR educational resources and by students to acquire knowledge in an area. Common problems teachers have in applying AR have been taken into account by producing an authoring tool for education which includes the following characteristics: (1) the ability to incorporate diverse multimedia resources such as video, sound, images and 3D objects in an easy manner, 2) the ability to incorporate tutored descriptions into elements which are being displayed (thus, the student is provided with an additional information, description or narrative about the resource, while the content gets adapted and personalized), (3) the possibility for the teacher to incorporate multiple choice questions (MCQ) into the virtual resource (useful for instant feedback to students on their understanding, it can be useful for the student to know what are the most important points of that issue and for the teacher to assess whether the student distinguishes different concepts) and (4) a library of virtual content where all resources are available in a simple and transparent way for any user. In this study ARLE is used to add AR technologies into notes or books created by the teacher, thereby supplementing both the theoretical and practical content without any programming skills needed on the designers' behalf. In addition to presenting system architecture and the examples of its educational use, a survey concerning use of AR amongst teachers in Spain has been conducted.","2377-634X","978-1-4799-3922-0","10.1109/FIE.2014.7044039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7044039","augmented reality;learning environment;mobile learning;authoring tools","Augmented reality;Education;Three-dimensional displays;Licenses;Mobile communication;Programming profession","augmented reality;mobile learning;multimedia computing","learning environment;augmented reality mobile learning;augmented reality activities;AR activities;3D objects;AR tools;virtual content;AR educational resources;authoring tool;multimedia resources;multiple choice questions;MCQ;virtual resource","","6","","33","","19 Feb 2015","","","IEEE","IEEE Conferences"
"Coping with hotspots: AoI adaption strategies for P2P Networked Virtual Environments","S. Krause","Institute for Telematics, Universität Karlsruhe (TH), Zirkel 2, D-76128, Germany","2009 International Conference on Ultra Modern Telecommunications & Workshops","4 Dec 2009","2009","","","1","6","Massively Multiplayer Online Games and Virtual Worlds are among the most popular applications on the Internet. As player numbers increase, the limits of the currently dominant client/server architecture are becoming obvious. To overcome those limits, the research community has developed protocols for these so-called Distributed Networked Virtual Environments (DVEs) based on peer-to-peer technologies. One problem that has to be solved for practical peer-to-peer protocols for DVEs are hotspots: participants tend to form groups in the virtual environment. If these groups become very large, players have to send event messages to a large number of other players. This imposes a big load on the peer-to-peer protocol. To alleviate the problem, adaptive Area of Interest (AoI) sizes can be used: If the player density becomes too high, the players' AoI size will be decreased. In this paper we identify different adaption strategies and, using simulations, evaluate the influence of the respective strategies on the peer-to-peer protocol. As a result, we show that distributed strategies generally yield a better performance than purely local strategies.","2157-023X","978-1-4244-3942-3","10.1109/ICUMT.2009.5345511","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5345511","","Virtual environment;Web server;Protocols;Peer to peer computing;Telematics;IP networks;Network servers;Environmental management;Aggregates;Relays","client-server systems;computer games;Internet;peer-to-peer computing;protocols;social networking (online);virtual reality","AoI adaption strategy;P2P networked virtual environment;massively multiplayer online game;virtual world;Internet;client-server architecture;distributed networked virtual environment;peer-to-peer protocol;adaptive area of interest","","1","","14","","4 Dec 2009","","","IEEE","IEEE Conferences"
"Motion Sickness in Virtual Reality: An Empirical Evaluation","U. A. Chattha; U. I. Janjua; F. Anwar; T. M. Madni; M. F. Cheema; S. I. Janjua","Department of Computer Science, COMSATS University Islamabad, Islamabad, Pakistan; Department of Computer Science, COMSATS University Islamabad, Islamabad, Pakistan; Department of Health Informatics, COMSATS University Islamabad, Islamabad, Pakistan; Department of Computer Science, COMSATS University Islamabad, Islamabad, Pakistan; Department of Computer Science, FAST University (NUCES) Islamabad, Islamabad, Pakistan; Medical Hospital, Islamabad, Pakistan","IEEE Access","23 Jul 2020","2020","8","","130486","130499","Due to rapid growth in Virtual Reality (VR) technology, the industry of VR is expected to grow around $26.89 billion by 2022. However, with its extensive growth and immersive inclusion in human life, health-related issues are reported including, but not limited to nauseated feeling, vomiting, dizziness and cold sweats. These issues introduce a well-known side effect termed as motion sickness in VR users. Consequently, motion sickness limits the VR community in the full adaptation of this immersive technology. Since there is no lack of literature investigating motion sickness caused by VR, yet researches on the effect of VR on human's physiology is still in its infancy. This study presents novel findings, by comparing different factors such as gender, motion sickness experience, 3D games experience and VR experience. Furthermore, it reports the impact of concerning factors in a within-subjects design (46 participants participated in an experiment) under different virtual environment genres. The key findings of this article report that there is a significant difference in the amount of motion sickness when shifting from pleasant to the horror genre of the environment and having a strong dependence on gender. Moreover, the type of virtual environment is an essential factor that has a notable effect on the user's blood pressure, blood sugar and heart rate. However, past experiences with motion sickness and 3D games show no significant impact on the user's level of motion sickness.","2169-3536","","10.1109/ACCESS.2020.3007076","Higher Education Commission of Pakistan through the Start-Up Research Grant Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9133071","Motion sickness;simulator sickness;virtual reality;virtual worlds;virtual environments;VR sickness","Virtual environments;Physiology;Heart rate;Industries;Three-dimensional displays;Games;Blood pressure","gender issues;human factors;physiology;virtual reality","heart rate;blood sugar;3D games;user blood pressure;virtual environment genres;3D games experience;human physiology;immersive technology;health-related issues;empirical evaluation;motion sickness experience;VR community;virtual reality technology","","","","42","CCBY","3 Jul 2020","","","IEEE","IEEE Journals"
"Virtual 3D Simulation of Fault Diagnosis and its Realization in the Electrical System of Certain Equipment","Z. Liu; S. An; Y. Wang; X. Wang","Dept. of Electron. Eng., Ordnance Eng. Coll., Shijiazhuang, China; Dept. of Electron. Eng., Ordnance Eng. Coll., Shijiazhuang, China; Dept. of Electron. Eng., Ordnance Eng. Coll., Shijiazhuang, China; NA","2012 Second International Conference on Instrumentation, Measurement, Computer, Communication and Control","4 Feb 2013","2012","","","1338","1341","Focusing on the problems existing in conventional maintenance training ways and means which can't adapt to the needs of equipment development, a set of desktop interactive in the electrical system of certain equipment by means of virtual reality techniques was developed. Aimed at the complicated structures and relationships within electrical maintenance, the general functional module of virtual maintenance system was established, the 3 dimension (3D) model nodes of electrical system were rebuilt, and the research on key techniques relevant to maintenance simulation interaction was carried out. The system is in practice proved to be a new way and mean for complicated electrical maintenance training.","","978-1-4673-5034-1","10.1109/IMCCC.2012.315","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6429151","fault diagnosis;virtual maintenance;modal node","Maintenance engineering;Circuit faults;Assembly;Training;Testing;Solid modeling;Instruments","fault diagnosis;geometry;maintenance engineering;power apparatus;power engineering computing;virtual reality","3D geometry model;3 dimension model;electrical maintenance;virtual reality technique;desktop interactive;maintenance training way;certain equipment;electrical system;fault diagnosis;virtual 3D simulation","","","","6","","4 Feb 2013","","","IEEE","IEEE Conferences"
"3rd Virtual and Augmented Reality for Good (VAR4Good) Workshop","A. Dey; M. Billinghurst; G. Welch; E. Rojas-Muñoz",NA; NA; NA; NA,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","364","364","Virtual Reality (VR) and Augmented Reality (AR) are becoming mainstream. With the research and technological advances, it is now possible to use these technologies in almost all domains and places. This provides a bigger opportunity to create applications that intend to impact society in greater ways than beyond just entertainment. Today the world is facing different challenges including healthcare, environment, and education. Now is the time to explore how VR/AR might be used to solve widespread societal challenges. The third Virtual and Augmented Reality for Good (VAR4Good) workshop will bring together researchers, developers, and industry partners in presenting and promoting research that intends to solve real-world problems using VR/AR. The workshop will provide a platform to grow a research community that discusses challenges and opportunities to create Virtual and Augmented Reality for Good. We invite application and position papers (2-4 pages, excluding references), that address the way that VR/AR technologies can solve real-world problems in various application domains including, but not limited to, health, the environment, education, sports, the arts, and applications in support of special needs such as assistive, adaptive, and rehabilitative applications. Our focus and preference will be on applications that are beyond general uses of VR/AR. Please see full CFP on our website.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699256","","Augmented reality;Conferences;Australia;Education;Entertainment industry;Medical services","augmented reality;human computer interaction;technology management","VAR4Good;technological advances;Virtual and Augmented Reality for Good workshop;VR/AR technologies","","","","","","29 Apr 2019","","","IEEE","IEEE Conferences"
"An analysis of eye-tracking data in foveated ray tracing","T. Roth; M. Weier; A. Hinkenjann; Y. Li; P. Slusallek","Bonn-Rhein-Sieg University of Applied Sciences and Brunel University London; Bonn-Rhein-Sieg University of Applied Sciences and Saarland University; Bonn-Rhein-Sieg University of Applied Sciences; Brunel University London; Saarland University, Intel Visual Computing Institute and German Research Center for Artificial Intelligence (DFKI)","2016 IEEE Second Workshop on Eye Tracking and Visualization (ETVIS)","16 Feb 2017","2016","","","69","73","We present an analysis of eye tracking data produced during a quality-focused user study of our own foveated ray tracing method. Generally, foveated rendering serves the purpose of adapting actual rendering methods to a user's gaze. This leads to performance improvements which also allow for the use of methods like ray tracing, which would be computationally too expensive otherwise, in fields like virtual reality (VR), where high rendering performance is important to achieve immersion, or fields like scientific and information visualization, where large amounts of data may hinder real-time rendering capabilities. We provide an overview of our rendering system itself as well as information about the data we collected during the user study, based on fixation tasks to be fulfilled during flights through virtual scenes displayed on a head-mounted display (HMD). We analyze the tracking data regarding its precision and take a closer look at the accuracy achieved by participants when focusing the fixation targets. This information is then put into context with the quality ratings given by the users, leading to a surprising relation between fixation accuracy and quality ratings.","","978-1-5090-4731-4","10.1109/ETVIS.2016.7851170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7851170","","Rendering (computer graphics);Visualization;Ray tracing;Target tracking;Electronic mail;Tunneling;Focusing","data analysis;data visualisation;gaze tracking;helmet mounted displays;ray tracing;rendering (computer graphics);virtual reality","eye-tracking data analysis;foveated ray tracing method;foveated rendering;actual rendering methods;virtual reality;scientific visualization;information visualization;real-time rendering capabilities;fixation tasks;virtual scenes;head-mounted display;HMD;quality ratings","","5","","17","","16 Feb 2017","","","IEEE","IEEE Conferences"
"Virtual Reality Video Game Paired with Physical Monocular Blurring as Accessible Therapy for Amblyopia","O. Hurd; S. Kurniawan; M. Teodorescu","University of California, Santa Cruz; University of California, Santa Cruz; University of California, Santa Cruz","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","492","499","This paper discusses a virtual reality (VR) therapeutic video game for treatment of the neurological eye disorder, Amblyopia. Amblyopia is often referred to as lazy eye, and it entails weaker vision in one eye due to a poor connection between the eye and the brain. Until recently it was thought to be untreatable in adults, but new research has proven that with consistent therapy even adults can improve their Amblyopia, especially through perceptual learning and video games. Even so, therapy compliance remains low due to the fact that conventional therapies are perceived as either invasive, dull and/or boring. Our game aims to make Amblyopia therapy more immersive, enjoyable and playful. The game was perceived by our users to be a fun and accessible alternative, as it involves adhering a Bangerter foil (an opaque sticker) on a VR headset to blur vision in an Amblyopic person's dominant eye while having them playa VR video game. To perform well in the video game, their brain must adapt to rely on seeing with their weaker eye, thereby reforging that neurological connection. While testing our game, we also studied users behavior to investigate what visual and kinetic components were more effective therapeutically. Our findings generally show positive results, showing that visual acuity in adults increases with 45 minutes of therapy. Amblyopia has many negative symptoms including poor depth perception (nec-essary for daily activities such as driving), so this therapy could be life changing for adults with Amblyopia.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8797997","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8797997","Visual acuity—Visual stereopsis—LogMAR—Crowding","Games;Vision defects;Medical treatment;Visualization;Virtual reality;Headphones;Testing","computer games;eye;medical computing;neurophysiology;patient treatment;virtual reality;vision;vision defects;visual perception","accessible therapy;virtual reality therapeutic video game;neurological eye disorder;lazy eye;consistent therapy;Amblyopia therapy;Amblyopic person;playa VR video game;weaker eye;VR headset;kinetic components;visual components;depth perception","","","","31","","15 Aug 2019","","","IEEE","IEEE Conferences"
"An innovative virtual reality system for mild cognitive impairment: Diagnosis and evaluation","S. Yeh; Y. Chen; C. Tsai; A. Rizzo","Computer Science and Information Engineering Dept., National Central University, Taiwan; Computer Science and Information Engineering Dept., National Central University, Taiwan; Taipei Veterans General Hospital, Taiwan; Institute for Creative Technologies, University of Southern California, USA","2012 IEEE-EMBS Conference on Biomedical Engineering and Sciences","15 Apr 2013","2012","","","23","27","In advanced countries throughout the world, the population of Alzheimer's Disease(AD) patients has been gradually increasing with the aging of the society. As a result, it has become an important research topic how to diagnose AD early and give necessary treatment and training to AD patients, especially those with mild cognitive impairment(MCI), whose executive functions such as response inhibition, cognitive flexibility, attention switching and planning may display evident disorder and impairment. Unlike traditional paper tests and subjective assessments by the patient's relatives, this study adopts virtual reality(VR) technology to develop a novel diagnosis & assessment system, which uses head mounted display(HMD), game technology and sensors to generate an interactive and panoramic scenario-a virtual convenience store-for assessment of executive functions and memory. A variety of tasks of multi-layered difficulty-level hierarchy, such as memorizing a shopping list, looking for certain goods, and checking out, has been designed for customized and adaptive assessment, training, and treatment of MD. In the meantime, the study also records test-takers' performance data (including path and central-vision movement) in the process of all tasks for the development of a novel diagnosis & assessment method. Moreover, test-takers' technology acceptance is measured for assessing the elderly's subjective perception of new technology and discussing the topic of human-machine interaction. In the study, tests on 2 healthy adults have been completed, the system's functionality has been preliminarily verified, and test-takers' subjective perception of the system has been investigated.","","978-1-4673-1666-8","10.1109/IECBES.2012.6498023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6498023","virtual realit;mild cognitive impairment;Alzheimer's Disease;executive function","","computer games;diseases;helmet mounted displays;patient diagnosis;patient treatment;sensors;virtual reality","innovative virtual reality system;mild cognitive impairment;Alzheimer disease patient;AD diagnosis;AD patient treatment;AD patient training;MCI;response inhibition;cognitive flexibility;attention switching;planning;VR;head mounted display;HMD;game technology;sensors;virtual convenience store;multilayered difficulty-level hierarchy;test-taker performance data;path movement;central-vision movement;test-taker technology acceptance;elderly subjective perception;human-machine interaction;system functionality;test-taker subjective perception","","7","","7","","15 Apr 2013","","","IEEE","IEEE Conferences"
"Virtual training of potential function based guiding styles","P. Korondi; A. R. Varkonyi-Koczy; S. Kovacs; P. Baranyi; M. Sugiyama","Japanese-Hungarian Lab., Budapest Univ. of Technol. & Econ., Hungary; NA; NA; NA; NA","Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569)","7 Aug 2002","2001","","","2529","2533 vol.5","The main goal of this paper is two-fold. One goal is to adapt the advantages of using an immersive virtual environment for teaching robots. The subsequent aim is to define a suitable model for a robot guiding-style description, which can serve as an easily adaptable and implementable general guiding-style description of various mobile robots. Guidelines for virtual training and the proposed general neural network-based guiding-style description model are also introduced in this paper.","","0-7803-7078-3","10.1109/NAFIPS.2001.943620","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=943620","","Humans;Employment;Telerobotics;Education;Laboratories;Environmental economics;Virtual environment;Mobile robots;Space technology;Displays","mobile robots;robot programming;learning systems;virtual reality;path planning;neural nets","virtual training;potential function-based guiding styles;immersive virtual environment;mobile robot teaching;robot guiding-style description;neural network-based model","","3","","14","","7 Aug 2002","","","IEEE","IEEE Conferences"
"MAC Scheduling for Multiuser Wireless Virtual Reality in 5G MIMO-OFDM Systems","M. Huang; X. Zhang","Intel Corp., USA; Intel Corp., USA","2018 IEEE International Conference on Communications Workshops (ICC Workshops)","5 Jul 2018","2018","","","1","6","Wireless Virtual Reality (VR) is a new-arising technology to enable the untethered connection between VR server and VR client, which needs to support simultaneously ultra-high data rate and ultra-high transfer reliability for video streaming, and also ultra-high responsive speed for motion-to-photon latency. Such three ultra-high (3UH) requirements constitute the basic characteristics of the generalized tactile internet. This paper proposes a multiuser MAC scheduling scheme for VR service in 5G MIMO-OFDM system, which can maximize the number of simultaneous VR clients while guaranteeing their 3UH quality-of-experience (QoE). Specifically, this scheme is composed of three novel functions, including video frame differentiation and delay-based weight calculation, spatial-frequency user selection based on maximum aggregate delay-capacity utility (ADCU), and link adaptation with dynamic block-error-rate (BLER) target. In addition, a low-complexity downlink MIMO user selection algorithm is developed, which can reduce the calculation amount with one order. It is demonstrated by the simulation results that the proposed scheme increases 31.6% for the maximum number of simultaneously served VR users than the traditional scheme with maximum-sum-capacity based scheduling and fixed BLER target based link adaptation.","2474-9133","978-1-5386-4328-0","10.1109/ICCW.2018.8403486","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8403486","","Streaming media;Wireless communication;5G mobile communication;Servers;Base stations;Payloads;Reliability","5G mobile communication;access protocols;Internet;MIMO communication;multi-access systems;OFDM modulation;quality of experience;radio links;telecommunication scheduling;video streaming;virtual reality","untethered connection;VR server;ultra-high data rate;ultra-high transfer reliability;video streaming;ultra-high responsive speed;ultra-high requirements;multiuser MAC scheduling scheme;VR service;simultaneous VR clients;3UH quality-of-experience;video frame differentiation;spatial-frequency user selection;maximum aggregate delay-capacity utility;dynamic block-error-rate target;low-complexity downlink MIMO user selection algorithm;simultaneously served VR users;multiuser wireless virtual reality;5G MIMO-OFDM systems;motion-to-photon latency;generalized tactile Internet;delay-based weight calculation;ADCU;link adaptation;BLER","","5","","15","","5 Jul 2018","","","IEEE","IEEE Conferences"
"Interactive physical robot guidance through advanced 3D dynamic simulation-based robot control — A new eRobotics approach","E. G. Kaigom; J. Roßmann","Institute for Man-Machine Interaction RWTH - Aachen University, Germany; Institute for Man-Machine Interaction RWTH - Aachen University, Germany","2014 IEEE International Conference on Industrial Technology (ICIT)","11 Sep 2014","2014","","","676","681","Manual robot guidance is an intuitive and flexible approach to teach robots. It is particularly useful for manufacturers because of the low programming efforts. However, this method often requires compliance control that is generally not available in conventional position-controlled industrial robots. Addressing this issue from the perspective of simulation-driven engineering, we introduce in this contribution a novel approach for interactive physical robot guidance based upon simulated adaptable joint admittance control. The developed simulation-based controller is driven in real-time with real external joint torques estimated during interaction with a physical robot. Since the simulator closely replicates the dynamic behavior of the real robot, it enriches and enhances the robot guidance by providing unique and reliable information on the robot that is useful to the operator. The simulated compliant joint trajectories are fed back into the real robot controller to enable full-body guidance. By opening new and practical perspectives in assisted physical guidance of position-controlled robots, this approach hightlights the effectiveness of control-by-3D-simulation [1] as pursued by eRobotics [2] to address challenging issues in robotics and automation. Simulation and experimental case studies conducted on a physical 7 DoF KUKA LWR 4+ robot manipulator are provided to illustrate the performance of the approach.","","978-1-4799-3939-8","10.1109/ICIT.2014.6894912","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6894912","","Joints;Admittance;Solid modeling;Robot kinematics;Service robots;Trajectory","compliant mechanisms;electric admittance;human-robot interaction;industrial manipulators;intelligent robots;manipulator dynamics;position control;robot programming;torque;virtual reality","interactive physical robot guidance;3D dynamic simulation-based robot control;e-robotics approach;robot teaching;compliance control;simulation-driven engineering;simulated adaptable joint admittance control;real-external joint torque estimation;physical robot dynamic behavior;simulated compliant joint trajectories;assisted physical guidance;position-controlled robots;control-by-3D-simulation;physical 7-DoF KUKA LWR 4+ robot manipulator","","2","","15","","11 Sep 2014","","","IEEE","IEEE Conferences"
"Novel, Robust, and Efficient Guidewire Modeling for PCI Surgery Simulator Based on Heterogeneous and Integrated Chain-Mails","W. Wang; S. Li; H. Qin; A. Hao",NA; NA; NA; NA,"2015 14th International Conference on Computer-Aided Design and Computer Graphics (CAD/Graphics)","9 Apr 2016","2015","","","105","112","Despite the long R&D history of interactive minimally-invasive surgery and therapy simulations, the guide wire/catheter behavior modeling remains challenging in Percutaneous Coronary Intervention (PCI) surgery simulators. This is primarily due to the heterogeneous heart physiological structures and complex intravascular inter-dynamic procedures. To ameliorate, this paper advocates a novel, robust, and efficient guide wire/catheter modeling method based on heterogeneous and integrated chain-mails, that can afford medical practitioners and trainees the unique opportunity to experience the entire guide wire-dominant PCI procedures in virtual environments as our model aims to mimic what occurs in clinical settings. Our approach's originality is primarily founded upon this new method's unconditional stability, real time performance, flexibility, and high-fidelity realism for guide wire/catheter simulation. Considering the front end of the guide wire has different stiffness with its conjunctive slender body and the guide wire length is adaptive to the surrounding environment, we propose to model the spatially-varying six-degree of freedom behaviors by solely resorting to the generalized 3D chain-mails. Meanwhile, to effectively accommodate the motion constraints caused by the beating vessels and flowing blood, we integrate heterogeneous volumetric chain mails to streamline guide wire modeling and its interaction with surrounding substances. By dynamically coupling guide wire chain-mails with the surrounding media via virtual links, we are capable of efficiently simulating the collision-involved interdynamic behaviors of the guide wire. Finally, we showcase a PCI prototype simulator equipped with hap tic feedback for mimicing the guide wire intervention therapy, including pushing, pulling, and twisting operations, where the built-in high-fidelity, real-time efficiency, and stableness show great promise for its practical applications in clinical training and surgery rehearsal fields.","","978-1-4673-8020-1","10.1109/CADGRAPHICS.2015.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7450404","guidewire simulation;heterogeneous chain-mails;guidewire-vessel interaction;guidewire-blood interaction;PCI simulator;haptic feedback","Solid modeling;Adaptation models;Three-dimensional displays;Blood;Couplings;Computational modeling;Surgery","catheters;haptic interfaces;medical computing;surgery","guidewire modeling;integrated chain-mails;interactive minimally-invasive surgery;therapy simulations;guide wire/catheter behavior modeling method;percutaneous coronary intervention surgery simulators;PCI surgery simulators;heterogeneous heart physiological structures;complex intravascular inter-dynamic procedures;guide wire-dominant PCI procedures;virtual environments;unconditional stability;high-fidelity realism;guide wire/catheter simulation;conjunctive slender body;guide wire length;generalized 3D chain-mails;beating vessels;flowing blood;heterogeneous volumetric chain mails;streamline guide wire modeling;guide wire chain-mails;virtual links;collision-involved interdynamic behaviors;PCI prototype simulator;haptic feedback;guide wire intervention therapy;surgery rehearsal fields","","1","","23","","9 Apr 2016","","","IEEE","IEEE Conferences"
"Using virtual reality to induce cross-axis adaptation of postural control: Implications for rehabilitation","W. G. Wright","Temple University, Dept. of Physical Therapy, Dept. of Bioengineering, Philadelphia, PA USA","2013 International Conference on Virtual Rehabilitation (ICVR)","14 Nov 2013","2013","","","289","294","Adaptation of sensorimotor processes has been studied for over a century. However, rigorous experimental approaches require controlling as many variables as possible to study the phenomenon, which limits generalizability. Conversely testing adaptation in an unconstrained ecologically valid situation makes it difficult to identify what parameters affect this process. This study utilizes virtual environments (VE) to create complex, but controlled environments to test visual, vestibular, and sensorimotor adaptation of whole-body posture. Findings show automatic postural processes can be adapted to unusual and discordant sensory environments, suggesting its lability would be advantageous when employing the kind of sensorimotor rehabilitation therapy VE affords.","2331-9569","978-1-4799-0774-8","10.1109/ICVR.2013.6662095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6662095","sensorimotor adaptation;posture;style;styling;insert","Visualization;Virtual environments;Sea surface;Optical sensors;Eye protection;Trajectory","control engineering computing;ecology;patient rehabilitation;patient treatment;virtual reality","sensorimotor rehabilitation therapy;virtual environments;unconstrained ecology;sensorimotor process;postural control;cross-axis adaptation;virtual reality","","1","","43","","14 Nov 2013","","","IEEE","IEEE Conferences"
"A 4-dof haptic device for hysteroscopy simulation","U. Spaelter; T. Moix; D. Ilic; H. Bleuler; M. Bajka","Laboratoire de Syst. Robotiques, Fed. Inst. of Technol., Lausanne, Switzerland; Laboratoire de Syst. Robotiques, Fed. Inst. of Technol., Lausanne, Switzerland; Laboratoire de Syst. Robotiques, Fed. Inst. of Technol., Lausanne, Switzerland; Laboratoire de Syst. Robotiques, Fed. Inst. of Technol., Lausanne, Switzerland; NA","2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)","14 Feb 2005","2004","4","","3257","3263 vol.4","In minimal-invasive surgery surgeons are generally confronted with complex scenario and sometimes they have to overcome unexpected pathologies or life-threatening injuries. Therefore there is a demand for realistic training without risk to the patient. Since a decade ago there have been research activities on virtual reality surgery simulators with haptic feedback with the goal to provide an alternative to traditional training methods on animals or cadavers. Haptic feedback is a key feature for every surgery simulator for the training of hand-eye coordination. In this paper a 4-dof haptic device is presented for hysteroscopy, the examination and treatment of the uterine cavity through the vagina. Specifications are presented, and kinematics as well as force transmission are analyzed. The realized prototype, result of a systematic design process, is based on a 2-dof spherical manipulator with low inertia and a 2-dof serial extension, which allows the use of slightly adapted original instruments. With difference to common surgery simulators tool insertion and complete removal can be performed. The performance of the prototype is shortly discussed.","","0-7803-8463-6","10.1109/IROS.2004.1389919","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1389919","","Haptic interfaces;Surgery;Feedback;Prototypes;Pathology;Injuries;Virtual reality;Animals;Cadaver;Kinematics","haptic interfaces;surgery;virtual reality;medical robotics;manipulators;medical computing","4dof haptic device;hysteroscopy simulation;minimal invasive surgery surgeon;virtual reality surgery simulator;haptic feedback;spherical manipulator","","4","","18","","14 Feb 2005","","","IEEE","IEEE Conferences"
"On Benchmarking Iris Recognition within a Head-mounted Display for AR/VR Applications","F. Boutros; N. Damer; K. Raja; R. Ramachandra; F. Kirchbuchner; A. Kuijper","Mathematical and Applied Visual Computing, TU Darmstadt,Darmstadt,Germany; Mathematical and Applied Visual Computing, TU Darmstadt,Darmstadt,Germany; Norwegian Biometrics Laboratory, NTNU,Gjovik,Norway; Norwegian Biometrics Laboratory, NTNU,Gjovik,Norway; Mathematical and Applied Visual Computing, TU Darmstadt,Darmstadt,Germany; Mathematical and Applied Visual Computing, TU Darmstadt,Darmstadt,Germany","2020 IEEE International Joint Conference on Biometrics (IJCB)","6 Jan 2021","2020","","","1","10","Augmented and virtual reality is being deployed in different fields of applications. Such applications might involve accessing or processing critical and sensitive information, which requires strict and continuous access control. Given that Head-Mounted Displays (HMD) developed for such applications commonly contains internal cameras for gaze tracking purposes, we evaluate the suitability of such setup for verifying the users through iris recognition. In this work, we first evaluate a set of iris recognition algorithms suitable for HMD devices by investigating three well-established handcrafted feature extraction approaches, and to complement it, we also present the analysis using four deep learning models. While taking into consideration the minimalistic hardware requirements of stand-alone HMD, we employ and adapt a recently developed miniature segmentation model (EyeMMS) for segmenting the iris. Further, to account for non-ideal and non-collaborative capture of iris, we define a new iris quality metric that we termed as Iris Mask Ratio (IMR) to quantify the iris recognition performance. Motivated by the performance of iris recognition, we also propose the continuous authentication of users in a non-collaborative capture setting in HMD. Through the experiments on a publicly available OpenEDS dataset, we show that performance with EER = 5% can be achieved using deep learning methods in a general setting, along with high accuracy for continuous user authentication.","2474-9699","978-1-7281-9186-7","10.1109/IJCB48548.2020.9304919","German Federal Ministry of Education and Research and the Hessen State Ministry for Higher Education, Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9304919","","Iris recognition;Resists;Feature extraction;Image segmentation;Cameras;Pupils;Authentication","authorisation;biometrics (access control);feature extraction;helmet mounted displays;image recognition;iris recognition;learning (artificial intelligence);virtual reality","recently developed miniature segmentation model;minimalistic hardware requirements;deep learning models;HMD devices;iris recognition algorithms;gaze tracking purposes;internal cameras;Head-Mounted Displays;continuous access control;strict access control;sensitive information;critical information;virtual reality;augmented reality;Head-mounted display;benchmarking Iris recognition;continuous user authentication;noncollaborative capture setting;iris recognition performance;Iris Mask Ratio;iris quality","","","","50","","6 Jan 2021","","","IEEE","IEEE Conferences"
"A Game Theoretic Approach for Modeling User-System Interaction in Networked Virtual Environments","S. Lazem; D. Gracanin; A. Abdel-Hamid","Department of Computer Science, Virginia Tech, US, e-mail: shlazem@vt.edu; Department of Computer Science, Virginia Tech, US, e-mail:gracanin@vt.edu; Arab Academy for Science, Technology, and Maritime Transport Alexandria, Egypt, e-mail:hamid@aast.edu","2009 IEEE Virtual Reality Conference","7 Apr 2009","2009","","","277","278","Networked Virtual Environments (NVEs) are distributed 3D simulations shared among geographically dispersed users. Adaptive resource allocation is a key issue in NVEs, since user interactions affect system resources which in turn affect the user's experience. Such interplay between the users and the system can be modeled using game theory. Game theory is an analytical tool that studies decision-making between interacting agents (players), where player decisions impact greatly other players. We propose a basic structure for a Game Theory model that describes the interaction between the users and the system in NVEs based on an exploratory study of mobile virtual environments.","2375-5334","978-1-4244-3943-0","10.1109/VR.2009.4811053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811053","C.2.4 [Computer-Communication Networks]: Distributed Systems¿Distributed Applications;H.5.1 [Information Interfaces AND Presentation]: Multimedia Information Systems¿Artificial, augmented, and virtual realities;G.2.0 [Mathematics of Computing]: Discrete Mathematics¿General","Game theory;Virtual environment;Rendering (computer graphics);Delay;Prefetching;Computer science;Resource management;Computer interfaces;Computer networks;Distributed computing","decision making;game theory;human computer interaction;mobile computing;resource allocation;virtual reality","game theoretic approach;user-system interaction modeling;networked virtual environment;distributed 3D simulation;adaptive resource allocation;decision-making;mobile virtual environment","","2","","4","","7 Apr 2009","","","IEEE","IEEE Conferences"
"The effect of visual display properties and gain presentation mode on the perceived naturalness of virtual walking speeds","N. C. Nilsson; S. Serafin; R. Nordahl",Aalborg University; Aalborg University; Aalborg University,"2015 IEEE Virtual Reality (VR)","27 Aug 2015","2015","","","81","88","Individuals tend to find realistic walking speeds too slow when relying on treadmill walking or Walking-In-Place (WIP) techniques for virtual travel. This paper details three studies investigating the effects of visual display properties and gain presentation mode on the perceived naturalness of virtual walking speeds: The first study compared three different degrees of peripheral occlusion; the second study compared three different degrees of perceptual distortion produced by varying the geometric field of view (GFOV); and the third study compared three different ways of presenting visual gains. All three studies compared treadmill walking and WIP locomotion. The first study revealed no significant main effects of peripheral occlusion. The second study revealed a significant main effect of GFOV, suggesting that the GFOV size may be inversely proportional to the degree of underestimation of the visual speed. The third study found a significant main effect of gain presentation mode. Allowing participants to interactively adjust the gain led to a smaller range of perceptually natural gains and this approach was significantly faster. However, the efficiency may come at the expense of confidence. Generally the lower and upper bounds of the perceptually natural speeds were higher for treadmill walking than WIP. However, not all differences were statistically significant.","2375-5334","978-1-4799-1727-3","10.1109/VR.2015.7223328","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223328","H.1.2 [Information Systems]: User/Machine Systems — Human factors;I.3.7 [Computer Graphics]: Three-Dimenshional Graphics and Realism — Virtual Reality","Legged locomotion;Visualization;Optical distortion;Analysis of variance;Virtual environments;Distortion;Adaptive optics","computer displays;gait analysis;human computer interaction;virtual reality","visual display properties;gain presentation mode;perceived naturalness;virtual walking speeds;realistic walking speeds;treadmill walking;walking-in-place technique;virtual travel;peripheral occlusion degrees;perceptual distortion;geometric field of view;GFOV;visual gains;WIP locomotion;visual speed underestimation degree;perceptually natural gains;lower bounds;upper bounds","","4","","33","","27 Aug 2015","","","IEEE","IEEE Conferences"
"Effects of Target Trajectory Bandwidth on Manual Control Behavior in Pursuit and Preview Tracking","K. van der El; D. M. Pool; M. R. M. van Paassen; M. Mulder","Control and Simulation Section, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Control and Simulation Section, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Control and Simulation Section, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Control and Simulation Section, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands","IEEE Transactions on Human-Machine Systems","16 Jan 2020","2020","50","1","68","78","The 1960s crossover model is widely applied to quantitatively predict a human controller's (HC's) manual control behavior. Unfortunately, the theory captures only compensatory tracking behavior and, as such, a limited range of real-world manual control tasks. This article finalizes recent advances in manual control theory toward more general pursuit and preview tracking tasks. It is quantified how HCs adapt their control behavior to a final crucial task variable: the target trajectory bandwidth. Beneficial adaptation strategies are first explored offline with computer simulations, using an extended crossover model theory for pursuit and preview tracking. The predictions are then verified with data from a human-in-the-loop experiment, in which participants tracked a target trajectory with bandwidths of 1.5, 2.5, and 4 rad/s, using compensatory, as well as pursuit and preview displays. In stark contrast to the crossover regression found in compensatory tasks, humans attenuate only their feedforward response when tracking higher-bandwidth trajectories in pursuit tasks, while their behavior is generally invariant in preview tasks. A full quantitative theory is now available to predict HC manual control behavior in tracking tasks, which includes HC adaptation to all key task variables.","2168-2305","","10.1109/THMS.2019.2947577","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897675","Manual control;modeling;pursuit;preview;target trajectory bandwidth","Task analysis;Target tracking;Bandwidth;Trajectory;Adaptation models;Human factors;Predictive models","computer simulation;control engineering computing;feedback;feedforward;human factors;human-robot interaction;tracking","target trajectory bandwidth;preview tracking;human controller;compensatory tracking behavior;manual control theory;extended crossover model theory;human-in-the-loop experiment;crossover regression;compensatory tasks;tracking higher-bandwidth trajectories;HC manual control behavior;HC adaptation;pursuit tracking;computer simulations","","","","28","IEEE","13 Nov 2019","","","IEEE","IEEE Journals"
"Repeatable Folding Task by Humanoid Robot Worker Using Deep Learning","P. Yang; K. Sasaki; K. Suzuki; K. Kase; S. Sugano; T. Ogata","Department of Modern Mechanical Engineering, Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Department of Modern Mechanical Engineering, Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan","IEEE Robotics and Automation Letters","20 May 2017","2017","2","2","397","403","We propose a practical state-of-the-art method to develop a machine-learning-based humanoid robot that can work as a production line worker. The proposed approach provides an intuitive way to collect data and exhibits the following characteristics: task performing capability, task reiteration ability, generalizability, and easy applicability. The proposed approach utilizes a real-time user interface with a monitor and provides a first-person perspective using a head-mounted display. Through this interface, teleoperation is used for collecting task operating data, especially for tasks that are difficult to be applied with a conventional method. A two-phase deep learning model is also utilized in the proposed approach. A deep convolutional autoencoder extracts images features and reconstructs images, and a fully connected deep time delay neural network learns the dynamics of a robot task process from the extracted image features and motion angle signals. The “Nextage Open” humanoid robot is used as an experimental platform to evaluate the proposed model. The object folding task utilizing with 35 trained and 5 untrained sensory motor sequences for test. Testing the trained model with online generation demonstrates a 77.8% success rate for the object folding task.","2377-3766","","10.1109/LRA.2016.2633383","AIST; Research Institute for Science and Engineering, Waseda University; MEXT Grant-in-Aid for Scientific Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7762066","Humanoid robots;learning and adaptive systems;motion control of manipulators;neurorobotics","Robot sensing systems;Machine learning;Feature extraction;Humanoid robots;Training;Data models","data handling;delays;feature extraction;generalisation (artificial intelligence);humanoid robots;human-robot interaction;image reconstruction;industrial robots;learning (artificial intelligence);neurocontrollers;robot dynamics;robot vision;telerobotics;user interfaces","repeatable folding task;humanoid robot worker;machine-learning-based humanoid robot;production line worker;task performing capability;task reiteration ability;generalizability;user interface;first-person perspective;head-mounted display;teleoperation;task operating data collection;two-phase deep learning;deep convolutional autoencoder;image feature extraction;image reconstruction;deep time delay neural network learning;robot task process dynamics;Nextage Open humanoid robot;sensory motor sequences","","76","","21","","29 Nov 2016","","","IEEE","IEEE Journals"
"An innovative VR-based vestibular rehabilitation system","Shih-Ching Yeh; Pa-Chun Wang; Yen-Po Hung; Chia-Huang Chang; Shuya Chen; Mu-Chun Su; Hsueh-Lin Chen","Department of Computer Science and Information Engineering, National Central University, Taoyuan, Taiwan; Department of otolaryngology, Cathay General Hospital, Taipei, Taiwan; Department of Computer Science and Information Engineering, National Central University, Taoyuan, Taiwan; Outcomes Research Unit, Cathay Medical Research Institute, Taipei, Taiwan; Department of Physical Therapy, China Medical University, China; Department of Computer Science and Information Engineering, National Central University, Taoyuan, Taiwan; Industrial Technology Research Institute, ITRI, China","2012 IEEE 14th International Conference on e-Health Networking, Applications and Services (Healthcom)","13 Dec 2012","2012","","","213","217","Dizziness caused by peripheral vestibular nerve disease might lead to the imbalance of center of gravity, which in turn might affect the quality of daily life. Vestibular function rehabilitation exercise is thought to be able to improve the symptom of dizziness effectively. However, since rehabilitation process is boring, lacks of challenges and adaptive training contents and lacks of assessment method based on exercise analysis, the effectiveness of rehabilitation exercise is thus reduced. In this research, Cawthorne-Cooksey vestibular rehabilitation training exercise in clinical use was modified as an innovative interactive rehabilitation training system in which stereo imagimg, interactive technology and game technology were applied. In this research, clinical test (17 subjects, 6 training sessions) has been successfully carried out, during the experimental process, the task performance data, the time-history of the deviation distribution of center of gravity and subjective feeling questionnaire survey data of the patient is completely measured and recorded. The experimental result has verified the functionalities of this system, in the mean time, through the task performance evaluation and the analysis of level of balance, the medical effect of this system in assisting the patient to perform dizziness rehabilitation training has been proved, and the clinical observation also shows that the patient has higher willingness and motive to use such new system to perform rehabilitation.","","978-1-4577-2040-6","10.1109/HealthCom.2012.6379410","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6379410","Virtual reality;rehabilitation;vertigo;vestibular dysfunction","Training;Games;Gravity;Indexes;Head;Finishing;Medical treatment","computer games;diseases;ear;mechanoception;medical computing;neurophysiology;patient rehabilitation;three-dimensional displays;virtual reality","VR-based vestibular rehabilitation system;dizziness;peripheral vestibular nerve disease;center-of-gravity imbalance;Cawthorne-Cooksey vestibular rehabilitation training exercise;innovative interactive rehabilitation training system;stereo imaging;interactive technology;game technology;task performance data;deviation time history;deviation distribution;subjective feeling questionnaire survey","","","","9","","13 Dec 2012","","","IEEE","IEEE Conferences"
"Finite element methods for real-time haptic feedback of soft-tissue models in virtual reality simulators","A. O. Frank; I. A. Twombly; T. J. Barth; J. D. Smith","Center for Bioinf., NASA Ames Res. Center, Moffett Field, CA, USA; NA; NA; NA","Proceedings IEEE Virtual Reality 2001","7 Aug 2002","2001","","","257","263","Applies the linear elastic finite element method to compute haptic force feedback and domain deformations of soft-tissue models for use in virtual reality simulators. Our results show that, for virtual object models of high-resolution 3D data (>10,000 nodes), haptic real-time computations (<500 Hz) are nor currently possible using traditional methods. Current research efforts are focused in the following areas: (1) efficient implementation of fully adaptive multi-resolution methods, and (2) multi-resolution methods with specialized basis functions to capture the singularity at the haptic interface (point loading). To achieve real-time computations, we propose parallel processing of a Jacobi pre-conditioned conjugate gradient method applied to a reduced system of equations resulting from surface domain decomposition. This can effectively be achieved using reconfigurable computing systems such as field programmable gate arrays (FPGAs), thereby providing a flexible solution that allows for new FPGA implementations as improved algorithms become available. The resulting soft-tissue simulation system would meet NASA Virtual Glovebox requirements and, at the same time, provide a generalized simulation engine for any immersive environment application, such as biomedical/surgical procedures or interactive scientific applications.","","0-7695-0948-7","10.1109/VR.2001.913794","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=913794","","Finite element methods;Haptic interfaces;Virtual reality;Computational modeling;Field programmable gate arrays;Deformable models;Force feedback;Real time systems;Concurrent computing;Parallel processing","biological tissues;finite element analysis;real-time systems;haptic interfaces;force feedback;virtual reality;digital simulation;elastic deformation;parallel programming;Jacobian matrices;reconfigurable architectures;field programmable gate arrays;medical computing","linear elastic finite element method;real-time haptic feedback;soft-tissue models;virtual reality simulators;domain deformations;virtual object models;high-resolution 3D data;fully adaptive multi-resolution methods;multi-resolution methods;specialized basis functions;haptic interface singularity;point loading;parallel processing;Jacobi preconditioned conjugate gradient method;reduced equation system;surface domain decomposition;reconfigurable computing systems;field programmable gate arrays;FPGA implementations;flexible solution;NASA Virtual Glovebox;generalized simulation engine;immersive environment;biomedical procedures;surgical procedures;interactive scientific applications","","15","","39","","7 Aug 2002","","","IEEE","IEEE Conferences"
"A cognitive theory for affective user modelling in a virtual reality educational game","G. Katsionis; M. Virvou","Dept. of Informatics, Piraeus Univ., Greece; Dept. of Informatics, Piraeus Univ., Greece","2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)","7 Mar 2005","2004","2","","1209","1213 vol.2","The educational community in general considers computer-assisted learning to be very beneficial. As a result, numerous new educational software applications are being developed. An educational application can become very effective if it is adaptive and individualised to the student. However, one important aspect of students that has been overlooked so far, and should be included in such individualisation models, is students' behaviour and emotional state that affects their learning. This paper describes how system observations of students' behavioural characteristics, during their interaction with an educational application, may provide important evidence about students' emotions while they learn. The information collected from these observations mainly concerns students' behaviour while using the application, combined with students' reactions and responds to questions depending on the correctness of their answers. The system's inferences about students' emotions are used to adapt interaction to each individual student's needs taking into account their character and mood.","1062-922X","0-7803-8566-7","10.1109/ICSMC.2004.1399789","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1399789","","Virtual reality;Game theory;Application software;Intelligent systems;Informatics;Decision making;Mood;Logic;Testing;Educational institutions","cognition;virtual reality;computer games;computer aided instruction;behavioural sciences computing","cognitive theory;affective user modelling;virtual reality educational game;computer-assisted learning;educational software applications","","6","","16","","7 Mar 2005","","","IEEE","IEEE Conferences"
"Real-time soft shadows for large-scale virtual environments","Lu Liu; Shuangjiu Xiao","Digital Art Lab of Software College, Shanghai Jiao Tong University, China; Digital Art Lab of Software College, Shanghai Jiao Tong University, China","2011 International Conference on Multimedia Technology","25 Aug 2011","2011","","","5464","5467","Shadow mapping is a widely used shadowing technique in real-time rendering because of its generality and efficiency. In this paper, a practical shadow-mapping-based method called PSPCSS is presented to generate real-time soft shadows in large-scale virtual environments. In PSPCSS, the view frustum is subdivided into several parts along the z-axis, each of which is corresponding to a shadow map with different resolution, and then percentage-closer soft shadows are adaptively applied in each of the shadow maps. The method focuses soft shadows on visual-important area and reduces the waste of shadow map resolution and the cost the adaptive filtering procedure takes. The experiments show plausible real-time soft shadow effect in large-scale virtual environments.","","978-1-61284-774-0","10.1109/ICMT.2011.6002281","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6002281","shadow mapping;soft shadows;real-time rendering;large-scale virtual environment","Real time systems;Shadow mapping;Virtual environments;Rendering (computer graphics);Light sources;Kernel","filtering theory;rendering (computer graphics);virtual reality","real time soft shadow;virtual environment;shadow mapping;shadowing technique;real time rendering;PSPCSS;percentage closer soft shadow;adaptive filtering procedure","","1","","13","","25 Aug 2011","","","IEEE","IEEE Conferences"
"Authoring and Visualization Tool for Augmented Scenic Performances Prototyping and Experience","V. R. S. Ferreira; L. F. d. Paiva; A. C. d. Paiva; R. C. d. Oliveira; M. S. S. Mendes; I. M. O. Maia","Applied Computer Group NCA Federal University of Maranhão,Sao Luis,Ma,Brazil; Applied Computer Group NCA Federal University of Maranhão,Sao Luis,Ma,Brazil; Applied Computer Group NCA Federal University of Maranhão,Sao Luis,Ma,Brazil; University of Lisbon,ITI/LARSYS Faculty of Fine Arts,Lisbon,Portugal; University of Lisbon,ITI/LARSYS Faculty of Fine Arts,Lisbon,Portugal; University of Lisbon,ITI/LARSYS Faculty of Fine Arts,Lisbon,Portugal","2020 22nd Symposium on Virtual and Augmented Reality (SVR)","23 Nov 2020","2020","","","413","419","There is a growing interest in the use of Augmented Reality technologies in artistic practices for performance execution and its use in the production process. The ability to overlay visual media onto the real world or, more specific onto the performer body in real-time has also captured the imagination of performance artists. Also, directors and choreographers glimpse the uses and applications of augmented reality in their production workflow. These applications provide specific challenges that require adaptations to standard content creation workflows. The present work describes the design and implementation of an authoring application for AR-based performance art, initially developed to support augmented performances but also extended to the prototyping of choreographies and costumes uses. The application enables several virtual augmented effects like images, videos, and 3D models to be attached simultaneously to the performer's body. This paper is presented as an application presentation providing a general view of the proposed solution and describing its development. We may see the effectiveness of the authoring application and establishes concrete requirements for a more generic tool to support the development of Artistic Performances with Augmented Reality.","","978-1-7281-9231-4","10.1109/SVR51698.2020.00068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9262642","Augmented Reality;Prototyping / Implementation;Artistic Performance;Innovative interfaces;Multi-disciplinary","Augmented reality","art;augmented reality;data visualisation","generic tool;artistic performances;visualization tool;augmented reality technologies;artistic practices;performance execution;production process;choreographer glimpse;augmented scenic performance prototyping;3D models;application presentation;virtual augmented effects;choreographies;AR-based performance art;authoring application;standard content creation workflows;production workflow;performance artists;performer body;visual media","","","","13","","23 Nov 2020","","","IEEE","IEEE Conferences"
"Generalized Net Model of Virtual Collaboration Space","D. Orozova; A. Ivanov","Free University of Burgas, Burgas, Bulgaria; Free University of Burgas, Burgas, Bulgaria","2018 20th International Symposium on Electrical Apparatus and Technologies (SIELA)","26 Aug 2018","2018","","","1","4","As a discrete tool for universal description of adaptable, flexible, structured and reusable models of complex systems, generalized nets have been applied to modeling of various practical aspects of education and scientific research. Here, in continuation of previous research in this area, generalized nets (GN) have been used for development of a model of the process of personalization and adaptive usage of an intelligent virtual collaboration space. In the model, significant role is assigned to the Personal Assistant, which is a component in the context-dependent environment for delivery of e-services, e-learning content and collaboration. Assessments and patterns can be derived based on the GN model developed and the statistical data absorbed from real processes concerning the servicing of the virtual collaboration space.","","978-1-5386-3419-6","10.1109/SIELA.2018.8447090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8447090","Virtual Collaboration Space;Personal Intelligent Assistants;Generalized Nets","Collaboration;Adaptation models;Databases;Software agents;Documentation;Tools;Education","groupware;Petri nets;virtual reality","complex systems;generalized nets;intelligent virtual collaboration space;Personal Assistant;e-learning content;GN model;ngeneralized net model;e-services","","","","6","","26 Aug 2018","","","IEEE","IEEE Conferences"
"Mobile augmented reality for cultural heritage: A technology acceptance study","A. Haugstvedt; J. Krogstie","IDI, NTNU, Norway; IDI, NTNU, Norway","2012 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","7 Jan 2013","2012","","","247","255","We have developed a mobile augmented reality application with historical photographs and information about a historical street. We follow a design science research methodology and use an extended version of the technology acceptance model (TAM) to study the acceptance of this application. A prototype has been developed in accordance with general principles for usability design, and two surveys have been conducted. A web survey with 200 participants that watched a short video demonstration of the application to validate the adapted acceptance model, and a street survey, where 42 participants got the opportunity to try the application in a live setting before answering a similar questionnaire and provide more concrete feedback. The results show that both perceived usefulness and perceived enjoyment has a direct impact on the intention to use mobile augmented reality applications with historical pictures and information. Further a number of practical recommendations for the development and deployment of such systems are provided.","","978-1-4673-4662-7","10.1109/ISMAR.2012.6402563","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6402563","H.5.1 [Multimedia Information Systems]: Artificial, augmented, and virtual realities—Evaluation/methodology","Augmented reality;Mobile communication;Cultural differences;Cities and towns;Adaptation models;Cameras;Prototypes","augmented reality;history;mobile computing;user centred design","mobile augmented reality;cultural heritage;technology acceptance model;historical photograph;historical street;design science research methodology;TAM;usability design;perceived usefulness;perceived enjoyment","","84","","46","","7 Jan 2013","","","IEEE","IEEE Conferences"
"Are virtual learning environments appropriate for dyscalculic students? A theoretical approach on design optimization of virtual worlds used in mixed-reality simulators","L. Lenz; A. Richert; K. Schuster; S. Jeschke","IMA/ZLW & IfU, RWTH Aachen University, Aachen, Germany; IMA/ZLW & IfU, RWTH Aachen University, Aachen, Germany; IMA/ZLW & IfU, RWTH Aachen University, Aachen, Germany; IMA/ZLW & IfU, RWTH Aachen University, Aachen, Germany","2015 IEEE Games Entertainment Media Conference (GEM)","11 Jan 2016","2015","","","1","8","In Germany, there are more than four million people (almost 6% of Germany's entire population) living with dyscalculia, a disorder which alludes numbers as well as general arithmetic and is closely related to dyslexia [1]. The estimated number of unreported cases is probably even higher. Medical researchers talk about a ""forestalled elite"" since these people are commonly not less intelligent than non-handicapped individuals. Still, they rarely make it to a university-entrance diploma; they get lost on the way because of missing standby facilities offered in primary and continuative schools [2]. They require special needs and attention in order to learn and show their de facto potential. This paper deals with the dyscalculic-friendliness of learning environments provided by mixed-reality simulators. After a presentation of the scientific state of the art on the specific needs of affected students, it will be elaborated in how far virtual environments used in the education of mechanical engineering students can sufficiently not only meet those needs but support them in their study.","","978-1-4673-7452-1","10.1109/GEM.2015.7377205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7377205","dyscalculia;dyslexics and dyscalculics in academia;virtual learning environments;learning content adaptation;mixed reality simulator;Dybuster Calcularis","Games;Software;Visualization;Education;Virtual reality;Finite element analysis;Mechanical engineering","augmented reality;computer aided instruction;educational institutions;engineering education;handicapped aids;mechanical engineering computing;medical disorders","virtual learning environments;dyscalculic students;design optimization;virtual worlds;mixed-reality simulators;Germany entire population;dyslexia;forestalled elite;nonhandicapped individuals;university-entrance diploma;continuative schools;primary schools;dyscalculic-friendliness;learning environments;virtual environments;mechanical engineering students","","1","","18","","11 Jan 2016","","","IEEE","IEEE Conferences"
"A Framework for Tangible User Interfaces within Projector-based Mixed Reality","Y. Yuan; X. Yang; S. Xiao","School of Software, Shanghai Jiao Tong University, China. e-mail: andy1789@sjtu.edu.cn; School of Software, Shanghai Jiao Tong University, China. e-mail: yangxubo@cs.sjtu.edu.cn; School of Software, Shanghai Jiao Tong University, China. e-mail: xsjiu99@cs.sjtu.edu.cn","2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality","6 Jun 2008","2007","","","283","284","This paper proposes a framework named TIPMR, for designing tangible user interfaces (TUIs) within projector-based mixed reality applications. The framework divides the target application into three parts: GUI-based application, TUI and an assistant. The assistant is employed as an adapter to translate between TUI operations and general GUI commands like mouse or keyboard events. This architecture makes it easier to focus on designing GUI-based applications and TUI separately. We built a tourist guidance system with two different tangible interaction modes based on TIPMR to demonstrate its usefulness and efficiency.","","978-1-4244-1749-0","10.1109/ISMAR.2007.4538868","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4538868","tangible user interface;graphical user interface;projector-based mixed reality;extended MCRpd model","User interfaces;Virtual reality;Graphical user interfaces;Application software;Mice;Electronic mail;Keyboards;Computer architecture;Computer interfaces;Joining processes","graphical user interfaces;user interfaces;virtual reality","tangible user interfaces;projector-based mixed reality;GUI commands;graphical user interfaces","","2","","4","","6 Jun 2008","","","IEEE","IEEE Conferences"
"Delay Compensation for a Telepresence System With 3D 360 Degree Vision Based on Deep Head Motion Prediction and Dynamic FoV Adaptation","T. Aykut; M. Karimi; C. Burgmair; A. Finkenzeller; C. Bachhuber; E. Steinbach","Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany","IEEE Robotics and Automation Letters","31 Aug 2018","2018","3","4","4343","4350","The usability of telepresence applications is strongly affected by the communication delay between the user and the remote system. Special attention needs to be paid in case the distant scene is experienced by means of a Head Mounted Display. A high motion-to-photon latency, which describes the time needed to fully reflect the user's motion on the display, results in a poor feeling of presence. Further consequences involve unbearable motion sickness, indisposition, and termination of the telepresence session in the worst case. In this letter, we present our low-cost MAVI telepresence system, which is equipped with a stereoscopic 360° vision system and high-payload manipulation capabilities. Special emphasis is placed on the stereoscopic vision system and its delay compensation. More specifically, we propose velocity-based dynamic field-of-view adaptation techniques to decrease the emergence of simulator sickness and to improve the achievable level of delay compensation. The proposed delay compensation approach relies on deep learning to predict the prospective head motion. We use our previously described head motion dataset for training, validation, and testing. To prove the general validity of our approach, we perform cross validation with another independent dataset. We use both qualitative measures and subjective experiments for evaluation. Our results show that the proposed approach is able to achieve mean compensation rates of around 99.9% for latencies between 0.1 and 0.5 s.","2377-3766","","10.1109/LRA.2018.2864359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8429079","3D vision;telepresence;virtual reality;remote reality;omnidirectional vision","Deep learning;Visualization;Delays;Telepresence;Virtual reality;Stereo image processing","compensation;delays;haptic interfaces;helmet mounted displays;learning (artificial intelligence);optical tracking;stereo image processing;three-dimensional displays;virtual reality;visual perception","field-of-view adaptation techniques;delay compensation approach;prospective head motion;mean compensation rates;dynamic FoV adaptation;telepresence applications;communication delay;remote system;Head Mounted Display;unbearable motion sickness;telepresence session;low-cost MAVI telepresence system;stereoscopic 360° vision system;high-payload manipulation capabilities;head motion dataset;3D 360 degree vision;velocity-based dynamic field-of-view adaptation techniques;high motion-to-photon latency;deep head motion prediction;simulator sickness;deep learning","","2","","29","","8 Aug 2018","","","IEEE","IEEE Journals"
"The Development and Evaluation of an Educational Board Game with Augmented Reality Integrating Contextual Clues as Multi-Level Scaffolding for Learning Ecosystem Concepts","P. Wang; H. Lin; S. Wang; H. Hou","Mini Educational Game Development Group, Graduate Institute of Applied Science and Technology, National Taiwan University of Science and Technology,Taiwan; Mini Educational Game Development Group, Graduate Institute of Applied Science and Technology, National Taiwan University of Science and Technology,Taiwan; Chinese Culture University,Department of Information Management,Taiwan; Mini Educational Game Development Group, Graduate Institute of Applied Science and Technology, National Taiwan University of Science and Technology,Taiwan","2019 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW)","13 Feb 2020","2019","","","1","2","The study developed an AR board game - Ecological Restoration, which employed AR as multi-level cognitive scaffoldings for learning ecosystem concepts. The advantage of this “hybrid” approach is it introduced the flexibility and adaptability to educational board games, which its learning content is generally fixed in printed cards. The game was implemented in a biology class for evaluation. Results show that students generally perceived the game as useful and ease of use for learning. Students' understanding of ecosystem concepts were also significantly improved. Implications of these findings are discussed.","","978-1-7281-3279-2","10.1109/ICCE-TW46550.2019.8991949","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8991949","","","augmented reality;biology computing;cognition;computer aided instruction;ecology","educational board game;augmented reality;ecosystem concepts;AR board game;multilevel cognitive scaffoldings;learning content;Ecological Restoration;biology class","","1","","4","","13 Feb 2020","","","IEEE","IEEE Conferences"
"A multi-modal interface for an interactive simulated vascular reconstruction system","E. V. Zudilova; P. M. A. Sloot; R. G. Belleman","Sect. of Computational Sci., Amsterdam Univ., Netherlands; Sect. of Computational Sci., Amsterdam Univ., Netherlands; Sect. of Computational Sci., Amsterdam Univ., Netherlands","Proceedings. Fourth IEEE International Conference on Multimodal Interfaces","22 Jan 2003","2002","","","313","318","This paper is devoted to multi-modal interface design and implementation of a simulated vascular reconstruction system. It provides multi-modal interaction methods such as speech recognition, hand gestures, direct manipulation of virtual 3D objects and measurement tools. The main challenge is that no general interface scenario in existence today can satisfy all the users of the system (radiologists, vascular surgeons, medical students, etc.). The potential users of the system can vary by their skills, expertise level, habits and psycho-motional characteristics. To make a multimodal interface user-friendly is a crucial issue. In this paper we introduce an approach to develop such an efficient, user-friendly multi-modal interaction system. We focus on adaptive interaction as a possible solution to address the variety of end-users. Based on a user model, the adaptive user interface identifies each individual by means of a set of criteria and generates a customized exploration environment.","","0-7695-1834-6","10.1109/ICMI.2002.1167013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1167013","","Computational modeling;Surgery;Aneurysm;Speech recognition;Arteries;Diseases;Computer simulation;Virtual environment;Stress;Blood flow","digital simulation;speech recognition;speech-based user interfaces;gesture recognition;cardiovascular system;user modelling;surgery;virtual reality;medical computing","multi-modal interface design;interactive simulated vascular reconstruction system;speech recognition;hand gestures;direct virtual 3D object manipulation;measurement tools;radiologists;vascular surgeons;medical students;psycho-motional characteristics;expertise level;user-friendly multi-modal interaction system;adaptive interaction;end-users;user model;customized exploration environment","","8","1","21","","22 Jan 2003","","","IEEE","IEEE Conferences"
"Feature selection for real-time image matching systems","Q. Wang; S. You","University of Southern California, Los Angeles, USA; University of Southern California, Los Angeles, USA","2008 19th International Conference on Pattern Recognition","23 Jan 2009","2008","","","1","4","This paper proposes a general feature selection approach for real-time image matching systems. To demonstrate the idea¿s effectiveness, we focus on the issue of rotational invariance. Most current image matching methods compute and align local image patches to a uniform dominant orientation, which are either too computationally expensive for real-time systems or insufficiently robust. In contrast to current approaches, we combine multiple-view training and feature selection into a unified framework. The most invariant features are selected during an offline training stage. Therefore, no additional computation is needed for online processing. Furthermore the proposed ROTATION INVARIANT FEATURE SELECTION (RIFS) can be easily adapted to similar image matching problems such as scale invariance improvement and kernel selection in feature description. Experimental results show the effectiveness of RIFS using only a small number of training views. The proposed approach is also successfully integrated into an augmented reality application for museum exhibitions.","1051-4651","978-1-4244-2174-9","10.1109/ICPR.2008.4761164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4761164","","Real time systems;Image matching;Kernel;Robustness;Histograms;Noise measurement;Augmented reality;Intelligent systems;Deductive databases;Machine vision","augmented reality;exhibitions;feature extraction;humanities;image matching;real-time systems","real-time image matching systems;rotation invariant feature selection;local image patches;scale invariance improvement;kernel selection;augmented reality;museum exhibitions","","1","","9","","23 Jan 2009","","","IEEE","IEEE Conferences"
"Robust optical see-through head-mounted display calibration: Taking anisotropic nature of user interaction errors into account","E. Azimi; L. Qian; P. Kazanzides; N. Navab","Johns Hopkins Univ., USA; Johns Hopkins Univ., USA; Johns Hopkins Univ., USA; Johns Hopkins Univ., USA, TU München, Germany","2017 IEEE Virtual Reality (VR)","6 Apr 2017","2017","","","219","220","Uncertainty in measurement of point correspondences negatively affects the accuracy and precision in the calibration of head-mounted displays (HMD). In general, the distribution of alignment errors for optical see-through calibration are not isotropic, and one can estimate its distribution based on interaction requirements of a given calibration process and the user's measurable head motion and hand-eye coordination characteristics. Current calibration methods, however, mostly utilize the Direct Linear Transformation (DLT) method which minimizes Euclidean distances for HMD projection matrix estimation, disregarding the anisotropicity in the alignment errors. We utilize the error covariance in order to take the anisotropic nature of error distribution into account. The main hypothesis of this study is that using Mahalonobis distance within the nonlinear optimization can improve the accuracy of the HMD calibration. The simulation results indicate that our new method outperforms the standard DLT method both in accuracy and precision, and is more robust against user alignment errors. To the best of our knowledge, this is the first time that anisotropic noise has been accommodated in the optical see-through HMD calibration.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892255","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892255","augmented reality;HMD;calibration;error propagation;Mahalonobis distance","Calibration;Resists;Robustness;Adaptive optics;Nonlinear optics;Standards;Uncertainty","augmented reality;calibration;helmet mounted displays;matrix algebra;nonlinear programming;user interfaces","robust optical see-through head-mounted display calibration;user interaction errors;augmented reality;point correspondence measurement;alignment error distribution;user measurable head motion;hand-eye coordination characteristics;direct linear transformation method;Euclidean distances;HMD projection matrix estimation;alignment error anisotropicity;error covariance;Mahalonobis distance;nonlinear optimization;standard DLT method;anisotropic noise","","5","","4","","6 Apr 2017","","","IEEE","IEEE Conferences"
"SonifEye: Sonification of Visual Information Using Physical Modeling Sound Synthesis","H. Roodaki; N. Navab; A. Eslami; C. Stapleton; N. Navab","Chair for Computer Aided Medical Procedures, Technische Universitäat Müunchen, Munich, Germany; Topological Media Lab, Concordia University, Montreal, Canada; Carl Zeiss Meditec AG, Munich, Germany; Simiosys Real World Laboratory, Oviedo, FL, USA; Computer Aided Medical Procedures, Johns Hopkins University, Baltimore, MD, USA","IEEE Transactions on Visualization and Computer Graphics","29 Sep 2017","2017","23","11","2366","2371","Sonic interaction as a technique for conveying information has advantages over conventional visual augmented reality methods specially when augmenting the visual field with extra information brings distraction. Sonification of knowledge extracted by applying computational methods to sensory data is a well-established concept. However, some aspects of sonic interaction design such as aesthetics, the cognitive effort required for perceiving information, and avoiding alarm fatigue are not well studied in literature. In this work, we present a sonification scheme based on employment of physical modeling sound synthesis which targets focus demanding tasks requiring extreme precision. Proposed mapping techniques are designed to require minimum training for users to adapt to and minimum mental effort to interpret the conveyed information. Two experiments are conducted to assess the feasibility of the proposed method and compare it against visual augmented reality in high precision tasks. The observed quantitative results suggest that utilizing sound patches generated by physical modeling achieve the desired goal of improving the user experience and general task performance with minimal training.","1941-0506","","10.1109/TVCG.2017.2734327","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007327","Aural augmented reality;sonification;sonic interaction;auditory feedback","Visualization;Mathematical model;Augmented reality;Load modeling;Auditory displays;Acceleration;Computational modeling","augmented reality;data visualisation","SonifEye;visual information;sound patches;conveyed information;minimum mental effort;mapping techniques;sonification scheme;cognitive effort;sonic interaction design;sensory data;computational methods;visual field;conventional visual augmented reality methods;physical modeling sound synthesis","Computer Graphics;Feedback, Sensory;Humans;Models, Neurological;Psychomotor Performance;Software;Virtual Reality","5","","13","Traditional","10 Aug 2017","","","IEEE","IEEE Journals"
"Feature Extraction of Human Motion Video Based on Virtual Reality Technology","M. Zhou","School of Philosophy, Heilongjiang University, Harbin, China","IEEE Access","2 Sep 2020","2020","8","","155563","155575","In virtual reality scenes, the premise of moving target recognition in video is accurate target segmentation and extraction of target low-level features. In order to distinguish moving targets, it is not enough to use the underlying features. Further extraction of structural features that reflect the target structure can improve the recognition and tracking of moving targets. In order to ensure the stability of the feature areas extracted from the three-channel most stable extremum region, this article proposes an improved algorithm of the three-channel most stable extremum region to improve the three-channel most stable extremum region. The algorithm can adaptively select the filters of each channel to filter the feature regions extracted from the three most stable extreme value regions. An action cycle is generally 30~50 frames, so it is faster and more advantageous to directly use the first 50 frames of video for processing. In this article, two feature representation methods of variance gait energy graph algorithm and image splitting algorithm are proposed. The variance energy graph algorithm significantly improves the recognition rate; image splitting enhances the robustness of behavior classification. This article proposes a feature representation algorithm of “distance from contour line to center line” to improve the recognition rate. By analyzing the feature extraction methods of principal component analysis, Fisher linear discriminant analysis and maximum divergence difference discriminant analysis, the main component discriminant analysis of row maximum divergence discriminant column and the two-dimensional two-dimensional maximum divergence discriminant analysis of row and column are proposed. This further enhances the ability to classify behaviors.","2169-3536","","10.1109/ACCESS.2020.3019233","Project of Inner Mongolia University for Nationalities: The Experimental Research on the Introduction of Healthy Physical Fitness Into Calisthenics Teaching; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9177108","Human motion video;feature extraction;improved three-channel most stable extreme value area;virtual reality","Feature extraction;Virtual reality;Face recognition;Face;Trajectory;Target tracking;Filtering algorithms","feature extraction;graph theory;image classification;image representation;image segmentation;principal component analysis;virtual reality","variance energy graph algorithm;image splitting algorithm;variance gait energy graph algorithm;stable extreme value regions;feature regions;stable extremum region;feature areas;target tracking;target structure;structural features;underlying features;moving targets;target low-level features;accurate target segmentation;target recognition;virtual reality scenes;virtual reality technology;human motion video;feature extraction methods;feature representation algorithm;recognition rate","","","","32","CCBY","25 Aug 2020","","","IEEE","IEEE Journals"
"Identifying Accessibility Conditions for Children with Multiple Disabilities: A Virtual Reality Wheelchair Simulator","N. Rodriguez",L1RMM - University of Montpellier - CNRS,"2018 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","29 Apr 2019","2018","","","370","372","Training is one of the main domain applications of Virtual Reality (VR). Simulation and visual realism provide training situations very close to practice with real systems while reducing cost and with greater safety. Furthermore, VR offers the possibility of change time or space scales, visualize from different perspectives, experience inaccessible real environments, all under the user's control, without risks, at her own pace. This allows to develop skills and to have confidence to work thereafter in real conditions with real equipment. Interaction technologies are now more widely available and affordable. But generally devices are conceived for “standard” people leaving behind people with impairments and further accentuating the digital gap. In this paper, we present our work in the development of an accessible wheelchair simulator designed to allow children with multiple disabilities to familiarize themselves with the wheelchair, and practitioners to better understand children capabilities.","","978-1-5386-7592-2","10.1109/ISMAR-Adjunct.2018.00107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699276","virtual reality;simulator;disability;multiple disabilities;wheelchair;learning;augmented and alternative communication;interaction devices;I.3.1 [Computer Graphics]: Hardware Architecture — Input devices;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism – Virtual reality;H.5.1 [Information Interfaces And Presentation]: Multimedia Information Systems — Artificial, augmented, and virtual realities;H.5.2 [Information Interfaces And Presentation]: User Interfaces — Input devices and strategies","Wheelchairs;Virtual reality;Tools;Solid modeling;Visualization;Games;Adaptation models","computer based training;computer simulation;handicapped aids;virtual reality;wheelchairs","accessibility conditions;VR;visual realism;interaction technologies;accessible wheelchair simulator;virtual reality wheelchair simulator;children with multiple disabilities","","","","12","","29 Apr 2019","","","IEEE","IEEE Conferences"
"Towards a Proximal resource-based architecture to support augmented reality applications","C. Taylor; J. Pasquale","Computer Science and Engineering, University of California, San Diego, La Jolla, CA; Computer Science and Engineering, University of California, San Diego, La Jolla, CA","2010 Cloud-Mobile Convergence for Virtual Reality Workshop (CMCVR 2010) Proceedings","2 Sep 2010","2010","","","5","9","We are developing a new enhanced cloud-based computing architecture, called the Proximal Workspace architecture to allow access and interaction between lightweight devices, e.g., video glasses, earphones, wrist displays, body sensors, etc., and applications that represent a new generation of computationand-data-intensive programs in areas such as augmented reality. While lightweight devices offer an easy way for these applications to collect user data and offer feedback, the applications cannot be run natively and completely on these devices because of high resource demands. Making these applications available via a cloud, while promoting ubiquitous access and providing the necessary resources to execute the applications, induces large delays due to network latency. To solve these problems, we are developing a new system architecture based on supporting workspaces which provide nearby computing power to the users devices and thus mediate between them and the clouds computing resources. Specifically, a workspace provides a set of middleware utilities designed to exploit local resources, and provide specific functions such as rendering of graphics, pre-fetching of data, and combining data from different servers. More generally, the workspace is designed to run any subset of activities that cannot be run on a user's device due to computation speed or storage size, and cannot be run on a cloud server due to network latency. Ultimately, the goal is to produce a set of middleware utilities that when run in the workspace with highly-interactive, computation/data intensive applications will result in better user-perceived performance. We are exploring this system architecture constructively, by adapting applications that benefit from this architecture and discovering how best to suit their needs. We have already adapted VNC (Virtual Network Computing, which allows local interaction with remote computations) to run under a similar architecture, and as a result increased video performance in high network latency conditions by an order of magnitude. We are currently working on adapting Google Earth to run under this system architecture, with the goal of the user being able to intuitively navigate through renderings of Ancient Rome in video glasses, without being hampered by any bulky equipment.","2160-2891","978-1-4244-5861-5","10.1109/CMCVR.2010.5560606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5560606","","Servers;Computer architecture;Google;Earth;Rendering (computer graphics);Three dimensional displays;Games","augmented reality;Internet;middleware;software architecture;ubiquitous computing","resource-based architecture;augmented reality applications;cloud-based computing architecture;proximal workspace architecture;lightweight devices;video glasses;earphones;wrist displays;body sensors;computation and-data-intensive programs;ubiquitous access;middleware utilities;VNC;virtual network computing;Google Earth","","7","","19","","2 Sep 2010","","","IEEE","IEEE Conferences"
"General-purpose telepresence with head-worn optical see-through displays and projector-based lighting","A. Maimone; X. Yang; N. Dierk; A. State; M. Dou; H. Fuchs",University of North Carolina at Chapel Hill; Shanghai Jiao Tong University; University of North Carolina at Chapel Hill; University of North Carolina at Chapel Hill; University of North Carolina at Chapel Hill; University of North Carolina at Chapel Hill,"2013 IEEE Virtual Reality (VR)","9 Sep 2013","2013","","","23","26","In this paper we propose a general-purpose telepresence system design that can be adapted to a wide range of scenarios and present a framework for a proof-of-concept prototype. The prototype system allows users to see remote participants and their surroundings merged into the local environment through the use of an optical see-through head-worn display. Real-time 3D acquisition and head tracking allows the remote imagery to be seen from the correct point of view and with proper occlusion. A projector-based lighting control system permits the remote imagery to appear bright and opaque even in a lit room. Immersion can be adjusted across the VR continuum. Our approach relies only on commodity hardware; we also experiment with wider field of view custom displays.","2375-5334","978-1-4673-4796-9","10.1109/VR.2013.6549352","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6549352","teleconferencing;augmented reality;virtual reality","Three-dimensional displays;Optical imaging;Optical sensors;Lighting control;Prototypes;Adaptive optics;Geometry","data acquisition;helmet mounted displays;lighting control;object tracking;optical projectors;virtual reality","head-worn optical see-through displays;projector-based lighting;general-purpose telepresence system design;proof-of-concept prototype;optical see-through head-worn display;real-time 3D acquisition;head tracking;remote imagery;projector-based lighting control system;VR continuum;field-of-view custom displays;commodity hardware","","29","7","11","","9 Sep 2013","","","IEEE","IEEE Conferences"
"Multiuser Interaction with Hybrid VR and AR for Cultural Heritage Objects","Y. Li; E. Ch’ng; S. Cai; S. See","International Doctoral Innovation Centre & NVIDIA Joint-Lab on Mixed Reality, University of Nottingham, Ningbo, China; NVIDIA Joint-Lab on Mixed Reality, University of Nottingham, Ningbo, China; Faculty of Humanities and Social Sciences & & NVIDIA Joint-Lab on Mixed Reality, University of Nottingham, Ningbo, China; NVIDIA AI Technology Centre, NVIDIA, Singapore","2018 3rd Digital Heritage International Congress (DigitalHERITAGE) held jointly with 2018 24th International Conference on Virtual Systems & Multimedia (VSMM 2018)","26 Aug 2019","2018","","","1","8","This research investigates the factors and ways in which users initiate conversations and engage in interactions in a hybrid virtual environment using a combination of Virtual Reality (VR) and Augmented Reality (AR) devices. The research was done in the `spirit of the ancient Silk Road' where trade brought in exchange of ideas, cultural influence and cross-border communications. The notion of a 21st century Silk Road is necessarily digital, over the Internet and based around 3D cultural heritage objects. Digi-Capital's Report forecasts the revenue of AR and VR to be US$150b by 2020. We projected that VR and AR will become pervasive, much like the Social Web and the universal ubiquity of mobile devices such as smartphones and wearables. Here, we conducted a user study exploring users' acceptance of the use of hybrid VR and AR for cultural heritage, and investigated the social nature of multiple co-located user interaction. We adapted the UTAUT questionnaire in our experiment and found that social influence has positive effects on performance expectancy and effort expectancy, which generate positive effects on user behavioural intention. This study pioneers the future design and use of hybrid VR and AR technology in cultural heritage specifically, and in other application areas generally by highlighting the significant role that social influence plays in enhancing users' behavioural intention facilitated by different immersive devices.","","978-1-7281-0292-4","10.1109/DigitalHeritage.2018.8810126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8810126","Virtual reality;augmented reality;hybrid VR AR;technology acceptance;interaction design;social interaction;cultural heritage;heritage objects","Cultural differences;Virtual environments;Roads;Global communication;Augmented reality;History","augmented reality;cultural aspects;history;human computer interaction;Internet;mobile computing;user interfaces","hybrid virtual environment;cross-border communications;mobile devices;user behavioural intention;multiuser interaction;social Web;immersive devices;hybrid VR;hybrid AR;virtual reality;augmented reality devices;3D cultural heritage objects;digi-capital's report;smartphones;multiple co-located user interaction;UTAUT questionnaire","","","","25","","26 Aug 2019","","","IEEE","IEEE Conferences"
"Evaluating the Effectiveness of Redirected Walking with Auditory Distractors for Navigation in Virtual Environments","N. Rewkowski; A. Rungta; M. Whitton; M. Lin","UNC, Chapel Hill; UNC, Chapel Hill; UNC, Chapel Hill; UMD College, Park UNC Chapel Hill","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","395","404","Many virtual locomotion interfaces allowing users to move in virtual reality have been built and evaluated, such as redirected walking (RDW), walking-in-place (WIP), and joystick input. RDW has been shown to be among the most natural and immersive as it supports real walking, and many newer methods further adapt RDW to allow for customization and greater immersion. Most of these methods have been demonstrated to work with vision, in this paper we evaluate the ability for a general distractor-based RDW framework to be used with only auditory display. We conducted two studies evaluating the differences between RDW with auditory distractors and other distractor modalities using distraction ratio, virtual and physical path information, immersion, simulator sickness, and other measurements. Our results indicate that auditory RDW has the potential to be used with complex navigational tasks, such as crossing streets and avoiding obstacles. It can be used without designing the system specifically for audio-only users. Additionally, sense of presence and simulator sickness remain reasonable across all user groups.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798286","virtual locomotion—redirected walking—distractors","Legged locomotion;Distortion;Navigation;Task analysis;Visualization;Virtual environments;Dogs","cognition;ergonomics;interactive devices;virtual reality","redirected walking;auditory distractors;virtual environments;virtual locomotion interfaces;virtual reality;walking-in-place;joystick input;general distractor-based RDW framework;auditory display;distractor modalities;virtual path information;physical path information;simulator sickness;auditory RDW;complex navigational tasks","","","","49","","15 Aug 2019","","","IEEE","IEEE Conferences"
"Distributed Video Transcoding System for 8K 360° VR Tiled Streaming Service","Y. Kim; J. Huh; J. Jeong","Intelligent Image Processing Research Center, Korea Electronics Technology Institute (KETI), Seongnam-si, Republic of Korea; Intelligent Image Processing Research Center, Korea Electronics Technology Institute (KETI), Seongnam-si, Republic of Korea; Intelligent Image Processing Research Center, Korea Electronics Technology Institute (KETI), Seongnam-si, Republic of Korea","2018 International Conference on Information and Communication Technology Convergence (ICTC)","18 Nov 2018","2018","","","592","595","360° Virtual Reality (VR) services with resolutions of 8K and beyond are a challenging task due to limits of both decoding complexity and constrained public internet bandwidth of consumer devices. Also, general streaming servers cannot service these large-resolution video streams to many clients because of bandwidth limitation. In this paper, we propose a distributed video transcoding system for achieving viewport adaptive streaming, which is known as tiled streaming, of 8K 360° VR video. The proposed system consists of many motion-constrained High Efficiency Video Coding (HEVC) encoders, a Hadoop/Spark-based distributed computing platform, light-weight bitstream stitcher, and dual HEVC decoders. Experimental results show that 8K 360° videos which are split by 8×8 tiles, respectively, can be encoded at 99 fps, and 4×4 tiles are stitched at 9,585 fps, on average.","2162-1233","978-1-5386-5041-7","10.1109/ICTC.2018.8539372","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8539372","360° video;virtual reality;distributed transcoding;HEVC;tiles;bitstream stitching","Streaming media;Transcoding;Decoding;Bit rate;Media;High efficiency video coding;Transform coding","data compression;Internet;parallel processing;transcoding;video coding;video streaming;virtual reality","distributed video transcoding system;VR tiled streaming service;decoding complexity;large-resolution video streams;bandwidth limitation;viewport adaptive streaming;dual HEVC decoders;VR video;motion-constrained high efficiency video coding;virtual reality services;constrained public internet bandwidth;streaming servers;Hadoop-Spark-based distributed computing;light-weight bitstream stitcher","","1","","12","","18 Nov 2018","","","IEEE","IEEE Conferences"
"Adaptive Parameters Estimation for Light Field Reconstruction using Shearlet Transform","S. Jinming; H. Xinjue; L. Yu; L. Zhang","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China","2018 International Conference on Network Infrastructure and Digital Content (IC-NIDC)","8 Nov 2018","2018","","","125","129","The research of light field can provide the VR (Virtual Reality)/AR (Augmented Reality) products' more realistic immersion effect and bring revolutionary development to the VR/AR industry. The light field reconstruction is one of the most important technologies in light field. The methods to reconstruct the light field can generally be divided into the time domain and the frequency domain. The advantage of reconstructing the light field from frequency domain is that it can eliminate the effect of occlusion on the light field reconstruction to a certain extent. Although many reconstruction algorithms in frequency domain has been put forward, their performance on different data sources strongly depends on pre-set fixed parameters. There is a great need for a method that can adaptively adjust parameters in dealing with various sources of data to improve this situation. This paper utilizes the correlation between the parameters to improve the efficiency of light field reconstruction using Sheartlet Transform and proposes an adaptive parameter estimation method to adjust the parameters to be suitable for all types of light fields. Simulation results illustrates that the PSNR is obviously higher than that of the original method, which verify the adaptability of the proposed parameter estimation method of the shearlet light field reconstruction to different light fields.","2575-4955","978-1-5386-6067-6","10.1109/ICNIDC.2018.8525651","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8525651","Light field reconstruction;EPI images;Correlation;Loop nesting","Image reconstruction;Parameter estimation;Transforms;Frequency-domain analysis;Correlation;Cameras","adaptive estimation;Bayes methods;image denoising;image reconstruction;parameter estimation;virtual reality;wavelet transforms","VR/AR products;frequency domain;adaptive parameter estimation method;shearlet light field reconstruction;Shearlet transform;time domain","","","","10","","8 Nov 2018","","","IEEE","IEEE Conferences"
