"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Disaster Management Simulation and research integration's Virtual Test Bed proposal for The Chilean National Research Center for Integrated Natural Disaster Management (CIGIDEN)","A. Vásquez; L. F. Robledo","Department of Computer Science, Pontificia Universidad Catolica de Chile, Santiago, CHILE; Department of Engineering Science, Universidad Andres Bello, Santiago, CHILE","2016 Winter Simulation Conference (WSC)","19 Jan 2017","2016","","","3028","3039","The Chilean National Research Center for Integrated Natural Disaster Management, CIGIDEN, was created in 2011 to develop, integrate, and transfer scientific knowledge to reduce the social consequences of extreme natural events. As one of its transfer products, CIGIDEN created a Disaster Management Simulation Lab (DMSLab) to deliver a practical training solution for disaster management. We propose a Virtual Test Bed to support the DMSLab by providing a simulation based, multi-disciplinary risk analysis platform. It will strengthen CIGIDEN's transfer and research integration capabilities, offering the tools and methodologies already being developed by the Center for emergency-based decision-making, optimization through simulation and humanitarian aid. A case study of a virtual disaster scenario developed with the Chilean National Emergency Office (ONEMI) is presented, to illustrate how the Virtual Test Bed can support research application in real scenarios.","1558-4305","978-1-5090-4486-3","10.1109/WSC.2016.7822337","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7822337","","Training;Disaster management;Decision making;Protocols;Emergency services;Optimization;Organizations","decision making;digital simulation;emergency management;knowledge management;risk analysis;virtual instrumentation","Chilean National Research Center for Integrated Natural Disaster Management;CIGIDEN;scientific knowledge transfer;scientific knowledge development;social consequences;extreme natural events;Disaster Management Simulation Lab;training solution;virtual test bed;DMSLab;simulation based multidisciplinary risk analysis;scientific knowledge integration;emergency-based decision-making optimization;humanitarian aid;Chilean National Emergency Office;ONEMI","","","","43","","19 Jan 2017","","","IEEE","IEEE Conferences"
"Expert user validation of transplant management procedure simulations","B. Borro-Escribano; J. Torrente; A. del Blanco; B. Fernandez-Manjon; I. Martinez-Alpuente; R. Matesanz","Department of Software Engineering and Artificial Intelligence, Complutense University of Madrid Madrid, Spain; Department of Software Engineering and Artificial Intelligence, Complutense University of Madrid Madrid, Spain; Department of Software Engineering and Artificial Intelligence, Complutense University of Madrid Madrid, Spain; Department of Software Engineering and Artificial Intelligence, Complutense University of Madrid Madrid, Spain; Organización Nacional de Trasplantes (ONT) Madrid, Spain; Organización Nacional de Trasplantes (ONT) Madrid, Spain","2014 IEEE 3nd International Conference on Serious Games and Applications for Health (SeGAH)","26 Mar 2015","2014","","","1","8","The Spanish National Transplant Organization (ONT) in collaboration with the e-UCM research group of the Complutense University of Madrid has developed three screen-based simulations representing the ONT supra-hospital deceased donation management processes. As the ONT is using these game-like simulations as a support tool for its instructional approach, it was necessary to perform a validation of these simulations to assure the knowledge had been correctly represented. This paper describes the methodology followed to validate and estimate how accurately this ONT complex knowledge has been captured (including some tacit knowledge used by the transplant coordination experts) and transferred into these screen-based simulations. We present the results obtained from the validation done with 15 ONT experts and how their feedback was used to improve the simulations.","","978-1-4799-4823-9","10.1109/SeGAH.2014.7067099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7067099","knowledge validation;screen-based simulation;transplant procedure","Games;Usability;Interviews;Computational modeling;Hospitals;Training","computer aided instruction;computer games;digital simulation;expert systems;hospitals;knowledge representation;medical computing;user interfaces","expert user validation;transplant management procedure simulation;Spanish National Transplant Organization;e-UCM research group;screen-based simulation;ONT suprahospital deceased donation management process game-like simulation;instructional approach;knowledge representation","","1","","26","","26 Mar 2015","","","IEEE","IEEE Conferences"
"Packet network simulation: speedup and accuracy versus timing granularity","Jong Suk Ahn; P. B. Danzig","Dept. of Comput. Eng., Dongguk Univ., Seoul, South Korea; NA","IEEE/ACM Transactions on Networking","6 Aug 2002","1996","4","5","743","757","This paper describes a new technique that can speedup simulation of high-speed, wide-area packet networks by one to two orders of magnitude. Speedup is achieved by coarsening the representation of network traffic from packet-by-packet to train-by-train, where a train represents a cluster of closely spaced packets. Coarsening the timing granularity creates longer trains and makes the simulation proceed more quickly since the cost of processing trains is independent of train size. Coarsening the timing granularity introduces, of course, a degree of approximation. This paper presents experiments that evaluate our coarse time-grain simulation technique for first in/first out (FIFO) switched, TCP/IP, and asynchronous transfer mode (ATM) networks carrying a mix of data and streaming traffic. We show that delay, throughput, and loss rate can frequently be estimated within a few percent via coarse time-grain simulation. This paper also describes how to apply coarse time-grain simulation to other switch disciplines. Finally, this paper introduces three more simulation techniques which together can double the performance of well written packet simulators without trading with the simulation accuracy. These techniques reduce the number of outstanding simulation events and reduce the cost of manipulating the event list.","1558-2566","","10.1109/90.541322","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=541322","","Accuracy;Timing;Telecommunication traffic;Traffic control;Costs;Asynchronous transfer mode;Delay estimation;Switches;TCPIP;Throughput","asynchronous transfer mode;packet switching;digital simulation;simulation;wide area networks;computational complexity;switching networks;delays;channel capacity;transport protocols","packet network simulation;speedup;accuracy;timing granularity;high-speed wide-area packet networks;representation;network traffic;train;closely spaced packets;approximation;first in/first out switched network;Internet protocol network;asynchronous transfer mode networks;ATM networks;delay;throughput;loss rate;time-grain simulation;performance;TCP/IP;FIFO","","35","3","28","","6 Aug 2002","","","IEEE","IEEE Journals"
"On-line simultaneous learning and recognition of everyday activities from virtual reality performances","T. Bates; K. Ramirez-Amaro; T. Inamura; G. Cheng","Institute for Cognitive Systems, Technical University of Munich, Arcisstraße 21, 80333 Munich Germany; Institute for Cognitive Systems, Technical University of Munich, Arcisstraße 21, 80333 Munich Germany; National Institute of Informatics, 2 Chome-2-1-2 Hitotsubashi, Chiyodaku, Tokyo 100-0003, Japan; Institute for Cognitive Systems, Technical University of Munich, Arcisstraße 21, 80333 Munich Germany","2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","14 Dec 2017","2017","","","3510","3515","Capturing realistic human behaviors is essential to learn human models that can later be transferred to robots. Recent improvements in virtual reality (VR) head-mounted displays provide a viable way to collect natural examples of human behavior without the difficulties often associated with capturing performances in a physical environment. We present a realistic, cluttered, VR environment for experimentation with household tasks paired with a semantic extraction and reasoning system able to utilize data collected in real-time and apply ontology-based reasoning to learn and classify activities performed in VR. The system performs continuous segmentation of the motions of users' hands and simultaneously classifies known actions while learning new ones on demand. The system then constructs a graph of all related activities in the environment through its observations, extracting the task space utilized by observed users during their performance. The action recognition and learning system was able to maintain a high degree of accuracy of around 92% while dealing with a more complex and realistic environment compared to earlier work in both physical and virtual spaces.","2153-0866","978-1-5386-2682-5","10.1109/IROS.2017.8206193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8206193","","Motion segmentation;Training;Cognition;Avatars;Semantics","helmet mounted displays;image recognition;learning (artificial intelligence);ontologies (artificial intelligence);virtual reality","virtual reality performances;realistic human behaviors;human models;robots;virtual reality head;human behavior;physical environment;VR environment;household tasks;semantic extraction;reasoning;continuous segmentation;task space;observed users;action recognition;learning system;complex environment;realistic environment;physical spaces;virtual spaces;on-line simultaneous learning","","10","","14","","14 Dec 2017","","","IEEE","IEEE Conferences"
"Skill transfer in a simulated underactuated dynamic task","M. K. O'Malley; A. Gupta","Mech. Eng. & Material Sci., Rice Univ., Houston, TX, USA; Mech. Eng. & Material Sci., Rice Univ., Houston, TX, USA","The 12th IEEE International Workshop on Robot and Human Interactive Communication, 2003. Proceedings. ROMAN 2003.","19 Dec 2003","2003","","","315","320","Machine-mediated teaching of dynamic task completion is typically implemented with passive intervention via virtual fixtures or active assist by means of record and replay strategies. During interaction with a real dynamic system however, the user relies on both visual and haptic feedback in order to elicit desired motions. This work investigates skill transfer from assisted to unassisted modes for a Fitts' type targeting task with an underactuated dynamic system. Performance, in terms of between target tap times, is measured during an unassisted baseline session and during various types of assisted training sessions. It is hypothesized that passive and active assist modes that are implemented during training of a dynamic task could improve skill transfer to a real environment or unassisted simulation of the task. Results indicate that transfer of skill is slight but significant for the assisted training modes.","","0-7803-8136-X","10.1109/ROMAN.2003.1251864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1251864","","Haptic interfaces;Education;Displays;Fixtures;Humans;Virtual reality;Force feedback;Shape control;Control systems;Mechanical engineering","haptic interfaces;computer based training;virtual reality;learning (artificial intelligence)","underactuated dynamic system;Fitts' type;skill transfer;haptic feedback","","3","","22","","19 Dec 2003","","","IEEE","IEEE Conferences"
"Transferring bioelasticity knowledge through haptic interaction","M. Nakao; K. Minato; T. Kuroda; M. Komori; H. Oyama; T. Takahashi","Nara Inst. of Sci. & Technol., Japan; Nara Inst. of Sci. & Technol., Japan; NA; NA; NA; NA","IEEE MultiMedia","7 Aug 2006","2006","13","3","50","60","This study establishes a practical environment for transferring knowledge on bioelasticity between expert and trainee medical practitioners. Through haptic interaction with a deformable virtual anatomical model, experts set the model's elasticity conditions by simulating a surgical procedure. Trainees experience the elasticity by attempting the same surgical manipulation","1941-0166","","10.1109/MMUL.2006.70","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1667976","computer-assisted instruction;physically based modeling;virtual reality;life and medical sciences","Haptic interfaces;Elasticity;Biomedical imaging;Deformable models;Medical simulation;Surgery;Education;Diseases;Surges;Hospitals","computer based training;haptic interfaces;medical computing;physiological models;surgery;virtual reality","bioelasticity knowledge transfer;haptic interaction;medical training;deformable virtual anatomical model;surgery simulation","","12","","23","","7 Aug 2006","","","IEEE","IEEE Magazines"
"Towards Fine-Grained Human Pose Transfer With Detail Replenishing Network","L. Yang; P. Wang; C. Liu; Z. Gao; P. Ren; X. Zhang; S. Wang; S. Ma; X. Hua; W. Gao","Video Coding Laboratory, Institute of Digital Media, Peking University (PKU-IDM-VCL), Beijing, China; Video Coding Laboratory, Institute of Digital Media, Peking University (PKU-IDM-VCL), Beijing, China; School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China; Video Coding Laboratory, Institute of Digital Media, Peking University (PKU-IDM-VCL), Beijing, China; Video Coding Laboratory, Institute of Digital Media, Peking University (PKU-IDM-VCL), Beijing, China; School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China; Institute of Digital Media, Peking University, Beijing, China; Institute of Digital Media, Peking University, Beijing, China; Video Coding Laboratory, Institute of Digital Media, Peking University (PKU-IDM-VCL), Beijing, China; Institute of Digital Media, Peking University, Beijing, China","IEEE Transactions on Image Processing","29 Jan 2021","2021","30","","2422","2435","Human pose transfer (HPT) is an emerging research topic with huge potential in fashion design, media production, online advertising and virtual reality. For these applications, the visual realism of fine-grained appearance details is crucial for production quality and user engagement. However, existing HPT methods often suffer from three fundamental issues: detail deficiency, content ambiguity and style inconsistency, which severely degrade the visual quality and realism of generated images. Aiming towards real-world applications, we develop a more challenging yet practical HPT setting, termed as Fine-grained Human Pose Transfer (FHPT), with a higher focus on semantic fidelity and detail replenishment. Concretely, we analyze the potential design flaws of existing methods via an illustrative example, and establish the core FHPT methodology by combing the idea of content synthesis and feature transfer together in a mutually-guided fashion. Thereafter, we substantiate the proposed methodology with a Detail Replenishing Network (DRN) and a corresponding coarse-to-fine model training scheme. Moreover, we build up a complete suite of fine-grained evaluation protocols to address the challenges of FHPT in a comprehensive manner, including semantic analysis, structural detection and perceptual quality assessment. Extensive experiments on the DeepFashion benchmark dataset have verified the power of proposed benchmark against start-of-the-art works, with 12%-14% gain on top-10 retrieval recall, 5% higher joint localization accuracy, and near 40% gain on face identity preservation. Our codes, models and evaluation tools will be released at https://github.com/Lotayou/RATE.","1941-0042","","10.1109/TIP.2021.3052364","National Natural Science Foundation of China; High-performance Computing Platform of Peking University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9335507","Image generation;pose transfer;detail replenishment","Semantics;Strain;Solid modeling;Faces;Protocols;Media;Hybrid power systems","feature extraction;information retrieval;Internet;learning (artificial intelligence);object detection;object tracking;pose estimation;virtual reality","perceptual quality assessment;replenishing network;fine-grained evaluation protocols;coarse-to-fine model training scheme;feature transfer;content synthesis;core FHPT methodology;potential design flaws;detail replenishment;semantic fidelity;fine-grained human pose transfer;HPT setting;real-world applications;visual quality;style inconsistency;content ambiguity;detail deficiency;HPT methods;user engagement;production quality;fine-grained appearance details;visual realism;virtual reality;online advertising;media production;fashion design","","","","43","IEEE","25 Jan 2021","","","IEEE","IEEE Journals"
"Multi-User Virtual System for Training of the Production and Bottling Process of Soft Drinks","J. I. Zambrano; D. A. Bermeo; C. A. Naranjo; V. H. Andaluz","Universidad de las Fuerzas Armadas ESPE,Sangolquí,Ecuador; Universidad de las Fuerzas Armadas ESPE,Sangolquí,Ecuador; Universidad de las Fuerzas Armadas ESPE,Sangolquí,Ecuador; Universidad de las Fuerzas Armadas ESPE,Sangolquí,Ecuador","2020 15th Iberian Conference on Information Systems and Technologies (CISTI)","15 Jul 2020","2020","","","1","7","The project consists of developing a virtual operational training system for the production and bottling process carried out in the soft drinks factory. For the virtualization of the industrial process, mathematical modeling is considered using a transfer function of the first order with downtime and control in relation to the flow plants that make up the substance mixing station in the company, for this, dynamic data and behaviors of the fully automated flow plants within the university are used and not the conventional station existing in the company, since its machines and data are kept confidential In addition, 3D CAD design techniques, electric diagrams of the process and instrumentation (P&ID) are used, all in order for multiple users to have immersive experiences sensory and can interact with each other within a virtual environment.","2166-0727","978-989-54659-0-3","10.23919/CISTI49556.2020.9141140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9141140","Virtual environment;Production and bottling process;Unity 3D;Multiple users;Training;4.0 Industry","Process control;Mathematical model;Training;Production facilities;Virtual environments;Industries","beverage industry;bottling;CAD;chemioception;computer based training;industrial plants;instrumentation;mathematical analysis;mixing;production engineering computing;virtual reality;virtualisation","mathematical modeling;transfer function;substance mixing station;3D CAD design techniques;multiuser virtual system;bottling process;virtual operational training system;soft drinks factory;virtualization;industrial process;automated flow plants;production process;electric diagrams;instrumentation;sensory experience","","","","17","","15 Jul 2020","","","IEEE","IEEE Conferences"
"Using of social networks in educational process","N. Kalinenko; V. Krasnopolsky; V. Kukharenko; A. Serebryakov","Volodymyr Dahl East Ukrainian National University, Molodizhnyi kvartal, 20-a, Luhansk, 91034, Ukraine; Volodymyr Dahl East Ukrainian National University, Molodizhnyi kvartal, 20-a, Luhansk, 91034, Ukraine; National Technical University “Kharkiv Polytechnic Institute”, 21, Frunze Street, 61002, Ukraine; Volodymyr Dahl East Ukrainian National University, Molodizhnyi kvartal, 20-a, Luhansk, 91034, Ukraine","2013 IEEE 7th International Conference on Intelligent Data Acquisition and Advanced Computing Systems (IDAACS)","14 Nov 2013","2013","02","","781","784","The learning process can now be described as targeted joint activities of the teacher and students in the educational environment. Education - a purposeful process of bilateral activities of the teacher and the student in the transfer and assimilation of knowledge. Development of Personal Learning Environment in virtual reality plays the key role.","","978-1-4799-1429-6","10.1109/IDAACS.2013.6663031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6663031","personal environment;virtual reality;mind mapping;social networks;web services;online learning;information technologies;educational environment","Social network services;Training;Materials;Educational institutions;Communities;Internet","computer aided instruction;social networking (online);virtual reality","social networks;educational process;learning process;educational environment;bilateral activity process;virtual reality;personal learning environment development","","1","","4","","14 Nov 2013","","","IEEE","IEEE Conferences"
"The use of simulation to calculate the labor requirements in an intermodal rail terminal","B. C. Kulick; J. T. Sawyer","Autom. Associates, Inc., Solana Beach, CA, USA; NA","Proceeding of the 2001 Winter Simulation Conference (Cat. No.01CH37304)","6 Aug 2002","2001","2","","1038","1041 vol.2","An intermodal rail terminal is a facility where the transfer of cargo occurs between truck and rail. The operations within these terminals involve many resources and operating rules. The ability of a terminal to respond to activity peaks that occur as a result of train arrivals and departures is critical. In order to explore how operations can be improved given the dynamics of resource and demand interactions, a simulation model was developed to assist in understanding and exploring areas where throughput can be improved. The model was constructed such that capacity issues could be explored incrementally. The first focus was for understanding if efficient deployment of labor resources could provide desired throughput.","","0-7803-7307-3","10.1109/WSC.2001.977411","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=977411","","Rails;Containers;Cranes;Throughput;Resource management;Strips;Automation;Availability;Productivity;Terminology","railways;logistics data processing;personnel;digital simulation;distributive data processing","intermodal rail terminal;cargo transfer;train arrivals;train departures;resource interactions;demand interactions;simulation model;labor requirements","","1","","","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Scalable sim-to-real transfer of soft robot designs","S. Kriegman; A. M. Nasab; D. Shah; H. Steele; G. Branin; M. Levin; J. Bongard; R. Kramer-Bottiglio",University of Vermont; Yale University; Yale University; Yale University; Yale University; Tufts University; University of Vermont; Yale University,"2020 3rd IEEE International Conference on Soft Robotics (RoboSoft)","15 Jun 2020","2020","","","359","366","The manual design of soft robots and their controllers is notoriously challenging, but it could be augmented-or, in some cases, entirely replaced-by automated design tools. Machine learning algorithms can automatically propose, test, and refine designs in simulation, and the most promising ones can then be manufactured in reality (sim2real). However, it is currently not known how to guarantee that behavior generated in simulation can be preserved when deployed in reality. Although many previous studies have devised training protocols that facilitate sim2real transfer of control polices, little to no work has investigated the simulation-reality gap as a function of morphology. This is due in part to an overall lack of tools capable of systematically designing and rapidly manufacturing robots. Here we introduce a low cost, open source, and modular soft robot design and construction kit, and use it to simulate, fabricate, and measure the simulation-reality gap of minimally complex yet soft, locomoting machines. We prove the scalability of this approach by transferring an order of magnitude more robot designs from simulation to reality than any other method. The kit and its instructions can be found here: github.com/skriegman/sim2real4designs.","","978-1-7281-6570-7","10.1109/RoboSoft48309.2020.9116004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9116004","","","augmented reality;CAD;learning (artificial intelligence);manufacturing systems;mobile robots","training protocols;sim2real transfer;simulation-reality gap;modular soft robot design;construction kit;scalable sim-to-real transfer;automated design tools;machine learning;minimally complex yet soft;locomoting machines;rapid manufacturing","","1","","37","","15 Jun 2020","","","IEEE","IEEE Conferences"
"Advantages of Virtual Reality in the Teaching and Training of Radiation Protection during Interventions in Harsh Environments","A. Cryer; G. Kapellmann-Zafra; S. Abrego-Hernández; H. Marin-Reyes; R. French","Department of Physics and Astronomy, University of Sheffield; Department of Physics and Astronomy, University of Sheffield; Department of Physics and Astronomy, University of Sheffield; Department of Physics and Astronomy, University of Sheffield; Department of Physics and Astronomy, University of Sheffield","2019 24th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)","17 Oct 2019","2019","","","784","789","Human interventions in radioactive environments have high stakes. They are often time-sensitive and radiation exposure must be minimised for the safety of personnel. Existing sites were not developed with remote decommissioning in mind, therefore human intervention remains the preferred approach for dexterous manual labour over robotic systems. For ageing sites, knowledge transfer after retirement is an increasingly relevant problem for maintenance and decommissioning tasks, where new workers lack the in-depth “on the ground” experience of the installation. Virtual Reality provides workers the agency to explore an accurate representation of the area, enabling them to gain experience without undue radiation exposure. This paper explores and discusses the teaching and training applications of a Virtual Reality environment with integrated radiation dose maps, and looks at where the system may be developed further.","1946-0759","978-1-7281-0303-7","10.1109/ETFA.2019.8869433","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869433","","Detectors;Task analysis;Solid modeling;Virtual reality;Training;Headphones;Large Hadron Collider","dosimetry;fission reactor decommissioning;personnel;radiation protection;virtual reality","radiation protection;harsh environments;human intervention;radioactive environments;remote decommissioning;dexterous manual labour;robotic systems;maintenance tasks;decommissioning tasks;teaching applications;training applications;virtual reality environment;integrated radiation dose maps;maintenance","","","","28","","17 Oct 2019","","","IEEE","IEEE Conferences"
"Modulation Recognition of Underwater Acoustic Communication Signals Based on Data Transfer","N. Jiang; B. Wang","PLA Strategic Support Force, Information Engineering University, Zhengzhou, China; PLA Strategic Support Force, Information Engineering University, Zhengzhou, China","2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)","5 Aug 2019","2019","","","243","246","In practical applications, there are few labeled training samples in modulation recognition of underwater acoustic communication signals. In order to solve the problem, a data transfer learning method is proposed. The underwater noise in the actual water area is superimposed on the simulation signals to form the training set. The power spectrums of signals are performed as the input of the sparse autoencoder (SAE) network for training. The experimental results show that, when the channel is in good condition, for 2FSK, 4FSK, 8FSK, BPSK, OFDM and LFM, the proposed method can improve the recognition rate to a certain extent compared with the training method without data transfer.","","978-1-5386-8178-7","10.1109/ITAIC.2019.8785698","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8785698","modulation recognition;SAE;data transfer","Modulation;Underwater acoustics;Training;OFDM;Data transfer;Feature extraction;Signal to noise ratio","acoustic noise;acoustic signal processing;frequency shift keying;geophysical signal processing;modulation;OFDM modulation;phase shift keying;telecommunication computing;underwater acoustic communication;unsupervised learning;wireless channels","underwater acoustic communication signals;data transfer learning method;underwater noise;actual water area;simulation signals;training set;2FSK;4FSK;training method;modulation recognition;labeled training samples;LFM;OFDM;BPSK;8FSK;SAE network;sparse autoencoder network;power spectrums;recognition rate improvement","","","","10","","5 Aug 2019","","","IEEE","IEEE Conferences"
"Clinical Evaluation of a Colonoscopy Simulator with Improved Haptics","S. Y. Yi; H. S. Woo; W. Ahn; J. K. Joo; D. Y. Lee","Department of Internal Medicine, Ewha Womans University, Seoul, Republic of Korea. syy@ewha.ac.kr; Department of Mechanical Engineering, KAIST, Daejeon, Republic of Korea. freely@kaist.ac.kr, sokna@kaist.ac.kr, mechychan@kaist.ac.kr; Department of Mechanical Engineering, KAIST, Daejeon, Republic of Korea. sokna@kaist.ac.kr, freely@kaist.ac.kr, mechychan@kaist.ac.kr; Department of Mechanical Engineering, KAIST, Daejeon, Republic of Korea. mechychan@kaist.ac.kr, freely@kaist.ac.kr, sokna@kaist.ac.kr; Department of Mechanical Engineering, KAIST, Daejeon, Republic of Korea. lee.dooyong@kaist.ac.kr, freely@kaist.ac.kr, sokna@kaist.ac.kr, mechychan@kaist.ac.kr","IECON 2006 - 32nd Annual Conference on IEEE Industrial Electronics","16 Apr 2007","2006","","","4125","4129","This paper presents a clinical evaluation of a newly-developed colonoscopy training simulator that includes a specialized haptic interface to transfer force-feedback through a long and flexible colonoscope tube. The colonoscopy simulator has a 2-DOF haptic device with folding guides, which can transfer large decoupled forces of the colonoscopy simulation to the user. Centerline-based parametric colon models are developed to compute collision detection and response in real-time. The clinical study included 22 subjects consisting of colonoscopy experts (n=3), fellows (n=4), residents (n=6), and medical school students (n=9). The study shows that the developed colonoscopy simulator can effectively improve the skills of the residents and medical school students, although no statistically significant training-effects can be established for the fellows","1553-572X","978-1-5090-9155-3","10.1109/IECON.2006.347723","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4153452","","Colonoscopy;Haptic interfaces;Medical simulation;Computational modeling;Medical diagnostic imaging;Colon;Endoscopes;Computer simulation;Graphics;Gastrointestinal tract","biomedical education;computer based training;endoscopes;haptic interfaces;medical computing","clinical evaluation;colonoscopy simulator;haptic interface;colonoscope tube;centerline-based parametric colon models;collision detection","","","1","10","","16 Apr 2007","","","IEEE","IEEE Conferences"
"Component based video communication tool for collaborative virtual environment","H. Sakamoto; Y. Okada; T. Shimokawa; K. Ushijima","Graduate Sch. of Inf. Sci. & Electr. Eng., Kyushu Univ., Fukuoka, Japan; NA; NA; NA","Proceedings 15th International Conference on Information Networking","7 Aug 2002","2001","","","375","380","This paper treats a component based video communication tool for collaborative virtual environments. Especially the authors propose a new concept and its realization mechanisms for easy construction of distributed 3D graphics applications using video communications, e.g., network meeting, conference, and training in a 3D virtual space. If a software component is represented as a visible, manually operable object, users can make its copy and transfer it to another computer easily and rapidly. If a facility that manages video/audio data is realized as such a object, even end-users can easily and rapidly build networked video communication environments through the copy-and-transfer operation. To clarify an availability of this concept, the authors employ the IntelligentBox system as a research platform. The authors introduced a video communication facility as a software component into the IntelligentBox system. IntelligentBox has provided a network communication facility as a software component. Using these components, it will be possible to build collaborative virtual environments, which support video communications, through copy-and-transfer operations.","","0-7695-0951-7","10.1109/ICOIN.2001.905454","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=905454","","Collaborative tools;Videoconference;Intelligent systems;Virtual environment;Computer graphics;Application software;Management training;Communication system operations and management;Computer network management;Environmental management","visual communication;virtual reality;groupware;computer graphics;information networks","component based video communication tool;collaborative virtual environment;distributed 3D graphics applications;network meeting;conference;training;3D virtual space;visible manually operable object;video/audio data management;networked video communication environments;copy-and-transfer operation;IntelligentBox system;research platform;information network technologies;broadband networks","","1","","11","","7 Aug 2002","","","IEEE","IEEE Conferences"
"A novel development tool of fuzzy neural networks","Meng Joo Er; Jun Liao; Jianya Lin; Maolin Ni","Sch. of Electr. & Electron. Eng., Nanyang Technol. Univ., Singapore; NA; NA; NA","Proceedings of the 2000 American Control Conference. ACC (IEEE Cat. No.00CH36334)","6 Aug 2002","2000","4","","2458","2462 vol.4","To facilitate the transfer of technology emerging from theoretical research into fuzzy neural networks (FNN) for industrial applications, a fuzzy neural networks system for the automatic generation (FNNAGS) is proposed. In FNNAGS, the fuzzy model constructed by the system can be expressed as either a Mamdani model or a Takagi-Sugeno model, according to the preference of the user. Off-line design and online applications are incorporated into an interactive software system. In the stage of off-line design, only the training data need to be provided in order to construct a process model. Users do not need to give the initial fuzzy partitions, membership functions or fuzzy logic rules. These initial parameters will be set up automatically by the FNNAGS, in accordance with the properties of the training data. After off-line design has been completed, the model can be expressed as a fuzzy rule base, which can be used to control, estimate, identify or predict a process or giant through an application interface between FNNAGS and the external world.","0743-1619","0-7803-5519-9","10.1109/ACC.2000.878623","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=878623","","Fuzzy neural networks;Fuzzy control;Training data;Fuzzy logic;Fuzzy systems;Takagi-Sugeno model;Application software;Software systems;Predictive models;Automatic control","technology transfer;fuzzy neural nets;digital simulation;learning (artificial intelligence);multilayer perceptrons;object-oriented methods","development tool;technology transfer;Mamdani model;Takagi-Sugeno model;interactive software system;off-line design;training data;process model;fuzzy rule base","","","","10","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Sim2Real Predictivity: Does Evaluation in Simulation Predict Real-World Performance?","A. Kadian; J. Truong; A. Gokaslan; A. Clegg; E. Wijmans; S. Lee; M. Savva; S. Chernova; D. Batra","Facebook AI Research, Menlo Park, CA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Facebook AI Research, Menlo Park, CA, USA; Facebook AI Research, Menlo Park, CA, USA; Facebook AI Research, Menlo Park, CA, USA; Oregon State University, Corvallis, OR, USA; Facebook AI Research, Menlo Park, CA, USA; Facebook AI Research, Menlo Park, CA, USA; Facebook AI Research, Menlo Park, CA, USA","IEEE Robotics and Automation Letters","26 Aug 2020","2020","5","4","6670","6677","Does progress in simulation translate to progress on robots? If one method outperforms another in simulation, how likely is that trend to hold in reality on a robot? We examine this question for embodied PointGoal navigation - developing engineering tools and a research paradigm for evaluating a simulator by its sim2real predictivity. First, we develop Habitat-PyRobot Bridge (HaPy), a library for seamless execution of identical code on simulated agents and robots - transferring simulation-trained agents to a LoCoBot platform with a one-line code change. Second, we investigate the sim2real predictivity of Habitat-Sim M. Savva et al., for PointGoal navigation. We 3D-scan a physical lab space to create a virtualized replica, and run parallel tests of 9 different models in reality and simulation. We present a new metric called Sim-vs-Real Correlation Coefficient (SRCC) to quantify predictivity. We find that SRCC for Habitat as used for the CVPR19 challenge is low (0.18 for the success metric), suggesting that performance differences in this simulator-based challenge do not persist after physical deployment. This gap is largely due to AI agents learning to exploit simulator imperfections - abusing collision dynamics to `slide' along walls, leading to shortcuts through otherwise non-navigable space. Naturally, such exploits do not work in the real world. Our experiments show that it is possible to tune simulation parameters to improve sim2real predictivity (e.g. improving SRCCSucc from 0.18 to 0.844) - increasing confidence that in-simulation comparisons will translate to deployed systems in reality.","2377-3766","","10.1109/LRA.2020.3013848","NSF; Air Force Research Laboratory; Defense Advanced Research Projects Agency; ONR YIPs; ARO PECASE; Amazon Catalyst; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9158349","Visual-based navigation;reinforcement learning","Robots;Navigation;Task analysis;Predictive models;Correlation;Measurement","artificial intelligence;collision avoidance;computer simulation;human-robot interaction;learning (artificial intelligence);mobile robots;multi-agent systems;virtual reality","one-line code change;simulation predict Real-world performance;embodied PointGoal navigation;Habitat-PyRobot Bridge;robots-transferring simulation-trained agents;LoCoBot platform;Sim-vs-Real Correlation Coefficient;Habitat-Sim M. Savva et al;Sim2Real Predictivity;virtualized replica;SRCC;AI agents learning;HaPy;agent simulation","","3","","37","IEEE","4 Aug 2020","","","IEEE","IEEE Journals"
"An assessment of resource exploitation using artificial intelligence based traffic control strategies","V. Catania; G. Ficili; D. Panno","Ist. di Inf. e Telecommun., Catania Univ., Italy; NA; NA","Proceedings Second IEEE Symposium on Computer and Communications","6 Aug 2002","1997","","","162","166","We assess the application of artificial intelligence techniques to the complex problem of traffic control in ATM networks. The paper deals with the close link between call admission control and usage parameter control and proposes a simulation-based analysis to demonstrate how inefficiency on the part of policing affects bandwidth allocation. To take this into account, the paper proposes a framework for traffic control in which the CAC and policing functions are both based on artificial intelligence techniques, i.e. neural networks and fuzzy logic. In this way it is possible to train the neural network in such a way as to take into account the real behavior of the policer. As the results obtained show this allows us to implement traffic management strategies which can improve the exploitation of network resources.","","0-8186-7852-6","10.1109/ISCC.1997.615989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=615989","","Artificial intelligence;Traffic control;Communication system traffic control;Asynchronous transfer mode;Neural networks;Telecommunication traffic;Call admission control;Fuzzy logic;Resource management;Quality of service","asynchronous transfer mode;learning (artificial intelligence);neural nets;telecommunication computing;telecommunication congestion control;telecommunication traffic;fuzzy logic;telecommunication network management;digital simulation;simulation","resource exploitation;artificial intelligence based traffic control;ATM networks;call admission control;usage parameter control;simulation based analysis;bandwidth allocation;policing;neural networks;fuzzy logic;neural network training;traffic management;network resources;performance degradation","","","3","8","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Perceptually Augmented Simulator Design","T. Edmunds; D. K. Pai","University of British Columbia, Vancouver; University of British Columbia, Vancouver","IEEE Transactions on Haptics","9 Mar 2012","2012","5","1","66","76","Training simulators have proven their worth in a variety of fields, from piloting to air-traffic control to nuclear power station monitoring. Designing surgical simulators, however, poses the challenge of creating trainers that effectively instill not only high-level understanding of the steps to be taken in a given situation, but also the low-level “muscle-memory” needed to perform delicate surgical procedures. It is often impossible to build an ideal simulator that perfectly mimics the haptic experience of a surgical procedure, but by focussing on the aspects of the experience that are perceptually salient we can build simulators that effectively instill learning. We propose a general method for the design of surgical simulators that augment the perceptually salient aspects of an interaction. Using this method, we can increase skill-transfer rates without requiring expensive improvements in the capability of the rendering hardware or the computational complexity of the simulation. In this paper, we present our decomposition-based method for surgical simulator design, and describe a user-study comparing the training effectiveness of a haptic-search-task simulator designed using our method versus an unaugmented simulator. The results show that perception-based task decomposition can be used to improve the design of surgical simulators that effectively impart skill by targeting perceptually significant aspects of the interaction.","2329-4051","","10.1109/TOH.2011.42","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5975145","Haptic I/O;artificial;augmented;and virtual realities;life and medical sciences;surgical simulation.","Haptic interfaces;Surgery;Training;Needles;Rendering (computer graphics);Surface roughness;Rough surfaces","augmented reality;computer based training;haptic interfaces;medical computing;surgery","perceptually augmented simulator design;training simulator;air-traffic control;piloting;nuclear power station monitoring;surgical simulator;low-level muscle-memory;surgical procedure;haptic experience;salient interaction aspect;skill-transfer rate;rendering hardware;computational complexity;decomposition-based method;user study;haptic-search-task simulator;unaugmented simulator;perception-based task decomposition","","2","","21","","4 Aug 2011","","","IEEE","IEEE Journals"
"Development of a brachial plexus blocker prototype","S. C. Monteiro","Escola Superior de Tecnologia e Gestão - Instituto Politécnico de Bragança, Alameda de Santa Apolónia, 5300-253 Bragança, Bragança, Portugal","2017 12th Iberian Conference on Information Systems and Technologies (CISTI)","13 Jul 2017","2017","","","1","6","Although the area of surgical simulation has been the subject of study in recent years, it is still necessary to develop artificial experimental models with a perspective to dismiss the use of biological models. Since this makes the simulators more real, transferring the environment of the health professional to a physical or virtual reality, an anesthetic prototype has been developed, where the motor response is replicated when the brachial plexus is subjected to a proximal nervous stimulus. Using action-research techniques, with this simulator it was possible to validate that the human nerve response can be replicated, which will aid the training of health professionals, reducing possible risks in a surgical environment.","","978-9-8998-4347-9","10.23919/CISTI.2017.7976010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7976010","Anesthesia;Simulation;brachial plexus blockade;Arduino;3D Print","Visualization;Solid modeling;Biological system modeling;Monitoring;Three-dimensional displays;Brachytherapy;Adaptation models","computer based training;digital simulation;medical computing;professional aspects;surgery;virtual reality","brachial plexus blocker prototype;surgical simulation;biological models;physical system;virtual reality;anesthetic prototype;motor response;proximal nervous stimulus;action-research techniques;human nerve response;health professional training;risk reduction;surgical environment","","","","8","","13 Jul 2017","","","IEEE","IEEE Conferences"
"Deep Transfer Learning-Based Adaptive Beamforming for Realistic Communication Channels","H. Yang; J. Jee; G. Kwon; H. Park","Korea Advanced Institute of Science and Technology (KAIST),School of Electrical Engineering,Daejeon,South Korea; Korea Advanced Institute of Science and Technology (KAIST),School of Electrical Engineering,Daejeon,South Korea; Korea Advanced Institute of Science and Technology (KAIST),School of Electrical Engineering,Daejeon,South Korea; Korea Advanced Institute of Science and Technology (KAIST),School of Electrical Engineering,Daejeon,South Korea","2020 International Conference on Information and Communication Technology Convergence (ICTC)","21 Dec 2020","2020","","","1373","1376","Recently, in a massive multiple-input multipleoutput (MIMO) system, deep learning (DL)-based beamforming method has been proposed for reducing the overhead associated with downlink training and uplink feedback. However, the DL-based approach is sensitive to the variation of the communication environment and requires a huge number of training data to ensure a certain level of performance. To reduce the number of required channel data for training a deep neural network (DNN), we introduce deep transfer learning (DTL), which exploits the information from the pre-trained DNN for training other DNNs to find the beamforming vector in the specific channel. Through DTL, DNN can be trained suitably for the communication environment at each BS with fewer channel data. Moreover, we propose `step-by-step' DTL to flexibly apply DTL considering the uncertainties of the realistic system. Simulation results show that DTL has better performance than the conventional DLapproaches even with a small amount number of channel data. Therefore, the DTL-based approach can be a good framework to train DNN when high overhead occurs or designing the beamformer is complicated such as a massive MIMO system.","2162-1233","978-1-7281-6758-9","10.1109/ICTC49870.2020.9289412","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9289412","Beamforming;Massive MIMO;Deep Learning;Transfer Learning","Training;Uncertainty;Array signal processing;Simulation;Neural networks;Training data;Uplink","array signal processing;feedback;learning (artificial intelligence);MIMO communication;neural nets;telecommunication computing;wireless channels","channel data;step-by-step DTL;realistic system;DTL-based approach;massive MIMO system;deep transfer learning;adaptive beamforming;realistic communication channels;downlink training;uplink feedback;communication environment;training data;required channel data;deep neural network;pre-trained DNN;beamforming vector","","","","10","","21 Dec 2020","","","IEEE","IEEE Conferences"
"A semi-physical virtual simulation system for AUV","Wang Hong-jian; Shi Xiao-cheng; Zhao Jie; Li Juan; Fu Ming-yu","Dept, of Mechatronic Eng., Harbin Inst. of Technol., China; Dept, of Mechatronic Eng., Harbin Inst. of Technol., China; Dept, of Mechatronic Eng., Harbin Inst. of Technol., China; NA; NA","Oceans '04 MTS/IEEE Techno-Ocean '04 (IEEE Cat. No.04CH37600)","14 Mar 2005","2004","3","","1560","1563 Vol.3","Just as Healey and Brutzman(1997) stated that ""... a critical bottleneck exists in AUV design and development"". Integrated simulator testing of AUV software and hardware is a broad and versatile method that supports rapid diagnosis and robust correction of system faults in the lab environment. So a semi-physical virtual simulation system for AUV is developed based on software developing platform-MultiGen Creator and Vega, and acts as an effective capable tool for long range training and intelligent behavioral operation for AUV. It is the objective of such design and development work to simulate a large-scale oceanic environment and to demonstrate a dynamic procedure of AUV under the control of the autonomous planning technology and the dynamic controlling technology. Some schemes about hardware topology architecture and software architecture of AUV simulation system are presented in the paper. Some mathematic models of AUV motion, the method of space consistency in visual simulation and data transfer mechanisms are also detailed introduced. All of above-mentioned forms a basis for integrating the intelligence technology and virtual simulation technology into the semi-physical simulation system. Finally, some real-time operational experiment results are presented at form of three-dimensional graphics, which is simulating the ocean exploration progress of AUV in virtual reality under the control of intelligence. The result shows that the simulation system is reasonable and reliable, that the mathematics model and simulation algorithm completely satisfy the real-time requirement, and that the simulation system can realistically demonstrate the simulation process of AUV. This semi-physical simulation system has been successfully applied to validate the correctness, validity and practicability for the autonomous planning algorithms and dynamic control algorithm of a certain AUV","","0-7803-8669-8","10.1109/OCEANS.2004.1406354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1406354","","Space technology;Marine technology;Hardware;Mathematics;Mathematical model;Heuristic algorithms;Software testing;System testing;Fault diagnosis;Robustness","oceanographic equipment;oceanographic techniques;remotely operated vehicles;test equipment;underwater vehicles;virtual reality","semiphysical virtual simulation system;autonomous underwater vehicle;integrated simulator testing;AUV software;AUV hardware;MultiGen Creator;Vega;long range training;intelligent behavioral operation;oceanic environment simulation;autonomous planning algorithm;dynamic control algorithm;hardware topology architecture;software architecture;mathematical model;AUV motion;visual simulation;data transfer;real-time operational experiment;3D graphics;ocean exploration;virtual reality","","1","","9","","14 Mar 2005","","","IEEE","IEEE Conferences"
"Approach on a new methodology for skills transfer using a parallel planar robot with visuo-vibrotactile feedback","P. Humblot-Niño; O. Sandoval-González; I. Herrera-Aguilar; D. Rangel-Peñuelas; A. Flores-Cuautle; B. González-Sánchez","División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México; División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México; División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México; División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México; CONACYT - División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México; División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México","2017 14th International Conference on Electrical Engineering, Computing Science and Automatic Control (CCE)","16 Nov 2017","2017","","","1","5","An approach of a new methodology for skills transfer from machine to human is proposed in this research. This methodology transmits a haptic feed-back using vibrotactile perception to transfer motor skills using a parallel planar robot and virtual reality environments. During the experimentation, the participants tried to learn a specific motion trajectory given by the system. During the process, the system computes the current position and generates a vibrotactile feed-back proportional to the error computed between the actual and the desired position of the motion trajectory. The results of the user studies showed this system can help with learning new skills.","","978-1-5386-3406-6","10.1109/ICEEE.2017.8108861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8108861","Skill Transfer;Parallel Planar Robot;Methodology","Haptic interfaces;Virtual environments;Robot sensing systems;Training;End effectors;Trajectory","feedback;haptic interfaces;human computer interaction;human-robot interaction;position control;virtual reality","haptic feedback;motion trajectory;visuo-vibrotactile feedback;virtual reality environments;parallel planar robot;motor skills;vibrotactile perception;skills transfer","","","","16","","16 Nov 2017","","","IEEE","IEEE Conferences"
"Evaluating exemplary training accelerators for Programming-by-Demonstration","T. Hulin; V. Schmirgel; E. Yechiam; U. E. Zimmermann; C. Preusche; G. Pöhler","Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; KUKA Roboter GmbH, Germany; Faculty of Industrial Engineering and Management, Technion, Israel; KUKA Roboter GmbH, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Otto-von-Guericke University, Magdeburg, Germany","19th International Symposium in Robot and Human Interactive Communication","11 Oct 2010","2010","","","440","445","Robot Programming by Demonstration requires comprehending the usage of a robotic system. This article is about accelerating the training of these skills, using the example of a DLR/KUKA light-weight robot. An augmented reality and a virtual reality setup are presented that aim to demonstrate and evaluate skills transfer of two different sub-tasks of this system: Avoiding robot singularities and setting correct compliance parameters. For this purpose training accelerators are introduced for visualising robot singularities, exploring robot singularities and feeling compliance parameters. An evaluation procedure for all three accelerators is suggested and has been performed on the first two. As interesting evaluation result a contrast to the Cognitive Theory of Multimedia Learning hypothesis could be observed: Additional visual information on the robot singularities impairs the participants' performance.","1944-9437","978-1-4244-7990-0","10.1109/ROMAN.2010.5598611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5598611","","Robots;Visualization;Training;Haptic interfaces;Games;Joints;Collision avoidance","augmented reality;automatic programming;industrial robots;robot programming","exemplary training accelerators;robot programming by demonstration;DLR/KUKA light-weight robot;augmented reality;virtual reality;robot singularities;multimedia learning hypothesis;cognitive theory","","6","1","21","","11 Oct 2010","","","IEEE","IEEE Conferences"
"Fast power control for GSM HBS using training sequences","M. I. Silventoinen; P. A. Ranta; M. Raitola","Nokia Res. Center, Espoo, Finland; NA; NA","1997 IEEE 47th Vehicular Technology Conference. Technology in Motion","6 Aug 2002","1997","3","","1689","1693 vol.3","We investigate the usage of fast power control (PC) in Global System for Mobile Communications (GSM) based home base station (HBS) system to alleviate Rayleigh fading for slow moving mobile stations (MS). Low-speed MSs suffer from Rayleigh fading most due to the long periods they spend in the fading dips. Especially, if the system does not employ other techniques to combat Rayleigh fading, such as frequency hopping (FH), the negative effects of the fading are serious. To implement the signalling for fast PC, we propose the usage of training sequences to transfer the power control information over the GSM radio interface. The benefits of this method are various: the transfer of the PC commands will be fast, reliable and the pay load of the frame is not wasted. The magnitude of the improvement was assessed by simulating the link using the COSSAP simulating tool. The conclusion was that the fast PC will increase the link capacity and partly compensates the lack of frequency hopping.","1090-3038","0-7803-3659-3","10.1109/VETEC.1997.605846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=605846","","Power control;GSM;Rayleigh channels;Frequency;Mobile communication;Base stations;Interference;Channel allocation;Spread spectrum communication;Telephone sets","cellular radio;telecommunication control;power control;fading;Rayleigh channels;telecommunication signalling;radio networks;telecommunication computing;digital simulation;simulation;multipath channels;land mobile radio;radiofrequency interference","GSM HBS;training sequences;fast power control;Global System for Mobile Communications;home base station;Rayleigh fading multipath channel;slow moving mobile stations;system performance;signalling;radio interface;COSSAP simulating tool;link capacity;mobile communications networks;interference","","1","12","7","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Driver's gaze zone estimation by transfer learning","I. R. Tayibnapis; M. Choi; S. Kwon","DGIST, Daegu, Republic of Korea; DGIST, Daegu, Republic of Korea; DGIST, Daegu, Republic of Korea","2018 IEEE International Conference on Consumer Electronics (ICCE)","29 Mar 2018","2018","","","1","5","Estimating driver's gaze zone has very important role to support advanced driver assistant system (ADAS). The gaze estimation can monitor the driver focus and indirectly control the user interface/user experience (UI/UX) on a windshield using augmented reality-head up display (AR-HUD). However, to train gaze zone estimator as a classification task, someone pays huge costs to gather a large amount of annotated dataset. To reduce the labor work, we used a transfer-learning method using pre-trained CNN model to project the gaze estimation task by regression on mobile devices that have large and reliable dataset into new classification task to overcome lack of annotated dataset for gaze zone estimation. We tested the proposed method to our own building simulation test bed. The result is shown in validation accuracy around 99.01 % and test accuracy with unseen driver around 60.25 % for estimating 10 gaze zones in-vehicle.","2158-4001","978-1-5386-3025-9","10.1109/ICCE.2018.8326308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8326308","","Estimation;Tablet computers;Support vector machines;Automobiles;Mobile handsets;Feature extraction","augmented reality;driver information systems;gaze tracking;head-up displays;human computer interaction;learning (artificial intelligence);mobile computing;motion estimation;neural nets;pattern classification;regression analysis;traffic engineering computing;user interfaces","transfer learning;advanced driver assistant system;augmented reality-head up display;gaze zone estimator;classification task;user interface;user experience;driver gaze zone estimation;pre-trained CNN model;regression;mobile devices","","","","16","","29 Mar 2018","","","IEEE","IEEE Conferences"
"Effects of mobile AR-enabled interactions on retention and transfer for learning in art museum contexts","Weiquan Lu; Linh-Chi Nguyen; Teong Leong Chuah; Ellen Yi-Luen Do","Keio-NUS CUTE Center, Interactive and Digital Media Institute, National University of Singapore, Singapore; Keio-NUS CUTE Center, Interactive and Digital Media Institute, National University of Singapore, Singapore; Keio-NUS CUTE Center, Interactive and Digital Media Institute, National University of Singapore, Singapore; Keio-NUS CUTE Center, Interactive and Digital Media Institute, National University of Singapore, Singapore","2014 IEEE International Symposium on Mixed and Augmented Reality - Media, Art, Social Science, Humanities and Design (ISMAR-MASH'D)","27 Oct 2014","2014","","","3","11","In this paper, we describe an experiment to study the effect of mobile Augmented Reality (AR) on learning in art museum contexts. We created six original paintings and placed them in a mini art museum. We then created an AR application on the iPad to enable the artist to visually augment each painting by introducing animation. We then measured the ability of the visitors to remember the appearance of the paintings after 24 hours, as well as their ability to objectify the paintings. Experiment results show that while AR does improve retention and transfer of such art information, the benefits of AR are mediated by other factors such as interference from other elements of the exhibition, as well as subjects' own prior art experience and training. The use of AR may also produce unexpected benefits, such as providing users with a new perspective of the artwork, as well as increasing their curiosity and encouraging them to experiment with the technology. Such benefits may potentially improve the chances for learning and analytical activities to take place.","2381-8360","978-1-4799-6887-9","10.1109/ISMAR-AMH.2014.6935432","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6935432","Evaluation;Learning;Museums;Software","Painting;Art;Tablet computers;Animation;Protocols;Context;Training","augmented reality;computer aided instruction;computer animation;mobile computing;museums","mobile AR enabled interaction;augmented reality;art museum context;learning;mini art museum;iPad;animation;art experience;art training","","2","","19","","27 Oct 2014","","","IEEE","IEEE Conferences"
"3D Hand Pose Estimation with a Single Infrared Camera via Domain Transfer Learning","G. Park; T. -K. Kim; W. Woo",KAIST UVR Lab.; Imperial College London & KAIST; KAIST UVR Lab.,"2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)","14 Dec 2020","2020","","","588","599","Previous methods successfully estimated 3D hand poses from unblurred depth images with slow and smooth hand motions. However, the performance drops when the depth images are contaminated by motion blur due to fast hand motion. In this paper, we exploit an infrared (IR) image input, which is weakly blurred under fast hand motion. The proposed method is based on domain transfer learning from depth to infrared images. Note we do not have IR images with hand skeletons, thus proposing self-supervision rather than direct supervision using the skeleton labels. We train a Hand Image Generator (HIG) and two Hand Pose Estimators (HPEs) on paired depth and infrared images via self-supervision using a consistency loss, guided by an existing HPE trained on paired depth and hand skeleton entries. The IR-based HPE is then refined on the weakly blurred infrared images. The qualitative and quantitative experiments demonstrate that the proposed method accurately estimates 3D hand poses under motion blur by fast hand motion, while existing depth-based methods fail. Our solution therefore supports fast 3D manipulation of virtual objects for augmented reality applications. Our model and dataset are publicly available for future research.1","1554-7868","978-1-7281-8508-8","10.1109/ISMAR50242.2020.00086","National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284791","Computing methodologies;Computer vision problems;Deep learning","Solid modeling;Three-dimensional displays;Pose estimation;Network architecture;Cameras;Skeleton;Augmented reality","augmented reality;cameras;computer vision;feature extraction;image colour analysis;image motion analysis;image segmentation;image sensors;infrared imaging;learning (artificial intelligence);object detection;object tracking;pose estimation","3D hand pose estimation;single infrared camera;domain transfer learning;unblurred depth images;slow hand motions;smooth hand motions;motion blur;fast hand motion;infrared image input;IR images;hand skeletons;hand pose estimators;paired depth;hand skeleton entries;weakly blurred infrared images;depth-based methods;fast 3D manipulation;hand image generator","","","","60","","14 Dec 2020","","","IEEE","IEEE Conferences"
"Towards automatic generation of multimodal AR-training applications and workflow descriptions","T. Engelke; S. Webel; U. Bockholt; H. Wuest; N. Gavish; F. Tecchia; C. Preusche","Fraunhofer IGD, Germany; Fraunhofer IGD, Germany; Fraunhofer IGD, Germany; Fraunhofer IGD, Germany; Technion-Israel, Institute of Technology, Israel; PERCRO - Scuola Superiore Sant'Anna, Italy; German Aerospace Center (DLR), Germany","19th International Symposium in Robot and Human Interactive Communication","11 Oct 2010","2010","","","434","439","Augmented Reality (AR) is a technology which has become very popular in the last years. In this context also the idea of using of AR for training applications has become very important. AR offers a large potential for training only if the training is well focused to the skills that have to be trained and if the training protocol is well designed. On the other hand, the generation of the training content to be transferred via AR is a comprehensive problem that is addressed in this paper. Thus, this paper tries to describe the whole chain of implementations and general aspects involved in the creation of AR training applications, including examples for used multimodal devices. This chain starts with the capturing of expert actions to be hold in the ""digital representation of skill"". The digital representation of skill is transferred to the training protocol that specifies the storyboard of the AR training session. The paper includes two different implementations of AR training systems and describes the general idea of informational abstraction from low level data up to interaction and from design to application.","1944-9437","978-1-4244-7990-0","10.1109/ROMAN.2010.5598613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5598613","","Training;Augmented reality;Protocols;Assembly;Solid modeling;Haptic interfaces;Maintenance engineering","augmented reality;computer aided instruction","multimodal AR-training applications;workflow descriptions;augmented reality;training protocol;digital representation","","2","","21","","11 Oct 2010","","","IEEE","IEEE Conferences"
"Exploiting Transfer Learning for Emotion Recognition Under Cloud-Edge-Client Collaborations","D. Wu; X. Han; Z. Yang; R. Wang","Chongqing Key Laboratory of Optical Communication and Networks, Chongqing Key Laboratory of Ubiquitous Sensing and Networking, School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Optical Communication and Networks, Chongqing Key Laboratory of Ubiquitous Sensing and Networking, School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Optical Communication and Networks, Chongqing Key Laboratory of Ubiquitous Sensing and Networking, School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China","IEEE Journal on Selected Areas in Communications","14 Jan 2021","2021","39","2","479","490","Emerging virtual reality/augmented reality games and self-driving cars necessitate accurate/responsive/private emotion recognition. Usually, traditional emotion recognition models are deployed at central servers, which results in the lack of abilities in generalization and covering the individual variation of clients. This paper proposes a responsive, localized, and private transfer learning based emotion recognition framework under the cloud-edge-client collaborations. Additionally, a 3-dimensional channel mapping method is designed to aggregate features extracted from electroencephalogram (EEG) signals for the generic emotion recognition model, which is further localized and personalized using transfer learning. Simulation results validate the performance of the proposed TLER framework in reducing model training time and improving emotion recognition accuracy.","1558-0008","","10.1109/JSAC.2020.3020677","National Natural Science Foundation of China; Science and Technology Research Program of Chongqing Municipal Education Commission; Natural Science Foundation of Chongqing of China; Science and Technology Research Program of Chongqing Municipal Education Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187207","Electroencephalogram;emotion recognition;transfer learning;cloud-edge-client collaboration","Brain modeling;Emotion recognition;Electroencephalography;Feature extraction;Machine learning;Collaboration;Scalp","augmented reality;cloud computing;computer games;electroencephalography;emotion recognition;feature extraction;learning (artificial intelligence);medical signal processing","cloud-edge-client collaborations;self-driving cars;3-dimensional channel mapping;responsive transfer learning based emotion recognition;localized transfer learning based emotion recognition;private transfer learning based emotion recognition;electroencephalogram signals;feature extraction;TLER framework;virtual reality-augmented reality games","","1","","43","IEEE","7 Sep 2020","","","IEEE","IEEE Journals"
"Training strategies for learning a 3D trajectory with accuracy","J. Rodríguez; T. Gutiérrez; S. Casado; E. J. Sánchez","Department of Applied Mechanics, CEIT - University of Navarra, Spain; LABEIN-TECNALIA, Spain; LABEIN-TECNALIA, Spain; Department of Applied Mechanics, CEIT - University of Navarra, Spain","2010 IEEE International Symposium on Haptic Audio Visual Environments and Games","9 Nov 2010","2010","","","1","6","The goal of this study was to evaluate different learning conditions for motor skill transfer. The study was divided into two experiments with the same task: learning a 3D trajectory with accuracy. The first experiment was focused on evaluating the efficiency of three feedback schemes for the target trajectory: visual, haptic and visual-haptic feedback. The second experiment was focused on analyzing the influence of decreasing the feedback during the training process. The results suggest that the best learning condition for learning a 3D trajectory with accuracy is to provide visual-haptic feedback, which facilitates the understanding of the dimension and orientation of each trajectory segment and solves any visual discrepancies that may exist. Furthermore, although continuous feedback can create dependences in users and impede the transfer of motor skills, feedback based on user request can also be dangerous since users can create a wrong mental representation that keep them from replicating the trajectory accurately. Therefore, when the performance of a task depends on references created during the training process, it seems appropriate for the system to provide automatic feedback based on user performance.","","978-1-4244-6509-5","10.1109/HAVE.2010.5623979","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5623979","virtual training;motor skill transfer;virtual teaching;haptic feedback","Trajectory;Haptic interfaces;Visualization;Training;Three dimensional displays;Accuracy;Shape","haptic interfaces;knowledge representation;training;virtual reality;visual perception","training strategy;3D trajectory;motor skill transfer;visual-haptic feedback;trajectory segment;visual discrepancy;virtual reality","","3","","13","","9 Nov 2010","","","IEEE","IEEE Conferences"
"Anthropomorphic robotic system with 6 DOF for space positioning in the virtual reality applications for human machine interaction","M. Chavez-Gamboa; I. Herrera-Aguilar; O. Sandoval-Gonzalez; F. Malagon-Gonzalez; J. M. Jacinto-Villegas","The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico; The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico; The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico; The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico; The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico","CONIELECOMP 2013, 23rd International Conference on Electronics, Communications and Computing","13 Jun 2013","2013","","","212","217","This paper presents a spatial hand tracking system using a 6 DOF anthropomorphic robot applied in human machine interaction. The main objective of this mechatronic system is to obtain information about the spatial position of a user's hand movements in order to be used like a skills trainer to accelerate the skills transfer from the machine to the human by integrating the laws of physics of virtual objects and adapting different design techniques and use of computer software for three-dimensional virtual reality.","","978-1-4673-6155-2","10.1109/CONIELECOMP.2013.6525788","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6525788","DOF;virtual reality;skills transfer;upper limbs;physical human-computer interaction;computational design","Virtual environments;Robots;Sensors;Software;Assembly;Kinematics","anthropology;gesture recognition;human-robot interaction;mechatronics;position control;robots;virtual reality","6 DOF anthropomorphic robotic system;space positioning;virtual reality applications;human machine interaction;spatial hand tracking system;mechatronic system;user hand movements;virtual objects;computer software;three-dimensional virtual reality","","","","18","","13 Jun 2013","","","IEEE","IEEE Conferences"
"Visual and Haptic Error Modulating Controllers for Robotic Gait Training","P. Tsangaridis; D. Obwegeser; S. Maggioni; R. Riener; L. Marchal-Crespo","Department of Health Sciences and Technology (HEST), Sensory-Motor Systems (SMS) Lab, Zurich, ETH, Switzerland; Department of Health Sciences and Technology (HEST), Sensory-Motor Systems (SMS) Lab, Zurich, ETH, Switzerland; Department of Health Sciences and Technology (HEST), Sensory-Motor Systems (SMS) Lab, Zurich, ETH, Switzerland; Department of Health Sciences and Technology (HEST), Sensory-Motor Systems (SMS) Lab, Zurich, ETH, Switzerland; University of of Bern, The Gerontechnology and Rehabilitation group, ARTORG Center for Biomedical Engineering Research, Switzerland","2018 7th IEEE International Conference on Biomedical Robotics and Biomechatronics (Biorob)","11 Oct 2018","2018","","","1050","1055","Robotic algorithms that augment movement errors have been proposed as promising training strategies to enhance motor training and neurorehabilitation. However, research effort has mainly focused on rehabilitation of upper limbs. In this study, we investigated the effect of training with novel error modulating strategies on learning an asymmetric gait pattern. Thirty healthy young participants walked in the robotic exoskeleton Lokomat, while learning a foot target-tracking task which required an increased hip and knee flexion in the dominant leg. Learning with three different strategies was evaluated: (i) No guidance: no disturbance/guidance was applied, (ii) Haptic error amplification: dangerous and discouraging large errors were limited with haptic guidance, while awareness of task relevant errors was enhanced with error amplification, and (iii) Visual error amplification: visually perceived errors were amplified in a virtual reality environment. We also evaluated whether increasing the movement variability during training by adding randomly-varying haptic disturbances on top of the other training strategies further enhanced learning. We found that training with the novel haptic error amplification strategy limited large errors during training, did not hamper learning and enhanced transfer of the learned asymmetric gait pattern. Training with visual error amplification, on the other hand, increased errors during training and hampered motor learning. Adding haptic disturbances did not have a significant effect on learning. The novel haptic error modulating controller that amplifies small task-relevant errors while limiting large errors provided the best framework to enhance motor learning.","2155-1782","978-1-5386-8183-1","10.1109/BIOROB.2018.8488011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8488011","","Training;Haptic interfaces;Legged locomotion;Visualization;Task analysis;Trajectory","gait analysis;haptic interfaces;learning (artificial intelligence);medical robotics;neurophysiology;patient rehabilitation;virtual reality","task-relevant errors;visual error modulating controllers;haptic error modulating controllers;novel haptic error modulating controller;hampered motor learning;increased errors;learned asymmetric gait pattern;enhanced transfer;novel haptic error amplification strategy;enhanced learning;haptic disturbances;visually perceived errors;visual error amplification;task relevant errors;haptic guidance;disturbance/guidance;different strategies;knee flexion;increased hip;foot target-tracking task;robotic exoskeleton Lokomat;thirty healthy young participants;motor training;promising training strategies;augment movement errors;robotic algorithms;robotic gait training","","","","26","","11 Oct 2018","","","IEEE","IEEE Conferences"
"Can immersive type of Virtual Reality bring EMG pattern changes post facial palsy?","U. Qidwai; M. S. Ajimsha","KINDI Lab for Computing Research, Department of Computer Science & Engineering, Qatar University, Doha, Qatar; Physiotherapy Specialist, Dept. of Physical Therapy, Hamad Medical Corporation, Doha, Qatar","2015 Science and Information Conference (SAI)","3 Sep 2015","2015","","","756","760","The loss of facial expression via facial paralysis is a devastating condition, both functionally and aesthetically. However, given the life-long plasticity of the brain one could assume that recovery could be facilitated by the harnessing of mechanisms underlying neuronal reorganization. Currently it is not clear how this reorganization can be mobilized. Novel technology based neurorehabilitation techniques hold promise to address this issue. In this paper an immersive Virtual Reality (VR) based system is presented that is based on a number of hypotheses related to the neural structures targeted for recovery/reorganization, the structure of training system, and the role of individualization. The purpose of this paper is to examine the effects of an immersive type virtual reality (VR) intervention on activation of facial upper quadrant muscles following facial palsy in comparison with a control program. The key components of an immersive Virtual Reality (VR) based system and its effectiveness on facial palsy rehabilitation has been described in the form of experimental findings. Experimental trial was performed on an individual with facial upper quadrant muscles weakness due to facial palsy in a crossover study methodology with and without VR. EMG patterns from the facial upper quadrant muscles were recorded and analyzed for results. This trial has plotted a positive relationship between VR and facial upper quadrant muscles activation following a neurological impetus. The results reported here also show a consistent transfer of movement kinematics between physical and virtual tasks. EMG analysis has shown progressing improvement in the muscle activation in response to the challenging and impulsive activities in the virtual environment provided by the immersive VR devise.","","978-1-4799-8547-0","10.1109/SAI.2015.7237227","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7237227","Facial palsy;Virtual Reality;EMG-based measurements;Impulsive impetus","Muscles;Virtual reality;Electromyography;Training;Medical treatment;Neuroplasticity;Psychology","brain;electromyography;medical disorders;medical signal processing;neurophysiology;patient rehabilitation;virtual reality","EMG pattern;facial expression;facial paralysis;life-long plasticity;brain;neuronal reorganization;neurorehabilitation technique;neural structure recovery;neural structure reorganization;immersive virtual reality system;facial upper quadrant muscles;facial palsy rehabilitation;facial upper quadrant muscle weakness;neurological impetus;movement kinematics;physical task;virtual task;EMG analysis;muscle activation;impulsive activity;virtual environment","","","","19","","3 Sep 2015","","","IEEE","IEEE Conferences"
"The use of structured digital road network data bases for dispatching and routeing of emergency service","J. G. Linders","Dept. of Comput. & Inf. Sci., Guelph Univ., Ont., Canada","Conference Record of papers presented at the First Vehicle Navigation and Information Systems Conference (VNIS '89)","6 Aug 2002","1989","","","A54","A59","The author describes the development of a digital road network database for the Region of Waterloo, Ont. from National Topographic Service 1:50000 digital map files. The system was developed for use in conjunction with a positionally based emergency location code assigned to rural properties in the Region, and is being extended to other areas. Real-time dispatching and routeing of emergency service vehicles from a digital database have been demonstrated for over 10000 nodes and 13000 road segments. The database is being enhanced to incorporate a variety of attribute data which can be used by all emergency service agencies. A full set of network functions is included for dispatching, routeing network flow, simulation and training, etc. The road data can be structured to accommodate arbitrarily large networks by using an embedded hypergraph model. Other potential applications are based on use of automatic vehicle location as an onboard facility in conjunction with the database.<>","","0-9692316-2-8","10.1109/VNIS.1989.98824","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=98824","","Dispatching;Emergency services;Routing;Information science;Road vehicles;Transfer functions;Snow;Decision making;Manuals;Delay","data structures;digital simulation;dispatching;emergency services;flow simulation;geographic information systems;real-time systems;road vehicles;training","structured digital road network data bases;digital map files;emergency location code;routeing of emergency service vehicles;network functions;dispatching;simulation;training;embedded hypergraph model;automatic vehicle location","","1","1","5","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Quality of service support of distributed interactive virtual environment applications in IP networks","Hong Yu; Quanyou Zhou; D. Makrakis; N. D. Georganas; E. Petriu","Broadband Wireless & Internetworking Res. Lab., Ottawa Univ., Ont., Canada; NA; NA; NA; NA","2001 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing (IEEE Cat. No.01CH37233)","7 Aug 2002","2001","1","","196","199 vol.1","This paper reports on the performance of Distributed Interactive Virtual Environment (DIVE) applications, deployed through Internet. Our goal is to understand the behaviour of a DIVE application, its interaction with competing traffic streams, as well as its network resource requirements for a satisfactory performance. As DIVE is becoming the building block of new applications and services, impacting several existing or new and growing sectors of our economy (email electronic commerce, tele-training, transportation), it is important that we understand the resource requirements of these applications, as well as the ""stress"" they will impose on the network.","","0-7803-7080-5","10.1109/PACRIM.2001.953556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=953556","","Quality of service;Virtual environment;Intelligent networks;IP networks;Diffserv networks;Internet;Application software;Telecommunication traffic;Computational modeling;Asynchronous transfer mode","distributed processing;virtual reality;Internet;quality of service;computer network management","Distributed Interactive Virtual Environment applications;Internet;DIVE application;competing traffic streams;network resource requirements;DiffServ;quality of service","","2","","6","","7 Aug 2002","","","IEEE","IEEE Conferences"
"Simulating perception with interactive virtual environments","K. Mania","Dept. of Informatics, Sussex Univ., Brighton, UK","2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)","7 Mar 2005","2004","3","","2770","2776 vol.3","Computer graphics algorithms have for long dealt with simulation of physics: simulation of the geometry of a real-world space, simulation of the light propagation in a real environment and simulation of motor actions with appropriate tracking. Perception principles have subsequently been incorporated into rendering algorithms in order to save rendering computation and produce photorealistic images from a human rather than a machine point of view. With virtual environment (VE) simulator technologies simulating real-world task situations mainly for transfer of training, the research community is challenged to produce a complex system. Furthermore, accurate simulation of physics is often not required in order to induce reality. Much less detail is adequate. This paper is going to review research literature exploring behavioral fidelity and reality benchmarking in interactive VEs focusing on results from two studies aiming to simulate perceptual processes. Study 1 investigates spatial awareness based on merging episodic information with spatial preconceptions and Study 2 looks at subjective impressions of illumination.","1062-922X","0-7803-8566-7","10.1109/ICSMC.2004.1400752","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1400752","","Virtual environment;Computational modeling;Solid modeling;Computer simulation;Physics;Rendering (computer graphics);Computer graphics;Computational geometry;Optical propagation;Humans","virtual reality;computer vision;large-scale systems;visual perception;human factors;digital simulation","interactive virtual environments;perception simulation;computer graphics algorithms;geometry simulation;light propagation simulation;photorealistic images;virtual environment simulator technologies;complex system;episodic information;spatial preconceptions;behavioral fidelity;reality benchmarking","","1","","29","","7 Mar 2005","","","IEEE","IEEE Conferences"
"Incision Sensor Using Conductive Tape for Cricothyrotomy Training Simulation With Quantitative Feedback","B. Ahn; W. Choi; M. P. Ottensmeyer; H. Jung","Robotics Research and Development Group, Korea Institute of Industrial Technology, Ansan-si, South Korea; Robotics Research and Development Group, Korea Institute of Industrial Technology, Ansan-si, South Korea; Department of Radiology, Medical Device and Simulation Laboratory, Massachusetts General Hospital, Cambridge, MA, USA; Department of Mechanical Engineering, Konkuk University, Seoul, South Korea","IEEE Access","5 Feb 2019","2019","7","","12947","12958","Cricothyrotomy procedures, involving risky incisions on the neck skin and internal membranes, require rigorous training. In this paper, a novel incision sensor measuring the incision path in a cricothyrotomy training simulation is proposed. The sensor provides quantitative feedback to trainees on their incision practice, enhancing the effectiveness of the simulation. The sensor measures the electric potential, which decreases monotonically along the direction of current flow on the conductive material at the incision point, and converts it to coordinate values, based on the relationship between the electric potential and the position. The sensor comprises three layers of conductive tape, which are electrically isolated by two dielectric layers, and is fabricated as a thin film. The first two conductive layers (driving layers) are alternately energized to create distributions of electric potential in the x or y directions across the sensor plane. The third conductive layer (sensing layer), placed under the driving layers, transfers the electric potential to the output channel of the sensor at the point where a metal blade creates a short circuit between the energized driving layer and the sensing layer. The alternating measurements are converted to x and y coordinates of the incision position. The experiments for characterization and performance validation were performed using sensor prototypes fabricated with the proposed design and fabrication procedures. The experimental results show that the proposed sensor facilitates the measurement of the incision paths aligned with and diagonal to the x andy axes within root mean square errors of 0.98 and 1.03 mm, respectively.","2169-3536","","10.1109/ACCESS.2019.2891958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8607980","Conductive tape;cricothyrotomy simulation;incision sensor;medical simulation","Electric potential;Training;Skin;Robot sensing systems;Electrodes;Coordinate measuring machines","biological techniques;biomedical transducers;blades;computerised instrumentation;conducting materials;dielectric materials;electric potential;electric variables measurement;mean square error methods;medical computing;membranes;thin film sensors","conductive tape;cricothyrotomy training simulation;quantitative feedback;cricothyrotomy procedures;conductive material;dielectric layers;conductive layer;sensing layer;energized driving layer;electric potential measurement;incision sensor;membranes;incision path measurement;thin film fabrication;electric potential distribution;metal blade;root mean square errors","","1","","28","","10 Jan 2019","","","IEEE","IEEE Journals"
"A Tangible Interface for Learning Recursion and Functional Programming","J. D. T. Vidarte; C. Rinderknecht; J. Kim; H. Kim","Dept. of Adv. Technol. Fusion, Konkuk Univ., Seoul, South Korea; Dept. of Internet & Multimedia Eng., Konkuk Univ., Seoul, South Korea; Dept. of Internet & Multimedia Eng., Konkuk Univ., Seoul, South Korea; Dept. of Internet & Multimedia Eng., Konkuk Univ., Seoul, South Korea","2010 International Symposium on Ubiquitous Virtual Reality","26 Aug 2010","2010","","","32","35","Recursion is a powerful programming technique which is notoriously difficult to master, especially in functional languages because they prominently feature structural recursion as the main control-flow mechanism. We propose several hypotheses to understand the issue and put some to the test by designing an open-source interactive interface based on a tangible block-world with augmented reality and software feedback. Stacks of blocks are used as an analogy for the list data structure, which enables the simplest form of structural recursion. After using this application, students are expected to transfer their training to directly write recursive programs in sequential Erlang, a purely functional language.","","978-1-4244-7702-9","10.1109/ISUVR.2010.18","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5557937","functional programming;tangible user interface;block world;augmented reality;software feedback","Augmented reality;Visualization;Programming profession;Multimedia communication;Training","augmented reality;data structures;functional programming;program control structures;public domain software;user interfaces","tangible interface;functional programming;control flow mechanism;open source interactive interface;tangible block world;augmented reality;software feedback;data structure;recursive programs;Erlang;sequential Erlang;functional language;structural recursion","","2","","23","","26 Aug 2010","","","IEEE","IEEE Conferences"
"A Heuristic Force Model for Haptic Simulation of Nasogastric Tube Insertion Using Fuzzy Logic","K. Choi; X. He; V. C. L. Chiang; Z. Deng; J. Qin","Centre for Smart Health, School of Nursing, Hong Kong Polytechnic University, Hung Hom, Hong Kong; Centre for Smart Health, School of Nursing, Hong Kong Polytechnic University, Hung Hom, Hong Kong; Centre for Smart Health, School of Nursing, Hong Kong Polytechnic University, Hung Hom, Hong Kong; School of Digital Media, Jiangnan University, Wuxi, China; Centre for Smart Health, School of Nursing, Hong Kong Polytechnic University, Hung Hom, Hong Kong","IEEE Transactions on Haptics","19 May 2017","2016","9","3","295","310","Nasogastric tube (NGT) placement is an essential clinical skill. The training is conventionally performed on rubber mannequins albeit practical limitations. Computer simulation with haptic feedback can potentially offer a more realistic and accessible training method. However, the complex interactions between the tube and the nasogastric passage make it difficult to model the haptic feedback during NGT placement. In this paper, a fuzzy-logic-based approach is proposed to directly transfer the experience of clinicians in NGT placement into the simulation system. Based on their perception of the varying tactile sensation and the conditions during NGT placement, the membership functions and fuzzy rules are defined to develop the force model. Forces created using the model are then combined with friction forces to drive the haptic device and render the insertion forces in real time. A prototype simulator is developed based on the proposed force model and the implementation details are presented. The usability of the prototype is also evaluated by clinical teachers. The proposed methodology has the potential for developing computerized NGT placement training methods for clinical education. It is also applicable for simulation systems involving complicated force interactions or computation-expensive models.","2329-4051","","10.1109/TOH.2016.2550044","SAR; Polytechnic University; Outstanding Youth Fund of the Jiangsu Province; Scholarship of Centre for Smart Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7448448","Fuzzy logic;force modeling;nasogastric tube intubation;haptic rendering","Force;Computational modeling;Haptic interfaces;Electron tubes;Training;Real-time systems;Finite element analysis","feedback;fuzzy logic;medical computing","heuristic force model;haptic simulation;nasogastric tube insertion;rubber mannequins albeit practical limitations;computer simulation;haptic feedback;realistic training method;complex interactions;nasogastric passage;fuzzy-logic-based approach;tactile sensation;fuzzy rules;friction forces;haptic device;insertion forces;prototype simulator;clinical teachers;computerized NGT placement;clinical education;training methods;complicated force interactions;computation-expensive models","Clinical Competence;Computer Simulation;Feedback;Friction;Fuzzy Logic;Heuristics;Humans;Intubation, Gastrointestinal;Mechanical Phenomena;Preceptorship;Touch;User-Computer Interface","1","","50","","6 Apr 2016","","","IEEE","IEEE Journals"
"Virtual Reality as Cost Effective Tool for Distance Healthcare","R. Papara; R. Galatus; L. Buzura","Technical University of Cluj-Napoca,Memorandumului 28th, Cluj-Napoca,Romania; Technical University of Cluj-Napoca,Memorandumului 28th, Cluj-Napoca,Romania; Technical University of Cluj-Napoca,Memorandumului 28th, Cluj-Napoca,Romania","2020 22nd International Conference on Transparent Optical Networks (ICTON)","22 Sep 2020","2020","","","1","6","VR can provide a rich, interactive environment in distance assisted actions for serious games in healthcare. The location-based decisions can be transferred for distance-based assisted decisions, when the specialists cannot be present in time at the probe/case location. The specialists can consult at distance, a probe in the real lab, by using images that are taken with high resolution cameras and that are sent over the internet. In advanced healthcare the virtual environment is conducted by a surgeon and decision is transmitted to a robotic instrument that mimics the actions. In this case the cost effective solution refers to regular healthcare activity such as visual assisted diagnosis in real time, training of the specialists, assessing a situation and give an expert opinion on it, future actions and treatment. The advancement in technology allowed VR systems to run on personal computers thus decreasing the implementation cost for a sophisticated system. In the present implementation, a cost-effective solution is presented. The solution is easy to use by the medical specialists and is helpful to compensate the time-delay for the doctor mobility at the probe/case location. A user-friendly interface was developed in order to facilitate the communication between a specialist in the lab and the expert at distance, using the immersive technology of VR, in order to replicates an environment via computer-simulated reality.","2161-2064","978-1-7281-8423-4","10.1109/ICTON51198.2020.9203420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9203420","virtual reality;interface for communication;camera distance-assisted diagnosis;smartphone assisted;real time transmission;healthcare","Medical services;Glass;Webcams;Software;Probes;Robots","health care;Internet;virtual reality","virtual reality;cost effective tool;distance healthcare;interactive environment;distance assisted actions;serious games;location-based decisions;distance-based assisted decisions;high resolution cameras;virtual environment;surgeon;robotic instrument;regular healthcare activity;visual assisted diagnosis;VR systems;implementation cost;cost-effective solution;time-delay;computer-simulated reality","","","","11","","22 Sep 2020","","","IEEE","IEEE Conferences"
"Teaching a Robot to Grasp Real Fish by Imitation Learning from a Human Supervisor in Virtual Reality","J. S. Dyrstad; E. Ruud Øye; A. Stahl; J. Reidar Mathiassen","SINTEF Ocean AS, Trondheim, Norway; SINTEF Ocean AS, Trondheim, Norway; Department of Engineering Cybernetics, NTNU, Trondheim, Norway; SINTEF Ocean AS, Trondheim, Norway","2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","6 Jan 2019","2018","","","7185","7192","We teach a real robot to grasp real fish, by training a virtual robot exclusively in virtual reality. Our approach implements robot imitation learning from a human supervisor in virtual reality. A deep 3D convolutional neural network computes grasps from a 3D occupancy grid obtained from depth imaging at multiple viewpoints. In virtual reality, a human supervisor can easily and intuitively demonstrate examples of how to grasp an object, such as a fish. From a few dozen of these demonstrations, we use domain randomization to generate a large synthetic training data set consisting of 100 000 example grasps of fish. Using this data set for training purposes, the network is able to guide a real robot and gripper to grasp real fish with good success rates. The newly proposed domain randomization approach constitutes the first step in how to efficiently perform robot imitation learning from a human supervisor in virtual reality in a way that transfers well to the real world.","2153-0866","978-1-5386-8094-0","10.1109/IROS.2018.8593954","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8593954","","Robots;Task analysis;Three-dimensional displays;Grippers;Grasping;Cameras;Virtual reality","convolutional neural nets;grippers;learning (artificial intelligence);mobile robots;pose estimation;virtual reality","teaching;gripper;domain randomization approach;depth imaging;3D occupancy grid;robot imitation learning;deep 3D convolutional neural network;virtual robot;grasp real fish;virtual reality;human supervisor","","2","","19","","6 Jan 2019","","","IEEE","IEEE Conferences"
"Monitoring rehabilitation training for hemiplegic patients by using a tri-axial accelerometer","Y. Higashi; M. Sekimoto; F. Horiuchi; T. Kodama; T. Yuji; T. Fujimoto; M. Sekine; T. Tamura","Fujimoto Hayasuzu Hosp., Miyazaki, Japan; Fujimoto Hayasuzu Hosp., Miyazaki, Japan; Fujimoto Hayasuzu Hosp., Miyazaki, Japan; Fujimoto Hayasuzu Hosp., Miyazaki, Japan; Fujimoto Hayasuzu Hosp., Miyazaki, Japan; Fujimoto Hayasuzu Hosp., Miyazaki, Japan; NA; NA","2001 Conference Proceedings of the 23rd Annual International Conference of the IEEE Engineering in Medicine and Biology Society","7 Nov 2002","2001","2","","1472","1474 vol.2","In rehabilitation training for hemiplegic patients, bed-to-wheelchair transfer is most important and allows a patient's early independence. We developed a monitoring system for transfer training that is quantitative and uses accelerometry. Two tri-axial accelerometers were attached to the subjects, at the head and waist. Subjects were trained in moving from a sitting position to standing, then turning through, about 90 degrees, and then sitting on the bed. The acceleration signals at the two sites were recorded via a multi-telemeter system, converted to a digital signal, and stored in a computer. Data were analysed by LabView and displayed on the computer screen as real time motion. The system can be operated by one staff member, and the patients did not feel restricted. We were able to evaluate the time course of the signals, and phase-plane locus of the vertical, lateral and horizontal directions of the signals. The transfer of hemiplegic patients occurred in two motions: a standing-up motion, and a sitting-down motion. Accordingly, we observed twin peaks in the plot of the original signal. In contrast, healthy volunteers moved smoothly and twin peaks were not present.","1094-687X","0-7803-7211-5","10.1109/IEMBS.2001.1020482","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1020482","","Patient monitoring;Accelerometers;Acceleration;Data analysis;Charge coupled devices;Charge-coupled image sensors;Transmitters;Microcomputers;Computer displays;Telemetry","patient rehabilitation;patient monitoring;accelerometers;biomedical telemetry;data analysis;medical computing;training","rehabilitation training;hemiplegic patients;tri-axial accelerometer;bed-to-wheelchair transfer;patient independence;monitoring system;sitting position;standing;turning;acceleration signals;multi-telemeter system;LabView;real time motion;CCD camera;time course evaluation;phase-plane locus","","1","","2","","7 Nov 2002","","","IEEE","IEEE Conferences"
"Perceptual Rendering for Learning Haptic Skills","T. Edmunds; D. K. Pai","Rutgers University, e-mail: tedmunds@cs.rutgers.edu; University of British Columbia, Rutgers University, e-mail: pai@cs.ubc.ca","2008 Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems","31 Mar 2008","2008","","","225","230","We approach the problem of creating haptic simulators that effectively impart skill without requiring high-fidelity devices by identifying perceptually salient events that signal transitions in the interaction. By augmenting these events, we seek to overcome deficiencies in the fidelity of the rendering hardware. We present an extension of event-based haptic rendering to non- collision events, and we describe a user-study of the training effectiveness of passive force-field haptic simulation vs. active event- augmented simulation in a tool-manipulation task. The results indicate that active augmentation improves skill transfer without requiring an increase in the quality of the rendering device.","2324-7355","978-1-4244-2005-6","10.1109/HAPTICS.2008.4479948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4479948","","Haptic interfaces;Discrete event simulation;Bones;Hardware;Humans;Feedback;Surgery;Surges;Signal processing;Shape","computer graphic equipment;haptic interfaces;learning (artificial intelligence);manipulators;rendering (computer graphics);virtual reality","perceptual rendering hardware;haptic skill learning;signal transitions;event-based haptic rendering;noncollision events;training;passive force-field haptic simulation;event-augmented simulation;tool-manipulation task","","9","","18","","31 Mar 2008","","","IEEE","IEEE Conferences"
"Maintenance of Complex Machines in Electric Power Systems Using Virtual Reality Techniques","B. Arendarski; W. Termath; P. Mecking","Fraunhofer Institute for Factory Operation and Automation (IFF), Sandtorstrasse 22, 39106 Magdeburg, Germany. bartlomiej.arendarski@iff.fraunhofer.de; Fraunhofer Institute for Factory Operation and Automation (IFF), Sandtorstrasse 22, 39106 Magdeburg, Germany; RWE Rhein-Ruhr-Netzservice GmbH, Reeser Landstrasse 41, 46483 Wesel, Germany","Conference Record of the 2008 IEEE International Symposium on Electrical Insulation","18 Jul 2008","2008","","","483","487","This paper illustrates how virtual reality (VR) techniques can be used in electric power systems visualization and how this can increase effectiveness of vocational training in field of power industry. The content of this article is based on a project oriented to specialized staff members, dealing with maintenance, repairs and diagnostics of complex machines such transformers and generators. Introducing a scheme that integrates VR technologies to electrical machines and equipment provides an efficient tool for implementing operator training methods. Three-dimensional (3D) visualization brings a new ways of knowledge transfer and education regarding complex equipment.","1089-084X","978-1-4244-2091-9","10.1109/ELINSL.2008.4570378","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4570378","","Virtual reality;Vocational training;Industrial training;Visualization;Transformers;Power system planning;Design engineering;Computational modeling;Testing;Power system modeling","electric generators;power systems;transformers;virtual reality","electric power systems;virtual reality;complex machines maintenance;power industry;transformers;generators;3D visualization","","17","","10","","18 Jul 2008","","","IEEE","IEEE Conferences"
"Short Video Datasets Show Potential for Outfits in Augmented Reality","A. Jong; T. -S. Moh","San José State University,Department of Computer Science,San José,CA; San José State University,Department of Computer Science,San José,CA","2019 International Conference on High Performance Computing & Simulation (HPCS)","9 Sep 2020","2019","","","201","208","We investigate the usage of short video datasets in place of large image datasets for outfit transfer. We replicate the warp stage of prior work, SwapNet, while swapping out the 800K-image DeepFashion dataset for two 5-minute videos. By successfully training the warp stage on video, we show that the previously proposed transfer technique for images has potential to apply to subjects in motion. In addition, specifically for video applications, we show the model need not be trained on a comprehensive dataset; instead the model only needs videos for the source outfit and target subject. Our results show promise for the usage of video datasets in future work to achieve fully-textured outfit transfer. We expect the implications of convenient-to-collect video datasets to appeal to small companies that lack resources to collect and annotate big data. If combined with high performance computing, faster training times in the cloud could lead to frictionless user experiences.","","978-1-7281-4484-9","10.1109/HPCS48598.2019.9188236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9188236","virtual try-on;clothing outfit transfer;image-to-image translation;generative video","Clothing;Training;Image segmentation;Gallium nitride;Generative adversarial networks;Generators;Companies","augmented reality;Big Data;image recognition;learning (artificial intelligence);video signal processing","short video datasets;image datasets;warp stage;800K-image DeepFashion dataset;video applications;convenient-to-collect video dataset","","","","20","","9 Sep 2020","","","IEEE","IEEE Conferences"
"Changes in Subjective Understanding of an Accident and Risk Awareness in First-Year Nursing Students Following Medical Accident Simulation-Based Experimental Learning","T. Yoneda; K. Itami; O. Yasuhara; K. Seki; Y. Kawabata; T. Maesako; L. Zhe","Sch. of Human Nursing, Univ. of Shiga Prefecture, Hikone, Japan; Sch. of Human Nursing, Univ. of Shiga Prefecture, Hikone, Japan; Sch. of Human Nursing, Univ. of Shiga Prefecture, Hikone, Japan; Sch. of Human Nursing, Univ. of Shiga Prefecture, Hikone, Japan; Sch. of Human Nursing, Univ. of Shiga Prefecture, Hikone, Japan; Sch. of Human Sci., Osaka Univ., Suita, Japan; Sch. of Human Sci., Osaka Univ., Suita, Japan","2017 International Conference of Educational Innovation through Technology (EITT)","12 Mar 2018","2017","","","159","164","Novice nurses with little professional experience tend to feature frequently in reported medical accidents and near-miss incidents in Japanese healthcare facilities. According to our previous survey, approximately 40% to 70% of nursing students experience near-miss incidents during their clinical training. Many of these incidents in nursing settings occur while providing assistance for wheelchair transfer or bathing. Fostering observational skills to enable accurate risk area identification is a requirement from the stage of basic education for the provision of safe medical care to patients. In the present study, we devised and implemented experimental learning aimed at first-year nursing students that incorporated medical accident reenactments and simulations using simulated patients. The results showed significant post-learning increases in both subjective understanding and the frequency of risk area identification, suggesting that experimental learning improves nursing student comprehension and skill in responding to perceived risks.","","978-1-5386-0629-2","10.1109/EITT.2017.46","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8308531","risk awareness;simulation-based training;experimental learning;medical safety training;nursing students","Accidents;Medical services;Biomedical imaging;Wheelchairs;Training;Safety","biomedical education;computer aided instruction;health care;medical computing;patient care;patient monitoring","professional experience;reported medical accidents;Japanese healthcare facilities;wheelchair transfer;accurate risk area identification;safe medical care;experimental learning;medical accident reenactments;simulated patients;subjective understanding;nursing student comprehension;perceived risks;medical accident simulation;nursing student experience","","","","15","","12 Mar 2018","","","IEEE","IEEE Conferences"
"ECG-Based Virtual Pathology Stethoscope Tracking Using Transfer Learning","H. Yhdego; N. Kidane; F. Mckenzie; M. Audette","Old Dominion University,Norfolk,VA,USA; Old Dominion University,Norfolk,VA,USA; Old Dominion University,Norfolk,VA,USA; Old Dominion University,Norfolk,VA,USA","2020 Spring Simulation Conference (SpringSim)","3 Sep 2020","2020","","","1","7","Standardized Patient (SP) based medical simulation is commonly used to teach bedside skills. However, SPs are typically healthy individuals, and the number and range of conditions they can portray are limited. Our research aims to improve the cardiac auscultation (CA) skills of medical students by utilizing a modified stethoscope in tandem with SP. This technology introduces the potential to augment virtual pathology sounds on otherwise healthy SP. In this study, CNN models, previously trained on large-scale image datasets, are transferred to identify the four CA sites. We applied the pre-trained CNN models of ResNet50, InceptionV3, and Alexnet, to the ECG recordings from the CA regions, which are converted to images using a wavelet scalogram. Moreover, data augmentation is performed to supplement limited labeled data. Experimental results illustrate data augmentation with InceptionV3 and Resnet50 models leads to a better performance than our previously reported methods, between 93% and 95% F1 score.","","978-1-56555-370-5","10.22360/SpringSim.2020.MSM.009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9185471","ECG;Transfer Learning;Clinical Simulation;Auscultation;Stethoscope Tracking","Electrocardiography;Stethoscope;Feature extraction;Medical diagnostic imaging;Continuous wavelet transforms;Computer architecture","bioacoustics;biomedical education;convolutional neural nets;electrocardiography;learning (artificial intelligence);medical computing;medical signal processing;teaching","wavelet scalogram;Alexnet;standardized patient based medical simulation;Resnet50;data augmentation;ECG recordings;InceptionV3;pretrained CNN models;large-scale image datasets;virtual pathology sounds;modified stethoscope;medical students;cardiac auscultation skills;bedside skills;transfer learning;ECG-based virtual pathology stethoscope tracking","","","","15","","3 Sep 2020","","","IEEE","IEEE Conferences"
"A Deep Cybersickness Predictor Based on Brain Signal Analysis for Virtual Reality Contents","J. Kim; W. Kim; H. Oh; S. Lee; S. Lee",Yonsei University; Yonsei University; Electronics & Telecommunications Research Institute; Yonsei University; Yonsei University. Korea,"2019 IEEE/CVF International Conference on Computer Vision (ICCV)","27 Feb 2020","2019","","","10579","10588","What if we could interpret the cognitive state of a user while experiencing a virtual reality (VR) and estimate the cognitive state from a visual stimulus? In this paper, we address the above question by developing an electroencephalography (EEG) driven VR cybersickness prediction model. The EEG data has been widely utilized to learn the cognitive representation of brain activity. In the first stage, to fully exploit the advantages of the EEG data, it is transformed into the multi-channel spectrogram which enables to account for the correlation of spectral and temporal coefficient. Then, a convolutional neural network (CNN) is applied to encode the cognitive representation of the EEG spectrogram. In the second stage, we train a cybersickness prediction model on the VR video sequence by designing a Recurrent Neural Network (RNN). Here, the encoded cognitive representation is transferred to the model to train the visual and cognitive features for cybersickness prediction. Through the proposed framework, it is possible to predict the cybersickness level that reflects brain activity automatically. We use 8-channels EEG data to record brain activity while more than 200 subjects experience 44 different VR contents. After rigorous training, we demonstrate that the proposed framework reliably estimates cognitive states without the EEG data. Furthermore, it achieves state-of-the-art performance comparing to existing VR cybersickness prediction models.","2380-7504","978-1-7281-4803-8","10.1109/ICCV.2019.01068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9010856","","Electroencephalography;Brain modeling;Spectrogram;Visualization;Predictive models;Solid modeling;Feature extraction","cognition;convolutional neural nets;electroencephalography;image sequences;medical image processing;recurrent neural nets;video signal processing;virtual reality","VR video sequence;recurrent neural network;cognitive representation;visual features;cognitive features;cybersickness level;brain activity;8-channels EEG data;cognitive state;deep cybersickness predictor;brain signal analysis;virtual reality contents;visual stimulus;VR cybersickness prediction model;multichannel spectrogram;spectral coefficient;temporal coefficient;convolutional neural network;electroencephalography;EEG spectrogram","","7","","32","","27 Feb 2020","","","IEEE","IEEE Conferences"
"Transfer from a simulation environment to a live robotic environment: Are certain demographics better?","P. L. McDermott; A. Fisher; T. Carolan; M. R. Gronowski; M. Gacy; M. Overstreet","Alion Science and Technology 4949 Pearl East Circle, Suite 200; Alion Science and Technology 4949 Pearl East Circle, Suite 200; Alion Science and Technology 4949 Pearl East Circle, Suite 200; Alion Science and Technology 4949 Pearl East Circle, Suite 200; Alion Science and Technology 4949 Pearl East Circle, Suite 200; Alion Science and Technology 4949 Pearl East Circle, Suite 200","2012 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","30 Jul 2012","2012","","","191","192","The ability to remotely operate an unmanned vehicle while simultaneously looking for suspicious targets and then classifying those targets is not a trivial skill. This study looked at different training approaches to make better use of simulation as a first training step. When transferring to a live environment, the operators could be grouped into two categories according to whether they passed live training criteria or not. There were clear performance differences between these groups. The group that failed to pass criteria had poorer performance overall, more SA errors, and spent more time in training. Post-hoc analysis showed differences in the demographics between those who passed and those that did not. Male participants and younger participants were more likely to achieve criteria. There were no differences in gaming experience and perceived sense of direction.","2167-2148","978-1-4503-1063-5","10.1145/2157689.2157750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249521","Situation awareness;learning curves;demographics;sense of direction;teleoperation","Training;Robot sensing systems;USA Councils;Human factors;Land vehicles","digital simulation;remotely operated vehicles;telerobotics","simulation environment;live robotic environment;remote operation;unmanned vehicle;suspicious targets;target classification;live training criteria;post-hoc analysis;demographics;male participants;younger participants;gaming experience;perceived direction sense","","","","4","","30 Jul 2012","","","IEEE","IEEE Conferences"
"Assistive VR Gym: Interactions with Real People to Improve Virtual Assistive Robots","Z. Erickson; Y. Gu; C. C. Kemp","Georgia Institute of Technology,Health-care Robotics Lab,Atlanta,GA,USA; Georgia Institute of Technology,Health-care Robotics Lab,Atlanta,GA,USA; Georgia Institute of Technology,Health-care Robotics Lab,Atlanta,GA,USA","2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)","14 Oct 2020","2020","","","299","306","Versatile robotic caregivers could benefit millions of people worldwide, including older adults and people with disabilities. Recent work has explored how robotic caregivers can learn to interact with people through physics simulations, yet transferring what has been learned to real robots remains challenging. Virtual reality (VR) has the potential to help bridge the gap between simulations and the real world. We present Assistive VR Gym (AVR Gym), which enables real people to interact with virtual assistive robots. We also provide evidence that AVR Gym can help researchers improve the performance of simulation-trained assistive robots with real people. Prior to AVR Gym, we trained robot control policies (Original Policies) solely in simulation for four robotic caregiving tasks (robot-assisted feeding, drinking, itch scratching, and bed bathing) with two simulated robots (PR2 from Willow Garage and Jaco from Kinova). With AVR Gym, we developed Revised Policies based on insights gained from testing the Original policies with real people. Through a formal study with eight participants in AVR Gym, we found that the Original policies performed poorly, the Revised policies performed significantly better, and that improvements to the biomechanical models used to train the Revised policies resulted in simulated people that better match real participants. Notably, participants significantly dis-agreed that the Original policies were successful at assistance, but significantly agreed that the Revised policies were successful at assistance. Overall, our results suggest that VR can be used to improve the performance of simulation-trained control policies with real people without putting people at risk, thereby serving as a valuable stepping stone to real robotic assistance.","1944-9437","978-1-7281-6075-7","10.1109/RO-MAN47096.2020.9223609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9223609","","","biomechanics;geriatrics;handicapped aids;humanoid robots;learning (artificial intelligence);medical computing;medical robotics;mobile robots;virtual reality","simulated robots;simulated people;simulation-trained control policies;robotic assistance;virtual assistive robots;versatile robotic caregivers;physics simulations;simulation-trained assistive robots;robot control policies;robotic caregiving tasks;drinking;assistive VR gym;revised policies;AVR gym","","","","48","","14 Oct 2020","","","IEEE","IEEE Conferences"
"Design of Novel Teaching Episodes in Medical Education Using Emerging Experiential Digital Assets: Technology Enabled Medical Education Beyond the Gimmicky","P. E. Antoniou; E. Dafli; P. D. Bamidis","Med. Phys. Lab., Univ. of Thessaloniki Thessaloniki, Thessaloniki, Greece; Med. Phys. Lab., Univ. of Thessaloniki Thessaloniki, Thessaloniki, Greece; Med. Phys. Lab., Univ. of Thessaloniki Thessaloniki, Thessaloniki, Greece","2015 IEEE International Conference on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; Pervasive Intelligence and Computing","28 Dec 2015","2015","","","1560","1565","Medical education has always been about experiential hands on training to prepare future doctors to create the necessary skillset to deal with the sensitive and immediate nature of their work. Contemporary experiential technologies such as Virtual and Augmented reality offer a realistic but consequence free test-bed in which to interact safely and cope with emotional challenges pertaining to the realistic tasks simulated through these media. This work describes the design guidelines and workflow for incorporating these novel virtual assets in medical education through serious role play learning episodes. This approach consists of the case selection, the identification of roles, information flow and narrative requirements, implementation of technological narrative tools and implementation of the learning episode. Using a specific example of case transfer through this model we describe the process, outline implementation, assessment and technological considerations. Finally rationale for this work as a counterweight to technological hype fluctuations and integration of these media into the mainstream curricula is discussed.","","978-1-5090-0154-5","10.1109/CIT/IUCC/DASC/PICOM.2015.360","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7363280","Autgmented Reality;Virtual Reality;Serious Role","Medical services;Context;Training;Solid modeling;Virtual reality;Biomedical monitoring","augmented reality;biomedical education;medical computing","narrative tool;information flow;consequence free test-bed;augmented reality;virtual reality;contemporary experiential technology;gimmicky;experiential digital asset;medical education","","3","","28","","28 Dec 2015","","","IEEE","IEEE Conferences"
"Neural network training using ant algorithm in ATM traffic control","Zhangsu-Bing; Liu Ze-Min","Beijing Univ. of Posts & Telecommun., China; NA","ISCAS 2001. The 2001 IEEE International Symposium on Circuits and Systems (Cat. No.01CH37196)","7 Aug 2002","2001","3","","157","160 vol. 2","To maintain the QoS using the traditional mathematical approaches to build an efficient network traffic controller in ATM traffic control is a difficult task. The advantage of using NNs is that the QoS can be accurately estimated without detailed user action models or knowledge about the switching system architecture. The disadvantage is that it will take longer time to train with ATM network changes. In this paper, we use an algorithm in neural network weights training for ATM Call Admission Control (CAC) and Usage Parameter Control (UPC). The simulation results show that this approach is efficient and feasible.","","0-7803-6685-9","10.1109/ISCAS.2001.921270","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=921270","","Neural networks;Intelligent networks;Traffic control;Asynchronous transfer mode;Communication system traffic control;Heuristic algorithms;Telecommunication control;Switching systems;Intserv networks;Packet switching","digital simulation;asynchronous transfer mode;telecommunication congestion control;neural nets;learning (artificial intelligence);digital communication;B-ISDN","neural network training;ATM traffic control;QoS;network traffic controller;user action models;Call Admission Control;Usage Parameter Control;simulation","","2","","11","","7 Aug 2002","","","IEEE","IEEE Conferences"
"Sport-specific virtual reality to identify profiles of anterior cruciate ligament injury risk during unanticipated cutting","A. W. Kiefer; C. DiCesare; S. Bonnette; K. Kitchen; B. Gadd; S. Thomas; K. D. Barber Foss; G. D. Myer; M. A. Riley; P. Silva","Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Department of Psychology, Center for Cognition, Action, & Perception, University of Cincinnati, OH USA; Department of Psychology, Center for Cognition, Action, & Perception, University of Cincinnati, OH USA","2017 International Conference on Virtual Rehabilitation (ICVR)","14 Aug 2017","2017","","","1","8","Female athletes are at an increased risk of anterior cruciate ligament (ACL) injury in competitive sport during running, jumping and cutting tasks. This risk is due to deficits in posterior chain and hip recruitment associated with aberrant frontal knee loads. The identification of these risk factors has led to targeted neuromuscular training (NMT) interventions to enhance hip neuromuscular control during such tasks. Despite the successful modification of ACL injury risk factors following NMT, the transfer of these corrected movement patterns to the sport-specific contexts has not been directly evaluated. Sport-specific virtual reality (VR) may provide the best method to measure training transfer to realistic sport performance, while still allowing appropriate experimental control and high-fidelity performance measurements. The current study examined the effect of a biofeedback-driven augmented NMT (aNMT) on skill transfer of ACL-injury resistant movement patterns during performance of sport-specific VR scenarios. Five trained athletes participated, and their performance on an unanticipated cutting task was assessed in VR prior to and after six weeks of aNMT. A significant 87% reduction in internal hip rotation was observed on the plant leg during the loading phase of cutting (p = .05), along with an observed 116% reduction during the push-off phase (p = .02), from pre- to post-training. A non-significant trend of a 19% reduction in knee abduction was also observed (p = .15). This study is the first that has utilized free ambulatory wireless VR to assess injury risk in athletes during performance of sport-specific tasks. The reduction in internal hip rotation and knee abduction align with previous findings on laboratory based tests. The current results are the first step in the validation of sport-specific VR as a tool for understanding injury risk during simulation of real-world sport performance.","2331-9569","978-1-5090-3053-8","10.1109/ICVR.2017.8007511","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007511","anterior cruciate ligament;virtual reality;sport;cutting;soccer","Injuries;Hip;Training;Neuromuscular;Biomechanics;Knee;Virtual reality","biomechanics;injuries;medical computing;muscle;neurophysiology;patient rehabilitation;sport;virtual reality","sport-specific virtual reality;anterior cruciate ligament injury risk;unanticipated cutting;female athletes;posterior chain;hip recruitment;aberrant frontal knee loads;neuromuscular training;biofeedback-driven augmented NMT;hip neuromuscular control;corrected movement patterns;sport-specific contexts;realistic sport performance;ACL-injury resistant movement patterns;push-off phase;free ambulatory wireless VR;internal hip rotation;knee abduction","","1","","62","","14 Aug 2017","","","IEEE","IEEE Conferences"
"SSVEP Stimulus Layout Effect on Accuracy of Brain-Computer Interfaces in Augmented Reality Glasses","X. Zhao; C. Liu; Z. Xu; L. Zhang; R. Zhang","School of Information Engineering, Zhengzhou University, Zhengzhou, China; School of Information Engineering, Zhengzhou University, Zhengzhou, China; Henan Key Laboratory of Brain Science and Brain–Computer Interface Technology, School of Electrical Engineering, Zhengzhou University, Zhengzhou, China; Henan Key Laboratory of Brain Science and Brain–Computer Interface Technology, School of Electrical Engineering, Zhengzhou University, Zhengzhou, China; Henan Key Laboratory of Brain Science and Brain–Computer Interface Technology, School of Electrical Engineering, Zhengzhou University, Zhengzhou, China","IEEE Access","13 Jan 2020","2020","8","","5990","5998","Steady-state visual evoked potentials-based brain-computer interfaces (SSVEP-BCI) has the advantage of high information transfer rate (ITR) and little user training, and it has a high application value in the field of disability assistance and human-computer interaction. Generally SSVEP-BCI requires a personal computer screen (PC) to display several repetitive visual stimuli for inducing the SSVEP response, which reduces its portability and flexibility. Using augmented reality (AR) glasses worn on the head to display the repetitive visual stimuli could solve the above drawbacks, but whether it could achieve the same accuracy as PC screen in the case of reduced brightness and increased interference is unknown. In current study, we firstly designed 4 stimulus layouts and displayed them with Microsoft HoloLens (AR-SSVEP) glasses, comparison analysis showed that the classification accuracies are influenced by the stimulus layout when the stimulus duration is less than 3s. When the stimulus duration exceeds 3s, there is no significant accuracy difference between the 4 layouts. Then we designed a similar experimental paradigm on PC screen (PC-SSVEP) based on the best layout of AR. Classification results showed that AR-SSVEP achieved similar accuracy with PC-SSVEP when the stimulus duration is more than 3s, but when the stimulus duration is less than 2s, the accuracy of AR-SSVEP is lower than PC-SSVEP. Brain topological analysis indicated that the spatial distribution of SSVEP responses is similar, both of which are strongest in the occipital region. Current study indicated that stimulus layout is a key factor when building SSVEP-BCI with AR glasses, especially when the stimulation time is short.","2169-3536","","10.1109/ACCESS.2019.2963442","National Natural Science Foundation of China; Key Project at Central Government Level; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8947980","Steady-state visual evoked potentials (SSVEP);brain–computer interfaces (BCI);augmented reality (AR);optical see-through (OST);human–computer interaction","Layout;Glass;Visualization;Electroencephalography;Correlation;Microsoft Windows;Brain-computer interfaces","augmented reality;brain;brain-computer interfaces;electroencephalography;glass;handicapped aids;medical signal processing;neurophysiology;visual evoked potentials","SSVEP stimulus layout effect;augmented reality glasses;steady-state visual evoked potentials-based brain-computer interfaces;high information transfer rate;high application value;disability assistance;human-computer interaction;personal computer screen;repetitive visual stimuli;SSVEP response;PC screen;classification accuracies;stimulus duration;significant accuracy difference;PC-SSVEP;AR-SSVEP achieved similar accuracy;brain topological analysis;building SSVEP-BCI;stimulus layouts;time 3.0 s;time 2.0 s","","","","45","CCBY","1 Jan 2020","","","IEEE","IEEE Journals"
"Effect of interface type in the VR-based acquisition of pedestrian skills in persons with ASD","M. Saiano; E. Garbarino; S. Lumachi; S. Solari; V. Sanguineti","Dept of Informatics, Bioengineering, Robotics and Systems Engineering, University of Genoa, Via all'Opera Pia 13, 16145, Italy; Dept. of Primary Care, ASL3 Genovese, Genoa, Italy; Philos Counseling Academy, Genoa, Italy; Dept. of Education Sciences, University of Genoa, Corso A. Podestá 2, Italy; Dept of Informatics, Bioengineering, Robotics and Systems Engineering, University of Genoa, Via all'Opera Pia 13, 16145, Italy","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","5 Nov 2015","2015","","","5728","5731","Possession of `social' skills is crucial for persons with autism spectrum disorders (ASD) to maintain a certain independence and a better quality of life, and interaction with virtual environments seems an effective learning aid. In a previous study, we reported that in adults with ASD interaction with a virtual environment (a virtual city) is beneficial to the acquisition of pedestrian skills (street crossing and street navigation). Interaction was based on a gesture-based interface (Microsoft Kinect). Here we compare the learning performance when the same virtual environment is operated by a gamepad interface. We used exactly the same training protocol and data analysis than the original study. We found that both interface types are effective in the acquisition of street crossing and city navigation skills. The gamepad interface seems easier to use (thus leading to faster interaction), but gesture-based interfaces are superior in terms of transfer of the learned skills to real road environments (as reported by parents and caregivers).","1558-4615","978-1-4244-9271-8","10.1109/EMBC.2015.7319693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7319693","","Nickel;Virtual environments;Training;Navigation;Autism;Protocols","computer games;data analysis;learning (artificial intelligence);medical diagnostic computing;medical disorders;virtual reality","interface type effect;VR-based acquisition;pedestrian skills;autism spectrum disorders;quality-of-life;virtual environments;effective learning aid;ASD interaction;street crossing;street navigation;gesture-based interface;Microsoft Kinect;learning performance;gamepad interface;training protocol;data analysis","Accidents, Traffic;Autism Spectrum Disorder;Humans;Pedestrians;Quality of Life;User-Computer Interface","3","","11","","5 Nov 2015","","","IEEE","IEEE Conferences"
"The wobbly table: Increased social presence via subtle incidental movement of a real-virtual table","M. Lee; K. Kim; S. Daher; A. Raij; R. Schubert; J. Bailenson; G. Welch",University of Central Florida; University of Central Florida; University of Central Florida; University of Central Florida; University of Central Florida and UNC-Chapel Hill; Stanford University; University of Central Florida,"2016 IEEE Virtual Reality (VR)","7 Jul 2016","2016","","","11","17","While performing everyday interactions, we often incidentally touch and move objects in subtle ways. These objects are not necessarily directly related to the task at hand, and the movement of an object might even be entirely unintentional. If another person is touching the object at the same time, the movement can transfer through the object and be experienced - however subtly - by the other person. For example, when one person hands a drink to another, at some point both individuals will be touching the glass, and consequently exerting small (often unnoticed) forces on the other person. Despite the frequency of such subtle incidental movements of shared objects in everyday interactions, few have examined how these movements affect human-virtual human (VH) interaction. We ran an experiment to assess how presence and social presence are affected when a person experiences subtle, incidental movement through a shared real-virtual object. We constructed a real-virtual room with a table that spanned the boundary between the real and virtual environments. The participant was seated on the real side of the table, which visually extended into the virtual world via a projection screen, and the VH was seated on the virtual side of the table. The two interacted by playing a game of “Twenty Questions,” where one player asked the other a series of 20 yes/no questions to deduce what object the other player was thinking about. During the game, the “wobbly” group of subjects experienced subtle incidental movements of the real-virtual table: the entire real-virtual table tilted slightly away/toward the subject when the virtual/real human leaned on it. The control group also played the same game, except the table did not wobble. Results indicate that the wobbly group had higher presence and social presence with the virtual human in general, with statistically significant increases in presence, co-presence, and attentional allocation. We present the experiment and results, and discuss some potential implications for virtual human systems and some potential future studies.","2375-5334","978-1-5090-0836-0","10.1109/VR.2016.7504683","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504683","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems — Artificial, Augmented and Virtual Realities;J.4 [Computer Applications]: Social and Behavioral Sciences — Psychology","Electronic mail;Measurement by laser beam;Virtual environments;Games;Training;Haptic interfaces;Force","human computer interaction;virtual reality","wobbly table;social presence;real-virtual table;subtle incidental movement;object movement;human-virtual human interaction;human-VH interaction;shared real-virtual object;real-virtual room;projection screen;virtual world;Twenty Questions game","","17","","42","","7 Jul 2016","","","IEEE","IEEE Conferences"
"Real-Time Evaluation and Visualization of Learner Performance in a Mixed-Reality Environment for Clinical Breast Examination","A. Kotranza; D. S. Lind; B. Lok","University of Florida, Gainesville; Medical College of Georgia, Augusta; University of Florida, Gainesville","IEEE Transactions on Visualization and Computer Graphics","16 May 2012","2012","18","7","1101","1114","We investigate the efficacy of incorporating real-time feedback of user performance within mixed-reality environments (MREs) for training real-world tasks with tightly coupled cognitive and psychomotor components. This paper presents an approach to providing real-time evaluation and visual feedback of learner performance in an MRE for training clinical breast examination (CBE). In a user study of experienced and novice CBE practitioners (n = 69), novices receiving real-time feedback performed equivalently or better than more experienced practitioners in the completeness and correctness of the exam. A second user study (n = 8) followed novices through repeated practice of CBE in the MRE. Results indicate that skills improvement in the MRE transfers to the real-world task of CBE of human patients. This initial case study demonstrates the efficacy of MREs incorporating real-time feedback for training real-world cognitive-psychomotor tasks.","1941-0506","","10.1109/TVCG.2011.132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5963665","Mixed and augmented reality;information visualization;life and medical sciences.","Breast;Sensors;Real time systems;Visualization;Training;Data models;Humans","biomedical education;computer based training;data visualisation;medical computing;patient diagnosis;virtual reality","real-time evaluation;learner performance visualization;mixed-reality environment;clinical breast examination;real-time user performance feedback;real-world tasks training;tightly coupled cognitive components;psychomotor components;visual feedback;MRE;human patients;real-world cognitive-psychomotor tasks","Breast;Computer Graphics;Computer-Assisted Instruction;Feedback, Sensory;Female;Humans;Medical Informatics Applications;Models, Anatomic;Palpation;Pressure;User-Computer Interface","9","","35","","28 Jul 2011","","","IEEE","IEEE Journals"
"The design of an object-oriented simulation tool for evaluating ATM network resource control schemes","J. Soldatos; D. Vergados; E. Vayias; N. Mitrou","Dept. of Electr. Eng. & Comput. Sci., Nat. Tech. Univ. of Athens, Greece; NA; NA; NA","1999 2nd International Conference on ATM. ICATM'99 (Cat. No.99EX284)","6 Aug 2002","1999","","","204","211","Changing the algorithmic components of ATM equipment such as ATM switches, requires full access to the switch control software, which is not available in most commercial products. Hence, most researchers still resort to simulation in order to evaluate new traffic control algorithms. This paper presents the architecture of an ATM simulator that operates at the call level, exposes the power of such a tool in evaluating different control architectures for ATM networks, and presents the status of a prototype implementation. ATM simulators based on the proposed architecture include a Web-based component (Java applet) which acts as user interface. This component enables tele-training and dissemination of important simulation results to remote sites.","","0-7803-5428-1","10.1109/ICATM.1999.786804","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=786804","","Object oriented modeling;Asynchronous transfer mode;Switches;Telecommunication control;Routing;Telecommunication switching;Java;User interfaces;Resource management;Computational modeling","object-oriented methods;software tools;digital simulation;telecommunication computing;asynchronous transfer mode;telecommunication control;telecommunication traffic;Java;distance learning","object-oriented simulation tool;ATM network resource control schemes;ATM switches;switch control software;traffic control algorithms;ATM simulator;call level;control architectures;prototype implementation;Web-based component;Java applet;user interface;tele-training;remote sites","","","","25","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Learning Safety Equipment Detection using Virtual Worlds","M. di Benedetto; E. Meloni; G. Amato; F. Falchi; C. Gennaro","National Research Council, Institute of Information Science and Technologies, Italy; Università di Pisa, Italy; National Research Council, Institute of Information Science and Technologies, Italy; National Research Council, Institute of Information Science and Technologies, Italy; National Research Council, Institute of Information Science and Technologies, Italy","2019 International Conference on Content-Based Multimedia Indexing (CBMI)","21 Oct 2019","2019","","","1","6","Nowadays, the possibilities offered by state-of-the-art deep neural networks allow the creation of systems capable of recognizing and indexing visual content with very high accuracy. Performance of these systems relies on the availability of high quality training sets, containing a large number of examples (e.g. million), in addition to the the machine learning tools themselves. For several applications, very good training sets can be obtained, for example, crawling (noisily) annotated images from the internet, or by analyzing user interaction (e.g.: on social networks). However, there are several applications for which high quality training sets are not easy to be obtained/created. Consider, as an example, a security scenario where one wants to automatically detect rarely occurring threatening events. In this respect, recently, researchers investigated the possibility of using a visual virtual environment, capable of artificially generating controllable and photo-realistic contents, to create training sets for applications with little available training images. We explored this idea to generate synthetic photo-realistic training sets to train classifiers to recognize the proper use of individual safety equipment (e.g.: worker protection helmets, high-visibility vests, ear protection devices) during risky human activities. Then, we performed domain adaptation to real images by using a very small image data set of real-world photographs. We show that training with the generated synthetic training set and using the domain adaptation step is an effective solution to address applications for which no training sets exist.","1949-3991","978-1-7281-4673-7","10.1109/CBMI.2019.8877466","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877466","Deep Learning;Virtual Dataset;Transfer Learning;Domain Adaptation;Safety Equipment Detection","Training;Safety;Games;Engines;Head;Neural networks;Visualization","feature extraction;image classification;learning (artificial intelligence);neural nets;occupational safety;virtual reality","visual virtual environment;photo-realistic training sets;high-visibility vests;safety equipment detection;virtual worlds;machine learning tools;classifier training;deep neural network training;individual safety equipment recognition;risky human activities","","2","","27","","21 Oct 2019","","","IEEE","IEEE Conferences"
"A Two-Phase Transfer Learning-Based Power Spectrum Maps Reconstruction Algorithm for Underlay Cognitive Radio Networks","X. Han; L. Xue; Y. Xu; Z. Liu","Electronic Countermeasure College, National University of Defense Technology, Hefei, China; Electronic Countermeasure College, National University of Defense Technology, Hefei, China; Electronic Countermeasure College, National University of Defense Technology, Hefei, China; Electronic Countermeasure College, National University of Defense Technology, Hefei, China","IEEE Access","13 May 2020","2020","8","","81232","81245","In the underlay cognitive radio networks, the power spectrum maps (PSMs) estimation is the main challenge in sensing the idle wireless radio resources. Traditional deep learning-based algorithms achieve good estimation performance, under the hypothesis that the training data must be independent and identically distributed (i.i.d.) with the PSMs in the target region. However, collecting the PSMs training data is not an easy task, which is time-consuming and requires a numerous number of sensing devices. For this reason, we propose a two-phase transfer learning generative adversarial network (TPTL-GAN) for the PSMs reconstruction task. The proposed algorithm relaxes the i.i.d. assumption in traditional deep learning-based algorithms, allowing us to estimate the PSMs based on the simulated or previously collected training data, which share similar rather than strictly identical distribution with the target data. In the first phase of the TPTL-GAN algorithm, we design a domain projecting (DP) framework to project the source domain to the adjacent domain. In the second phase, we propose a domain completing (DC) framework, which extracts helpful radio environment features from the adjacent domain and reconstructs the PSMs in the target domain. Through the above two phases, the proposed algorithm provides a more accurate PSMs reconstruction performance than the traditional methods, as verified by the simulation results.","2169-3536","","10.1109/ACCESS.2020.2991183","Technology Funds of Fundamental Research Strengthening Plan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9081914","Cognitive radio networks;deep learning;power spectrum;transfer learning;wireless communication","Training data;Estimation;Cognitive radio;Task analysis;Interpolation;Feature extraction","cognitive radio;learning (artificial intelligence);neural nets;radio networks;radio spectrum management;telecommunication computing;wireless channels","power spectrum maps reconstruction algorithm;two-phase transfer learning;accurate PSMs reconstruction performance;target domain;helpful radio environment features;adjacent domain;TPTL-GAN algorithm;simulated collected training data;PSMs reconstruction task;generative adversarial network;PSMs training data;good estimation performance;traditional deep learning-based algorithms;idle wireless radio resources;power spectrum maps estimation;underlay cognitive radio networks","","1","","32","CCBY","29 Apr 2020","","","IEEE","IEEE Journals"
"Virtual surgery system for abdominal organs based on VR helmet","M. Liu; J. Deng; Y. Wang; X. Zhang; X. Zhang","School of Computer, Electronics and Information, Guangxi University, Nanning, Guangxi 530004, P. R. China; School of Computer, Electronics and Information, Guangxi University, Nanning, Guangxi 530004, P. R. China; School of Computer, Electronics and Information, Guangxi University, Nanning, Guangxi 530004, P. R. China; School of Computer, Electronics and Information, Guangxi University, Nanning, Guangxi 530004, P. R. China; Guangxi Key Laboratory of Multimedia Communications and Network Technology, Guangxi University, Nanning, Guangxi 530004, P. R. China","2018 International Workshop on Advanced Image Technology (IWAIT)","31 May 2018","2018","","","1","4","Now Days doctors interpret the human body abdomen via CT images, which is always lack of intuitive, three-dimensional viewing. Statistics show that 80% of clinical errors are caused by human error. Therefore surgical training for young surgeons is very important to their experience growth. In order to observe the body structure of the human body efficiently and improve the technical proficiency of doctors, this paper designs a surgical system for abdominal organs based on VR helmet. Using 3D Labeling algorithm and time varying phase difference algorithm, the system can automatically segment the organs in medical image and transfer the reconstruction of the human abdominal body into three-dimensional model, from which a VR helmet could perform a real-time visualization of the human organs in different viewpoints. Our system provides a virtual tool set (scalpel, surgical clamp) that enable the use of collision detection and cutting algorithm to achieve the cutting effects of the abdominal organs. Experimental results show that our system are robust to achieve the establishment of three-dimensional abdominal organ model, and virtual surgery tools could help doctors to simulate the operation completely together with the use of force-feedback device.","","978-1-5386-2615-3","10.1109/IWAIT.2018.8369801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8369801","Three-dimensional reconstruction;VR helmet;Virtual surgery","Surgery;Solid modeling;Three-dimensional displays;Biomedical imaging;Tools;Computed tomography;Labeling","biological organs;computerised tomography;force feedback;image segmentation;medical image processing;surgery;virtual reality","virtual surgery tools;three-dimensional abdominal organ model;cutting algorithm;collision detection;surgical clamp;virtual tool set;human organs;three-dimensional model;human abdominal body;medical image;phase difference algorithm;3D Labeling algorithm;body structure;young surgeons;surgical training;human error;clinical errors;three-dimensional viewing;CT images;human body abdomen;VR helmet;abdominal organs;virtual surgery system","","1","","10","","31 May 2018","","","IEEE","IEEE Conferences"
"WAVE: Interactive Wave-based Sound Propagation for Virtual Environments","R. Mehra; A. Rungta; A. Golas; M. Lin; D. Manocha",UNC Chapel Hill; UNC Chapel Hill; UNC Chapel Hill; UNC Chapel Hill; UNC Chapel Hill,"IEEE Transactions on Visualization and Computer Graphics","20 Mar 2015","2015","21","4","434","442","We present an interactive wave-based sound propagation system that generates accurate, realistic sound in virtual environments for dynamic (moving) sources and listeners. We propose a novel algorithm to accurately solve the wave equation for dynamic sources and listeners using a combination of precomputation techniques and GPU-based runtime evaluation. Our system can handle large environments typically used in VR applications, compute spatial sound corresponding to listener's motion (including head tracking) and handle both omnidirectional and directional sources, all at interactive rates. As compared to prior wave-based techniques applied to large scenes with moving sources, we observe significant improvement in runtime memory. The overall sound-propagation and rendering system has been integrated with the Half-Life 2 game engine, Oculus-Rift head-mounted display, and the Xbox game controller to enable users to experience high-quality acoustic effects (e.g., amplification, diffraction low-passing, high-order scattering) and spatial audio, based on their interactions in the VR application. We provide the results of preliminary user evaluations, conducted to study the impact of wave-based acoustic effects and spatial audio on users' navigation performance in virtual environments.","1941-0506","","10.1109/TVCG.2015.2391858","Advanced Simulation and Training; ARO Contracts; National Science Foundation; Impulsonic Inc.; Acoustect SDK; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7014276","Sound propagation;dynamic sources;spatial sound;Sound propagation;dynamic sources;directivity;spatial sound;Helmholtz equation","Runtime;Acoustics;Vectors;Transfer functions;Virtual environments;Linear systems;Navigation","acoustic wave propagation;graphics processing units;rendering (computer graphics);virtual reality;wave equations","WAVE;interactive wave-based sound propagation;virtual environments;dynamic sources;wave equation;GPU-based runtime evaluation;VR applications;omnidirectional sources;rendering system;Half-Life 2 game engine;Oculus-Rift head-mounted display;Xbox game controller;high-quality acoustic effects;spatial audio;wave-based acoustic effects;user navigation performance","Acoustic Stimulation;Adult;Algorithms;Computer Graphics;Female;Humans;Male;Sound;User-Computer Interface;Video Games;Young Adult","20","","43","","19 Jan 2015","","","IEEE","IEEE Journals"
"Multimedia tele-surgery using high speed optical fiber network and its application to intravascular neurosurgery - system configuration and computer networked robotic implementation","F. Arai; M. Tanimoto; T. Fukuda; K. Shimojima; H. Matsuura; M. Negoro","Dept. of Micro Syst. Eng., Nagoya Univ., Japan; Dept. of Micro Syst. Eng., Nagoya Univ., Japan; Dept. of Micro Syst. Eng., Nagoya Univ., Japan; Dept. of Micro Syst. Eng., Nagoya Univ., Japan; Dept. of Micro Syst. Eng., Nagoya Univ., Japan; NA","Proceedings of IEEE International Conference on Robotics and Automation","6 Aug 2002","1996","1","","878","883 vol.1","We propose a multimedia tele-surgery system for training, diagnosis, and assistance in surgery. To realize this system, a high speed optical fiber network with asynchronous transfer mode (ATM) is used to provide high quality moving pictures. We designed a new teleoperation system based on ATM, which is different from the conventional one that is based on Ethernet. We built a prototype of the virtual simulator system for the intravascular neurosurgery that consists of a 3D-computer graphics simulator and two types of joysticks. The joysticks are used for the controller and force display of catheter head direction, position, and orientation. A visual assistance method is proposed to assist the operator. We performed teleoperation experiments between Nagoya and Tokyo, about 350 km apart from each other, using high speed optical fiber network, and evaluated the effectiveness of the proposed system.","1050-4729","0-7803-2988-0","10.1109/ROBOT.1996.503883","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=503883","","Optical fiber networks;Asynchronous transfer mode;Force control;Multimedia systems;Surgery;Ethernet networks;Virtual prototyping;Neurosurgery;Graphics;Displays","surgery;telerobotics;multimedia communication;asynchronous transfer mode;optical fibre networks;optical fibre communication;virtual reality;solid modelling;medical computing","multimedia tele-surgery system;optical fiber network;intravascular neurosurgery;asynchronous transfer mode;teleoperation;virtual simulator;3D-computer graphics simulator;joysticks;visual assistance","","24","","12","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Co-presentation of force cues for skill transfer via shared-control systems","D. Powell; M. K. O'Malley","Rice University, USA; Rice University, USA","2010 IEEE Haptics Symposium","8 Apr 2010","2010","","","453","456","During training and rehabilitation with haptic devices, it is often necessary to simultaneously present force cues arising from different haptic models (such as guidance cues and environmental forces). Multiple force cues are typically summed to produce a single output force, which conveys only relative information about the original force cues and may not be useful to trainees. Two force co-presentation paradigms are proposed as potential solutions to this problem: temporal separation of force cues, where one type of force is overlaid with the other in staggered pulses, and spatial separation, where the forces are presented via multiple haptic devices. A generalized model for separating task and guidance forces in a virtual environment is also proposed. In a pilot study where sixteen participants were trained in a dynamic target-hitting task using these co-presentation paradigms, simple summation was in fact most effective at eliciting skill transfer in most respects. Spatial separation imposed the lowest overall workload on participants, however, and might thus be more appropriate than summation in tasks with other significant physical or mental demands. Temporal separation was relatively inferior at eliciting skill transfer, but it is hypothesized that this paradigm would have performed considerably better in a non-rhythmic task, and the need for further research is indicated.","2324-7355","978-1-4244-6822-5","10.1109/HAPTIC.2010.5444619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444619","","Haptic interfaces;Virtual environment;Fixtures;Education;Performance evaluation;Manipulator dynamics;Displays;USA Councils;Force control;Feedback","haptic interfaces;virtual reality","force cues;skill transfer;shared-control systems;haptic devices;guidance cues;environmental forces;virtual environment;copresentation paradigms","","1","","7","","8 Apr 2010","","","IEEE","IEEE Conferences"
"VBR traffic prediction in ATM system","W. Lobejko","Mil. Commun. Inst., Zegrze, Poland","MILCOM 97 MILCOM 97 Proceedings","6 Aug 2002","1997","3","","1585","1588 vol.3","This paper presents new ATM (asynchronous transfer mode) VBR (variable bit rate) traffic prediction using an artificial neural network (ANN). The paper describes a model of the neural network and its training algorithm. It discusses a new method of designing the neural network using genetic algorithms and it explains the mechanism of three main genetic operations: selection, crossover and mutation. Computer simulation results are presented. It is shown that the neural network can predict the VBR traffic by learning the relationship between ATM traffic variations.","","0-7803-4249-6","10.1109/MILCOM.1997.645034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=645034","","Telecommunication traffic;Traffic control;Asynchronous transfer mode;Artificial neural networks;Bit rate;Design methodology;Algorithm design and analysis;Genetic algorithms;Genetic mutations;Computer simulation","telecommunication traffic;genetic algorithms;asynchronous transfer mode;neural nets;telecommunication computing","VBR traffic prediction;ATM system;asynchronous transfer mode;variable bit rate traffic;artificial neural network;ANN;training algorithm;design;genetic algorithms;selection;crossover;mutation;traffic variations","","2","","3","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Mapping distributed interactive simulation network requirements onto broadband networks and services","T. L. Gehl","IBM, Federal Syst. Co., USA","Proceedings of ICC/SUPERCOMM'94 - 1994 International Conference on Communications","6 Aug 2002","1994","","","154","159 vol.1","Just imagine, being able to immerse yourself into a virtual world where you could see the results of your actions with respect to other realistic entities (i.e. people, machines, environments) in a particular scenario. Then, imagine the expansion of this virtual world through the interaction of real-time distributed simulations. This interaction of real-time distributed simulations could greatly enhance education and training, operational verification of design, and mission rehearsal functions needed to support the defense and commercial industries. Through the advancements in technologies (i.e. visual systems, host processors, databases, and networks), we can now realize the expectations of this virtual world. This paper addresses the network requirements for a federal government initiative called Distributed Interactive Simulation (DIS). Through our discussion of the DIS environment, we will identify the services and performance capabilities required of advanced network architectures, and relate these requirements to the proposed capabilities of the standard-based broadband technologies of asynchronous transfer mode (ATM) and synchronous optical network (SONET). We map the DIS network requirements to the capabilities inherent to these broadband technologies, and specify the access of those capabilities from the DIS application through the broadband network and services.<>","","0-7803-1825-0","10.1109/ICC.1994.369004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=369004","","Broadband communication;Computational modeling;Computer simulation;Protocols;Distributed computing;Application software;Industrial training;Visual databases;Asynchronous transfer mode;Space technology","B-ISDN;asynchronous transfer mode;SONET;digital simulation;telecommunication computing;interactive systems","distributed interactive simulation;broadband networks;broadband services;real-time distributed simulations;federal government initiative;performance;network architectures;asynchronous transfer mode;synchronous optical network;ATM;SONET;B-ISDN","","","","2","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Transfer Learning of a Temporal Bone Performance Model via Anatomical Feature Registration","Y. Zhou; I. Ioannou; S. Wijewickrema; J. Bailey; P. Piromchai; G. Kennedy; S. OLeary","Dept. of Comput. & Inf. Syst., Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Comput. & Inf. Syst., Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Centre for the Study of Higher Educ., Univ. of Melbourne, Melbourne, VIC, Australia; NA","2014 22nd International Conference on Pattern Recognition","6 Dec 2014","2014","","","1916","1921","Evaluation of the outcome (end-product) of surgical procedures carried out in virtual reality environments is an essential part of simulation-based surgical training. Automated end-product assessment can be carried out by performance classifiers built from a set of expert performances. When applied to temporal bone surgery simulation, these classifiers can evaluate performance on the bone specimen they were trained on, but they cannot be extended to new specimens. Thus, new expert performances need to be recorded for each new specimen, requiring considerable time commitment from time-poor expert surgeons. To eliminate this need, we propose a transfer learning framework to adapt a classifier built on a single temporal bone specimen to multiple specimens. Once a classifier is trained, we translate each new specimens' features to the original feature space, which allows us to carry out performance evaluation on different specimens using the same classifier. In our experiment, we built a surgical end-product performance classifier from 16 expert trials on a simulated temporal bone specimen. We applied the transfer learning approach to 8 new specimens to obtain machine generated end-products. We also collected end-products for these 8 specimens drilled by a single expert. We then compared the machine generated end-products to those drilled by the expert. The drilled regions generated by transfer learning were similar to those drilled by the expert.","1051-4651","978-1-4799-5209-0","10.1109/ICPR.2014.335","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6977047","transfer learning;anatomy registration;automatic evaluation","Surgery;Bones;Anatomical structure;Solid modeling;Adaptation models;Decision trees;Training","bone;feature extraction;image classification;image registration;learning (artificial intelligence);medical image processing;surgery;virtual reality","temporal bone performance model;anatomical feature registration;surgical procedures;virtual reality environments;simulation-based surgical training;automated end-product assessment;performance classifiers;temporal bone surgery simulation;bone specimen;time-poor expert surgeons;transfer learning framework;surgical end-product performance classifier;transfer learning approach;machine generated end-products","","","","17","","6 Dec 2014","","","IEEE","IEEE Conferences"
"Robot Patient Design to Simulate Various Patients for Transfer Training","Z. Huang; C. Lin; M. Kanai-Pak; J. Maeda; Y. Kitajima; M. Nakamura; N. Kuwahara; T. Ogata; J. Ota","School of Automation, Guangdong University of Technology, Guangzhou, China; Research into Artifacts, Center for Engineering, University of Tokyo, Chiba, Japan; Kanto Gakuin University, Yokohama, Japan; Faculty of Nursing, Tokyo Ariake University of Medical and Health Sciences, Tokyo, Japan; Faculty of Nursing, Tokyo Ariake University of Medical and Health Sciences, Tokyo, Japan; Faculty of Nursing, Tokyo Ariake University of Medical and Health Sciences, Tokyo, Japan; Department of Advanced Fibro-Science, Kyoto Institute of Technology, Kyoto, Japan; Research into Artifacts, Center for Engineering, University of Tokyo, Chiba, Japan; Research into Artifacts, Center for Engineering, University of Tokyo, Chiba, Japan","IEEE/ASME Transactions on Mechatronics","13 Oct 2017","2017","22","5","2079","2090","To improve the patient transfer skill of nursing education students, we developed a robot patient that can simulate three categories of patients: 1) patients whose movements are affected by paralysis; 2) patients whose movements are sensitive to pain with painful expression; and 3) patients whose movements are constrained by medical devices. By practicing with the robot patient, nursing students can learn the skills required for interacting with various patients. To simulate trunk movements of these different patients, novel waist and hip joints with hardware-inherent compliance and force-sensing capability were proposed. In addition, control methods were developed and the parameters were tuned based on actual patient videos. To evaluate the developed robot, nursing teachers performed trials of transferring the robot patient as they would transfer an actual patient. The nursing teachers scored the robot patients based on a checklist. Moreover, subjective evaluations of a questionnaire were performed by the nursing teachers. The results showed that the nursing teachers performed most of the required skills of the checklist and agreed regarding the learning effectiveness of the robot. They recommended training nursing students using the robot patient in the questionnaire. Finally, hugging speed comparison showed that the nurses slow down the speed when dealing with a robot patient with painful expression.","1941-014X","","10.1109/TMECH.2017.2730848","Japan Society for the Promotion of Science KAKENHI; National Science Foundation of China; Natural Science Foundation of Guangdong Province, China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990192","Compliant joint;patient transfer;robot patient;various patients","Training;Medical services;Robot sensing systems;Hip;Force","biomedical education;computer aided instruction;control system synthesis;educational robots;human-robot interaction;medical computing;medical robotics;patient care","nursing teachers;robot patient design;patient transfer skill;nursing education students;force-sensing capability;control parameter tuning;transfer training","","","","48","Traditional","24 Jul 2017","","","IEEE","IEEE Journals"
"Motor learning of the upper limb in children with cerebral palsy after virtual and physical training intervention","M. T. Robert; R. Guberek; M. F. Levin; H. Sveistrup","Integrated Program of Neuroscience, School of P & OT, and Feil/Oberfeld/CRIR Research Centre, McGill University and Jewish Rehabilitation Hospital, Montreal, Canada; Integrated Program of Neuroscience, School of P & OT, and Feil/Oberfeld/CRIR Research Centre, McGill University and Jewish Rehabilitation Hospital, Montreal, Canada; Integrated Program of Neuroscience, School of P & OT, and Feil/Oberfeld/CRIR Research Centre, McGill University and Jewish Rehabilitation Hospital, Montreal, Canada; Faculty of Health Sciences, University of Ottawa, Ottawa, Canada","2013 International Conference on Virtual Rehabilitation (ICVR)","14 Nov 2013","2013","","","194","195","Evidence for improvement and retention of upper limb kinematics in children with cerebral palsy (CP) is scarce especially following training interventions using virtual environments. Children with CP were randomly allocated to one of two groups: task-oriented training with or without trunk restraint. For both groups, training was done in both virtual and physical environments. Motor improvements were retained 3 months after the intervention and transferred to a similar task. Sensory status was related to learning and retention of kinematics. Training in combined virtual and physical environments led to learning and retention of movement patterns in children with CP.","2331-9569","978-1-4799-0774-8","10.1109/ICVR.2013.6662125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6662125","Cerebral Palsy;Motor learning;Upper limb","Training;Kinematics;Virtual environments;Educational institutions;Pediatrics;Games;Motor drives","medical computing;patient rehabilitation;virtual reality","motor learning;upper limb learning;children with cerebral palsy;virtual training intervention;physical training intervention;upper limb kinematics;virtual environments;task-oriented training;trunk restraint;sensory status;kinematics learning;kinematics retention","","1","","7","","14 Nov 2013","","","IEEE","IEEE Conferences"
"Thermal Characterization of a Virtual Reality Headset during Transient and Resting Operation","R. McAfee; C. Haxton; M. Harrison; J. Gess","Oregon State University,204 Rogers Hall, Corvallis,OR,97331; Oregon State University,204 Rogers Hall, Corvallis,OR,97331; Oregon State University,204 Rogers Hall, Corvallis,OR,97331; Oregon State University,204 Rogers Hall, Corvallis,OR,97331","2020 36th Semiconductor Thermal Measurement, Modeling & Management Symposium (SEMI-THERM)","17 Jul 2020","2020","","","131","136","Virtual Reality (VR) is a powerful tool for maintenance process development, engineering design, pedagogy, and combat training. The evolution of the gaming industry has driven the demand for comfortable and reliable VR performance. By using the headset's user datasheet defined MicroController Unit's (MCU) operational temperature, the thermal resistance of the headset used in this study was found to have an external resistance, Rja, of 29.1 K/W, but 28.6% of this heat load is transmitted to the user. Relying on the user's body, specifically the forehead, as a heat sink results in uncomfortable perspiration during usage. Collected data show that after 2 hours of operation, the temperature increases 2.8°C on average when the headset is removed from the user and placed at rest while still operational. The maximum temperature increase is 5.6°C at the top of the VR headset, the surface nearest the internal MCU. This temperature spike proves that the headset needs more effective convective surface area in order to maintain a steady and comfortable operational temperature during “headset on” and “headset off” usage as the user's body was not available as a heat sink in the latter mode. A copper sheet has been added inside the headset to thermally connect all of the external surfaces on the device, effectively increasing the optimal convective heat transfer by 61%. The temperature nearest the MCU dropped 6.5°C with the improved thermal management solution and users reported a 25% reduction in perspiration during prolonged use.","","978-0-578-43862-7","10.23919/SEMI-THERM50369.2020.9142850","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9142850","Wearable;thermal management;consumer products;Virtual Reality;comfort measurements;free convection;heat transfer","Headphones;Temperature measurement;Heating systems;Temperature distribution;Convection;Forehead","convection;cooling;heat sinks;microcontrollers;thermal resistance;virtual reality","optimal convective heat transfer;comfortable operational temperature;steady temperature;temperature spike;VR headset;maximum temperature increase;heat sink results;heat load;external resistance;thermal resistance;MCU;MicroController Unit's operational temperature;reliable VR performance;comfortable VR performance;maintenance process development;resting operation;virtual Reality headset;thermal characterization;time 2.0 hour","","","","8","","17 Jul 2020","","","IEEE","IEEE Conferences"
"Perceptually augmented simulator design through decomposition","T. Edmunds; D. K. Pai","Rutgers University, USA; University of British Columbia, USA","World Haptics 2009 - Third Joint EuroHaptics conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems","3 Apr 2009","2009","","","505","510","We approach the problem of determining a general method for augmenting haptic simulators to amplify the perceptually salient aspects of the interaction that induce effective skill transfer. Using such a method, we seek to simplify the design of haptic simulators that can improve training effectiveness without requiring expensive improvements in the capability of the rendering hardware. We present a decomposition approach to the automated design of perceptually augmented simulations, and we describe a user-study of the training effectiveness of a search-task simulator designed using our approach vs. an un-augmented simulator. The results indicate that our decomposition approach allows existing psychophysical findings to be leveraged in the design of haptic simulators that effectively impart skill by targeting perceptually significant aspects of the interaction.","","978-1-4244-3858-7","10.1109/WHC.2009.4810890","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810890","","Haptic interfaces;Engines;Shape;Analytical models;Surface texture;Hardware;Surgery;Jamming;Virtual environment;Teleoperators","augmented reality;haptic interfaces;rendering (computer graphics)","perceptually augmented simulator design;haptic simulators augmentation;rendering hardware;search-task simulator","","1","","14","","3 Apr 2009","","","IEEE","IEEE Conferences"
"Games and Learning Alliance (GaLA) Supporting Education and Training through Hi-Tech Gaming","F. Bellotti; R. Berta; A. De Gloria","Dynatech - Dept. of Naval, Electr. & Inf. Technol. Eng., Univ. of Genoa, Genoa, Italy; Dynatech - Dept. of Naval, Electr. & Inf. Technol. Eng., Univ. of Genoa, Genoa, Italy; Dynatech - Dept. of Naval, Electr. & Inf. Technol. Eng., Univ. of Genoa, Genoa, Italy","2012 IEEE 12th International Conference on Advanced Learning Technologies","16 Aug 2012","2012","","","740","741","Games and Learning Alliance (GaLA) is the EU Network of Excellence on serious games (SG). The main expected outcome is the set-up a Virtual Research Centre (VRC) aimed at integrating, harmonizing and coordinating research on SGs and disseminating knowledge, best practices and tools as a reference point at an international level. The other two key focuses of the project are (1) the support to deployment in the actual educational and training settings and (2) the fostering of innovation and knowledge transfer through research-business dialogue. The NoE is composed of organizations that aim to integrate their activities and resources in a long-term view. A long-term perspective is systematically pursued as GaLA sets-up an infrastucture and aims at making it viable and sustainable. The major expected outcomes include: the European Society on Serious Games; the European conference on Serious Games; journal special issues; the Virtual Research Environment (VRE); the SG Living Labs (SG LLs); a MSc programme on SGs, with the relevant didactic tools; PhD projects on SGs; the schools (alignment and summer) on SGs.","2161-377X","978-1-4673-1642-2","10.1109/ICALT.2012.146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6268245","Serious Games;Technology Enhanced Learning;Virtual Research Environment;Virtual research Center;Living Labs","Games;Europe;Educational institutions;Training;Best practices;Industries;Media","computer aided instruction;computer games;interactive programming;knowledge management;virtual reality","games and learning alliance;serious game;EU network;virtual research centre;VRC;training;knowledge transfer;innovation;research-business dialogue;NoE;GaLA;virtual research environment;SG;VRE;hi-tech game","","7","","2","","16 Aug 2012","","","IEEE","IEEE Conferences"
"Intelligent Robotic Peg-in-Hole Insertion Learning Based on Haptic Virtual Environment","Y. Chen; X. Han; M. Okada; Y. Chen; F. Naghdy","School of Information Science and Engineering, Central South University, Changsha, 410083, China. cyt28@126.com; School of Information Science and Engineering, Central South University, Changsha, 410083, China; School of Information, Production and Systems, Waseda University, Kitakyushu, 808-0135, Japan. okada@okada-lab.org; School of Electrical, Computer and Telecommunication Engineering, University of Wollongong, NSW, 2522, Australia. ycquiet@126.com; School of Electrical, Computer and Telecommunication Engineering, University of Wollongong, NSW, 2522, Australia","2007 10th IEEE International Conference on Computer-Aided Design and Computer Graphics","26 Dec 2007","2007","","","355","360","A new approach is explored to transfer human manipulation skills to a robotics system. A skill acquisition algorithm utilizes the position and contact force/torque data generated in the virtual environment combined with a priori knowledge about the task to generate the skills required to perform such a task. Such skills are translated into actual robotic trajectories for implementation in real time. The peg-in-hole insertion problem is used as a case study. The results are reported.","","978-1-4244-1578-6","10.1109/CADCG.2007.4407908","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4407908","","Intelligent robots;Haptic interfaces;Virtual environment;Humans;Imaging phantoms;Friction;Torque;Training data;Force feedback;Solid modeling","haptic interfaces;intelligent robots;learning (artificial intelligence);manipulators;rendering (computer graphics);virtual reality","intelligent robotic peg-in-hole insertion learning;haptic virtual environment;human manipulation skills;skill acquisition algorithm","","4","","12","","26 Dec 2007","","","IEEE","IEEE Conferences"
"Street Crossing by Typically Developed Children in Real and Virtual Environments","O. Bart; N. Katz; P. L. Tamar; W. W. Josman; N. Josman","Dept. of Occupational Therapy, Tel Aviv Univ.; NA; NA; NA; NA","2006 International Workshop on Virtual Rehabilitation","9 Oct 2006","2006","","","42","46","Pedestrian injury is the second leading cause of death and serious injury among children between the ages of 5 and 14. The existing methods for teaching children how to cross the street safely are difficult to transfer to real life situations. The objective of this study was to evaluate the effectiveness of a virtual reality (VR) environment in teaching children how to cross a street safely. Eighty-six children (55 girls and 31 boys), aged 7-12 years, participated in the study. The children were observed while crossing a real street and tested on a test in the virtual environment (VE) prior to and following VR training. The children in the training group significantly improved their street crossing abilities in the VR simulation as well as in the real street crossing in comparison to the control group. Street crossing became safer with age however, no differences were found between boys and girls. This low-cost and readily available street crossing simulation had a positive effect on children's street crossing behavior and on their self-reported satisfaction","2331-9569","1-4244-0280-8","10.1109/IWVR.2006.1707525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1707525","","Injuries;Virtual reality;Safety;Medical treatment;Education;Road accidents;Testing;Aging;Virtual environment;Cancer","computer aided instruction;psychology;road safety;road traffic;teaching;virtual reality","street crossing;pedestrian injury;teaching;virtual reality environment;street safety","","1","","44","","9 Oct 2006","","","IEEE","IEEE Conferences"
"A new symbolic program package for the interactive design of analog circuits","A. Liberatore; A. Luchetta; S. Manetti; M. C. Piccirilli","Florence Univ., Italy; NA; NA; NA","Proceedings of ISCAS'95 - International Symposium on Circuits and Systems","6 Aug 2002","1995","3","","2209","2212 vol.3","A new program package which constitutes an environment for the interactive exploration and improvement of analog circuit topologies is presented in this paper. The environment is provided with functionalities which permit the graphical schematic entry of the circuit, the symbolic analysis, the approximation of the symbolic results, the use of an external numerical simulator and the graphical postprocessing of both the symbolic and numerical simulation results. These functionalities allow us to immediately evaluate the influence of both topology and component value changes on the circuit behavior. The result is useful for educational/training purposes and for the interactive synthesis of new high-performance analog circuits.","","0-7803-2570-2","10.1109/ISCAS.1995.523866","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=523866","","Packaging;Analog circuits;Numerical simulation;Circuit simulation;Circuit topology;Circuit analysis;Analytical models;Performance analysis;Network topology;Transfer functions","software packages;circuit CAD;analogue circuits;network topology;circuit analysis computing;digital simulation","symbolic program package;interactive design;analog circuits;circuit topologies;functionalities;graphical schematic entry;symbolic analysis;external numerical simulator;graphical postprocessing;component value changes;training purposes","","21","1","4","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Control of Dual-User Haptic Training System With Online Authority Adjustment: An Observer-Based Adaptive Robust Scheme","M. Motaharifar; H. D. Taghirad; K. Hashtrudi-Zaad; S. F. Mohammadi","Advanced Robotics and Automated Systems (ARAS), Industrial Control Center of Excellence, Faculty of Electrical Engineering, K. N. Toosi University of Technology, Tehran, Iran; Advanced Robotics and Automated Systems (ARAS), Industrial Control Center of Excellence, Faculty of Electrical Engineering, K. N. Toosi University of Technology, Tehran, Iran; Department of Electrical and Computer Engineering, BioRobotics Research Laboratory, Queen’s University, Kingston, ON, Canada; Translational Ophthalmology Research Center, Farabi Eye Hospital, Tehran University of Medical Sciences, Tehran, Iran","IEEE Transactions on Control Systems Technology","8 Oct 2020","2020","28","6","2404","2415","The design problem for the control a dual-user haptic surgical training system is studied in this article. The system allows the trainee to perform the task on a virtual environment, while the trainer is able to interfere in the operation and correct probable mistakes made by the trainee. The proposed methodology allows the trainer to transfer the task authority to or from the trainee in real time. The robust adaptive nature of the controller ensures position tracking. The stability of the closed-loop system is analyzed using the input-to-output stability approach and the small-gain theorem. Simulation and experimental results are presented to validate the effectiveness of the proposed control scheme.","1558-0865","","10.1109/TCST.2019.2946943","National Institute for Medical Research Development (NIMAD); Tehran University of Medical Sciences, Tehran, Iran; K. N. Toosi University of Technology, Tehran, Iran Research Grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886365","Dual-user haptics;robust adaptive control;stability;surgical training;task dominance","Haptic interfaces;Task analysis;Training;Stability analysis;Force;Robots;Surgery","adaptive control;closed loop systems;computer based training;control system synthesis;haptic interfaces;human computer interaction;medical control systems;robust control;surgery;virtual reality","control scheme;online authority adjustment;observer-based adaptive robust scheme;dual-user haptic surgical training system;virtual environment;task authority;closed-loop system;dual-user haptic training system control;design problem;position tracking;robust adaptive controller;input-to-output stability approach;small-gain theorem","","","","22","IEEE","30 Oct 2019","","","IEEE","IEEE Journals"
"Language therapy of aphasia supported by augmented reality applications","D. Antkowiak; C. Kohlschein; R. Krooß; M. Speicher; T. Meisen; S. Jeschke; C. J. Werner","RWTH Aachen University, Institute of Information Management in Mechanical Engineering, Aachen, Germany; RWTH Aachen University, Institute of Information Management in Mechanical Engineering, Aachen, Germany; Bitstars GmbH, Aachen, Germany; Bitstars GmbH, Aachen, Germany; RWTH Aachen University, Institute of Information Management in Mechanical Engineering, Aachen, Germany; RWTH Aachen University, Institute of Information Management in Mechanical Engineering, Aachen, Germany; Department of Neurology, University Hospital RWTH Aachen, Aachen, Germany","2016 IEEE 18th International Conference on e-Health Networking, Applications and Services (Healthcom)","21 Nov 2016","2016","","","1","6","In Europe there are more than 580 000 people who suffer from aphasia - an acquired speech and language disorder that occurs because of brain damage, primarily as a result of a stroke. Especially with regards to demographic change, health care systems have to face present and future challenges to improve aphasia therapy. Thereby, immediate therapeutic measures are decisive for best possible and long-term success in language therapy. Regarding essential requirements, on the one hand, therapy intensity and frequency have to be increased significantly while on the other hand, measures need to be adjusted along everyday activities. A very promising approach to meet this requirements are augmented reality applications. They can be used to create a highly natural exercise situation, in which patients interact and practice with their personal possessions at home. This facilitates the successful and continuous transfer of learnings for the patient, contrary to being solely dependent on clinical therapy units. This paper gives an overview of the concept of a real-time software providing augmented and dynamic language therapy, which is interactive and utilizes simple user interface design, for home-based training.","","978-1-5090-3370-6","10.1109/HealthCom.2016.7749511","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7749511","Aphasia therapy;augmented reality;therapy frequency;speech recognition;3D scanning;3D tracking","Medical treatment;Augmented reality;Training;Context;Speech;Cognition","augmented reality;brain;medical computing;medical disorders;patient treatment","aphasia language therapy;augmented reality applications;language disorder;speech disorder;brain damage;stroke;real-time software;dynamic language therapy;user interface design;home-based training","","3","","42","","21 Nov 2016","","","IEEE","IEEE Conferences"
"Towards understanding the capability of spatial audio feedback in virtual environments for people with visual impairments","M. Dong; R. Guo",Kennesaw State University; Kennesaw State University,"2016 IEEE 2nd Workshop on Everyday Virtual Reality (WEVR)","23 Feb 2017","2016","","","15","20","This research analyzes if and how the Head Related Transfer Function (HRTF) can be used to support effective Human-Computer Interaction when people in a Virtual Environment (VE) without visual feedback. If sounds can be located in a VE by using HRTF only, designing and developing considerably safer but diversified training environments might greatly benefit individuals with visual impairments. To investigate this, we ran 2 usability studies: 1) to ascertain whether the HRTF could provide sufficient position information in VEs; 2) to learn whether the HRTF could provide sufficient distance and direction information in VEs. The results showed that a continuous audio feedback could help navigate in a VE without vision feedback.","","978-1-5090-0840-7","10.1109/WEVR.2016.7859538","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7859538","Assistive technology; HRTF; 3D Audio; user study","Visualization;Training;Three-dimensional displays;Virtual environments;Navigation;Headphones;Haptic interfaces","feedback;human computer interaction;transfer functions;virtual reality;vision defects","spatial audio feedback;virtual environments;visual impairments;head related transfer function;HRTF;human-computer interaction;VE;diversified training environments might;position information;direction information","","1","","19","","23 Feb 2017","","","IEEE","IEEE Conferences"
"LadderNet: Knowledge Transfer Based Viewpoint Prediction in 360◦ Video","P. Zhao; Y. Zhang; K. Bian; H. Tuo; L. Song","Peking University, Beijing, China; Peking University, Beijing, China; Peking University, Beijing, China; iQIYI Co. Ltd., Beijing, China; Peking University, Beijing, China","ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","16 Apr 2019","2019","","","1657","1661","In the past few years, virtual reality (VR) has become an enabling technique, not only for enriching our visual experience but also for providing new channels for businesses. Untethered mobile devices are the main players for watching 360-degree content, thereby the precision of predicting the future viewpoints is one key challenge to improve the quality of the playbacks. In this paper, we investigate the image features of the 360-degree videos and the contextual information of the viewpoint trajectories. Specifically, we design ladder convolution to adapt for the distorted image, and propose LadderNet to transfer the knowledge from the pre-trained model and retrieve the features from the distorted image. We then combine the image features and the contextual viewpoints as the inputs for long short-term memory (LSTM) to predict the future viewpoints. Our approach is compared with several state-of-the-art viewpoint prediction algorithms over two 360-degree video datasets. Results show that our approach can improve the Intersection over Union (IoU) by at least 5% and meeting the requirements of the playback of 360-degree video on mobile devices.","2379-190X","978-1-4799-8131-1","10.1109/ICASSP.2019.8682776","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682776","Untethered virtual reality;image distortion;viewpoint prediction","Trajectory;Streaming media;Strips;Kernel;Convolution;Mobile handsets;Shape","feature extraction;learning (artificial intelligence);mobile computing;user interfaces;video cameras;video recording;video signal processing;virtual reality","LadderNet;pre-trained model;distorted image;image features;contextual viewpoints;future viewpoints;state-of-the-art viewpoint prediction algorithms;360-degree video datasets;playback;knowledge transfer based viewpoint prediction;virtual reality;enabling technique;visual experience;untethered mobile devices;main players;360-degree content;contextual information;viewpoint trajectories;design ladder convolution;intersection over union;IoU","","3","","19","","16 Apr 2019","","","IEEE","IEEE Conferences"
"Beyond DoD: non-defense training and education applications of DIS","E. A. Fitzsimmons; J. D. Fletcher","Office of Sci. & Technol. Policy, Washington, DC, USA; NA","Proceedings of the IEEE","6 Aug 2002","1995","83","8","1179","1187","Networked simulation for education and training is discussed as a functional capability though which distributed interactive simulation (DIS) may find application in the non-defense world. Effectiveness of networked simulation in defense education and training applications has yet to be conclusively demonstrated, but studies completed thus far have yielded positive results. Results from non-defense applications are also likely to be positive. The characteristics of networked simulation that are relevant to its transfer to non-defense applications include a focus on group performance, physical dispersion of participants, requirements for real-time response, emergent task environments, visual task environments, accessible performance data, provisions for practice, immersive realism, and interactions with many entities. These characteristics are matched with potential, non-defense applications of networked simulation such as training for crews, teams, and units, edutainment, education, training, school-to-work transitions, and lifelong learning. Remaining issues include further development of technical standards, legal standards, research and development, fiscal and regulatory policies, and development of the communications infrastructure.<>","1558-2256","","10.1109/5.400457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=400457","","US Department of Defense;Computational modeling;Computer simulation;Communication standards;Standards development;Computer networks;Military computing;Safety;Stress;Law","computer based training;training;computer aided instruction;digital simulation;simulation;standards;interactive systems;legislation;groupware;local area networks","nondefense training applications;nondefense education applications;DIS;functional capability;networked simulation;distributed interactive simulation;group performance;physical participant dispersion;real-time response;emergent task environments;visual task environments;accessible performance data;practice provisions;immersive realism;interactions;crews;teams;units;edutainment;school-to-work transitions;lifelong learning;technical standards","","4","","22","","6 Aug 2002","","","IEEE","IEEE Journals"
"Simulation studies in a hot mill facility","L. C. Giussani","Daxus Corp., Pittsburgh, PA, USA","1991 Winter Simulation Conference Proceedings.","6 Aug 2002","1991","","","474","481","The author illustrates several phases of a simulation study done in a hot mill facility for a prominent US steel producer. The first phase of the study focuses on operational and material handling issues for the hot mill banding, weighing, and marking stations. The next phase provides additional support for the objectives of the first phase, along with technology transfer and training to support practical operations at the client's site. The final phase addresses strategic issues at downstream operations from the hot mill banding, weighing, and marking line, and the impact of any operational strategy on the whole system. The models for this project have been developed using the AUTOMOD II simulation software and were executed on an IRIS-Silicon Graphics workstation. The focus of the present work is to interpret the results obtained in the first completed phase and to share the experience of the whole project in terms of lessons learned. The author also points out the extensibility and the synergistic advantages that can be obtained by focusing at an early stage on the customer's short- and long-term goals and objectives.<>","","0-7803-0181-1","10.1109/WSC.1991.185649","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=185649","","Milling machines;Materials handling;Metals industry;Coils;Steel;Investments;Material storage;Analytical models;Technology transfer;Iris","digital simulation;hot working;steel industry","hot mill facility;US steel producer;material handling;technology transfer;training;hot mill banding;weighing;marking line;operational strategy;AUTOMOD II simulation software;IRIS-Silicon Graphics workstation","","1","1","5","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Parameter evaluation for virtual Laparoscopic simulation","S. B. Mansoor; Z. Mukhtar; M. Malik; Z. Amjad; H. Qureshi","School of EECS, National university of Sciences & Technology, Islamabad, Pakistan; School of EECS, National university of Sciences & Technology, Islamabad, Pakistan; School of EECS, National university of Sciences & Technology, Islamabad, Pakistan; School of EECS, National university of Sciences & Technology, Islamabad, Pakistan; School of EECS, National university of Sciences & Technology, Islamabad, Pakistan","2011 7th International Conference on Emerging Technologies","20 Oct 2011","2011","","","1","6","Virtual Reality based surgical simulators have become quite common for training of surgeons for different surgical skills. Simulators have been widely used particularly in minimal invasive surgery. In this paper we find parameters that would be required to create a real time working simulation for exercises given in the Fundamentals of Laparoscopic Surgery curriculum. We use peg transfer exercise as our example in this work and create simulations for parameter analysis using SOFA, an open source surgical framework [1]. The parameters we choose are generic and can be used to create other more complex simulations like cholecystectomy [2] (gall bladder removal) and appendectomy (appendix removal). We show the implementation of these parameters and their behavior in a virtual reality surgical simulation. This work can be used by researchers and developers to choose the right parameters in the context of the simulation they are developing. It also shows the cost and behavior of achieving good visualization (frames per second), physical characteristics and a realistic behavioral model to be used in simulations for training purposes.","","978-1-4577-0768-1","10.1109/ICET.2011.6048481","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6048481","Surgical Simulations;Virtual Reality;Biomechanical Modeling;Laparoscopic Surgery","Solid modeling;Surgery;Finite element methods;Computational modeling;Floors;Springs;Deformable models","data visualisation;digital simulation;medical computing;surgery;virtual reality","parameter evaluation;virtual laparoscopic simulation;virtual reality based surgical simulator;surgical skills;laparoscopic surgery curriculum;peg transfer exercise;parameter analysis;SOFA;open source surgical;complex simulation;cholecystectomy;appendectomy;realistic behavioral model","","","","15","","20 Oct 2011","","","IEEE","IEEE Conferences"
"Communications realism for network simulations","K. H. Brockel; C. Sheth; W. P. Sudnikovich; J. Pasirstein; R. Wood; A. Huynh; A. Mack; H. Drucker","Space & Terrestrial Commun. Directorate, US Army Commun.-Electron. Command, Fort Monmouth, NJ, USA; Space & Terrestrial Commun. Directorate, US Army Commun.-Electron. Command, Fort Monmouth, NJ, USA; Space & Terrestrial Commun. Directorate, US Army Commun.-Electron. Command, Fort Monmouth, NJ, USA; NA; NA; NA; NA; NA","Proceedings of MILCOM '95","6 Aug 2002","1995","2","","484","490 vol.2","The digital battlefield will present unprecedented requirements for the transfer of digital information (voice, data, and imagery). Realizing the vision of the Army's 21st century information transport architecture will require application of advanced modeling and simulation technology for performing architecture analysis, ""what-if"" drills, systems design, testing, and user training. The models and simulations must include communications realism, which is a simulation feature through which a synthetic environment reflects the same communications problems that exist in a real environment. Communications realism for link-level simulations has been achieved in the Integrated Terrain-Environment-Multipath Model (ITEMM). The paper describes the ITEMM, its real-time simulation algorithms, and work in progress to evolve these into a Real-Time Communications network Simulator (RTCNS) for use in a distributed interactive simulation (DIS) environment. It also describes how communication realism has been modeled for stationary and moving platforms and provides a detailed technical description of real-time simulation algorithms developed for modeling mobile radio links.","","0-7803-2489-7","10.1109/MILCOM.1995.483514","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=483514","","Mobile communication;Analytical models;Computational modeling;Performance analysis;System testing;Military computing;Radio communication;Performance evaluation;Information analysis;System analysis and design","military communication;military computing;digital simulation;simulation;multipath channels;digital radio;land mobile radio;radiowave propagation;radio networks;radio links;telecommunication computing","network simulations;digital battlefield;digital information transfer;mobile radio links;voice;data;information transport architecture;US Army;distributed interactive simulation environment;imagery;architecture analysis;systems design;testing;user training;communications realism;synthetic environment;link-level simulations;Integrated Terrain-Environment-Multipath Model;ITEMM;real-time simulation algorithms;Real-Time Communications Network Simulator;distributed interactive simulation","","","1","7","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Robust Impedance Control for Dual User Haptic Training System","R. Heidari; M. Motaharifar; H. D. Taghirad","Advanced Robotics and Automated Systems (ARAS), Industrial Control Center of Excellence (ICCE), Faculty of Electrical Engineering, K.N. Toosi University of Technology,Tehran,Iran; Advanced Robotics and Automated Systems (ARAS), Industrial Control Center of Excellence (ICCE), Faculty of Electrical Engineering, K.N. Toosi University of Technology,Tehran,Iran; Advanced Robotics and Automated Systems (ARAS), Industrial Control Center of Excellence (ICCE), Faculty of Electrical Engineering, K.N. Toosi University of Technology,Tehran,Iran","2019 7th International Conference on Robotics and Mechatronics (ICRoM)","20 Apr 2020","2019","","","181","185","In this paper, an impedance controller with switching parameters for a dual-user haptic training system is introduced. The trainer and the trainee are connected through their haptic consoles, and the trainee performs the surgical procedure on the environment. The trainer can intervene in the procedure by pressing a mechanical pedal; thus, the control parameters are switched to transfer the authority over the task from the trainee to the trainer. The stability of each subsystem and the closed-loop stability of the overall system are investigated. The simulation results verify the performance of the proposed controller.","2572-6889","978-1-7281-6604-9","10.1109/ICRoM48714.2019.9071859","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9071859","Teleoperation;Dual-user;MIS;Surgery training;Impedance control;Dwell time","Haptic interfaces;Impedance;Surgery;Training;Mathematical model;Stability analysis;Force","closed loop systems;computer based training;control engineering computing;haptic interfaces;mechanical stability;medical computing;medical control systems;robot dynamics;robust control;surgery;switching systems (control);telerobotics","haptic consoles;robust impedance control;dual user haptic training system;surgical procedure;mechanical pedal;closed-loop stability;switching parameters;teleoperation methods","","","","19","","20 Apr 2020","","","IEEE","IEEE Conferences"
"Training and development tool for the open innovation quality management system","K. Zgodavova; A. Sutoova","Technical University of Kosice, Faculty of Materials, Metallurgy and Recycling, Institute of Materials and Quality Engineering, Kosice, Slovakia; Technical University of Kosice, Faculty of Materials, Metallurgy and Recycling, Institute of Materials and Quality Engineering, Kosice, Slovakia","2017 15th International Conference on Emerging eLearning Technologies and Applications (ICETA)","9 Nov 2017","2017","","","1","4","The purpose of the paper is to contribute to learning, knowledge creation and knowledge transfer obtained through a web-based role-play simulation environment as a training and development tool for the new phenomena of Open Innovation (OI) concepts of organizations. This paper is based on the survey realized within the OI-NET project. Learning objectives for OI course were chosen by the expert team of the project. A new approach to education using OIMS-RPS has been tested on a sample of PhD students from different study fields at the University. The study is limited by the complexity of the actual Open Innovation environment, measurability of any real enhancement achieved and the possible verification of empirical results.","","978-1-5386-3296-3","10.1109/ICETA.2017.8102543","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8102543","","Technological innovation;Organizations;ISO Standards;Education;Standards organizations;Quality management","computer based training;digital simulation;educational courses;innovation management;quality management","development tool;OI-NET project;learning objectives;OI course;open innovation quality management system;knowledge creation;knowledge transfer;training tool;Web-based role-play simulation environment;OIMS-RPS","","","","16","","9 Nov 2017","","","IEEE","IEEE Conferences"
"Simulating asynchronous, decentralized military command and control","T. Lee; S. Ghosh","Arizona State Univ., AZ, USA; NA","IEEE Computational Science and Engineering","6 Aug 2002","1996","3","4","69","79","The pace and scope of modern warfare have made some aspects of traditional, centralized decision making obsolete. A decentralized scheme grants greater autonomy to fighting units, which process data locally for efficient decision making. In experimental simulations using a decentralized algorithm, units react to information faster in both offensive and defensive scenarios. We used asynchronous, distributed, discrete event simulation techniques to model the command and control problem. These algorithms are appropriate for problems involving discrete data transfer, geographically dispersed decision making entities, asynchronously generated stimuli, and data feedback. To compare our algorithm with traditional algorithms and identify scenarios for which it is effective, we used a loosely coupled parallel processor as a simulation testbed. To the best of our knowledge, this research is the first attempt to scientifically model decentralized C/sup 3/ and assess its performance through extensive parallel simulation. State-of-the-art battlefield simulators such as Simnet and CATT provide training environments in which human operators make the decisions. In contrast, our testbed provides an automated environment for fast, efficient, accurate warfare modeling. By ""accurate"" we mean spatial and timing resolution; we do not claim to represent all battlefield details, such as terrain.","1558-190X","","10.1109/99.556514","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=556514","","Command and control systems;Decision making;Discrete event simulation;Feedback;Humans;Automatic testing;Timing;Spatial resolution","command and control systems;discrete event simulation;distributed algorithms;parallel programming;computer based training;computer aided instruction","asynchronous decentralized military command and control simulation;modern warfare modelling;decentralized scheme;fighting units;decision making;experimental simulations;decentralized algorithm;defensive scenarios;discrete event simulation techniques;discrete data transfer;geographically dispersed decision making entities;asynchronously generated stimuli;data feedback;loosely coupled parallel processor;simulation testbed;decentralized C/sup 3/;parallel simulation;battlefield simulators;Simnet;CATT;automated environment;training environments","","5","","9","","6 Aug 2002","","","IEEE","IEEE Magazines"
"Development of a mathematical model of a train in the energy point of view for the international conference on control, automation and systems 2007 (ICCAS 2007)","Daeki Hong; Hyeongcheol Lee; Jaeho Kwak","Department of Electrical Engineering, Hanyang University, Seoul, Korea; Division of Electrical Control and Instrumentation Biomedical Engineering Hanyang University, Seoul, Korea; Vehicle Dynamics Research Team, Korea Railroad Research Institute, Seoul, Korea","2007 International Conference on Control, Automation and Systems","26 Dec 2007","2007","","","350","355","This paper presents a mathematical model and simulation program of an electric train with regenerative braking system by using Matlab/Simulink in the energy generation, consumption and transfer point of view. This paper also determines the specifications of each component of the electric train by using the developed program. The electric train model and simulation program consist of the speed profile of the electric train, longitudinal dynamics of the electric train, wheel dynamics with brake system, and electric system such as the motor/generator and the energy storage. This paper also provides observation of the energy consumption and regeneration ratios of the energy storage equipped electric train. The simulation results are compared with the test results to verify the simulation program.","","978-89-950038-6-2","10.1109/ICCAS.2007.4406936","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4406936","Electric Train;Energy Saving;Braking Energy;Energy Train Modeling","Mathematical model;Control system synthesis;Automatic control;Automation;Vehicle dynamics;Energy storage;Energy consumption;Rail transportation;Automatic generation control;Electronic mail","brakes;digital simulation;electric vehicles;mathematics computing;power consumption;railway engineering;regenerative braking;wheels","electric train model;simulation program;mathematical model;Matlab/Simulink;energy generation;energy consumption;energy transfer;longitudinal dynamics;wheel dynamics;regenerative braking system","","","1","13","","26 Dec 2007","","","IEEE","IEEE Conferences"
"Laboratory framework TEAM for investigating the dependability issues of microprocessor systems","A. Jasnetski; R. Ubar; A. Tsertov; H. Kruus","Tallinn University of Technology, Dept. of Comp. Engineering, Estonia; Tallinn University of Technology, Dept. of Comp. Engineering, Estonia; Testonica Lab OÜ, Tallinn, Estonia; Tallinn University of Technology, Dept. of Comp. Engineering, Estonia","10th European Workshop on Microelectronics Education (EWME)","14 Aug 2014","2014","","","80","83","We propose a laboratory research and student training oriented framework consisting of Test Evaluation Automated Means (TEAM) as a set of tools for evaluating the quality of test programs for microprocessors and systems. TEAM enables students to learn and analyze the dependability issues of microprocessor systems, to create their own designs and develop test programs, to analyze the quality of testing, and to make decisions about improving the testability of systems. The tool set in TEAM is mostly open and consists of the assembly level test converter, register transfer level test program simulator, global test converter into local test sequences for modules of the system, and gate-level fault simulator. The general ideas of hands-on laboratory training supported by TEAM are outlined. The research tasks of test program generation can be set up in a way that enables a competition between students, and as a consequence, motivates them to better understand the problems of testing of complex systems and their dependability.","","978-1-4799-4016-5","10.1109/EWME.2014.6877400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6877400","microprocessor systems;behaviour level test generation;register transfer and gate level simulation;high-level decision diagrams","Program processors;Microprocessors;Logic gates;Educational institutions;Training;Built-in self-test","circuit simulation;computer aided instruction;electronic engineering education;integrated circuit design;integrated circuit reliability;integrated circuit testing;microprocessor chips;student experiments","TEAM laboratory framework;microprocessor systems;student training oriented framework;test evaluation automated means;test program quality evaluation;dependability analysis;assembly level test converter;register transfer level test program simulator;global test converter;local test sequences;gate-level fault simulator;hands-on laboratory training;complex system testing","","1","","20","","14 Aug 2014","","","IEEE","IEEE Conferences"
"Enabling virtual assembly training in and beyond the automotive industry","A. Stork; N. Sevilmis; D. Weber; D. Gorecky; C. Stahl; M. Loskyll; F. Michel","Interactive Engineering, Technologies, Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany; Interactive Engineering, Technologies, Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany; Interactive Engineering, Technologies, Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany; Innovative Factory Systems, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany; Innovative Factory Systems, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany; Innovative Factory Systems, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany; Augmented Vision, German Research Center for Artificial Intelligence, DFKI, Kaiserslautern, Germany","2012 18th International Conference on Virtual Systems and Multimedia","3 Dec 2012","2012","","","347","352","Virtual assembly training systems show a high potential to complement or even replace physical setups for training of assembly processes in and beyond the automotive industry. The precondition for the breakthrough of virtual training is that it overcomes the problems of former approaches. The paper presents the design approach taken during the development of a game-based, virtual training system for procedural assembly knowledge in the EU-FP7 project VISTRA. One key challenge to address when developing virtual assembly training is the extensive authoring effort for setting up virtual environments. Although knowledge from the product and manufacturing design is available and could be used for virtual training, a concept for integration of this data is still missing. This paper presents the design of a platform which transfers available enterprise data into a unified model for virtual training and thus enables virtual training of workers at the assembly line before the physical prototypes exist. The data requirements and constraints stemming from industrial partners involved in the project will be discussed. A second hurdle for virtual training is the insufficient user integration and acceptance. In this context, the paper introduces an innovative hardware set-up for game-based user interaction, which has been chosen to enhance user involvement and acceptance of virtual training.","","978-1-4673-2563-9","10.1109/VSMM.2012.6365944","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365944","Data Integration;Industrial Training;PLM;User-Interaction;Virtual Reality","Training;Assembly;Data models;Solid modeling;Hardware;Production;Geometry","assembling;automobile industry;business data processing;computer based training;data integration;human factors;product design;virtual manufacturing;virtual reality","automotive industry;virtual assembly training systems;game-based virtual training system;procedural assembly knowledge;EU-FP7 project;VISTRA;virtual environments;manufacturing design;product design;data integration;enterprise data;unified model;assembly line;user integration;game-based user interaction;user involvement;user acceptance","","26","","12","","3 Dec 2012","","","IEEE","IEEE Conferences"
"Virtual vs. experiment, programmable vs. wired logic, hardware vs. software in teaching digital control for electrochemical engineering","D. Mihai; C. Constantinescu","Craiova Univ., Romania; Craiova Univ., Romania","The IEEE Region 8 EUROCON 2003. Computer as a Tool.","3 Dec 2003","2003","2","","7","11 vol.2","Based on industrial, academic and research experience, the authors make an evaluation of basic components involved in training students of electrochemical profiles for the digital control field. The best equilibrium between old and new solutions (from device to equipment) as well as the optimal weights for physical experiments and computer simulation are major issues for certifying a good training level.","","0-7803-7763-X","10.1109/EURCON.2003.1248122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1248122","","Programmable control;Hardware;Education;Digital control;Industrial training;Logic;Computer industry;Industrial control;Application software;Automotive engineering","training;student experiments;control engineering education;digital control;mechanical engineering;electrical engineering;digital simulation;control engineering computing;automation","programmable logic;wired logic;hardware;software;digital control teaching;electrochemical engineering;digital control field;optimal weight;automation;programming language;transfer function;computer simulation;physical experiment;virtual methods","","1","","8","","3 Dec 2003","","","IEEE","IEEE Conferences"
"A Novel Robot Teaching System Based on Mixed Reality","Y. Xu; C. Yang; X. Liu; Z. Li","Key Lab of Autonomous Systems and Networked Control, School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; Key Lab of Autonomous Systems and Networked Control, School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China; Hohai University, Jiangsu, China; Key Lab of Autonomous Systems and Networked Control, School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510641, China","2018 3rd International Conference on Advanced Robotics and Mechatronics (ICARM)","13 Jan 2019","2018","","","250","255","In this paper, we have developed a robot teaching system where the robot learns the point-to-point motions from human demonstrations. In the demonstration phase, the operator's gestures and palm position are used to guide the robot to complete the task. At the same time, the scene of robots and its work environment, and the virtual model of the palms are integrated into Unity. Then the mixed reality scene is transferred to a virtual reality(VR) helmet, which provides operator real-time visual feedback. In the learning and reproduction phase, the Extreme Learning Machine(ELM) is used to generate a new trajectory from the training data. The experimental result shows that the robot teaching system based on mixed reality has more realistic and natural interaction. And the learning algorithm based on ELM has a good fitting ability.","","978-1-5386-7066-8","10.1109/ICARM.2018.8610861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8610861","Robot Teaching;Mixed Reality;Teaching by Demonstration;Extreme Learning Machine","Robot kinematics;Education;Zirconium;Service robots;Virtual reality;End effectors","gesture recognition;human-robot interaction;learning (artificial intelligence);virtual reality","reproduction phase;novel robot teaching system;point-to-point motions;human demonstrations;demonstration phase;mixed reality scene;operator real-time visual feedback;extreme learning machine;virtual reality helmet","","2","","22","","13 Jan 2019","","","IEEE","IEEE Conferences"
"Thinking Penguin: Multimodal Brain–Computer Interface Control of a VR Game","R. Leeb; M. Lancelle; V. Kaiser; D. W. Fellner; G. Pfurtscheller","Center for Neuroprosthetics, École Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland; Nanyang Technological University, Singapore, Singapore; Laboratory of Brain-Computer Interfaces, Institute for Knowledge Discovery, Graz University of Technology, Graz, Austria; Institute of Computer Graphics and Knowledge Visualization, Graz University of Technology, Austria; Emeritus Professor at the Laboratory of Brain-Computer Interfaces, Institute for Knowledge Discovery, Graz University of Technology, Graz, Austria","IEEE Transactions on Computational Intelligence and AI in Games","10 Jun 2013","2013","5","2","117","128","In this paper, we describe a multimodal brain-computer interface (BCI) experiment, situated in a highly immersive CAVE. A subject sitting in the virtual environment controls the main character of a virtual reality game: a penguin that slides down a snowy mountain slope. While the subject can trigger a jump action via the BCI, additional steering with a game controller as a secondary task was tested. Our experiment profits from the game as an attractive task where the subject is motivated to get a higher score with a better BCI performance. A BCI based on the so-called brain switch was applied, which allows discrete asynchronous actions. Fourteen subjects participated, of which 50% achieved the required performance to test the penguin game. Comparing the BCI performance during the training and the game showed that a transfer of skills is possible, in spite of the changes in visual complexity and task demand. Finally and most importantly, our results showed that the use of a secondary motor task, in our case the joystick control, did not deteriorate the BCI performance during the game. Through these findings, we conclude that our chosen approach is a suitable multimodal or hybrid BCI implementation, in which the user can even perform other tasks in parallel.","1943-0698","","10.1109/TCIAIG.2013.2242072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6418003","Brain–computer interfaces (BCI);brain switch;game;hybrid BCI;multimodal;multitasking;virtual reality (VR)","Games;Electroencephalography;Electrodes;Training;Brain computer interfaces;Educational institutions;Feature extraction","brain-computer interfaces;computer games;virtual reality","thinking penguin game;multimodal brain computer interface control;VR game;highly immersive CAVE;virtual environment;virtual reality game;jump action;game controller;BCI performance;discrete asynchronous action;visual complexity;task demand;joystick control;hybrid BCI implementation","","49","","51","","23 Jan 2013","","","IEEE","IEEE Journals"
"FoodChangeLens: CNN-Based Food Transformation on HoloLens","S. Naritomi; R. Tanno; T. Ege; K. Yanai","Dept. of Inf., Univ. of Electro-Commun., Tokyo, Japan; Technol. Dev., NTT Commun. Corp., Tokyo, Japan; Dept. of Inf., Univ. of Electro-Commun., Tokyo, Japan; Dept. of Inf., Univ. of Electro-Commun., Tokyo, Japan","2018 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","17 Jan 2019","2018","","","197","199","In this demonstration, we implemented food category transformation in mixed reality using both image generation and HoloLens. Our system overlays transformed food images to food objects in the AR space, so that it is possible to convert in consideration of real shape. This system has the potential to make meals more enjoyable. In this work, we use the Conditional CycleGAN trained with a large-scale food image data collected from the Twitter Stream for food category transformation which can transform among ten kinds of foods mutually keeping the shape of a given food. We show the virtual meal experience which is food category transformation among ten kinds of typical Japanese foods: ramen noodle, curry rice, fried rice, beef rice bowl, chilled noodle, spaghetti with meat source, white rice, eel bowl, and fried noodle. Note that additional results including demo videos can be see at https://negi111111.github.io/FoodChangeLensProjectHP/.","","978-1-5386-9269-1","10.1109/AIVR.2018.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613665","Deep Learning, Convolutional Neural Network, Generative Adversarial Networks, HoloLens, Food Image Transfer","Virtual reality;Transforms;Geometry;Image generation;Conferences;Shape;Training","convolutional neural nets;food products;learning (artificial intelligence);social networking (online);virtual reality","CNN-based food transformation;HoloLens;food category transformation;food images;food objects;large-scale food image data;typical Japanese foods;FoodChangeLens;conditional CycleGAN;Twitter stream;virtual meal experience","","","","5","","17 Jan 2019","","","IEEE","IEEE Conferences"
"Training with Virtual Operating Room Teammates to Influence Team Behaviors","B. Lok","Univ. of Florida, Gainesville, FL, USA","2016 International Conference on Collaboration Technologies and Systems (CTS)","6 Mar 2017","2016","","","615","616","Imagine you are an operating room nurse. Could training with virtual human teammates empower you to speak up to a bullying teammate? Could virtual teammates change the way you speak as to reduce errors? How about learn new patient safety policies or efficiently transfer care?In this talk, we will explore the emerging area of using virtual humans to subtly influence healthcare teams' teamwork and communication skills. This application of virtual humans could have significant patient safety impact as teamwork and communication is the top reason for adverse events in critical care areas, such as the emergency room, intensive care unit, and operating room.","","978-1-5090-2300-4","10.1109/CTS.2016.0115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7871053","","Training;Virtual reality;Teamwork;Surgery;Virtual groups;Computers","health care;human computer interaction;team working;training;virtual reality","virtual operating room teammates;team behaviors;patient safety policies;virtual humans;healthcare team teamwork;healthcare communication skills;team training","","","","5","","6 Mar 2017","","","IEEE","IEEE Conferences"
"Communication mission-type orders to virtual commanders","M. S. Kleiner; S. A. Carey; J. Beach","Logicon RDA, New Haven, CT, USA; NA; NA","1998 Winter Simulation Conference. Proceedings (Cat. No.98CH36274)","6 Aug 2002","1998","1","","881","885 vol.1","We discuss issues in modeling C4I and cognitive processes in next generation simulations and applications to Force XXI command and control. We propose a modification to the way military operations orders are written and published to achieve simulation/C4I interoperability. We suggest that the standard five-paragraph format be retained but that significant structure be applied to its free text components. We also propose a significant reduction in the size and content of divisional and corps orders, while promoting increased clarity and conciseness in them. We discuss issues related to the transfer of this initiative to field usage. We also address its impact on the next generation of simulations and training in a digitized force structure.","","0-7803-5133-9","10.1109/WSC.1998.745085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=745085","","Computational modeling;Computer simulation;Command and control systems;Context modeling;Runtime;Data mining;Large-scale systems;Humans;Data communication;Natural languages","digital simulation;military computing;computer based training;command and control systems","communication mission-type orders;virtual commanders;C4I modeling;cognitive processes;next generation simulations;Force XXI;command and control;military operations;interoperability;training","","","","","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Online simulation of pedestrian flow in public buildings","Hanisch; Tolujew; Richter; Schulze","Oper. & Autom. IFF, Fraunhofer-Inst. for Factory, Magdeburg, Germany; Oper. & Autom. IFF, Fraunhofer-Inst. for Factory, Magdeburg, Germany; Oper. & Autom. IFF, Fraunhofer-Inst. for Factory, Magdeburg, Germany; NA","Proceedings of the 2003 Winter Simulation Conference, 2003.","30 Jan 2004","2003","2","","1635","1641 vol.2","Online simulation of pedestrian flow in public buildings is a new tool which can be especially useful for improving the aspects of safety and short-term planning in the phase of organizing and operating large public buildings. These might be places such as a train station, an airport or a shopping center. We provide an insight into the different concepts of pedestrian flow simulation. Special emphasis is placed on explaining the mesoscopic approach as applied to the area of traffic simulation. This approach is transferred to the context of analyzing and predicting the pedestrian flow. A first prototypical implementation of a simulation supported control center is briefly presented, also.","","0-7803-8131-9","10.1109/WSC.2003.1261613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1261613","","Buildings;Safety;Airports;Traffic control;Virtual prototyping;Information systems;Air traffic control;Advertising;Shape;Context modeling","digital simulation;Internet;traffic engineering computing","online simulation;pedestrian flow;public buildings;short-term planning;traffic simulation","","12","","14","","30 Jan 2004","","","IEEE","IEEE Conferences"
"Keynote 1: Internet of Things(IoT) and augmented reality for e-learning","N. S. C. Babu",C-DAC Bangalore,"2017 5th National Conference on E-Learning & E-Learning Technologies (ELELTECH)","19 Oct 2017","2017","","","1","10","With the advent of the Internet of Things (IOT) technology, we will be expecting all the smart devices around us to provide various services in real-time. When this IoT technology is combined with Augmented Reality (AR), it will provide end users with real time as well as real world information. One of the prime advantages of AR combining with IoT is the bridging of the gap between the real and digital worlds around us. The ease of downloading features and scope of dynamic usage which AR brings to the smart devices and is expected to bring to the IoT is beyond human imagination! The education sector is expected to gain significantly using these technologies. The goal of technology in education is to make, learning easier, faster and more engaging for the students and to equip the instructor with powerful tools to provide more relevant courseware to their students. With introducing AR in education, we shall be able to provide contextually aware, more relevant, engaging and interactive courseware to the students, which would keep them interested in subject. Also, through IoT, the physical devices can provide context that the AR ecosystem would use for contextually aware rendering of multimedia content. Medical education domain is expected to gain significantly using IOT and AR. It is also observed that the training in the areas of equipment maintenance could gain significantly by applying these technologies judiciously. For eg. The conventional software virtual lab solution does not provide a real feel of performing an experiment. However, using IOT and AR technology, a sensor enabled Hardware based real lab environment can be created for performing the volumetric analysis experiments in chemistry by using WATER instead of Chemicals. C-DAC has developed few AR products in education domain - AR Board, AR Book and AR Game. AR Board is a virtual writing board on which a user can write with a laser pointer. It uses projection based AR Technology by creating a virtual environment for contextual information presentation, and facilitates real-time interaction with the content. AR Book is a standard book that has been instrumented with AR markers printed, which when scanned would show augmented, 3D interactive content, videos, audio and animations contextually, on a printed book, thus adding new dimensionality to it. AR Game is a game based learning mobile application that can be used by students for learning through playing, and for evaluating their knowledge. The technology of these products has been transferred to industry for their further development and proliferation to various educational institutes.","","978-1-5386-1922-3","10.1109/ELELTECH.2017.8074987","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8074987","","","augmented reality;biomedical education;computer aided instruction;computer games;Internet of Things;mobile computing","augmented reality;smart devices;IoT technology;education sector;medical education domain;Internet of Things technology;IoT;e-learning;AR technology;AR board;AR book;AR game;game based learning mobile application","","1","","","","19 Oct 2017","","","IEEE","IEEE Conferences"
"VR-Goggles for Robots: Real-to-Sim Domain Adaptation for Visual Control","J. Zhang; L. Tai; P. Yun; Y. Xiong; M. Liu; J. Boedecker; W. Burgard","Department of Computer Science, University of Freiburg, Breisgau, Germany; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong; Department of Computer Science, University of Freiburg, Breisgau, Germany; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong; Department of Computer Science, University of Freiburg, Breisgau, Germany; Department of Computer Science, University of Freiburg, Breisgau, Germany","IEEE Robotics and Automation Letters","11 Feb 2019","2019","4","2","1148","1155","In this letter, we deal with the reality gap from a novel perspective, targeting transferring deep reinforcement learning (DRL) policies learned in simulated environments to the real-world domain for visual control tasks. Instead of adopting the common solutions to the problem by increasing the visual fidelity of synthetic images output from simulators during the training phase, we seek to tackle the problem by translating the real-world image streams back to the synthetic domain during the deployment phase, to make the robot feel at home. We propose this as a lightweight, flexible, and efficient solution for visual control, as first, no extra transfer steps are required during the expensive training of DRL agents in simulation; second, the trained DRL agents will not be constrained to being deployable in only one specific real-world environment; and third, the policy training and the transfer operations are decoupled, and can be conducted in parallel. Besides this, we propose a simple yet effective shift loss that is agnostic to the downstream task, to constrain the consistency between subsequent frames which is important for consistent policy outputs. We validate the shift loss for artistic style transfer for videos and domain adaptation, and validate our visual control approach in indoor and outdoor robotics experiments.","2377-3766","","10.1109/LRA.2019.2894216","Shenzhen Science and Technology Innovation Commission; German Research Foundation; Research Grant Council of Hong Kong SAR Government, China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8620258","Deep learning in robotics and automation;visual-based navigation;model learning for control","Visualization;Training;Robots;Adaptation models;Semantics;Task analysis;Navigation","control engineering computing;learning (artificial intelligence);mobile robots;robot vision;virtual reality","VR-goggles;real-to-sim domain adaptation;deep reinforcement learning policies;simulated environments;real-world domain;visual control tasks;visual fidelity;synthetic images output;training phase;real-world image streams;synthetic domain;expensive training;trained DRL agents;real-world environment;policy training;transfer operations;consistent policy outputs;artistic style transfer;visual control approach;indoor robotics experiments;outdoor robotics experiments;synthetic image output;real-world image stream translation;DRL agent training;shift loss;domain adaptation","","12","","30","","20 Jan 2019","","","IEEE","IEEE Journals"
"The role of feedback on cognitive motor learning in children with cerebral palsy: A protocol","M. T. Robert; M. F. Levin; R. Guberek; K. Sambasivan; M. F. Levin","Integrated Program of Neuroscience and CRIR, McGill University, Montreal, Canada; Integrated Program of Neuroscience and CRIR, McGill University, Montreal, Canada; School of Physical and Occupational Therapy and CRIR, McGill University, Montreal, Canada; School of Physical and Occupational Therapy and CRIR, McGill University, Montreal, Canada; School of Physical and Occupational Therapy and CRIR, McGill University, Montreal, Canada","2015 International Conference on Virtual Rehabilitation (ICVR)","17 Dec 2015","2015","","","141","142","Evidence of provision of extrinsic feedback for improvement and retention of upper limb kinematics in children with cerebral palsy (CP) is scarce, especially following training interventions using virtual environments. Benefits of using a virtual environment can range from increasing the participant's motivation to the ease of adapting extrinsic feedback for optimizing motor learning. In the proposed research, children with CP will be randomly allocated to one of three groups: no additional feedback, continuous feedback and faded feedback. For all groups, upper-limb motor training will be done in a virtual environment using the Jintronix virtual reality system. Motor improvements will be evaluated after an 8 hour training intervention and motor learning will be evaluated after one month. Transfer of motor gains to performance of a similar upper-limb task will also be used to assess learning. Findings from this research will provide crucial information on which frequency of feedback should be used to optimize motor learning and upper-limb rehabilitation in children with CP.","2331-9569","978-1-4799-8984-3","10.1109/ICVR.2015.7358617","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358617","Cerebral Palsy;Motor learning;Upper limb;Feedback","","feedback;medical computing;medical disorders;neurophysiology;patient rehabilitation;virtual reality","upper-limb rehabilitation;upper-limb task;Jintronix virtual reality system;upper-limb motor training;faded feedback;continuous feedback;additional feedback;extrinsic feedback;virtual environment;training intervention;upper limb kinematics retention;upper limb kinematics improvement;cerebral palsy;cognitive motor learning;time 8 h;time 1 month","","1","","7","","17 Dec 2015","","","IEEE","IEEE Conferences"
