"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Virtual Reality-Based Casting Skill Transfer and Human Resource Development","K. Watanuki","Saitama Univ., Saitama","17th International Conference on Artificial Reality and Telexistence (ICAT 2007)","2 Jan 2008","2007","","","316","317","This paper proposes a new virtual reality-based skill transfer and human resource development system for casting design, which is composed of the explicit and tacit knowledge transfer systems using synchronized multimedia and the knowledge internalization system using portable virtual environment. In our proposed system, the education content is displayed in the immersive virtual environment, whereby a trainee may experience work in the virtual site operation. Provided that the trainee has gained explicit and tacit knowledge of casting through the multimedia-based knowledge transfer system, the immersive virtual environment catalyzes the internalization of knowledge and also enables the trainee to gain tacit knowledge before undergoing on- the-job training at a real-time operation site.","","0-7695-3056-7","10.1109/ICAT.2007.60","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4414664","","Casting;Humans;Virtual environment;Industrial training;Manufacturing industries;Knowledge transfer;On the job training;Force feedback;Multimedia systems;Libraries","casting;computer based training;design;engineering education;human resource management;industrial training;knowledge management;multimedia systems;multiskilling;on-the-job training;production engineering computing;virtual reality","virtual reality-based casting skill transfer;human resource development system;casting design;multimedia-based knowledge transfer system;education content;immersive virtual environment;training;virtual site operation;on-the-job training","","","","1","","2 Jan 2008","","","IEEE","IEEE Conferences"
"Evaluating simulator-based training of skill-based control behavior using multimodal operator models","D. M. Pool; G. A. Harder; H. J. Damveld; M. M. van Paassen; M. Mulder","Control & Simulation, Department Control & Operations, Delft University of Technology, The Netherlands; Control & Simulation, Department Control & Operations, Delft University of Technology, The Netherlands; Control & Simulation, Department Control & Operations, Delft University of Technology, The Netherlands; Control & Simulation, Department Control & Operations, Delft University of Technology, The Netherlands; Control & Simulation, Department Control & Operations, Delft University of Technology, The Netherlands","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","4 Dec 2014","2014","","","3132","3137","This paper describes a novel method for analyzing the training effectiveness for skill-based manual control tasks based on multimodal human operator models. For skill-based tracking tasks, it is known that the adopted human operator dynamics can be modeled accurately with multimodal human operator models. In this paper, estimated human operator model parameters are used to explicitly quantify the changes that occur in the operator's use of visual and motion feedback during skill-acquisition and transfer. A quasi-transfer-of-training experiment is described, in which inexperienced participants were trained to perform an aircraft pitch attitude tracking task, either in a fixed-base or in moving-base simulator environment. After the training phase, the participants were transferred to the other simulator setting, to reveal possible transfer effects. Preliminary results from one participant in each experiment group indicate that the fitted models are successful in revealing the changes that occur in the multimodal manual control characteristics of the participants, and show that convergence to a final skill-based control strategy requires significant training. Furthermore, the presented results suggest that there might be limited direct transfer from training in a fixed-base environment to a moving-base environment.","1062-922X","978-1-4799-3840-7","10.1109/SMC.2014.6974409","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974409","","Training;Visualization;Tracking;Dynamics;Human factors;Delays;Atmospheric measurements","aerospace computing;aircraft control;attitude control;computer based training;control engineering computing;digital simulation","simulator-based training;skill-based manual control behavior;multimodal human operator models;skill-based tracking tasks;human operator dynamics;visual feedback;motion feedback;skill-acquisition;quasitransfer-of-training experiment;aircraft pitch attitude tracking task;fixed-base simulator environment;moving-base simulator environment","","2","","13","","4 Dec 2014","","","IEEE","IEEE Conferences"
"Manipulation of Human Behavior by Distorted Dynamics Vision","H. Kobayashi; Y. Ohyama; H. Hashimoto; J. She","Department of Biomedical Engineering, Osaka Institute of Technology, Osaka, Japan. Tel : +81-6-6654-4489; e-mail: kobayashi@bme.oit.ac.jp; School of Bionics, Tokyo University of Technology, Tokyo, Japan; School of Bionics, Tokyo University of Technology, Tokyo, Japan; School of Bionics, Tokyo University of Technology, Tokyo, Japan","2006 SICE-ICASE International Joint Conference","26 Feb 2007","2006","","","4446","4450","They say that human plans its motion mostly relying on visual information. From this point of view, in this paper the authors attempt to modify transfer characteristics of human operated system by displaying false image of plant whose dynamics is intentionally distorted from the real to enhance performance. Though the proposed method is a kind of human assisting scheme, it doesn't require any physical actuator unlike others and basically only a sensor system and a display device such as LCD monitor are needed. The authors employ simulated inverted pendulum as target plant to be controlled. In previous works, the authors found that there is a relationship between performance of human who is playing inverted pendulum game and his or her gain from eye to extremity at a certain frequency. The dynamics distortion is performed by 2nd order filter which is based on this relationship. The filter is designed to educe potential performance of human thus it is called as ""performance educer"" in this paper. Experiments are made by human subjects, in which they provide higher performance than usual. Finally, the validity of proposed idea is discussed","","89-950038-4-7","10.1109/SICE.2006.314779","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4108300","system identification;transfer function of human;inverted pendulum;distorted dynamics;performance educer;human skill;augmented reality","Humans;Manipulator dynamics;Filters;Actuators;Sensor systems;Liquid crystal displays;Monitoring;Performance gain;Extremities;Frequency","computer games;digital simulation;display devices;human factors;pendulums;transfer functions;visual perception","human behavior;distorted dynamic vision;visual information;human operated system;sensor system;display device;simulated inverted pendulum video game;performance educer;transfer functions","","2","","6","","26 Feb 2007","","","IEEE","IEEE Conferences"
"Transfer of Coordination Skill to the Unpracticed Hand in Immersive Environments","S. Xiao; X. Ye; Y. Guo; B. Gao; J. Long","Jinan University,College of Information Science and Technology,Guangzhou,China,510640; Jinan University,College of Information Science and Technology,Guangzhou,China,510640; Jinan University,College of Information Science and Technology,Guangzhou,China,510640; Jinan University,College of Information Science and Technology,Guangzhou,China,510640; Jinan University,College of Information Science and Technology,Guangzhou,China,510640","2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","11 May 2020","2020","","","258","265","Physical practice with one hand results in performance gains of the other (un-practiced) hand in a unilateral motor task. Yet how it induces performance gains of interlimb coordination in the bimanual movements between trained limb and the opposite, untrained limb is unclear. The present study designed a game-like interactive system for physical practice, in which an avatar’s hands could be controlled itself or by the subject during a bimanual movement task in an immersive virtual reality environment. Participants practiced with the bimanual task by simultaneously drawing non-symmetric three-sided squares (e.g., U and C) to learn limb coordination with the following training strategies: (1) performing and seeing a bimanual task (BH-BH); (2) performing a unimanual task with right hand and seeing a bimanual action (RH-BH); (3) not performing a task but seeing a bimanual action (noH-BH); (4) performing and seeing a unimanual task (RH-RH). We found that the learning performance was better after BH-BH and RH-BH compared with other training strategies. In addition, we examined the effects of virtual hand representations on the learning performance after RH-BH. We found that the performance after training was increased with the realism level of virtual hands. These findings suggest that the proposed approach of RH-BH with realistic virtual hand would result in transfer of coordination skill to the unpracticed hand, which puts forward a new approach for learning and rehabilitation of coordination skill in patients with unilateral motor deficit in immersive environments.","2642-5254","978-1-7281-5608-8","10.1109/VR46266.2020.00045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9089455","Avatar hands;bimanual movement;coordination skill;virtual reality","Training;Task analysis;Visualization;Thumb;Shape;Virtual reality","","","","","","27","","11 May 2020","","","IEEE","IEEE Conferences"
"Skill transfer in a simulated underactuated dynamic task","M. K. O'Malley; A. Gupta","Mech. Eng. & Material Sci., Rice Univ., Houston, TX, USA; Mech. Eng. & Material Sci., Rice Univ., Houston, TX, USA","The 12th IEEE International Workshop on Robot and Human Interactive Communication, 2003. Proceedings. ROMAN 2003.","19 Dec 2003","2003","","","315","320","Machine-mediated teaching of dynamic task completion is typically implemented with passive intervention via virtual fixtures or active assist by means of record and replay strategies. During interaction with a real dynamic system however, the user relies on both visual and haptic feedback in order to elicit desired motions. This work investigates skill transfer from assisted to unassisted modes for a Fitts' type targeting task with an underactuated dynamic system. Performance, in terms of between target tap times, is measured during an unassisted baseline session and during various types of assisted training sessions. It is hypothesized that passive and active assist modes that are implemented during training of a dynamic task could improve skill transfer to a real environment or unassisted simulation of the task. Results indicate that transfer of skill is slight but significant for the assisted training modes.","","0-7803-8136-X","10.1109/ROMAN.2003.1251864","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1251864","","Haptic interfaces;Education;Displays;Fixtures;Humans;Virtual reality;Force feedback;Shape control;Control systems;Mechanical engineering","haptic interfaces;computer based training;virtual reality;learning (artificial intelligence)","underactuated dynamic system;Fitts' type;skill transfer;haptic feedback","","3","","22","","19 Dec 2003","","","IEEE","IEEE Conferences"
"Analyze assembly skills using a motion simulator","Feng Duan; Jeffrey Too Chuan Tan; Ye Zhang; Kei Watanabe; Nuttapol Pongthanya; Masao Sugi; Hiroshi Yokoi; Tamio Arai","Department of Precision Engineering, School of Engineering, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656 Japan; Department of Precision Engineering, School of Engineering, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656 Japan; Department of Precision Engineering, School of Engineering, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656 Japan; Department of Precision Engineering, School of Engineering, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656 Japan; Department of Precision Engineering, School of Engineering, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656 Japan; Department of Precision Engineering, School of Engineering, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656 Japan; Department of Precision Engineering, School of Engineering, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656 Japan; Department of Precision Engineering, School of Engineering, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-8656 Japan","2007 IEEE International Conference on Robotics and Biomimetics (ROBIO)","16 May 2008","2007","","","1428","1433","Many researchers have focused on transferring human skills to robots by extracting those skills into the machine- understandable models. It is an important step towards creating an intelligent robot in a cooperative environment. These models not only can be employed to transfer human control strategy to robots, but also can be used to improve the new workers' performance. In this paper, we propose a method that is to extract the advantages of several operators' skills and synthesize new skills to train new workers. To realize the skill extract, synthesis and transfer system, it is absolutely necessary to reproduce and synthesize the experts' motions. In the latter case, a kinematic simulator of human body is employed to realize the synthesis of the operators' motions based on the detected motion data. To verify the proposed method, we employed it to execute a peg-in-hole assembly task. The results show that after training by the synthesized skill model, the new operator's performance is improved significantly.","","978-1-4244-1761-2","10.1109/ROBIO.2007.4522374","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4522374","Human Skill Transfer;Motion Tracking;Kinematic Simulator of Human Body;Direct Linear Transformation Method","Motion analysis;Analytical models;Humans;Control system synthesis;Biological system modeling;Robotic assembly;Intelligent robots;Robot control;Data mining;Kinematics","humanoid robots;intelligent robots;motion control;robot kinematics","assembly skills;motion simulator;intelligent robot;human control strategy;expert motions;kinematic simulator;peg-in-hole assembly task;synthesized skill;human skill transfer;motion tracking","","6","","12","","16 May 2008","","","IEEE","IEEE Conferences"
"The effects of presentation method and simulation fidelity on psychomotor education in a bimanual metrology training simulation","J. Bertrand; A. Bhargava; K. C. Madathil; A. Gramopadhye; S. V. Babu","Clemson University, USA; Clemson University, USA; Clemson University, USA; Clemson University, USA; Clemson University, USA","2017 IEEE Symposium on 3D User Interfaces (3DUI)","6 Apr 2017","2017","","","59","68","In this study, we empirically evaluated the effects of presentation method and simulation fidelity on task performance and psychomotor skills acquisition in an immersive bimanual simulation towards precision metrology education. In a 2 × 2 experiment design, we investigated a large-screen immersive display (LSID) with a head-mounted display (HMD), and the presence versus absence of gravity. Advantages of the HMD include interacting with the simulation in a more natural manner as compared to using a large-screen immersive display due to the similarities between the interactions afforded in the virtual compared to the real-world task. Suspending the laws of physics may have an effect on usability and in turn could affect learning outcomes. Our dependent variables consisted of a pre and post cognition questionnaire, quantitative performance measures, perceived workload and system usefulness, and a psychomotor assessment to measure to what extent transfer of learning took place from the virtual to the real world. Results indicate that the HMD condition was preferable to the immersive display in several metrics while the no-gravity condition resulted in users adopting strategies that were not advantageous for task performance.","","978-1-5090-6716-9","10.1109/3DUI.2017.7893318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7893318","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems—Artificial, augmented, and virtual realities","Solid modeling;Training;Aerospace electronics;Resists;Metrology;Visualization;Gravity","computer based training;digital simulation;helmet mounted displays;measurement;virtual reality","presentation method;simulation fidelity;psychomotor education;bimanual metrology training simulation;psychomotor skill acquisition;immersive bimanual simulation;precision metrology education;large-screen immersive display;LSID;head-mounted display;HMD;no-gravity condition","","3","","36","","6 Apr 2017","","","IEEE","IEEE Conferences"
"Between-Subject Variability in Transfer-of-Training of Skill-Based Manual Control Behavior","D. M. Pool; P. M. T. Zaal","Delft Univ. of Technol., Delft, Netherlands; NASA Ames Res. Center, Jose State Univ., Moffett Field, CA, USA","2015 IEEE International Conference on Systems, Man, and Cybernetics","14 Jan 2016","2015","","","1094","1099","This paper describes a new approach for analyzing training effectiveness in transfer-of-training experiments, by considering the between-subject variability of post-transfer changes in task performance and control activity of individual trained pilots. First, exponential learning curve models were fit on experimental data of individual pilots. Second, curve parameters were used to analyze the immediate changes in task performance and control gain following transfer, and the correlation between immediate changes in task performance and continued learning rate after transfer. Data from two experiments with different experimental designs were compared using the new approach. The method revealed similar post-transfer effects in the immediate changes in task performance and control gain following transfer between the two experiments when pilots trained without motion. However, differences in post-transfer effects were found when comparing the correlations between the immediate change in task performance and learning rate. In addition, differences were found between participant groups training with different levels of flight simulator motion fidelity.","","978-1-4799-8697-2","10.1109/SMC.2015.196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379328","","Training;NASA;Correlation;Tracking;Human factors;Dynamics;Data models","aerospace computing;aerospace simulation;aircraft control;computer based training","between-subject variability;skill-based manual control behavior;training effectiveness analysis;transfer-of-training experiment;task performance;control activity;pilot training;exponential learning curve model;curve parameters;control gain;learning rate;flight simulator motion fidelity","","","","12","","14 Jan 2016","","","IEEE","IEEE Conferences"
"“Woodlands” - a Virtual Reality Serious Game Supporting Learning of Practical Road Safety Skills","K. Szczurowski; M. Smith","Department of Informatics, Institute of Technology Blanchardstown, Dublin, Ireland; Department of Informatics, Institute of Technology Blanchardstown, Dublin, Ireland","2018 IEEE Games, Entertainment, Media Conference (GEM)","1 Nov 2018","2018","","","1","9","In developed societies road safety skills are taught early and often practiced under the supervision of a parent, providing children with a combination of theoretical and practical knowledge. At some point children will attempt to cross a road unsupervised, at that point in time their safety depends on the effectiveness of their road safety education. To date, various attempts to supplement road safety education with technology were made. Most common approach focus on addressing declarative knowledge, by delivering road safety theory in an engaging fashion. Apart from expanding on text based resources to include instructional videos and animations, some stakeholders (e.g.: Irish Road Safety Authority) attempt to take advantage of game-based learning [1]. However, despite the high capacity for interaction being common in Virtual Environments, available game-based solutions to road safety education are currently limited to delivering and assessing declarative knowledge. With recent advancements in the field of Virtual Reality (VR) Head Mounted Displays, procedural knowledge might also be addressed in Virtual Environments. This paper describes the design and development process of a computer-supported learning system that attempts to address psycho-motor skills involved in crossing a road safely, changing learners' attitude towards road safety best practices, and enabling independent practice of transferable skills. By implementing game-based learning principles and following best practice for serious game design (such as making educational components essential to successful game-play, or instructional scaffolding) we hope to make it not only more effective, but also engaging, allowing us to rely on learners' intrinsic motivation [2], to increase their independent practice time and provide them with feedback that will help to condition safe behaviour and increase retention. Presence in Virtual Reality might evoke responses to Virtual Environment as if it was real (RAIR) [3] and enable learners to truly experience learning scenarios. In consequence leading to formation of autobiographical memories constructed from multisensory input, which should result in an increased knowledge retention and transfer [4].","","978-1-5386-6304-2","10.1109/GEM.2018.8516493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516493","Virtual Reality;VR;Road Safety;Serious Game;Experiential Learning;Game-Based Learning;Virtual Environment","Games;Road safety;Virtual environments;Training","computer aided instruction;helmet mounted displays;road safety;serious games (computing);virtual reality","road safety education;declarative knowledge;road safety theory;road safety best practices;serious game design;virtual reality serious game;virtual environment;virtual reality head mounted displays;Woodlands;game-based learning","","4","","34","","1 Nov 2018","","","IEEE","IEEE Conferences"
"Video game experience and basic robotic skills","A. Tanaka; R. Smith; C. Hughes","The Nicholson Center, Florida Hospital, Celebration, US; The Nicholson Center, Florida Hospital, Celebration, US; Department of Computer Science, The University of Central Florida, Orlando, US","2016 IEEE International Conference on Serious Games and Applications for Health (SeGAH)","10 Oct 2016","2016","","","1","6","Virtual reality simulators have emerged as valuable tools for standardized and objective robotic surgery skill training and assessments. In recent years the idea of using video game technology in surgical education for laparoscopy has also been explored, however few have attempted to make a connection between video game experience and robotic surgical skills. Thus, the current study aims to examine the performance of video gamers in a virtual reality robotic surgery simulator. Furthermore, the video gamers' performance was compared to that of medical students, expert robotic surgeons, and “laypeople.” The purpose of this study is to demonstrate that video gamers acquire perceptual and psychomotor skills through video game play, similar to those used by robotic surgeons. Subjects completed a demographic questionnaire and performed three computer-based perceptual tests: a Flanker compatibility task, a subsidizing task, and a Multiple Object Tracking test. Participants then performed two warm-up exercises and eight trials of two core exercises on a robotic surgery simulator. After completing all trials, participants completed a post-questionnaire regarding their experience with the system. Expert video gamers (n=40), medical students (n=24), laypeople (n=42) and expert robotic surgeons (n=16) were recruited. Medical students and gamers were significantly faster than experts in the Flanker Task. The experts were significantly slower than the all other groups in the subsidizing task. Experts scored significantly higher, were significantly more efficient, and were significantly faster than laypeople, medical students, and gamers in the first trial of Ring & Rail 1 and Suture Sponge. In trial eight of the simulation exercises, the experts performed significantly better than most groups in all of the metrics. Contrary to prior literature in laparoscopy, this study was unable to validate enhanced abilities of video gamers in a robotic surgery simulator. This study does further demonstrate that the transfer of skills developed through video game play is relevant to the surgical technique. This may be due to the differences of the systems and how the users interact within them. In a society where video games have become an integral past time, it is important to determine the role that video games play in the perceptual and psychomotor development of users. These findings can be generalized to domains outside of medicine that utilize robotic and computer-controlled systems, speaking to the scope of the gamers' abilities and pointing to the capacity within these systems.","","978-1-5090-2210-6","10.1109/SeGAH.2016.7586262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7586262","","Surgery;Robots;Measurement;Games;Training;Rails;Cameras","biomedical education;computer aided instruction;computer games;educational robots;human-robot interaction;medical computing;medical robotics;surgery;virtual reality","video game experience;basic robotic skills;virtual reality robotic surgery simulator;standardized robotic surgery skill training;objective robotic surgery skill training;standardized robotic surgery skill assessment;objective robotic surgery skill assessment;surgical education;laparoscopy;video game technology;perceptual skill acquisition;psychomotor skill acquisition;computer-based perceptual tests;flanker compatibility task;subsidizing task;multiple object tracking test;computer-controlled systems","","1","","17","","10 Oct 2016","","","IEEE","IEEE Conferences"
"Prenatal to postnatal transfer of motor skills through motor-compatible sensory representations","T. A. Mann; Y. Choe","Department of Computer Science and Engineering, Texas A&M University, College Station, TX 77843; Department of Computer Science and Engineering, Texas A&M University, College Station, TX 77843","2010 IEEE 9th International Conference on Development and Learning","20 Sep 2010","2010","","","185","190","How can sensory-motor skills developed as a fetus transfer to postnatal life? We investigate a simulated reaching task by training controllers under prenatal conditions (i.e. confined space) and evaluating them based on postnatal conditions (i.e. targets outside of the confined training space). One possible solution is to identify a sensory representation that is easy to extrapolate over. We compared two kinds of sensory representations: world-centered sensory representation based on Cartesian coordinates and agent-centered sensory representation based on polar coordinates. Despite similar performance under prenatal conditions, controllers using agent-centered sensory representation had significantly better performance than controllers using world-centered sensory representation under postnatal conditions. It turns out that the success of the agent-centered sensory representation is (in part) due to being complementary to the action encodings. Further analysis shows that the action encodings (i.e. changes in joint angles) were highly predictive of the change in state when agent-centered sensory representation was used (but not world-centered). This suggests that a powerful strategy for transferring sensory-motor skills to postnatal life involves selecting a sensory representation that complements the action encodings used by an agent.","2161-9476","978-1-4244-6902-4","10.1109/DEVLRN.2010.5578844","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5578844","","Joints;Optical wavelength conversion;Training;Elbow;Shoulder;Encoding;Fetus","biomechanics;cognition;medical computing;obstetrics;paediatrics","prenatal transfer;postnatal transfer;motor skills;motor-compatible sensory representations;sensory-motor skills;fetus;reaching task;extrapolation;Cartesian coordinates;agent-centered sensory representation;action encodings","","4","","18","","20 Sep 2010","","","IEEE","IEEE Conferences"
"Practice and exploration of skills transfer theory in swimming teaching","L. Ting","Swimming teaching and research facilities. Wuhan Inst. of P.E., Wuhan 430079, P.R. China","2009 ISECS International Colloquium on Computing, Communication, Control, and Management","29 Sep 2009","2009","1","","457","460","This paper combines theories with practice, explores and discusses the general principles of swimming instruction, applies techniques of skill transfer and proposes way to apply to actual teaching situations. Furthermore, according to the theories of technical transference, and adapting the experimental methods (comparing and programming covered in three groups), this paper verifies the transferring status and relationship of three types of swimming skills: a.) simulative ability practice; b.) underwater swimming; c.) breathing - at different teaching phases technique-ambination. Thus I draw a conclusion that all the techniques and skills are somehow interrelated and directly affects students studying and grasping of these swimming techniques and skills. This paper is also significant for us to promote and accelerate the teaching process and will accomplish the mission of teaching swimming more successfully.","2154-963X","978-1-4244-4247-8","10.1109/CCCM.2009.5268084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5268084","Swimming teaching;Skill transference;Module comparing;Effects","Education;Testing;Interference;Communication system control;Acceleration;Impedance;Educational institutions;Stress;Timing;Aging","teaching","skills transfer theory;swimming teaching;swimming instruction;technical transference;experimental methods;simulative ability practice;underwater swimming","","","","6","","29 Sep 2009","","","IEEE","IEEE Conferences"
"EMG and Kinematic Responses to Unexpected Slips After Slip Training in Virtual Reality","P. Parijat; T. E. Lockhart; J. Liu","School of Biomedical Engineering and Science, Virginia Tech, Blacksburg, VA, USA; School of Biological and Health Systems Engineering, Arizona State University, Tempe, AZ, USA; Division of Applied Science and Technology, Marshall University, Huntington, WV, USA","IEEE Transactions on Biomedical Engineering","16 Jan 2015","2015","62","2","593","599","The objective of the study was to design a virtual reality (VR) training to induce perturbation in older adults similar to a slip and examine the effect of the training on kinematic and muscular responses in older adults. Twenty-four older adults were involved in a laboratory study and randomly assigned to two groups (VR training and control). Both groups went through three sessions including baseline slip, training, and transfer of training on slippery surface. The training group experienced 12 simulated slips using a visual perturbation induced by tilting a VR scene while walking on the treadmill and the control group completed normal walking during the training session. Kinematic, kinetic, and electromyography data were collected during all the sessions. Results demonstrated the proactive adjustments such as increased trunk flexion at heel contact after training. Reactive adjustments included reduced time to peak activations of knee flexors, reduced knee coactivation, reduced time to trunk flexion, and reduced trunk angular velocity after training. In conclusion, the study findings indicate that the VR training was able to generate a perturbation in older adults that evoked recovery reactions and such motor skill can be transferred to the actual slip trials.","1558-2531","","10.1109/TBME.2014.2361324","NSF; NIOSH; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6915881","Elderly;electromyography (EMG);fall prevention training;falls;virtual reality (VR)","Training;Legged locomotion;Muscles;Electromyography;Knee;Virtual reality;Kinematics","electromyography;gait analysis;kinematics;medical signal processing;perturbation theory;virtual reality","EMG;kinematic responses;unexpected slips;slip training;virtual reality training;older adults;muscular responses;VR training;VR control;baseline slip;slippery surface;visual perturbation;VR scene;treadmill;normal walking;training session;electromyography data collection;proactive adjustments;trunk flexion;heel contact;knee flexors;peak activations;reduced knee coactivation;reduced trunk angular velocity;evoked recovery reactions;motor skill;actual slip trials","Accidental Falls;Aged;Biofeedback, Psychology;Electromyography;Female;Gait;Humans;Male;Muscle Contraction;Photic Stimulation;Physical Stimulation;Postural Balance;Psychomotor Performance;Treatment Outcome;User-Computer Interface;Virtual Reality Exposure Therapy","13","","33","","3 Oct 2014","","","IEEE","IEEE Journals"
"Adversarial Skill Networks: Unsupervised Robot Skill Learning from Video","O. Mees; M. Merklinger; G. Kalweit; W. Burgard","University of Freiburg,Germany; University of Freiburg,Germany; University of Freiburg,Germany; Toyota Research Institute,Los Altos,USA","2020 IEEE International Conference on Robotics and Automation (ICRA)","15 Sep 2020","2020","","","4188","4194","Key challenges for the deployment of reinforcement learning (RL) agents in the real world are the discovery, representation and reuse of skills in the absence of a reward function. To this end, we propose a novel approach to learn a task-agnostic skill embedding space from unlabeled multi-view videos. Our method learns a general skill embedding independently from the task context by using an adversarial loss. We combine a metric learning loss, which utilizes temporal video coherence to learn a state representation, with an entropy-regularized adversarial skill-transfer loss. The metric learning loss learns a disentangled representation by attracting simultaneous viewpoints of the same observations and repelling visually similar frames from temporal neighbors. The adversarial skill-transfer loss enhances re-usability of learned skill embeddings over multiple task domains. We show that the learned embedding enables training of continuous control policies to solve novel tasks that require the interpolation of previously seen skills. Our extensive evaluation with both simulation and real world data demonstrates the effectiveness of our method in learning transferable skills from unlabeled interaction videos and composing them for new tasks. Code, pretrained models and dataset are available at http://robotskills.cs.uni-freiburg.de.","2577-087X","978-1-7281-7395-5","10.1109/ICRA40945.2020.9196582","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9196582","","Task analysis;Entropy;Measurement;Training;Robots;Interpolation;Learning (artificial intelligence)","interactive video;learning (artificial intelligence);robot vision;video signal processing","adversarial skill-transfer loss;task domain;learned skill embeddings;entropy-regularized adversarial skill-transfer loss;temporal video coherence;metric learning loss;adversarial loss;task context;unlabeled multiview videos;task-agnostic skill embedding space;reinforcement learning agents;unsupervised robot skill learning;adversarial skill networks;learned embedding","","1","","33","","15 Sep 2020","","","IEEE","IEEE Conferences"
"Experience with head-mounted virtual reality (HMD-VR) predicts transfer of HMD-VR motor skills","J. M. Juliano; D. Saldana; A. Schmiesing; S. Liew","University of Southern California (USC),Neuroscience Graduate Program,Los Angeles,CA,USA; University of Southern California,Chan Division of Occupational,Los Angeles,CA,USA; University of Southern California,Chan Division of Occupational,Los Angeles,CA,USA; University of Southern California,Chan Division of Occupational,Los Angeles,CA,USA","2019 International Conference on Virtual Rehabilitation (ICVR)","13 Feb 2020","2019","","","1","2","Immersive, head-mounted virtual reality (HMD-VR) has the potential to be a useful tool for motor rehabilitation. However, when developing tools for rehabilitation, it is essential to design interventions that will be most effective for generalizing to the real world. Therefore, it is important to understand what factors facilitate transfer from HMD-VR to non-HMD-VR environments. Here we used a well-established test of skilled motor learning, the Sequential Visual Isometric Pinch Task (SVIPT), to train healthy individuals in an HMD-VR environment. We examined whether learned motor skills transferred to a more conventional (non-HMD-VR) environment and what factors facilitated transfer. Our results suggest that on average, learned motor skills from this task transfer from an immersive virtual environment to a conventional environment; however, some individuals did not transfer the learned motor skills. We then examined individual differences between those that did show transfer and those that did not. We found that individuals who had previous exposure to HMD-VR were more likely to transfer their learned motor skills than those who did not. Individual differences in previous exposure to HMD-VR environments prior to training may serve as a predictor to whether learned motor skills will transfer out of HMD-VR.","2331-9569","978-1-7281-1285-5","10.1109/ICVR46560.2019.8994345","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994345","head-mounted virtual reality;skilled motor learning;transfer","","biomechanics;helmet mounted displays;learning (artificial intelligence);patient rehabilitation;virtual reality","HMD-VR environment;learned motor skills;head-mounted virtual reality;HMD-VR motor skills;motor rehabilitation;nonHMD-VR environments;skilled motor learning;immersive virtual environment","","","","9","","13 Feb 2020","","","IEEE","IEEE Conferences"
"Implementing overground turning on a linear treadmill","H. Park; S. H. Chae; J. W. Yoon; J. Kim; A. Sudduth; C. Stanley","Department of Mechanical Engineering, KAIST, Daejeon, Korea; Department of Mechanical Engineering, KAIST, Daejeon, Korea; Department of Mechanical Engineering, Gyeongsang National University, Jinju, Korea; Department of Robotics Engineering, DGIST, Daegu, Korea; Rehabilitation Medicine Department, National Institutes of Health, Bethesda, USA; Rehabilitation Medicine Department, National Institutes of Health, Bethesda, USA","2015 12th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)","17 Dec 2015","2015","","","390","391","The purpose of treadmill-based locomotor training is to transfer walking skills obtained from training to real world walking (overground: OG). For optimal skill transfer, treadmill-based training should simulate OG as closely as possible. The constant speed of a standard treadmill encourages automaticity rather than engagement and fails to simulate the variable speeds encountered during OG walking. Our effort to overcome this limitation has focused on developing user-driven treadmill (UDT) velocity control schemes that allow the user to freely change walking speed and feel the same inertial force that they feel during OG walking. In this study, we have combined the user driven treadmill control with the virtual reality (VR) display to simulate realistic turning in a safe environment.","","978-1-4673-7971-7","10.1109/URAI.2015.7358882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358882","Gait Rehabilitation;Turning;User-driven Treadmill;Virtual Reality","Turning;Legged locomotion;Virtual reality;Electronic mail;Training;Velocity control","force control;gait analysis;patient rehabilitation;velocity control;virtual reality","overground turning;linear treadmill;treadmill-based locomotor training;walking skills;optimal skill transfer;user-driven treadmill;velocity control;inertial force;virtual reality;VR display;walking speed","","","","4","","17 Dec 2015","","","IEEE","IEEE Conferences"
"An audio game for training navigation skills of blind children","K. Allain; B. Dado; M. Van Gelderen; O. Hokke; M. Oliveira; R. Bidarra; N. D. Gaubitch; R. C. Hendriks; B. Kybartas","Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science Delft University of Technology The Netherlands","2015 IEEE 2nd VR Workshop on Sonic Interactions for Virtual Environments (SIVE)","28 Dec 2015","2015","","","1","4","Training blind children to use audio-based navigation is a demanding and risky task, as children can walk into objects and hurt themselves. Furthermore, training outdoors is dangerous due to traffic, noise and weather conditions. Having a controlled indoor environment is safer but not always available. To tackle this problem, we developed an audio-based computer game, Legend of Iris (LOI), specifically designed to train navigation skills. The game is a 3D exploration game, which uses the headtracking capabilities of the Oculus Rift to create an immersive experience, and the new sound libraries AstoundSound and Phonon3D, to generate an accurate and realistic soundscape. These libraries use a head-related transfer function, allowing the player to localize the audio source in 3D space. The design of LOI involved selecting sounds that are easily recognizable to provide cues to blind people playing the game. A subset of these cues were incorporated into the game. To verify the effectiveness of the game in developing audio orientation and navigation skills, we performed a preliminary qualitative experiment with blind children in a dedicated school. LOI scored high in terms of accuracy and immersion, but a larger test is required to make statistical conclusions.","","978-1-4799-1969-7","10.1109/SIVE.2015.7361292","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7361292","","Games;Navigation;Training;Libraries;Visualization;Three-dimensional displays;Transfer functions","acoustic noise;hearing;transfer functions","audio game;training navigation skills;training blind children;audio-based navigation;risky task;training outdoors;traffic condition;weather condition;noise condition;controlled indoor environment;audio-based computer game;train navigation skills;3D exploration game;headtracking capability;sound libraries;phonon3D;realistic soundscape;head-related transfer function;audio source;3D space;blind people;audio orientation;statistical conclusion","","7","","12","","28 Dec 2015","","","IEEE","IEEE Conferences"
"Enhancing Learning Transfer: A Case Study of a Learning Simulation Game-Farmtasia","Y. Zhou; M. Wang; Y. Chen","Inf. Coll., Yunnan Normal Univ., Kunming, China; Shanghai Int. Studies Univ., Shanghai, China; Old Dominion Univ., Norfolk, VA, USA","2014 International Conference on Intelligent Environments","29 Sep 2014","2014","","","289","296","The occurrence of learning transfer is an important criterion for checking whether learning has taken place. In recent years, simulation games have been applied widely in the field of skill training and education. But research about whether learning transfer occurs in simulation games is still limited. This paper aims to examine whether learning transfer occurs among learners and to explore the characteristics of the transfer, if any, occur, when they play a learning simulation game called Farmtasia 2. The case study shows students provided with question prompts are more likely to have learning transfer, and they can reach a cognitive level of analysis, synthesis, and evaluation. In contrast, students not provided with question prompts are more likely to think about the questions they had in the game at a level between factual and conceptual understanding. They did not show activities that require higher order thinking and evidence the occurrence of learning transfer.","","978-1-4799-2947-4","10.1109/IE.2014.62","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6910465","Simulation Game;Learning Transfer;Question prompts;Farmtasia","Games;Context;Agriculture;Educational institutions;Meteorology;Production","computer games;learning (artificial intelligence)","learning transfer;learning simulation game;farmtasia;skill training and education;factual understanding;conceptual understanding;higher order thinking","","","","27","","29 Sep 2014","","","IEEE","IEEE Conferences"
"The role of dimensional symmetry on bimanual psychomotor skills education in immersive virtual environments","J. Bertrand; D. Brickler; S. Babu; K. Madathil; M. Zelaya; T. Wang; J. Wagner; A. Gramopadhye; J. Luo",Clemson University; Clemson University; Clemson University; Clemson University; Clemson University; Clemson University; Clemson University; Clemson University; Clemson University,"2015 IEEE Virtual Reality (VR)","27 Aug 2015","2015","","","3","10","The need for virtual reality applications for education and training involving bimanual dexterous activities has been increasing in recent years. However, it is unclear how the amount of correspondence between a virtual interaction metaphor to the real-world equivalent, otherwise known as dimensional symmetry, affects bimanual pscyhomotor skills training and how skills learned in the virtual simulation transfer to the real world. How does the number of degrees of freedom enhance or hinder the learning process? Does the increase in dimensional symmetry affect cognitive load? In an empirical evaluation, we compare the effectiveness of a natural 6-DOF interaction metaphor to a simplified 3-DOF metaphor. Our simulation interactively educates users in the step-by-step process of taking a precise measurement using calipers and micrometers in a simulated technical workbench environment. We conducted a usability study to evaluate the user experience and pedagogical benefits using measures including a pre and post cognition questionnaire over all levels of Bloom's taxonomy, workload assessment, system usability, and real world psychomotor assessment tasks. Results from the pre and post cognition questionnaires suggest that learning outcomes improved throughout all levels of Bloom's taxonomy for both conditions, and trends in the data suggest that the 6-DOF metaphor was more effective in real-world skill transference compared to the 3-DOF metaphor.","2375-5334","978-1-4799-1727-3","10.1109/VR.2015.7223317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223317","Bimanual interaction;psychomotor skills education;dimensional symmetry","Atmospheric measurements;Particle measurements;Instruments;Training;Metrology;Solid modeling","computer aided instruction;user interfaces;virtual reality","dimensional symmetry role;bimanual psychomotor skills education;immersive virtual environment;virtual reality applications;education application;training application;virtual simulation;learning process;cognitive load;natural 6-DOF interaction;degrees-of-freedom;calipers;micrometers;user experience;pedagogical benefits;psychomotor assessment tasks;Bloom taxonomy;bimanual dexterous activities","","9","","27","","27 Aug 2015","","","IEEE","IEEE Conferences"
"Simulation Based Approach To Modeling Product And Process Interactions","Suresh Palaniswamy; Nanua Singh",Wayne State University; NA,"Innovation in Technology Management. The Key to Global Leadership. PICMET '97","18 Sep 2006","1997","","","956","956","Summary form only given. In this paper some of the policy issues in the transfer of technology to developing countries are examined. Technology transfer is considered within the context of production function by which the role of a given technology transfer policy in promoting the production of goods and services is discussed. It is argued that several factors influence the effective implementation of a given policy option. These include: (a) availability of materials may be are referred to as the hardware; (b) technical know-how and skilled work forces referred to as the software; and (c) the necessary organization in the which integration of capital and a skilled work force can take place. Other factors such as government policies and socio-cultural attitude towards learning and work habits of the recipient country may also significantly influence the implementation of a given technology transfer plan. As such, no single policy option can be considered to be an optimum policy to be applied in all of the developing countries.","","0-7803-3574-0","10.1109/PICMET.1997.623635","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=623635","","Costs;Product development;Manufacturing industries;Manufacturing processes;Stability;Lead time reduction;Product design","research and development management;technology transfer;government policies","technology transfer;developing countries;policy issues;production function;technical know-how;skilled workforce;organization;government policies;socio-cultural attitude;recipient country","","","","","","18 Sep 2006","","","IEEE","IEEE Conferences"
"Perceptually Augmented Simulator Design","T. Edmunds; D. K. Pai","University of British Columbia, Vancouver; University of British Columbia, Vancouver","IEEE Transactions on Haptics","9 Mar 2012","2012","5","1","66","76","Training simulators have proven their worth in a variety of fields, from piloting to air-traffic control to nuclear power station monitoring. Designing surgical simulators, however, poses the challenge of creating trainers that effectively instill not only high-level understanding of the steps to be taken in a given situation, but also the low-level “muscle-memory” needed to perform delicate surgical procedures. It is often impossible to build an ideal simulator that perfectly mimics the haptic experience of a surgical procedure, but by focussing on the aspects of the experience that are perceptually salient we can build simulators that effectively instill learning. We propose a general method for the design of surgical simulators that augment the perceptually salient aspects of an interaction. Using this method, we can increase skill-transfer rates without requiring expensive improvements in the capability of the rendering hardware or the computational complexity of the simulation. In this paper, we present our decomposition-based method for surgical simulator design, and describe a user-study comparing the training effectiveness of a haptic-search-task simulator designed using our method versus an unaugmented simulator. The results show that perception-based task decomposition can be used to improve the design of surgical simulators that effectively impart skill by targeting perceptually significant aspects of the interaction.","2329-4051","","10.1109/TOH.2011.42","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5975145","Haptic I/O;artificial;augmented;and virtual realities;life and medical sciences;surgical simulation.","Haptic interfaces;Surgery;Training;Needles;Rendering (computer graphics);Surface roughness;Rough surfaces","augmented reality;computer based training;haptic interfaces;medical computing;surgery","perceptually augmented simulator design;training simulator;air-traffic control;piloting;nuclear power station monitoring;surgical simulator;low-level muscle-memory;surgical procedure;haptic experience;salient interaction aspect;skill-transfer rate;rendering hardware;computational complexity;decomposition-based method;user study;haptic-search-task simulator;unaugmented simulator;perception-based task decomposition","","2","","21","","4 Aug 2011","","","IEEE","IEEE Journals"
"Transfer of a skilled motor learning task between virtual and conventional environments","J. Anglin; D. Saldana; A. Schmiesing; S. Liew","University of Southern California, Los Angeles, California, United States of America; University of Southern California, Los Angeles, California, United States of America; University of Southern California, Los Angeles, California, United States of America; University of Southern California, Los Angeles, California, United States of America","2017 IEEE Virtual Reality (VR)","6 Apr 2017","2017","","","401","402","Immersive, head-mounted virtual reality (HMD-VR) can be a potentially useful tool for motor rehabilitation. However, it is unclear whether the motor skills learned in HMD-VR transfer to the non-virtual world and vice-versa. Here we used a well-established test of skilled motor learning, the Sequential Visual Isometric Pinch Task (SVIPT), to train individuals in either an HMD-VR or conventional training (CT) environment. Participants were then tested in both environments. Our results show that participants who train in the CT environment have an improvement in motor performance when they transfer to the HMD-VR environment. In contrast, participants who train in the HMD-VR environment show a decrease in skill level when transferring to the CT environment. This has implications for how training in HMD-VR and CT may affect performance in different environments.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892346","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892346","Virtual reality;skilled motor learning;transfer","Training;Logic gates;Virtual reality;Computed tomography;Electroencephalography;Visualization;Indexes","medical computing;patient rehabilitation;virtual reality","skilled motor learning task;virtual environments;head-mounted virtual reality;HMD-VR;motor rehabilitation;sequential visual isometric pinch task;SVIPT;conventional training environment;CT environment","","8","","4","","6 Apr 2017","","","IEEE","IEEE Conferences"
"Influences on the Elicitation of Interpersonal Space with Virtual Humans","D. M. Krum; S. Kang; T. Phan","University of Southern California, Institute for Creative Technologies; University of Southern California, Institute for Creative Technologies; University of Southern California, Institute for Creative Technologies","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","223","9","The emergence of low cost virtual and augmented reality systems has encouraged the development of immersive training applications for medical, military, and many other fields. Many of the training scenarios for these various fields may require the presentation of realistic interactions with virtual humans. It is thus vital to determine the critical factors of fidelity required in those interactions to elicit naturalistic behavior on the part of trainees. Negative training may occur if trainees are inadvertently influenced to react in ways that are unexpected and unnatural, hindering proper learning and transfer of skills and knowledge back into real world contexts. In this research, we examined whether haptic priming (presenting an illusion of virtual human touch at the beginning of the virtual experience) and different locomotion techniques (either joystick or physical walking) might affect proxemic behavior in human users. The results of our study suggest that locomotion techniques can alter proxemic behavior in significant ways. Haptic priming did not appear to impact proxemic behavior, but did increase rapport and other subjective social measures. The results suggest that designers and developers of immersive training systems should carefully consider the impact of even simple design and fidelity choices on trainee reactions in social interactions.","","978-1-5386-3365-6","10.1109/VR.2018.8446235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446235","Virtual humans;virtual reality;immersive training;fidelity;proxemics;haptic priming;locomotion techniques.: Human-centered computing-Human Computer Interaction (HCI)-Interaction Paradigms-Virtual Reality;Human-centered computing-Interaction design-Interaction design process and methods-User interface design","Haptic interfaces;Training;Legged locomotion;Virtual environments;Atmospheric measurements;Particle measurements","augmented reality;haptic interfaces;interactive devices;training","elicitation;interpersonal space;virtual humans;augmented reality systems;immersive training applications;training scenarios;realistic interactions;naturalistic behavior;negative training;proper learning;virtual human touch;virtual experience;human users;impact proxemic behavior;immersive training systems;trainee reactions;social interactions;locomotion techniques","","","","28","","30 Aug 2018","","","IEEE","IEEE Conferences"
"Training of high-skilled workers using exercisers and simulators","L. Steshina; I. Petukhov; I. Tanryerdiev; P. Kurasov; A. Glazyrin","Volga State University of Technology,Department of Radio Technical,Yoshkar-Ola,Russia; Volga State University of Technology,Department of Radio Technical,Yoshkar-Ola,Russia; Volga State University of Technology,Department of Radio Technical,Yoshkar-Ola,Russia; Volga State University of Technology,Department of Radio Technical,Yoshkar-Ola,Russia; Volga State University of Technology,Department of Radio Technical,Yoshkar-Ola,Russia","2019 3rd European Conference on Electrical Engineering and Computer Science (EECS)","20 Nov 2020","2019","","","134","139","The paper considers a new method of personalized training of logging machine operators. It deals with factors affecting efficiency of the logging process as well as with an influence of experience and training level of an human-operator on efficiency of the production process. Mathematical representation of an operator in form of transfer functions is presented. The paper presents a model of interaction between a human-operator and production equipment in the transfer functions and offers an evaluation method for a person's rate of making an operating decision. The method for evaluation of operator's professionally important qualities is presented. The key idea using the tests for the measuring of motor and sensory layers. The tests describe typical model of reaction for operator and activate motor and sensory layers as in real professional case. The imitation model shows that during four seconds of the control action the beam moved by 1.281 m and a delay of the beam movement start after the control signal start for 0.578 sec. Therefore quality of operator's control is definitely determined by the following parameters: a time constant that means a response time of a neuromuscular system and human adaptive abilities and describes a rate of control action development; a ratio of human internal feedback and describes accuracy of the control action development; and an operator's response delay time.","","978-1-7281-6109-9","10.1109/EECS49779.2019.00036","NSFC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9257542","Machine;Operator;Performance;Harvester;Simulator","Mathematical model;Training;Process control;Tools;Vegetation;Transfer functions;Production equipment","computer based training;human computer interaction;production engineering computing;production equipment;transfer functions;well logging","personalized training;logging process;production process;operator response delay time;neuromuscular system;human-operator training level;logging machine operators;simulators;high-skilled worker training;exercisers;human internal feedback;control action development;human adaptive abilities;control signal start;beam movement start;imitation model;sensory layers;evaluation method;production equipment;transfer functions;mathematical representation;size 1.281 m;time 0.578 s","","","","23","","20 Nov 2020","","","IEEE","IEEE Conferences"
"Approach on a new methodology for skills transfer using a parallel planar robot with visuo-vibrotactile feedback","P. Humblot-Niño; O. Sandoval-González; I. Herrera-Aguilar; D. Rangel-Peñuelas; A. Flores-Cuautle; B. González-Sánchez","División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México; División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México; División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México; División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México; CONACYT - División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México; División de Estudios de Posgrado e Investigación, Instituto Tecnológico de Orizaba, Orizaba, México","2017 14th International Conference on Electrical Engineering, Computing Science and Automatic Control (CCE)","16 Nov 2017","2017","","","1","5","An approach of a new methodology for skills transfer from machine to human is proposed in this research. This methodology transmits a haptic feed-back using vibrotactile perception to transfer motor skills using a parallel planar robot and virtual reality environments. During the experimentation, the participants tried to learn a specific motion trajectory given by the system. During the process, the system computes the current position and generates a vibrotactile feed-back proportional to the error computed between the actual and the desired position of the motion trajectory. The results of the user studies showed this system can help with learning new skills.","","978-1-5386-3406-6","10.1109/ICEEE.2017.8108861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8108861","Skill Transfer;Parallel Planar Robot;Methodology","Haptic interfaces;Virtual environments;Robot sensing systems;Training;End effectors;Trajectory","feedback;haptic interfaces;human computer interaction;human-robot interaction;position control;virtual reality","haptic feedback;motion trajectory;visuo-vibrotactile feedback;virtual reality environments;parallel planar robot;motor skills;vibrotactile perception;skills transfer","","","","16","","16 Nov 2017","","","IEEE","IEEE Conferences"
"Augmented reality for skill transfer in assembly task","N. Pathomaree; S. Charoenseang","Inst. of Field Robotics, King Mongkut's Univ. of Technol., Bangkok, Thailand; Inst. of Field Robotics, King Mongkut's Univ. of Technol., Bangkok, Thailand","ROMAN 2005. IEEE International Workshop on Robot and Human Interactive Communication, 2005.","3 Oct 2005","2005","","","500","504","In this research, an augmented reality is proposed to enhance the skill transfer in the assembly task. In this system, a user can see the additional graphics information superimposed on the real world scenes. Graphical instructions and virtual objects are used for advising the user with the assembly steps and the targeted positions in assembly task. Furthermore, the system's judgment component can guide the user for the sequences of assembly and check whether the user performs actions correctly. The experimental results show that the training system with augmented reality has high percentages of transferability and high transfer effectiveness ratio. The system can also reduce assembly completion times and the number of assembly steps. Moreover, the questionnaire results show that the users are very satisfied with this kind of system. Therefore, the training system embedded with an augmented reality would be a new trend to improve the user's skills.","1944-9437","0-7803-9274-4","10.1109/ROMAN.2005.1513829","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1513829","","Augmented reality;Robotic assembly;Assembly systems;Layout;Robot sensing systems;Virtual reality;Computer graphics;Medical robotics;Intrusion detection;Cameras","augmented reality;industrial training;assembling;computer aided instruction;engineering education;production engineering","augmented reality;skill transfer;assembly task;training system;graphical instructions;virtual objects","","24","2","12","","3 Oct 2005","","","IEEE","IEEE Conferences"
"Anthropomorphic robotic system with 6 DOF for space positioning in the virtual reality applications for human machine interaction","M. Chavez-Gamboa; I. Herrera-Aguilar; O. Sandoval-Gonzalez; F. Malagon-Gonzalez; J. M. Jacinto-Villegas","The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico; The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico; The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico; The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico; The Technological Institute of Orizaba; Electronics Department, Orizaba; Veracruz, Mexico","CONIELECOMP 2013, 23rd International Conference on Electronics, Communications and Computing","13 Jun 2013","2013","","","212","217","This paper presents a spatial hand tracking system using a 6 DOF anthropomorphic robot applied in human machine interaction. The main objective of this mechatronic system is to obtain information about the spatial position of a user's hand movements in order to be used like a skills trainer to accelerate the skills transfer from the machine to the human by integrating the laws of physics of virtual objects and adapting different design techniques and use of computer software for three-dimensional virtual reality.","","978-1-4673-6155-2","10.1109/CONIELECOMP.2013.6525788","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6525788","DOF;virtual reality;skills transfer;upper limbs;physical human-computer interaction;computational design","Virtual environments;Robots;Sensors;Software;Assembly;Kinematics","anthropology;gesture recognition;human-robot interaction;mechatronics;position control;robots;virtual reality","6 DOF anthropomorphic robotic system;space positioning;virtual reality applications;human machine interaction;spatial hand tracking system;mechatronic system;user hand movements;virtual objects;computer software;three-dimensional virtual reality","","","","18","","13 Jun 2013","","","IEEE","IEEE Conferences"
"An Automatic Robot Skills Learning System from Robot’s Real-World Demonstrations","B. Li; T. Lu; X. Li; Y. Cai; S. Wang","Research Center on Intelligent Robotic Systems, Chinese Academy of Sciences, Beijing, 100190; Research Center on Intelligent Robotic Systems, Chinese Academy of Sciences, Beijing, 100190; Research Center on Intelligent Robotic Systems, Chinese Academy of Sciences, Beijing, 100190; Research Center on Intelligent Robotic Systems, Chinese Academy of Sciences, Beijing, 100190; Research Center on Intelligent Robotic Systems, Chinese Academy of Sciences, Beijing, 100190","2019 Chinese Control And Decision Conference (CCDC)","12 Sep 2019","2019","","","5138","5142","In order to avoid complicated programming difficulties in robot control, we propose an automatic robot learning system which can learn skills from real-world demonstrations by robot. The system utilizes RGB-D camera to record one robot's demonstrations and then the demonstration data are processed and transferred into robot simulation environment. The policy model is trained entirely in simulation with the advantage of avoiding safety problem which is the key difficulty of real-world training. Then the learned policy is automatically transferred to another robot to reproduce the demonstrated skills. The experiments show that the system could automatically finish entire learning process from recording the robot demonstrations to applying the learned policy to another robot. And with the selected policy learning method, the robot could not only acquire skills but outperform the demonstrator.","1948-9447","978-1-7281-0106-4","10.1109/CCDC.2019.8833143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8833143","learn from demonstrations;simulation;real-world demonstrations;coordinate transformation","Robot kinematics;Training;Cameras;Robot vision systems;Data models;Grippers","control engineering computing;learning (artificial intelligence);robots","automatic robot skills learning system;robot control;robot simulation environment;policy model;real-world training;learned policy;robot demonstrations;selected policy learning method","","3","","14","","12 Sep 2019","","","IEEE","IEEE Conferences"
"DESK: A Robotic Activity Dataset for Dexterous Surgical Skills Transfer to Medical Robots","N. Madapana; M. M. Rahman; N. Sanchez-Tamayo; M. V. Balakuntala; G. Gonzalez; J. P. Bindu; L. N. Vishnunandan Venkatesh; X. Zhang; J. B. Noguera; T. Low; R. M. Voyles; Y. Xue; J. Wachs","Purdue University, West Lafayette, IN,School of Industrial Engineering,USA,47907; Purdue University, West Lafayette, IN,Department of Computer Science,USA,47907; Purdue University, West Lafayette, IN,School of Industrial Engineering,USA,47907; School of Engineering Technology, Purdue University, West Lafayette, IN,USA,47907; Purdue University, West Lafayette, IN,School of Industrial Engineering,USA,47907; School of Engineering Technology, Purdue University, West Lafayette, IN,USA,47907; School of Engineering Technology, Purdue University, West Lafayette, IN,USA,47907; Purdue University, West Lafayette, IN,School of Industrial Engineering,USA,47907; Purdue University, West Lafayette, IN,School of Industrial Engineering,USA,47907; SRI International; School of Engineering Technology, Purdue University, West Lafayette, IN,USA,47907; Purdue University, West Lafayette, IN,Department of Computer Science,USA,47907; Purdue University, West Lafayette, IN,School of Industrial Engineering,USA,47907","2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","28 Jan 2020","2019","","","6928","6934","Datasets are an essential component for training effective machine learning models. In particular, surgical robotic datasets have been key to many advances in semi-autonomous surgeries, skill assessment, and training. Simulated surgical environments can enhance the data collection process by making it faster, simpler and cheaper than real systems. In addition, combining data from multiple robotic domains can provide rich and diverse training data for transfer learning algorithms. In this paper, we present the DESK (DExterous Surgical SKills) dataset. It comprises a set of surgical robotic skills collected during a surgical training task using three robotic platforms: the Taurus II robot, Taurus II simulated robot, and the YuMi robot. This dataset was used to test the idea of transferring knowledge across different domains (e.g. from Taurus to YuMi robot) for a surgical gesture classification task with seven gestures/surgemes. We explored two different scenarios: 1) No transfer and 2) Domain transfer (simulated Taurus to real Taurus and YuMi robots). We conducted extensive experiments with three supervised learning models and provided baselines in each of these scenarios. Results show that using simulation data during training enhances the performance on the real robots, where limited real data is available. In particular, we obtained an accuracy of 55% on the real Taurus data using a model that is trained only on the simulator data, but that accuracy improved to 82% when the ratio of real to simulated data was increased to 0.18 in the training set.","2153-0866","978-1-7281-4004-9","10.1109/IROS40897.2019.8967760","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8967760","","","control engineering computing;dexterous manipulators;gesture recognition;image classification;medical image processing;medical robotics;multi-robot systems;supervised learning;surgery;telerobotics","dexterous surgical skills dataset;supervised learning models;surgical gesture classification task;YuMi robot;Taurus II simulated robot;Taurus II robot;robotic platforms;surgical training task;surgical robotic skills;DESK dataset;transfer learning;simulated surgical environments;surgical robotic datasets;machine learning;medical robots;robotic activity dataset","","3","","30","","28 Jan 2020","","","IEEE","IEEE Conferences"
"An empirical study on tangible augmented reality learning space for design skill transfer","R. Chen; X. Wang","Design Lab., Faculty of Architecture, Design and Planning, The University of Sydney, Sydney NSW 2006, Australia; Design Lab., Faculty of Architecture, Design and Planning, The University of Sydney, Sydney NSW 2006, Australia","Tsinghua Science and Technology","17 Jan 2012","2008","13","S1","13","18","Tangible augmented reality (TAR) technology opens a novel realm which integrates the computergenerated elements into the real word. Its applications into design education have been explored with a limitation to this entire area. TAR offers an innovative learning space by merging digital learning materials into the format of media with tools or objects which are direct parts of the physical space. It is therefore conceived that such combination opens new perspectives in teaching and learning. This paper presented and evaluated one TAR system to improve the pedagogical effectiveness of experiential and collaborative learning process in urban design education. The results from the experiments were analyzed under a previously developed theoretical framework, which show that TAR can enhance the design activities in some collaborative work.","1007-0214","","10.1016/S1007-0214(08)70120-2","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6072951","tangible interface;augmented reality;tangible augmented reality;design learning;physicality","Education;Augmented reality;Visualization;Context;Testing;Computers;Materials","","","","5","2","","","17 Jan 2012","","","TUP","TUP Journals"
"Developing a client-centered tele-rehabilitation virtual reality program for children with autism to address socio-emotional skills","P. Ghanouni; T. Jarus; J. G. Zwicker; S. Chauhan; C. Moir; E. Stokley; B. Fenn","Occupational Science and Occupational Therapy, University of British Columbia, Vancouver, Canada; Occupational Science and Occupational Therapy, University of British Columbia, Vancouver, Canada; Occupational Science and Occupational Therapy, University of British Columbia, Vancouver, Canada; Occupational Science and Occupational Therapy, University of British Columbia, Vancouver, Canada; Occupational Science and Occupational Therapy, University of British Columbia, Vancouver, Canada; Occupational Science and Occupational Therapy, University of British Columbia, Vancouver, Canada; Occupational Science and Occupational Therapy, University of British Columbia, Vancouver, Canada","2017 International Conference on Virtual Rehabilitation (ICVR)","14 Aug 2017","2017","","","1","2","This qualitative study investigated stakeholders' ideas on features of a tele-rehabilitation platform among children with ASD. We recruited and interviewed 20 stakeholders, including clinicians, parents, and youth with autism, to explore their perspectives on the design and parameters of using a tele-rehabilitation platform among individuals with ASD. We transcribed and analyzed data through thematic analysis. Three themes emerged: (a) “improving clinical features”, (b)“transferring the skills”, and (c) “increasing motivational factors”. Using a client-centered approach and involving stakeholders will fulfill clients' needs and deliver accessible rehabilitation services for end-users.","2331-9569","978-1-5090-3053-8","10.1109/ICVR.2017.8007463","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007463","tele-rehabilitation;virtual reality program;client centered;autism","Virtual reality;Stakeholders;Autism;Interviews;Variable speed drives;Medical treatment;Organizations","medical disorders;paediatrics;patient rehabilitation;telemedicine;virtual reality","client-centered telerehabilitation virtual reality program;children;socio-emotional skills;autism;qualitative study;stakeholders;data analysis;thematic analysis;clinical features;skill transferring;accessible rehabilitation service delivery;end-users","","","","6","","14 Aug 2017","","","IEEE","IEEE Conferences"
"PhD Forum: Strengthening Social Emotional Skills for Individuals with Developmental Disabilities Through Virtual Reality Games","T. Thang","Comput. Media, Univ. of California, Santa Cruz, Santa Cruz, CA, USA","2018 IEEE International Conference on Smart Computing (SMARTCOMP)","30 Jul 2018","2018","","","242","243","Defining qualities of developmental disabilities include deficits in social-emotional skills, especially with respect to emotion recognition. This study aims to assist adults with developmental disabilities in strengthening emotion recognition skills through the research and development of virtual reality games to increase accessibility to life-changing therapies. Work previously accomplished in this study includes the development of EmotionVR, a virtual reality game created for the HTC Vive. EmotionVR takes traditional methods of therapy aimed at teaching emotion recognition and translates it into an interesting and interactive narrative that provides users the opportunity to learn and practice emotion recognition in realistic settings. This work observed and analyzed the interaction between adults with developmental disabilities, and the HTC Vive and virtual environments. While the game supports the idea that virtual reality is a feasible method of providing such therapies, users found some discomfort with using the HTC Vive, and had slight difficulty translating what they had learned from the game in different situational contexts. To resolve those issues, we investigate interactions between adults with developmental disabilities and other virtual reality systems, and develop a 360 video based virtual reality game to assist with transfer of skills.","","978-1-5386-4705-9","10.1109/SMARTCOMP.2018.00061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8421355","assistive technology;virtual reality;human computer interaction;developmental disabilities","Conferences","computer aided instruction;computer games;emotion recognition;handicapped aids;teaching;virtual reality","social-emotional skills;adults;developmental disabilities;emotion recognition skills;HTC Vive;virtual reality systems;EmotionVR;teaching;interactive narrative;virtual environments;video based virtual reality game","","","","9","","30 Jul 2018","","","IEEE","IEEE Conferences"
"Improving wheelchair driving performance in a virtual reality simulator","P. S. Archambault; C. Bigras","McGill University,School of Physical and Occupational Therapy,Montreal,Canada; McGill University,School of Physical and Occupational Therapy,Montreal,Canada","2019 International Conference on Virtual Rehabilitation (ICVR)","13 Feb 2020","2019","","","1","2","In this study, we measured if practice of a wheelchair activity in a virtual reality simulator (entering an elevator) improved wheelchair positioning skills in naïve, healthy adults. Performance was assessed immediately after practice, two days later (retention) and in a real-world equivalent task (transfer). The influence of augmented feedback on retention and transfer was also assessed. Forty participants were randomized to either an augmented feedback group (who received information on collisions and on task completion time) and a no-feedback group. Following training, both groups improved their wheelchair positioning abilities. Learning was maintained at retention and skills transferred to the real-world wheelchair. Augmented feedback did not procure any additional effects. Practice in a virtual reality simulator significantly improved wheelchair positioning skills. Higher performance gains could be achieved by providing task-specific feedback.","2331-9569","978-1-7281-1285-5","10.1109/ICVR46560.2019.8994644","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994644","power wheelchair;simulator;performance;learning;transfer","","computer simulation;feedback;handicapped aids;virtual reality;wheelchairs","no-feedback group;wheelchair positioning abilities;virtual reality simulator;task-specific feedback;wheelchair activity;augmented feedback group;wheelchair positioning skills;wheelchair driving performance","","","","8","","13 Feb 2020","","","IEEE","IEEE Conferences"
"Immersive virtual environments for tacit knowledge transfer focusing on gestures: A workflow","H. Esmaeili; H. Thwaites; P. C. Woods","Centre for Research-Creation in Digital Media, School of Arts, Sunway University, Malaysia; Centre for Research-Creation in Digital Media, School of Arts, Sunway University, Malaysia; Faculty of Creative Multimedia, Multimedia University, Malaysia","2017 23rd International Conference on Virtual System & Multimedia (VSMM)","26 Apr 2018","2017","","","1","6","This study presents a workflow for creating immersive virtual environments for tacit knowledge transfer. The main focus is on gestures, which are related to skill, performance, or physical emotion (not facial) e.g. sports, martial arts, playing instruments, acting, etc. The initial idea behind this design is to provide a virtual practice environment mainly for actors in order to learn new gestures or moves. However, this virtual environment can also be used by many other target audiences based on their needs. Sometimes, ambiguity is part of knowledge transfer and becomes more salient or critical when it comes to tacit knowledge, especially at early stages of transfer. Performance while maintaining believable gesture is a must have requirement for actors. Visual references (mainly video in absence of trainer) are commonly used by actors in order to learn specific moves or gestures. However, videos are limited to 2D screen view (even if stereoscopic or 360°) and do not provide chance of studying a freezing moment from all angles, simultaneously. Although this can be partly mimicked using multi-camera rig, it is still limited to the number of shots taken and only provides a linear frame sequence (mostly used as VFX). Immersive virtual environments not only eliminate this limitation but also provide one to one scale experience. In this study, the process of creating such environment is discussed in detail. This includes planning, concept design, selecting tools, establishing the environment, properly selecting or creating the virtual character(s), capturing the motion or using existing ones from different Mocap libraries, actor's interaction with VR equipment, user experience, etc. In addition to studying reference moves and gestures (frame by frame and from any angle), the user is able to observe his/her performance in VR. This can be achieved using motion capture cameras installed at the practice location. The captured content is later assigned to the user's virtual representative i.e. a 3d character created based on his/her physical body features for side by side analysis with the reference. This provides countless interaction possibilities that cannot be achieved in the real world. Few examples are: multiplying the reference character and freeze two or more different moments (frames) and create a walkthrough, creating an immersive timeline based on the actor's progress (also requires multiplying), assigning reference moves to the user's avatar to be compared with his/her movements by himself/herself or anyone else (different from side by side comparison with the reference character), and many others. What has been discussed above is fully illustrated and described in this paper including detailed figures. The contribution of this study can be extended to various fields from acting and sport to stop motion and creative art, as the processes presented in the paper are designed in the most affordable way, using hardware and software currently available to basic users.","2474-1485","978-1-5386-4494-2","10.1109/VSMM.2017.8346255","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8346255","immersive virtual environments;immersive virtual reality;tacit knowledge transfer;gesture;virtual reality;mocap;learning in virtual reality;htc vive;oculus rift;unity;steam vr","Teleportation;Knowledge transfer;Observers;Virtual environments;Art;Tools;Three-dimensional displays","gesture recognition;virtual reality","reference character;reference moves;immersive virtual environments;tacit knowledge transfer;virtual practice environment;believable gesture;virtual character;virtual representative","","1","","10","","26 Apr 2018","","","IEEE","IEEE Conferences"
"Unified approach for teleoperation of virtual and real environment for skill based teleoperation","K. Kosuge; K. Takeo; T. Fukuda; T. Sugiura; A. Sakai; K. Yamada","Dept. of Mech.-Inf. & Syst., Nagoya Univ., Japan; Dept. of Mech.-Inf. & Syst., Nagoya Univ., Japan; Dept. of Mech.-Inf. & Syst., Nagoya Univ., Japan; NA; NA; NA","Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'94)","6 Aug 2002","1994","2","","1242","1247 vol.2","This paper proposes an alternative control scheme for a teleoperation system which consists of a master arm, a slave arm and a virtual environment. For a given task, the operator manipulates a virtual environment and executes the task, a skill for the task is extracted through the manipulation, and the skill is transferred to the remote site to execute the task in real. First, the authors consider the design of a control algorithm for a master arm manipulating the virtual environment so that the system has a given dynamics for the operator and the environment. Then the authors consider the design of a control algorithm for the master-slave system manipulating the real environment so that the system has the same dynamics given to the manipulator of the virtual environment. By designing a control scheme, with which the master arm with a real environment and the master arm with a virtual environment have the same dynamics, the skill extracted from the operation of the virtual environment would be applied to the real task using the slave arm. The proposed control system is applied to an experimental master-slave manipulator and experimental results illustrate the effectiveness of the system.<>","","0-7803-1933-8","10.1109/IROS.1994.407520","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=407520","","Master-slave;Virtual environment;Control systems;Manipulator dynamics;Algorithm design and analysis;Delay effects;Force feedback;Humans;Stability;Research and development","telerobotics;feedback;robot programming;manipulators","teleoperation;real environment;virtual environment;skill based teleoperation;master arm;slave arm;master-slave system;skill extraction","","8","12","9","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Does virtual-reality training on orthopaedic simulators improve performance in the operating room?","N. Vaughan; V. N. Dubey; T. W. Wainwright; R. G. Middleton","Faculty of Science and Technology, Bournemouth University (BU) Bournemouth, UK; Faculty of Science and Technology, Bournemouth University (BU) Bournemouth, UK; Department of Orthopaedics, Royal Bournemouth Hospital NHS Foundation Trust, Bournemouth, UK; Department of Orthopaedics, Royal Bournemouth Hospital NHS Foundation Trust, Bournemouth, UK","2015 Science and Information Conference (SAI)","3 Sep 2015","2015","","","51","54","This paper summarises recent validation studies and evidence demonstrating whether training on virtual reality (VR) simulators directly relates to improved performance in-vivo for orthopaedic surgical procedures. This research provides a summary of transfer validity on virtual reality orthopaedic simulators. This covers studies which have shown validation of simulators and have shown the transfer of simulator-acquired skill to the operating room. The findings of this study are that there are 6 studies showing transfer of skill for VR to in-vivo However more studies assessing efficacy and transfer validity are required to conclusively quantify the transfer validity of VR orthopaedic simulators. However there is a popular positive opinion for the ability of VR training to convert into better in-vivo performance.","","978-1-4799-8547-0","10.1109/SAI.2015.7237125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7237125","Orthopeadic;Simulator;Transfer validity;Efficacy;Testing;Surgery;Performance","Training;Surgery;Virtual reality;Hip;Solid modeling;Injuries","computer based training;medical computing;orthopaedics;surgery;virtual reality","virtual-reality training;operating room performance;orthopaedic surgical procedures;virtual reality orthopaedic simulators;simulator-acquired skill transfer;VR orthopaedic simulators","","3","","18","","3 Sep 2015","","","IEEE","IEEE Conferences"
"Perceptual Rendering for Learning Haptic Skills","T. Edmunds; D. K. Pai","Rutgers University, e-mail: tedmunds@cs.rutgers.edu; University of British Columbia, Rutgers University, e-mail: pai@cs.ubc.ca","2008 Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems","31 Mar 2008","2008","","","225","230","We approach the problem of creating haptic simulators that effectively impart skill without requiring high-fidelity devices by identifying perceptually salient events that signal transitions in the interaction. By augmenting these events, we seek to overcome deficiencies in the fidelity of the rendering hardware. We present an extension of event-based haptic rendering to non- collision events, and we describe a user-study of the training effectiveness of passive force-field haptic simulation vs. active event- augmented simulation in a tool-manipulation task. The results indicate that active augmentation improves skill transfer without requiring an increase in the quality of the rendering device.","2324-7355","978-1-4244-2005-6","10.1109/HAPTICS.2008.4479948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4479948","","Haptic interfaces;Discrete event simulation;Bones;Hardware;Humans;Feedback;Surgery;Surges;Signal processing;Shape","computer graphic equipment;haptic interfaces;learning (artificial intelligence);manipulators;rendering (computer graphics);virtual reality","perceptual rendering hardware;haptic skill learning;signal transitions;event-based haptic rendering;noncollision events;training;passive force-field haptic simulation;event-augmented simulation;tool-manipulation task","","9","","18","","31 Mar 2008","","","IEEE","IEEE Conferences"
"A Training System of Orientation and Mobility for Blind People Using Acoustic Virtual Reality","Y. Seki; T. Sato","Human Technology Research Institute, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Ibaraki, Japan; College of Rehabilitation for the Blind, National Rehabilitation Center for Persons with Disabilities, Tokorozawa, Saitama, Japan","IEEE Transactions on Neural Systems and Rehabilitation Engineering","7 Feb 2011","2011","19","1","95","104","A new auditory orientation training system was developed for blind people using acoustic virtual reality (VR) based on a head-related transfer function (HRTF) simulation. The present training system can reproduce a virtual training environment for orientation and mobility (O&M) instruction, and the trainee can walk through the virtual training environment safely by listening to sounds such as vehicles, stores, ambient noise, etc., three-dimensionally through headphones. The system can reproduce not only sound sources but also sound reflection and insulation, so that the trainee can learn both sound location and obstacle perception skills. The virtual training environment is described in extensible markup language (XML), and the O&M instructor can edit it easily according to the training curriculum. Evaluation experiments were conducted to test the efficiency of some features of the system. Thirty subjects who had not acquired O&M skills attended the experiments. The subjects were separated into three groups: a no-training group, a virtual-training group using the present system, and a real-training group in real environments. The results suggested that virtual-training can reduce “veering” more than real-training and also can reduce stress as much as real training. The subjective technical and anxiety scores also improved.","1558-0210","","10.1109/TNSRE.2010.2064791","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5559478","Auditory orientation;blindness;head-related transfer function;obstacle perception;orientation and mobility;sound localization;stress pulse ratio","Training;Roads;Coils;Magnetic heads;Acoustics;Knee;Stress measurement","biomechanics;computer based training;handicapped aids;headphones;hearing;medical computing;virtual reality;XML","mobility;blind people;acoustic virtual reality;auditory orientation training system;head-related transfer function;HRTF simulation;listening;headphones;extensible markup language;XML","Acoustic Stimulation;Acoustics;Blindness;Computer-Assisted Instruction;Equipment Design;Equipment Failure Analysis;Therapy, Computer-Assisted;User-Computer Interface","35","","18","","30 Aug 2010","","","IEEE","IEEE Journals"
"Networked tank gunnery skill training based on haptic interaction","G. Liu; K. Lu","State Key Laboratory of Virtual Reality Technology and Systems, Robotics Institute, School of Mechanical Engineering and Automation, Beihang University, Beijing, 100191, China; State Key Laboratory of Virtual Reality Technology and Systems, Robotics Institute, School of Mechanical Engineering and Automation, Beihang University, Beijing, 100191, China","2011 4th International Conference on Biomedical Engineering and Informatics (BMEI)","12 Dec 2011","2011","4","","2220","2224","This paper introduces networked tank gunnery skill training based on haptic interaction. “Hand in hand” training mode is implemented by constructing a networked haptic display system. A teacher and a trainee can respectively manipulate his own haptic device to realize skill transferring. In this process, the trainee can experience the teacher's motor skill and can be corrected by the teacher. A local network is built to connect two haptic devices and computers. Two modes for tank gunnery skill training are designed in this system: haptic guidance and real-time correction. A prototype system is established to testify the effectiveness of such a new type “Hand in hand” training system.","1948-2922","978-1-4244-9352-4","10.1109/BMEI.2011.6098650","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6098650","networked skill training;hand in hand;haptic display;haptic guidance;real-time correction","Haptic interfaces;Training;Real time systems;Computers;Virtual environments;Fixtures;Torque","computer based training;haptic interfaces;local area networks;military computing","networked tank gunnery skill training;haptic interaction;hand in hand training mode;networked haptic display system;teacher;trainee;skill transferring;motor skill;local network;haptic guidance;realtime correction","","2","","11","","12 Dec 2011","","","IEEE","IEEE Conferences"
"ECG-Based Virtual Pathology Stethoscope Tracking Using Transfer Learning","H. Yhdego; N. Kidane; F. Mckenzie; M. Audette","Old Dominion University,Norfolk,VA,USA; Old Dominion University,Norfolk,VA,USA; Old Dominion University,Norfolk,VA,USA; Old Dominion University,Norfolk,VA,USA","2020 Spring Simulation Conference (SpringSim)","3 Sep 2020","2020","","","1","7","Standardized Patient (SP) based medical simulation is commonly used to teach bedside skills. However, SPs are typically healthy individuals, and the number and range of conditions they can portray are limited. Our research aims to improve the cardiac auscultation (CA) skills of medical students by utilizing a modified stethoscope in tandem with SP. This technology introduces the potential to augment virtual pathology sounds on otherwise healthy SP. In this study, CNN models, previously trained on large-scale image datasets, are transferred to identify the four CA sites. We applied the pre-trained CNN models of ResNet50, InceptionV3, and Alexnet, to the ECG recordings from the CA regions, which are converted to images using a wavelet scalogram. Moreover, data augmentation is performed to supplement limited labeled data. Experimental results illustrate data augmentation with InceptionV3 and Resnet50 models leads to a better performance than our previously reported methods, between 93% and 95% F1 score.","","978-1-56555-370-5","10.22360/SpringSim.2020.MSM.009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9185471","ECG;Transfer Learning;Clinical Simulation;Auscultation;Stethoscope Tracking","Electrocardiography;Stethoscope;Feature extraction;Medical diagnostic imaging;Continuous wavelet transforms;Computer architecture","bioacoustics;biomedical education;convolutional neural nets;electrocardiography;learning (artificial intelligence);medical computing;medical signal processing;teaching","wavelet scalogram;Alexnet;standardized patient based medical simulation;Resnet50;data augmentation;ECG recordings;InceptionV3;pretrained CNN models;large-scale image datasets;virtual pathology sounds;modified stethoscope;medical students;cardiac auscultation skills;bedside skills;transfer learning;ECG-based virtual pathology stethoscope tracking","","","","15","","3 Sep 2020","","","IEEE","IEEE Conferences"
"Mobile Augmented Reality as an Orientation Aid: A Scavenger Hunt Prototype","K. Rogers; J. Frommel; L. Breier; S. Celik; H. Kramer; S. Kreidel; J. Brich; V. Riemer; C. Schrader","Ulm Univ., Ulm, Germany; Ulm Univ., Ulm, Germany; Ulm Univ., Ulm, Germany; Ulm Univ., Ulm, Germany; Ulm Univ., Ulm, Germany; Ulm Univ., Ulm, Germany; Ulm Univ., Ulm, Germany; Ulm Univ., Ulm, Germany; Ulm Univ., Ulm, Germany","2015 International Conference on Intelligent Environments","13 Aug 2015","2015","","","172","175","Orientation in public environments is a critical skill for new arrivals, yet also one that is usually only learned gradually through trial and error. This paper suggests the use of pervasive augmented reality (AR) for the design of a serious game that teaches navigational skills in a public environment. Many AR scavenger hunt games confront players with new environments by default, however they rarely focus explicitly on teaching navigational skills. We propose a concept that utilises augmented reality techniques for increased immersion and motivation, while upholding the real-world sense of presence for an easy transfer of orientation skills to everyday life. For this purpose, we implemented a first prototypical serious game in the form of an AR scavenger hunt. A preliminary evaluation regarding its usability produced promising results. As such, the prototype constitutes a first proof of concept. In future iterations, it will be further developed as an adaptive AR serious game, and evaluated in respect to its efficacy in teaching orientation and navigation skills.","","978-1-4673-6654-0","10.1109/IE.2015.37","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194292","","Games;Navigation;Prototypes;Augmented reality;Usability;Education;Cities and towns","augmented reality;computer aided instruction;graphical user interfaces;mobile learning;serious games (computing);teaching","navigation skills;teaching orientation;adaptive AR serious game;orientation skills transfer;AR scavenger hunt games;navigational skills teaching;serious game design;pervasive augmented reality;critical skill;public environments;scavenger hunt prototype;orientation aid;mobile augmented reality","","6","","24","","13 Aug 2015","","","IEEE","IEEE Conferences"
"Analyzing human skill through control trajectories and motion capture data","F. Duan; Y. Zhang; N. Pongthanya; K. Watanabe; H. Yokoi; T. Arai","Intelligent Systems Division, Department of Precision Engineering, School of Engineering, The University of Tokyo, 113-8656, Japan; Intelligent Systems Division, Department of Precision Engineering, School of Engineering, The University of Tokyo, 113-8656, Japan; Department of Systems Innovation, The University of Tokyo, Japan; Intelligent Systems Division, Department of Precision Engineering, School of Engineering, The University of Tokyo, 113-8656, Japan; Intelligent Systems Division, Department of Precision Engineering, School of Engineering, The University of Tokyo, 113-8656, Japan; Intelligent Systems Division, Department of Precision Engineering, School of Engineering, The University of Tokyo, 113-8656, Japan","2008 IEEE International Conference on Automation Science and Engineering","19 Sep 2008","2008","","","454","459","Extracting and transferring human skills is an important step towards creating an intelligent robot in a cooperative environment. Human skill contains human control skill and human motion skill. Many studies have been done to extract and transfer either human control skill or human motion skill successfully; however, the complete human-to-human skill transfer process (including both human control skill and human motion skill) has not been realized. In this study, the objective is to achieve the complete human-to-human skill transfer process from an expert to a novice. To realize the human control skill extract, synthesis and transfer process, a dynamic simulator is built up to record human operatorspsila control trajectories. Based on the simulation results, the best control strategy can be obtained. To analyze human motion skill, motion capture equipment is employed to record human operatorspsila motions, and BvhViewer software is utilized to compute human joint angle values. To make human novices understand human expertspsila motions easily, it is absolutely necessary to reproduce and synthesize the expertspsila motions. In this case, a kinematic human body simulator is utilized to synthesize the expertspsila motions. A ball shooting task is employed to evaluate the effect of the proposed method. The results show that, after training by the synthesized human control skill model and the human motion skill model, the novicepsilas performance is significantly improved.","2161-8089","978-1-4244-2022-3","10.1109/COASE.2008.4626426","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4626426","","Bridges;USA Councils;Automation;Conferences","humanoid robots;intelligent robots;mobile robots","human operator control trajectory;motion capture data;intelligent robot;cooperative environment;human control skill model;human motion skill model;human-to-human skill transfer process;BvhViewer software;kinematic human body simulator;dynamic simulator;ball shooting task","","9","","11","","19 Sep 2008","","","IEEE","IEEE Conferences"
"Closing the Skills Gap: Construction and Engineering Education Using Mixed Reality – A Case Study","W. Wu; A. Tesei; S. Ayer; J. London; Y. Luo; V. Gunji","Dept. of Construction Mgmt, Cal. State University, Fresno Fresno, CA, USA; Dept. of Construction Mgmt, Cal. State University, Fresno Fresno, CA, USA; Del E. Webb School of Construction, Arizona State University, Tempe, AZ, USA; Ira A. Fulton Schools of Engineering, The Polytechnic School, Mesa, AZ, USA; Dept. of Construction Mgmt, Cal. State University, Fresno Fresno, CA, USA; Dept. of Computer Science, Cal. State University, Fresno, Fresno, CA, USA","2018 IEEE Frontiers in Education Conference (FIE)","7 Mar 2019","2018","","","1","5","This research work-in-progress paper investigated the application of emerging mixed reality (MR) technology in construction and engineering education. The construction industry is facing a severe shortage of skilled workforce. As the baby boomers are retiring, the younger generation, especially college students, are often criticized for their lack of professional experience and career-specific competency. To close the skills gap and accelerate the transition of college students to competent workforce, this paper proposed a new genre of learning and professional training using MR. The main promise of the MR technology resides in its ability to augment virtual contents on top of the physical reality to facilitate tacit knowledge learning, and simulate learning activities that traditionally can only be obtained from actual professional experience. An undergraduate wood framing lab was designed as a case study to explore how students might perform in this new learning and training environment. Specifically, the case study investigated if MR would facilitate student design comprehension and transfer such understanding into the knowledge and skills needed to build the wood structure. A randomly selected student control group was given traditional paper-based construction drawings to perform the same tasks with other student groups with various visualization technology assistance. Project performance and behavior of student groups were compared to determine if there was a significant difference between the control group and the experiment groups. A pair of pre- and post-survey on MR-intervened learning experience was also conducted to explore student perceptions towards this new genre of learning and training. The research design proposed in this work-in-progress study and its preliminary results could be a good reference and foundation to future research in this arena.","2377-634X","978-1-5386-1174-6","10.1109/FIE.2018.8658992","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658992","mixed reality;construction;workforce;skills;learning","Virtual reality;Two dimensional displays;Training;Solid modeling;Buildings;Engineering education","augmented reality;computer based training;construction industry;design engineering;educational courses;engineering education;further education;knowledge management;professional aspects;termination of employment;wood","mixed reality;case study;construction industry;skilled workforce;baby boomers;college students;career-specific competency;professional training;physical reality;undergraduate wood framing lab;wood structure;visualization technology assistance;construction engineering education;retirement;augment virtual contents;knowledge learning;design engineering;paper-based construction drawings;student behavior","","2","","19","","7 Mar 2019","","","IEEE","IEEE Conferences"
"Transfer from a simulation environment to a live robotic environment: Are certain demographics better?","P. L. McDermott; A. Fisher; T. Carolan; M. R. Gronowski; M. Gacy; M. Overstreet","Alion Science and Technology 4949 Pearl East Circle, Suite 200; Alion Science and Technology 4949 Pearl East Circle, Suite 200; Alion Science and Technology 4949 Pearl East Circle, Suite 200; Alion Science and Technology 4949 Pearl East Circle, Suite 200; Alion Science and Technology 4949 Pearl East Circle, Suite 200; Alion Science and Technology 4949 Pearl East Circle, Suite 200","2012 7th ACM/IEEE International Conference on Human-Robot Interaction (HRI)","30 Jul 2012","2012","","","191","192","The ability to remotely operate an unmanned vehicle while simultaneously looking for suspicious targets and then classifying those targets is not a trivial skill. This study looked at different training approaches to make better use of simulation as a first training step. When transferring to a live environment, the operators could be grouped into two categories according to whether they passed live training criteria or not. There were clear performance differences between these groups. The group that failed to pass criteria had poorer performance overall, more SA errors, and spent more time in training. Post-hoc analysis showed differences in the demographics between those who passed and those that did not. Male participants and younger participants were more likely to achieve criteria. There were no differences in gaming experience and perceived sense of direction.","2167-2148","978-1-4503-1063-5","10.1145/2157689.2157750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249521","Situation awareness;learning curves;demographics;sense of direction;teleoperation","Training;Robot sensing systems;USA Councils;Human factors;Land vehicles","digital simulation;remotely operated vehicles;telerobotics","simulation environment;live robotic environment;remote operation;unmanned vehicle;suspicious targets;target classification;live training criteria;post-hoc analysis;demographics;male participants;younger participants;gaming experience;perceived direction sense","","","","4","","30 Jul 2012","","","IEEE","IEEE Conferences"
"Transferability of Spatial Maps: Augmented Versus Virtual Reality Training","N. R. Caluya; A. Plopski; J. F. Ty; C. Sandor; T. Taketomi; H. Kato","Nara Institute of Science and Technology, Interactive Media Design Laboratory; Nara Institute of Science and Technology, Interactive Media Design Laboratory; Nara Institute of Science and Technology, Interactive Media Design Laboratory; Nara Institute of Science and Technology, Interactive Media Design Laboratory; Nara Institute of Science and Technology, Interactive Media Design Laboratory; Nara Institute of Science and Technology, Interactive Media Design Laboratory","2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","387","393","Work space simulations help trainees acquire skills necessary to perform their tasks efficiently without disrupting the workflow, forgetting important steps during a procedure, or the location of important information. This training can be conducted in Augmented and Virtual Reality (AR, VR) to enhance its effectiveness and speed. When the skills are transferred to the actual application, it is referred to as positive training transfer. However, thus far, it is unclear which training, AR or VR, achieves better results in terms of positive training transfer. We compare the effectiveness of AR and VR for spatial memory training in a control-room scenario, where users have to memorize the location of buttons and information displays in their surroundings. We conducted a within-subject study with 16 participants and evaluated the impact the training had on short-term and long-term memory. Results of our study show that VR outperformed AR when tested in the same medium after the training. In a memory transfer test conducted two days later AR outperformed VR. Our findings have implications on the design of future training scenarios and applications.","","978-1-5386-3365-6","10.1109/VR.2018.8447561","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8447561","H.5.1-Information Interfaces and Presentation: Multimedia Information Systems-Artificial;augmented;and virtual realities;H.5.2-Information Interfaces and Presentation: Multimedia Information Systems-Ergonomics;Evaluation/methodology;Theory and methods","Training;Task analysis;Virtual reality;Resists;Layout;Legged locomotion;Media","augmented reality;computer based training","work space simulations;VR;spatial memory training;information displays;long-term memory;memory transfer test;spatial maps;virtual reality training;augmented reality training;training transfer;AR","","","","24","","30 Aug 2018","","","IEEE","IEEE Conferences"
"The Design and Evaluation of a Computerized and Physical Simulator for Training Clinical Prostate Exams","G. J. Gerling; S. Rigsbee; R. M. Childress; M. L. Martin","Dept. of Syst. & Inf. Eng., Univ. of Virginia, Charlottesville, VA; Dept. of Syst. & Inf. Eng., Univ. of Virginia, Charlottesville, VA; Sch. of Nursing, Univ. of Virginia, Charlottesville, VA; Sch. of Med., Univ. of Virginia, Charlottesville, VA","IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans","18 Feb 2009","2009","39","2","388","403","The most effective screening for prostate cancer combines the prostate specific antigen blood test with the digital rectal examination (DRE). In performing a DRE, two sequential tasks are completed: ( task a) palpating the prostate to identify abnormalities and ( task b) linking identified abnormalities to a disease diagnosis. At present, clinicians find too few abnormalities and have variable rates of detection, due in part to the inadequacy of training simulators. The Virginia Prostate Examination Simulator (VPES) was designed, built, and tested to address the inadequacies of current simulators by incorporating the design requirements of the basic elements of accurate anatomy, multiple and reconfigurable scenarios of graded difficulty, and technique and performance feedback. We compared the training effectiveness of the VPES with two commercial simulators in an experiment of 36 medical and nurse practitioner students. Results indicate each type of training simulator-improved abilities, in general. Upon closer analysis, however, the following key patterns emerge: 1) Across all types of training, more deficiencies lie in skill-based rather than rule-based decision making, which improves only for VPES trainees; 2) only VPES training transfers both to other simulators and previously unencountered scenarios; 3) visual feedback may increase the number of abnormalities reported yet hinder the ability to discriminate; and 4) applied finger pressure did not correlate with the ability to identify abnormalities.","1558-2426","","10.1109/TSMCA.2008.2009769","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4729621","Evaluation;haptics;medical;nursing;simulation;simulator;tactile;training","Physics computing;Computational modeling;Computer simulation;Medical simulation;Testing;Feedback;Prostate cancer;Blood;Joining processes;Diseases","cancer;digital simulation;medical diagnostic computing","computerized simulator;physical simulator;clinical prostate exams;prostate cancer screening;prostate specific antigen blood test;digital rectal examination;disease diagnosis;training simulators;Virginia prostate examination simulator;accurate anatomy;decision making;VPES trainees;visual feedback","","24","","57","","22 Dec 2008","","","IEEE","IEEE Journals"
"Transfer method of Force Information using Five-Fingered Haptic Interface Robot","T. Endo; H. Kawasaki; K. Kigaku; T. Mouri","Gifu University, Japan; Gifu University, Japan; Gifu University, Japan; Gifu University, Japan","Second Joint EuroHaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems (WHC'07)","2 Apr 2007","2007","","","599","600","In the expert skill transfer, it takes a great deal of time and effort to obtain new skills for beginners. In particular, it is difficult to teach the skills by using only words. So, the skill transfer system that uses VR attracts attention. In this paper, we propose a method for transferring force information and consider the skill transfer system for human five fingers by using five-fingered haptic interface robot","","0-7695-2738-8","10.1109/WHC.2007.119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4145255","","Haptic interfaces;Robots;Humans;Fingers;Virtual reality;Information systems;Surgery;System testing;Virtual environment;Teleoperators","control engineering education;dexterous manipulators;haptic interfaces;robots;virtual reality","force information transfer;five-fingered haptic interface robot;skill transfer system;virtual reality;human five fingers","","6","","4","","2 Apr 2007","","","IEEE","IEEE Conferences"
"In motor learning, variable practice improves transfer, but only when the variations elicit synergies","V. Yadav; R. L. Sainburg","Kinesiology, Pennsylvania State University, University Park, PA; Kinesiology, Pennsylvania State University, Neurology, Penn State College of Medicine","2014 40th Annual Northeast Bioengineering Conference (NEBEC)","4 Dec 2014","2014","","","1","2","It has previously been suggested that providing variable experience during motor practice is crucial for learning, retention, and transfer of motor skills. However, it is not clear what should be varied to optimize learning. In this study, we investigate whether practicing to modulate or regulate performance parameters, during practice of a virtual shuffleboard task, leads to better transfer of learning between tasks. Our results indicate that during practice, the parameter that was held constant improved the most during initial learning, and transferred best to a task requiring modulation of that parameter. Translation of this improvement into task performance depended upon the sensitivity of each task to changes in each variable. We conclude that during variable practice, learning to regulate, not modulate task variables leads to optimal learning and transfer. Further, optimal transfer occurs when variable practice elicits synergistic covariation between performance parameters.","2160-7028","978-1-4799-3728-8","10.1109/NEBEC.2014.6972982","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6972982","Constant vs variable practice;motor learning;skill acquisition;regulation vs. modulation","Indexes;Accuracy;Educational institutions;Modulation;Steady-state;Manifolds;Abstracts","biomechanics;medical computing;patient rehabilitation;virtual reality","motor learning;variable practice;synergies;variable experience;motor practice;motor skill learning;motor skill retention;motor skill transfer;optimize learning;performance parameters;virtual shuffleboard task;learning transfer;initial learning;parameter modulation;improvement translation;task performance;task sensitivity;task variables;optimal learning;optimal transfer;synergistic covariation","","","","3","","4 Dec 2014","","","IEEE","IEEE Conferences"
"Applied RFID and Virtual Reality Technology in professional training system for manufacturing","S. F. Wong; Z. X. Yang; N. Cao; W. I. Ho","Department of Electromechanical Engineering, University of Macau, China; Department of Electromechanical Engineering, University of Macau, China; Department of Electromechanical Engineering, University of Macau, China; Department of Electromechanical Engineering, University of Macau, China","2010 IEEE International Conference on Industrial Engineering and Engineering Management","23 Dec 2010","2010","","","676","680","Enhancing the professional knowledge in different levels of operator is a critical success factor to advance the performance of manufacturing industry. However, the traditional training system is lack of scientific method to transfer the professional knowledge (tacit knowledge) to the operator. Applied RFID and Virtual Reality Technology in Knowledge-based Training System can convert the tacit knowledge to the explicit knowledge to different levels of operator. The trainee can capture the basic operation skill through the web-enabled and knowledge-based training system. Moreover, the system can provide the working experience and operation history about the production and tool application to the trainee through RFID technology. They can quickly and conveniently search their target tools that will apply the real manufacturing processes without any human-being supervising. The cost of training resource can be saved, because the workload of supervisor or senior operation is reduced. The senior operation can report the updating and real-time situation of production and tools through RFID technology with knowledge-based training system. The closed loop knowledge can enhance the precision level of analysis results of production system. The industry can be sustainable development through this system.","2157-362X","978-1-4244-8503-1","10.1109/IEEM.2010.5674534","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5674534","RFID;virtual reality technology;knowledge-based training system","Training;Knowledge engineering;Radiofrequency identification;Manufacturing;Computer numerical control;Knowledge based systems;Process control","continuing professional development;industrial training;intelligent tutoring systems;Internet;manufacturing industries;production engineering computing;radiofrequency identification;sustainable development;virtual reality","virtual reality technology;professional training system;professional knowledge enhancement;critical success factor;manufacturing industry;traditional training system;scientific method;tacit knowledge;knowledge-based training system;explicit knowledge;Web-enabled training system;RFID technology;manufacturing processes;human-being supervision;training resource;closed loop knowledge;production system;sustainable development","","2","","14","","23 Dec 2010","","","IEEE","IEEE Conferences"
"Sport-specific virtual reality to identify profiles of anterior cruciate ligament injury risk during unanticipated cutting","A. W. Kiefer; C. DiCesare; S. Bonnette; K. Kitchen; B. Gadd; S. Thomas; K. D. Barber Foss; G. D. Myer; M. A. Riley; P. Silva","Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Division of Sports Medicine, Cincinnati Children's Hospital, OH USA; Department of Psychology, Center for Cognition, Action, & Perception, University of Cincinnati, OH USA; Department of Psychology, Center for Cognition, Action, & Perception, University of Cincinnati, OH USA","2017 International Conference on Virtual Rehabilitation (ICVR)","14 Aug 2017","2017","","","1","8","Female athletes are at an increased risk of anterior cruciate ligament (ACL) injury in competitive sport during running, jumping and cutting tasks. This risk is due to deficits in posterior chain and hip recruitment associated with aberrant frontal knee loads. The identification of these risk factors has led to targeted neuromuscular training (NMT) interventions to enhance hip neuromuscular control during such tasks. Despite the successful modification of ACL injury risk factors following NMT, the transfer of these corrected movement patterns to the sport-specific contexts has not been directly evaluated. Sport-specific virtual reality (VR) may provide the best method to measure training transfer to realistic sport performance, while still allowing appropriate experimental control and high-fidelity performance measurements. The current study examined the effect of a biofeedback-driven augmented NMT (aNMT) on skill transfer of ACL-injury resistant movement patterns during performance of sport-specific VR scenarios. Five trained athletes participated, and their performance on an unanticipated cutting task was assessed in VR prior to and after six weeks of aNMT. A significant 87% reduction in internal hip rotation was observed on the plant leg during the loading phase of cutting (p = .05), along with an observed 116% reduction during the push-off phase (p = .02), from pre- to post-training. A non-significant trend of a 19% reduction in knee abduction was also observed (p = .15). This study is the first that has utilized free ambulatory wireless VR to assess injury risk in athletes during performance of sport-specific tasks. The reduction in internal hip rotation and knee abduction align with previous findings on laboratory based tests. The current results are the first step in the validation of sport-specific VR as a tool for understanding injury risk during simulation of real-world sport performance.","2331-9569","978-1-5090-3053-8","10.1109/ICVR.2017.8007511","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007511","anterior cruciate ligament;virtual reality;sport;cutting;soccer","Injuries;Hip;Training;Neuromuscular;Biomechanics;Knee;Virtual reality","biomechanics;injuries;medical computing;muscle;neurophysiology;patient rehabilitation;sport;virtual reality","sport-specific virtual reality;anterior cruciate ligament injury risk;unanticipated cutting;female athletes;posterior chain;hip recruitment;aberrant frontal knee loads;neuromuscular training;biofeedback-driven augmented NMT;hip neuromuscular control;corrected movement patterns;sport-specific contexts;realistic sport performance;ACL-injury resistant movement patterns;push-off phase;free ambulatory wireless VR;internal hip rotation;knee abduction","","1","","62","","14 Aug 2017","","","IEEE","IEEE Conferences"
"Skill acquisition and transfer system as approach to the intelligent assisting system-IAS","M. Buss; H. Hashimoto","Inst. of Ind. Sci., Tokyo Univ., Japan; Inst. of Ind. Sci., Tokyo Univ., Japan","Proceedings of IEEE International Conference on Control and Applications","6 Aug 2002","1993","","","451","456 vol.1","In this paper we propose a new forthcoming research topic, the Intelligent Assisting System-IAS. Using this system we are approaching identification and analysis of human manipulation skill to be used for intelligent human operator assistance. A manipulation skill database enables the IAS to perform complex manipulations on the motion control level. Through repeated interaction with the operator for unknown environment states, manipulation skill in the database can be increased online. A model for manipulation skill based on the grip transformation matrix is proposed, which describes the transformation between the object trajectory and contact conditions. We describe the experimental system setup of a skill acquisition and transfer system as a first approach to the IAS and some results confirming the calibration method of the developed sensor glove using an artificial neural network. A simple manipulation example shows the feasibility of the proposed manipulation skill model. Further this paper derives a control algorithm realizing object task trajectories and its efficiency is shown by simulation.<>","","0-7803-0908-1","10.1109/CCA.1993.348249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=348249","","Intelligent systems;Humans;Intelligent robots;Sensor phenomena and characterization;Sensor systems;Robotics and automation;Master-slave;Automatic control;Motion control;Artificial neural networks","robots;telecontrol;intelligent control;man-machine systems;database management systems;neural nets","skill acquisition;skill transfer system;Intelligent Assisting System;IAS;human manipulation skill;intelligent human operator assistance;manipulation skill database;grip transformation matrix;calibration method;sensor glove;object task trajectories","","3","","9","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Comparison of a Gamified and Non-Gamified Virtual Reality Training Assembly Task","F. Palmas; D. Labode; D. A. Plecher; G. Klinker","Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Research Group Augmented Reality, Technical University of Munich, Munich, Germany","2019 11th International Conference on Virtual Worlds and Games for Serious Applications (VS-Games)","14 Oct 2019","2019","","","1","8","By using simulations in virtual reality (VR), people have the chance to train without supervision in a safe and controlled environment. VR simulation training allows users to gain new skills and apply them to real-life situations. However, the learning curve of this technology from a novice level could influence the expected learning results of a training session. A training approach based on the combination of VR and gamification could speed up this overall learning process and not just for a novice. In this paper we evaluate how gamification in a VR training session can improve the efficiency of the training and the accuracy of the task execution in a real-world practical test. In the training scenario of this study, 50 randomly assigned participants were divided into two groups. The groups were assigned to a gamified and a non-gamified version of the same VR training and were then guided through a step-by-step tutorial outlining how to solve an assembly task. Performance differences were evaluated based on time taken and specific errors made during the training session. The results of this study show, in general, that beneficial effects can be attributed to the use of gamification in the conducted VR training simulation, particularly for the VR novice participants.","2474-0489","978-1-7281-4540-2","10.1109/VS-Games.2019.8864583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8864583","virtual training;virtual reality;gamification;training;learning transfer;assembly task","Training;Task analysis;Games;Tutorials;Solid modeling;Augmented reality","computer based training;computer simulation;serious games (computing);virtual reality","VR simulation training;learning curve;novice level;gamification;learning process;VR training session;task execution;virtual reality training assembly task","","3","","44","","14 Oct 2019","","","IEEE","IEEE Conferences"
"Digital representation of skills for human-robot interaction","C. A. Avizzano; E. Ruffaldi; M. Bergamasco","PERCRO, Center of Excellence for Information and Communication Engineering, Scuola Superiore Sant'Anna, Pisa, Italy; PERCRO, Center of Excellence for Information and Communication Engineering, Scuola Superiore Sant'Anna, Pisa, Italy; PERCRO, Center of Excellence for Information and Communication Engineering, Scuola Superiore Sant'Anna, Pisa, Italy","RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication","10 Nov 2009","2009","","","769","774","The present paper deals with a system architecture and a digital format to support the acquisition, storage and transfer of human skills. Virtual environments and haptic interfaces will be addressed as target platforms for the capturing and rendering of skills. There are several methodologies for approaching definition and modelling of skills, and the present work will focus on a specific approach that merges evidences from human sciences with present approaches in intelligent robotics and machine learning. This work presents a supporting tool that enables researchers to model, analyse and control the skill transfer process. In addition this work will provide an overview of a skill transfer framework, and information related to the models of skill representation that are being employed.","1944-9437","978-1-4244-5081-7","10.1109/ROMAN.2009.5326295","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5326295","","Computer aided instruction;Virtual environment;Haptic interfaces;Intelligent robots;Machine learning;Robot sensing systems;Human robot interaction;Rendering (computer graphics);Learning systems;Application software","haptic interfaces;human-robot interaction;rendering (computer graphics)","digital skill representation;human-robot interaction;digital format;virtual environments;haptic interfaces;skill rendering;intelligent robotics;machine learning;skill transfer process","","1","","23","","10 Nov 2009","","","IEEE","IEEE Conferences"
"Improving motor skill transfer during dyadic robot training through the modulation of the expert role","E. Galofaro; P. Morasso; J. Zenzeri","Department of Informatics, Bioengineering, Robotics, and System Engineering, University of Genoa, 16145, Genoa, Italy; Robotics, Brain and Cognitive Sciences Unit, Center for Human Technologies, Istituto Italiano di Tecnologia, 16152, Genoa, Italy; Robotics, Brain and Cognitive Sciences Unit, Center for Human Technologies, Istituto Italiano di Tecnologia, 16152, Genoa, Italy","2017 International Conference on Rehabilitation Robotics (ICORR)","14 Aug 2017","2017","","","78","83","In daily life it is necessary to learn skills that can be applied in different tasks and different contexts. Usually these skills are acquired by observation or by direct physical training with another expert person. The critical point is to know which is the best possible way to achieve this knowledge acquisition. In this work we have proposed a collaborative environment where subjects with different levels of expertise have to interact through the use of a robotic platform. A motor skill learning algorithm has been designed in order to allow the less skilled subjects-naïves-to explore the virtual environment and to exploit the advantages of working with a skilled partner. Results show that the correct trade - off between exploration and exploitation, provided by the implemented algorithm applied during the dyadic training, allows a group of naive subjects to learn the task and generalize better the acquired skills respect to subjects trained without the proposed algorithm.","1945-7901","978-1-5386-2296-4","10.1109/ICORR.2017.8009225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8009225","","Robots;Training;Springs;Tools;Algorithm design and analysis;Visualization;Haptic interfaces","gait analysis;learning (artificial intelligence);medical robotics","motor skill transfer improvement;dyadic robot training;expert role modulation;motor skill learning algorithm;virtual environment;dyadic training","Adult;Algorithms;Humans;Motor Skills;Rehabilitation;Robotics;Task Performance and Analysis;Young Adult","1","","12","","14 Aug 2017","","","IEEE","IEEE Conferences"
"Persistent issues in the application of virtual environment systems to training","J. K. Caird","Dept. of Psychol., Calgary Univ., Alta., Canada","Proceedings Third Annual Symposium on Human Interaction with Complex Systems. HICS'96","6 Aug 2002","1996","","","124","132","The flexible constellation of technologies that comprise virtual environment (VE) systems provide many new opportunities for training. However, the lessons learned from decades of research in flight and driving simulation seem largely forgotten. This review recalls a set of long-term issues that will constrain the application of VE systems to training. In particular, the issues of cost effectiveness, interface usability, transfer of training, transfer theory, and training feedback are addressed. Training and research decisions that do not consider these issues are likely to result in programs and recommendations that do little to efficiently improve skills and knowledge.","","0-8186-7493-8","10.1109/HUICS.1996.549502","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=549502","","Virtual environment;Costs;Computer graphics;Force feedback;Psychology;Aerospace simulation;Usability;Computational modeling;Image generation;Physics computing","virtual reality","virtual environment systems;training;long-term issues;cost effectiveness;interface usability;transfer theory;training feedback","","8","31","79","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Haptic-enabled driving training system","R. H. Osgouei; H. Lee; S. Choi","Haptics and Virtual Reality Laboratory (HVRLab), Department of Computer Science and Engineering, Pohang University of Science and Technology (POSTECH), Gyungbuk, 790-784, Republic of Korea; Haptics and Virtual Reality Laboratory (HVRLab), Department of Computer Science and Engineering, Pohang University of Science and Technology (POSTECH), Gyungbuk, 790-784, Republic of Korea; Haptics and Virtual Reality Laboratory (HVRLab), Department of Computer Science and Engineering, Pohang University of Science and Technology (POSTECH), Gyungbuk, 790-784, Republic of Korea","2013 IEEE RO-MAN","15 Oct 2013","2013","","","302","303","The objective of the current work is a driving training system to capture and transfer skills from the expert to the novice drivers. The emphasis is on the haptic feedback applied on the steering wheel and the accelerator pedal to improve trainee's performance. For capturing skills, driving signals of an expert driver, performing a given task using a developed driving simulator, are recorded as reference trajectories. For transferring, two different methods are considered: guidance to assist and disturbance to distract following the reference. For evaluation, two performance measures are assumed: trajectory-based and model-based. They are used not only to evaluate the progress of the trainee but also to tune the gain of controllers delivering haptic feedback.","1944-9437","978-1-4799-0509-6","10.1109/ROMAN.2013.6628494","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6628494","","Haptic interfaces;Training;Hidden Markov models;Vehicles;Wheels;Torque;Trajectory","computer based training;digital simulation;haptic interfaces;steering systems;wheels","haptic-enabled driving training system;skill transfer;novice drivers;haptic feedback;steering wheel;accelerator pedal;skill capturing;driving signals;expert driver;driving simulator;reference trajectories;guidance method;disturbance method;trajectory-based performance measure;model-based performance measure;trainee performance;controller gain","","","1","9","","15 Oct 2013","","","IEEE","IEEE Conferences"
"Effect of interface type in the VR-based acquisition of pedestrian skills in persons with ASD","M. Saiano; E. Garbarino; S. Lumachi; S. Solari; V. Sanguineti","Dept of Informatics, Bioengineering, Robotics and Systems Engineering, University of Genoa, Via all'Opera Pia 13, 16145, Italy; Dept. of Primary Care, ASL3 Genovese, Genoa, Italy; Philos Counseling Academy, Genoa, Italy; Dept. of Education Sciences, University of Genoa, Corso A. Podestá 2, Italy; Dept of Informatics, Bioengineering, Robotics and Systems Engineering, University of Genoa, Via all'Opera Pia 13, 16145, Italy","2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)","5 Nov 2015","2015","","","5728","5731","Possession of `social' skills is crucial for persons with autism spectrum disorders (ASD) to maintain a certain independence and a better quality of life, and interaction with virtual environments seems an effective learning aid. In a previous study, we reported that in adults with ASD interaction with a virtual environment (a virtual city) is beneficial to the acquisition of pedestrian skills (street crossing and street navigation). Interaction was based on a gesture-based interface (Microsoft Kinect). Here we compare the learning performance when the same virtual environment is operated by a gamepad interface. We used exactly the same training protocol and data analysis than the original study. We found that both interface types are effective in the acquisition of street crossing and city navigation skills. The gamepad interface seems easier to use (thus leading to faster interaction), but gesture-based interfaces are superior in terms of transfer of the learned skills to real road environments (as reported by parents and caregivers).","1558-4615","978-1-4244-9271-8","10.1109/EMBC.2015.7319693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7319693","","Nickel;Virtual environments;Training;Navigation;Autism;Protocols","computer games;data analysis;learning (artificial intelligence);medical diagnostic computing;medical disorders;virtual reality","interface type effect;VR-based acquisition;pedestrian skills;autism spectrum disorders;quality-of-life;virtual environments;effective learning aid;ASD interaction;street crossing;street navigation;gesture-based interface;Microsoft Kinect;learning performance;gamepad interface;training protocol;data analysis","Accidents, Traffic;Autism Spectrum Disorder;Humans;Pedestrians;Quality of Life;User-Computer Interface","3","","11","","5 Nov 2015","","","IEEE","IEEE Conferences"
"Haptic stiffness identification by veterinarians and novices: A comparison","N. Forrest; S. Baillie; H. Z. Tan","Royal Veterinary College, University of London, Hawkshead Lane, AL9 7TA, UK; Royal Veterinary College, University of London, Hawkshead Lane, AL9 7TA, UK; Haptic Interface Research Laboratory, Purdue University, West Lafayette, IN, USA","World Haptics 2009 - Third Joint EuroHaptics conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems","3 Apr 2009","2009","","","646","651","Palpation is important in both veterinary and medical health professions. It is however difficult to learn, teach and assess. More must be understood about the skills involved in palpation. The present study compares the ability of practicing veterinarians and veterinary students to identify stiffness values. An absolute identification paradigm was used where a force-feedback device rendered virtual surfaces with 5 levels of stiffness within a ldquoclinically relevantrdquo range of 0.2 - 0.5 N/mm. The results from 12 veterinarians and 14 veterinary students show that the veterinarians performed significantly better than the students (p Lt 0.001). The mean information transfer was 0.97 bits (almost 2 perfectly-identifiable stiffness levels) for the veterinarians and 0.58 bits (1 correctly-identified stiffness level) for the students. However, neither group was able to reliably identify more than 2 levels of stiffness, indicating that the success of veterinarians in clinical practice probably relies on additional properties such as size, shape and texture. Our findings suggest that stiffness perception in the context of veterinary medicine is a learned clinical skill. Quantifying expert ability will help inform teaching methods and set targets for students. Similar psychophysical methods can also be used to monitor student performance throughout the learning process. Future work will examine the contributions of other object properties as well as motor strategies to palpation performance.","","978-1-4244-3858-7","10.1109/WHC.2009.4810800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810800","palpation;stiffness identification;comparison of experts and novices;veterinary medical education;haptics","Haptic interfaces;Medical simulation;Medical diagnostic imaging;Pregnancy;Education;Virtual reality;Educational institutions;Breast cancer;Cows;Psychology","biomedical education;computer aided instruction;force feedback;haptic interfaces;medical diagnostic computing;rendering (computer graphics);teaching;touch (physiological);veterinary medicine;virtual reality","haptic stiffness perception identification;veterinary medicine;palpation;medical health profession;force-feedback device;virtual surface rendering;mean information transfer;clinical skill learning;teaching method;psychophysical method;motor strategy;virtual reality haptic simulation;medical diagnosis","","11","","26","","3 Apr 2009","","","IEEE","IEEE Conferences"
"User Performance of VR-Based Dissection: Direct Mapping and Motion Coupling of a Surgical Tool","F. Trejo; Y. Hu","Dept. of Electr. & Comput. Eng., Univ. of Calgary, Calgary, AB, Canada; Dept. of Electr. & Comput. Eng., Univ. of Calgary, Calgary, AB, Canada","2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","17 Jan 2019","2018","","","3039","3044","Robot-assisted surgical systems aim at enhancing surgeon's skills. Nonetheless, the learning curve for mastering such systems is very slow due to the motion-coupling mode that is usually presented in these systems for manipulating a surgical tool. This mode has limitations compared to the direct mapping mode used in open surgery for manipulating a tool. Virtual reality (VR) surgical simulators may reduce the learning time for transferring the surgeon's skills from direct mapping to motion coupling of tool manipulation. This may be accomplished by adding two features to the simulator. First, force models of tool-tissue interaction can be implemented in the haptic interface of the simulator. Second, VR-based surgical tasks can be designed to recreate directmapping mode and motion coupling mode of tool manipulation, as in open and robot-assisted surgeries, respectively. This may permit to transfer the surgeon's skills from open surgery to robotassisted surgery in a timely manner. This work presents a preliminary study on the effect of direct mapping mode and motion coupling mode of tool manipulation on the performance of naïve participants for VR-based brain tissue dissection. An Analytic force model of soft-tissue dissection was implemented in the simulator along with visual feedback of a predefined tool speed of 1 mm/s, which is observed in neurosurgery. The outcomes indicated that the motion quality of the tool via direct mapping was significantly better than with motion coupling. Thus, the study might serve as a first step toward the assessment of user's skills for VR-based robot-assisted dissection.","2577-1655","978-1-5386-6650-0","10.1109/SMC.2018.00516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8616512","VR-based surgical simulation;direct mapping;motion coupling;robot-assisted surgery;soft-tissue dissection","Tools;Surgery;Task analysis;Robots;Couplings;Analytical models;Force","biological tissues;brain;haptic interfaces;medical computing;medical robotics;surgery;virtual reality","VR-based dissection;surgical tool;robot-assisted surgical systems;surgeon;motion-coupling mode;direct mapping mode;open surgery;surgical simulators;tool manipulation;tool-tissue interaction;VR-based surgical tasks;motion coupling mode;robot-assisted surgeries;VR-based brain tissue dissection;predefined tool speed;motion quality;VR-based robot-assisted dissection;direct-mapping mode;velocity 1.0 mm/s","","","","22","","17 Jan 2019","","","IEEE","IEEE Conferences"
"Combining ARToolKit with scene graph libraries","M. Haller; W. Hartmann; T. Luckeneder; J. Zauner","Univ. of Appl. Sci., Hagenberg, Austria; NA; NA; NA","The First IEEE International Workshop Agumented Reality Toolkit,","6 Jan 2003","2002","","","2 pp.","","Many Augmented and Mixed Reality applications are based on two libraries: OpenGL is used for rendering and ARToolKit is used for marker recognition. The ARToolkit library is great for rapid prototyping of AR/MR applications. The library is very easy to use and it hides the complexity of marker recognition. In the AMIRE (Authoring Mixed Reality) project, a European founded AR project, we follow up the aim of ARToolKit consistently: the AMIRE approach is to offer well-established gems (software solutions) and components for a faster prototyping of AR/MR applications. Each content user should be able to develop his/her own AR/MR application without any computer graphics skills. Therefore, one of the primary goals of AMIRE is to find well-established solutions of current AR/MR applications. One of the solution is the ARToolKit library, which is used in numberless AR/MR applications. But which library should be used for rendering? Can we use a high-level graphics AN together with ARToolKit? Which graphic library would be the best for farther AR/MR applications? Should developers use Direct3D/OpenGL or should we propose a high-level graphics API, like Open Inventor, OpenGL Performer, OpenSG, or Open SceneGraph? High-level graphics APIs have a number of advantages as opposed to low-level graphics APIs. They include: A set of loaders (e.g. model and texture loaders); A scenegraph concept; Modern object oriented design; High performance (optimized rendering, view frustum culling, small object culling, Level of Detail nodes, etc.). One problem still remains: How difficult is the usage of ARToolKit, originally based on OpenGL, in combination with a high-level graphics API like OpenSG? For the AMIRE project we tested two different APIs: Open SO and Open SceneGraph.","","0-7803-7680-3","10.1109/ART.2002.1106978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1106978","","Layout;Virtual reality;Application software;Software prototyping;Rendering (computer graphics);Prototypes;Software libraries;Computer graphics;Load modeling;Object oriented modeling","rendering (computer graphics);augmented reality;authoring systems","AMIRE;Authoring Mixed Reality;Augmented Reality;rendering;ARToolKit;marker recognition","","6","","6","","6 Jan 2003","","","IEEE","IEEE Conferences"
"SkyTools and DigiStrips: from the technology to the European operational context","S. Carlier; G. Gawinowski; L. Guichard; H. Hering","Innovative Res. Unit, Eurocontrol Exp. Centre, Bretigny, France; NA; NA; NA","20th DASC. 20th Digital Avionics Systems Conference (Cat. No.01CH37219)","6 Aug 2002","2001","2","","7E1/1","7E1/7 vol.2","For four years, CENA has been developing DigiStrips (Cena'00), a prototype that offers human machine interaction solutions based on large flat, touch-input screen, animation, graphical design, feedback and gesture recognition. DigiStrips offers an alternative solution to the display screen and mouse-based interaction. The Eurocontrol Experimental Centre (EEC) in its neutral role to identify, promote and integrate, at the European level, innovative ideas from European ATC R&D institutes, has considered DigiStrips as being able to provide benefits for the controller working position. Assumptions were made that this technology, when embedded in an operational context could make the ATCO work more comfortable and safe. This paper describes how we carried out the design and the validation of an air traffic controller working position that uses this technology. The challenge of this project is to make an ecological interface that respects controllers' skills and know-how, while introducing new technologies-new at least in the ATC domain. First, we summarize the technology proposed by CENA. Then we present the operational context and the result of the demonstrations given to several hundreds of European controllers. We also describe the validation approach chosen for DigiStrips.","","0-7803-7034-1","10.1109/DASC.2001.964203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=964203","","Humans;Air traffic control;Feedback;Virtual reality;Animation;Large screen displays;Paper technology;Auditory system;Prototypes;Research and development","air traffic control;interactive systems;touch sensitive screens;gesture recognition;human factors;computer graphics;aerospace computing;technology transfer","DigiStrips;human machine interaction;large flat screen;touch-input screen;animation;gesture recognition;graphical design;feedback;SkyTools project;European operational context;European ATC;air traffic controller working position;CENA;technology transfer","","","1","5","","6 Aug 2002","","","IEEE","IEEE Conferences"
"A visual/haptic interface to virtual environment (WYSIWYF display) and its application","Y. Yokokohji","Dept. of Mech. Eng., Kyoto Univ., Japan","Proceedings 1998 IEEE and ATR Workshop on Computer Vision for Virtual Reality Based Human Communications","6 Aug 2002","1998","","","99","104","VR training or skill transfer via virtual environment is a kind of human communication from one (expert) to others (trainee). To build a VR training system for visuo-motor skills, a visual interface should be correctly registered to a haptic interface so that the visual sensation and the haptic sensation are consistent spatially and temporally. Ideally a visual/haptic interface should be configured in such a way that what you see is what you feel as it is in the real life situations. In this paper, a reasonable method to realize correct visual/haptic registration is introduced. This method provides correct visual/haptic registration using a vision-based object tracking technique and a video keying technique. The first prototype called WYSIWYF Display has been built and the proposed concept was demonstrated. The paper then discusses a potential application to VR training using the WYSIWYF Display.","","0-8186-8283-3","10.1109/CVVRHC.1998.660376","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=660376","","Haptic interfaces;Virtual environment;Displays;Cameras;Rendering (computer graphics)","virtual reality;graphical user interfaces","visual/haptic interface;virtual environment;WYSIWYF display;virtual reality;visuo-motor skills;visual interface;video keying technique","","2","","19","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Co-presentation of force cues for skill transfer via shared-control systems","D. Powell; M. K. O'Malley","Rice University, USA; Rice University, USA","2010 IEEE Haptics Symposium","8 Apr 2010","2010","","","453","456","During training and rehabilitation with haptic devices, it is often necessary to simultaneously present force cues arising from different haptic models (such as guidance cues and environmental forces). Multiple force cues are typically summed to produce a single output force, which conveys only relative information about the original force cues and may not be useful to trainees. Two force co-presentation paradigms are proposed as potential solutions to this problem: temporal separation of force cues, where one type of force is overlaid with the other in staggered pulses, and spatial separation, where the forces are presented via multiple haptic devices. A generalized model for separating task and guidance forces in a virtual environment is also proposed. In a pilot study where sixteen participants were trained in a dynamic target-hitting task using these co-presentation paradigms, simple summation was in fact most effective at eliciting skill transfer in most respects. Spatial separation imposed the lowest overall workload on participants, however, and might thus be more appropriate than summation in tasks with other significant physical or mental demands. Temporal separation was relatively inferior at eliciting skill transfer, but it is hypothesized that this paradigm would have performed considerably better in a non-rhythmic task, and the need for further research is indicated.","2324-7355","978-1-4244-6822-5","10.1109/HAPTIC.2010.5444619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444619","","Haptic interfaces;Virtual environment;Fixtures;Education;Performance evaluation;Manipulator dynamics;Displays;USA Councils;Force control;Feedback","haptic interfaces;virtual reality","force cues;skill transfer;shared-control systems;haptic devices;guidance cues;environmental forces;virtual environment;copresentation paradigms","","1","","7","","8 Apr 2010","","","IEEE","IEEE Conferences"
"InterPoser: Visualizing Interpolated Movements for Bouldering Training","K. Shiro; K. Egawa; T. Miyaki; J. Rekimoto","The University of Tokyo; The University of Tokyo; The University of Tokyo; The University of Tokyo, Sony Computer Science Laboratories, Inc.","2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","15 Aug 2019","2019","","","1563","1565","Bouldering is an urban form of rock climbing that requires precise and complex movement. Similarly to other sports, the simplest way to learn bouldering skill is to mimic professional's motion. However, ordinary beginner boulders cannot learn to coaches, so that they learn by themselves or tutorial videos. Even if they managed, bouldering has a communication difficulty between a trainee and a trainer, that is, climbers cannot mimic the trainer's movement in parallel. Accordingly, we considered a video feedback system would be useful for beginners and suggested InterPoser: a novel visualization system for intermediate motion between a beginner climber and a more experienced. InterPoser receives two videos of different subjects climbing the sample problem and generates an intermediate movement. In addition, this motion is transferred into realistic images of the climber. The proposed system is expected to support beginner to acquire more detailed observation and understanding of the motion.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798366","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798366","Computing methodologies;Motion Processing;Human-centered computing;Visualization;Visualization techniques;Human computer interaction (HCI)","Sports;Training;Visualization;Interpolation;Pose estimation;Human computer interaction;Two dimensional displays","computer based training;data visualisation;sport","InterPoser;bouldering training;rock climbing;sports;bouldering skill;ordinary beginner boulders;tutorial videos;communication difficulty;video feedback system;intermediate motion;beginner climber;intermediate movement;visualization system","","","","14","","15 Aug 2019","","","IEEE","IEEE Conferences"
"Incorporation of motor control and motor learning principles into VR applications","M. F. Levin; S. K. Subramanian; M. T. Robert","School of Physical and Occupational Therapy, McGill University; Department of Neuroscience, University of Montreal; Integrated Program in Neuroscience, McGill University","2015 International Conference on Virtual Rehabilitation (ICVR)","17 Dec 2015","2015","","","2","2","The primary focus of rehabilitation for individuals with motor deficits is the relearning of specific motor skills and daily tasks. Rehabilitation strives to take advantage of neuroplastic processes during recovery, a process that can be addressed by creating enriched training environments using virtual reality (VR) based simulations. The objectives of this workshop are to review motor control and motor learning principles, to discuss how they can be exploited by VR training environments and to provide examples of how these principles have been incorporated into different VR simulations for improving upper limb motor recovery. The workshop includes a practical component in which participants will design a specific intervention for improving a typical motor problem incorporating motor control and motor learning principles, in both a VR-based and a non-VR-based clinical application. Finally, we will discuss the limitations of the current technologies with respect to their effectiveness and transfer of learning to daily life tasks.","2331-9569","978-1-4799-8984-3","10.1109/ICVR.2015.7358630","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7358630","","Motor drives;Neuroscience;Training;Solid modeling;Conferences;Medical treatment;Virtual reality","bioelectric potentials;learning (artificial intelligence);neurophysiology;patient rehabilitation;virtual reality","motor control principles;motor learning principles;patient rehabilitation;neuroplastic processes;virtual reality based simulations;upper limb motor recovery","","","","","","17 Dec 2015","","","IEEE","IEEE Conferences"
"Operational Skill Training Needs Analysis for Manufacturing Industry","Z. Cheng; Z. Niu; P. Wei","Coll. of Manage. & Econ., Tianjin Univ., Tianjin, China; Coll. of Manage. & Econ., Tianjin Univ., Tianjin, China; Coll. of Manage. & Econ., Tianjin Univ., Tianjin, China","2011 International Conference of Information Technology, Computer Engineering and Management Sciences","29 Dec 2011","2011","3","","394","397","Manufacturers face the problem of how to enhance the operational skill of the operators, with the purpose of improving overall efficiency and quality. A three-step method is offered in this paper to solve the problem. The method includes key position analysis, key motion cells analysis, and key skill cells analysis. Key positions are observed by bottleneck and CTQ analysis from all positions. Key motions cells are found by five principles from key positions. And key skill cells are found by cluster analysis and simulation from key motion cells. Empirical results show that the three-step method can extract information from the operations in plant to form the key skill cells with high efficiency and precision. The three-step method can effectively help us observe the key motions and transfer them into key skill cells which will be the fundament for skill training, and thus the problem of operational skill training needs analysis is solved.","","978-1-4577-1419-1","10.1109/ICM.2011.99","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6113559","training needs;operational skills;motion cells;skill cells;cluster analysis","Training;Fasteners;Presses;Valves;Analytical models;Face;Educational institutions","human resource management;industrial training","operational skill training needs analysis;manufacturing industry;three-step method;key position analysis;key motion cells analysis;key skill cells analysis;cluster analysis","","2","","14","","29 Dec 2011","","","IEEE","IEEE Conferences"
"Keyboard control method for virtual reality micro-robotic cell injection training","S. Faroque; B. Horan; M. Joordens","School of Engineering, Deakin University Geelong, VIC, Australia; School of Engineering, Deakin University Geelong, VIC, Australia; School of Engineering, Deakin University Geelong, VIC, Australia","2015 10th System of Systems Engineering Conference (SoSE)","9 Jul 2015","2015","","","416","421","The rapid development of virtual reality offers significant potential for skills training applications. Our ongoing work proposes virtual reality operator training for the micro-robotic cell injection procedure. The interface between the operator and the system can be achieved in many different ways. The computer keyboard is ubiquitous in its use for everyday computing applications and also commonly utilized in virtual reality systems. Based on the premise that most people have experience in using a computer keyboard, as opposed to more sophisticated input devices, this paper considers the feasibility of using a keyboard to control the micro-robot for cell injection. In this study, thirteen participants underwent the experimental evaluation. The participants were asked to perform three simulated trial sessions in a virtual micro-robotic cell injection environment. Each session consisted of ten cell injection trials and relevant data for each trial were recorded and analyzed. Results showed participants' performance improvement after the three sessions. It was also observed that participants intuitively controlled multiple axes of the micro-robot simultaneously despite the absence of instruction on how to do so. This continued throughout the experiments and suggests skills transfer from other keyboard based interactions. Based on the results provided, it is suggested that keyboard control is a feasible, simple and low-cost control method for the virtual micro-robot.","","978-1-4799-7611-9","10.1109/SYSOSE.2015.7151946","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7151946","Cell injection;virtual reality;micromanipulation;micro-robot;skills training","Keyboards;Haptic interfaces;Training;Systems engineering and theory;Computers;Virtual environments","biomedical education;cellular biophysics;computer based training;keyboards;microrobots;virtual reality","keyboard control method;virtual reality microrobotic cell injection training;skill training applications;virtual reality operator training;microrobotic cell injection procedure;ubiquitous computer keyboard;input devices;keyboard based interactions;low-cost control method","","1","","15","","9 Jul 2015","","","IEEE","IEEE Conferences"
"Coupled-clay: Physical-virtual 3D collaborative interaction environment","K. Ozacar; T. Hagiwara; J. Huang; K. Takashima; Y. Kitamura",Research Institute of Electrical Communication Tohoku University; Research Institute of Electrical Communication Tohoku University; Research Institute of Electrical Communication Tohoku University; Research Institute of Electrical Communication Tohoku University; Research Institute of Electrical Communication Tohoku University,"2015 IEEE Virtual Reality (VR)","27 Aug 2015","2015","","","255","256","We propose Coupled-clay, a bi-directional 3D collaborative interactive environment that supports the 3D modeling work between groups of users at remote locations. Coupled-clay consists of two network-connected workspaces, the Physical Interaction Space and the Virtual Interaction Space. The physical interaction space allows a user to directly manipulate a physical object whose shape and position are precisely tracked. This tracked 3D information is transferred to the virtual interaction space in real time. The virtual interaction space is made of an interactive multi-user stereoscopic 3D tabletop, or other 3D displays with adequate interaction device. The users at the virtual interaction space observe the virtual 3D object which corresponds to the physical object and manipulate its geometrical attributes (e.g., translation, rotation and scaling). Additionally, they can control the graphical attributes of the virtual object such as color and texture. Information about changes in geometrical and graphical attributes are sent back to the physical interaction space in real time and reflected to the object in the physical interaction space by a robotic arm and a top-mounted projector. Coupled-clay can be used to remotely collaborate on 3D modeling tasks such as between a skilled designer and novice learners. This paper details our Coupled-clay implementation and presents its interaction capabilities.","2375-5334","978-1-4799-1727-3","10.1109/VR.2015.7223392","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223392","H.5.3 [INFORMATION INTERFACES AND PRESENTATION]: Group and Organization Interfaces — Collaborative computing;I.3.7 [Computing Methodologies];COMPUTER GRAPHICS — Three-Dimensional Graphics and Realism","Three-dimensional displays;Shape;Real-time systems;Collaboration;Bidirectional control;Electronic mail;Robots","interactive devices;solid modelling;stereo image processing;three-dimensional displays;virtual reality","coupled-clay;physical-virtual 3D collaborative interaction environment;bidirectional 3D collaborative interactive environment;remote location;network-connected workspace;physical interaction space;virtual interaction space;3D information;multiuser stereoscopic 3D tabletop;3D display;interaction device;virtual 3D object;physical object;geometrical attribute;graphical attribute;virtual object;robotic arm;top-mounted projector;3D modeling task","","","","4","","27 Aug 2015","","","IEEE","IEEE Conferences"
"Using Augmented Reality to Elicit Pretend Play for Children with Autism","Z. Bai; A. F. Blackwell; G. Coulouris","Computer Laboratory, University of Cambridge, United Kingdom; Computer Laboratory, University of Cambridge, United Kingdom; Computer Laboratory, University of Cambridge, United Kingdom","IEEE Transactions on Visualization and Computer Graphics","25 Mar 2015","2015","21","5","598","610","Children with autism spectrum condition (ASC) suffer from deficits or developmental delays in symbolic thinking. In particular, they are often found lacking in pretend play during early childhood. Researchers believe that they encounter difficulty in generating and maintaining mental representation of pretense coupled with the immediate reality. We have developed an interactive system that explores the potential of Augmented Reality (AR) technology to visually conceptualize the representation of pretense within an open-ended play environment. Results from an empirical study involving children with ASC aged 4 to 7 demonstrated a significant improvement of pretend play in terms of frequency, duration and relevance using the AR system in comparison to a non computer-assisted situation. We investigated individual differences, skill transfer, system usability and limitations of the proposed AR system. We discuss design guidelines for future AR systems for children with ASC and other pervasive developmental disorders.","1941-0506","","10.1109/TVCG.2014.2385092","Cambridge Overseas Trust; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7000596","H.5.1 Multimedia Information Systems;Augmented Reality, pretend play, children, autism","Autism;Computers;Airplanes;Vehicles;Educational institutions;Target tracking;Materials","augmented reality;handicapped aids;medical disorders","augmented reality;pervasive developmental disorders;system limitations;system usability;skill transfer;individual-differences;relevance parameter;duration parameter;frequency parameter;empirical study;open-ended play environment;visually conceptualized pretense representation;AR technology;interactive system;pretense mental representation;immediate reality;pretend play;symbolic thinking;developmental delays;deficits;ASC;autism spectrum condition;autistic children","Asperger Syndrome;Autistic Disorder;Child;Child, Preschool;Computer Graphics;Female;Humans;Male;Play Therapy;Virtual Reality Exposure Therapy","35","","36","","31 Dec 2014","","","IEEE","IEEE Journals"
"Toward machine mediated training of motor skills. Skill transfer from human to human via virtual environment","Y. Yokokohji; R. L. Hollis; T. Kanade; K. Henmi; T. Yoshikawa","Dept. of Mech. Eng., Kyoto Univ., Japan; NA; NA; NA; NA","Proceedings 5th IEEE International Workshop on Robot and Human Communication. RO-MAN'96 TSUKUBA","6 Aug 2002","1996","","","32","37","We investigate a possibility of skill mapping from human to human via a visual/haptic display system. Our goal in the future is to develop a training system for motor skills such as surgical operations. We have proposed a new concept of visual/haptic display called a WYSIWYF Display; (What You See Is What You Feel). The proposed concept ensures correct visual/haptic registration which is important for effective hand-eye coordination training. Using the prototype WYSIWYF display, we did a preliminary experiment of skill training. Our idea of skill transfer is very simple; basically it is a ""record-and-replay"" strategy. Questions are ""What is the essential data to be recorded for transferring the skill?"" and ""What is the best way to provide the data to the trainee?"". Several methods were tried but no remarkable result was obtained, presumably because the chosen task was too simple.","","0-7803-3253-9","10.1109/ROMAN.1996.568646","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=568646","","Humans;Robot kinematics;Displays;Intelligent robots;Haptic interfaces;Virtual reality;Prototypes;Medical robotics;Surgery;Mechanical engineering","computer based training;virtual reality","machine mediated training;motor skills;skill transfer;virtual environment;skill mapping;visual/haptic display system;surgical operations;WYSIWYF Display;What You See Is What You Feel;hand-eye coordination training;record-and-replay strategy","","44","","21","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Robot Patient Design to Simulate Various Patients for Transfer Training","Z. Huang; C. Lin; M. Kanai-Pak; J. Maeda; Y. Kitajima; M. Nakamura; N. Kuwahara; T. Ogata; J. Ota","School of Automation, Guangdong University of Technology, Guangzhou, China; Research into Artifacts, Center for Engineering, University of Tokyo, Chiba, Japan; Kanto Gakuin University, Yokohama, Japan; Faculty of Nursing, Tokyo Ariake University of Medical and Health Sciences, Tokyo, Japan; Faculty of Nursing, Tokyo Ariake University of Medical and Health Sciences, Tokyo, Japan; Faculty of Nursing, Tokyo Ariake University of Medical and Health Sciences, Tokyo, Japan; Department of Advanced Fibro-Science, Kyoto Institute of Technology, Kyoto, Japan; Research into Artifacts, Center for Engineering, University of Tokyo, Chiba, Japan; Research into Artifacts, Center for Engineering, University of Tokyo, Chiba, Japan","IEEE/ASME Transactions on Mechatronics","13 Oct 2017","2017","22","5","2079","2090","To improve the patient transfer skill of nursing education students, we developed a robot patient that can simulate three categories of patients: 1) patients whose movements are affected by paralysis; 2) patients whose movements are sensitive to pain with painful expression; and 3) patients whose movements are constrained by medical devices. By practicing with the robot patient, nursing students can learn the skills required for interacting with various patients. To simulate trunk movements of these different patients, novel waist and hip joints with hardware-inherent compliance and force-sensing capability were proposed. In addition, control methods were developed and the parameters were tuned based on actual patient videos. To evaluate the developed robot, nursing teachers performed trials of transferring the robot patient as they would transfer an actual patient. The nursing teachers scored the robot patients based on a checklist. Moreover, subjective evaluations of a questionnaire were performed by the nursing teachers. The results showed that the nursing teachers performed most of the required skills of the checklist and agreed regarding the learning effectiveness of the robot. They recommended training nursing students using the robot patient in the questionnaire. Finally, hugging speed comparison showed that the nurses slow down the speed when dealing with a robot patient with painful expression.","1941-014X","","10.1109/TMECH.2017.2730848","Japan Society for the Promotion of Science KAKENHI; National Science Foundation of China; Natural Science Foundation of Guangdong Province, China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990192","Compliant joint;patient transfer;robot patient;various patients","Training;Medical services;Robot sensing systems;Hip;Force","biomedical education;computer aided instruction;control system synthesis;educational robots;human-robot interaction;medical computing;medical robotics;patient care","nursing teachers;robot patient design;patient transfer skill;nursing education students;force-sensing capability;control parameter tuning;transfer training","","","","48","Traditional","24 Jul 2017","","","IEEE","IEEE Journals"
"Virtual Reality Based Knowledge Acquisition and Job Training for Advanced Casting Skills","K. Watanuki; K. Kojima","Saitama University, Japan; Saitama University, Japan","16th International Conference on Artificial Reality and Telexistence--Workshops (ICAT'06)","12 Feb 2007","2006","","","666","671","The environment where Japanese industry has beenpaid with respect is changing tremendously due to the globalization of economics, where Asian countries are undergoing economical and technical development as well as advancing in information technology. For example, in the design of custom-made casting product, a designer whom lacking of casting knowledge may not be able to produce a good design. In order to obtain a good design and manufacturing result, it is necessary to equip the designer and manufacturer with a support system related to casting design or so called, knowledge transfer and creation system. In recent years, the design supporting system using VR technology is developed, and introduced in the manufacturing industry. The merit of using VR system is being able to carry out the stereoscopy of the product model drawn by 3D CAD, and to carry out the design review of the product model in the same size as thing. However, since many systems extend the display of the conventional 3D CAD, they cannot input annotation and so on directly in VR environment. In this paper, the system which can input and display the annotation in VR environment is developed. By drawing annotation to the product model displayed on VR environment, sharing of technical tacit knowledge and engineers' communication are promoted, and engineers becomes possible gaining physical tacit knowledge.","","0-7695-2754-X","10.1109/ICAT.2006.147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4089335","","Virtual reality;Knowledge acquisition;Casting;Environmental economics;Manufacturing;Design automation;Knowledge engineering;Industrial training;Industrial economics;Globalization","CAD;casting;computer aided instruction;multimedia systems;production engineering computing;virtual reality","virtual reality;knowledge acquisition;job training;advanced casting skills;Japanese industry;Asian countries;information technology;custom-made casting product;casting knowledge;casting design;knowledge transfer;design supporting system;manufacturing industry;VR system;3D CAD;technical tacit knowledge","","3","","4","","12 Feb 2007","","","IEEE","IEEE Conferences"
"IMA-VR: A multimodal virtual training system for skills transfer in Industrial Maintenance and Assembly tasks","T. Gutiérrez; J. Rodríguez; Y. Vélaz; S. Casado; A. Suescun; E. J. Sánchez","LABEIN-TECNALIA, Spain; Department of Applied Mechanics, CEIT and TECNUN, Spain; Department of Applied Mechanics, CEIT and TECNUN, Spain; LABEIN-TECNALIA, Spain; Department of Applied Mechanics, CEIT and TECNUN, Spain; Department of Applied Mechanics, CEIT and TECNUN, Spain","19th International Symposium in Robot and Human Interactive Communication","11 Oct 2010","2010","","","428","433","Industrial Maintenance and Assembly is a very complex task involving both cognitive skills (procedural skills) and motor skills (fine motor control and bi-manual coordination skills). This paper presents a controlled multimodal training system, for transferring the motor and cognitive skills involved in these tasks. The new platform provides different multimodal aids and learning strategies that help and guide the users during their training process. One of the main features of this system is its flexibility to adapt itself to the task demands and to the users' preferences and needs supporting different configurations. To address bi-manual operations the platform offers different alternatives, one of them is a set-up composed of a haptic device to track the motion of the operator's dominant hand and simulate the physical interaction within the virtual environment, together with a marker-less motion capture system to track the motion of the other hand in real time.","1944-9437","978-1-4244-7990-0","10.1109/ROMAN.2010.5598643","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5598643","","Haptic interfaces;Training;Assembly;Rendering (computer graphics);Visualization;Force;Message systems","assembling;computer based training;haptic interfaces;maintenance engineering;production engineering computing;virtual reality","multimodal virtual training system;skills transfer;industrial maintenance task;industrial assembly task;multimodal aids;learning strategy;haptic device;marker-less motion capture system;IMA-VR training system;virtual reality","","20","","18","","11 Oct 2010","","","IEEE","IEEE Conferences"
"VR training system with adaptive operational assistance considering straight-line transfer operation","M. Yoneda; F. Arai; T. Fukuda; K. Miyata; T. Naito","Dept. of Micro Syst. Eng., Nagoya Univ., Japan; NA; NA; NA; NA","8th IEEE International Workshop on Robot and Human Interaction. RO-MAN '99 (Cat. No.99TH8483)","6 Aug 2002","1999","","","142","147","This paper deals with an operational assistance system of a rough terrain crane. A proper control rule to operate the payload in the straight-line motion is proposed. The system assists straight-line operation with force display based on the rule. The strength of assistance can be adapted to operator's skill level by changing the gain of force display. We present some experiments on a crane simulator, and show the effectiveness of the proposed operational assistance system.","","0-7803-5841-4","10.1109/ROMAN.1999.900330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=900330","","Virtual reality;Adaptive systems;Cranes;Control systems;Automatic control;Displays;Proposals;Payloads;Systems engineering and theory;Motion control","cranes;computer based training;virtual reality;force feedback;simulation;adaptive systems","training;operational assistance system;straight-line motion;force display;operator skill;crane simulator;virtual reality","","1","","6","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Comparative Study on Networking Simulation Tools Using Correlation Analysis","E. Chua; A. Magbag; A. T. Manaloto; M. J. Rabena; M. R. Rodavia","CICT, Holy Angel Univ. Angeles City, Angeles, Philippines; CICT, Holy Angel Univ. Angeles City, Angeles, Philippines; CICT, Holy Angel Univ. Angeles City, Angeles, Philippines; CICT, Holy Angel Univ. Angeles City, Angeles, Philippines; GS, AUF, Angeles, Philippines","2018 International Symposium on Educational Technology (ISET)","6 Sep 2018","2018","","","123","127","Several researches were conducted and has proven the effectiveness and differences of network simulation tools such as Packet Tracer and Graphical Network Simulator. Simulation tools provide a means for the students to experience network configuration in a virtual environment and enhances their troubleshooting skills in the network architecture. This paper aims to provide a comparison in the transfer of knowledge from the simulated environment and the actual laboratory of Packet Tracer and Graphical Network Simulator 3(GNS3). An experimental approach was implemented to identify the performance of 30 students grouped into two. Each group was assigned a simulation tool but were given the same topology and network requirements. The instrument used to measure the configuration and troubleshooting skills were lifted from the Cisco Certified Network Entry Technician certification. Correlation analysis was applied in processing the data from students' scores. Results showed evidence on the transfer of skills from two environments and identified GNS3 as getting a higher percentage of knowledge transfer.","","978-1-5386-7209-9","10.1109/ISET.2018.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8456203","simulation;packet tracer;GNS","Tools;Correlation;Task analysis;Education;Routing;Urban areas;Network topology","computer aided instruction;computer networks;computer science education;correlation methods;digital simulation;telecommunication computing;telecommunication engineering education;topology","network requirements;troubleshooting skills;Cisco Certified Network Entry Technician certification;correlation analysis;networking simulation tools;network simulation tools;Packet Tracer;simulation tool;network configuration;network architecture;simulated environment;Graphical Network Simulator 3;topology requirements;knowledge transfer","","","","16","","6 Sep 2018","","","IEEE","IEEE Conferences"
"A Reinforcement Learning Architecture That Transfers Knowledge Between Skills When Solving Multiple Tasks","P. Tommasino; D. Caligiore; M. Mirolli; G. Baldassarre","Robotics Research Centre, Nanyang Technological University, Singapore; Laboratory of Computational Embodied Neuroscience, Istituto di Scienze e Tecnologie della Cognizione, Consiglio Nazionale delle Ricerce, Rome, Italy; Laboratory of Computational Embodied Neuroscience, Istituto di Scienze e Tecnologie della Cognizione, Consiglio Nazionale delle Ricerce, Rome, Italy; Laboratory of Computational Embodied Neuroscience, Istituto di Scienze e Tecnologie della Cognizione, Consiglio Nazionale delle Ricerce, Rome, Italy","IEEE Transactions on Cognitive and Developmental Systems","10 Jun 2019","2019","11","2","292","317","When humans learn several skills to solve multiple tasks, they exhibit an extraordinary capacity to transfer knowledge between them. We present here the last enhanced version of a bio-inspired reinforcement-learning (RL) modular architecture able to perform skill-to-skill knowledge transfer and called transfer expert RL (TERL) model. TERL architecture is based on a RL actor-critic model where both actor and critic have a hierarchical structure, inspired by the mixture-of-experts model, formed by a gating network that selects experts specializing in learning the policies or value functions of different tasks. A key feature of TERL is the capacity of its gating networks to accumulate, in parallel, evidence on the capacity of experts to solve the new tasks so as to increase the responsibility for action of the best ones. A second key feature is the use of two different responsibility signals for the experts' functioning and learning: this allows the training of multiple experts for each task so that some of them can be later recruited to solve new tasks and avoid catastrophic interference. The utility of TERL mechanisms is shown with tests involving two simulated dynamic robot arms engaged in solving reaching tasks, in particular a planar 2-DoF arm, and a 3-D 4-DoF arm.","2379-8939","","10.1109/TCDS.2016.2607018","European Commission; ICT Challenge 2 “Cognitive Systems and Robotics” through the Project “IM-CLeVeR—Intrinsically Motivated Cumulative Learning Versatile Robots”; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7592409","Autonomous robotics;bio-inspired modular neural architecture;catastrophic interference;cumulative learning;functioning and learning responsibility signals;mixture-of-expert networks;reaching tasks;transfer reinforcement learning (TRL)","Biological system modeling;Computer architecture;Learning (artificial intelligence);Manipulators;Brain modeling;Organisms","knowledge management;learning (artificial intelligence);manipulator dynamics","gating network;TERL mechanisms;reinforcement learning architecture;extraordinary capacity;bio-inspired reinforcement-learning modular architecture;skill-to-skill knowledge transfer;transfer expert RL model;TERL architecture;RL actor-critic model;mixture-of-experts model;responsibility signals;planar 2-DoF arm;3-DoF arm;4-DoF arm","","4","","101","","14 Oct 2016","","","IEEE","IEEE Journals"
"Perceptually augmented simulator design through decomposition","T. Edmunds; D. K. Pai","Rutgers University, USA; University of British Columbia, USA","World Haptics 2009 - Third Joint EuroHaptics conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems","3 Apr 2009","2009","","","505","510","We approach the problem of determining a general method for augmenting haptic simulators to amplify the perceptually salient aspects of the interaction that induce effective skill transfer. Using such a method, we seek to simplify the design of haptic simulators that can improve training effectiveness without requiring expensive improvements in the capability of the rendering hardware. We present a decomposition approach to the automated design of perceptually augmented simulations, and we describe a user-study of the training effectiveness of a search-task simulator designed using our approach vs. an un-augmented simulator. The results indicate that our decomposition approach allows existing psychophysical findings to be leveraged in the design of haptic simulators that effectively impart skill by targeting perceptually significant aspects of the interaction.","","978-1-4244-3858-7","10.1109/WHC.2009.4810890","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810890","","Haptic interfaces;Engines;Shape;Analytical models;Surface texture;Hardware;Surgery;Jamming;Virtual environment;Teleoperators","augmented reality;haptic interfaces;rendering (computer graphics)","perceptually augmented simulator design;haptic simulators augmentation;rendering hardware;search-task simulator","","1","","14","","3 Apr 2009","","","IEEE","IEEE Conferences"
"Evaluation of learner's skills in the context of dynamic and complex systems","K. Yacef; L. Alem","Thomson Radar Australia Corp., Australia; NA","1996 IEEE International Conference on Systems, Man and Cybernetics. Information Intelligence and Systems (Cat. No.96CH35929)","6 Aug 2002","1996","3","","2200","2204 vol.3","The air traffic control (ATC) operational skills are developed using simulation of authentic problems. Such authentic problems have enormous potential for learning as they are real and will probably arise in the controller's real work. Resolving authentic problems on a simulator encourages transfer by demonstrating when the knowledge is useful and by showing the effect of the learner's actions. However this process is difficult, since authentic problems tend to require a wide range of knowledge which often lead the learner in activities beyond their abilities. Some support is required for learning from simulation to occur. Sometimes this support is provided by human tutors (in ATC training for example this support is provided by a human instructor sitting at the back of the controller during the running of an exercise on the simulator), this support could also be given by a computer learning environment. This paper presents an intelligent simulator-based learning environment for air traffic controllers which provides a protected and guided environment to the learner. One central element of this environment is the ability to evaluate the learner's skills. We describe our approach to the evaluation of learner's skills, which uses task performance as well as situation complexity and degree of task practice as a means for building an overlay model of the learner.","1062-922X","0-7803-3280-6","10.1109/ICSMC.1996.565492","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=565492","","Humans;Problem-solving;Availability;Intelligent systems;Context modeling;Intelligent structures;Performance evaluation;Air traffic control","air traffic control;aerospace simulation;digital simulation;computer based training;computer aided instruction;user modelling","learner skill evaluation;dynamic complex systems;air traffic control;ATC;human tutors;intelligent simulator-based learning environment;task performance;situation complexity","","1","1","14","","6 Aug 2002","","","IEEE","IEEE Conferences"
"An Evaluation of Inanimate and Virtual Reality Training for Psychomotor Skill Development in Robot-Assisted Minimally Invasive Surgery","G. Caccianiga; A. Mariani; E. De Momi; G. Cantarero; J. D. Brown","Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Biorobotics Institute, Scuola Superiore Sant’Anna, Pisa, Italy; Department of Electronics, Information, and Bioengineering, Politecnico di Milano, Milan, Italy; Department of Physical Medicine and Rehabilitation, Johns Hopkins Medical Institute, Baltimore, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA","IEEE Transactions on Medical Robotics and Bionics","20 May 2020","2020","2","2","118","129","Robot-assisted minimally invasive surgery (RAMIS) is gaining widespread adoption in many surgical specialties, despite the lack of a standardized training curriculum. Current training approaches rely heavily on virtual reality simulators, in particular for basic psychomotor and visuomotor skill development. It is not clear, however, whether training in virtual reality is equivalent to inanimate model training. In this manuscript, we seek to compare virtual reality training to inanimate model training, with regard to skill learning and skill transfer. Using a custom-developed needle-driving training task with inanimate and virtual analogs, we investigated the extent to which N=18 participants improved their skill on a given platform post-training, and transferred that skill to the opposite platform. Results indicate that the two approaches are not equivalent, with more salient skill transfer after inanimate training than virtual training. These findings support the claim that training with real physical models is the gold standard, and suggest more inanimate model training be incorporated into training curricula for early psychomotor skill development.","2576-3202","","10.1109/TMRB.2020.2990692","JHU internal fundings; Tesi All’estero Scholarship of Politecnico di Milano; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9080087","Automated;inanimate;minimally invasive;objective;robot-assisted;sensors;simulation;skill transfer;surgery;training;virtual reality","Training;Task analysis;Solid modeling;Robot sensing systems;Needles","computer based training;control engineering computing;medical computing;medical robotics;surgery;training;virtual reality","current training approaches;virtual reality simulators;basic psychomotor;visuomotor skill development;inanimate model training;virtual reality training;skill learning;custom-developed needle-driving training task;inanimate analogs;virtual analogs;given platform post-training;salient skill transfer;inanimate training;virtual training;training curricula;early psychomotor skill development;robot-assisted minimally invasive surgery;standardized training curriculum","","","","53","IEEE","28 Apr 2020","","","IEEE","IEEE Journals"
"Simulation-Based Training Improves Catering Apprentices' Mise-en-Place Knowledge and Procedure Skills","Y. R. Yen","Dept. of MIS, Far East Univ., Tainan, Taiwan","2014 IEEE 14th International Conference on Advanced Learning Technologies","22 Sep 2014","2014","","","240","241","The research purpose of this paper is to discuss skill education's computer simulation training method and, with traditional film teaching method as the control group, know about the learning effectiveness of freshmen majoring in catering with respect to mise-en-place course of Western-style food. Moreover, the paper will probe further into the personal characteristics that affect the willingness to participate in simulation learning, and the user experience of instructional media.","2161-377X","978-1-4799-4038-7","10.1109/ICALT.2014.76","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6901448","Simulation-based training;computer self-efficacy;transfer of training;Mise en place component;Catering training","Training;Computational modeling;Computers;Marine animals;Films;Iron;Computer simulation","catering industry;computer based training;digital simulation;teaching","catering apprentices Mise-en-Place knowledge;procedure skills;skill education computer simulation training method;film teaching method;control group;freshmen learning effectiveness;Western-style food;personal characteristics;simulation learning;instructional media","","","","4","","22 Sep 2014","","","IEEE","IEEE Conferences"
"A Framework for Development of an Intra-Hospital Patient Transfer Using Queue Management System","E. Meephu; S. Arwatchananukul; N. Aunsri","Mae Fah Luang University, School of Information Technology, Chiang Rai, Thailand; Mae Fah Luang University, School of Information Technology, Chiang Rai, Thailand; Mae Fah Luang University, Brain Science and Engineering Innovation Reseach Group, Chiang Rai, Thailand","2018 Global Wireless Summit (GWS)","11 Apr 2019","2018","","","300","303","This article presents a framework for the design of a queue management system for Intra-hospital patient transfer (IHT) process. The proposed queue management system aims to improve efficientcy of the process and to reduce waiting time of Intra-hospital patients transfers. Factor that effect the quality of IHT is staff skill. There are three factors that increase the waiting time of transfer process are communication between staff and transfer center, overcrowds of request, and inadequate number of staffs. The development of queue management system began with collecting and analysis the data of current IHT process for finding the waiting time, number of requests and adverse events form transfer process. After that, we generate Intra-hospital patient transfer algorithm to the reduce waiting time and improve quality if IHT. We plan to create various type of conditions that can be used in the future for model validation and realiability.","","978-1-5386-4288-7","10.1109/GWS.2018.8686487","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8686487","Intra-hospital patient transfer;intrahospital transfer;Queue management system;Patient transport;Simulation","","health care;hospitals;medical administrative data processing;queueing theory","queue management system;waiting time;Intra-hospital patient transfer algorithm;IHT quality;health care system","","","","16","","11 Apr 2019","","","IEEE","IEEE Conferences"
"Machine-mediated Motor Skill Training Method in Haptic-enabled Chinese Handwriting Simulation System","D. Wang; Y. Zhang; C. Yao","Robotics Institute, Beihang University Beijing, P. R. China, 100083. hapticwang@buaa.edu.cn, rushyao007@163.com; Robotics Institute, Beihang University Beijing, P. R. China, 100083. yuru@buaa.edu.cn, rushyao007@163.com; Robotics Institute, Beihang University Beijing, P. R. China, 100083. rushyao007@163.com","2006 IEEE/RSJ International Conference on Intelligent Robots and Systems","15 Jan 2007","2006","","","5644","5649","Training of motor skill through machine-mediated method is a promising way to improve complex dexterous manipulation skill. New method of fusion between human motor skill and machine capability is studied to transfer skill from expert to novice. Haptic-enabled Chinese handwriting training system is established as a benchmark platform for studying learning and transfer of motor skill. Perceptible element of haptic skill is proposed to model human motor skill. Four rules of machine-mediated training system are identified according to human's skill learning characteristics. Architecture of a hierarchical hybrid control training system is proposed based on the learning rules. Phantom desktop is used as the haptic interface and haptic-visual feedback is developed for three training modes, which includes facsimile mode, transcribe mode and reciting mode. Human subject experiments validate the proposed training rules. Fusion of human skill and machine capability by haptic-enable multiple signal feedback system is proved effective to train novice to get familiar with Chinese character handwriting skill","2153-0866","1-4244-0258-1","10.1109/IROS.2006.282363","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4059331","Motor skill;Chinese handwriting;haptic training","Humans;Haptic interfaces;Machine learning;Intelligent robots;Robot kinematics;Feedback;Fingers;Acceleration;Learning systems;Error correction","control engineering computing;dexterous manipulators;feedback;haptic interfaces","machine-mediated motor skill training method;haptic-enabled Chinese character handwriting simulation system;complex dexterous manipulation;human motor skill;hierarchical hybrid control training system;phantom desktop;haptic interface;haptic-visual feedback;facsimile mode;transcribe mode;reciting mode;haptic-enable multiple signal feedback system","","2","","12","","15 Jan 2007","","","IEEE","IEEE Conferences"
"Intelligent Robotic Peg-in-Hole Insertion Learning Based on Haptic Virtual Environment","Y. Chen; X. Han; M. Okada; Y. Chen; F. Naghdy","School of Information Science and Engineering, Central South University, Changsha, 410083, China. cyt28@126.com; School of Information Science and Engineering, Central South University, Changsha, 410083, China; School of Information, Production and Systems, Waseda University, Kitakyushu, 808-0135, Japan. okada@okada-lab.org; School of Electrical, Computer and Telecommunication Engineering, University of Wollongong, NSW, 2522, Australia. ycquiet@126.com; School of Electrical, Computer and Telecommunication Engineering, University of Wollongong, NSW, 2522, Australia","2007 10th IEEE International Conference on Computer-Aided Design and Computer Graphics","26 Dec 2007","2007","","","355","360","A new approach is explored to transfer human manipulation skills to a robotics system. A skill acquisition algorithm utilizes the position and contact force/torque data generated in the virtual environment combined with a priori knowledge about the task to generate the skills required to perform such a task. Such skills are translated into actual robotic trajectories for implementation in real time. The peg-in-hole insertion problem is used as a case study. The results are reported.","","978-1-4244-1578-6","10.1109/CADCG.2007.4407908","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4407908","","Intelligent robots;Haptic interfaces;Virtual environment;Humans;Imaging phantoms;Friction;Torque;Training data;Force feedback;Solid modeling","haptic interfaces;intelligent robots;learning (artificial intelligence);manipulators;rendering (computer graphics);virtual reality","intelligent robotic peg-in-hole insertion learning;haptic virtual environment;human manipulation skills;skill acquisition algorithm","","4","","12","","26 Dec 2007","","","IEEE","IEEE Conferences"
"An Object State Estimation for the Peg Transfer Task in Computer-Guided Surgical Training","K. Meisner; M. Hong; J. W. Rozenblit","Universität der Bundeswehr,Department of Computer Science,Neubiberg,Germany,85579; University of Arizona,Department of Electrical and Computer Engineering,Tucson,AZ,USA; University of Arizona,Department of Electrical and Computer Engineering,Tucson,AZ,USA","2020 Spring Simulation Conference (SpringSim)","3 Sep 2020","2020","","","1","12","Computer-based simulators have been developed to enhance training experiences in laparoscopic surgical skills training. Most simulators can evaluate a trainee's performance objectively. However, only few simulators can provide active guidance features such as audio and visual guidance. In this paper, an object state estimation and tracking method is presented to support visual and force guidance for computer-assisted surgical trainer (CAST) using image processing schemes in real-time fashion given a specific object transfer task. The experimental results show that the proposed tracking method reaches 100 frame per seconds and estimates an object state effectively for the standard laparoscopy peg transfer task.","","978-1-56555-370-5","10.22360/SpringSim.2020.MSM.004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9185423","simulation-based surgical training;object recognition;object state detection","Image color analysis;Training;Instruments;Task analysis;Surgery;Image segmentation;State estimation","biomedical education;computer based training;medical computing;medical robotics;surgery","object state estimation;computer-guided surgical training;computer-based simulators;training experiences;laparoscopic surgical skills training;trainee;active guidance features;audio guidance;visual guidance;tracking method;force guidance;computer-assisted surgical trainer;specific object transfer task;standard laparoscopy peg transfer task","","","","25","","3 Sep 2020","","","IEEE","IEEE Conferences"
"Text Entry in Immersive Head-Mounted Display-Based Virtual Reality Using Standard Keyboards","J. Grubert; L. Witzani; E. Ofek; M. Pahud; M. Kranz; P. O. Kristensson",Coburg University of Applied Sciences and Arts; University of Passau; Microsoft Research; Microsoft Research; University of Passau; University of Cambridge,"2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)","30 Aug 2018","2018","","","159","166","We study the performance and user experience of two popular mainstream text entry devices, desktop keyboards and touchscreen keyboards, for use in Virtual Reality (VR) applications. We discuss the limitations arising from limited visual feedback, and examine the efficiency of different strategies of use. We analyze a total of 24 hours of typing data in VR from 24 participants and find that novice users are able to retain about 60% of their typing speed on a desktop keyboard and about 40-45% of their typing speed on a touchscreen keyboard. We also find no significant learning effects, indicating that users can transfer their typing skills fast into VR. Besides investigating baseline performances, we study the position in which keyboards and hands are rendered in space. We find that this does not adversely affect performance for desktop keyboard typing and results in a performance trade-off for touchscreen keyboard typing.","","978-1-5386-3365-6","10.1109/VR.2018.8446059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446059","H.5.2: [User Interfaces - Input devices and strategies.]","Keyboards;Visualization;Electronic mail;Virtual reality;Error analysis;Performance evaluation;User interfaces","helmet mounted displays;keyboards;learning (artificial intelligence);touch sensitive screens;user interfaces;virtual reality","immersive head-mounted display-based Virtual Reality;standard keyboards;user experience;popular mainstream text entry devices;Virtual Reality applications;VR;novice users;typing speed;typing skills;baseline performances;desktop keyboard typing;touchscreen keyboard typing","","23","","38","","30 Aug 2018","","","IEEE","IEEE Conferences"
"A Study and Simulation on Thermal Cycling System of CFB Boiler","Y. Hou; X. Jiang","State Grid Jibei Electr. Power Co. Limite Skills Training Center, Baoding Electr. Power VOC.& TECH. Coll., Baoding, China; State Grid Jibei Electr. Power Co. Limite Skills Training Center, Baoding Electr. Power VOC.& TECH. Coll., Baoding, China","2017 International Conference on Computer Network, Electronic and Automation (ICCNEA)","7 Dec 2017","2017","","","507","511","Energy is the main resource for our country to survive. However, in recent years, the excessive consumption of energy has made the environment worse and worse, and made the development of our country restricted. Technology of circulating fluid-bed boiler is the main way of general clean coal at present, and is a hot topic for each country in the world. However, the experimental process of the technology often spend a great cost, therefore is not suitable in practice. So simulation technology of circulating fluid-bed was used in this paper to solve practical problems. This paper established a circulating fluid-bed (CFB) boiler simulation system based on XinXiang HG-440 CFB, and analyzed final simulation system. Simulation process from thermal efficiency to thermal energy transformation were researched based on rules of thermal cycling and outlet of improving thermal energy utilization. This technology can not only improved the efficiency of energy, but also effectively reduced the energy generated in the process of burning gas pollution. Moreover, it has played an important role in China's energy construction.","","978-1-5386-3981-8","10.1109/ICCNEA.2017.45","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128619","Thermal cycling;Heat transfer model;Thermal energy utilization;Cyclone separator;CFB boiler","Coal;Combustion;Boilers;Furnaces;Thermal analysis;Particle separators;Mathematical model","air pollution;boilers;coal;combustion;fluidised beds","general clean coal;experimental process;simulation technology;practical problems;circulating fluid-bed boiler simulation system;XinXiang HG-440 CFB;final simulation system;simulation process;thermal efficiency;thermal energy transformation;thermal energy utilization;thermal cycling system;CFB boiler;excessive consumption;burning gas pollution;China energy construction","","","","10","","7 Dec 2017","","","IEEE","IEEE Conferences"
"Brain connectivity in spatial orientation task","G. Sharma; V. Singh; R. V. Daniel; A. P. Mittal; S. Chandra","Bio Medical Engineering Department, Institute of Nuclear Medicine & Allied Sciences, DRDO, Delhi, India; Instrumentation & Control Engineering Department, NSIT, Delhi, India; Advanced Technology Development Centre, IIT Kharagpur, WB, India; AICTE, Delhi, India; Bio Medical Engineering Department, Institute of Nuclear Medicine & Allied Sciences, DRDO, Delhi, India","2016 International Conference on Emerging Trends in Communication Technologies (ETCT)","23 Mar 2017","2016","","","1","4","Spatial orientation (SOT) is one of the spatial skill which is required in motor imagery and navigation. A lot of researches have shown underlying neural dynamics during SOT as an effect of spatial transformation strategy, but the consistent findings related to flow of information between designated brain areas are not present. The purpose of the study is to identify flux of information between pairs of channel to identify active hubs during the course of task. The directed transfer function (DTF) method is used to detect alterations in the functional coupling of EEG rhythms (0.5-30 Hz) in different brain cortical areas during virtual reality based perspective taking test. Results confirmed that there were common regions for motor imagery and SOT. It has also shed light on the active role of parietal and occipital lobe in SOT. This study proffers DTF as a useful technique for identifying hubs and flux of information in neuroscience.","","978-1-5090-4505-1","10.1109/ETCT.2016.7882958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7882958","Spatial Orientation;Directed Transfer Function (DTF);Virtual Reality;Perspective Taking Test","Cognition;Electroencephalography;Psychology;Mathematical model;Virtual reality;Atmospheric measurements;Particle measurements","electroencephalography;medical computing;neurophysiology;virtual reality","brain connectivity;neuroscience;occipital lobe;parietal lobe;virtual reality based perspective taking test;brain cortical areas;EEG rhythms;functional coupling;DTF;directed transfer function method;active hubs;brain areas;spatial transformation strategy;SOT;neural dynamics;navigation;motor imagery;spatial skill;spatial orientation task;frequency 0.5 Hz to 30 Hz","","2","","25","","23 Mar 2017","","","IEEE","IEEE Conferences"
"Parameter evaluation for virtual Laparoscopic simulation","S. B. Mansoor; Z. Mukhtar; M. Malik; Z. Amjad; H. Qureshi","School of EECS, National university of Sciences & Technology, Islamabad, Pakistan; School of EECS, National university of Sciences & Technology, Islamabad, Pakistan; School of EECS, National university of Sciences & Technology, Islamabad, Pakistan; School of EECS, National university of Sciences & Technology, Islamabad, Pakistan; School of EECS, National university of Sciences & Technology, Islamabad, Pakistan","2011 7th International Conference on Emerging Technologies","20 Oct 2011","2011","","","1","6","Virtual Reality based surgical simulators have become quite common for training of surgeons for different surgical skills. Simulators have been widely used particularly in minimal invasive surgery. In this paper we find parameters that would be required to create a real time working simulation for exercises given in the Fundamentals of Laparoscopic Surgery curriculum. We use peg transfer exercise as our example in this work and create simulations for parameter analysis using SOFA, an open source surgical framework [1]. The parameters we choose are generic and can be used to create other more complex simulations like cholecystectomy [2] (gall bladder removal) and appendectomy (appendix removal). We show the implementation of these parameters and their behavior in a virtual reality surgical simulation. This work can be used by researchers and developers to choose the right parameters in the context of the simulation they are developing. It also shows the cost and behavior of achieving good visualization (frames per second), physical characteristics and a realistic behavioral model to be used in simulations for training purposes.","","978-1-4577-0768-1","10.1109/ICET.2011.6048481","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6048481","Surgical Simulations;Virtual Reality;Biomechanical Modeling;Laparoscopic Surgery","Solid modeling;Surgery;Finite element methods;Computational modeling;Floors;Springs;Deformable models","data visualisation;digital simulation;medical computing;surgery;virtual reality","parameter evaluation;virtual laparoscopic simulation;virtual reality based surgical simulator;surgical skills;laparoscopic surgery curriculum;peg transfer exercise;parameter analysis;SOFA;open source surgical;complex simulation;cholecystectomy;appendectomy;realistic behavioral model","","","","15","","20 Oct 2011","","","IEEE","IEEE Conferences"
"Development of Augmented Reality Body-Mark system to support echography","T. Yoshinaga; D. Arita; K. Masuda","Institute of Systems, Information Technologies and Nanotechnologies, Fukuoka, Japan; Institute of Systems, Information Technologies and Nanotechnologies, Fukuoka, Japan; Graduate school of Bio-Applications and Systems Engineering, Tokyo University of Agriculture & Technology, Japan","2012 IEEE Biomedical Circuits and Systems Conference (BioCAS)","24 Jan 2013","2012","","","348","351","We propose visualization system of 3D shape of internal organs using Augmented Reality and Virtual Reality technology. Echography has been used in every field of medical diagnosis because of its safety and cost-effectiveness. Therefore, portable echography device so called “Ubiquitous Echo” was released by many manufacturers. However, the skill to recognize relationship between ultrasound probe and internal organ is required to acquire echogram. Therefore we have developed tracking system of probe orientation to transfer 2D position of echogram into 3D space. Then we have applied Radial Basis Function Interpolation to reconstruct the shape of internal organs. Furthermore, GUI interface to visualize the internal organ was developed by OpenGL. As a result of evaluation experiments, visualization of internal organ was satisfied to show the echogram for diagnosis.","2163-4025","978-1-4673-2293-5","10.1109/BioCAS.2012.6418425","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6418425","","Shape;Image reconstruction;Biological systems;Probes;Data visualization;Augmented reality;Phantoms","augmented reality;biological organs;biomedical ultrasonics;graphical user interfaces;image reconstruction;interpolation;medical image processing;portable instruments;radial basis function networks;ultrasonic imaging","augmented reality body-mark system;support echography;3D shape visualization system;internal organs;virtual reality;medical diagnosis;portable echography device;Ubiquitous Echo;ultrasound probe;tracking system;radial basis function interpolation;GUI interface;OpenGL;image reconstruction","","","","11","","24 Jan 2013","","","IEEE","IEEE Conferences"
"MoVEROffice: Virtual Reality for Upper Limbs Rehabilitation","R. V. Aranha; L. V. Araújo; C. B. M. Monteiro; T. D. Da Silva; F. L. S. Nunes","Lab. de Aplic. de Inf. em Saude, Univ. de Sao Paulo, Sao Paulo, Brazil; Lab. de Aplic. de Inf. em Saude, Univ. de Sao Paulo, Sao Paulo, Brazil; Lab. de Aplic. de Inf. em Saude, Univ. de Sao Paulo, Sao Paulo, Brazil; Lab. de Aplic. de Inf. em Saude, Univ. de Sao Paulo, Sao Paulo, Brazil; Lab. de Aplic. de Inf. em Saude, Univ. de Sao Paulo, Sao Paulo, Brazil","2016 XVIII Symposium on Virtual and Augmented Reality (SVR)","21 Jul 2016","2016","","","160","169","Considering the complexity involved in the motor rehabilitation process, this paper presents the development of a serious game with virtual reality and natural interaction to act as a support tool for physical therapy professionals. The objective of the developed application is to enable that patients acquire skill in performing tasks in the virtual environment to transfer them later to the real environment. An experiment was conducted to compare the performance of people with and without mobility limitations in the use of the virtual environment. The results showed that the time spent for performing tasks tend to be reduced when the users familiarize them selves with natural interaction, and size and position of objects have influence in the interaction. The study allowed inferring in this sample evaluated that the motor limitations of the patients did not have influence in the performance of the volunteers.","","978-1-5090-4149-7","10.1109/SVR.2016.36","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7517270","Virtual Reality;Natural Interaction;Serious Game;Virtual Rehabilitation","Visualization;Games;Virtual environments;Mice;Augmented reality;Art","medical computing;patient treatment;serious games (computing);virtual reality","MoVEROffice;virtual reality;upper limbs rehabilitation;motor rehabilitation process;natural interaction;physical therapy professionals;virtual environment;mobility limitations","","2","","","","21 Jul 2016","","","IEEE","IEEE Conferences"
"Large-scale Virtual Reality micro-robotic cell injection training","S. Faroque; B. Horan; M. Mortimer; M. Pangestu","CADET Virtual Reality Lab, School of Engineering, Deakin University, Geelong, Australia; CADET Virtual Reality Lab, School of Engineering, Deakin University, Geelong, Australia; CADET Virtual Reality Lab, School of Engineering, Deakin University, Geelong, Australia; Department of Obstetrics and Gynaecology, Monash University, Melbourne, Australia","2016 World Automation Congress (WAC)","6 Oct 2016","2016","","","1","6","Currently the micro-robotic cell injection procedure is performed manually by professional bio-operators. It is a challenging task requiring advanced skills including the ability to precisely control the movement of a micropipette. Developing these skills requires both lengthy and intensive training, and significant practical experience. This paper extends upon our previous work in desktop Virtual Reality (VR) cell injection training to introduce a large-scale VR micro-robotic cell injection system. Through utilization of large visual displays and the large workspace INCA 6D haptic device, the proprioception related to large arm movements (and corresponding visual representation) and the resulting movement of the micropipette in relation to the cell aims to provide the user with a better understanding of the spatial relationship between the micropipette and cell. The haptic device can be operated either with or without haptic guidance. When enabled, haptic guidance is provided in the form of virtual fixtures (VFs) and force feedback to assist the user in following the ideal trajectory towards the penetration point, applying appropriate force for penetration and stopping the micropipette's tip at the suitable deposition point. A user evaluation was conducted to study the usability of the system. Eighteen participants took part in the experiments and were randomly divided into six groups based on the display and haptic guidance modes assigned. The results demonstrated that the large-scale VR micro-robotic cell injection system is a feasible and effective method for bio-operator training where it is suggested that the skills and knowledge acquired can be transferred to the real-world task.","","978-1-8893-3551-3","10.1109/WAC.2016.7583006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7583006","Micro-robot;cell injection;virtual reality;haptics;skill training","Image edge detection;Visualization;Robots","computer based training;haptic interfaces;large-scale systems;medical computing;medical robotics;microrobots;virtual reality","large-scale virtual reality;microrobotic cell injection training;bio-operators;micropipette;intensive training;INCA 6D haptic device;virtual fixtures;VF;user evaluation","","3","","18","","6 Oct 2016","","","IEEE","IEEE Conferences"
"No transfer of gains after a single training session within a virtual environment to fundamental tests of stability","O. Elion; Y. Bahat; I. Siev-Ner; I. Sela; A. Karni; P. L. Weiss","The CAREN VR Lab, The C Sheba Medical Centre, Tel Hashomer, Israel; The CAREN VR Lab, The C Sheba Medical Centre, Tel Hashomer, Israel; The CAREN VR Lab, The C Sheba Medical Centre, Tel Hashomer, Israel; Dept. of Neurobiology and Ethology and Dept. of Learning Disabilities, University of Haifa, Israel; Dept. of Neurobiology and Ethology and Dept. of Learning Disabilities, University of Haifa, Israel; Dept. of Occupational Therapy, University of Haifa, Israel","2009 Virtual Rehabilitation International Conference","24 Jul 2009","2009","","","136","139","How specific are postural and balance control skills? An important issue for the establishment of effective training and retraining (rehabilitation) programs is whether skills gained while training in laboratory settings can be transferred to performance gains in somewhat different conditions (including every-day life). While there is much evidence showing that for volitional motor tasks the gains in performance (procedural, implicit, knowledge) accrued in practice may not always be transferable to novel task conditions, it is not clear whether the (implicit) knowledge gained in learning postural adjustments can be transferred to measures of balance (reaction to external perturbations) that have not been trained. The objective of the current study was to elucidate what aspects of a postural skill learned within a virtual environment (VE) by healthy adults may be transferable to the performance of standard tests of postural adjustments. Sixteen healthy young adults, aged 20-40 years (mean alpha SD = 29.8 alpha 2.8 years), were pseudo-randomly assigned to either a training group (Group A) or a no-training, control group (Group B). Group A performed a single training session in a VE in which maintenance of stability on a platform, while travelling along a road scenario and reaching for visual targets (secondary task) were required. Each participant underwent 8 consecutive runs of the task (2:48 m per run). A balance assessment with a given set of perturbations was performed before and after training as well as at 24 hours and 4 weeks post-training. Group B underwent the same assessments but without VE training. The results showed that the Center of Pressure (CoP) displacement tended to decrease over successive balance assessments in both groups, however, this decrease was not statistically significant. Moreover, there was no clear advantage for Group A. Thus, the postural adjustment gains were not transferred to the balance assessment tests. Non-volitional balance control gains are, in this respect, similar to gains attained in a volitional manual task learning.","2331-9569","978-1-4244-4188-4","10.1109/ICVR.2009.5174220","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5174220","Postural adjustments;Procedural knowledge;specificity;transfer","Virtual environment;Testing;Stability;Performance gain;Delay effects;Medical tests;Virtual reality;Laboratories;Gain measurement;Aging","biomechanics;computer based training;medical computing;patient rehabilitation;virtual reality","balance control skills;postural control skills;single training session;retraining programs;rehabilitation programs;virtual environment;stability;postural adjustment learning;healthy adults;visual target reaching;road scenario;center of pressure displacement","","","","23","","24 Jul 2009","","","IEEE","IEEE Conferences"
"Region-Specific Automated Feedback in Temporal Bone Surgery Simulation","S. Wijewickrema; I. Ioannou; Y. Zhou; P. Piromchai; J. Bailey; G. Kennedy; S. O'Leary","Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Comput. & Inf. Syst., Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Comput. & Inf. Syst., Univ. of Melbourne, Melbourne, VIC, Australia; Centre for the Study of Higher Educ., Univ. of Melbourne, Melbourne, VIC, Australia; Dept. of Otolaryngology, Univ. of Melbourne, Melbourne, VIC, Australia","2015 IEEE 28th International Symposium on Computer-Based Medical Systems","27 Jul 2015","2015","","","310","315","The use of virtual reality simulators for surgical training has gained popularity in recent years, with an ever increasing body of evidence supporting the benefits and validity of simulation-based training. However, a crucial component of effective skill acquisition has not been adequately addressed, namely the provision of timely performance feedback. The utility of a surgical simulator is limited if it still requires the presence of experts to guide trainees. Automated feedback that emulates the advise provided by experts is necessary to facilitate independent learning. We propose an automated system that provides region-specific feedback on surgical technique within a temporal bone surgery simulator. The design of this system allows easy transfer of feedback models to multiple temporal bone specimens in the simulator. The system was validated by an expert otologist and was found to provide highly accurate and timely feedback.","2372-9198","978-1-4673-6775-2","10.1109/CBMS.2015.13","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7167506","Automated Feedback in Surgery Simulation;Simulation-Based Surgical Training;Virtual Reality Temporal Bone Surgery","Surgery;Bones;Measurement;Accuracy;Solid modeling;Force;Anatomical structure","biomedical education;bone;computer based training;ear;educational aids;feedback;medical computing;surgery;teaching;virtual reality","region-specific automated surgical feedback;temporal bone surgery simulation;virtual reality simulator;surgical training;simulation-based training;effective skill acquisition;timely performance feedback;surgical simulator utility limitation;independent learning facilitation;temporal bone surgery simulator design;feedback model transfer;temporal bone specimen;system validation;otology","","4","","14","","27 Jul 2015","","","IEEE","IEEE Conferences"
"Inductive transfer assist-control for human-interface steering device","R. C. S. Antunes; L. B. Palma; F. V. Coito; H. Duarte-Ramos","Escola Superior de Tecnologia de Setúbal, Polytechnic Institute of Setúbal, Portugal 2910-761; Faculdade de Ciâncias e Tecnologia, Universidade Nova de Lisboa, Caparica, Portugal 2829-516; Faculdade de Ciâncias e Tecnologia, Universidade Nova de Lisboa, Caparica, Portugal 2829-516; Faculdade de Ciâncias e Tecnologia, Universidade Nova de Lisboa, Caparica, Portugal 2829-516","2015 IEEE International Conference on Evolving and Adaptive Intelligent Systems (EAIS)","4 Jan 2016","2015","","","1","8","Human Adaptive Mechatronics (HAM) is the research area that covers the design for assisting the human operator in improving its skills. HAM devices are capable to measure/estimate the operator's skill/dexterity, while a realtime embedded assist-controller enhances machine operation, improving the overall human-machine performance. Nowadays, the demand for such devices has particular potential in many activities which involve manual operations. The main contribution of this work is the development of a human adaptive real-time electronic switching controller obtained from a fuzzy clustering inductive learning technique, for improving the operator's proficiency, based on the transfer learning information of an expert driver. Several tests were conducted under a hardware/software driving simulator setup, to prove the effectiveness of the proposed methodology.","","978-1-4673-6698-4","10.1109/EAIS.2015.7368795","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368795","transfer learning;embedded assist-control;human adaptive mechatronics;human-machine interface;skill analysis","Adaptation models;Analytical models;Microcontrollers;Yttrium","automotive electronics;electronic switching systems;embedded systems;fuzzy control;fuzzy set theory;learning (artificial intelligence);man-machine systems;mechatronics;pattern clustering;steering systems;switching systems (control)","inductive transfer assist-control;human-interface steering device;human adaptive mechatronics;HAM devices;human operator assistance;skills improvement;operator skill;real-time embedded assist-controller;machine operation enhancement;human-machine performance improvement;human adaptive real-time electronic switching controller;fuzzy clustering inductive learning technique;operator proficiency improvement;transfer learning information;expert driver;hardware driving simulator setup;operator dexterity;software driving simulator setup","","2","","44","","4 Jan 2016","","","IEEE","IEEE Conferences"
"Optimization Design and Analysis of Pore Ratio Structure of Solid Electric Heat Storage Body Applied to Intelligent Park Heating","C. Yu; J. Su; Y. Zhu; L. Yang; Y. Yi; Z. Xing","State Grid,State Grid LiaoNing Skills Training Center,Shenyang,China; Shenyang university of technology,School of Electrical Engineering,Shenyang,China; State Grid,State Grid LiaoNing Skills Training Center,Shenyang,China; State Grid,State Grid LiaoNing Skills Training Center,Shenyang,China; State Grid,State Grid LiaoNing Skills Training Center,Shenyang,China; Shenyang university of technology,School of Electrical Engineering,Shenyang,China","2020 10th International Conference on Power and Energy Systems (ICPES)","15 Feb 2021","2020","","","482","488","Smart Park adopts solid electric heat storage device for heating. Energy storage can store electric energy into heat energy and play an advantage in peak load rule. The heat transfer performance of regenerator in solid electric energy storage system is studied. According to the characteristics of the built-in resistance regenerator and the heat transfer theory of fluid structure coupling, the three-dimensional numerical simulation of the flow field and temperature field coupling of the regenerator is carried out. The simulation results are compared with the experimental data to verify the correctness of the simulation results. At the same time, the best design and analysis of the regenerator with different void ratio are carried out. The results show the structure with 20% porosity is ideal considering the heat storage and release properties.","","978-0-7381-4255-5","10.1109/ICPES51309.2020.9349717","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9349717","solid electric thermal storage;optimization;fluid solid coupling;void ratio;numerical simulation;design and analysis","Couplings;Temperature distribution;Cogeneration;Wires;Numerical simulation;Heat transfer;Resistance heating","","","","","","15","","15 Feb 2021","","","IEEE","IEEE Conferences"
"Thinking Penguin: Multimodal Brain–Computer Interface Control of a VR Game","R. Leeb; M. Lancelle; V. Kaiser; D. W. Fellner; G. Pfurtscheller","Center for Neuroprosthetics, École Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland; Nanyang Technological University, Singapore, Singapore; Laboratory of Brain-Computer Interfaces, Institute for Knowledge Discovery, Graz University of Technology, Graz, Austria; Institute of Computer Graphics and Knowledge Visualization, Graz University of Technology, Austria; Emeritus Professor at the Laboratory of Brain-Computer Interfaces, Institute for Knowledge Discovery, Graz University of Technology, Graz, Austria","IEEE Transactions on Computational Intelligence and AI in Games","10 Jun 2013","2013","5","2","117","128","In this paper, we describe a multimodal brain-computer interface (BCI) experiment, situated in a highly immersive CAVE. A subject sitting in the virtual environment controls the main character of a virtual reality game: a penguin that slides down a snowy mountain slope. While the subject can trigger a jump action via the BCI, additional steering with a game controller as a secondary task was tested. Our experiment profits from the game as an attractive task where the subject is motivated to get a higher score with a better BCI performance. A BCI based on the so-called brain switch was applied, which allows discrete asynchronous actions. Fourteen subjects participated, of which 50% achieved the required performance to test the penguin game. Comparing the BCI performance during the training and the game showed that a transfer of skills is possible, in spite of the changes in visual complexity and task demand. Finally and most importantly, our results showed that the use of a secondary motor task, in our case the joystick control, did not deteriorate the BCI performance during the game. Through these findings, we conclude that our chosen approach is a suitable multimodal or hybrid BCI implementation, in which the user can even perform other tasks in parallel.","1943-0698","","10.1109/TCIAIG.2013.2242072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6418003","Brain–computer interfaces (BCI);brain switch;game;hybrid BCI;multimodal;multitasking;virtual reality (VR)","Games;Electroencephalography;Electrodes;Training;Brain computer interfaces;Educational institutions;Feature extraction","brain-computer interfaces;computer games;virtual reality","thinking penguin game;multimodal brain computer interface control;VR game;highly immersive CAVE;virtual environment;virtual reality game;jump action;game controller;BCI performance;discrete asynchronous action;visual complexity;task demand;joystick control;hybrid BCI implementation","","49","","51","","23 Jan 2013","","","IEEE","IEEE Journals"
"Impact of Using a Robot Patient for Nursing Skill Training in Patient Transfer","Z. Huang; C. Lin; M. Kanai-Pak; J. Maeda; Y. Kitajima; M. Nakamura; N. Kuwahara; T. Ogata; J. Ota","School of Automation, Guangdong University of Technology, Guangzhou, China; Research into Artifacts, Center for Engineering (RACE), University of Tokyo, Chiba, Japan; Faculty of Nursing, Tokyo Ariake University of Medical and Health Sciences, Tokyo, Japan; Faculty of Nursing, Tokyo Ariake University of Medical and Health Sciences, Tokyo, Japan; Faculty of Nursing, Tokyo Ariake University of Medical and Health Sciences, Tokyo, Japan; Faculty of Nursing, Tokyo Ariake University of Medical and Health Sciences, Tokyo, Japan; Department of Advanced Fibro-Science, Kyoto Institute of Technology, Kyoto, Japan; Research into Artifacts, Center for Engineering (RACE), University of Tokyo, Chiba, Japan; Research into Artifacts, Center for Engineering (RACE), University of Tokyo, Chiba, Japan","IEEE Transactions on Learning Technologies","21 Sep 2017","2017","10","3","355","366","In the past few decades, simulation training has been used to help nurses improve their patient-transfer skills. However, the effectiveness of such training remains limited because it lacks effective ways of simulating patients' actions realistically. It is difficult for nurses to use the skills learned from simulation training to transfer an actual patient. Therefore, we developed a robot patient that could simulate the behavior of patients' limbs for patient-transfer training. This study examined the performance of the robot used in training and evaluated its training effectiveness. Four nursing teachers individually transferred the robot patient and then scored the robot patient's ability to simulate patients' actions and its suitability for skill training. An experiment using pre-post control group design was carried out to examine the robot patient's training effectiveness compared with the human simulated patient. The participants were 20 nursing students and one nursing teacher who was responsible for scoring the students' skills in the pre-test and post-test. All of the students were assigned to train with either the proposed robot patient or a healthy person simulating the patient. The results show that all four nursing teachers regarded the robot patient's actions as realistic. In addition, all four teachers agreed that the robot patient was suitable for skill training. The results also show that the proposed robot patient is more challenging than the current method, which employs a healthy person to simulate the patient. Significant skill improvement (p <; 0.01) was observed in the experimental group when transferring the robot patient.","1939-1382","","10.1109/TLT.2016.2599537","Grants-in-Aid for Scientific Research (KAKENHI); Japan Society for the Promotion of Science (JSPS); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7542122","Computer uses in education;educational technology;training;robot patient","Training;Medical services;Mobile robots;Wheelchairs;Servomotors;Haptic interfaces","computer based training;health care;patient care;robots;teaching","robot patient;nursing skill training;patients limbs behavior simulation;patient-transfer training;nursing teachers;computer usage;educational technology","","1","","39","Traditional","11 Aug 2016","","","IEEE","IEEE Journals"
"Design and implementation of real-time simulation system of OTV based on xPC target and SIT","Yehan Ma; Mingxiang Ling; Changhong Wang; Qingshuang Zeng","School of Astronautics, Harbin Institute of Technology, Heilongjiang province, China; School of Astronautics, Harbin Institute of Technology, Heilongjiang province, China; School of Astronautics, Harbin Institute of Technology, Heilongjiang province, China; School of Astronautics, Harbin Institute of Technology, Heilongjiang province, China","Proceeding of the 11th World Congress on Intelligent Control and Automation","5 Mar 2015","2014","","","5896","5900","Developing real-time simulation systems by manual programming is a relatively complex, unreliable and costly process. In order to overcome the problems above, real-time simulation systems of the model of orbital transfer vehicle (OTV) were designed in two ways based on xPC Target and mix-programming of LabVIEW/SIT and MATLAB/Simulink, respectively in this paper. Both methods not only had little requirement for the programming skills of the designers but also were convenient for hardware-in-the-loop (HIL) simulations. The process of building the real-time simulation system, semi-physical simulation and the characteristics of the two methods were presented in detail in the paper. The simulation results showed that both methods avoided programming for models and drivers of hardwares successfully. They are efficient ways to develop systems and have high application value.","","978-1-4799-5825-2","10.1109/WCICA.2014.7053728","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7053728","Orbital transfer vehicle;Real-time simulation;Semi-physical simulation;xPC Target;LabVIEW/SIT","Space vehicles;Mathematical model;Real-time systems;MATLAB;Hardware;Programming","aerospace computing;control engineering computing;digital simulation;Earth orbit;real-time systems;space vehicles;virtual instrumentation","real-time simulation system design;orbital transfer vehicle;OTV;xPC target;mix-programming;LabVIEW/SIT;MATLAB/Simulink;programming skills;hardware-in-the-loop simulations;HIL simulations;semiphysical simulation","","","","11","","5 Mar 2015","","","IEEE","IEEE Conferences"
"Skill acquisition in transfer of manipulation skills from human to machine through a haptic virtual environment","Y. Chen; F. Naghdy","Sch. of Electr., Comput. & Telecommun. Eng., Wollongong Univ., NSW, Australia; Sch. of Electr., Comput. & Telecommun. Eng., Wollongong Univ., NSW, Australia","2002 IEEE International Conference on Industrial Technology, 2002. IEEE ICIT '02.","2 Apr 2003","2002","1","","337","342 vol.1","A new paradigm for programming a robotics manipulator is developed. It is intended that the teaching of the machine will begin with the necessary skills being demonstrated by the human operator in a virtual environment with tactile sensing (haptics). Position and contact force and torque data generated in the virtual environment combined with a priori knowledge about the task is used to identify and learn the skills in the newly demonstrated tasks and then to reproduce them in the robotics system. The peg-in-hole insertion problem is used as a case study. The overall concept is described. The methodologies developed to build the virtual environment and to learn the basic skills are explained. The results obtained so far are presented.","","0-7803-7657-9","10.1109/ICIT.2002.1189918","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1189918","","Humans;Haptic interfaces;Virtual environment;Robot programming;Robot sensing systems;Manipulators;Robotic assembly;Education;Robotics and automation;Telecommunication computing","robot programming;virtual reality;haptic interfaces","robotics manipulator;haptics;skill learning;virtual reality;robotics teaching;virtual environment;tactile sensing;peg-in-hole insertion;robot programming","","10","","28","","2 Apr 2003","","","IEEE","IEEE Conferences"
"Small Marker Tracking with Low-Cost, Unsynchronized, Movable Consumer Cameras For Augmented Reality Surgical Training","N. Rewkowski; A. State; H. Fuchs","UNC Chapel Hill, UMD College Park; UNC Chapel Hill; UNC Chapel Hill","2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","16 Dec 2020","2020","","","90","95","Surgeons improve their skills through repetition of training tasks in order to operate on living patients, ideally receiving timely, useful, and objective performance feedback. However, objective performance measurement is currently difficult without 3D visualization, with effective surgical training apparatus being extremely expensive or limited in accessibility. This is problematic for medical students, especially in situations such as the COVID-19 pandemic in which they are needed by the community but have few ways of practicing without lab access. In this work, we propose and prototype a system for augmented reality (AR) visualization of laparoscopic training tasks using cheap and widely-compatible borescopes, which can track small objects typical of surgical training. We use forward kinematics for calibration and multi-threading to attempt synchronization in order to increase compatibility with consumer applications, resulting in an effective AR simulation with low-cost devices and consumer software, while also providing dynamic camera and marker tracking. We test the system with a typical peg transfer task on the HoloLens 1 and MagicLeap One.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288414","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality; Computing methodologies;Artificial intelligence;Computer vision;Computer vision problems;Tracking","Training;Visualization;Three-dimensional displays;Surgery;Cameras;Task analysis;Augmented reality","augmented reality;computer based training;medical computing;medical image processing;object tracking;surgery","MagicLeap One;HoloLens 1;surgical training apparatus;peg transfer task;dynamic camera;consumer software;low-cost devices;AR simulation;consumer applications;widely-compatible borescopes;laparoscopic training tasks;augmented reality visualization;COVID-19 pandemic;medical students;objective performance measurement;objective performance feedback;augmented reality surgical training;movable consumer cameras;marker tracking","","","","35","","16 Dec 2020","","","IEEE","IEEE Conferences"
