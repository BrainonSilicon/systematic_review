"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Snapshots for semantic maps","C. W. Nielsen; B. Ricks; M. A. Goodrich; D. Bruemmer; D. Few; M. Few","Dept. of CS, Brigham Young Univ., Provo, UT, USA; Dept. of CS, Brigham Young Univ., Provo, UT, USA; Dept. of CS, Brigham Young Univ., Provo, UT, USA; NA; NA; NA","2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)","7 Mar 2005","2004","3","","2853","2858 vol.3","A significant area of research in mobile robotics is in the local representation of a remote environment. In order to include a human in a mobile robot task it becomes important to present the remote information efficiently to a human. A relatively new approach to information presentation is semantic maps. Semantic maps provide more detail about an environment than typical maps because they are augmented by icons or symbols that provide meaning for places or objects of interest. In this paper we present snapshot technology as a means to take pictures from the real world and store them in a semantic map. To make the snapshots and semantic map available to an operator, we identify and discuss general attributes for useful displays and present a mixed reality 3D interface that meets the requirements. The interface and snapshot technology are validated through experiments in real and simulated environments.","1062-922X","0-7803-8566-7","10.1109/ICSMC.2004.1400765","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1400765","","Displays;Mobile robots;Virtual reality;Orbital robotics;Navigation;Human robot interaction;Context awareness;Computer hacking;Robot vision systems;Cameras","mobile robots;man-machine systems;user interfaces","semantic maps;mobile robotics;remote information;snapshot technology;mixed reality 3D interface;human-robot team","","11","","17","","7 Mar 2005","","","IEEE","IEEE Conferences"
"Communication Through Motion: Legibility of Multi-Robot Systems","B. Capelli; C. Secchi; L. Sabattini","University of Modena and Reggio,Department of Sciences and Methods for Engineering (DISMI),Emilia,Italy; University of Modena and Reggio,Department of Sciences and Methods for Engineering (DISMI),Emilia,Italy; University of Modena and Reggio,Department of Sciences and Methods for Engineering (DISMI),Emilia,Italy","2019 International Symposium on Multi-Robot and Multi-Agent Systems (MRS)","14 Nov 2019","2019","","","126","132","The interaction between a user and a multi-robot system in a shared environment is a relatively uncharted topic. But, as these types of systems will increase in the future years, an efficient way of communication is necessary. To this aim, it is interesting to discover if a multi-robot system can communicate its intentions exploiting only some motion-variables, which are characteristics of the motion of the robots. This study is about the legibility of a multi-robot system: in particular, we focus on the influence of these motion-variables on the legibility of more than one group of robots that move in a shared environment with the user. These motion-variables are: trajectory, dispersion and stiffness. They are generally used to define the motion of a group of mobile robots. Trajectory and dispersion were found relevant for the correctness of the communication between the user and the multi-robot system, while stiffness was found relevant for the rapidity of communication. The analysis of the influence of the motion-variables was carried out with an ANOVA (analysis of variance) based on a series of data coming from an experimental campaign conducted in a virtual reality set-up.","","978-1-7281-2876-4","10.1109/MRS.2019.8901100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8901100","","Multi-robot systems;Mobile robots;Trajectory;Virtual reality;Complexity theory;Collision avoidance","control engineering computing;elasticity;mobile robots;motion control;multi-robot systems;statistical analysis;virtual reality","multirobot system;motion-variables;shared environment;mobile robots;stiffness;ANOVA;analysis of variance;virtual reality set-up","","1","","18","","14 Nov 2019","","","IEEE","IEEE Conferences"
"SensePath: Understanding the Sensemaking Process Through Analytic Provenance","P. H. Nguyen; K. Xu; A. Wheat; B. L. W. Wong; S. Attfield; B. Fields",Middlesex University; Middlesex University; Middlesex University; Middlesex University; Middlesex University; Middlesex University,"IEEE Transactions on Visualization and Computer Graphics","27 Oct 2015","2016","22","1","41","50","Sensemaking is described as the process of comprehension, finding meaning and gaining insight from information, producing new knowledge and informing further action. Understanding the sensemaking process allows building effective visual analytics tools to make sense of large and complex datasets. Currently, it is often a manual and time-consuming undertaking to comprehend this: researchers collect observation data, transcribe screen capture videos and think-aloud recordings, identify recurring patterns, and eventually abstract the sensemaking process into a general model. In this paper, we propose a general approach to facilitate such a qualitative analysis process, and introduce a prototype, SensePath, to demonstrate the application of this approach with a focus on browser-based online sensemaking. The approach is based on a study of a number of qualitative research sessions including observations of users performing sensemaking tasks and post hoc analyses to uncover their sensemaking processes. Based on the study results and a follow-up participatory design session with HCI researchers, we decided to focus on the transcription and coding stages of thematic analysis. SensePath automatically captures user's sensemaking actions, i.e., analytic provenance, and provides multi-linked views to support their further analysis. A number of other requirements elicited from the design session are also implemented in SensePath, such as easy integration with existing qualitative analysis workflow and non-intrusive for participants. The tool was used by an experienced HCI researcher to analyze two sensemaking sessions. The researcher found the tool intuitive and considerably reduced analysis time, allowing better understanding of the sensemaking process.","1941-0506","","10.1109/TVCG.2015.2467611","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7194834","Sensemaking;analytic provenance;transcription;coding;qualitative research;timeline visualization;Sensemaking;analytic provenance;transcription;coding;qualitative research;timeline visualization","Human computer interaction;Visual analytics;Context;Encoding;Manuals;Web pages","data visualisation;human computer interaction","SensePath;sensemaking process;analytic provenance;visual analytics tool;observation data;screen capture video;think-aloud recording;recurring pattern;general model;qualitative analysis process;browser-based online sensemaking;qualitative research session;participatory design session;HCI researcher;transcription stage;coding stage;thematic analysis;qualitative analysis workflow;sensemaking session","","16","","42","","13 Aug 2015","","","IEEE","IEEE Journals"
"Designing a Simulation Middleware for FIPA Multiagent Systems","A. Schuldt; J. D. Gehrke; S. Werner",NA; NA; NA,"2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology","6 Jan 2009","2008","2","","109","113","Multiagent systems ease the implementation of software systems to control complex processes. Instead of monolithic programs, decision-making is delegated to software agents as local entities. Like in software development in general, testing and evaluation play an important role also for multiagent systems. Particularly, because run-time interactions between agents and their effects cannot always be predicted at design time. Multiagent-based simulation is an adequate means to evaluate agents regarding their applicability in real-world operation. However, general agent development frameworks do not consider simulation-specific issues. Because they provide no means for synchronisation, an additional simulation middleware is required. Temporal criteria that are relevant for middleware design are defined in this paper. Furthermore, the actual implementation and example applications in logistics are presented.","","978-0-7695-3496-1","10.1109/WIIAT.2008.202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4740607","","Middleware;Multiagent systems;Software systems;Process control;Control systems;Decision making;Software agents;Programming;Software testing;System testing","digital simulation;middleware;multi-agent systems","simulation middleware design;FIPA multiagent systems;software agents;run-time interactions;complex process;agent development frameworks","","10","","12","","6 Jan 2009","","","IEEE","IEEE Conferences"
"Impedance-based Gaussian Processes for predicting human behavior during physical interaction","J. R. Medina; S. Endo; S. Hirche","Information-Oriented Control, Department of Electrical Engineering and Information Technology, Technische Universität München, D-80290 Munich, Germany; Information-Oriented Control, Department of Electrical Engineering and Information Technology, Technische Universität München, D-80290 Munich, Germany; Information-Oriented Control, Department of Electrical Engineering and Information Technology, Technische Universität München, D-80290 Munich, Germany","2016 IEEE International Conference on Robotics and Automation (ICRA)","9 Jun 2016","2016","","","3055","3061","For seamless physical human-robot interaction (pHRI), estimating human intention is essential. Most system identification approaches to pHRI model the human as a black box without prior assumptions about the underlying behavioral structure. However, integrating a priori knowledge about behavioral characteristics of the human provides superior prediction performance. In this work we present a novel method for human behavior prediction during physical interaction that incorporates an empirically supported human motor control model. The arm dynamics of the human are modeled as a mechanical impedance that follows a latent desired trajectory. We adopt a Bayesian perspective setting Gaussian Process (GP) priors on impedance parameters and the desired trajectory, which allows regression about human behavior from observed trajectories and interaction forces. The proposed impedance-based GP model is validated in simulation and in an experiment with human participants to demonstrate its prediction performance and generalization capability.","","978-1-4673-8026-3","10.1109/ICRA.2016.7487470","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7487470","","Trajectory;Impedance;Robots;Damping;Predictive models;Torque;Bayes methods","Gaussian processes;human-robot interaction","impedance-based Gaussian processes;human behavior prediction;seamless physical human-robot interaction;pHRI;black box;human motor control model;GP;impedance parameters","","8","","20","","9 Jun 2016","","","IEEE","IEEE Conferences"
"Force Feedback is Noticeably Different for Linear versus Nonlinear Elastic Tissue Models","S. Misra; A. M. Okamura; K. T. Ramesh",Johns Hopkins University; Johns Hopkins University; Johns Hopkins University,"Second Joint EuroHaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems (WHC'07)","2 Apr 2007","2007","","","519","524","Realistic modeling of the interaction between surgical instruments and human organs has been recognized as a key requirement in the development of high-fidelity surgical simulators. Primarily due to computational considerations, most of the past simulation research within the haptics community has assumed linear elastic behavior for modeling tissues, even though human soft tissues generally possess nonlinear viscoelastic properties. Hence, this paper quantitatively compares linear and nonlinear elasticity-based models. It is demonstrated that, for a nonlinear model, the well-known Poynting effect developed during shearing of the tissue results in normal forces not seen in a linear elastic model. The difference in force magnitude and force direction for linear and nonlinear models are larger than the just noticeable difference for contact force and force-direction discrimination thresholds published in the psychophysics literature, respectively. This work applies a proposed framework for examining the effect of tool-tissue interaction modeling techniques on human perception of surgical simulators with haptic feedback","","0-7695-2738-8","10.1109/WHC.2007.55","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4145227","","Force feedback;Humans;Surgery;Computational modeling;Haptic interfaces;Surgical instruments;Biological tissues;Viscosity;Elasticity;Shearing","biological tissues;biotechnology;force feedback;haptic interfaces","force feedback;linear elastic tissue model;nonlinear elastic tissue model;realistic modeling;surgical simulator;haptics community;linear elastic behavior;human soft tissue;nonlinear viscoelastic property;linear elasticity-based model;nonlinear elasticity-based model;Poynting effect;force-direction discrimination threshold;tool-tissue interaction modeling;haptic feedback","","8","","26","","2 Apr 2007","","","IEEE","IEEE Conferences"
"Dynamic user-centric mobile context model","Y. Chang; E. Barrenechea; P. Alencar","David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Canada","2010 Fifth International Conference on Digital Information Management (ICDIM)","10 Dec 2010","2010","","","442","447","Context-aware systems can dynamically adapt to specific dynamic user situations to provide smarter mobile services. In general, context refers to the information that can be used to characterize these situations, and context models are employed to specify contextual information described in context-aware systems. However, even though user context is highly dynamic, existing context models either focus on modeling static views of context or lack appropriate design abstractions to deal with dynamic aspects and interactions involving contextual elements such location, time, user roles, social relationships, changing preferences and virtual environments. In this paper, we present a dynamic user-centric mobile context model that can be used to model the aspects of context-aware systems that are subject to frequent changes. We illustrate the applicability of our approach by describing a case study on mobile e-healthcare. Benefits of these models include avoiding the development of context-aware systems from scratch, enabling future use of model-driven approaches, and reducing implementation effort.","","978-1-4244-7573-5","10.1109/ICDIM.2010.5662575","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5662575","context-aware systems;context model;user-centric;mobile application;dynamic interactions","Context;Context modeling;Virtual environment;Adaptation model;Mobile communication;Hospitals;Mobile handsets","mobile computing;virtual reality","dynamic user centric mobile context model;context aware systems;mobile services;model driven approach","","1","1","23","","10 Dec 2010","","","IEEE","IEEE Conferences"
"Haptic Perception of Material Properties and Implications for Applications","R. L. Klatzky; D. Pawluk; A. Peer","Department of Psychology and the Human-Computer Interaction Institute , Carnegie Melon University, Pittsburgh, PA , USA; Department of Biomedical Engineering, Virginia Commonwealth University, Richmond, VA, USA; Institute of Automatic Control Engineering, Technische Universitäat München, Munich, Germany","Proceedings of the IEEE","16 Aug 2013","2013","101","9","2081","2092","Perceiving the material properties of objects through touch is generally superior to the perception of shape. We review major material properties accessible through haptic interaction, along with theoretical accounts of the underlying perceptual processes. These include roughness, friction, compliance, and thermal properties. Subsequently, we describe algorithms that have been used to render these same material properties on haptic devices. We then point to applications that have capitalized on the accessibility of material through touch, including tactile displays, simulation of mechanical mechanisms in the automobile, and medical training simulators.","1558-2256","","10.1109/JPROC.2013.2248691","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6510431","Applications;haptic perception;haptic rendering","Haptic interfaces;Rendering (computer graphics);Shape analysis;Algorithm design and analysis","digital simulation;haptic interfaces","haptic perception;material properties;shape perception;friction;thermal properties;haptic devices;tactile displays;mechanical mechanisms;automobile simulators;medical training simulators","","9","","128","","30 Apr 2013","","","IEEE","IEEE Journals"
"Multiscale Point Cloud Optimization for SfM Reconstruction","Y. Li; G. Baciu","Deptartment of Computing, The Hong Kong Polytechnic University; Deptartment of Computing, The Hong Kong Polytechnic University","2019 IEEE 18th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC)","22 Jul 2020","2019","","","439","445","The 3D scanning and reconstruction technologies for augmented reality, autonomous vehicles, remote sensing, GIS, object recognition and localization, are often impaired by a critical fundamental problem: noise. Noise is even more problematic in 3D models generated by SfM, or Structure from Motion. Here, the outlier points have an adverse effect on the processing and application of the generated point clouds that are often the basis for 3D feature detection, localization and navigation algorithms. In general, visualization of 3D environments, navigation, and volumetric medical image segmentation present numerous challenges when noisy outliers interfere with the surface delimiters of the scanned objects. In this paper, we propose an effective strategy to filter noisy points generated in the process of SfM reconstruction. We formulate a novel approach based on an adaptive moving least squares (MLS) to optimize the geometric structure of a typical 3D indoor scene model. Different from other existing adaptive MLS, our method considers the adverse interactions between the neighboring non-continuous model components. The effectiveness and the performance of our approach is demonstrated on extended indoor scene models generated from 3D point clouds based on SfM.","","978-1-7281-1419-4","10.1109/ICCICC46617.2019.9146055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9146055","","Three-dimensional displays;Image reconstruction;Adaptation models;Solid modeling;Filtering;Surface reconstruction;Smoothing methods","augmented reality;computer vision;feature extraction;image reconstruction;image segmentation;least squares approximations;object detection;object recognition;solid modelling","scanned objects;noisy points;SfM reconstruction;geometric structure;adverse interactions;neighboring noncontinuous model components;extended indoor scene models;3D point clouds;multiscale point cloud optimization;reconstruction technologies;augmented reality;autonomous vehicles;remote sensing;GIS;object recognition;localization;critical fundamental problem;outlier points;generated point clouds;3D feature detection;navigation;volumetric medical image segmentation;noisy outliers;surface delimiters;adaptive MLS;adaptive moving least squares;3D indoor scene model","","","","23","","22 Jul 2020","","","IEEE","IEEE Conferences"
"Designing LED Lights for Communicating Gaze with Appearance-Constrained Robots","S. Song; S. Yamada","The Graduate University for Advanced Studies (SOKENDAI), Tokyo, Japan; Seiji Yamada is with the National Institute of Informatics and SOK-ENDAI, Tokyo, Japan","2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)","8 Nov 2018","2018","","","94","97","Functional robots are generally restricted in appearance, thus lacking ways to express their intent. In human-human interaction, gaze is an important cue for providing information and regulating interaction. In this pilot study, we investigate how we can implement gaze behavior in functional robots since gaze communication can allow humans to read a robot's intent and adjust their behavior accordingly. We explore design principles based on LED lights as we consider LEDs to be easily installed in most robots while not introducing features that are too human-like (to prevent users from having high expectations). In the paper, we present a design interface that allows designers to explore the parameter space of an LED strip attached to a Roomba robot. We then summarize a set of design principles for optimally simulating light-based gazes. Finally, our suggested design is evaluated by a large group of participants, and their comments are discussed.","1944-9437","978-1-5386-7980-7","10.1109/ROMAN.2018.8525661","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8525661","","Light emitting diodes;Robot kinematics;Strips;Space exploration;Lighting;Image color analysis","human-robot interaction;light emitting diodes;mobile robots;service robots;user interfaces","appearance-constrained robots;functional robots;human-human interaction;gaze behavior;gaze communication;design interface;Roomba robot;LED lights design;autonomous robotic vacuum cleaners","","","","8","","8 Nov 2018","","","IEEE","IEEE Conferences"
"Learning Algorithms for Human–Machine Interfaces","Z. Danziger*; A. Fishbach; F. A. Mussa-Ivaldi","Northwestern Univ., Evanston, IL; Sensory Motor Performance Program, Rehabilitation Inst. of Chicago, Chicago, IL; Northwestern Univ., Evanston, IL","IEEE Transactions on Biomedical Engineering","26 May 2009","2009","56","5","1502","1511","The goal of this study is to create and examine machine learning algorithms that adapt in a controlled and cadenced way to foster a harmonious learning environment between the user and the controlled device. To evaluate these algorithms, we have developed a simple experimental framework. Subjects wear an instrumented data glove that records finger motions. The high-dimensional glove signals remotely control the joint angles of a simulated planar two-link arm on a computer screen, which is used to acquire targets. A machine learning algorithm was applied to adaptively change the transformation between finger motion and the simulated robot arm. This algorithm was either LMS gradient descent or the Moore-Penrose (MP) pseudoinverse transformation. Both algorithms modified the glove-to-joint angle map so as to reduce the endpoint errors measured in past performance. The MP group performed worse than the control group (subjects not exposed to any machine learning), while the LMS group outperformed the control subjects. However, the LMS subjects failed to achieve better generalization than the control subjects, and after extensive training converged to the same level of performance as the control subjects. These results highlight the limitations of coadaptive learning using only endpoint error reduction.","1558-2531","","10.1109/TBME.2009.2013822","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4776455","Adaptive learning;hand posture;human–machine interface;machine learning","Machine learning algorithms;Machine learning;Fingers;Computational modeling;Least squares approximation;Control systems;Electronic mail;Instruments;Data gloves;Computer simulation","biocybernetics;data gloves;gradient methods;human-robot interaction;learning (artificial intelligence);least mean squares methods;telecontrol","human-machine interfaces;machine learning algorithms;data glove;finger motions;high dimensional glove signals;remote control;simulated planar two link arm;simulated robot arm;least mean square gradient descent;Moore-Penrose pseudoinverse transformation","Algorithms;Artificial Intelligence;Communication Aids for Disabled;Hand;Humans;Man-Machine Systems;Multivariate Analysis;Posture;Psychomotor Performance;Robotics;Signal Processing, Computer-Assisted;User-Computer Interface","32","","31","","6 Feb 2009","","","IEEE","IEEE Journals"
"Distributed dynamic density coverage for human-swarm interactions","Y. Diaz-Mercado; S. G. Lee; M. Egerstedt","Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA; Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA; Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA","2015 American Control Conference (ACC)","30 Jul 2015","2015","","","353","358","This paper presents two approaches to externally influence a team of robots by means of time-varying density functions. These density functions represent rough references for where the robots should be located. Recently developed continuous-time algorithms move the robots so as to provide optimal coverage of a given the time-varying density functions. This makes it possible for a human operator to abstract away the number of robots and focus on the general behavior of the team of robots as a whole. Using a distributed approximation to this algorithm whereby the robots only need to access information from adjacent robots allows these algorithms to scale well with the number of robots. Simulations and robotic experiments show that the desired behaviors are achieved.","2378-5861","978-1-4799-8684-2","10.1109/ACC.2015.7170761","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7170761","","Density functional theory;Approximation methods;Shape;Mobile robots;Computers;Transmission line matrix methods","control engineering computing;human-robot interaction;optimal control;time-varying systems","distributed dynamic density coverage;human-swarm interaction;time-varying density function;rough reference;continuous-time algorithm;optimal coverage;human operator;distributed approximation","","17","","18","","30 Jul 2015","","","IEEE","IEEE Conferences"
"Unobtrusive map navigation using eye tracking","T. Atrey; P. Gupta; P. K. Atrey","S. V. National Institute of Technology, Surat, India; S. V. National Institute of Technology, Surat, India; The University of Winnipeg, Canada","2012 25th IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)","22 Oct 2012","2012","","","1","4","Virtual maps technology is one of many innovations of the past decade. Currently navigation with such maps is generally performed using keyboard and mouse inputs. For improved human social communication, there is a need for more effective and unobtrusive navigation methods. In this paper, we adopt a human-centric approach to reinvent the way in which users interact with virtual maps. The proposed approach allows the system to observe the human operator's viewing behavior and provide an uninterrupted navigation environment. The feasibility and effectiveness of the proposed method is demonstrated for 2D maps. The results are promising and require further investigation for the method's applicability to 3D maps.","0840-7789","978-1-4673-1433-6","10.1109/CCECE.2012.6335015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6335015","Virtual maps;Navigation;Unobtrusive;Eye tracking","Navigation;Keyboards;Mice;Humans;Cities and towns;Tracking;Cameras","cartography;eye;human computer interaction;Internet;keyboards;mouse controllers (computers);object tracking;user interfaces;virtual reality","unobtrusive map navigation;eye tracking;virtual maps technology;keyboard inputs;mouse inputs;human social communication;human-centric approach;human operator viewing behavior;2D maps;3D maps;Google maps;Bing maps","","","","7","","22 Oct 2012","","","IEEE","IEEE Conferences"
"On a non-web-based multimodal interactive documentary production","M. Song; S. A. Mokhov; P. Grogono; S. P. Mudur","Concordia University, Montreal, Canada; Concordia University, Montreal, Canada; Concordia University, Montreal, Canada; Concordia University, Montreal, Canada","2014 International Conference on Virtual Systems & Multimedia (VSMM)","29 Jun 2015","2014","","","329","336","The most common rendering of interactive documentary film is through the web-based medium, which is not “tangible” or as immersive as a different form could be. The earlier making of the “I Still Remember” documentary's memory floating bubbles interactive with audience's participation using ordinary OpenGL was the first non-web-based prototype. We describe a new HCI process and the design of an associated programmer framework for making a passive documentary interactive using currently available tools and preserving the aesthetic and emotional appeal. It is done in a local space as an artistic installation. In this context, we briefly review the proof-of-concept design and implementation of a multimodal interactive system, the Illimitable Space System (ISS). It was designed to supplement digital artists' work for various interactive scenarios and applications. Its design supports non-web-based interactive documentary creation with speech and gesture based interaction (via Kinect), music visualization and green screening for interactive dance visualization, among other things in real-time. The ISS framework provides a unified generalized architecture that supports a configurable setup of installations, as in public places described in earlier work. We also compare advantages and disadvantages of the ISS's based XNA/C# realization to that of the earlier OpenGL prototype for interactive documentary production.","","978-1-4799-7227-2","10.1109/VSMM.2014.7136675","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7136675","multimodal interaction;Kinect;interactive documentaries;XNA;OpenGL","Production;Keyboards","entertainment;human computer interaction;interactive systems;Internet;rendering (computer graphics)","OpenGL prototype;unified generalized architecture;interactive dance visualization;green screening;music visualization;ISS;illimitable space system;multimodal interactive system;HCI process;nonWeb-based prototype;interactive documentary film;rendering;nonWeb-based multimodal interactive documentary production","","4","","41","","29 Jun 2015","","","IEEE","IEEE Conferences"
"Futuristic humanoid robot of twenty first century","S. Mohanty; S. S. Samal; S. Sathyamurthy","Department of EEE Sathyabama University, Chennai, India; Centre of Nanoscience & Nanotechnology, (A Joint Initiative of IGCAR, Kalpakkam & Sathyabama University), Chennai, India; Centre for Robotics, Sathyabama University, Chennai, India","INTERACT-2010","31 Jan 2011","2010","","","185","188","This paper represents the basics of robotics in the context of artificial intelligence and provides solution in future trend in robotics. It describes the very basics of robotics like sensors and actuators, gives an overview on robotic history and introduces some basic problems encountered in modern robotics. It describes possible solutions to those problems without going deeply into theory. The problems introduced are perception, basic pose description, transition and sensor models, localization as a special case of perception, representation of environment, path planning (cell decomposition, potential fields, skeletonization, and probabilistic roadmaps), movement of robots, and some real-life examples. The general problem of simulating intelligence has been broken down into a number of specific sub-problems like deduction, reasoning, problem solving, natural Knowledge processing, motion and manipulation, perception and social intelligence, cybernetics and brain simulation. These intelligences together provide better computational robotics named HUMANOID ROBOT. These will prove important in applications like surgical robots, robots for civil use and military robots. Human-robot interaction and robot understandings are the main topics covered to enhance our future trends of robotics through artificial intelligence.","","978-1-4244-9006-6","10.1109/INTERACT.2010.5706223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5706223","sensor;actuators;Robot;Humanoid;skeletonization","Robot sensing systems;Humanoid robots;Humans;Robot kinematics;Legged locomotion","actuators;artificial intelligence;humanoid robots;human-robot interaction;path planning;sensors","futuristic humanoid robot;twenty first century;artificial intelligence;path planning;human robot interaction","","","","11","","31 Jan 2011","","","IEEE","IEEE Conferences"
"Enhanced frame rate for real-time eye tracking using circular hough transform","A. Al-Rahayfeh; M. Faezipour","Department of Computer Science and Engineering University of Bridgeport, Bridgeport, CT 06604; Department of Computer Science and Engineering University of Bridgeport, Bridgeport, CT 06604","2013 IEEE Long Island Systems, Applications and Technology Conference (LISAT)","15 Aug 2013","2013","","","1","6","Eye-gaze detection and tracking has been widely investigated and presented as a way of unconventional human computer interaction. This area has provided convenience for many fields of practical applications, such as assistive systems and technology for people with severe disabilities, virtual reality, driver assistance and monitoring systems. Many methods for eye tracking have been introduced in literature. In this paper, a real-time eye tracking system is presented. To locate the iris of the eye in the captured video frames, the system uses the Circular Hough Transform which aims to recognize circular patterns in an image. Generally, the speed of eye motion is not as high as the used video frame rate of 30 Frames per Second (FPS) which is the frame rate used in general live video. In other words, the eye cannot move as fast as 30 motions per second. This led to proposing an enhancement to the eye tracking system being presented. This enhancement improved the CPU processing time requirements. The enhancement presented in this paper suggests that not all captured live video frames need to be processed for eye detection because the same eye movement will be captured on multiple subsequent video frames. Processing only a subset of frames will be enough to detect all eye movements in the video. The required CPU processing time is improved by selecting the minimum accepted video frame rate sufficient for accurately detecting all eye motions in a video. This was investigated for both the low and high speed eye movements. For low speed eye movements, the improvement in required CPU time was 1500%. For high speed eye movements, it was 750%. The improvement in CPU time is general and applies to different eye tracking algorithms when using the proposed enhancement. These improvements are a result of the elimination of the redundant video frames which are no longer processed in the procedure of eye detection.","","978-1-4673-6245-0","10.1109/LISAT.2013.6578214","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6578214","Eye tracking;eye motion speed;Real-time;Circular Hough Transform. frame rate","Transforms;Tracking;Real-time systems;Streaming media;Iris recognition;Human computer interaction;Image edge detection","eye;Hough transforms;human computer interaction;image enhancement;image motion analysis;iris recognition;object tracking;video signal processing","eye-gaze detection;eye-gaze tracking;human computer interaction;real-time eye tracking system;iris location;captured video frame rate;circular Hough transform;circular pattern recognition;eye motion speed;frame per second;FPS;CPU processing time requirements;eye movement;minimum accepted video frame rate selection;eye motion detection;redundant video frame elimination","","7","","16","","15 Aug 2013","","","IEEE","IEEE Conferences"
"Multihierarchical Interactive Task Planning: Application to Mobile Robotics","C. Galindo; J. Fernandez-Madrigal; J. Gonzalez","Syst. & Eng. Dept., Univ. of Malaga, Malaga; Syst. & Eng. Dept., Univ. of Malaga, Malaga; Syst. & Eng. Dept., Univ. of Malaga, Malaga","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)","16 May 2008","2008","38","3","785","798","To date, no solution has been proposed to human-machine interactive task planning that deals simultaneously with two important issues: 1) the capability of processing large amounts of information in planning (as it is needed in any real application) and 2) being efficient in human-machine communication (a proper set of symbols for human-machine interaction may not be suitable for efficient automatic planning and vice versa). In this paper, we formalize a symbolic model of the environment to solve these issues in a natural form through a human-inspired mechanism that structures knowledge in multiple hierarchies. Planning with a hierarchical model may be efficient even in cases where the lack of hierarchical information would make it intractable. However, in addition, our multihierarchical model is able to use the symbols that are most familiar to each human user for interaction, thus achieving efficiency in human-machine communication without compromising the task-planning performance. We formalize here a general interactive task-planning process which is then particularized to be applied to a mobile robotic application. The suitability of our approach has been demonstrated with examples and experiments.","1941-0492","","10.1109/TSMCB.2008.920227","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4505426","Hierarchical task planning;interactive task planning;mobile robots;world modeling;Hierarchical task planning;interactive task planning;mobile robots;world modeling","Mobile robots;Process planning;Grounding;Application software;Human robot interaction;Associate members;Mobile communication;Robotics and automation;Systems engineering and theory;Large-scale systems","interactive systems;mobile robots","multi hierarchical interactive task planning;mobile robotics;human-machine interaction;human-inspired mechanism","Artificial Intelligence;Computer Simulation;Decision Making;Decision Support Techniques;Models, Theoretical;Motion;Robotics","16","","55","","2 May 2008","","","IEEE","IEEE Journals"
"LazyNav: 3D ground navigation with non-critical body parts","E. Guy; P. Punpongsanon; D. Iwai; K. Sato; T. Boubekeur","Telecom ParisTech - CNRS - Institut Mines-Telecom, France; Osaka University, Japan; Osaka University, Japan; Osaka University, Japan; Telecom ParisTech - CNRS - Institut Mines-Telecom, France","2015 IEEE Symposium on 3D User Interfaces (3DUI)","25 Jun 2015","2015","","","43","50","With the growing interest in natural input devices and virtual reality, mid-air ground navigation is becoming a fundamental interaction for a large collection of application scenarios. While classical input devices (e.g., mouse/keyboard, gamepad, touchscreen) have their own ground navigation standards, natural input techniques still lack acknowledged mechanisms for travelling in a 3D scene. In particular, for most applications, navigation is not the primary interaction. Thus, the user should navigate in the scene while still being able to perform other interactions with her hands, and observe the displayed content by moving her eyes and locally rotating her head. Since most ground navigation scenarios require only two degrees of freedom to move forward or backward and rotate the view to the left or to the right, we propose LazyNav a mid-air ground navigation control model which lets the users hands, eyes or local head orientation completely free, making use of a single pair of the remaining tracked body elements to tailor the navigation. To this end, we design several navigation body motions and study their desired properties, such as being easy to discover, easy to control, socially acceptable, accurate and not tiring. We also develop several assumptions about motions design for ground navigation and evaluate them. Finally, we highlight general advices on mid-air ground navigation techniques.","","978-1-4673-6886-5","10.1109/3DUI.2015.7131725","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7131725","","Navigation;Hip;Knee;Three-dimensional displays;Tracking;Legged locomotion;Cameras","computer graphics;gesture recognition;human computer interaction","LazyNav;3D ground navigation;noncritical body parts;mid-air ground navigation control model","","22","","16","","25 Jun 2015","","","IEEE","IEEE Conferences"
"Modeling communicative behaviors for object references in human-robot interaction","H. Admoni; T. Weng; B. Scassellati","Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15213 USA; Microsoft Corporation, Redmond, WA 98052 USA; Department of Computer Science, Yale University, New Haven, CT 06520 USA","2016 IEEE International Conference on Robotics and Automation (ICRA)","9 Jun 2016","2016","","","3352","3359","This paper presents a model that uses a robot's verbal and nonverbal behaviors to successfully communicate object references to a human partner. This model, which is informed by computer vision, human-robot interaction, and cognitive psychology, simulates how low-level and high-level features of the scene might draw a user's attention. It then selects the most appropriate robot behavior that maximizes the likelihood that a user will understand the correct object reference while minimizing the cost of the behavior. We present a general computational framework for this model, then describe a specific implementation in a human-robot collaboration. Finally, we analyze the model's performance in two human evaluations-one video-based (75 participants) and one in person (20 participants)-and demonstrate that the system predicts the correct behaviors to perform successful object references.","","978-1-4673-8026-3","10.1109/ICRA.2016.7487510","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7487510","","Visualization;Robot kinematics;Computational modeling;Mathematical model;Robot sensing systems;Context","feature extraction;humanoid robots;human-robot interaction;maximum likelihood estimation;object detection;robot vision","communicative behavior modeling;human-robot interaction;robot verbal behaviors;robot nonverbal behaviors;human partner;computer vision;cognitive psychology;low-level scene features;high-level scene features;user attention;likelihood maximization;human-robot collaboration;human evaluations","","7","","29","","9 Jun 2016","","","IEEE","IEEE Conferences"
"Chatbot-based Interview Simulator: A Feasible Approach to Train Novice Requirements Engineers","M. Laiq; O. Dieste","Universidad Politécnica de Madrid,Escuela Técnica Superior de Ingenieros Informáticos,28660 Boadilla del Monte,Spain; Universidad Politécnica de Madrid,Escuela Técnica Superior de Ingenieros Informáticos,28660 Boadilla del Monte,Spain","2020 10th International Workshop on Requirements Engineering Education and Training (REET)","7 Oct 2020","2020","","","1","8","Introduction: Although the interview is the most important and widely used requirements elicitation technique, novice engineers do not receive adequate training in Requirements Engineering (RE) courses. Objectives: Develop an AI-based interview simulator for helping novice requirements engineers in gaining interview skills. Methods: The research is based on the Design Science Methodology for Information Systems. The simulator is the outcome of six cycles; in each cycle, a proof of concept with additional features is created. Each cycle finishes with evaluation and improvement suggestions. Results: The simulator has been tested with students and results have been promising. The interview simulator understands context-free questions, retrieving the right information related to RE concepts such as goals, tasks, users, benefits, and constraints. The simulator also answers questions based on the context, makes summaries of the conversation, responds to meta-questions, and adds ambiguity and incompleteness to the conversation. Conclusions: The results have been promising. The simulator has been tested with degree and master level students. They were able to create a requirements specification using the simulator, and the feedback has been generally positive. The simulator will be tested in a real RE course in the academic year 2020-2021. Once it proves effective in the classroom, it will be opened to the RE community for free use and improvement.","2164-0297","978-1-7281-8348-0","10.1109/REET51203.2020.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9216178","Requirements elicitation;chatbots;interviews;training","Interviews;Training;Security;Software;Solid modeling;Navigation;Design methodology","computer aided instruction;formal specification;human computer interaction;information systems;interactive systems;software agents","design science methodology;context-free questions;requirements specification;chatbot-based interview simulator;novice requirements engineers;requirements elicitation technique;adequate training;requirements engineering courses;interview skills","","","","37","","7 Oct 2020","","","IEEE","IEEE Conferences"
"The Effect of Sound on Haptic Perception","S. Kim; K. Kyung; D. Kwon","Telerobotics and Control Lab at KAIST, Korea; POST-PC Group, Digital Home Division at ETRI, Korea; Telerobotics and Control Lab at KAIST, Korea","Second Joint EuroHaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems (WHC'07)","2 Apr 2007","2007","","","354","360","Research on the intermodality relationship of auditory and tactile perceptions was conducted. An experiment is performed with 78(26 auditory cues times 3 tactile cues) stimuli combinations. The result of this experiment showed that the sound intensity level definitely affects perceived sensation in three ways: 1) The perceived roughness and ruggedness sensation is more innervated when the specific frequency is enhanced, e.g. approximately 30Hz~300Hz for ruggedness and 30Hz~600Hz for roughness sensation; 2) Conversely, the perceived density is reciprocally affected by an intensity adjustment of the sound; 3) A frequency adjustment of the sound can elicit a perceived roughness if even no stimuli are conveyed to subjects. In general, the importance of congruency between modalities was observed","","0-7695-2738-8","10.1109/WHC.2007.110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4145200","","Haptic interfaces;Frequency conversion;Displays;Telerobotics;Human computer interaction;Computer interfaces;Visual perception;Frequency synchronization;Rough surfaces;Surface roughness","acoustic intensity;acoustic signal processing;acoustic wave effects;haptic interfaces;hearing","haptic perception;intermodality relationship;auditory perceptions;tactile perceptions;auditory cues;tactile cues;sound intensity level;roughness sensation","","8","","19","","2 Apr 2007","","","IEEE","IEEE Conferences"
"Impact of Travelers Information Level on Disturbed Transit Networks: A Multiagent Simulation","M. Zargayouna; A. Othman; G. Scemama; B. Zeddini","IFSTTAR, GRETTIA, Univ. Paris Est, Champs-sur-Marne, France; IFSTTAR, GRETTIA, Univ. Paris Est, Champs-sur-Marne, France; Quartz Lab., EISTI, Cergy Pontoise, France; Quartz Lab., EISTI, Cergy Pontoise, France","2015 IEEE 18th International Conference on Intelligent Transportation Systems","2 Nov 2015","2015","","","2889","2894","With the generalization of real-time traveler information, the behavior of modern transport networks becomes harder to analyze and to predict. It is now critical to develop simulation tools for mobility policies makers, taking into account this new information environment. Information is now individualized, and the interaction of a population of individually guided travelers have to be taken into account in the simulations. Multiagent simulation is proving to be a powerful model for analyzing transport activities. Indeed, autonomous agents provide an appropriate basis for modeling heterogeneous systems and environment-based systems. In this paper, we present a multiagent simulation model to measure the impact of information provision on the quality of passengers travels. This impact is measured by simulating different scenarios in function of the percentage of connected travelers, represented as agents. These simulated scenarios are analyzed following their impact on the average travel times of the travelers. Results show that the number of connected travelers has a positive impact on overall travel times up until a certain threshold before becoming negative.","2153-0017","978-1-4673-6596-3","10.1109/ITSC.2015.464","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7313556","","Vehicles;Real-time systems;Computational modeling;Roads;Data models;Geographic information systems;Monitoring","digital simulation;multi-agent systems;traffic information systems;transportation","traveler information level;disturbed transit networks;multiagent simulation model;heterogeneous systems;environment-based systems;information provision","","3","","20","","2 Nov 2015","","","IEEE","IEEE Conferences"
"On the role of dissipation in haptic systems","B. E. Miller; J. E. Colgate; R. A. Freeman","Intuitive Surg., Sunnyvale, CA, USA; NA; NA","IEEE Transactions on Robotics","9 Aug 2004","2004","20","4","768","771","Passivity theory has been used for the past decade to derive stability conditions for human/machine interface applications. Demonstrating passivity of the haptic display implies stable and safe interaction for the human user. At the heart of the stability analysis is the physical dissipation provided by the haptic device, as it plays a key role in the design process for all components. This paper will derive the condition that the haptic device must satisfy in order to achieve passivity of the haptic display. These results will be used to investigate a general nonlinear device model.","1941-0468","","10.1109/TRO.2004.829452","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1321168","","Haptic interfaces;Stability;Humans;Displays;Robots;Virtual environment;DC motors;Magnetic levitation;Damping;Heart","stability;haptic interfaces;sampled data systems;man-machine systems;nonlinear systems;damping;virtual reality","haptic display passivity;stability analysis;human/machine interface;nonlinear device model;haptic systems;dissipation;damping","","34","","10","","9 Aug 2004","","","IEEE","IEEE Journals"
"A Novel Propagation Model Coupling the Offline Network with Online Social Network Framework","Q. Shao; S. Sun; C. Xia","Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Key Laboratory of Computer Vision and System (Ministry of Education), Tianjin University of Technology, Tianjin, China; Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Key Laboratory of Computer Vision and System (Ministry of Education), Tianjin University of Technology, Tianjin, China; Tianjin Key Laboratory of Intelligence Computing and Novel Software Technology, Key Laboratory of Computer Vision and System (Ministry of Education), Tianjin University of Technology, Tianjin, China","2019 IEEE International Symposium on Circuits and Systems (ISCAS)","1 May 2019","2019","","","1","5","We present a multi-layer network propagation model including both offline and online social networks, which aims to imitate the interaction between the offline actual individuals and the online social networking ones throughout the propagation process. After that, we utilize the improved SIR model to simulate the transmission in social networks under the impact of actual individuals. In our model, the individual layer adopts the generalized linear threshold model, while the social network layer uses the improved SIR model proposed in this paper. We apply these two propagation models into a three-layer network with inter-layer links, and use Monte Carlo simulation to analyze the model dynamic properties. Furthermore, we make use of mean-field approximations to obtain the analytical solutions to the critical thresholds regarding the epidemic process. We discuss the effect of different factors on the model results, and observe whether the model has different dynamic performance from the classical SIR model as well. The present results will provide some deeper insights into how various contagion phenomena spread within many real-world networks.","2158-1525","978-1-7281-0397-6","10.1109/ISCAS.2019.8702760","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8702760","propagation model;multi-layer framework;offline and online networks;Monte Carlo simulation","Numerical models;Social networking (online);Switches;Analytical models;Mathematical model;Couplings;Monte Carlo methods","human computer interaction;Monte Carlo methods;social networking (online)","online social network framework;multilayer network propagation model;online social networks;offline actual individuals;generalized linear threshold model;three-layer network;inter-layer links;Monte Carlo simulation;offline network;online social networking;SIR model","","","","43","","1 May 2019","","","IEEE","IEEE Conferences"
"Disappearing computers, social actors and embodied agents","A. Nijholt","Dept. of Comput. Sci., Univ. of Twente, Enschede, Netherlands","Proceedings. 2003 International Conference on Cyberworlds","8 Jan 2004","2003","","","128","134","Presently, there are user interfaces that allow multimodal interactions. Many existing research and prototype systems introduced embodied agents, assuming that they allow a more natural conversation or dialogue between user and computer. Here we will first take a look at how in general people react to computers. We will look at some of the theories, in particular the CASA (""Computers Are Social Actors"") paradigm, and then discuss how new technology, for example ambient intelligence technology, needs to anticipate the need of humans to build up social relationships. One way to anticipate is to do research in the area of social psychology, to translate findings there to the human-computer situation and to investigate technological possibilities to include human-human communication characteristics in the interface. For that reason we will discuss embodied conversational agents, the role they can play in human-computer interaction (in face-to-face conversation), in ambient intelligence environments and in virtual communities.","","0-7695-1922-9","10.1109/CYBER.2003.1253445","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1253445","","Pervasive computing;Ambient intelligence;Humans;Equations;Computer science;User interfaces;Prototypes;Psychology;Face;Books","virtual reality;user interfaces;human computer interaction","user interface;multimodal interaction;embodied agents;CASA;computers are social actors;ambient intelligence technology;human-computer situation;human-human communication;conversational agents;human-computer interaction;virtual community","","11","","17","","8 Jan 2004","","","IEEE","IEEE Conferences"
"Nonlinear model predictive control of an upper extremity rehabilitation robot using a two-dimensional human-robot interaction model","B. Ghannadi; N. Mehrabi; R. S. Razavian; J. McPhee","Department of Systems Design Engineering, University of Waterloo, Waterloo, ON N2L3G1, Canada; Department of Systems Design Engineering, University of Waterloo, Waterloo, ON N2L3G1, Canada; Department of Systems Design Engineering, University of Waterloo, Waterloo, ON N2L3G1, Canada; Department of Systems Design Engineering, University of Waterloo, Waterloo, ON N2L3G1, Canada","2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","14 Dec 2017","2017","","","502","507","Stroke rehabilitation technologies have focused on reducing treatment cost while improving effectiveness. Rehabilitation robots are generally developed for home and clinical usage to: 1) deliver repetitive practice to post-stroke patients, 2) minimize therapist interventions, and 3) increase the number of patients per therapist, thereby decreasing the associated cost. The control of rehabilitation robots is often limited to black-or gray-box approaches; thus, safety issues regarding the human-robot interaction are not easily considered. To overcome this issue, controllers working with physics-based models gain more importance. In this study, we have developed an efficient two dimensional (2D) human-robot interaction model to implement a model-based controller on a planar end-effector-type rehabilitation robot. The developed model was used within a nonlinear model predictive control (NMPC) structure to control the rehabilitation robot. The GPOPS-II optimal control package was used to implement the proposed NMPC structure. The controller performance was evaluated by simulating the human-robot rehabilitation system, modeled in MapleSim®. In this system, a musculoskeletal model of the arm interacting with the robot is used to predict movement and muscle activation patterns, which are used by the controller to provide optimal assistance to the patient. In simulations, the controller achieved desired performance and predicted muscular activities of the dysfunctional subject with a good accuracy. In our future work, a structure exploiting the NMPC framework will be developed for the real-time control of the rehabilitation robot.","2153-0866","978-1-5386-2682-5","10.1109/IROS.2017.8202200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8202200","","Solid modeling;Robot kinematics;Rehabilitation robotics;Muscles;Two dimensional displays","end effectors;human-robot interaction;medical robotics;nonlinear control systems;optimal control;patient rehabilitation;patient treatment;predictive control","human-robot rehabilitation system;musculoskeletal model;real-time control;upper extremity rehabilitation robot;stroke rehabilitation technologies;planar end-effector-type rehabilitation robot;nonlinear model predictive control;human-robot interaction model;GPOPS-II optimal control","","3","","24","","14 Dec 2017","","","IEEE","IEEE Conferences"
"Vernier: Accurate and Fast Acoustic Motion Tracking Using Mobile Devices","Y. Liu; J. Wang; Y. Zhang; L. Cheng; W. Wang; Z. Wang; W. Xu; Z. Li","Michigan State University, East Lansing, MI, USA; School of Software and BNRist, Tsinghua University, Beijing, China; School of Software and BNRist, Tsinghua University, Beijing, China; School of Software and BNRist, Tsinghua University, Beijing, China; School of Software and BNRist, Tsinghua University, Beijing, China; School of Software and BNRist, Tsinghua University, Beijing, China; School of Software and BNRist, Tsinghua University, Beijing, China; City University of Hong Kong, Kowloon Tong, Hong Kong","IEEE Transactions on Mobile Computing","11 Jan 2021","2021","20","2","754","764","Acoustic motion tracking has been viewed as a promising user interaction technique in many scenarios such as Virtual Reality (VR), Smart Appliance, video gaming, etc. Existing acoustic motion tracking approaches, however, suffer from long window of accumulated signal and time-consuming signal processing. They are inherently difficult to achieve both high accuracy and low delay. In this paper, we present Vernier, an efficient and accurate acoustic tracking method based on commodity mobile devices. We design a new approach to efficiently and accurately derive phase change and thus moving distance. Vernier significantly reduces the tracking delay/overhead by removing the complicated frequency analysis and long window of signal accumulation, while keeping a high tracking accuracy. We implement Vernier on Android, and evaluate its performance with COTS mobile devices including Samsung Galaxy S7 and Sony L50t. Experimental results show that Vernier outperforms previous approaches with a tracking error less than 4 mm. The tracking speed achieves 3× improvement to the previous phase based approaches and 10× to Doppler Effect based approaches. Vernier is also validated in applications like controlling and drawing, and we believe it is generally applicable in many real applications.","1558-0660","","10.1109/TMC.2019.2945955","National Key R&D Program of China; National Natural Science Fund China for Excellent Young Scholars; NSFC key program; NSFC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861148","Acoustic signal;tracking;mobile phone","Tracking;Mobile handsets;Microsoft Windows;Acoustics;Delays;Doppler effect;Performance evaluation","acoustic signal detection;Doppler effect;mobile computing;object detection;tracking;virtual reality","Vernier;COTS mobile devices;tracking error;tracking speed;fast acoustic motion tracking;virtual reality;acoustic motion tracking approaches;time-consuming signal processing;commodity mobile devices;user interaction technique;Doppler effect based approach;Samsung Galaxy S7;Sony L50t;size 4.0 mm","","","","33","IEEE","7 Oct 2019","","","IEEE","IEEE Journals"
"Real time simulation of Smart Grids for interface protection test and analysis","M. Brenna; E. De Berardinis; L. Delli Carpini; P. Paulon; P. Petroni; G. Sapienza; G. Scrosati; D. Zaninelli","Politecnico di Milano - Department of Energy, Italy; CESI S.p.A., Italy; Enel Distribuzione S.p.A, Italy; Enel Distribuzione S.p.A, Italy; Enel Distribuzione S.p.A, Italy; Politecnico di Milano, Italy; Enel Distribuzione S.p.A, Italy; Politecnico di Milano - Department of Energy, Italy","Proceedings of 14th International Conference on Harmonics and Quality of Power - ICHQP 2010","9 Nov 2010","2010","","","1","6","The widespread of the Distributed Generation (DG) impacts the future development of modern electrical distribution systems that must to evolve towards Smart Grids. Fundamental topics of the Smart Grid context are the Distributed Voltage Automation and the Advanced Network Automation based on fast communication channels. In order to analyze the behavior of a network which evolves in Smart Grid, real time digital simulation, using a closed loop system, is an indispensable approach because allow to study normal and critical situations that can happen in the grid. Besides the interaction with real devices can be performed, in order to verify their correct operation. In this paper, after a general description of the real time simulation in the Smart Grid context, the behavior analysis of an interface protection device is performed using the Real Time Digital Simulator (RTDS) installed in the Enel Distribuzione S.p.A. test centre.","2164-0610","978-1-4244-7246-8","10.1109/ICHQP.2010.5625444","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5625444","Distributed Generation;Smart Grids;Anti-Islanding protections;Interface Protection Devices;Network Automation Systems","Generators;Reactive power;IP networks;Real time systems;Smart grids;Threshold voltage;Automation","closed loop systems;digital simulation;distributed power generation;power distribution protection;power generation protection;smart power grids","smart grid real time simulation;interface protection test;distributed generation;electrical distribution systems;distributed voltage automation;advanced network automation;fast communication channels;real time digital simulation;closed loop system;real time digital simulator","","8","","11","","9 Nov 2010","","","IEEE","IEEE Conferences"
"A modular approach for exchangeable driving task models in a microscopic simulation framework","W. Schakel; B. van Arem; H. van Lint; G. Tamminga","Delft University of Technology, Department of Transport and Planning, P.O. Box 5048, 2600 GA, The Netherlands; Delft University of Technology, Department of Transport and Planning, P.O. Box 5048, 2600 GA, The Netherlands; Delft University of Technology, Department of Transport and Planning, P.O. Box 5048, 2600 GA, The Netherlands; Delft University of Technology, Department of Transport and Planning, P.O. Box 5048, 2600 GA, The Netherlands","16th International IEEE Conference on Intelligent Transportation Systems (ITSC 2013)","30 Jan 2014","2013","","","565","571","We present a structure for driver models regarding different driving tasks in microscopic simulation. This structure is part of an open and extendable simulation framework which facilitates development and research into ITS applications and driver behavior. The structure deals with typical difficulties of providing a high level of flexibility while allowing a high level of overview and user-friendliness. For driver behavior this is not a trivial task as different driving tasks depend on each other and as one requires a consistent driver, e.g. an aggressive driver is usually aggressive regarding all aspects of driving. This results in a high degree of interaction and dependency of driver models where we would like to segregate as much as possible in order to make them individually exchangeable. Our model structure allows a number of ways in which models may interact with varying degrees of generality. Inevitably this leads to concessions where we favor flexibility over user-friendliness. Specifically, the structure does not force appropriate use of model interactions. Appropriate use is thus up to the user.","2153-0017","978-1-4799-2914-6","10.1109/ITSC.2013.6728291","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6728291","","Vehicles;Adaptation models;Acceleration;Object oriented modeling;Mathematical model;Microscopy;Software","digital simulation;intelligent transportation systems","exchangeable driving task models;microscopic simulation framework;driver models;ITS applications;driver behavior;user-friendliness;consistent driver;aggressive driver","","5","","17","","30 Jan 2014","","","IEEE","IEEE Conferences"
"Towards automatic generation of multimodal AR-training applications and workflow descriptions","T. Engelke; S. Webel; U. Bockholt; H. Wuest; N. Gavish; F. Tecchia; C. Preusche","Fraunhofer IGD, Germany; Fraunhofer IGD, Germany; Fraunhofer IGD, Germany; Fraunhofer IGD, Germany; Technion-Israel, Institute of Technology, Israel; PERCRO - Scuola Superiore Sant'Anna, Italy; German Aerospace Center (DLR), Germany","19th International Symposium in Robot and Human Interactive Communication","11 Oct 2010","2010","","","434","439","Augmented Reality (AR) is a technology which has become very popular in the last years. In this context also the idea of using of AR for training applications has become very important. AR offers a large potential for training only if the training is well focused to the skills that have to be trained and if the training protocol is well designed. On the other hand, the generation of the training content to be transferred via AR is a comprehensive problem that is addressed in this paper. Thus, this paper tries to describe the whole chain of implementations and general aspects involved in the creation of AR training applications, including examples for used multimodal devices. This chain starts with the capturing of expert actions to be hold in the ""digital representation of skill"". The digital representation of skill is transferred to the training protocol that specifies the storyboard of the AR training session. The paper includes two different implementations of AR training systems and describes the general idea of informational abstraction from low level data up to interaction and from design to application.","1944-9437","978-1-4244-7990-0","10.1109/ROMAN.2010.5598613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5598613","","Training;Augmented reality;Protocols;Assembly;Solid modeling;Haptic interfaces;Maintenance engineering","augmented reality;computer aided instruction","multimodal AR-training applications;workflow descriptions;augmented reality;training protocol;digital representation","","2","","21","","11 Oct 2010","","","IEEE","IEEE Conferences"
"A universal model for flexible item selection in conversational dialogs","A. Celikyilmaz; Z. Feizollahi; D. Hakkani-Tur; R. Sarikaya",Microsoft; Microsoft; Microsoft; Microsoft,"2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)","11 Feb 2016","2015","","","361","367","Human-computer interaction and statistical natural language understanding has changed with the addition of a visual display screen in modern mobile devices, as visual rendering is used to communicate the dialog system's response. Onscreen item identification and resolution when interpreting the user utterances is one critical problem to achieve the natural and accurate human-machine communication. This problem, also called Flexible Item Selection (FIS), has been posed as a classification task to correctly identify intended on-screen item(s) from user utterances. This paper presents a universal FIS model that can be applied to dialog systems developed in different languages. We design a set of input features for the FIS model that makes it largely language-independent. We demonstrate that a single universal FIS model can be used in place of language specific FIS models with no loss in accuracy. We also show that such a model can generalize well to new unseen languages with minimal loss in accuracy on held out languages including English, French, Spanish, Italian, German, and Chinese. Eliminating the need for building and maintaining a separate FIS model for each new language, the universal FIS model helps scaling an existing dialogue system to new languages faster at a lower development cost.","","978-1-4799-7291-3","10.1109/ASRU.2015.7404817","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7404817","on screen item selection;multi language and universal models;language expansion;spoken language understanding;spoken dialog systems;language independence","Feature extraction;Semantics;Engines;Motion pictures;Numerical models;Support vector machines;Natural languages","human computer interaction;interactive systems;natural language processing","flexible item selection;conversational dialogs;universal FIS model;dialog systems;language specific FIS models;human-computer interaction;natural language understanding","","","","21","","11 Feb 2016","","","IEEE","IEEE Conferences"
"Impact of modelling assumptions in event-driven software simulation tools for the performance evaluation of cellular mobile systems","A. G. Acx; A. Rolando","CNET, Issy-les-Moulineaux, France; NA","VTC '98. 48th IEEE Vehicular Technology Conference. Pathway to Global Wireless Revolution (Cat. No.98CH36151)","6 Aug 2002","1998","2","","1558","1562 vol.2","This paper addresses the problem of comparing results obtained by means of different software tools when evaluating the radio access capacity and the system performance of a cellular mobile communication system. Particularly, an analysis of the impact on the final results of modelling and working assumptions independent of radio link control aspects is performed. Main focuses are mobility modelling, path loss and shadowing modelling, as well as measurement reporting criteria and their interactions with different sets of radio network functions. The case study presented here deals with a TDMA system (GSM-like). The study is done by comparing the results obtained for the same reference scenario by two event-driven system simulation software tools, developed internally by CSELT and CNET. Nevertheless, since the topics analysed are common to any system simulation activity, the conclusions drawn here can be easily extended to a more general context. Therefore, from these results, useful guidelines for building simulation tools or comparing outputs can be derived.","1090-3038","0-7803-4320-4","10.1109/VETEC.1998.686550","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=686550","","Discrete event simulation;Software tools;System performance;Mobile communication;Performance analysis;Radio link;Radio control;Communication system control;Shadow mapping;Loss measurement","cellular radio;radio access networks;time division multiple access;telecommunication computing;digital simulation;software tools","event-driven software simulation tools;performance evaluation;cellular mobile radio systems;radio access capacity;mobile communication system;mobility modelling;path loss;shadowing;TDMA system;GSM","","1","","7","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Local search particle filter applied to human-computer interaction","J. J. Pantrigo; A. S. Montemayor; A. Sanchez","Rey Juan Carlos Univ., Mostoles, Spain; Rey Juan Carlos Univ., Mostoles, Spain; Rey Juan Carlos Univ., Mostoles, Spain","ISPA 2005. Proceedings of the 4th International Symposium on Image and Signal Processing and Analysis, 2005.","24 Oct 2005","2005","","","279","284","This paper presents an hybridization of particle filter and local search algorithms, called local search particle filter (LSPF), and its application to human-computer interaction. The proposed algorithm combines both sequential Monte Carlo (particle filter - PF) and local search methods to achieve an accurate real-time hand tracking. The system allows to control different mouse actions through a reduced set of hand movements and gestures. Hand are segmented using a skin-color model based on explicit RGB region definition. The proposed hybrid tracking method increases the performance of general particle filter. It also improves the quality of the hand tracking task (the standard deviation between hand spatial positions for LSPF is reduced a 75% with respect to the PF algorithm). More precisely, a local search enhances a hand-simulated mouse cursor to smoothly move and thus recognize gestures for performing their associate actions.","1845-5921","953-184-089-X","10.1109/ISPA.2005.195423","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1521302","","Particle filters;Mice;Particle tracking;Computer vision;Face detection;Control systems;Humans;Motion analysis;User interfaces;Artificial intelligence","particle filtering (numerical methods);Monte Carlo methods;image segmentation;image colour analysis;human computer interaction;search problems;gesture recognition","local search particle filter;human-computer interaction;particle filter hybridization;sequential Monte Carlo methods;real-time hand tracking;image segmentation;skin-color model","","","","16","","24 Oct 2005","","","IEEE","IEEE Conferences"
"Neurovision®; The way to merge visual reality with navigational and military systems","G. Hector","Metamathics, Mexico City, DF (Mexico)","2013 IEEE/AIAA 32nd Digital Avionics Systems Conference (DASC)","23 Jan 2014","2013","","","3D5-1","3D5-12","Historically, the extrapolation of the navigational data into what is perceived as reality by the pilot through the cockpit's window, and vice versa, has been a major source of human error during flight. Advanced computer generated terrain simulation systems provide real time virtual flights, but the pilot still needs to constantly keep checking visual reality with virtual environment and merge those on his mind. Besides, the field of view is narrow. In order to address this problem the head up display superimposes virtual and visual information. Unfortunately, angular inaccuracies related to angular vision coordinates and the changing pilot's point of view such as head position and distance to the device puts the “head up” display on need of improvement. We propose an advanced method to merge visual reality with advanced navigational systems on a wide (180°) or very wide (360°) field of view. The system is able to acquire the tridimensional visual reality as well as infrared view merged with present and future advanced navigational systems and it is also able to deliver it to the pilot in the way the human brain better understands it. The Intruder Planes Projected Trajectory and the 3D shapes of Complex Weather may also be instantaneously understood by the pilot. The exceptional capability of the system to display intruder's angular position and projected trajectories into the panoramic visual perception of the pilot is shown. Such feature may also be extended to ground or unmanned units. We call this system Neurovision®. This advanced method for stereographic projection, able to generate Riemannian manifolds facilitates and even makes some computer tasks now possible, allowing improvements derived from differential geometry and neuroscience to hopefully provide novel opportunities to avionics and technology in general. Neurovision® enables to merge Panoramic View, Infrared, Navigation Computer Generated Graphics, Complex 3D weather and Intruder's Planes or Target's Projected 3D Trajectories for every plane or military units's 3D unique visual perspective.","2155-7209","978-1-4799-1538-5","10.1109/DASC.2013.6712571","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6712571","","Visualization;Azimuth;Navigation;Trajectory;Three-dimensional displays;Meteorology;Geometry","aerospace computing;aircraft displays;computer graphics;computer vision;differential geometry;extrapolation;graphical user interfaces;head-up displays;human computer interaction;human factors;military computing;military systems;stereo image processing;virtual reality","neurovision;visual reality;navigational systems;military systems;navigational data extrapolation;cockpit window;human error;advanced computer generated terrain simulation systems;real time virtual flights;head up display;intruder planes;trajectory projection;3D shapes;complex 3D weather;panoramic visual perception;stereographic projection;Riemannian manifold generation;differential geometry;navigation computer generated graphics;angular vision coordinates","","","","17","","23 Jan 2014","","","IEEE","IEEE Conferences"
"Neurosurgical Craniotomy Localization Using Interactive 3D Lesion Mapping for Image-Guided Neurosurgery","Z. Dai; R. Yang; F. Hang; J. Zhuang; Q. Lin; Z. Wang; Y. Lao","School of Medicine, South China University of Technology, Guangzhou, China; Department of Biomedical Engineering, South China University of Technology, Guangzhou, China; School of Medicine, South China University of Technology, Guangzhou, China; Department of Cardiac Surgery, Guangdong Academy of Medical Science, Guangdong Cardiovascular Institute, Guangdong General Hospital, Guangzhou, China; School of Medicine, South China University of Technology, Guangzhou, China; Guangzhou Aimooe Technology Co., Ltd., Guangzhou, China; Department of Biomedical Engineering, South China University of Technology, Guangzhou, China","IEEE Access","29 Jan 2019","2019","7","","10606","10616","Precise craniotomy localization is essential in neurosurgical procedures, especially during the preoperative planning. The mainstream craniotomy localization method utilizing image-guided neurosurgery system (IGNS) or augmented reality (AR) navigation system require experienced neurosurgeons to point out the lesion margin by probe and draw the craniotomy manually on the patient's head according to cranial anatomy. However, improper manual operation and dither from the AR model will bring in errors about craniotomy localization. In addition, there is no specific standard to evaluate the accuracy of craniotomy. This paper attempts to propose a standardized interactive 3D method using orthogonal transformation to map the lesion onto the scalp model and generate a conformal virtual incision in real time. Considering clinical requirements, the incision can be amended by 3D interaction and margin modification. According to the IGNS and the virtual incision, an actual craniotomy will be located on the patient's head and the movement path of the probe will be recorded and evaluated by an indicator, which is presented as an evaluated standard to measure the error between virtual and actual craniotomies. After the experiment, an incision is drawn on a 3D printing phantom based on the generated virtual one. The results show that the proposed method can generate a lesion-consistent craniotomy according to the size of the lesion and the mapping angle and delineate the incision on the patient's head precisely under the IGNS.","2169-3536","","10.1109/ACCESS.2019.2890977","National Natural Science Foundation of China; Guangdong Science and Technology Department; Fundamental Research Funds for Central Universities; Guangzhou Science and Technology Program key projects; Chinese Scholarship Fund; China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611441","Craniotomy localization;image-guided neurosurgery;interactive 3D lesion mapping;octree decomposition;margin modification","Lesions;Three-dimensional displays;Scalp;Neurosurgery;Solid modeling;Image segmentation","augmented reality;brain;medical image processing;neurophysiology;phantoms;surgery","3D interaction;orthogonal transformation;augmented reality navigation system;image-guided neurosurgery system;interactive 3D lesion mapping;manual operation;patient head;mapping angle;lesion-consistent craniotomy;3D printing phantom;virtual craniotomies;actual craniotomy;margin modification;clinical requirements;conformal virtual incision;scalp model;standardized interactive 3D method;cranial anatomy;lesion margin;IGNS;mainstream craniotomy localization method;preoperative planning;neurosurgical procedures;precise craniotomy localization;neurosurgical craniotomy localization","","3","","27","","14 Jan 2019","","","IEEE","IEEE Journals"
"Simulation of restricted neural networks with reprogrammable neurons","D. K. Hartline","Bekesey Lab. of Neurobiol., Honolulu, HI, USA","IEEE Transactions on Circuits and Systems","6 Aug 2002","1989","36","5","653","660","A network model is described which is composed of reprogrammable neurons, incorporating the following design features: (1) spikes can be generated by a model representing repetitive firing at axon (and dendritic) trigger zones; (2) active responses (plateau potentials; delaying mechanisms) are simulated with Hodgkin-Huxley-type kinetics; (3) synaptic interactions, both spike-mediated and nonspiking chemical (chemotonic), simulate transmitter release and binding to postsynaptic receptors; facilitation and antifacilitation of spike-mediated postsynaptic potentials (PSPs) are included; (4) chemical pools are used to simulate second messenger systems, trapping ions in extracellular spaces, and electrogenic pumps, as well as biochemical reaction chains of quite general character; modulation of any of the parameters of any compartment can be effected through the pools; and (5) intracellular messengers of three kinds are simulated explicitly: those produced by voltage-gated processes (e.g. Ca), those dependent on transmitter (or hormone) binding; and those dependent on other internal messengers (e.g. internally released Ca; enzymatically activated pathways).<>","1558-1276","","10.1109/31.31312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=31312","","Neural networks;Chemical processes;Neurons;Character generation;Nerve fibers;Delay effects;Kinetic theory;Neurotransmitters;Extracellular;Voltage","digital simulation;neural nets","restricted neural networks;reprogrammable neurons;network model;design features;model representing repetitive firing at axon;active responses;plateau potentials;delaying mechanisms;Hodgkin-Huxley-type kinetics;synaptic interactions;spike-mediated;nonspiking chemical;transmitter release;binding to postsynaptic receptors;facilitation;antifacilitation;chemical pools;second messenger systems;trapping ions;electrogenic pumps;biochemical reaction chains;modulation;intracellular messengers;Ca","","9","","42","","6 Aug 2002","","","IEEE","IEEE Journals"
"An anatomy-based approach to human muscle modeling and deformation","Feng Dong; G. J. Clapworthy; M. A. Krokos; Jialiang Yao","Dept. of Comput. & Inf. Sci., De Montfort Univ., Milton Keynes, UK; NA; NA; NA","IEEE Transactions on Visualization and Computer Graphics","7 Aug 2002","2002","8","2","154","170","Muscle simulation is an important component of human modeling, but there have been few attempts to demonstrate, in 3D and in an anatomically correct way, the structures of muscles and the way in which these change during motion. This paper proposes an anatomically-based approach to muscle modeling that attempts to provide models for human musculature based on the real morphological structures. These models provide a good visual description of muscle form and action and represent a sound base from which to produce further progress toward medically accurate simulation of human bodies. Three major problems have been addressed: geometric modeling, deformation and texture. To allow for the wide variety of deformable muscle shapes encountered in the body, while retaining as many of their common properties as possible, the geometric models are classified into several categories according to the characteristics of their structures and actions. Within each category, the model for each muscle has an efficient structural form, created using anatomical data. Deformation is also performed on the basis of the categories, with all models within each category sharing the same deformation scheme. The categories cover both general and special cases. The result is an efficient, anatomically accurate muscle representation that is specifically designed to accommodate the particular form of deformation exhibited by each individual muscle. Interactions between muscles; are also taken into account to avoid penetration occurring between adjacent muscles in our model. To provide a suitable visual effect, the muscle texture is generated directly on the model surface. The textures and colors are obtained from anatomical data via image analysis. Some results are presented on the geometric modeling, the deformation and the texture of muscles related to the lower limb.","1941-0506","","10.1109/2945.998668","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=998668","","Humans;Muscles;Deformable models;Biological system modeling;Solid modeling;Image color analysis;Biomedical imaging;Medical simulation;Shape;Visual effects","muscle;physiological models;deformation;biomechanics;computer animation;biology computing;medical computing;digital simulation;image texture;colour graphics;computational geometry","human muscle modeling;human muscle deformation;anatomy-based approach;muscle simulation;muscle morphological structures;muscle motion;visual description;medically accurate simulation;geometric modeling;muscle texture;deformable muscle shapes;anatomically accurate muscle representation;penetration;colors;image analysis;lower limb;human figure animation","","45","","44","","7 Aug 2002","","","IEEE","IEEE Journals"
"Physically Plausible Wrench Decomposition for Multieffector Object Manipulation","P. Donner; S. Endo; M. Buss","Chair of Automatic Control Engineering and the TUM Institute for Advanced Study, Technical University of Munich, Garching, Germany; Chair of Information-oriented control, Technical University of Munich, München, Germany; Chair of Information-oriented control, Technical University of Munich, München, Germany","IEEE Transactions on Robotics","15 Aug 2018","2018","34","4","1053","1067","When manipulating an object with multiple effectors such as in multidigit grasping or multiagent collaboration, forces and torques (i.e., wrench) applied to the object at different contact points generally do not fully contribute to the resultant object wrench, but partly compensate each other. The current literature, however, lacks a physically plausible decomposition of the applied wrench into its manipulation and internal components. We formulate the wrench decomposition as a convex optimization problem, minimizing the Euclidean norms of manipulation forces and torques. Physical plausibility in the optimization solution is ensured by constraining the internal and manipulation wrench by the applied wrench. We analyze specific cases of three-fingered grasping and 2-D beam manipulation, and show the applicability of our method to general object manipulation with multiple effectors. The wrench decomposition method is then extended to quantification of measures that are important in evaluating physical human-human and human-robot interaction tasks. We validate our approach via comparison to the state of the art in simulation and via application to a human-human object transport study.","1941-0468","","10.1109/TRO.2018.2830369","European Research Council under the European Union's Seventh Framework Program; Technical University of Munich—Institute for Advanced Study; German Excellence Initiative; EU Seventh Framework Program; ERC Starting Grant Control Based on Human Models; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8375105","Cooperative manipulators;force decomposition;grasping;haptics and haptic interfaces;internal force;physical human–robot interaction","Force;Task analysis;Torque;Robots;Grasping;Matrix decomposition","biomechanics;convex programming;dexterous manipulators;end effectors;haptic interfaces;human-robot interaction;manipulator dynamics;multi-agent systems;torque","convex optimization problem;torques;three-fingered grasping;physical human-human;human-robot interaction tasks;multieffector object manipulation;multidigit grasping;multiagent collaboration;Euclidean norms manipulation forces;2-D beam manipulation;physically plausible wrench decomposition;haptic interfaces","","1","","42","CCBY","7 Jun 2018","","","IEEE","IEEE Journals"
"Stability of internet-based teleoperation systems using Bayesian predictions","J. Lee; S. Payandeh","Experimental Robotics Laboratory, School of Engineering Science, Simon Fraser University, Burnaby, BC, Canada; Experimental Robotics Laboratory, School of Engineering Science, Simon Fraser University, Burnaby, BC, Canada","2011 IEEE World Haptics Conference","11 Jul 2011","2011","","","499","504","In this paper, we present a Bayesian prediction approach to improve stability of teleoperation systems over the Internet. Motion and force data flows in a teleoperation system are formulated in discrete time state-space models predicted by Bayesian filters, including the Kalman filter and particle filter. The particle filter, which is known as a robust tracking method in nonlinear and non-Gaussian environments, is used to compensate for the time-varying Internet delay. A stochastic analysis is presented to show stability improvement of a teleoperation system in the case when convergence of a Bayesian predictor is achieved and a generalized form of scattering transformation is used as a control scheme. Experiments are performed using a teleoperation system based on virtual reality. A haptic device is used as a human operator in conjunction with a mechanic-based virtual teleoperator by implementing the proposed Bayesian prediction method. Experimental results show that the proposed method improve stability of an overall teleoperation system in the presence of time-varying delay.","","978-1-4577-0298-3","10.1109/WHC.2011.5945536","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5945536","Teleoperation;haptic interface;time-varying delay;Internet;Bayesian;particle filter;Kalman filter;sequential Monte Carlo;scattering transformation","Force;Delay;Internet;Scattering;Particle filters;Bayesian methods;Stability analysis","Bayes methods;delays;discrete time filters;Gaussian processes;haptic interfaces;human-robot interaction;Internet;Kalman filters;particle filtering (numerical methods);predictive control;stability;state-space methods;telerobotics;time-varying filters;virtual reality","stability;Internet-Based teleoperation systems;Bayesian predictions;discrete time state-space models;Kalman filter;particle filter;nonGaussian environments;time-varying Internet delay;stochastic analysis;scattering transformation;virtual reality;haptic device;human operator;mechanic-based virtual teleoperator","","5","","25","","11 Jul 2011","","","IEEE","IEEE Conferences"
"A semantic layer for knowledge-based game design in edutainment applications","A. Repetto; C. E. Catalano","CNR-IMATI Ge, Via De Marini, 616149 Genova, Italy; CNR-IMATI Ge, Via De Marini, 616149 Genova, Italy","2015 7th International Conference on Intelligent Technologies for Interactive Entertainment (INTETAIN)","12 Nov 2015","2015","","","186","194","Creating and maintaining complex and realistic virtual worlds is still a challenge in game design. Realism is not only related to visual appearance but also to the interactions and situations in the game. This issue is particularly crucial in edutainment applications where realism impacts the learning aspect of the game experience. Introducing semantics in virtual worlds helps define intelligent objects and interactions which would turn into a more realistic game. In this work, we propose to decouple the semantic definition of the game world from its actual implementation in a general-purpose game engine. A semantic layer has been developed to bridge the semantics formalized by ontologies with its realization in the engine. Thanks to this software library, semantics can be specified in a separate formal module and reused in different projects. The proposed approach has been tested to design a serious game concept set in the marine environment.","","978-1-6319-0061-7","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325503","Semantics;object interaction;ontologies;edutainment;natural heritage","Games;Semantics;Engines;Ontologies;Knowledge based systems;Concrete","computer aided instruction;entertainment;formal specification;ontologies (artificial intelligence);serious games (computing);software libraries;virtual reality","knowledge-based game design;edutainment applications;virtual worlds;visual appearance;game experience;learning aspect;intelligent objects;general-purpose game engine;ontologies;software library;formal module;serious game concept;marine environment","","","","22","","12 Nov 2015","","","IEEE","IEEE Conferences"
"Representations and Algorithms for Force-Feedback Display","M. A. Otaduy; C. Garre; M. C. Lin","Department of Computer Science, Universidad Rey Juan Carlos de Madrid (URJC Madrid), Móstoles, Madrid, Spain; Department of Computer Science, Universidad Rey Juan Carlos de Madrid (URJC Madrid), Móstoles, Madrid, Spain; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA","Proceedings of the IEEE","16 Aug 2013","2013","101","9","2068","2080","“Haptic rendering” or “haptic display” can be broadly defined as conveying information about virtual objects or data to a user through the sense of touch. Among all applications of haptic rendering, force-feedback display of contact interactions with rigid and deformable virtual models through the sense of touch has matured considerably over the last decade. In this paper, we present a general framework for force-feedback display of rigid and virtual environments, and we outline its major building blocks. We focus on computational aspects, and we classify algorithms and representations successfully used in the three major subproblems of force-feedback display: collision detection, dynamics simulation, and constrained optimization. In addition, force-feedback display is an integral part of a multimodal experience, often involving both visual and auditory display; therefore, we also discuss the choice of algorithms and representations for force feedback as a part of multimodal display.","1558-2256","","10.1109/JPROC.2013.2246131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6479222","Collision detection;contact modeling;force-feedback display;haptic rendering;physically-based simulation","Haptic interfaces;Rendering (computer graphics);Visualization;Collision avoidance;Heuristic algorithms;Deformable models","digital simulation;display devices;force feedback;haptic interfaces","haptic display;virtual objects;haptic rendering;force-feedback display;deformable virtual models;collision detection;dynamics simulation;constrained optimization;multimodal experience;auditory display;visual display;multimodal display","","15","","98","","13 Mar 2013","","","IEEE","IEEE Journals"
"Evaluating an Immersive Space-Time Cube Geovisualization for Intuitive Trajectory Data Exploration","J. A. W. Filho; W. Stuerzlinger; L. Nedel",Federal University of Rio Grande do Sul; Simon Fraser University; Federal University of Rio Grande do Sul,"IEEE Transactions on Visualization and Computer Graphics","25 Nov 2019","2020","26","1","514","524","A Space-Time Cube enables analysts to clearly observe spatio-temporal features in movement trajectory datasets in geovisualization. However, its general usability is impacted by a lack of depth cues, a reported steep learning curve, and the requirement for efficient 3D navigation. In this work, we investigate a Space-Time Cube in the Immersive Analytics domain. Based on a review of previous work and selecting an appropriate exploration metaphor, we built a prototype environment where the cube is coupled to a virtual representation of the analyst's real desk, and zooming and panning in space and time are intuitively controlled using mid-air gestures. We compared our immersive environment to a desktop-based implementation in a user study with 20 participants across 7 tasks of varying difficulty, which targeted different user interface features. To investigate how performance is affected in the presence of clutter, we explored two scenarios with different numbers of trajectories. While the quantitative performance was similar for the majority of tasks, large differences appear when we analyze the patterns of interaction and consider subjective metrics. The immersive version of the Space-Time Cube received higher usability scores, much higher user preference, and was rated to have a lower mental workload, without causing participants discomfort in 25-minute-long VR sessions.","1941-0506","","10.1109/TVCG.2019.2934415","Conselho Nacional de Desenvolvimento Científico e Tecnológico; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854316","Space-time cube;Trajectory visualization;Immersive analytics","Task analysis;Trajectory;Three-dimensional displays;Data visualization;Clutter;Two dimensional displays;Visualization","data visualisation;human computer interaction;user interfaces;virtual reality","intuitive trajectory data exploration;spatiotemporal features;movement trajectory datasets;user interface features;immersive space-time cube geovisualization;immersive analytics domain;exploration metaphor;virtual representation","","4","","59","","1 Oct 2019","","","IEEE","IEEE Journals"
"Motion sensing based framework for robot manipulation","H. Deng; Z. Xia; S. Weng; Y. Gan; P. Fang; J. Xiong","Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China","2016 IEEE International Conference on Real-time Computing and Robotics (RCAR)","15 Dec 2016","2016","","","511","516","To data, outside of controlled environments, robots have normally performed manipulation tasks when operated with human. This pattern requires operators with high technical skills training and targeted knowledge acquiring for varied teach-pendant operating system. Motion sensing technology, enabling human-machine interaction in a novel and natural user interface using gestures, crucial inspires us to adopt a user-friendly and straight-forward interaction mode on robot manipulation. Thus, in this paper, we presented a motion sensing based framework for robot manipulation, which recognizes gesture commands captured by motion sensing input device and drives the action of robots. For compatibility, a general hardware interface layer was also developed in the framework. Simulation and physical experiments have been conducted for preliminary validation. The results have shown that the proposed framework is an effective approach for general robot manipulation with motion sensing control.","","978-1-4673-8959-4","10.1109/RCAR.2016.7784082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7784082","Human-machine interaction;motion sensing;gesture recognition;robot manipulation","Robot sensing systems;Robot kinematics;Tracking;Hardware;Three-dimensional displays","gesture recognition;human-robot interaction;interactive devices;manipulators;motion control;operating systems (computers)","motion sensing control;robot manipulation;teach-pendant operating system;human-machine interaction;user interface;gesture recognition;input device;hardware interface layer","","1","","19","","15 Dec 2016","","","IEEE","IEEE Conferences"
"GIS attribute data knowledge discovery system","Min Han; Yannan Sun; Shiguo Xu","Sch. of Electron. & Inf. Eng., Dalian Technol. Univ., China; Sch. of Electron. & Inf. Eng., Dalian Technol. Univ., China; NA","IGARSS 2004. 2004 IEEE International Geoscience and Remote Sensing Symposium","27 Dec 2004","2004","4","","2416","2419 vol.4","This paper designs a system that discovers knowledge from a GIS attribute data list. The system can acquire useful knowledge from the attribute data in a spatial database and get if-then rules to assist in decision-making. Four models, a qualitative model, an importance-judging model, a decision-table reducing model and a decision-making model form the backbone of the system. Every model connects orderly. User inputs parameters in qualitative model by human-computer interaction. According to these parameters the system determines actual bell membership functions based on the golden section model. With the membership functions quantitative data are changed into qualitative data that form an initial decision-table. According to rough set theory we develop an importance-judging model and a decision-table reducing model. In the importance-judging model, based on indiscernible relation we get importance of every condition attribute to decision attribute. In the reducing model we provide an effective reducing method to get the most concise if-then rules. The reducing process consists of two steps: firstly forming a discernable matrix to get core attributes, then simplifying every rule until every rule is composed of the least condition attributes. In the decision-making model neural network is used to simulate the most concise rules getting from decision-table reducing model and test the general ability. At the same time the paper makes transparent three factors that affect the general ability. The paper presents an example of its use for judging drought and flood disasters in Songhua river basin. Simulation results show that the system can quickly form the most concise if-then rules and make the right decision.","","0-7803-8742-2","10.1109/IGARSS.2004.1369778","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1369778","","Geographic Information Systems;Decision making;Set theory;Data engineering;Design engineering;Knowledge engineering;Paper technology;Expert systems;Sun;Spatial databases","geographic information systems;data mining;visual databases;human computer interaction;rough set theory;neural nets;decision tables;decision making;rivers;floods;rain;hydrological techniques;geophysics computing","geographic information system;data knowledge discovery system;spatial database;decision making;importance-judging model;decision table reducing model;human-computer interaction;bell membership functions;golden section model;rough set theory;if-then rules;neural network;drought;flood disasters;Songhua river basin;China","","","","7","","27 Dec 2004","","","IEEE","IEEE Conferences"
"Workflows and Challenges Involved in Creation of Realistic Immersive Virtual Museum, Heritage, and Tourism Experiences: A Comprehensive Reference for 3D Asset Capturing","H. Esmaeili; H. Thwaites; P. C. Woods","Sch. of Arts, Sunway Univ., Malaysia; Sch. of Arts, Sunway Univ., Malaysia; Fac. of Creative Multimedia, Multimedia Univ., Cyberjaya, Malaysia","2017 13th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)","12 Apr 2018","2017","","","465","472","This study provides a technical review of the current state of immersive virtual museum, heritage, and tourism focusing on workflows and challenges involved in realistic asset creation. The workflow includes two parts i.e. virtualization of historic objects and creation of environment. However, in some instances the environment itself is a cultural heritage site e.g. an old castle that can be considered as historic object. Otherwise, the environment is just a conceptual virtual place (created using traditional 3D modeling methods) to mimic museum experience, embedding smaller historic objects, which are virtualized. Although tools and technologies such as photogrammetry, 3D scanning, or aerial 3D mapping have made the process of virtualization of historic/cultural objects considerably easier for basic users, challenges and limitations still remain as these automatic processes are not always accompanied by flawless outcomes. This study addresses some of those challenges and limitations faced during preparation of experimental immersive virtual museum for exhibition purposes. This covers various ranges of topics from lighting, texturing, and topology to limitations related to opacity, dark colors, and small details. This paper also provides a comprehensive overview of the technical details when it comes to preparation of virtual cultural heritage environments specifically for immersive experiences. Areas such as user interaction, navigation, space optimization, quality and viewing distance, access, purpose and objectives, degree of realism, etc. are covered in this review. The major processes illustrated in this study include photogrammetry, aerial 3D mapping, polygon modeling, 3D sculpting, 3D painting, UV Mapping, etc. The major software/tools used in this workflow include Agisoft Photoscan, Autodesk Remake, Pixologic ZBrush, xNormal, Autodesk 3ds Max, Unity, SteamVR, HTC Vive, including other relevant plugins and scripts. However, this study is not a step by step guide or a tutorial, but a reference for the currently available technologies to create immersive virtual museum, cultural heritage, and tourism aiming to distinguish the lines between different levels of processes involved. The objective is to provide a clear understanding of the challenges involved. Based on the literature review done prior to this study, a comprehensive academic reference (covering the mentioned areas) for digital heritage researchers is lacking (to date). The authors believe that due to the increasing availability and affordability of the current immersive virtual reality technologies for basic users this is a proper time for gathering major processes/challenges involved in creation of such environments and present them in form of a comprehensive reference. Although the main focus of this study is on digital heritage, the processes undertaken and explained can be generalized to be used by researchers in other fields where applicable.","","978-1-5386-4283-2","10.1109/SITIS.2017.82","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8334788","immersive virtual reality;virtual museum;cultural heritage;virtual tourism;photogrammetry;3d scan;aerial 3d mapping;3d visualization;HTC Vive;Oculus Rift;Unity","Three-dimensional displays;Solid modeling;Painting;Cultural differences;Cameras;Software;Virtualization","history;museums;photogrammetry;solid modelling;travel industry;virtual reality","realistic immersive virtual museum;tourism experiences;3d asset capturing;technical review;realistic asset creation;historic object;conceptual virtual place;traditional 3D modeling methods;museum experience;smaller historic objects;aerial 3D mapping;experimental immersive virtual museum;virtual cultural heritage environments;Autodesk 3;currently available technologies;comprehensive academic reference;digital heritage researchers;current immersive virtual reality technologies;cultural heritage site;historic-cultural objects","","3","","23","","12 Apr 2018","","","IEEE","IEEE Conferences"
"Model-free Probabilistic Movement Primitives for physical interaction","A. Paraschos; E. Rueckert; J. Peters; G. Neumann","Intelligent Autonomous Systems, TU Darmstadt, 64289 Germany; Intelligent Autonomous Systems, TU Darmstadt, 64289 Germany; Intelligent Autonomous Systems, TU Darmstadt, 64289 Germany; Intelligent Autonomous Systems, TU Darmstadt, 64289 Germany","2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","17 Dec 2015","2015","","","2860","2866","Physical interaction in robotics is a complex problem that requires not only accurate reproduction of the kinematic trajectories but also of the forces and torques exhibited during the movement. We base our approach on Movement Primitives (MP), as MPs provide a framework for modelling complex movements and introduce useful operations on the movements, such as generalization to novel situations, time scaling, and others. Usually, MPs are trained with imitation learning, where an expert demonstrates the trajectories. However, MPs used in physical interaction either require additional learning approaches, e.g., reinforcement learning, or are based on handcrafted solutions. Our goal is to learn and generate movements for physical interaction that are learned with imitation learning, from a small set of demonstrated trajectories. The Probabilistic Movement Primitives (ProMPs) framework is a recent MP approach that introduces beneficial properties, such as combination and blending of MPs, and represents the correlations present in the movement. The ProMPs provides a variable stiffness controller that reproduces the movement but it requires a dynamics model of the system. Learning such a model is not a trivial task, and, therefore, we introduce the model-free ProMPs, that are learning jointly the movement and the necessary actions from a few demonstrations. We derive a variable stiffness controller analytically. We further extent the ProMPs to include force and torque signals, necessary for physical interaction. We evaluate our approach in simulated and real robot tasks.","","978-1-4799-9994-1","10.1109/IROS.2015.7353771","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7353771","","Robot sensing systems;Trajectory;Probabilistic logic;Dynamics;Robot kinematics;Force","force control;human-robot interaction;learning (artificial intelligence);probability;signal processing;torque control;variable structure systems","model-free ProMP framework;variable stiffness controller;imitation learning;reinforcement learning;complex movement modelling;kinematic trajectories;complex problem;physical interaction;model-free probabilistic movement primitives","","9","","18","","17 Dec 2015","","","IEEE","IEEE Conferences"
"Learning the sense of touch in simulation: a sim-to-real strategy for vision-based tactile sensing","C. Sferrazza; T. Bi; R. D’Andrea","ETH Zurich,Institute for Dynamic Systems and Control,Switerland; ETH Zurich,Institute for Dynamic Systems and Control,Switerland; ETH Zurich,Institute for Dynamic Systems and Control,Switerland","2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)","10 Feb 2021","2020","","","4389","4396","Data-driven approaches to tactile sensing aim to overcome the complexity of accurately modeling contact with soft materials. However, their widespread adoption is impaired by concerns about data efficiency and the capability to generalize when applied to various tasks. This paper focuses on both these aspects with regard to a vision-based tactile sensor, which aims to reconstruct the distribution of the three- dimensional contact forces applied on its soft surface. Accurate models for the soft materials and the camera projection, derived via state-of-the-art techniques in the respective domains, are employed to generate a dataset in simulation. A strategy is proposed to train a tailored deep neural network entirely from the simulation data. The resulting learning architecture is directly transferable across multiple tactile sensors without further training and yields accurate predictions on real data, while showing promising generalization capabilities to unseen contact conditions.","2153-0866","978-1-7281-6212-6","10.1109/IROS45743.2020.9341285","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9341285","","Training;Surface reconstruction;Tactile sensors;Data models;Sensors;Task analysis;Optical flow","deep learning (artificial intelligence);human-robot interaction;neural net architecture;robot vision;stereo image processing;tactile sensors;touch (physiological)","vision-based tactile sensing;data-driven approaches;contact modeling;soft materials;camera projection;deep neural network;learning architecture;multiple tactile sensors;three-dimensional contact forces;sim-to-real strategy;sense of touch learning;robot interaction","","","","26","","10 Feb 2021","","","IEEE","IEEE Conferences"
"A Fuzzy Rule-Based Model of Vibrotactile Perception via an Automobile Haptic Screen","L. Duţu; G. Mauris; P. Bolon; S. Dabic; J. Tissot","Laboratoire d’Informatique, Systèmes, Traitement de l’Information et de la Connaissance, Polytech Annecy-Chambéry, University of Savoie, Chambéry, France; Laboratoire d’Informatique, Systèmes, Traitement de l’Information et de la Connaissance, Polytech Annecy-Chambéry, University of Savoie, Chambéry, France; Laboratoire d’Informatique, Systèmes, Traitement de l’Information et de la Connaissance, Polytech Annecy-Chambéry, University of Savoie, Chambéry, France; Department of Interior Controls, Valeo, Annemasse, France; Department of Interior Controls, Valeo, Annemasse, France","IEEE Transactions on Instrumentation and Measurement","10 Jul 2015","2015","64","8","2323","2333","With the increased popularity of touch-sensitive surfaces, much attention has been drawn to their security-related issues, as they currently rely only on the visual sense for feedback. To improve operability, vibrotactile signals may be delivered to the finger on screen interaction. The way vibrotactile signals affect human perception is examined via three measured variables, related to their energy, velocity, and spectral complexity, and which are analytically defined in this paper. It is shown that these variables accurately account for the psychophysical properties of the tactile sense. Based on this, a psychophysical fuzzy rule-based model of vibrotactile perception is introduced to forecast the comfort values of the vibrational signals provided by an automobile haptic screen. Using an efficient rule-based generation method, a Mamdani fuzzy inference system is proposed; it achieves a mean error rate of 14% for the train set and 17% for the test set, while correctly classifying most of the signals within a reasonable tolerance, related to human evaluation imprecision. The system also produces a comprehensible linguistic rule structure, which allows behavioral patterns to be detected.","1557-9662","","10.1109/TIM.2015.2398952","FUI-MISAC Project through the French Government; Conseil Général 74; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7047868","Continuous wavelet transforms (CWTs);fuzzy systems;haptic interfaces;sensory evaluation;signal processing.;Continuous wavelet transforms (CWTs);fuzzy systems;haptic interfaces;sensory evaluation;signal processing","Acceleration;Haptic interfaces;Time-frequency analysis;Complexity theory;Automobiles;Visualization;Indexes","computerised instrumentation;fuzzy reasoning;haptic interfaces;knowledge acquisition;learning (artificial intelligence);signal classification;tactile sensors;touch (physiological);vibration measurement","psychophysical fuzzy rule-based model;rule-based generation method;Mamdani fuzzy inference system;signal classification;human evaluation imprecision;comprehensible linguistic rule structure;tactile sensor;psychophysical property;velocity complexity;energy complexity;spectral complexity;human perception;vibrotactile signal;visual sensor;security related issue;touch-sensitive surface;automobile haptic screen;vibrotactile perception","","5","","52","","24 Feb 2015","","","IEEE","IEEE Journals"
"Exploring Feature-Based Learning for Data-Driven Haptic Rendering","A. Sianov; M. Harders","Department of Computer Science, Interactive Graphics and Simulation Group, University of Innsbruck, Innsbruck, Austria; Department of Computer Science, Interactive Graphics and Simulation Group, University of Innsbruck, Innsbruck, Austria","IEEE Transactions on Haptics","16 Sep 2018","2018","11","3","388","399","In this work, we extend ideas of machine learning to the domain of data-driven haptic rendering. The proposed approach facilitates the processing of high-dimensional haptic interaction signals, which so far proved too difficult for existing data-driven methods. The key idea is to construct a compact feature space in the frequency domain which allows for efficient data reduction via a feature selection process. First, in a recording stage, extensive force and displacement datasets are acquired in automated measurements on deformable sample objects. These data are then transformed into a dimensionally reduced, compact frequency space representation. Next, feature-based learning is carried out in this feature space to significantly reduce the size of the original dataset. Based on this, time-domain haptic models capable of real-time performance are finally generated to encode the forces arising from bimanual object interactions. The presented processing chain is generally applicable and extendable to more complex interactions with even higher-dimensional data. The resulting haptic models are directly usable for data-driven haptic rendering. We illustrate the improved performance in comparison with previously existing data-processing approaches.","2329-4051","","10.1109/TOH.2018.2817483","Swiss National Science Foundation, CH; Doktoratsstipendium der Nachwuchsförderung, AT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8320317","Haptic rendering;measurement-based synthesis/modeling","Haptic interfaces;Rendering (computer graphics);Force;Feature extraction;Computational modeling;Force sensors;Phantoms","data reduction;haptic interfaces;learning (artificial intelligence);rendering (computer graphics)","resulting haptic models;data-driven haptic rendering;existing data-processing approaches;exploring feature-based;high-dimensional haptic interaction signals;data-driven methods;compact feature space;efficient data reduction;feature selection process;dimensionally reduced frequency space representation;compact frequency space representation;feature-based learning;time-domain haptic models;higher-dimensional data","","2","","31","","20 Mar 2018","","","IEEE","IEEE Journals"
"Indoor Scene Layout Estimation from a Single Image","H. J. Lin; S. Huang; S. Lai; C. Chiang","Dept. of Computer Science, National Tsing Hua University, Hsinchu, Taiwan; Dept. of Computer Science, National Tsing Hua University, Hsinchu, Taiwan; Dept. of Computer Science, National Tsing Hua University, Hsinchu, Taiwan; Dept. of Computer Science and Information Engineering, National Chung Cheng University, Chiayi, Taiwan","2018 24th International Conference on Pattern Recognition (ICPR)","29 Nov 2018","2018","","","842","847","With the popularity of the hand devices and intelligent agents, many aimed to explore machine's potential in interacting with reality. Scene understanding, among the many facets of reality interaction, has gained much attention for its relevance in applications such as augmented reality (AR). Scene understanding can be partitioned into several sub tasks (i.e., layout estimation, scene classification, saliency prediction, etc). In this paper, we propose a deep learning-based approach for estimating the layout of a given indoor image in real-time. Our method consists of a deep fully convolutional network, a novel layout-degeneration augmentation method, and a new training pipeline which integrate an adaptive edge penalty and smoothness terms into the training process. Unlike previous deep learning-based methods that depend on post-processing refinement (e.g., proposal ranking and optimization), our method motivates the generalization ability of the network and the smoothness of estimated layout edges without deploying postprocessing techniques. Moreover, the proposed approach is time-efficient since it only takes the model one forward pass to render accurate layouts. We evaluate our method on LSUN Room Layout and Hedau dataset and obtain estimation results comparable with the state-of-the-art methods.","1051-4651","978-1-5386-3788-3","10.1109/ICPR.2018.8546278","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8546278","","Layout;Estimation;Semantics;Training;Image edge detection;Task analysis;Pipelines","augmented reality;convolution;feedforward neural nets;image classification;image segmentation;learning (artificial intelligence)","Hedau dataset;proposal ranking;indoor scene layout estimation;layout-degeneration augmentation method;deep learning-based methods;augmented reality interaction;LSUN Room Layout;optimization;post-processing refinement;adaptive edge penalty;training pipeline;deep fully convolutional network;saliency prediction;scene classification;intelligent agents;hand devices","","2","","17","","29 Nov 2018","","","IEEE","IEEE Conferences"
"Vehicle Control in Highway Traffic by Using Reinforcement Learning and Microscopic Traffic Simulation","L. Szoke; S. Aradi; T. Becsi; P. Gaspar","Budapest University of Technology and Economics, Megyetem rkp. 3,Department of Control for Transportation and Vehicle Systems,Budapest,Hungary,H-1111; Budapest University of Technology and Economics, Megyetem rkp. 3,Department of Control for Transportation and Vehicle Systems,Budapest,Hungary,H-1111; Budapest University of Technology and Economics, Megyetem rkp. 3,Department of Control for Transportation and Vehicle Systems,Budapest,Hungary,H-1111; Computer and Automation Research Institute, Hungarian Academy of Sciences, Kende u. 13-17,Systems and Control Laboratory,Budapest,Hungary,H-1111","2020 IEEE 18th International Symposium on Intelligent Systems and Informatics (SISY)","8 Oct 2020","2020","","","21","26","The paper presents a simple yet powerful and intelligent driver agent, designed to operate in a preset highway situation using Policy Gradient Reinforcement Learning (RL) agent. The goal is to navigate safely in dense highway traffic and proceed through the defined length with the shortest time possible. The algorithm uses a dense neural network as a function approximator for the agent with discrete action space on the control level, e.g., acceleration and steering. The developed simulation environment uses the open-source traffic simulator called Simulation of Urban MObility (SUMO), integrated with an interface, to interact with the agent in real-time. With this tool, numerous driving and highway situations can be created and fed to the agent from which it can learn. The environment opens the opportunity to randomize and customize the other road users' behavior. Thus the experience can be more diverse, and thus the representation becomes more general. The article describes the modeling environment, the details on the learning agent, and the rewarding scheme. After evaluating the experiences gained from the training, some ideas for optimization and further development goals are also proposed.","1949-0488","978-1-7281-7352-8","10.1109/SISY50555.2020.9217076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9217076","","Learning (artificial intelligence);Task analysis;Vehicles;Roads;Training;Microscopy","intelligent transportation systems;interactive systems;learning (artificial intelligence);neural nets;real-time systems;road safety;road traffic control;software agents;traffic engineering computing","vehicle control;microscopic traffic simulation;intelligent driver agent;policy gradient reinforcement learning agent;highway traffic;dense neural network;open source traffic simulator;simulation of urban mobility;SUMO;real time agent interaction;road user behavior","","","","23","","8 Oct 2020","","","IEEE","IEEE Conferences"
"A platform to design and run dynamic virtual environments","H. I. Piza; F. Zuniga; F. F. Ramos","Centro de Investigacion y de Estudios Avanzados, Instituto Politecnico Nacional, Mexico City, Mexico; Centro de Investigacion y de Estudios Avanzados, Instituto Politecnico Nacional, Mexico City, Mexico; Centro de Investigacion y de Estudios Avanzados, Instituto Politecnico Nacional, Mexico City, Mexico","2004 International Conference on Cyberworlds","27 Dec 2004","2004","","","78","85","This paper is devoted to introducing, in a general fashion, a platform that allows users to generate virtual scenes. Such generation involves two phases: 1) description of the attributes, arrangement and intentions of the virtual characters participants throughout a natural language, and 2) a virtual representation of a dynamic scene during which the characters interact with each other in order to fulfill the specification provided by the modeler.","","0-7695-2140-1","10.1109/CW.2004.9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1366157","","Layout;Animation;Engines;Computational modeling;Multiagent systems;Character generation;Natural languages;Animals;Human robot interaction;Avatars","virtual reality;computer animation;natural scenes","virtual scenes;natural language;virtual environment;computer animation","","3","","11","","27 Dec 2004","","","IEEE","IEEE Conferences"
"Image data flows and bottlenecks in medical informatics: exploratory dynamic simulation of radiologic processes at a moderate-size California medical center","R. Burkhard; T. Horan","San Jose State Univ., CA, USA; NA","Proceedings 5th International Workshop on Enterprise Networking and Computing in Healthcare Industry (HealthCom)","4 Aug 2003","2003","","","52","57","The objective of medical informatic systems is to enhance the efficiency of the medical process, especially as it relates to patient interaction with the health care system. We use a dynamic simulation model to estimate the current performance of a moderate size radiological unit in an urban health care center. The principal findings include description of existing informatics processes, as well as calculated results from dynamic statistical simulation of the system. Bottlenecks were observed throughout the process, with simulation estimated maximum queues ranging from 33.9 hours (fluoroscopy) to 254.3 hours (general X-rays). The impact of digital systems (e.g. PACS) on each delay point is also discussed. We demonstrate that the dynamic modelling approach such as by the ARENA model can answer specific questions pertaining to streamlining of complex, multistage medical information processes and assist in cost/benefit analysis for implementation of all digital alternatives to existing systems.","","0-7803-7960-8","10.1109/HEALTH.2003.1218718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1218718","","Biomedical informatics;Medical simulation;Biomedical imaging;Aerodynamics;Medical services;X-rays;Digital systems;Picture archiving and communication systems;Delay;Cost benefit analysis","medical information systems;health care;medical computing;biomedical imaging;radiology;digital simulation;cost-benefit analysis","image data flow;medical informatic systems;radiologic process;health care;dynamic simulation;digital systems;ARENA model;cost-benefit analysis;PACS;picture archiving and communication systems;California medical center;MedCenter;33.9 to 254.3 hours","","1","","6","","4 Aug 2003","","","IEEE","IEEE Conferences"
"Intent Inference of Human Hand Motion for Haptic Feedback Systems","M. Zhao; S. Dai",Beihang University; Beihang University,"2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)","27 Dec 2019","2019","","","218","2185","The haptic feedback system (HFS) in the virtual cockpit system (VCS) can definitely enhance the sense of immersion. Most HFSs in prior works sacrificed the native advantages of VCSs to achieve haptic interaction. This paper addresses the problem by proposing a novel framework for the HFS, which can predict the most likely interacting target of the human hand in advance. We introduce a HFS with a non-contact visual tracking sensor and a probability inference method based on Bayesian statistics, the features extracted by this HFS could be low-cost, high generality and flexibility. Simulations show that human intent inference can be computed in real-time and the results can meet the requirements of the HFM, which provides an important basis for haptic interactions in VCSs.","","978-1-7281-5604-0","10.1109/AIVR46125.2019.00046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942346","intent inference;haptic feedback;virtual cockpit system;human computer interaction;Kalman filter","Hafnium;Haptic interfaces;Kalman filters;Bayes methods;Manipulators;Predictive models;Three-dimensional displays","aerospace computing;aircraft;Bayes methods;feature extraction;haptic interfaces;inference mechanisms","human hand motion;haptic feedback system;HFS;virtual cockpit system;VCSs;haptic interaction;noncontact visual tracking sensor;probability inference method;human intent inference;Bayesian statistics","","","","21","","27 Dec 2019","","","IEEE","IEEE Conferences"
"Research on model description method of multi-agent system","C. Guo; W. Xiong","Equipment Academy, Beijing, China; Equipment Academy, Beijing, China","2015 6th IEEE International Conference on Software Engineering and Service Science (ICSESS)","30 Nov 2015","2015","","","603","606","When Agent-based modeling and simulation is applied to researches on complex systems in different areas, the generality and normalization are usually insufficient, because there are differences between different target systems. So an abstracted method of describing multi-Agent systems is necessary. A method of model description of multi-Agent systems is put forward. It describes a multi-Agent system in respects of environment, Agents and interactions, and models an Agent by attributes, behaviors and rules. According to the method, a simulation framework generation tool is developed, and a military confronting system is taken as an example to verify the method.","2327-0594","978-1-4799-8353-7","10.1109/ICSESS.2015.7339130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7339130","multi-Agent system;model description;simulation framework generation","Biological system modeling;Complex systems;Multi-agent systems;Object oriented modeling;Sensors;Agent-based modeling;Artificial intelligence","digital simulation;multi-agent systems","model description method;multiagent system;agent-based modeling;agent-based simulation framework generation tool;military confronting system","","","","6","","30 Nov 2015","","","IEEE","IEEE Conferences"
"Self-organization based DSS framework","Zhang Lei; Ren Shouju; Liu Zuzhao","Tsinghua Univ., Beijing, China; NA; NA","Smc 2000 conference proceedings. 2000 ieee international conference on systems, man and cybernetics. 'cybernetics evolving to systems, humans, organizations, and their complex interactions' (cat. no.0","6 Aug 2002","2000","1","","609","614 vol.1","This paper presents a new decision support system (DSS) framework based on the self-organization principle, which offers flexibility and rationality in a complex enterprise environment. Firstly, the complexity of the current decision environment is analyzed. Then, the decision procedure model and its general dynamic state equation model are introduced. As the order-parameter is a key concept in the self-organization principle, the paper gives a diagrammatic strategy for DSS modeling, which divides the DSS solution methodology into both an order-parameter abstraction and a rule propagation procedure. The fractal data structure of the DSS is explained. Furthermore, a self-organization simulation model is introduced, which is the core of the new DSS framework, and which results in an advanced decision support strategy.","1062-922X","0-7803-6583-6","10.1109/ICSMC.2000.885061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=885061","","Decision support systems;Chaos;Decision theory;Layout;Probability distribution;Negative feedback;Nonlinear equations;Power system modeling;Fractals;Data structures","decision support systems;self-adjusting systems;interconnected systems;digital simulation","self-organization based DSS framework;complex decision problems;complex enterprise environment;decision environment;decision procedure model;dynamic state equation model;order-parameter;self-organization principle;diagrammatic strategy;DSS modeling;DSS solution methodology;order-parameter abstraction;rule propagation procedure;fractal data structure;self-organization simulation model;decision support","","1","","5","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Agentsheets: applying grid-based spatial reasoning to human-computer interaction","A. Repenning; W. Citrin","Dept. of Comput. Sci., Colorado Univ., Boulder, CO, USA; NA","Proceedings 1993 IEEE Symposium on Visual Languages","6 Aug 2002","1993","","","77","82","This paper argues that grid-based spatial reasoning can significantly improve human-computer interaction. While grids constrain the user's ability to position objects on a screen on one hand, they greatly increase the transparency of functional relationships among these objects on the other hand. A system called Agentsheets employs a spatio-temporal metaphor of communicating agents sharing a structured space. This domain-independent metaphor can be used to create domain-oriented visual programming systems. This paper explains how Agentsheets fits into the spectrum of domain-orientation ranging from general purpose visual programming languages to domain-oriented construction kits, gives a short introduction of Agentsheets, sketches sample applications, and evaluates the contribution of grid-based spatial reasoning to human-computer interaction.<>","","0-8186-3970-9","10.1109/VL.1993.269581","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=269581","","Computer languages;Application software;Computer science;Cognitive science;Grid computing;Hardware;Humans;Graphical user interfaces;Libraries;Communication channels","cooperative systems;spatial reasoning;user interfaces;visual programming","Agentsheets;grid-based spatial reasoning;human-computer interaction;spatio-temporal metaphor;communicating agents;domain-oriented visual programming;general purpose visual programming languages;domain-oriented construction kits","","10","1","21","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Supporting human interaction with robust robot swarms","S. Kerman; D. Brown; M. A. Goodrich","Brigham Young University, Provo, UT 84602, USA; Brigham Young University, Provo, UT 84602, USA; Computer Science Department, Brigham Young University, Provo, UT 84602, USA","2012 5th International Symposium on Resilient Control Systems","24 Sep 2012","2012","","","197","202","In this paper we propose a bio-inspired model for a decentralized swarm of robots, similar to the model proposed by Couzin [5], that allows for dynamic task assignment and is robust to limited communication from a human. We provide evidence that the model has two fundamental attractors: a torus attractor and a flock attractor. Through simulation and mathematical analysis we investigate the stability of these attractors and show that a control input can be used to force the system to change from one attractor to the other. Finally, we generalize another of Couzin's ideas [4] and present the idea of a stakeholder agent. We show how a human operator can use stakeholders to responsively influence group behavior while maintaining group structure.","","978-1-4673-0163-3","10.1109/ISRCS.2012.6309318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6309318","","Lead;Hafnium compounds","human-robot interaction;mathematical analysis;multi-robot systems;robust control","human interaction;robust robot swarms;bioinspired model;dynamic task assignment;flock attractor;torus attractor;mathematical analysis;stakeholder agent;human operator","","12","","13","","24 Sep 2012","","","IEEE","IEEE Conferences"
"Motion planning for a new golf swing robot","A. Ming; M. Kajitani","Univ. of Electro-Commun., Tokyo, Japan; NA","Smc 2000 conference proceedings. 2000 ieee international conference on systems, man and cybernetics. 'cybernetics evolving to systems, humans, organizations, and their complex interactions' (cat. no.0","6 Aug 2002","2000","5","","3282","3287 vol.5","A new golf swing robot to simulate the human skill of motion control in a golf swing has been developed by authors. It consists of one actuated joint and one passive joint with mechanical stopper. Optimal motion planning of the robot to satisfy the boundary conditions and non-holonomic constraint introduced by the stopper under different cost functions is discussed. A general method for motion planning of such types of system is described and the results of motion planning for the golf swing robot are shown.","1062-922X","0-7803-6583-6","10.1109/ICSMC.2000.886511","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=886511","","Motion planning;Robots;Humans;Motion control;Acceleration;Prototypes;Torque;Equations;Shafts;Damping","mobile robots;path planning;motion control;sport;digital simulation;behavioural sciences computing","boundary conditions;golf swing robot;human skill;motion control;actuated joint;passive joint;mechanical stopper;optimal motion planning;non-holonomic constraint;cost functions","","3","","5","","6 Aug 2002","","","IEEE","IEEE Conferences"
"System level interference mitigation schemes in EGPRS: Mode-0 and scheduling","K. Balachandran; Kirk Chang; Wei Luo; S. Nanda","Lucent Technol. Bell Labs., Holmdel, NJ, USA; NA; NA; NA","IEEE VTS 53rd Vehicular Technology Conference, Spring 2001. Proceedings (Cat. No.01CH37202)","7 Aug 2002","2001","4","","2489","2493 vol.4","We study different packet transmission scheduling algorithms and their interactions with Mode-0 for EGPRS. Our simulation results show that the highest-rate-first scheduling algorithm achieves a good balance between throughput performance and ease of implementation, When combined with Mode-0, the mean throughput performance can be improved up to 20%.","1090-3038","0-7803-6728-6","10.1109/VETECS.2001.944049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=944049","","Interference;Throughput;Scheduling algorithm;Delay effects;Kirk field collapse effect;Packet radio networks;Modulation coding;Degradation;Resumes;Web pages","radiofrequency interference;packet radio networks;digital simulation","system level interference mitigation;EGPRS;Mode-0;Enhanced General Packet Radio Service;packet transmission scheduling algorithms;simulation results;highest-rate-first scheduling algorithm;mean throughput performance","","1","","9","","7 Aug 2002","","","IEEE","IEEE Conferences"
"A Mirror World-Based Robot Control System","J. McLin; N. Hoang; W. Deneke; P. McDowell","Comput. Sci. & Ind. Technol., Southeastern Louisiana Univ. d, Hammond, LA, USA; Comput. Sci. & Ind. Technol., Southeastern Louisiana Univ. d, Hammond, LA, USA; Comput. Sci. & Ind. Technol., Southeastern Louisiana Univ. d, Hammond, LA, USA; Comput. Sci. & Ind. Technol., Southeastern Louisiana Univ. d, Hammond, LA, USA","2017 Second International Conference on Information Systems Engineering (ICISE)","28 Dec 2017","2017","","","74","77","This paper describes an approach to establish bidirectional interactions between robots in the physical and virtual worlds, enabling changes that occur to a physical robot to be automatically reflected by its virtual counterpart, and vice versa. To explore this mirror world concept, a general approach is developed to trigger events that propagate changes between physical and virtual robot counterparts. The accuracy and usability of this approach are then evaluated by constructing a physical robot, creating a virtual model of this robot in Unity, and gathering results from test scenarios.","2160-1291","978-1-5090-4879-3","10.1109/ICISE.2017.10","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8241223","virtual worlds;robotics;mirror worlds","Robot sensing systems;Robot kinematics;Mirrors;Usability;Keyboards;Testing","control engineering computing;mobile robots;solid modelling;virtual reality","virtual worlds;mirror world concept;physical robot counterparts;virtual robot counterparts;virtual model;bidirectional interactions;physical worlds;mobile robot control;Unity model","","","","9","","28 Dec 2017","","","IEEE","IEEE Conferences"
"Tele-robotics for motion planning assistance to search pipeline defects","E. A. Martínez-García; A. Martínez-Villafañe; R. E. Mohan","Laboratorio de Robótica, Institute of Engeneering and Technology, Universidad Autónoma de Cd. Juárez, Ave. Charro 450 Norte, 32310, Mexico; Centro de Investigación en Materiales Avanzados, Integridad y Diseño de Materiales Compuestos, Comp. Ind. Chih., 31109 Mexico; Singapore University of Technology and Design, 20 Dover Road, Singapore 138682","2012 7th IEEE Conference on Industrial Electronics and Applications (ICIEA)","24 Nov 2012","2012","","","160","165","We present a novel robotised search procedure to find flaws in buried pipelines. The motion planning system is based on an electrochemical ground measuring technique called direct-current voltage gradient (DCVG), and we combine it with the use of a tele-robotics assistance system. Remote human-robot interaction (HRI) deploys a trade on/off of information to accomplish defects search (in semi-autonomous mode). Furthermore, in the autonomous, we formulated a novel non-linear potential field approach to give the robot capabilities to automatically perform the search. The whole system consists of a tele-system; a four-wheeled driven (4WD) mobile robot with instruments on-board; a DCVG-based motion planning model; and the human-robot interaction protocol. In this approach we provide a general mathematical solution, numerical simulations, and experimental teleoperation trades.","2158-2297","978-1-4577-2119-9","10.1109/ICIEA.2012.6360716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360716","","Mathematical model;Humans;Robot kinematics;Electric potential;Equations;Electrodes","buried object detection;control engineering computing;fracture;human-robot interaction;industrial robots;mobile robots;nonlinear control systems;numerical analysis;path planning;pipelines;telerobotics","motion planning assistance;pipeline defect search;robotised search procedure;buried pipeline flaw;motion planning system;electrochemical ground measuring technique;direct-current voltage gradient;telerobotics assistance system;remote human-robot interaction;HRI;semiautonomous mode;nonlinear potential field approach;robot capabilities;telesystem;four-wheeled driven mobile robot;4WD mobile robot;DCVG-based motion planning model;human-robot interaction protocol;mathematical solution;numerical simulation;teleoperation trade","","","","8","","24 Nov 2012","","","IEEE","IEEE Conferences"
"Information Constrained Control Analysis of Eye Gaze Distribution Under Workload","R. M. Hecht; A. B. Hillel; A. Telpaz; O. Tsimhoni; N. Tishby","Rachel and Selim Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem, Israel; Department of Industrial Engineering and Management, Ben-Gurion University of the Negev—Faculty of Engineering Sciences, Beersheba, Israel; Advanced Technical Center Israel, General Motors, Herzliya, Israel; General Motors Technical Center, Warren, MI, USA; Rachel and Selim Benin School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem, Israel","IEEE Transactions on Human-Machine Systems","4 Dec 2019","2019","49","6","474","484","We describe a novel model of human eye gaze behavior under workload, derived from the basic principle of information constrained control. The model assumes two distributions over the visual field: A saliency distribution, which is nongoal oriented, and a reward task-related distribution. The eye gaze behavior is determined by the tradeoff between these two distributions, where the goal is to preserve the task-related constraints, while remaining as close as possible to the saliency distribution representing a comfort zone. Based on minimum Kullback-Liebler divergence principles, the model gives rise to a family of gaze distributions controlled by a single tradeoff parameter. The model was evaluated experimentally in a driving simulator that consisted of an immersive environment with clear tasks and accurate monitoring capabilities. The findings confirm the theoretical predictions with respect to the low rank manifold and order relations in the data. We show that the model can be used to visualize the unknown reward function associated with a task, and predict human workload based on gaze pattern.","2168-2305","","10.1109/THMS.2019.2930996","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8821410","Eye gazing distribution;information constrained control (ICC)","Gaze tracking;Visual systems;Computational modeling;Task analysis;Visualization;Position measurement","control engineering computing;data visualisation;distributed control;human computer interaction;statistical distributions","Kullback-Liebler divergence principles;human eye gaze behavior;visual field;information constrained control","","","","43","IEEE","30 Aug 2019","","","IEEE","IEEE Journals"
"Spatial Blockchain-Based Secure Mass Screening Framework for Children With Dyslexia","M. A. Rahman; E. Hassanain; M. M. Rashid; S. J. Barnes; M. S. Hossain","Department of Forensic Computing and Cyber Security, Faculty Computing and Cyber Sciences, University of Prince Mugrin, Madinah, Saudi Arabia; Department of Forensic Computing and Cyber Security, Faculty Computing and Cyber Sciences, University of Prince Mugrin, Madinah, Saudi Arabia; Consumer and Organizational Digital Analytics Research Centre, King’s Business School, King’s College London, London, WC2B 4BG, U.K.; Consumer and Organizational Digital Analytics Research Centre, King’s Business School, King’s College London, London, WC2B 4BG, U.K.; Research Chair of Pervasive and Mobile Computing, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia","IEEE Access","9 Nov 2018","2018","6","","61876","61885","In this paper, we present a novel method, process, and system for calculating dyslexic symptoms, generating metric data for an individual user, community, or group in general. We present a mobile multimedia Internet of Things (IoT)-based environment that can capture multimodal smartphone or tab-based user interaction data during dyslexia testing and share it via a mobile edge network, which employs auto-grading algorithms to find dyslexia symptoms. In addition to algorithm-based auto-grading, the captured mobile multimedia payload is stored in a decentralized repository that can be shared with a medical practitioner for replay and further manual analysis purposes. Since the framework is language-independent and based on Blockchain and a decentralized big data repository, dyslexic patterns and a massive amount of captured multimedia IoT test data can be shared for further clinical research, statistical analysis, and quality assurance. Notwithstanding, our proposed Blockchain and off-chain-based decentralized and secure dyslexia data storage, management, and sharing framework will allow security, anonymity, and multimodal visualization of the captured test data for mobile users. This paper presents the detailed design, implementation, and test results, which demonstrate the strong potential for wider adoption of the dyslexia mobile health management globally.","2169-3536","","10.1109/ACCESS.2018.2875242","CODA Research Centre, King’s Business School, King’s College London, UK; Deanship of Scientific Research, King Saud University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8488459","Blockchain;dyslexia;auto-grading;mass screening;mobile multimedia health","Big Data;Writing;Stakeholders;Testing;Multimedia systems","Big Data;cryptography;data analysis;diseases;handicapped aids;Internet of Things;medical computing;mobile computing;multimedia communication;smart phones;statistical analysis;user interfaces","captured test data;mobile users;test results;dyslexia mobile health management;spatial Blockchain-based secure mass screening framework;dyslexic symptoms;metric data;mobile multimedia Internet;multimodal smartphone;dyslexia testing;mobile edge network;auto-grading algorithms;dyslexia symptoms;captured mobile multimedia payload;decentralized repository;manual analysis purposes;decentralized big data repository;dyslexic patterns;captured multimedia;off-chain-based;sharing framework;anonymity;Internet of Things-based environment","","8","","46","","10 Oct 2018","","","IEEE","IEEE Journals"
"Efficient client-to-server assignments for distributed virtual environments","Duong Nguyen Binh Ta; Suiping Zhou","Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore; Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore","Proceedings 20th IEEE International Parallel & Distributed Processing Symposium","26 Jun 2006","2006","","","10 pp.","","Distributed virtual environments (DVEs) are distributed systems that allow multiple geographically distributed clients (users) to interact simultaneously in a computer-generated, shared virtual world. Applications of DVEs can be seen in many areas nowadays, such as online games, military simulations, collaborative designs, etc. To support large-scale DVEs with real-time interactions among thousands or more distributed clients, a geographically distributed server architecture (GDSA) is generally needed, and the virtual world can be partitioned into many distinct zones to distribute the load among the servers. Due to the geographic distributions of clients and servers in such architectures, it is essential to efficiently assign the participating clients to servers to enhance users' experience in interacting within the DVE. This problem is termed the client assignment problem. In this paper, we propose a two-phase approach, consisting of an initial assignment phase and a refined assignment phase to address this problem. Both phases are shown to be NP-hard, and several heuristic assignment algorithms are then devised based on this two-phase approach. Via extensive simulation studies with realistic settings, we evaluate these algorithms in terms of their performances in enhancing interactivity of the DVE","1530-2075","1-4244-0054-6","10.1109/IPDPS.2006.1639288","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1639288","","Virtual environment;Military computing;Distributed computing;Application software;Computational modeling;Online Communities/Technical Collaboration;Large-scale systems;Computer architecture;Heuristic algorithms;Performance evaluation","client-server systems;computational complexity;real-time systems;virtual reality","client-to-server assignments;distributed virtual environments;computer-generated shared virtual world;real-time interactions;geographically distributed server architecture;client assignment problem;NP-hard problem;heuristic assignment algorithms","","4","","26","","26 Jun 2006","","","IEEE","IEEE Conferences"
"Development of platform-independent multi-user choreographies for virtual worlds based on ontology combination and mapping","E. Silva; N. Silva; H. Paredes; P. Martins; B. Fonseca; L. Morgado","School of Engineering, Plytechnic of Porto, Portugal; School of Engineering, Plytechnic of Porto, Portugal; INESC TEC/UTAD, University of Trás-os-Montes e Alto Douro, Vila Real, Portugal; INESC TEC/UTAD, University of Trás-os-Montes e Alto Douro, Vila Real, Portugal; INESC TEC/UTAD, University of Trás-os-Montes e Alto Douro, Vila Real, Portugal; INESC TEC/UTAD, University of Trás-os-Montes e Alto Douro, Vila Real, Portugal","2012 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)","10 Nov 2012","2012","","","149","152","This paper presents two contributions: (i) a system architecture capable of staging platform-independent choreographies within different virtual worlds, and (ii) an ontology-based solution for capturing and representing multi-user choreographies with reduced time/effort. We argue that choreographies for virtual worlds should be clearly separated from the technical characteristics of their execution in virtual world technological platforms. Due to the heterogeneity of the various virtual worlds and their domain requirements, we propose exploiting the modularity, generality, and granularity dimensions of ontologies to simplify and empower the choreography modeling capabilities. Instead of a unique ontology, several ontologies with different levels of generality and granularity can be progressively combined to support the modeling requirements of a given choreography. Because these ontologies are aligned with the ontology of each specific virtual world platform, the mapping and transformation between the core ontology is simplified and automated, thus reducing the development and time-to-market.","1943-6106","978-1-4673-0853-3","10.1109/VLHCC.2012.6344502","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6344502","virtual worlds;choreographies;multi-user;ontology;combination;mapping","Ontologies;Data models;Humans;Engines;Computer architecture;Games;Strips","groupware;human computer interaction;ontologies (artificial intelligence);virtual reality","platform-independent multiuser choreography;ontology combination;ontology mapping;system architecture;platform-independent choreography;ontology-based solution;multiuser choreography capture;multiuser choreography representation;technical characteristics;virtual world technological platform;domain requirement;modularity dimension;generality dimension;granularity dimension;choreography modeling;time-to-market","","5","","16","","10 Nov 2012","","","IEEE","IEEE Conferences"
"Toward automated haptic modeling using commercial haptic interfaces: surface normal estimation and static model identification","M. A. Judd; T. L. Brown; M. B. Colton","Brigham Young University, Department of Mechanical Engineering, USA; Brigham Young University, Department of Mechanical Engineering, USA; Brigham Young University, Department of Mechanical Engineering, USA","World Haptics 2009 - Third Joint EuroHaptics conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems","3 Apr 2009","2009","","","434","439","The use of commercial haptic interfaces to create models of the feel of physical objects has the potential to transform the field of haptic modeling by broadening the availability of haptic modeling technology. In this paper we develop methods that enable general haptic interfaces to actuate and measure the dynamic properties of physical objects and generate models of their behavior. Specifically, methods are presented that allow commercial haptic interfaces to 1) estimate interaction forces without the use of force sensors, 2) estimate surface normal directions, and 3) actuate objects and identify haptic models from experimental data. Results are presented for two 1-D push buttons, one foam ball, and one inflatable vinyl ball. Initial results suggest that the methods have promise, but challenges must be overcome related estimating forces without the use of force sensors.","","978-1-4244-3858-7","10.1109/WHC.2009.4810878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810878","","Haptic interfaces;Force sensors;Probes;Nonlinear dynamical systems;Force measurement;Instruments;Virtual environment;Teleoperators;Cities and towns;Mechanical engineering","estimation theory;haptic interfaces;identification","automated haptic modeling;commercial haptic interfaces;surface normal estimation;static model identification;1-D push buttons","","2","","9","","3 Apr 2009","","","IEEE","IEEE Conferences"
"Tandem Stance Avoidance Using Adaptive and Asymmetric Admittance Control for Fall Prevention","S. Nakagawa; Y. Hasegawa; T. Fukuda; I. Kondo; M. Tanimoto; P. Di; J. Huang; Q. Huang","Department of Micro-Nano Systems Engineering, Nagoya University, Nagoya, Japan; Department of Micro-Nano Systems Engineering, Nagoya University, Nagoya, Japan; Department of Mechatronics Engineering, Meijo University, Nagoya University, Beijing Institute of Technology, Nagoya, Japan; Department of Rehabilitation, National Center for Geriatrics and Gerontology, Obu, Aichi, Japan; Department of Rehabilitation, National Center for Geriatrics and Gerontology, Obu, Aichi, Japan; Department of Micro-Nano Systems Engineering, Nagoya University, Nagoya, Japan; Department of Control Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; Department of Mechatronics, Beijing Institute of Technology, Beijing, China","IEEE Transactions on Neural Systems and Rehabilitation Engineering","9 May 2016","2016","24","5","542","550","Fall prevention is one of the most important functions of walking assistance devices for user's safety. It is preferable that these devices prevent the user from being in the state where the risk of falling is high rather than helping them recovering from falling motion. During turning, when the user is in the tandem stance, a state where both legs form a line along walking direction, a support base that is surrounded by two legs becomes small, and a stability margin becomes small. This paper therefore aims to prevent the tandem stance by using nonwearable robot “intelligent cane” for the elderly or physically challenged person. Generally, the behavior of the lower limb follows the upper body turning. This paper therefore introduces a cane robot control method which constrains the behavior of user's upper body. By adjusting an admittance parameter of the robot according to the positions of a support leg, the robot resists to turn while a support leg is on the same side of the turning direction. A swing leg on the turning direction side therefore freely moves to the turning direction, while a swing leg on the opposite direction side of turning hardly move to the turning direction.","1558-0210","","10.1109/TNSRE.2015.2429315","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7101279","Accident prevention;human–robot interaction;rehabilitation robotics;tandem stance","Legged locomotion;Turning;Admittance;Force;Senior citizens;Robot sensing systems","adaptive control;gait analysis;geriatrics;handicapped aids;human-robot interaction;intelligent robots;medical robotics","tandem stance avoidance;adaptive admittance control;asymmetric admittance control;fall prevention;walking assistance devices;walking direction;nonwearable robot intelligent cane;elderly person;physically challenged person;lower limb behavior;upper body turning;cane robot control method;turning direction;swing leg;admittance parameter","Accidental Falls;Aged;Aged, 80 and over;Canes;Computer Simulation;Equipment Design;Equipment Failure Analysis;Exoskeleton Device;Female;Gait;Gait Disorders, Neurologic;Humans;Male;Man-Machine Systems;Models, Biological;Monitoring, Ambulatory;Physical Stimulation;Robotics;Self-Help Devices;Stress, Mechanical;Touch;Walking","18","","13","","4 May 2015","","","IEEE","IEEE Journals"
"From spreadsheets to simulations: a comparison of analysis methods for IC manufacturing performance","M. Baudin; V. Mehrotra; B. Tullis; D. Yeaman; R. A. Hughes","MTJ, Palo Alto, CA, USA; NA; NA; NA; NA","[1992 Proceedings] IEEE/SEMI International Semiconductor Manufacturing Science Symposium","6 Aug 2002","1992","","","94","99","Illustrates the differences between spreadsheet and simulation models through the examples of diffusion cell staffing, material flows through a process segment, and the operations of a full fab. The results show that engineering judgment applied to spreadsheet outputs is not the most prudent solution when more realistic tools are available, and, that by overstating capacity, spreadsheet logic can lead to a lack of key equipment and space. Using similar input data, simulation models provide capacity estimates, as well as WIP (work in process) and cycle time predictions, which take into account the interactions between lots, machines, and people. Generally speaking, the spreadsheet model is inadequate for modeling the coordinated use of several types of resources. Until recently, the spreadsheet was still preferred in spite of its limitations because of the vast amounts of computing resources required for simulation runs. It is concluded that the advent of cheap and powerful workstations has made this a moot point.<>","","0-7803-0680-5","10.1109/ISMSS.1992.197644","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=197644","","Analytical models;Performance analysis;Virtual manufacturing;Production facilities;Logic;Performance gain;Capacity planning;Predictive models;Computational modeling;Embedded software","digital simulation;integrated circuit manufacture;process control;spreadsheet programs","spreadsheet models;analysis methods;IC manufacturing performance;simulation models;diffusion cell staffing;material flows;process segment;full fab;WIP;cycle time predictions;computing resources;workstations","","8","4","6","","6 Aug 2002","","","IEEE","IEEE Conferences"
"3D Symbiotic space for agent-aided collaborative work","A. Sakatoku; A. Kawato; T. Osada; G. Kitagata; T. Kinoshita","Graduate School of Information Sciences, Tohoku University, Aramaki aza Aoba 6-3-09, Aoba-ku, Sendai, Miyagi, Japan; Graduate School of Information Sciences, Tohoku University, Aramaki aza Aoba 6-3-09, Aoba-ku, Sendai, Miyagi, Japan; Research Institute of Electrical Communication, Tohoku University, Katahira 2-1-1, Aoba-ku, Sendai, Miyagi, Japan; Research Institute of Electrical Communication, Tohoku University, Katahira 2-1-1, Aoba-ku, Sendai, Miyagi, Japan; Research Institute of Electrical Communication, Tohoku University, Katahira 2-1-1, Aoba-ku, Sendai, Miyagi, Japan","9th IEEE International Conference on Cognitive Informatics (ICCI'10)","11 Oct 2010","2010","","","590","595","In this paper, we propose 3D space which is based on concept of real and digital spaces symbiosis. Recently, collaborative work environments which are using Augmented Reality have been expected to realize effective collaborative works. However, these environments have some limitations. One of limitations is restricted availability of devices, and another limitation is low usability. Because of these limitations, it is difficult to utilize these environments, for general users. To break these limitations, we propose the construction scheme of 3D symbiotic space. Collaborative work environments based on 3D symbiotic space enable users to do collaborative works intuitively as if virtual spaces united with the real space. First, we present fundamental technologies for 3D symbiotic space. Next, we show the design and implementation of the agent-aided collaborative work environments based on 3D symbiotic space. Finally, we confirm feasibility of 3D symbiotic space with experimental results.","","978-1-4244-8042-5","10.1109/COGINF.2010.5599837","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5599837","","Symbiosis;Three dimensional displays;Servers;Collaborative work;Aerospace electronics;Space technology;Cameras","augmented reality;groupware;human computer interaction;software agents","3D symbiotic space;agent-aided collaborative work;augmented reality;virtual spaces","","","","10","","11 Oct 2010","","","IEEE","IEEE Conferences"
"BCI decoder performance comparison of an LSTM recurrent neural network and a Kalman filter in retrospective simulation","T. Hosman; M. Vilela; D. Milstein; J. N. Kelemen; D. M. Brandman; L. R. Hochberg; J. D. Simeral","School of Engineering and Carney Institute for Brain Science, Brown University, Providence, RI, 02912; School of Engineering and Carney Institute for Brain Science, Brown University, Providence, RI, 02912; Department of Computer Science and Carney Institute for Brain Science, Brown University; Department of Neurology, Massachusetts General Hospital (MGH), Boston, MA; School of Engineering, Brown University; Dept. of VA Med. Ctr., VA Rehabilitation R&D Center for Neurorestoration and Neurotechnology, Providence, RI; Dept. of VA Med. Ctr., VA Rehabilitation R&D Center for Neurorestoration and Neurotechnology, Providence, RI","2019 9th International IEEE/EMBS Conference on Neural Engineering (NER)","20 May 2019","2019","","","1066","1071","Intracortical brain computer interfaces (iBCIs) using linear Kalman decoders have enabled individuals with paralysis to control a computer cursor for continuous point-and-click typing on a virtual keyboard, browsing the internet, and using familiar tablet apps. However, further advances are needed to deliver iBCI-enabled cursor control approaching able-bodied performance. Motivated by recent evidence that nonlinear recurrent neural networks (RNNs) can provide higher performance iBCI cursor control in nonhuman primates (NHPs), we evaluated decoding of intended cursor velocity from human motor cortical signals using a long-short term memory (LSTM) RNN trained across multiple days of multi-electrode recordings. Running simulations with previously recorded intracortical signals from three BrainGate iBCI trial participants, we demonstrate an RNN that can substantially increase bits-per-second metric in a high-speed cursor-based target selection task as well as a challenging small-target high-accuracy task when compared to a Kalman decoder. These results indicate that RNN decoding applied to human intracortical signals could achieve substantial performance advances in continuous 2-D cursor control and motivate a real-time RNN implementation for online evaluation by individuals with tetraplegia.","1948-3554","978-1-5386-7921-0","10.1109/NER.2019.8717140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8717140","","Decoding;Task analysis;Kalman filters;Recurrent neural networks;Bit rate;Data models;Brain modeling","biomedical electrodes;brain;brain-computer interfaces;decoding;handicapped aids;human computer interaction;Kalman filters;medical signal processing;neural nets;neurocontrollers;neurophysiology;recurrent neural nets","retrospective simulation;intracortical brain computer interfaces;linear Kalman decoders;computer cursor;continuous point;virtual keyboard;familiar tablet apps;cursor control;able-bodied performance;nonlinear recurrent neural networks;higher performance;intended cursor velocity;human motor cortical signals;long-short term memory RNN;multielectrode recordings;recorded intracortical signals;BrainGate iBCI trial participants;high-speed cursor-based target selection task;challenging small-target high-accuracy task;Kalman decoder;human intracortical signals;substantial performance advances;BCI decoder performance comparison;LSTM recurrent neural network;Kalman filter","","3","","31","","20 May 2019","","","IEEE","IEEE Conferences"
"Space walking [topological manifold visualization]","A. J. Hanson; Hui Ma","Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA; Dept. of Comput. Sci., Indiana Univ., Bloomington, IN, USA","Proceedings Visualization '95","6 Aug 2002","1995","","","126","133","Proposes an interactive method for exploring topological spaces based on the natural local geometry of the space. Examples of spaces appropriate for this visualization approach occur in abundance in mathematical visualization, surface and volume visualization problems, and scientific applications such as general relativity. Our approach is based on using a controller to choose a direction in which to ""walk"" a manifold along a local geodesic path. The method automatically generates orientation changes that produce a maximal viewable region with each step of the walk. The proposed interaction framework has many natural properties to help the user develop a useful cognitive map of a space and is well-suited to haptic interfaces that may be incorporated into desktop virtual reality systems.","1070-2385","0-8186-7187-4","10.1109/VISUAL.1995.480804","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=480804","","Legged locomotion;Visualization;Space exploration;Haptic interfaces;Mice;Three dimensional displays;Two dimensional displays;Motion control;Computer science;Computational geometry","topology;virtual reality;interactive systems;data visualisation;path planning;computational geometry;differential geometry","topological manifold visualization;interactive method;local geometry;mathematical visualization;surface visualization;volume visualization;scientific applications;general relativity;controller;direction selection;local geodesic path;automatically generated orientation changes;maximal viewable region;interaction framework;cognitive map;haptic interfaces;desktop virtual reality systems","","6","","19","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Simple Gesture Distinction for Brief Message Exchange","T. Ito","Inst. of Technol. & Sci., Univ. of Tokushima, Tokushima, Japan","2010 Fourth Asia International Conference on Mathematical/Analytical Modelling and Computer Simulation","21 Jun 2010","2010","","","18","23","This paper propose an idea of simple gesture distinction, which is under study by three innovative projects, including the topics of walking stick movement recognition, hand gesture recognition and building walking model generation. First, walking stick movement recognition project is presented, which is designed for senior people to interact with computer systems by using walking stick as a gesture-based input device. Next, hand gesture recognition method project is presented, which is designed for general users to interact with ubiquitous network services without conventional WIMP interface systems. Obtaining acceleration data from spatial gesture, this paper shows how to distinct the different numbers. Then, walking model generation project is presented, which aims at recognizing walking status from sensor data and generates its corresponding walking model to show the results of recognition. This paper reviews the results of the experiments and discusses the feasibility of the interface.","2376-1172","978-1-4244-7197-3","10.1109/AMS.2010.17","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5489311","gesture interface;gesture distinction;ubiquitous network;human interface","Legged locomotion;Humans;Mathematical model;Buildings;Pervasive computing;Graphical user interfaces;User interfaces;Asia;Analytical models;Computer simulation","geriatrics;gesture recognition;handicapped aids;human computer interaction;ubiquitous computing","gesture distinction;message exchange;hand gesture recognition;walking stick movement recognition;computer system;ubiquitous network service;WIMP interface system","","","","20","","21 Jun 2010","","","IEEE","IEEE Conferences"
"Generalized Task-Parameterized Skill Learning","Y. Huang; J. Silvério; L. Rozo; D. G. Caldwell","Department of Advanced Robotics, Istituto Italiano di Tecnologia, Via Morego 30, Genoa, 16163, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Via Morego 30, Genoa, 16163, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Via Morego 30, Genoa, 16163, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Via Morego 30, Genoa, 16163, Italy","2018 IEEE International Conference on Robotics and Automation (ICRA)","13 Sep 2018","2018","","","5667","5474","Programming by demonstration has recently gained much attention due to its user-friendly and natural way to transfer human skills to robots. In order to facilitate the learning of multiple demonstrations and meanwhile generalize to new situations, a task-parameterized Gaussian mixture model (TP-GMM) has been recently developed. This model has achieved reliable performance in areas such as human-robot collaboration and dual-arm manipulation. However, the crucial task frames and associated parameters in this learning framework are often set by the human teacher, which renders three problems that have not been addressed yet: (i) task frames are treated equally, without considering their individual importance, (ii) task parameters are defined without taking into account additional task constraints, such as robot joint limits and motion smoothness, and (iii) a fixed number of task frames are pre-defined regardless of whether some of them may be redundant or even irrelevant for the task at hand. In this paper, we generalize the task-parameterized learning by addressing the aforementioned problems. Moreover, we provide a novel learning perspective which allows the robot to refine and adapt previously learned skills in a low dimensional space. Several examples are studied in both simulated and real robotic systems, showing the applicability of our approach.","2577-087X","978-1-5386-3081-5","10.1109/ICRA.2018.8461079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8461079","","Task analysis;Trajectory;Robot kinematics;Optimization;Feature extraction;Robot sensing systems","Gaussian processes;humanoid robots;human-robot interaction;learning (artificial intelligence);manipulators;mixture models;motion control;robot programming","generalized task-parameterized skill learning;human skills;task-parameterized Gaussian mixture model;TP-GMM;human-robot collaboration;dual-arm manipulation;learning framework;task parameters;robot joint limits;task-parameterized learning;learned skills;real robotic systems;task constraints;learning perspective;Programming by demonstration","","3","","18","","13 Sep 2018","","","IEEE","IEEE Conferences"
"Robust control of robots with variable joint stiffness","G. Palli; C. Melchiorri","Dipartimento di Elettronica, Informatica e Sistemistica, Università di Bologna, Via Risorgimento 2, 40136, Italy; Dipartimento di Elettronica, Informatica e Sistemistica, Università di Bologna, Via Risorgimento 2, 40136, Italy","2009 International Conference on Advanced Robotics","28 Jul 2009","2009","","","1","6","The development of safe and dependable robots for physical human-robot interaction requires both the mechanical design of lightweight and compliant manipulators and the definition of motion control laws that allow compliant behavior in reaction to possible collisions, while preserving accuracy and performance during the motion in the free space. For these motivations, great attention has been posed in the design of robots manipulators with relevant and programmable joint/transmission stiffness. A robust control strategy for a general class of multi-dof manipulators with variable joint stiffness is presented in this paper. The proposed control scheme is based on three elements: the first one compensates for the robot dynamics, the second one is based on a linear controller to impose a desired behavior, while a smooth sliding mode control action is added to ensure robustness with respect to model uncertainties. The stability of the overall system is studied by using the direct Lyapunov method. The effectiveness of the proposed approach is demonstrated by simulation analysis.","","978-1-4244-4855-5","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5174675","Robotic Manipulators;Elastic Joints;Variable Stiffness;Robust Control;Nonlinear Systems","Robust control;Sliding mode control;Orbital robotics;Manipulator dynamics;Human robot interaction;Motion control;Uncertainty;Stability;Lyapunov method;Analytical models","compensation;control system synthesis;feedback;human-robot interaction;linear systems;linearisation techniques;Lyapunov methods;manipulator dynamics;motion control;robust control;uncertain systems;variable structure systems","robust control;variable joint stiffness;safe robot;dependable robot;physical human-robot interaction;mechanical design;lightweight-compliant robot manipulator;motion control;transmission stiffness;compensation;robot dynamics;linear controller;smooth sliding mode control action;uncertain system;stability;direct Lyapunov method;feedback linearization","","4","","32","","28 Jul 2009","","","IEEE","IEEE Conferences"
"A Linear Affect–Expression Space Model and Control Points for Mascot-Type Facial Robots","H. S. Lee; J. W. Park; M. J. Chung","Korea Adv. Inst. of Sci. & Technol., Daejeon; Korea Adv. Inst. of Sci. & Technol., Daejeon; Korea Adv. Inst. of Sci. & Technol., Daejeon","IEEE Transactions on Robotics","8 Oct 2007","2007","23","5","863","873","A robot's face is its symbolic feature, and its facial expressions are the best method for interacting with people with emotional information. Moreover, a robot's facial expressions play an important role in human-robot emotional interactions. This paper proposes a general rule for the design and realization of expressions when some mascot-type facial robots are developed. Mascot-type facial robots are developed to enable friendly human feelings. The number and type of control points for six basic expressions or emotions were determined through a questionnaire. A linear affect-expression space model is provided to realize continuous and various expressions effectively, and the effects of the proposed method are shown through experiments using a simulator and an actual robot system.","1941-0468","","10.1109/TRO.2007.907477","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4339538","Affect space;emotion;facial expression;facial robot","Orbital robotics;Human robot interaction;Intelligent robots;Space technology;Emotion recognition;Face recognition;Magnetic heads;Robot control;Broadcasting","emotion recognition;human computer interaction;intelligent robots;man-machine systems","linear affect-expression space model;mascot-type facial robots;facial expressions;human-robot emotional interactions","","30","","34","","8 Oct 2007","","","IEEE","IEEE Journals"
"Physical mobile interaction with kinesthetic feedback","B. Han; S. Kim; S. Lim; D. Pyo; D. Kwon","Telerobotics and Control Laboratory, KAIST, Korea; Telerobotics and Control Laboratory, KAIST, Korea; Samsung Advanced Institute of Technology, Korea; Telerobotics and Control Laboratory, KAIST, Korea; Telerobotics and Control Laboratory, KAIST, Korea","2012 IEEE Haptics Symposium (HAPTICS)","16 Apr 2012","2012","","","571","575","As the gestural interface is emerging as one of the key interfaces for mobile computing, the ability of these interfaces to provide physical feedback is becoming more important. Especially in the context of interacting with a virtual world, generating proper feedback is more important when seeking to engage users in a simulated world. However, due to the inherent size problems of mechanical structures and due to power issues, most handheld devices relied on vibrotactile feedback. To resolve this issue, this paper proposes a haptic interface module that can represent realistic kinesthetic feedback for use with hand interfaces. Large-scale but slowly changing force is generated using a linear servomotor to provide general object information, such as the overall shape of an object. On the other hand, subtle haptic feedback generated by a solenoid-magnet pair provides the detailed surface properties of the object. To measure the performance of the proposed system, two experiments are conducted. From the experimental results, it was revealed that the proposed solenoid-magnet pair could generate about 1N of magnetic force. In terms of perception, the device can provide six levels of kinesthetic feedback. As an application, we propose depth-based interaction in which the proposed system is controlled by a depth-measuring unit.","2324-7355","978-1-4673-0809-0","10.1109/HAPTIC.2012.6183849","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6183849","Haptic interface;Haptic I/O;Kinesthetic feedback;Depth-based interaction","Haptic interfaces;Force;Solenoids;Servomotors;Force measurement;Films;Magnetic forces","haptic interfaces;mobile computing","physical mobile interaction;kinesthetic feedback;gestural interface;mobile computing;physical feedback;virtual world;mechanical structures;vibrotactile feedback;handheld devices;hand interfaces;object information;linear servomotor;solenoid magnet pair;depth measuring unit","","5","","16","","16 Apr 2012","","","IEEE","IEEE Conferences"
"Implementation of a modified state estimator for topology error identification","S. Zhong; A. Abur","Dept. of Electr. Eng., Texas A&M Univ., College Station, TX, USA; Dept. of Electr. Eng., Texas A&M Univ., College Station, TX, USA","2003 IEEE Power Engineering Society General Meeting (IEEE Cat. No.03CH37491)","15 Mar 2004","2003","2","","765","770 Vol. 2","This paper describes the implementation of a modified state estimation program and its associated user interface. The state estimator is improved by adding the capability of detecting and identifying topology errors, which are caused by the incorrect status information for the circuit breakers at the substations. The developed program is tested using a library of topology error scenarios. A user friendly interface is also implemented in order to facilitate testing of these cases. Some representative cases that are simulated, are presented along with the detailed models for the system and substations.","","0-7803-7989-6","10.1109/PES.2003.1270403","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1270403","","State estimation;Substations;Circuit breakers;Circuit topology;Power system modeling;User interfaces;Circuit testing;Power system simulation;Error correction;Power system control","power system state estimation;error detection;circuit breakers;substations;human computer interaction;user interfaces","power system state estimation;topology error identification;incorrect status information;substations circuit breakers;user friendly interface","","5","","12","","15 Mar 2004","","","IEEE","IEEE Conferences"
"Production of body model for education of dance by measurement active quantity","M. Takai","Graduate School of Science and Engineering, Tokyo Institute of Technology, Yokohama, Japan","The 1st IEEE Global Conference on Consumer Electronics 2012","13 Dec 2012","2012","","","212","216","This study makes a body model for education of dance how lively a dance trainer moves his/her body so that the dance student can learn dance from the dance trainer who is in the distant place through communication line in virtual dance studio. In late years, network game gives the virtual space enjoying sports, music, and dance to plural people who are in the remote place at the same time. However, the general network game has to attach sensors or devices to the body of the players to input livingness by the movement of them. Therefore, not only they feel botheration in the player attaching sensors or devices, but also it is necessary to spend labor and time to attach sensors or devices to the body. This study proposes Active Quantity to measure with quantity from 0.0 to 1.0 from a dynamic image which photographed the movement of the dance trainer in digital video camera. Furthermore, the proposal method makes the body model that put the silhouette of the dance trainer and Active Quantity together so that the dance students are easy to understand the movement of the dance trainer from sight.","2378-8143","978-1-4673-1501-2","10.1109/GCCE.2012.6379584","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6379584","human action;body model;camera;virtual;dance","Proposals;Foot;Brightness;Legged locomotion;Sensors;Hidden Markov models;Games","computer aided instruction;computer games;human computer interaction;humanities;image sensors;music;sport;user interfaces;virtual reality","body model production;dance education;measurement active quantity;communication line;virtual dance studio;network game;virtual space;digital video camera;sports;music","","1","","6","","13 Dec 2012","","","IEEE","IEEE Conferences"
"Preliminary Study on Gesture Recognition for Walking-Stick Interface","T. Ito","Inst. of Technol. & Sci., Univ. of Tokushima, Tokushima, Japan","2010 International Conference on Intelligent Systems, Modelling and Simulation","18 Feb 2010","2010","","","65","70","This paper proposes a walking stick-based human interface for senior people towards ubiquitous society. This study focuses on the gesture interaction, which could be performed by the senior people as a means of input signal using the stick-based interface system without any prior knowledge or practice. Using the prototype system of the stick-based human interface developed in this study, gesture recognition experiments were conducted to see if the gesture could be understood in the proposed method in this study. The test results show that the gesture could be recognized in a high performance in certain conditions, which could be carried out under general restrictions of use. This paper reviews the results of the experiments and discusses the feasibility of the interface.","2166-0670","978-1-4244-5985-8","10.1109/ISMS.2010.23","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5416119","gesture recognition;ubiquitous network;human interface","Humans;Prototypes;Legged locomotion;Mobile handsets;Intelligent systems;Indium tin oxide;Testing;Atherosclerosis;Portable computers;Electronic mail","gesture recognition;human computer interaction;ubiquitous computing","gesture recognition;walking stick-based human interface system;ubiquitous network","","2","","21","","18 Feb 2010","","","IEEE","IEEE Conferences"
"A Sentiment Analysis Study on Recognition of Facial Expressions: Gauss and Canny Methods","A. Sevinç; B. Kaya; A. Geçmez","Fırat University,dept. Technology and Information Management,Elazığ,Turkey; Furat University,dept. Electronics and Automation,Elazig,Turkey; Firat University,dept. Electrical and Electronics Engineering,Elazig,Turkey","2020 International Conference on Decision Aid Sciences and Application (DASA)","15 Jan 2021","2020","","","1041","1046","Human-computer interaction has been the focus of today's current researches. Human-computer interaction is accepted as a multidisciplinary field that takes place through interfaces. These interfaces can sometimes be software functions, or sometimes they can be interact provided with hardware components. Facial expressions give information about people's emotions play an important role in sentiment recognition. Today, facial expressions are used in many fields such as education, psychological studies, virtual reality, robotics, facial animation, health and law, and the need for analysis of facial expressions in many areas is increasing. In addition, the analysis of human facial expressions with computers is a remarkable research area, but it is considered a challenging problem. In this context, it is necessary to analyze facial expressions accurately and quickly by software. In this study, sentiment recognition from facial expressions (sad, happy, scared, confused) was performed using 50 different images obtained from various databases and internet sources. With digital image processing techniques, improved images can be obtained and feature extraction can be made. In this research, digital image processing functions and MATLAB programming language of MATLAB 2018 program, which provides advanced programming for scientific studies, were used. Image noise was removed with the Gauss filter, and edge detection operations were performed with the Canny method. Geometric ratios were used to eliminate errors. As a result of the study, it was determined that sentiment recognition procedures performed on images with similar facial expressions made incorrect sentiment classification. However, it has been observed that face recognition with MATLAB functions and MATLAB programming has generally produced successful results.","","978-1-7281-9677-0","10.1109/DASA51403.2020.9317234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9317234","Face expression recognition;Sentiment analysis;Image processing;Gauss and Canny method","Face recognition;Sentiment analysis;Matlab;Image edge detection;Emotion recognition;Robots;Maximum likelihood detection","computer animation;edge detection;emotion recognition;face recognition;feature extraction;human computer interaction;image denoising;Matlab;sentiment analysis;virtual reality","sentiment analysis;human-computer interaction;sentiment recognition;law;human facial expressions;software functions;digital image processing;Matlab programming language;image noise;Gauss filter;edge detection;Canny method","","","","25","","15 Jan 2021","","","IEEE","IEEE Conferences"
"Studying Navigation as a Form of Interaction: a Design Approach for Social Robot Navigation Methods*","P. Scales; O. Aycard; V. Aubergé","Univ. Grenoble Alpes,CNRS,Grenoble,France,38000; Univ. Grenoble Alpes,CNRS,Grenoble,France,38000; Univ. Grenoble Alpes,CNRS,Grenoble,France,38000","2020 IEEE International Conference on Robotics and Automation (ICRA)","15 Sep 2020","2020","","","6965","6972","Social Navigation methods attempt to integrate knowledge from Human Sciences fields such as the notion of Proxemics into mobile robot navigation. They are often evaluated in simulations, or lab conditions with informed participants, and studies of the impact of the robot behavior on humans are rare. Humans communicate and interact through many vectors, among which are motion and positioning, which can be related to social hierarchy and the socio-physical context. If a robot is to be deployed among humans, the methods it uses should be designed with this in mind. This work acts as the first step in an ongoing project in which we explore how to design navigation methods for mobile robots destined to be deployed among humans. We aim to consider navigation as more than just a functionality of the robot, and to study the impact of robot motion on humans. In this paper, we focus on the person-following task. We selected a state of the art person-following method as the basis for our method, which we modified and extended in order for it to be more general and adaptable. We conducted pilot experiments using this method on a real mobile robot in ecological contexts. We used results from the experiments to study the Human-Robot Interaction as a whole by analysing both the person-following method and the human behavior. Our preliminary results show that the way in which the robot followed a person had an impact on the interaction that emerged between them.","2577-087X","978-1-7281-7395-5","10.1109/ICRA40945.2020.9197037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197037","","Navigation;Biological system modeling;Robot sensing systems;Mobile robots;Design methodology;Task analysis","human-robot interaction;mobile robots;motion control;navigation","social robot navigation methods;social navigation methods;human sciences fields;mobile robot navigation;robot behavior;social hierarchy;socio-physical context;robot motion;human-robot interaction;human behavior","","1","","39","","15 Sep 2020","","","IEEE","IEEE Conferences"
"Memetic Evolution for Generic Full-Body Inverse Kinematics in Robotics and Animation","S. Starke; N. Hendrich; J. Zhang","School of Informatics, University of Edinburgh, Edinburgh, U.K.; Faculty of Mathematics Computer Science and Natural Sciences, TAMS Group, University of Hamburg, Hamburg, Germany; Faculty of Mathematics Computer Science and Natural Sciences, TAMS Group, University of Hamburg, Hamburg, Germany","IEEE Transactions on Evolutionary Computation","29 May 2019","2019","23","3","406","420","In this paper, a novel and fast memetic evolutionary algorithm is presented which can solve fully constrained generic inverse kinematics with multiple end effectors and goal objectives, leaving high flexibility for the design of custom cost functions. The algorithm utilizes a hybridization of evolutionary and swarm optimization, combined with the limited-memory-Broyden-Fletcher-Goldfarb-Shanno with bound constraints algorithm for gradient-based optimization. Accurate solutions can be found in real-time and suboptimal extrema are robustly avoided, scaling well even for greatly higher degree of freedom. The algorithm provides a general framework for bounded continuous optimization which only requires two parameters for the number of individuals and elites to be set, and supports adding additional goals and constraints for inverse kinematics, such as minimal displacement between solutions, collision avoidance, or functional joint relations. Experimental results on several industrial and anthropomorphic robots as well as on virtual characters demonstrate the algorithm to be applicable for solving complex kinematic postures for different challenging tasks in robotics, human-robot interaction and character animation, including dexterous object manipulation, collision-free full-body motion, as well as animation post-processing for video games and films. Implementations are made available for Unity3D and robot operating system.","1941-0026","","10.1109/TEVC.2018.2867601","German Research Foundation (DFG); National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8449979","Artificial intelligence;character animation;collision avoidance;evolutionary computation;full-body motion;inverse kinematics;optimization;robotics","Kinematics;Geometry;End effectors;Optimization;Animation;Collision avoidance","collision avoidance;computer animation;dexterous manipulators;end effectors;evolutionary computation;gradient methods;human-robot interaction;manipulator kinematics;mobile robots;particle swarm optimisation;path planning;search problems;virtual reality","robotics;human-robot interaction;character animation;dexterous object manipulation;collision-free full-body motion;robot operating system;generic full-body inverse kinematics;multiple end effectors;high flexibility;custom cost functions;evolutionary optimization;swarm optimization;gradient-based optimization;suboptimal extrema;bounded continuous optimization;collision avoidance;functional joint relations;industrial robots;anthropomorphic robots;complex kinematic postures;memetic evolutionary algorithm;limited-memory-Broyden-Fletcher-Goldfarb-Shanno bound constraints algorithm;virtual characters;animation post-processing video games","","3","","46","","29 Aug 2018","","","IEEE","IEEE Journals"
"Development of a virtual coach scenario for hand therapy using LEAP motion","M. Sourial; A. Elnaggar; D. Reichardt","Faculty of Computer Science and Engineering, German University in Cairo; Intelligent Interaction Lab, DHBW Stuttgart; Intelligent Interaction Lab, DHBW Stuttgart","2016 Future Technologies Conference (FTC)","19 Jan 2017","2016","","","1071","1078","Hand therapy is the art that fills the gap between surgery and practical life. It helps the patient to regain the hands full functionality after a certain injury or surgery. Hand therapy could be a very tedious process that implies physical exhaustion. Also finding appointments with the therapist frequent enough for an efficient healing process, is difficult and costly. Since trying new technologies is usually exciting to people, using the advancements in the field of artificial intelligence could be a solution to this. A virtual therapist (VT) was implemented to help the patient do his exercises at home in an engaging gamified environment. The VT artificial intelligence used hierarchical finite state machine architecture. This VT can explain the exercise, monitor the patient, correct error and assess the performance of the patient during the exercise. To test the efficiency of the VT, a web hand therapy exercise was implemented using Unity platform to build the exercise environment. LEAP motion technology was used to detect the information of the hand movement. The exercise was chosen to be run on the web to enable its access to the user from home and allow the therapist to have access to the data of the patient. Facial expression detection was used to keep track of the patients' facial expression to detect whenever he feels pain. At the end of the exercise, a general feedback is given to the patient to keep track of his progress. This exercise was tested with 19 persons. The idea of being coached by a VT was very welcomed by the test subjects. The exercise was fun and motivating to them. The VT guidance and assessment were very helpful and easy to follow. However, some modifications are needed in the pain detection part to form a more efficient exercise.","","978-1-5090-4171-8","10.1109/FTC.2016.7821736","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7821736","Hand Therapy;Virtual Coaching;LEAP Motion;Artificial Intelligence","Medical treatment;Pain;Monitoring;Hardware;Mouth;Artificial intelligence;Software","computer vision;face recognition;finite state machines;gesture recognition;Internet;patient treatment;virtual reality","virtual coach scenario development;patient injury;patient surgery;virtual therapist;VT artificial intelligence;gamified environment;hierarchical finite state machine architecture;patient monitoring;error correction;exercise performance assessment;Web hand therapy;Unity platform;exercise environment;LEAP motion technology;hand movement detection;facial expression detection;pain detection part","","5","","22","","19 Jan 2017","","","IEEE","IEEE Conferences"
"Hybrid method for human eye detection","D. Zhu; S. Xia; X. Zhou; J. Zheng","Key Laboratory of Measurement and Control of CSE, Ministry of Education, School of Automation, Southeast University, Jiangsu, 210096, China; Key Laboratory of Measurement and Control of CSE, Ministry of Education, School of Automation, Southeast University, Jiangsu, 210096, China; Key Laboratory of Measurement and Control of CSE, Ministry of Education, School of Automation, Southeast University, Jiangsu, 210096, China; Key Laboratory of Measurement and Control of CSE, Ministry of Education, School of Automation, Southeast University, Jiangsu, 210096, China","The 26th Chinese Control and Decision Conference (2014 CCDC)","14 Jul 2014","2014","","","5368","5373","Eye detection is required in many applications in human-computer interaction, which plays an important role in screen control, user recognition and auto-stereoscopic displays. Considering the defects of traditional methods of human-eye detection, an accurate human-eye-detection algorithm has been proposed. This paper proposes a novel technique combining the Adaboost algorithm and a hybrid matching method. First, facial part in the whole image is located with Adaboost algorithm; the human-eye area is positioned through the hybrid feature extraction method. In extraction process, edge density, chrominance, HSV and skin color cues are applied separately. Some of the regions are then removed by applying rules that are based on the general geometry and shape of eyes. The remaining connected regions obtained through these four cues are then combined in a systematic way to enhance the identification of the candidate regions for the eyes. The proposed eye-detection algorithm effectively reduces the eye-detection candidate area and improves the detection accuracy.","1948-9447","978-1-4799-3708-0","10.1109/CCDC.2014.6852223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6852223","Human-computer interaction;eye detection;hybrid method","Image color analysis;Face;Image edge detection;Skin;Accuracy;Lighting;Feature extraction","eye;face recognition;human computer interaction;image colour analysis;image matching;learning (artificial intelligence);object detection;stereo image processing","human eye detection;human-computer interaction;screen control;user recognition;auto-stereoscopic displays;Adaboost algorithm;hybrid matching method;facial part;edge density;chrominance;HSV;skin color cues","","1","","34","","14 Jul 2014","","","IEEE","IEEE Conferences"
"Human motor performance while using a single-DOF visual-haptic interface","C. M. Hendrix; W. K. Durfee","Dept. of Mech. Eng., Minnesota Univ., Minneapolis, MN, USA; Dept. of Mech. Eng., Minnesota Univ., Minneapolis, MN, USA","11th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, 2003. HAPTICS 2003. Proceedings.","2 Apr 2003","2003","","","70","76","Applications of haptic displays in Human Computer Interfaces (HCI) are partly limited by the lack of generalizable guidelines and principles directing their implementation. The purpose of this research was to examine human visuo-motor behavior when visual and haptic feedback displays are integrated. A Fitts' Law paradigm involving a target acquisition task was used. Performance measures included movement time to complete the task as well as movement kinematics and kinetics. The variables manipulated included two target widths, two target amplitudes, and six haptic emulations. Damping forces over target areas result in the best performance. Spring forces over target areas resulted in the worse overall performance. Haptic emulations were found to be most effective as the Index of Difficulty increased. Motor planning changed as a function of the haptic emulation used. The implication of these findings is that the effectiveness of the HCI design is greatly influenced by haptics.","","0-7695-1890-7","10.1109/HAPTIC.2003.1191234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1191234","","Haptic interfaces;Emulation;Computer displays;Human computer interaction;Application software;Computer interfaces;Guidelines;Feedback;Motion measurement;Time measurement","haptic interfaces;user interfaces;performance evaluation","Human Computer Interfaces;haptic displays;human visuo-motor behavior;performance measures;HCI design;haptics","","2","","22","","2 Apr 2003","","","IEEE","IEEE Conferences"
"DCA: An Approach for Face Recognition through Component Analysis","P. Shamna; C. Tripti; P. Augustine","Dept. of Comput. Sci., Rajagiri Sch. of Eng. & Technol., Kochi, India; Dept. of Comput. Sci., Rajagiri Sch. of Eng. & Technol., Kochi, India; Dept. of Comput. Sci., Rajagiri Sch. of Eng. & Technol., Kochi, India","2013 Third International Conference on Advances in Computing and Communications","19 Dec 2013","2013","","","34","38","The developments in digital technologies is enhancing the communication between computers and Human. Face recognition is a vital technique that helps to develops user-friendly methods for Human Computer Interaction (HCI). In this paper we suggest a pattern recognition method using Difference Component Analysis (DCA) and present its application in face recognition. The DCA removes all the general features of images and compute the difference components of the images. The DCA is based on the principle that two similar images will have least difference components. Simulation of DCA is done by using Yale face database and AT&T face database. The experimental results indicate that, the presented approach is remarkably effective in recognizing faces under different conditions.","","978-0-7695-5033-6","10.1109/ICACC.2013.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6686332","Face Recognition;PCA;Difference Component Analysis(DCA);Image Processing;Pattern Recognition","Face;Face recognition;Databases;Training;Image recognition;Principal component analysis","face recognition;feature extraction;human computer interaction;principal component analysis","digital technologies;face recognition;user-friendly methods;human computer interaction;HCI;pattern recognition method;difference component analysis;DCA;image general features;Yale face database;AT&T face database","","","","12","","19 Dec 2013","","","IEEE","IEEE Conferences"
"The Role of the Experimenter in HRI Research - A Case Study Evaluation of Children with Autism Interacting with a Robotic Toy","B. Robins; K. Dautenhahn","Adaptive Systems Research Group, School of Computer Science, University of Hertfordshire, Hatfield, Herts AL10 9AB, U.K (Phone: +44(0)1707281150; Fax: +44 (0)1707 284185; e-mail: b.robins@herts.ac.uk); Adaptive Systems Research Group, School of Computer Science, University of Hertfordshire, Hatfield, Herts AL10 9AB, U.K (Phone: +44(0)1707281150; Fax: +44 (0)1707 284185; e-mail: k.dautenhahn@herts.ac.uk)","ROMAN 2006 - The 15th IEEE International Symposium on Robot and Human Interactive Communication","26 Feb 2007","2006","","","646","651","The general context of the work presented in this paper is assistive robotics with our long-term aim to support children with autism. This paper is part of an investigation into what ways and to what extent a robot can assume the role of a social mediator - encouraging autistic children to interact with the robot, with each other and with co-present adults. The article focuses on the role of the experimenter in these triadic interactions, and provides a case study evaluation of segments of trials where a robot mediated both indirect and direct interactions between children with autism and the experimenter","1944-9437","1-4244-0564-5","10.1109/ROMAN.2006.314473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4107881","","Autism;Educational robots;Human robot interaction;Instruments;Pediatrics;Virtual environment;Educational technology;Medical treatment;Computer science education","diseases;human computer interaction;human factors;humanoid robots;paediatrics;social sciences","experimenter;HRI research;autism;robotic toy;assistive robotics;social mediator;autistic children","","30","","14","","26 Feb 2007","","","IEEE","IEEE Conferences"
"The cone of gaze","H. Hecht; R. Weiland; E. Boyarskaya","Johannes Gutenberg-Universität, Mainz, Germany; Johannes Gutenberg-Universität, Mainz, Germany; Johannes Gutenberg-Universität, Mainz, Germany","2011 4th International Conference on Human System Interactions, HSI 2011","4 Jul 2011","2011","","","378","385","Gaze direction is an important cue that regulates social interactions. Although humans are very accurate in determining gaze directions in general, they have a surprisingly liberal criterion for the presence of mutual gaze. We first established a psychophysical task to measure the cone of gaze, which required observers to adjust the eyes of a virtual head to the margins of the area of mutual gaze. Then we examined differences between 2D, 3D, and genuine real life gaze. Finally, the tolerance for image distortions when the virtual head is not viewed from the proper vantage point was investigated. Gaze direction was remarkably robust toward loss in detail and distortion. Important lessons for the design of eye-contact in virtual environments can be derived from these findings.","2158-2254","978-1-4244-9638-9","10.1109/HSI.2011.5937396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5937396","gaze;perception;realism;social pressure","Observers;Three dimensional displays;Humans;Rendering (computer graphics);Analysis of variance;Robustness;Visualization","rendering (computer graphics);virtual reality","gaze cone;gaze direction;social interactions;psychophysical task;virtual head;mutual gaze;eye-contact","","","","24","","4 Jul 2011","","","IEEE","IEEE Conferences"
"A reverse engineering approach to teach biology students mathematical complexity in ecology: Interdisciplinary teaching connects mathematical literacy and outdoor practice","P. Silapachote; A. Srisuphab; S. Srikosamatara","Faculty of Information and Communication Technology, Mahidol University, Nakhon Pathom, Thailand; Faculty of Information and Communication Technology, Mahidol University, Nakhon Pathom, Thailand; Faculty of Science, Mahidol University, Bangkok, Thailand","2014 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)","19 Mar 2015","2014","","","141","147","Mathematics has long held a prominent spot in common core competencies. Rapid advances in information and communication technology literacy have gained it recognition as an essential skill in the 21st century. Mastering both is a challenge, as is teaching them. Integration with other disciplines, addressing STEM education, makes this even more challenging. Tackling this dilemma, we adapt cooperative learning and co-teaching schemes. Hands-on class activities effectively convey an understanding of a complex model without equations. Computer simulations promote visual comprehensions for highly dynamic systems. In our course, general ecology for biologists, mathematical complexity is a crucial element required for transitioning from the real world to the world of numbers pertaining both linear and non-linear relationships. We designed indoor activities to initiate analytical thinking and to extend appreciations of outdoor experiences to abstract reasoning in numerical terms and computer models. Our approach fulfills the objectives of guiding biology students to construct scenarios reflecting complex interactions among organisms in the natural world. They overcame their primarily negative mindset, feeling intimidated by mathematics and uncomfortably unfamiliar with computer technology. To evaluate our teaching method, students were asked to qualitatively write an after action evaluation. They expressed enjoyment in their learning. Though struggling at times, the experience was very rewarding and worthwhile. Students came to a realization of the importance of mathematics and information literacy skills, while drawing appreciation and awareness from outdoor experiences. Besides, we quantitatively analyzed students' performance, which effectively serves as a guideline for adjusting our course contents for the next offering of this subject.","","978-1-4799-7672-0","10.1109/TALE.2014.7062605","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7062605","interdisciplinary co-teaching;active and cooperative learning;mathematical literacy;computer simulations","Decision support systems;Handheld computers;Education;Conferences;Sociology;Statistics;Estimation","biology computing;computer aided instruction;digital simulation;ecology;educational courses;information science education;reverse engineering;STEM;teaching","reverse engineering approach;biology student;mathematical complexity;interdisciplinary teaching;mathematical literacy;outdoor practice;information and communication technology literacy;STEM education;cooperative learning;co-teaching schemes;hands-on class activities;computer simulations;visual comprehensions;course;general ecology;indoor activities;analytical thinking;numerical terms;computer models;information literacy skills","","","","9","","19 Mar 2015","","","IEEE","IEEE Conferences"
"Webcam Based Eye Gaze Prediction System with Automatic Calibration for Web Browser","N. Karngumpol; W. Kreesuradej","King Mongkut’s Institute of Technology Ladkrabang,Faculty of Information Technology,Bangkok,Thailand; King Mongkut’s Institute of Technology Ladkrabang,Faculty of Information Technology,Bangkok,Thailand","2019 16th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)","13 Jan 2020","2019","","","109","112","Now a day, researches about Eye Gaze Prediction Systems with General Webcam was interested by many researchers and has been continuously developed because it is cheap and can be applied in many ways. Currently, a Browser based open source library for eye gaze prediction has been developed, which is easy to use and can be developed in a variety fields. However, this method is still limited because of low precision and inconveniences because users must perform calibration every time before use it. Therefore, we propose ways to develop and solve the above problems. This research has two objectives. The first is to improve the accuracy of an existing Eye Gaze Prediction System. The solution is using the Simple Moving Average to reduce the volatile of results and increase accuracy. From a results, this method gives a test scores higher than the existing method with statistically significant at 0.01, calculated as 14.96 percent increase from average score of the old method. The second objective is to propose a solution for making the system can recalibrate itself to improve accuracy in a long time without having to perform calibration by the users. We record the gaze data from system in the first 1 minute and then take the recorded data to calculate the boundary of the screen. And then, compare the calculated boundary with the real screen boundary to find error factors. This calculated error factor has been applied back to the next result to increase accuracy. From the test results, we found that over time the average test scores gradually increase. And at the last minute, the average score from this method is higher than the average score from traditional method up to 13.66 percent.","","978-1-7281-3361-4","10.1109/ECTI-CON47248.2019.8955149","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8955149","eye gaze prediction;moving avarage;eye tracking;SMA;self-calibration","","calibration;eye;gaze tracking;human computer interaction;Internet;moving average processes;online front-ends","automatic calibration;Web browser;General Webcam;Eye Gaze Prediction System;open source library;simple moving average","","","","12","","13 Jan 2020","","","IEEE","IEEE Conferences"
"Stereo imaging using a camera with stereoscopic adapter","Woontack Woo; Namgyu Kim; Y. Iwadate","ATR MIC Labs., Kyoto, Japan; NA; NA","Smc 2000 conference proceedings. 2000 ieee international conference on systems, man and cybernetics. 'cybernetics evolving to systems, humans, organizations, and their complex interactions' (cat. no.0","6 Aug 2002","2000","2","","1512","1517 vol.2","The authors analyze the characteristics of the stereoscopic adapter, which is a cost-effective way to generate stereo video sequences with a camera. We also propose an efficient way to compensate for the inherent distortions. In general, stereo sequences can be captured using a pair of cameras but the resulting sequences tend to yield various well-known problems due to different characteristics of the pair of stereo cameras. Meanwhile, a camera with the stereoscopic adapter provides a natural way to capture and display stereoscopic video. It allows users to access all the functions built into the camera, e.g. zoom, auto-focus, auto-exposure, special effects, etc. The cost however is the reduced quality of the videos since the adapter allows capture of stereo video sequences in the field sequential format, i.e. left and right images in different scan lines, respectively. In addition, it generates size and color distortions due to the physical configuration of the mirror in the adapter. We analyze and compensate for such distortions to reduce possible errors in vision applications exploiting the stereo images. According to our preliminary study, the adapter with the proposed compensation scheme will pave the way for various low cost image based virtual reality applications at hand.","1062-922X","0-7803-6583-6","10.1109/ICSMC.2000.886069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=886069","","Cameras;Video sequences;Three dimensional displays;Costs;Mirrors;Image analysis;Calibration;Layout;Microwave integrated circuits;Image sequence analysis","stereo image processing;video cameras;image sequences;video signal processing;virtual reality","stereo imaging;stereoscopic adapter;stereo video sequences;stereo sequences;stereo cameras;stereoscopic video;zoom;auto-focus;auto-exposure;special effects;field sequential format;scan lines;physical configuration;vision applications;compensation scheme;low cost image based virtual reality applications","","4","1","12","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Virtual Remote Electronic Laboratory","A. A. Siddiqui; M. Y. I. Zia; M. Aamir; S. E. Haque",NA; NA; NA; NA,"IEEE Students Conference, ISCON '02. Proceedings.","28 Jul 2003","2002","1","","94","98 vol.1","In this paper the development of a Virtual Remote Electronic Laboratory and its implementation using National Instrument's LabVIEW is discussed. The techniques presented in this paper are general purpose and can be used to develop any laboratory that requires simulation, hands-on experience, and the ability to run the laboratory over a network of computers. As a case study a digital signal processing course taught in the Department of Electronic Engineering at Sir Syed University of Engineering and Technology is selected. The practical implementation of this laboratory using LabVIEW is also discussed in this paper. The main advantage of this laboratory is that the students can perform the experiments of different subjects remotely through the Internet. Engineering education has always been dynamically interrelated with technology change. Educators and researchers worldwide are using National Instrument's products to automate routine tasks, accomplish new objectives, replace outdated and expensive equipment, and demonstrate students the potential of high technology. Physical systems are modeled and manipulated in software, and realized in hardware to demonstrate what differences may occur with real-life applications. By solving problems using software-based virtual instruments and actual hardware, students gain an appreciation of the interaction of process instrumentation and computers.","","0-7803-7505-X","10.1109/ISCON.2002.1215946","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1215946","","Laboratories;Instruments;Hardware;Computational modeling;Computer simulation;Computer networks;Digital signal processing;Internet;Engineering education;Educational technology","signal processing;electronic engineering education;simulation;Internet;educational courses;computer aided instruction;distance learning","Virtual Remote Electronic Laboratory;National Instrument LabVIEW;simulation;hands-on experience;computer network;digital signal processing course;Department of Electronic Engineering;Sir Syed University of Engineering and Technology;Internet;remote experiments;engineering education;physical system modeling;software-based virtual instruments;hardware realization;process instrumentation","","5","","5","","28 Jul 2003","","","IEEE","IEEE Conferences"
"A Design Framework and Its Applications for Tangible Panel Display","H. Nishino; R. Goto; T. Kagawa; K. Utsumiya","Dept. of Comput. Sci. & Intell. Syst., Oita Univ., Oita, Japan; Grad. Sch. of Eng., Oita Univ., Oita, Japan; Dept. of Comput. Sci. & Intell. Syst., Oita Univ., Oita, Japan; Dept. of Comput. Sci. & Intell. Syst., Oita Univ., Oita, Japan","2010 13th International Conference on Network-Based Information Systems","15 Nov 2010","2010","","","147","154","Various information displays are becoming available for implementing new kinds of human computer interaction (HCI) methods. Among many types and models, touch panel displays have been used in wide range of applications and are proven to be a useful infrastructure for creating intuitive HCI. In spite of their popularity, there are some weak points. The most serious drawback is their hardness to operate especially for the weak in information technology such as elderly and blind users. A tactile feedback function has a potential ability for enabling them to make full use of the devices. We propose an approach for effectively designing user-friendly HCI based on the tactile feedback. We exemplify our approach through the design and development of a few practical applications, an electronic voting system and a disaster information exploration system. The applications are targeted at supporting the weak, but the touch interactions quite are useful for general public for improving the stability and the degree of satisfaction in operations. These systems use a touch panel haptic display for helping the users to operate with straightforward touch sensations. It allows them to easily confirm, select, and activate their desired functions. We also conducted some evaluations to verify the effectiveness of the proposed framework.","2157-0426","978-1-4244-8053-1","10.1109/NBiS.2010.69","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5635893","touch panel display;tactile feedback;haptization;graphical user interface;assistive information technology","Tactile sensors;Graphical user interfaces;Electronic voting systems;Vibrations;Mobile communication;Force feedback","disasters;haptic interfaces;human computer interaction;touch sensitive screens","design framework;tangible panel display;information displays;human computer interaction methods;touch panel haptic displays;information technology;tactile feedback function;electronic voting system;disaster information exploration system","","2","","18","","15 Nov 2010","","","IEEE","IEEE Conferences"
"K-HapticModelerTM: a haptic modeling scope and basic framework","Y. Seo; B. Lee; Y. Kim; J. Kim; J. Ryu","Human-Machine-Computer Interface Lab, Gwangju Institute of Science and Technology, KOREA, E-mail: seoyw@gist.ac.kr; Human-Machine-Computer Interface Lab, Gwangju Institute of Science and Technology, KOREA, E-mail: bclee@gist.ac.kr; Human-Machine-Computer Interface Lab, Gwangju Institute of Science and Technology, KOREA, E-mail: kym@gist.ac.kr; Human-Machine-Computer Interface Lab, Gwangju Institute of Science and Technology, KOREA, E-mail: lowtar@gist.ac.kr; Human-Machine-Computer Interface Lab, Gwangju Institute of Science and Technology, KOREA, E-mail: ryu@gist.ac.kr","2007 IEEE International Workshop on Haptic, Audio and Visual Environments and Games","29 Oct 2007","2007","","","136","141","Haptics has been studied as a means of providing users with a natural and immersive tactile sensation in real, augmented, and virtual environments in the various areas. However, in spite of the considerable advantages offered by haptic technology, it is still relatively unfamiliar to the general public. One of reasons for this unfamiliarity is the lack of abundant haptic interaction contents, especially in areas that are very close to the general public. Even though there are a few modeling tools for creating haptic contents, addition of haptic data to graphic models or scenes is limited and many haptic modeling processes have to be done mostly manually, which is time consuming and is not intuitive. For this reason, a new, intuitive, comprehensive, and efficient haptic modeling system is needed. This paper tries to define haptic modeling processes and its scopes and proposes a basic framework for a haptic modeling system (K-HapticModelerTM) that can create and edit haptic contents easily and intuitively for any virtual objects or graphic scenes.","","978-1-4244-1570-0","10.1109/HAVE.2007.4371602","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4371602","haptics;haptic modeling;Haptic User Interface (HUI)","Haptic interfaces;Layout;Solid modeling;Painting;Computer graphics;User interfaces;Material properties;Friction;Conferences;Virtual environment","haptic interfaces;virtual reality","K-haptic modeler;haptic modeling scope;immersive tactile sensation;virtual environments;abundant haptic interaction contents;graphic models;virtual objects","","2","1","17","","29 Oct 2007","","","IEEE","IEEE Conferences"
"The applicability of the visual programming language LabVIEW to large real-world applications","R. Jamal; L. Wenzel","Dept. of Applications Eng., Nat. Instrum. Germany GmbH, Munchen, Germany; Dept. of Applications Eng., Nat. Instrum. Germany GmbH, Munchen, Germany","Proceedings of Symposium on Visual Languages","6 Aug 2002","1995","","","99","106","Graphical programming languages allow a natural, intuitive man-machine interaction. As a result, graphical programming has gained much popularity over the past several years, primarily because many scientists and engineers have experienced improvements in programming efficiency due to the natural understandability of graphical programming tools. In general, however, there is a perception that the graphical paradigm does not lend itself well to large-scale applications. The paper examines the suitability of graphical programming languages to real-world applications. The specific graphical programming language evaluated in this paper is LabVIEW, though some of the concepts discussed apply to other visual programming languages as well. A relatively large case study involving simulation as well as real-time acquisition programmed in LabVIEW is investigated. Advantages and limitations of LabVIEW for such applications are discussed.","1049-2615","0-8186-7045-2","10.1109/VL.1995.520791","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=520791","","Computer languages;Instruments;Laboratories;Automation;Man machine systems;Humans;Design engineering;Prototypes;Large-scale systems;Usability","visual programming;visual languages;digital simulation;real-time systems;simulation;software tools;automatic testing;ultrasonic materials testing;data acquisition;data analysis;programming environments;user interfaces;laboratory techniques","LabVIEW visual programming language;large real-world applications;graphical programming languages;natural intuitive man-machine interaction;graphical programming;graphical programming tools;programming efficiency;simulation;real-time acquisition","","16","6","19","","6 Aug 2002","","","IEEE","IEEE Conferences"
"Putting Haptics into the Ambience","K. E. MacLean","University of British Columbia, Vancouver","IEEE Transactions on Haptics","28 Aug 2009","2009","2","3","123","135","In an attentionally overloaded world, relief will come only from interfaces between humans and computation that are able to provide information in the background of our sensory and cognitive processes. Haptic displays may have a special role to play in this emerging movement toward ambient interfaces, because the touch sense is well suited to present many types of information in a way that treads lightly on our mental resources. This paper offers an introduction to the notion of ambient information display, and explores why and how the haptic channel could contribute. It begins with a discussion of the attentional problems posed by contemporary interface technology, and a broad overview of ambient interfaces themselves: their purpose, specification, features, and some general examples. Sense is made of the haptic ambient design space through a morphology of the functionality and social configurations exhibited by existing and envisioned examples. Finally, reflections on design principles and challenges for ambient haptic interfaces are aimed at inspiring, shaping, and informing future development in this area.","2329-4051","","10.1109/TOH.2009.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5184837","Haptic I/O;human computer interaction (HCI);human information processing;ambient interfaces.","Haptic interfaces;Displays;Space technology;Human computer interaction;Cellular phones;Writing;Computer interfaces;Morphology;Optical reflection;Information processing","haptic interfaces;touch sensitive screens","haptic interfaces;haptic displays;ambient interfaces;haptic channel","","31","","100","","31 Jul 2009","","","IEEE","IEEE Journals"
"Teleoperation of Multiple Social Robots","D. F. Glas; T. Kanda; H. Ishiguro; N. Hagita","Intelligent Robotics and Communication Laboratories, ATR (Advanced Telecommunications Research Institute International), Kyoto, Japan; Intelligent Robotics and Communication Laboratories, ATR (Advanced Telecommunications Research Institute International), Kyoto, Japan; Intelligent Robotics Laboratory, Graduate School of Engineering Science, Osaka University , Osaka, Japan; Intelligent Robotics and Communication Laboratories, ATR (Advanced Telecommunications Research Institute International), Kyoto, Japan","IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans","16 Apr 2012","2012","42","3","530","544","Teleoperation of multiple robots by a single operator has been studied extensively for applications such as search and navigation; however, this concept has never been applied to the field of social, conversational robots. In this paper, we explore the unique challenges posed by the remote operation of multiple social robots, where an operator must perform auditory multitasking to assist multiple interactions at once. It describes the general system requirements in four areas: social human-robot interaction (HRI) design, autonomy design, multirobot coordination, and teleoperation interface design. Based on this design framework, we have developed a system in which a single operator can simultaneously control four robots in conversational interactions with users. Key elements of our implementation include a control architecture enabling the scripting of conditional behavior flows for social interaction, a graphical interface enabling an operator to control one robot at a time while monitoring several others in the background, and a technique called “proactive timing control,” which is an automated method for smoothly interleaving the demands of multiple robots for the operator's attention. We also present metrics for describing and predicting robot performance, and we show experimental results demonstrating the effectiveness of our system through simulations and a laboratory experiment based on real-world interactions.","1558-2426","","10.1109/TSMCA.2011.2164243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6017134","Adjustable autonomy;communication robots;human–robot interaction (HRI);multiple robots;networked robots;single-operator multiple-robot systems;social robots;supervisory control;teleoperation of social robots","Robot kinematics;Robot sensing systems;Humans;Measurement;Monitoring;Speech recognition","human-robot interaction;multi-robot systems;telerobotics","multiple social robots;remote operation;auditory multitasking;human-robot interaction design;HRI;autonomy design;multirobot coordination;teleoperation interface design;control architecture;conditional behavior flows;graphical interface;proactive timing control;robot performance","","33","","37","","12 Sep 2011","","","IEEE","IEEE Journals"
"Platform Calibration for Load Balancing of Large Simulations: TLM Case","C. Ruiz; M. Alexandru; O. Richard; T. Monteil; H. Aubert","LIG, INRIA MESCAL, Monbonnot Saint Martin, France; LAAS, Toulouse, France; LIG, INRIA MESCAL, Monbonnot Saint Martin, France; LAAS, Toulouse, France; LAAS, Toulouse, France","2014 14th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","8 Jul 2014","2014","","","465","472","The heterogeneous nature of distributed platforms such as computational Grids is one of the main barriers to effectively deploy tightly-coupled applications. For those applications, one common problem that appears due to the hardware heterogeneity is the load imbalance which slows down the application to the pace of the slower processor. One solution is to distribute the load adequately taking into account hardware capacities. To do so, an estimation of the hardware capacities for running the application has to be obtained. In this paper, we present a static load balancing for iterative tightly-coupled applications based on a profile prediction model. This technique is presented as a successful example of the interaction between experiment management tools and parallel applications. The experiment management tool Expo is used that enabled to: (1) provide a general, lightweight and descriptive way to capture the tuning and deployment of a parallel application in a computing infrastructure, (2) perform the tuning of the application efficiently in terms of human effort and resources needed. This paper reports the costs for carrying out the tuning of a large electromagnetic simulation based on TLM for the platform Grid'5000 and the improvements obtained on the total execution time of the application.","","978-1-4799-2784-5","10.1109/CCGrid.2014.26","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6846482","Load balancing;Experiment methodology;Large scale system;Grid computing;High performance computing;Transmission-line matrix methods","Computational modeling;Load management;Calibration;Load modeling;Computer architecture;Predictive models;Engines","calibration;computational electromagnetics;digital simulation;grid computing;parallel processing;resource allocation;transmission line matrix methods","platform calibration;distributed platforms;computational grids;hardware heterogeneity;load distribution;static load balancing;iterative tightly-coupled applications;profile prediction model;experiment management tool Expo;parallel application tuning;parallel application deployment;electromagnetic simulation tuning;TLM;transmission line matrix numerical method;Grid 5000 platform","","1","","21","","8 Jul 2014","","","IEEE","IEEE Conferences"
"Modeling of multifrequency process in lossy structures by using MAGY","A. N. Vlasov; T. M. Antonsen; K. T. Nguyen","Sci. Applications Int. Corp., McLean, VA, USA; NA; NA","ICOPS 2000. IEEE Conference Record - Abstracts. 27th IEEE International Conference on Plasma Science (Cat. No.00CH37087)","6 Aug 2002","2000","","","201","","Summary form only given. The computer code MAGY developed at the University of Maryland is able to describe the self-consistent nonlinear interaction between electromagnetic fields of an axisymmetric structure and a gyrating electron beam. The code was been used successfully to simulate the operation of both gyro-amplifiers and gyro-oscillators. New applications for gyrodevices require operation at high power and high frequency in overmoded structures. Consequently, multifrequncy processes including sub harmonic bunching can be expected to be important. At the same time suppression of unwanted parasitic modes is critical. One of the most efficient ways for suppression of parasitic modes is coating of the structure's wall by lossy materials and the inclusion of lossy ceramics. The self-consistent non-linear model in MAGY is based on the generalized telegrapher's equations for the electromagnetic field and the equations of motion averaged over period of fast cyclotron rotation for the electrons. A problem arises in cases in which the wall has a finite surface admittance. To avoid the divergence of series a new approach was developed. To test the developed approach the electromagnetic fields and its interaction with an electron beam in the beam tunnel containing lossy elements was analyzed. The studied beam tunnel was described completely by Pedrozzi et al., (1998). The results of calculations were compared with experimental data presented in Pedrozzi et al.'s work.","0730-9244","0-7803-5982-8","10.1109/PLASMA.2000.855007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=855007","","Electromagnetic fields;Electron beams;Nonlinear equations;Computational modeling;Application software;Frequency;Coatings;Ceramics;Electromagnetic modeling;Cyclotrons","gyrotrons;microwave tubes;electromagnetic fields;absorbing media;digital simulation","multifrequency process;lossy structures;MAGY computer code;self-consistent nonlinear interaction;electromagnetic fields;axisymmetric structure;gyrating electron beam;gyro-amplifiers;gyro-oscillators;overmoded structures;sub harmonic bunching;parasitic mode suppression;structure wall coating;lossy materials;lossy ceramics;generalized telegrapher's equations;electromagnetic field;fast cyclotron rotation;equations of motion;beam tunnel;electron beam","","","","2","","6 Aug 2002","","","IEEE","IEEE Conferences"
